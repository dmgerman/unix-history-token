begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * CDDL HEADER START  *  * The contents of this file are subject to the terms of the  * Common Development and Distribution License (the "License").  * You may not use this file except in compliance with the License.  *  * You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE  * or http://www.opensolaris.org/os/licensing.  * See the License for the specific language governing permissions  * and limitations under the License.  *  * When distributing Covered Code, include this CDDL HEADER in each  * file and include the License file at usr/src/OPENSOLARIS.LICENSE.  * If applicable, add the following below this CDDL HEADER, with the  * fields enclosed by brackets "[]" replaced with your own identifying  * information: Portions Copyright [yyyy] [name of copyright owner]  *  * CDDL HEADER END  */
end_comment

begin_comment
comment|/*  * Copyright (c) 2005, 2010, Oracle and/or its affiliates. All rights reserved.  * Copyright (c) 2011, 2015 by Delphix. All rights reserved.  * Copyright (c) 2013 by Saso Kiselkov. All rights reserved.  * Copyright (c) 2014 Integros [integros.com]  */
end_comment

begin_include
include|#
directive|include
file|<sys/zfs_context.h>
end_include

begin_include
include|#
directive|include
file|<sys/dmu.h>
end_include

begin_include
include|#
directive|include
file|<sys/dmu_tx.h>
end_include

begin_include
include|#
directive|include
file|<sys/space_map.h>
end_include

begin_include
include|#
directive|include
file|<sys/metaslab_impl.h>
end_include

begin_include
include|#
directive|include
file|<sys/vdev_impl.h>
end_include

begin_include
include|#
directive|include
file|<sys/zio.h>
end_include

begin_include
include|#
directive|include
file|<sys/spa_impl.h>
end_include

begin_include
include|#
directive|include
file|<sys/zfeature.h>
end_include

begin_define
define|#
directive|define
name|GANG_ALLOCATION
parameter_list|(
name|flags
parameter_list|)
define|\
value|((flags)& (METASLAB_GANG_CHILD | METASLAB_GANG_HEADER))
end_define

begin_decl_stmt
name|uint64_t
name|metaslab_aliquot
init|=
literal|512ULL
operator|<<
literal|10
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|metaslab_gang_bang
init|=
name|SPA_MAXBLOCKSIZE
operator|+
literal|1
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* force gang blocks */
end_comment

begin_comment
comment|/*  * The in-core space map representation is more compact than its on-disk form.  * The zfs_condense_pct determines how much more compact the in-core  * space map representation must be before we compact it on-disk.  * Values should be greater than or equal to 100.  */
end_comment

begin_decl_stmt
name|int
name|zfs_condense_pct
init|=
literal|200
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Condensing a metaslab is not guaranteed to actually reduce the amount of  * space used on disk. In particular, a space map uses data in increments of  * MAX(1<< ashift, space_map_blksize), so a metaslab might use the  * same number of blocks after condensing. Since the goal of condensing is to  * reduce the number of IOPs required to read the space map, we only want to  * condense when we can be sure we will reduce the number of blocks used by the  * space map. Unfortunately, we cannot precisely compute whether or not this is  * the case in metaslab_should_condense since we are holding ms_lock. Instead,  * we apply the following heuristic: do not condense a spacemap unless the  * uncondensed size consumes greater than zfs_metaslab_condense_block_threshold  * blocks.  */
end_comment

begin_decl_stmt
name|int
name|zfs_metaslab_condense_block_threshold
init|=
literal|4
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * The zfs_mg_noalloc_threshold defines which metaslab groups should  * be eligible for allocation. The value is defined as a percentage of  * free space. Metaslab groups that have more free space than  * zfs_mg_noalloc_threshold are always eligible for allocations. Once  * a metaslab group's free space is less than or equal to the  * zfs_mg_noalloc_threshold the allocator will avoid allocating to that  * group unless all groups in the pool have reached zfs_mg_noalloc_threshold.  * Once all groups in the pool reach zfs_mg_noalloc_threshold then all  * groups are allowed to accept allocations. Gang blocks are always  * eligible to allocate on any metaslab group. The default value of 0 means  * no metaslab group will be excluded based on this criterion.  */
end_comment

begin_decl_stmt
name|int
name|zfs_mg_noalloc_threshold
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Metaslab groups are considered eligible for allocations if their  * fragmenation metric (measured as a percentage) is less than or equal to  * zfs_mg_fragmentation_threshold. If a metaslab group exceeds this threshold  * then it will be skipped unless all metaslab groups within the metaslab  * class have also crossed this threshold.  */
end_comment

begin_decl_stmt
name|int
name|zfs_mg_fragmentation_threshold
init|=
literal|85
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Allow metaslabs to keep their active state as long as their fragmentation  * percentage is less than or equal to zfs_metaslab_fragmentation_threshold. An  * active metaslab that exceeds this threshold will no longer keep its active  * status allowing better metaslabs to be selected.  */
end_comment

begin_decl_stmt
name|int
name|zfs_metaslab_fragmentation_threshold
init|=
literal|70
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * When set will load all metaslabs when pool is first opened.  */
end_comment

begin_decl_stmt
name|int
name|metaslab_debug_load
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * When set will prevent metaslabs from being unloaded.  */
end_comment

begin_decl_stmt
name|int
name|metaslab_debug_unload
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Minimum size which forces the dynamic allocator to change  * it's allocation strategy.  Once the space map cannot satisfy  * an allocation of this size then it switches to using more  * aggressive strategy (i.e search by size rather than offset).  */
end_comment

begin_decl_stmt
name|uint64_t
name|metaslab_df_alloc_threshold
init|=
name|SPA_OLD_MAXBLOCKSIZE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * The minimum free space, in percent, which must be available  * in a space map to continue allocations in a first-fit fashion.  * Once the space map's free space drops below this level we dynamically  * switch to using best-fit allocations.  */
end_comment

begin_decl_stmt
name|int
name|metaslab_df_free_pct
init|=
literal|4
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * A metaslab is considered "free" if it contains a contiguous  * segment which is greater than metaslab_min_alloc_size.  */
end_comment

begin_decl_stmt
name|uint64_t
name|metaslab_min_alloc_size
init|=
name|DMU_MAX_ACCESS
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Percentage of all cpus that can be used by the metaslab taskq.  */
end_comment

begin_decl_stmt
name|int
name|metaslab_load_pct
init|=
literal|50
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Determines how many txgs a metaslab may remain loaded without having any  * allocations from it. As long as a metaslab continues to be used we will  * keep it loaded.  */
end_comment

begin_decl_stmt
name|int
name|metaslab_unload_delay
init|=
name|TXG_SIZE
operator|*
literal|2
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Max number of metaslabs per group to preload.  */
end_comment

begin_decl_stmt
name|int
name|metaslab_preload_limit
init|=
name|SPA_DVAS_PER_BP
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Enable/disable preloading of metaslab.  */
end_comment

begin_decl_stmt
name|boolean_t
name|metaslab_preload_enabled
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Enable/disable fragmentation weighting on metaslabs.  */
end_comment

begin_decl_stmt
name|boolean_t
name|metaslab_fragmentation_factor_enabled
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Enable/disable lba weighting (i.e. outer tracks are given preference).  */
end_comment

begin_decl_stmt
name|boolean_t
name|metaslab_lba_weighting_enabled
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Enable/disable metaslab group biasing.  */
end_comment

begin_decl_stmt
name|boolean_t
name|metaslab_bias_enabled
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Enable/disable segment-based metaslab selection.  */
end_comment

begin_decl_stmt
name|boolean_t
name|zfs_metaslab_segment_weight_enabled
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * When using segment-based metaslab selection, we will continue  * allocating from the active metaslab until we have exhausted  * zfs_metaslab_switch_threshold of its buckets.  */
end_comment

begin_decl_stmt
name|int
name|zfs_metaslab_switch_threshold
init|=
literal|2
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Internal switch to enable/disable the metaslab allocation tracing  * facility.  */
end_comment

begin_decl_stmt
name|boolean_t
name|metaslab_trace_enabled
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Maximum entries that the metaslab allocation tracing facility will keep  * in a given list when running in non-debug mode. We limit the number  * of entries in non-debug mode to prevent us from using up too much memory.  * The limit should be sufficiently large that we don't expect any allocation  * to every exceed this value. In debug mode, the system will panic if this  * limit is ever reached allowing for further investigation.  */
end_comment

begin_decl_stmt
name|uint64_t
name|metaslab_trace_max_entries
init|=
literal|5000
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|uint64_t
name|metaslab_weight
parameter_list|(
name|metaslab_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|metaslab_set_fragmentation
parameter_list|(
name|metaslab_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
name|kmem_cache_t
modifier|*
name|metaslab_alloc_trace_cache
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * ==========================================================================  * Metaslab classes  * ==========================================================================  */
end_comment

begin_function
name|metaslab_class_t
modifier|*
name|metaslab_class_create
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|metaslab_ops_t
modifier|*
name|ops
parameter_list|)
block|{
name|metaslab_class_t
modifier|*
name|mc
decl_stmt|;
name|mc
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|metaslab_class_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|mc
operator|->
name|mc_spa
operator|=
name|spa
expr_stmt|;
name|mc
operator|->
name|mc_rotor
operator|=
name|NULL
expr_stmt|;
name|mc
operator|->
name|mc_ops
operator|=
name|ops
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|mc
operator|->
name|mc_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|refcount_create_tracked
argument_list|(
operator|&
name|mc
operator|->
name|mc_alloc_slots
argument_list|)
expr_stmt|;
return|return
operator|(
name|mc
operator|)
return|;
block|}
end_function

begin_function
name|void
name|metaslab_class_destroy
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|mc
operator|->
name|mc_rotor
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mc
operator|->
name|mc_alloc
operator|==
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mc
operator|->
name|mc_deferred
operator|==
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mc
operator|->
name|mc_space
operator|==
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mc
operator|->
name|mc_dspace
operator|==
literal|0
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|mc
operator|->
name|mc_alloc_slots
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|mc
operator|->
name|mc_lock
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|mc
argument_list|,
sizeof|sizeof
argument_list|(
name|metaslab_class_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|metaslab_class_validate
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|)
block|{
name|metaslab_group_t
modifier|*
name|mg
decl_stmt|;
name|vdev_t
modifier|*
name|vd
decl_stmt|;
comment|/* 	 * Must hold one of the spa_config locks. 	 */
name|ASSERT
argument_list|(
name|spa_config_held
argument_list|(
name|mc
operator|->
name|mc_spa
argument_list|,
name|SCL_ALL
argument_list|,
name|RW_READER
argument_list|)
operator|||
name|spa_config_held
argument_list|(
name|mc
operator|->
name|mc_spa
argument_list|,
name|SCL_ALL
argument_list|,
name|RW_WRITER
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|mg
operator|=
name|mc
operator|->
name|mc_rotor
operator|)
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
do|do
block|{
name|vd
operator|=
name|mg
operator|->
name|mg_vd
expr_stmt|;
name|ASSERT
argument_list|(
name|vd
operator|->
name|vdev_mg
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|vd
operator|->
name|vdev_top
argument_list|,
operator|==
argument_list|,
name|vd
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|mg
operator|->
name|mg_class
argument_list|,
operator|==
argument_list|,
name|mc
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|vd
operator|->
name|vdev_ops
argument_list|,
operator|!=
argument_list|,
operator|&
name|vdev_hole_ops
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
operator|(
name|mg
operator|=
name|mg
operator|->
name|mg_next
operator|)
operator|!=
name|mc
operator|->
name|mc_rotor
condition|)
do|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|void
name|metaslab_class_space_update
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|,
name|int64_t
name|alloc_delta
parameter_list|,
name|int64_t
name|defer_delta
parameter_list|,
name|int64_t
name|space_delta
parameter_list|,
name|int64_t
name|dspace_delta
parameter_list|)
block|{
name|atomic_add_64
argument_list|(
operator|&
name|mc
operator|->
name|mc_alloc
argument_list|,
name|alloc_delta
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|mc
operator|->
name|mc_deferred
argument_list|,
name|defer_delta
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|mc
operator|->
name|mc_space
argument_list|,
name|space_delta
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|mc
operator|->
name|mc_dspace
argument_list|,
name|dspace_delta
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|uint64_t
name|metaslab_class_get_alloc
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|)
block|{
return|return
operator|(
name|mc
operator|->
name|mc_alloc
operator|)
return|;
block|}
end_function

begin_function
name|uint64_t
name|metaslab_class_get_deferred
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|)
block|{
return|return
operator|(
name|mc
operator|->
name|mc_deferred
operator|)
return|;
block|}
end_function

begin_function
name|uint64_t
name|metaslab_class_get_space
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|)
block|{
return|return
operator|(
name|mc
operator|->
name|mc_space
operator|)
return|;
block|}
end_function

begin_function
name|uint64_t
name|metaslab_class_get_dspace
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|)
block|{
return|return
operator|(
name|spa_deflate
argument_list|(
name|mc
operator|->
name|mc_spa
argument_list|)
condition|?
name|mc
operator|->
name|mc_dspace
else|:
name|mc
operator|->
name|mc_space
operator|)
return|;
block|}
end_function

begin_function
name|void
name|metaslab_class_histogram_verify
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|)
block|{
name|vdev_t
modifier|*
name|rvd
init|=
name|mc
operator|->
name|mc_spa
operator|->
name|spa_root_vdev
decl_stmt|;
name|uint64_t
modifier|*
name|mc_hist
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
operator|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_HISTOGRAM_VERIFY
operator|)
operator|==
literal|0
condition|)
return|return;
name|mc_hist
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
operator|*
name|RANGE_TREE_HISTOGRAM_SIZE
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|c
init|=
literal|0
init|;
name|c
operator|<
name|rvd
operator|->
name|vdev_children
condition|;
name|c
operator|++
control|)
block|{
name|vdev_t
modifier|*
name|tvd
init|=
name|rvd
operator|->
name|vdev_child
index|[
name|c
index|]
decl_stmt|;
name|metaslab_group_t
modifier|*
name|mg
init|=
name|tvd
operator|->
name|vdev_mg
decl_stmt|;
comment|/* 		 * Skip any holes, uninitialized top-levels, or 		 * vdevs that are not in this metalab class. 		 */
if|if
condition|(
name|tvd
operator|->
name|vdev_ishole
operator|||
name|tvd
operator|->
name|vdev_ms_shift
operator|==
literal|0
operator|||
name|mg
operator|->
name|mg_class
operator|!=
name|mc
condition|)
block|{
continue|continue;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|RANGE_TREE_HISTOGRAM_SIZE
condition|;
name|i
operator|++
control|)
name|mc_hist
index|[
name|i
index|]
operator|+=
name|mg
operator|->
name|mg_histogram
index|[
name|i
index|]
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|RANGE_TREE_HISTOGRAM_SIZE
condition|;
name|i
operator|++
control|)
name|VERIFY3U
argument_list|(
name|mc_hist
index|[
name|i
index|]
argument_list|,
operator|==
argument_list|,
name|mc
operator|->
name|mc_histogram
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|mc_hist
argument_list|,
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
operator|*
name|RANGE_TREE_HISTOGRAM_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Calculate the metaslab class's fragmentation metric. The metric  * is weighted based on the space contribution of each metaslab group.  * The return value will be a number between 0 and 100 (inclusive), or  * ZFS_FRAG_INVALID if the metric has not been set. See comment above the  * zfs_frag_table for more information about the metric.  */
end_comment

begin_function
name|uint64_t
name|metaslab_class_fragmentation
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|)
block|{
name|vdev_t
modifier|*
name|rvd
init|=
name|mc
operator|->
name|mc_spa
operator|->
name|spa_root_vdev
decl_stmt|;
name|uint64_t
name|fragmentation
init|=
literal|0
decl_stmt|;
name|spa_config_enter
argument_list|(
name|mc
operator|->
name|mc_spa
argument_list|,
name|SCL_VDEV
argument_list|,
name|FTAG
argument_list|,
name|RW_READER
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|c
init|=
literal|0
init|;
name|c
operator|<
name|rvd
operator|->
name|vdev_children
condition|;
name|c
operator|++
control|)
block|{
name|vdev_t
modifier|*
name|tvd
init|=
name|rvd
operator|->
name|vdev_child
index|[
name|c
index|]
decl_stmt|;
name|metaslab_group_t
modifier|*
name|mg
init|=
name|tvd
operator|->
name|vdev_mg
decl_stmt|;
comment|/* 		 * Skip any holes, uninitialized top-levels, or 		 * vdevs that are not in this metalab class. 		 */
if|if
condition|(
name|tvd
operator|->
name|vdev_ishole
operator|||
name|tvd
operator|->
name|vdev_ms_shift
operator|==
literal|0
operator|||
name|mg
operator|->
name|mg_class
operator|!=
name|mc
condition|)
block|{
continue|continue;
block|}
comment|/* 		 * If a metaslab group does not contain a fragmentation 		 * metric then just bail out. 		 */
if|if
condition|(
name|mg
operator|->
name|mg_fragmentation
operator|==
name|ZFS_FRAG_INVALID
condition|)
block|{
name|spa_config_exit
argument_list|(
name|mc
operator|->
name|mc_spa
argument_list|,
name|SCL_VDEV
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
return|return
operator|(
name|ZFS_FRAG_INVALID
operator|)
return|;
block|}
comment|/* 		 * Determine how much this metaslab_group is contributing 		 * to the overall pool fragmentation metric. 		 */
name|fragmentation
operator|+=
name|mg
operator|->
name|mg_fragmentation
operator|*
name|metaslab_group_get_space
argument_list|(
name|mg
argument_list|)
expr_stmt|;
block|}
name|fragmentation
operator|/=
name|metaslab_class_get_space
argument_list|(
name|mc
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|fragmentation
argument_list|,
operator|<=
argument_list|,
literal|100
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|mc
operator|->
name|mc_spa
argument_list|,
name|SCL_VDEV
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
return|return
operator|(
name|fragmentation
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Calculate the amount of expandable space that is available in  * this metaslab class. If a device is expanded then its expandable  * space will be the amount of allocatable space that is currently not  * part of this metaslab class.  */
end_comment

begin_function
name|uint64_t
name|metaslab_class_expandable_space
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|)
block|{
name|vdev_t
modifier|*
name|rvd
init|=
name|mc
operator|->
name|mc_spa
operator|->
name|spa_root_vdev
decl_stmt|;
name|uint64_t
name|space
init|=
literal|0
decl_stmt|;
name|spa_config_enter
argument_list|(
name|mc
operator|->
name|mc_spa
argument_list|,
name|SCL_VDEV
argument_list|,
name|FTAG
argument_list|,
name|RW_READER
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|c
init|=
literal|0
init|;
name|c
operator|<
name|rvd
operator|->
name|vdev_children
condition|;
name|c
operator|++
control|)
block|{
name|vdev_t
modifier|*
name|tvd
init|=
name|rvd
operator|->
name|vdev_child
index|[
name|c
index|]
decl_stmt|;
name|metaslab_group_t
modifier|*
name|mg
init|=
name|tvd
operator|->
name|vdev_mg
decl_stmt|;
if|if
condition|(
name|tvd
operator|->
name|vdev_ishole
operator|||
name|tvd
operator|->
name|vdev_ms_shift
operator|==
literal|0
operator|||
name|mg
operator|->
name|mg_class
operator|!=
name|mc
condition|)
block|{
continue|continue;
block|}
comment|/* 		 * Calculate if we have enough space to add additional 		 * metaslabs. We report the expandable space in terms 		 * of the metaslab size since that's the unit of expansion. 		 */
name|space
operator|+=
name|P2ALIGN
argument_list|(
name|tvd
operator|->
name|vdev_max_asize
operator|-
name|tvd
operator|->
name|vdev_asize
argument_list|,
literal|1ULL
operator|<<
name|tvd
operator|->
name|vdev_ms_shift
argument_list|)
expr_stmt|;
block|}
name|spa_config_exit
argument_list|(
name|mc
operator|->
name|mc_spa
argument_list|,
name|SCL_VDEV
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
return|return
operator|(
name|space
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|metaslab_compare
parameter_list|(
specifier|const
name|void
modifier|*
name|x1
parameter_list|,
specifier|const
name|void
modifier|*
name|x2
parameter_list|)
block|{
specifier|const
name|metaslab_t
modifier|*
name|m1
init|=
name|x1
decl_stmt|;
specifier|const
name|metaslab_t
modifier|*
name|m2
init|=
name|x2
decl_stmt|;
if|if
condition|(
name|m1
operator|->
name|ms_weight
operator|<
name|m2
operator|->
name|ms_weight
condition|)
return|return
operator|(
literal|1
operator|)
return|;
if|if
condition|(
name|m1
operator|->
name|ms_weight
operator|>
name|m2
operator|->
name|ms_weight
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
comment|/* 	 * If the weights are identical, use the offset to force uniqueness. 	 */
if|if
condition|(
name|m1
operator|->
name|ms_start
operator|<
name|m2
operator|->
name|ms_start
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
if|if
condition|(
name|m1
operator|->
name|ms_start
operator|>
name|m2
operator|->
name|ms_start
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|ASSERT3P
argument_list|(
name|m1
argument_list|,
operator|==
argument_list|,
name|m2
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Verify that the space accounting on disk matches the in-core range_trees.  */
end_comment

begin_function
name|void
name|metaslab_verify_space
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|txg
parameter_list|)
block|{
name|spa_t
modifier|*
name|spa
init|=
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_spa
decl_stmt|;
name|uint64_t
name|allocated
init|=
literal|0
decl_stmt|;
name|uint64_t
name|sm_free_space
decl_stmt|,
name|msp_free_space
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_METASLAB_VERIFY
operator|)
operator|==
literal|0
condition|)
return|return;
comment|/* 	 * We can only verify the metaslab space when we're called 	 * from syncing context with a loaded metaslab that has an allocated 	 * space map. Calling this in non-syncing context does not 	 * provide a consistent view of the metaslab since we're performing 	 * allocations in the future. 	 */
if|if
condition|(
name|txg
operator|!=
name|spa_syncing_txg
argument_list|(
name|spa
argument_list|)
operator|||
name|msp
operator|->
name|ms_sm
operator|==
name|NULL
operator|||
operator|!
name|msp
operator|->
name|ms_loaded
condition|)
return|return;
name|sm_free_space
operator|=
name|msp
operator|->
name|ms_size
operator|-
name|space_map_allocated
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
operator|-
name|space_map_alloc_delta
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
expr_stmt|;
comment|/* 	 * Account for future allocations since we would have already 	 * deducted that space from the ms_freetree. 	 */
for|for
control|(
name|int
name|t
init|=
literal|0
init|;
name|t
operator|<
name|TXG_CONCURRENT_STATES
condition|;
name|t
operator|++
control|)
block|{
name|allocated
operator|+=
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
operator|(
name|txg
operator|+
name|t
operator|)
operator|&
name|TXG_MASK
index|]
argument_list|)
expr_stmt|;
block|}
name|msp_free_space
operator|=
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|)
operator|+
name|allocated
operator|+
name|msp
operator|->
name|ms_deferspace
operator|+
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_freedtree
argument_list|)
expr_stmt|;
name|VERIFY3U
argument_list|(
name|sm_free_space
argument_list|,
operator|==
argument_list|,
name|msp_free_space
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * ==========================================================================  * Metaslab groups  * ==========================================================================  */
end_comment

begin_comment
comment|/*  * Update the allocatable flag and the metaslab group's capacity.  * The allocatable flag is set to true if the capacity is below  * the zfs_mg_noalloc_threshold or has a fragmentation value that is  * greater than zfs_mg_fragmentation_threshold. If a metaslab group  * transitions from allocatable to non-allocatable or vice versa then the  * metaslab group's class is updated to reflect the transition.  */
end_comment

begin_function
specifier|static
name|void
name|metaslab_group_alloc_update
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|)
block|{
name|vdev_t
modifier|*
name|vd
init|=
name|mg
operator|->
name|mg_vd
decl_stmt|;
name|metaslab_class_t
modifier|*
name|mc
init|=
name|mg
operator|->
name|mg_class
decl_stmt|;
name|vdev_stat_t
modifier|*
name|vs
init|=
operator|&
name|vd
operator|->
name|vdev_stat
decl_stmt|;
name|boolean_t
name|was_allocatable
decl_stmt|;
name|boolean_t
name|was_initialized
decl_stmt|;
name|ASSERT
argument_list|(
name|vd
operator|==
name|vd
operator|->
name|vdev_top
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
name|was_allocatable
operator|=
name|mg
operator|->
name|mg_allocatable
expr_stmt|;
name|was_initialized
operator|=
name|mg
operator|->
name|mg_initialized
expr_stmt|;
name|mg
operator|->
name|mg_free_capacity
operator|=
operator|(
operator|(
name|vs
operator|->
name|vs_space
operator|-
name|vs
operator|->
name|vs_alloc
operator|)
operator|*
literal|100
operator|)
operator|/
operator|(
name|vs
operator|->
name|vs_space
operator|+
literal|1
operator|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|mc
operator|->
name|mc_lock
argument_list|)
expr_stmt|;
comment|/* 	 * If the metaslab group was just added then it won't 	 * have any space until we finish syncing out this txg. 	 * At that point we will consider it initialized and available 	 * for allocations.  We also don't consider non-activated 	 * metaslab groups (e.g. vdevs that are in the middle of being removed) 	 * to be initialized, because they can't be used for allocation. 	 */
name|mg
operator|->
name|mg_initialized
operator|=
name|metaslab_group_initialized
argument_list|(
name|mg
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|was_initialized
operator|&&
name|mg
operator|->
name|mg_initialized
condition|)
block|{
name|mc
operator|->
name|mc_groups
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|was_initialized
operator|&&
operator|!
name|mg
operator|->
name|mg_initialized
condition|)
block|{
name|ASSERT3U
argument_list|(
name|mc
operator|->
name|mc_groups
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|mc
operator|->
name|mc_groups
operator|--
expr_stmt|;
block|}
if|if
condition|(
name|mg
operator|->
name|mg_initialized
condition|)
name|mg
operator|->
name|mg_no_free_space
operator|=
name|B_FALSE
expr_stmt|;
comment|/* 	 * A metaslab group is considered allocatable if it has plenty 	 * of free space or is not heavily fragmented. We only take 	 * fragmentation into account if the metaslab group has a valid 	 * fragmentation metric (i.e. a value between 0 and 100). 	 */
name|mg
operator|->
name|mg_allocatable
operator|=
operator|(
name|mg
operator|->
name|mg_activation_count
operator|>
literal|0
operator|&&
name|mg
operator|->
name|mg_free_capacity
operator|>
name|zfs_mg_noalloc_threshold
operator|&&
operator|(
name|mg
operator|->
name|mg_fragmentation
operator|==
name|ZFS_FRAG_INVALID
operator|||
name|mg
operator|->
name|mg_fragmentation
operator|<=
name|zfs_mg_fragmentation_threshold
operator|)
operator|)
expr_stmt|;
comment|/* 	 * The mc_alloc_groups maintains a count of the number of 	 * groups in this metaslab class that are still above the 	 * zfs_mg_noalloc_threshold. This is used by the allocating 	 * threads to determine if they should avoid allocations to 	 * a given group. The allocator will avoid allocations to a group 	 * if that group has reached or is below the zfs_mg_noalloc_threshold 	 * and there are still other groups that are above the threshold. 	 * When a group transitions from allocatable to non-allocatable or 	 * vice versa we update the metaslab class to reflect that change. 	 * When the mc_alloc_groups value drops to 0 that means that all 	 * groups have reached the zfs_mg_noalloc_threshold making all groups 	 * eligible for allocations. This effectively means that all devices 	 * are balanced again. 	 */
if|if
condition|(
name|was_allocatable
operator|&&
operator|!
name|mg
operator|->
name|mg_allocatable
condition|)
name|mc
operator|->
name|mc_alloc_groups
operator|--
expr_stmt|;
elseif|else
if|if
condition|(
operator|!
name|was_allocatable
operator|&&
name|mg
operator|->
name|mg_allocatable
condition|)
name|mc
operator|->
name|mc_alloc_groups
operator|++
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|mc
operator|->
name|mc_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|metaslab_group_t
modifier|*
name|metaslab_group_create
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|,
name|vdev_t
modifier|*
name|vd
parameter_list|)
block|{
name|metaslab_group_t
modifier|*
name|mg
decl_stmt|;
name|mg
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|metaslab_group_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|avl_create
argument_list|(
operator|&
name|mg
operator|->
name|mg_metaslab_tree
argument_list|,
name|metaslab_compare
argument_list|,
sizeof|sizeof
argument_list|(
name|metaslab_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
expr|struct
name|metaslab
argument_list|,
name|ms_group_node
argument_list|)
argument_list|)
expr_stmt|;
name|mg
operator|->
name|mg_vd
operator|=
name|vd
expr_stmt|;
name|mg
operator|->
name|mg_class
operator|=
name|mc
expr_stmt|;
name|mg
operator|->
name|mg_activation_count
operator|=
literal|0
expr_stmt|;
name|mg
operator|->
name|mg_initialized
operator|=
name|B_FALSE
expr_stmt|;
name|mg
operator|->
name|mg_no_free_space
operator|=
name|B_TRUE
expr_stmt|;
name|refcount_create_tracked
argument_list|(
operator|&
name|mg
operator|->
name|mg_alloc_queue_depth
argument_list|)
expr_stmt|;
name|mg
operator|->
name|mg_taskq
operator|=
name|taskq_create
argument_list|(
literal|"metaslab_group_taskq"
argument_list|,
name|metaslab_load_pct
argument_list|,
name|minclsyspri
argument_list|,
literal|10
argument_list|,
name|INT_MAX
argument_list|,
name|TASKQ_THREADS_CPU_PCT
argument_list|)
expr_stmt|;
return|return
operator|(
name|mg
operator|)
return|;
block|}
end_function

begin_function
name|void
name|metaslab_group_destroy
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_prev
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_next
operator|==
name|NULL
argument_list|)
expr_stmt|;
comment|/* 	 * We may have gone below zero with the activation count 	 * either because we never activated in the first place or 	 * because we're done, and possibly removing the vdev. 	 */
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_activation_count
operator|<=
literal|0
argument_list|)
expr_stmt|;
name|taskq_destroy
argument_list|(
name|mg
operator|->
name|mg_taskq
argument_list|)
expr_stmt|;
name|avl_destroy
argument_list|(
operator|&
name|mg
operator|->
name|mg_metaslab_tree
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|mg
operator|->
name|mg_alloc_queue_depth
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|mg
argument_list|,
sizeof|sizeof
argument_list|(
name|metaslab_group_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|metaslab_group_activate
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|)
block|{
name|metaslab_class_t
modifier|*
name|mc
init|=
name|mg
operator|->
name|mg_class
decl_stmt|;
name|metaslab_group_t
modifier|*
name|mgprev
decl_stmt|,
modifier|*
name|mgnext
decl_stmt|;
name|ASSERT
argument_list|(
name|spa_config_held
argument_list|(
name|mc
operator|->
name|mc_spa
argument_list|,
name|SCL_ALLOC
argument_list|,
name|RW_WRITER
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mc
operator|->
name|mc_rotor
operator|!=
name|mg
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_prev
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_next
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_activation_count
operator|<=
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|++
name|mg
operator|->
name|mg_activation_count
operator|<=
literal|0
condition|)
return|return;
name|mg
operator|->
name|mg_aliquot
operator|=
name|metaslab_aliquot
operator|*
name|MAX
argument_list|(
literal|1
argument_list|,
name|mg
operator|->
name|mg_vd
operator|->
name|vdev_children
argument_list|)
expr_stmt|;
name|metaslab_group_alloc_update
argument_list|(
name|mg
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|mgprev
operator|=
name|mc
operator|->
name|mc_rotor
operator|)
operator|==
name|NULL
condition|)
block|{
name|mg
operator|->
name|mg_prev
operator|=
name|mg
expr_stmt|;
name|mg
operator|->
name|mg_next
operator|=
name|mg
expr_stmt|;
block|}
else|else
block|{
name|mgnext
operator|=
name|mgprev
operator|->
name|mg_next
expr_stmt|;
name|mg
operator|->
name|mg_prev
operator|=
name|mgprev
expr_stmt|;
name|mg
operator|->
name|mg_next
operator|=
name|mgnext
expr_stmt|;
name|mgprev
operator|->
name|mg_next
operator|=
name|mg
expr_stmt|;
name|mgnext
operator|->
name|mg_prev
operator|=
name|mg
expr_stmt|;
block|}
name|mc
operator|->
name|mc_rotor
operator|=
name|mg
expr_stmt|;
block|}
end_function

begin_function
name|void
name|metaslab_group_passivate
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|)
block|{
name|metaslab_class_t
modifier|*
name|mc
init|=
name|mg
operator|->
name|mg_class
decl_stmt|;
name|metaslab_group_t
modifier|*
name|mgprev
decl_stmt|,
modifier|*
name|mgnext
decl_stmt|;
name|ASSERT
argument_list|(
name|spa_config_held
argument_list|(
name|mc
operator|->
name|mc_spa
argument_list|,
name|SCL_ALLOC
argument_list|,
name|RW_WRITER
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|--
name|mg
operator|->
name|mg_activation_count
operator|!=
literal|0
condition|)
block|{
name|ASSERT
argument_list|(
name|mc
operator|->
name|mc_rotor
operator|!=
name|mg
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_prev
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_next
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_activation_count
operator|<
literal|0
argument_list|)
expr_stmt|;
return|return;
block|}
name|taskq_wait
argument_list|(
name|mg
operator|->
name|mg_taskq
argument_list|)
expr_stmt|;
name|metaslab_group_alloc_update
argument_list|(
name|mg
argument_list|)
expr_stmt|;
name|mgprev
operator|=
name|mg
operator|->
name|mg_prev
expr_stmt|;
name|mgnext
operator|=
name|mg
operator|->
name|mg_next
expr_stmt|;
if|if
condition|(
name|mg
operator|==
name|mgnext
condition|)
block|{
name|mc
operator|->
name|mc_rotor
operator|=
name|NULL
expr_stmt|;
block|}
else|else
block|{
name|mc
operator|->
name|mc_rotor
operator|=
name|mgnext
expr_stmt|;
name|mgprev
operator|->
name|mg_next
operator|=
name|mgnext
expr_stmt|;
name|mgnext
operator|->
name|mg_prev
operator|=
name|mgprev
expr_stmt|;
block|}
name|mg
operator|->
name|mg_prev
operator|=
name|NULL
expr_stmt|;
name|mg
operator|->
name|mg_next
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_function
name|boolean_t
name|metaslab_group_initialized
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|)
block|{
name|vdev_t
modifier|*
name|vd
init|=
name|mg
operator|->
name|mg_vd
decl_stmt|;
name|vdev_stat_t
modifier|*
name|vs
init|=
operator|&
name|vd
operator|->
name|vdev_stat
decl_stmt|;
return|return
operator|(
name|vs
operator|->
name|vs_space
operator|!=
literal|0
operator|&&
name|mg
operator|->
name|mg_activation_count
operator|>
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|uint64_t
name|metaslab_group_get_space
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|)
block|{
return|return
operator|(
operator|(
literal|1ULL
operator|<<
name|mg
operator|->
name|mg_vd
operator|->
name|vdev_ms_shift
operator|)
operator|*
name|mg
operator|->
name|mg_vd
operator|->
name|vdev_ms_count
operator|)
return|;
block|}
end_function

begin_function
name|void
name|metaslab_group_histogram_verify
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|)
block|{
name|uint64_t
modifier|*
name|mg_hist
decl_stmt|;
name|vdev_t
modifier|*
name|vd
init|=
name|mg
operator|->
name|mg_vd
decl_stmt|;
name|uint64_t
name|ashift
init|=
name|vd
operator|->
name|vdev_ashift
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
operator|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_HISTOGRAM_VERIFY
operator|)
operator|==
literal|0
condition|)
return|return;
name|mg_hist
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
operator|*
name|RANGE_TREE_HISTOGRAM_SIZE
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|RANGE_TREE_HISTOGRAM_SIZE
argument_list|,
operator|>=
argument_list|,
name|SPACE_MAP_HISTOGRAM_SIZE
operator|+
name|ashift
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|m
init|=
literal|0
init|;
name|m
operator|<
name|vd
operator|->
name|vdev_ms_count
condition|;
name|m
operator|++
control|)
block|{
name|metaslab_t
modifier|*
name|msp
init|=
name|vd
operator|->
name|vdev_ms
index|[
name|m
index|]
decl_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_sm
operator|==
name|NULL
condition|)
continue|continue;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|SPACE_MAP_HISTOGRAM_SIZE
condition|;
name|i
operator|++
control|)
name|mg_hist
index|[
name|i
operator|+
name|ashift
index|]
operator|+=
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|RANGE_TREE_HISTOGRAM_SIZE
condition|;
name|i
operator|++
control|)
name|VERIFY3U
argument_list|(
name|mg_hist
index|[
name|i
index|]
argument_list|,
operator|==
argument_list|,
name|mg
operator|->
name|mg_histogram
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|mg_hist
argument_list|,
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
operator|*
name|RANGE_TREE_HISTOGRAM_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|metaslab_group_histogram_add
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|,
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|metaslab_class_t
modifier|*
name|mc
init|=
name|mg
operator|->
name|mg_class
decl_stmt|;
name|uint64_t
name|ashift
init|=
name|mg
operator|->
name|mg_vd
operator|->
name|vdev_ashift
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_sm
operator|==
name|NULL
condition|)
return|return;
name|mutex_enter
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|SPACE_MAP_HISTOGRAM_SIZE
condition|;
name|i
operator|++
control|)
block|{
name|mg
operator|->
name|mg_histogram
index|[
name|i
operator|+
name|ashift
index|]
operator|+=
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
expr_stmt|;
name|mc
operator|->
name|mc_histogram
index|[
name|i
operator|+
name|ashift
index|]
operator|+=
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|metaslab_group_histogram_remove
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|,
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|metaslab_class_t
modifier|*
name|mc
init|=
name|mg
operator|->
name|mg_class
decl_stmt|;
name|uint64_t
name|ashift
init|=
name|mg
operator|->
name|mg_vd
operator|->
name|vdev_ashift
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_sm
operator|==
name|NULL
condition|)
return|return;
name|mutex_enter
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|SPACE_MAP_HISTOGRAM_SIZE
condition|;
name|i
operator|++
control|)
block|{
name|ASSERT3U
argument_list|(
name|mg
operator|->
name|mg_histogram
index|[
name|i
operator|+
name|ashift
index|]
argument_list|,
operator|>=
argument_list|,
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|mc
operator|->
name|mc_histogram
index|[
name|i
operator|+
name|ashift
index|]
argument_list|,
operator|>=
argument_list|,
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|mg
operator|->
name|mg_histogram
index|[
name|i
operator|+
name|ashift
index|]
operator|-=
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
expr_stmt|;
name|mc
operator|->
name|mc_histogram
index|[
name|i
operator|+
name|ashift
index|]
operator|-=
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|metaslab_group_add
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|,
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_group
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_group
operator|=
name|mg
expr_stmt|;
name|msp
operator|->
name|ms_weight
operator|=
literal|0
expr_stmt|;
name|avl_add
argument_list|(
operator|&
name|mg
operator|->
name|mg_metaslab_tree
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|metaslab_group_histogram_add
argument_list|(
name|mg
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|metaslab_group_remove
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|,
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|metaslab_group_histogram_remove
argument_list|(
name|mg
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_group
operator|==
name|mg
argument_list|)
expr_stmt|;
name|avl_remove
argument_list|(
operator|&
name|mg
operator|->
name|mg_metaslab_tree
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_group
operator|=
name|NULL
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|metaslab_group_sort
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|,
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|weight
parameter_list|)
block|{
comment|/* 	 * Although in principle the weight can be any value, in 	 * practice we do not use values in the range [1, 511]. 	 */
name|ASSERT
argument_list|(
name|weight
operator|>=
name|SPA_MINBLOCKSIZE
operator|||
name|weight
operator|==
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_group
operator|==
name|mg
argument_list|)
expr_stmt|;
name|avl_remove
argument_list|(
operator|&
name|mg
operator|->
name|mg_metaslab_tree
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_weight
operator|=
name|weight
expr_stmt|;
name|avl_add
argument_list|(
operator|&
name|mg
operator|->
name|mg_metaslab_tree
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Calculate the fragmentation for a given metaslab group. We can use  * a simple average here since all metaslabs within the group must have  * the same size. The return value will be a value between 0 and 100  * (inclusive), or ZFS_FRAG_INVALID if less than half of the metaslab in this  * group have a fragmentation metric.  */
end_comment

begin_function
name|uint64_t
name|metaslab_group_fragmentation
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|)
block|{
name|vdev_t
modifier|*
name|vd
init|=
name|mg
operator|->
name|mg_vd
decl_stmt|;
name|uint64_t
name|fragmentation
init|=
literal|0
decl_stmt|;
name|uint64_t
name|valid_ms
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|m
init|=
literal|0
init|;
name|m
operator|<
name|vd
operator|->
name|vdev_ms_count
condition|;
name|m
operator|++
control|)
block|{
name|metaslab_t
modifier|*
name|msp
init|=
name|vd
operator|->
name|vdev_ms
index|[
name|m
index|]
decl_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_fragmentation
operator|==
name|ZFS_FRAG_INVALID
condition|)
continue|continue;
name|valid_ms
operator|++
expr_stmt|;
name|fragmentation
operator|+=
name|msp
operator|->
name|ms_fragmentation
expr_stmt|;
block|}
if|if
condition|(
name|valid_ms
operator|<=
name|vd
operator|->
name|vdev_ms_count
operator|/
literal|2
condition|)
return|return
operator|(
name|ZFS_FRAG_INVALID
operator|)
return|;
name|fragmentation
operator|/=
name|valid_ms
expr_stmt|;
name|ASSERT3U
argument_list|(
name|fragmentation
argument_list|,
operator|<=
argument_list|,
literal|100
argument_list|)
expr_stmt|;
return|return
operator|(
name|fragmentation
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Determine if a given metaslab group should skip allocations. A metaslab  * group should avoid allocations if its free capacity is less than the  * zfs_mg_noalloc_threshold or its fragmentation metric is greater than  * zfs_mg_fragmentation_threshold and there is at least one metaslab group  * that can still handle allocations. If the allocation throttle is enabled  * then we skip allocations to devices that have reached their maximum  * allocation queue depth unless the selected metaslab group is the only  * eligible group remaining.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|metaslab_group_allocatable
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|,
name|metaslab_group_t
modifier|*
name|rotor
parameter_list|,
name|uint64_t
name|psize
parameter_list|)
block|{
name|spa_t
modifier|*
name|spa
init|=
name|mg
operator|->
name|mg_vd
operator|->
name|vdev_spa
decl_stmt|;
name|metaslab_class_t
modifier|*
name|mc
init|=
name|mg
operator|->
name|mg_class
decl_stmt|;
comment|/* 	 * We can only consider skipping this metaslab group if it's 	 * in the normal metaslab class and there are other metaslab 	 * groups to select from. Otherwise, we always consider it eligible 	 * for allocations. 	 */
if|if
condition|(
name|mc
operator|!=
name|spa_normal_class
argument_list|(
name|spa
argument_list|)
operator|||
name|mc
operator|->
name|mc_groups
operator|<=
literal|1
condition|)
return|return
operator|(
name|B_TRUE
operator|)
return|;
comment|/* 	 * If the metaslab group's mg_allocatable flag is set (see comments 	 * in metaslab_group_alloc_update() for more information) and 	 * the allocation throttle is disabled then allow allocations to this 	 * device. However, if the allocation throttle is enabled then 	 * check if we have reached our allocation limit (mg_alloc_queue_depth) 	 * to determine if we should allow allocations to this metaslab group. 	 * If all metaslab groups are no longer considered allocatable 	 * (mc_alloc_groups == 0) or we're trying to allocate the smallest 	 * gang block size then we allow allocations on this metaslab group 	 * regardless of the mg_allocatable or throttle settings. 	 */
if|if
condition|(
name|mg
operator|->
name|mg_allocatable
condition|)
block|{
name|metaslab_group_t
modifier|*
name|mgp
decl_stmt|;
name|int64_t
name|qdepth
decl_stmt|;
name|uint64_t
name|qmax
init|=
name|mg
operator|->
name|mg_max_alloc_queue_depth
decl_stmt|;
if|if
condition|(
operator|!
name|mc
operator|->
name|mc_alloc_throttle_enabled
condition|)
return|return
operator|(
name|B_TRUE
operator|)
return|;
comment|/* 		 * If this metaslab group does not have any free space, then 		 * there is no point in looking further. 		 */
if|if
condition|(
name|mg
operator|->
name|mg_no_free_space
condition|)
return|return
operator|(
name|B_FALSE
operator|)
return|;
name|qdepth
operator|=
name|refcount_count
argument_list|(
operator|&
name|mg
operator|->
name|mg_alloc_queue_depth
argument_list|)
expr_stmt|;
comment|/* 		 * If this metaslab group is below its qmax or it's 		 * the only allocatable metasable group, then attempt 		 * to allocate from it. 		 */
if|if
condition|(
name|qdepth
operator|<
name|qmax
operator|||
name|mc
operator|->
name|mc_alloc_groups
operator|==
literal|1
condition|)
return|return
operator|(
name|B_TRUE
operator|)
return|;
name|ASSERT3U
argument_list|(
name|mc
operator|->
name|mc_alloc_groups
argument_list|,
operator|>
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 		 * Since this metaslab group is at or over its qmax, we 		 * need to determine if there are metaslab groups after this 		 * one that might be able to handle this allocation. This is 		 * racy since we can't hold the locks for all metaslab 		 * groups at the same time when we make this check. 		 */
for|for
control|(
name|mgp
operator|=
name|mg
operator|->
name|mg_next
init|;
name|mgp
operator|!=
name|rotor
condition|;
name|mgp
operator|=
name|mgp
operator|->
name|mg_next
control|)
block|{
name|qmax
operator|=
name|mgp
operator|->
name|mg_max_alloc_queue_depth
expr_stmt|;
name|qdepth
operator|=
name|refcount_count
argument_list|(
operator|&
name|mgp
operator|->
name|mg_alloc_queue_depth
argument_list|)
expr_stmt|;
comment|/* 			 * If there is another metaslab group that 			 * might be able to handle the allocation, then 			 * we return false so that we skip this group. 			 */
if|if
condition|(
name|qdepth
operator|<
name|qmax
operator|&&
operator|!
name|mgp
operator|->
name|mg_no_free_space
condition|)
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
comment|/* 		 * We didn't find another group to handle the allocation 		 * so we can't skip this metaslab group even though 		 * we are at or over our qmax. 		 */
return|return
operator|(
name|B_TRUE
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|mc
operator|->
name|mc_alloc_groups
operator|==
literal|0
operator|||
name|psize
operator|==
name|SPA_MINBLOCKSIZE
condition|)
block|{
return|return
operator|(
name|B_TRUE
operator|)
return|;
block|}
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * ==========================================================================  * Range tree callbacks  * ==========================================================================  */
end_comment

begin_comment
comment|/*  * Comparison function for the private size-ordered tree. Tree is sorted  * by size, larger sizes at the end of the tree.  */
end_comment

begin_function
specifier|static
name|int
name|metaslab_rangesize_compare
parameter_list|(
specifier|const
name|void
modifier|*
name|x1
parameter_list|,
specifier|const
name|void
modifier|*
name|x2
parameter_list|)
block|{
specifier|const
name|range_seg_t
modifier|*
name|r1
init|=
name|x1
decl_stmt|;
specifier|const
name|range_seg_t
modifier|*
name|r2
init|=
name|x2
decl_stmt|;
name|uint64_t
name|rs_size1
init|=
name|r1
operator|->
name|rs_end
operator|-
name|r1
operator|->
name|rs_start
decl_stmt|;
name|uint64_t
name|rs_size2
init|=
name|r2
operator|->
name|rs_end
operator|-
name|r2
operator|->
name|rs_start
decl_stmt|;
if|if
condition|(
name|rs_size1
operator|<
name|rs_size2
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
if|if
condition|(
name|rs_size1
operator|>
name|rs_size2
condition|)
return|return
operator|(
literal|1
operator|)
return|;
if|if
condition|(
name|r1
operator|->
name|rs_start
operator|<
name|r2
operator|->
name|rs_start
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
if|if
condition|(
name|r1
operator|->
name|rs_start
operator|>
name|r2
operator|->
name|rs_start
condition|)
return|return
operator|(
literal|1
operator|)
return|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Create any block allocator specific components. The current allocators  * rely on using both a size-ordered range_tree_t and an array of uint64_t's.  */
end_comment

begin_function
specifier|static
name|void
name|metaslab_rt_create
parameter_list|(
name|range_tree_t
modifier|*
name|rt
parameter_list|,
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|metaslab_t
modifier|*
name|msp
init|=
name|arg
decl_stmt|;
name|ASSERT3P
argument_list|(
name|rt
operator|->
name|rt_arg
argument_list|,
operator|==
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_tree
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|avl_create
argument_list|(
operator|&
name|msp
operator|->
name|ms_size_tree
argument_list|,
name|metaslab_rangesize_compare
argument_list|,
sizeof|sizeof
argument_list|(
name|range_seg_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|range_seg_t
argument_list|,
name|rs_pp_node
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Destroy the block allocator specific components.  */
end_comment

begin_function
specifier|static
name|void
name|metaslab_rt_destroy
parameter_list|(
name|range_tree_t
modifier|*
name|rt
parameter_list|,
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|metaslab_t
modifier|*
name|msp
init|=
name|arg
decl_stmt|;
name|ASSERT3P
argument_list|(
name|rt
operator|->
name|rt_arg
argument_list|,
operator|==
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|,
operator|==
argument_list|,
name|rt
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|avl_numnodes
argument_list|(
operator|&
name|msp
operator|->
name|ms_size_tree
argument_list|)
argument_list|)
expr_stmt|;
name|avl_destroy
argument_list|(
operator|&
name|msp
operator|->
name|ms_size_tree
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|metaslab_rt_add
parameter_list|(
name|range_tree_t
modifier|*
name|rt
parameter_list|,
name|range_seg_t
modifier|*
name|rs
parameter_list|,
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|metaslab_t
modifier|*
name|msp
init|=
name|arg
decl_stmt|;
name|ASSERT3P
argument_list|(
name|rt
operator|->
name|rt_arg
argument_list|,
operator|==
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|,
operator|==
argument_list|,
name|rt
argument_list|)
expr_stmt|;
name|VERIFY
argument_list|(
operator|!
name|msp
operator|->
name|ms_condensing
argument_list|)
expr_stmt|;
name|avl_add
argument_list|(
operator|&
name|msp
operator|->
name|ms_size_tree
argument_list|,
name|rs
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|metaslab_rt_remove
parameter_list|(
name|range_tree_t
modifier|*
name|rt
parameter_list|,
name|range_seg_t
modifier|*
name|rs
parameter_list|,
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|metaslab_t
modifier|*
name|msp
init|=
name|arg
decl_stmt|;
name|ASSERT3P
argument_list|(
name|rt
operator|->
name|rt_arg
argument_list|,
operator|==
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|,
operator|==
argument_list|,
name|rt
argument_list|)
expr_stmt|;
name|VERIFY
argument_list|(
operator|!
name|msp
operator|->
name|ms_condensing
argument_list|)
expr_stmt|;
name|avl_remove
argument_list|(
operator|&
name|msp
operator|->
name|ms_size_tree
argument_list|,
name|rs
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|metaslab_rt_vacate
parameter_list|(
name|range_tree_t
modifier|*
name|rt
parameter_list|,
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|metaslab_t
modifier|*
name|msp
init|=
name|arg
decl_stmt|;
name|ASSERT3P
argument_list|(
name|rt
operator|->
name|rt_arg
argument_list|,
operator|==
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|,
operator|==
argument_list|,
name|rt
argument_list|)
expr_stmt|;
comment|/* 	 * Normally one would walk the tree freeing nodes along the way. 	 * Since the nodes are shared with the range trees we can avoid 	 * walking all nodes and just reinitialize the avl tree. The nodes 	 * will be freed by the range tree, so we don't want to free them here. 	 */
name|avl_create
argument_list|(
operator|&
name|msp
operator|->
name|ms_size_tree
argument_list|,
name|metaslab_rangesize_compare
argument_list|,
sizeof|sizeof
argument_list|(
name|range_seg_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|range_seg_t
argument_list|,
name|rs_pp_node
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_decl_stmt
specifier|static
name|range_tree_ops_t
name|metaslab_rt_ops
init|=
block|{
name|metaslab_rt_create
block|,
name|metaslab_rt_destroy
block|,
name|metaslab_rt_add
block|,
name|metaslab_rt_remove
block|,
name|metaslab_rt_vacate
block|}
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * ==========================================================================  * Common allocator routines  * ==========================================================================  */
end_comment

begin_comment
comment|/*  * Return the maximum contiguous segment within the metaslab.  */
end_comment

begin_function
name|uint64_t
name|metaslab_block_maxsize
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|avl_tree_t
modifier|*
name|t
init|=
operator|&
name|msp
operator|->
name|ms_size_tree
decl_stmt|;
name|range_seg_t
modifier|*
name|rs
decl_stmt|;
if|if
condition|(
name|t
operator|==
name|NULL
operator|||
operator|(
name|rs
operator|=
name|avl_last
argument_list|(
name|t
argument_list|)
operator|)
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0ULL
operator|)
return|;
return|return
operator|(
name|rs
operator|->
name|rs_end
operator|-
name|rs
operator|->
name|rs_start
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|range_seg_t
modifier|*
name|metaslab_block_find
parameter_list|(
name|avl_tree_t
modifier|*
name|t
parameter_list|,
name|uint64_t
name|start
parameter_list|,
name|uint64_t
name|size
parameter_list|)
block|{
name|range_seg_t
modifier|*
name|rs
decl_stmt|,
name|rsearch
decl_stmt|;
name|avl_index_t
name|where
decl_stmt|;
name|rsearch
operator|.
name|rs_start
operator|=
name|start
expr_stmt|;
name|rsearch
operator|.
name|rs_end
operator|=
name|start
operator|+
name|size
expr_stmt|;
name|rs
operator|=
name|avl_find
argument_list|(
name|t
argument_list|,
operator|&
name|rsearch
argument_list|,
operator|&
name|where
argument_list|)
expr_stmt|;
if|if
condition|(
name|rs
operator|==
name|NULL
condition|)
block|{
name|rs
operator|=
name|avl_nearest
argument_list|(
name|t
argument_list|,
name|where
argument_list|,
name|AVL_AFTER
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|rs
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This is a helper function that can be used by the allocator to find  * a suitable block to allocate. This will search the specified AVL  * tree looking for a block that matches the specified criteria.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|metaslab_block_picker
parameter_list|(
name|avl_tree_t
modifier|*
name|t
parameter_list|,
name|uint64_t
modifier|*
name|cursor
parameter_list|,
name|uint64_t
name|size
parameter_list|,
name|uint64_t
name|align
parameter_list|)
block|{
name|range_seg_t
modifier|*
name|rs
init|=
name|metaslab_block_find
argument_list|(
name|t
argument_list|,
operator|*
name|cursor
argument_list|,
name|size
argument_list|)
decl_stmt|;
while|while
condition|(
name|rs
operator|!=
name|NULL
condition|)
block|{
name|uint64_t
name|offset
init|=
name|P2ROUNDUP
argument_list|(
name|rs
operator|->
name|rs_start
argument_list|,
name|align
argument_list|)
decl_stmt|;
if|if
condition|(
name|offset
operator|+
name|size
operator|<=
name|rs
operator|->
name|rs_end
condition|)
block|{
operator|*
name|cursor
operator|=
name|offset
operator|+
name|size
expr_stmt|;
return|return
operator|(
name|offset
operator|)
return|;
block|}
name|rs
operator|=
name|AVL_NEXT
argument_list|(
name|t
argument_list|,
name|rs
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If we know we've searched the whole map (*cursor == 0), give up. 	 * Otherwise, reset the cursor to the beginning and try again. 	 */
if|if
condition|(
operator|*
name|cursor
operator|==
literal|0
condition|)
return|return
operator|(
operator|-
literal|1ULL
operator|)
return|;
operator|*
name|cursor
operator|=
literal|0
expr_stmt|;
return|return
operator|(
name|metaslab_block_picker
argument_list|(
name|t
argument_list|,
name|cursor
argument_list|,
name|size
argument_list|,
name|align
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * ==========================================================================  * The first-fit block allocator  * ==========================================================================  */
end_comment

begin_function
specifier|static
name|uint64_t
name|metaslab_ff_alloc
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|size
parameter_list|)
block|{
comment|/* 	 * Find the largest power of 2 block size that evenly divides the 	 * requested size. This is used to try to allocate blocks with similar 	 * alignment from the same area of the metaslab (i.e. same cursor 	 * bucket) but it does not guarantee that other allocations sizes 	 * may exist in the same region. 	 */
name|uint64_t
name|align
init|=
name|size
operator|&
operator|-
name|size
decl_stmt|;
name|uint64_t
modifier|*
name|cursor
init|=
operator|&
name|msp
operator|->
name|ms_lbas
index|[
name|highbit64
argument_list|(
name|align
argument_list|)
operator|-
literal|1
index|]
decl_stmt|;
name|avl_tree_t
modifier|*
name|t
init|=
operator|&
name|msp
operator|->
name|ms_tree
operator|->
name|rt_root
decl_stmt|;
return|return
operator|(
name|metaslab_block_picker
argument_list|(
name|t
argument_list|,
name|cursor
argument_list|,
name|size
argument_list|,
name|align
argument_list|)
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|metaslab_ops_t
name|metaslab_ff_ops
init|=
block|{
name|metaslab_ff_alloc
block|}
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * ==========================================================================  * Dynamic block allocator -  * Uses the first fit allocation scheme until space get low and then  * adjusts to a best fit allocation method. Uses metaslab_df_alloc_threshold  * and metaslab_df_free_pct to determine when to switch the allocation scheme.  * ==========================================================================  */
end_comment

begin_function
specifier|static
name|uint64_t
name|metaslab_df_alloc
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|size
parameter_list|)
block|{
comment|/* 	 * Find the largest power of 2 block size that evenly divides the 	 * requested size. This is used to try to allocate blocks with similar 	 * alignment from the same area of the metaslab (i.e. same cursor 	 * bucket) but it does not guarantee that other allocations sizes 	 * may exist in the same region. 	 */
name|uint64_t
name|align
init|=
name|size
operator|&
operator|-
name|size
decl_stmt|;
name|uint64_t
modifier|*
name|cursor
init|=
operator|&
name|msp
operator|->
name|ms_lbas
index|[
name|highbit64
argument_list|(
name|align
argument_list|)
operator|-
literal|1
index|]
decl_stmt|;
name|range_tree_t
modifier|*
name|rt
init|=
name|msp
operator|->
name|ms_tree
decl_stmt|;
name|avl_tree_t
modifier|*
name|t
init|=
operator|&
name|rt
operator|->
name|rt_root
decl_stmt|;
name|uint64_t
name|max_size
init|=
name|metaslab_block_maxsize
argument_list|(
name|msp
argument_list|)
decl_stmt|;
name|int
name|free_pct
init|=
name|range_tree_space
argument_list|(
name|rt
argument_list|)
operator|*
literal|100
operator|/
name|msp
operator|->
name|ms_size
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|avl_numnodes
argument_list|(
name|t
argument_list|)
argument_list|,
operator|==
argument_list|,
name|avl_numnodes
argument_list|(
operator|&
name|msp
operator|->
name|ms_size_tree
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|max_size
operator|<
name|size
condition|)
return|return
operator|(
operator|-
literal|1ULL
operator|)
return|;
comment|/* 	 * If we're running low on space switch to using the size 	 * sorted AVL tree (best-fit). 	 */
if|if
condition|(
name|max_size
operator|<
name|metaslab_df_alloc_threshold
operator|||
name|free_pct
operator|<
name|metaslab_df_free_pct
condition|)
block|{
name|t
operator|=
operator|&
name|msp
operator|->
name|ms_size_tree
expr_stmt|;
operator|*
name|cursor
operator|=
literal|0
expr_stmt|;
block|}
return|return
operator|(
name|metaslab_block_picker
argument_list|(
name|t
argument_list|,
name|cursor
argument_list|,
name|size
argument_list|,
literal|1ULL
argument_list|)
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|metaslab_ops_t
name|metaslab_df_ops
init|=
block|{
name|metaslab_df_alloc
block|}
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * ==========================================================================  * Cursor fit block allocator -  * Select the largest region in the metaslab, set the cursor to the beginning  * of the range and the cursor_end to the end of the range. As allocations  * are made advance the cursor. Continue allocating from the cursor until  * the range is exhausted and then find a new range.  * ==========================================================================  */
end_comment

begin_function
specifier|static
name|uint64_t
name|metaslab_cf_alloc
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|size
parameter_list|)
block|{
name|range_tree_t
modifier|*
name|rt
init|=
name|msp
operator|->
name|ms_tree
decl_stmt|;
name|avl_tree_t
modifier|*
name|t
init|=
operator|&
name|msp
operator|->
name|ms_size_tree
decl_stmt|;
name|uint64_t
modifier|*
name|cursor
init|=
operator|&
name|msp
operator|->
name|ms_lbas
index|[
literal|0
index|]
decl_stmt|;
name|uint64_t
modifier|*
name|cursor_end
init|=
operator|&
name|msp
operator|->
name|ms_lbas
index|[
literal|1
index|]
decl_stmt|;
name|uint64_t
name|offset
init|=
literal|0
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|avl_numnodes
argument_list|(
name|t
argument_list|)
argument_list|,
operator|==
argument_list|,
name|avl_numnodes
argument_list|(
operator|&
name|rt
operator|->
name|rt_root
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
operator|*
name|cursor_end
argument_list|,
operator|>=
argument_list|,
operator|*
name|cursor
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|cursor
operator|+
name|size
operator|)
operator|>
operator|*
name|cursor_end
condition|)
block|{
name|range_seg_t
modifier|*
name|rs
decl_stmt|;
name|rs
operator|=
name|avl_last
argument_list|(
operator|&
name|msp
operator|->
name|ms_size_tree
argument_list|)
expr_stmt|;
if|if
condition|(
name|rs
operator|==
name|NULL
operator|||
operator|(
name|rs
operator|->
name|rs_end
operator|-
name|rs
operator|->
name|rs_start
operator|)
operator|<
name|size
condition|)
return|return
operator|(
operator|-
literal|1ULL
operator|)
return|;
operator|*
name|cursor
operator|=
name|rs
operator|->
name|rs_start
expr_stmt|;
operator|*
name|cursor_end
operator|=
name|rs
operator|->
name|rs_end
expr_stmt|;
block|}
name|offset
operator|=
operator|*
name|cursor
expr_stmt|;
operator|*
name|cursor
operator|+=
name|size
expr_stmt|;
return|return
operator|(
name|offset
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|metaslab_ops_t
name|metaslab_cf_ops
init|=
block|{
name|metaslab_cf_alloc
block|}
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * ==========================================================================  * New dynamic fit allocator -  * Select a region that is large enough to allocate 2^metaslab_ndf_clump_shift  * contiguous blocks. If no region is found then just use the largest segment  * that remains.  * ==========================================================================  */
end_comment

begin_comment
comment|/*  * Determines desired number of contiguous blocks (2^metaslab_ndf_clump_shift)  * to request from the allocator.  */
end_comment

begin_decl_stmt
name|uint64_t
name|metaslab_ndf_clump_shift
init|=
literal|4
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|uint64_t
name|metaslab_ndf_alloc
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|size
parameter_list|)
block|{
name|avl_tree_t
modifier|*
name|t
init|=
operator|&
name|msp
operator|->
name|ms_tree
operator|->
name|rt_root
decl_stmt|;
name|avl_index_t
name|where
decl_stmt|;
name|range_seg_t
modifier|*
name|rs
decl_stmt|,
name|rsearch
decl_stmt|;
name|uint64_t
name|hbit
init|=
name|highbit64
argument_list|(
name|size
argument_list|)
decl_stmt|;
name|uint64_t
modifier|*
name|cursor
init|=
operator|&
name|msp
operator|->
name|ms_lbas
index|[
name|hbit
operator|-
literal|1
index|]
decl_stmt|;
name|uint64_t
name|max_size
init|=
name|metaslab_block_maxsize
argument_list|(
name|msp
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|avl_numnodes
argument_list|(
name|t
argument_list|)
argument_list|,
operator|==
argument_list|,
name|avl_numnodes
argument_list|(
operator|&
name|msp
operator|->
name|ms_size_tree
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|max_size
operator|<
name|size
condition|)
return|return
operator|(
operator|-
literal|1ULL
operator|)
return|;
name|rsearch
operator|.
name|rs_start
operator|=
operator|*
name|cursor
expr_stmt|;
name|rsearch
operator|.
name|rs_end
operator|=
operator|*
name|cursor
operator|+
name|size
expr_stmt|;
name|rs
operator|=
name|avl_find
argument_list|(
name|t
argument_list|,
operator|&
name|rsearch
argument_list|,
operator|&
name|where
argument_list|)
expr_stmt|;
if|if
condition|(
name|rs
operator|==
name|NULL
operator|||
operator|(
name|rs
operator|->
name|rs_end
operator|-
name|rs
operator|->
name|rs_start
operator|)
operator|<
name|size
condition|)
block|{
name|t
operator|=
operator|&
name|msp
operator|->
name|ms_size_tree
expr_stmt|;
name|rsearch
operator|.
name|rs_start
operator|=
literal|0
expr_stmt|;
name|rsearch
operator|.
name|rs_end
operator|=
name|MIN
argument_list|(
name|max_size
argument_list|,
literal|1ULL
operator|<<
operator|(
name|hbit
operator|+
name|metaslab_ndf_clump_shift
operator|)
argument_list|)
expr_stmt|;
name|rs
operator|=
name|avl_find
argument_list|(
name|t
argument_list|,
operator|&
name|rsearch
argument_list|,
operator|&
name|where
argument_list|)
expr_stmt|;
if|if
condition|(
name|rs
operator|==
name|NULL
condition|)
name|rs
operator|=
name|avl_nearest
argument_list|(
name|t
argument_list|,
name|where
argument_list|,
name|AVL_AFTER
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|rs
operator|!=
name|NULL
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|rs
operator|->
name|rs_end
operator|-
name|rs
operator|->
name|rs_start
operator|)
operator|>=
name|size
condition|)
block|{
operator|*
name|cursor
operator|=
name|rs
operator|->
name|rs_start
operator|+
name|size
expr_stmt|;
return|return
operator|(
name|rs
operator|->
name|rs_start
operator|)
return|;
block|}
return|return
operator|(
operator|-
literal|1ULL
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|metaslab_ops_t
name|metaslab_ndf_ops
init|=
block|{
name|metaslab_ndf_alloc
block|}
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|metaslab_ops_t
modifier|*
name|zfs_metaslab_ops
init|=
operator|&
name|metaslab_df_ops
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * ==========================================================================  * Metaslabs  * ==========================================================================  */
end_comment

begin_comment
comment|/*  * Wait for any in-progress metaslab loads to complete.  */
end_comment

begin_function
name|void
name|metaslab_load_wait
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
while|while
condition|(
name|msp
operator|->
name|ms_loading
condition|)
block|{
name|ASSERT
argument_list|(
operator|!
name|msp
operator|->
name|ms_loaded
argument_list|)
expr_stmt|;
name|cv_wait
argument_list|(
operator|&
name|msp
operator|->
name|ms_load_cv
argument_list|,
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|int
name|metaslab_load
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|int
name|error
init|=
literal|0
decl_stmt|;
name|boolean_t
name|success
init|=
name|B_FALSE
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|msp
operator|->
name|ms_loaded
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|msp
operator|->
name|ms_loading
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_loading
operator|=
name|B_TRUE
expr_stmt|;
comment|/* 	 * If the space map has not been allocated yet, then treat 	 * all the space in the metaslab as free and add it to the 	 * ms_tree. 	 */
if|if
condition|(
name|msp
operator|->
name|ms_sm
operator|!=
name|NULL
condition|)
name|error
operator|=
name|space_map_load
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|,
name|msp
operator|->
name|ms_tree
argument_list|,
name|SM_FREE
argument_list|)
expr_stmt|;
else|else
name|range_tree_add
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|,
name|msp
operator|->
name|ms_start
argument_list|,
name|msp
operator|->
name|ms_size
argument_list|)
expr_stmt|;
name|success
operator|=
operator|(
name|error
operator|==
literal|0
operator|)
expr_stmt|;
name|msp
operator|->
name|ms_loading
operator|=
name|B_FALSE
expr_stmt|;
if|if
condition|(
name|success
condition|)
block|{
name|ASSERT3P
argument_list|(
name|msp
operator|->
name|ms_group
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_loaded
operator|=
name|B_TRUE
expr_stmt|;
for|for
control|(
name|int
name|t
init|=
literal|0
init|;
name|t
operator|<
name|TXG_DEFER_SIZE
condition|;
name|t
operator|++
control|)
block|{
name|range_tree_walk
argument_list|(
name|msp
operator|->
name|ms_defertree
index|[
name|t
index|]
argument_list|,
name|range_tree_remove
argument_list|,
name|msp
operator|->
name|ms_tree
argument_list|)
expr_stmt|;
block|}
name|msp
operator|->
name|ms_max_size
operator|=
name|metaslab_block_maxsize
argument_list|(
name|msp
argument_list|)
expr_stmt|;
block|}
name|cv_broadcast
argument_list|(
operator|&
name|msp
operator|->
name|ms_load_cv
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
name|void
name|metaslab_unload
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
name|range_tree_vacate
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_loaded
operator|=
name|B_FALSE
expr_stmt|;
name|msp
operator|->
name|ms_weight
operator|&=
operator|~
name|METASLAB_ACTIVE_MASK
expr_stmt|;
name|msp
operator|->
name|ms_max_size
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
name|int
name|metaslab_init
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|,
name|uint64_t
name|id
parameter_list|,
name|uint64_t
name|object
parameter_list|,
name|uint64_t
name|txg
parameter_list|,
name|metaslab_t
modifier|*
modifier|*
name|msp
parameter_list|)
block|{
name|vdev_t
modifier|*
name|vd
init|=
name|mg
operator|->
name|mg_vd
decl_stmt|;
name|objset_t
modifier|*
name|mos
init|=
name|vd
operator|->
name|vdev_spa
operator|->
name|spa_meta_objset
decl_stmt|;
name|metaslab_t
modifier|*
name|ms
decl_stmt|;
name|int
name|error
decl_stmt|;
name|ms
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|metaslab_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|ms
operator|->
name|ms_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|ms
operator|->
name|ms_load_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ms
operator|->
name|ms_id
operator|=
name|id
expr_stmt|;
name|ms
operator|->
name|ms_start
operator|=
name|id
operator|<<
name|vd
operator|->
name|vdev_ms_shift
expr_stmt|;
name|ms
operator|->
name|ms_size
operator|=
literal|1ULL
operator|<<
name|vd
operator|->
name|vdev_ms_shift
expr_stmt|;
comment|/* 	 * We only open space map objects that already exist. All others 	 * will be opened when we finally allocate an object for it. 	 */
if|if
condition|(
name|object
operator|!=
literal|0
condition|)
block|{
name|error
operator|=
name|space_map_open
argument_list|(
operator|&
name|ms
operator|->
name|ms_sm
argument_list|,
name|mos
argument_list|,
name|object
argument_list|,
name|ms
operator|->
name|ms_start
argument_list|,
name|ms
operator|->
name|ms_size
argument_list|,
name|vd
operator|->
name|vdev_ashift
argument_list|,
operator|&
name|ms
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|kmem_free
argument_list|(
name|ms
argument_list|,
sizeof|sizeof
argument_list|(
name|metaslab_t
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|ASSERT
argument_list|(
name|ms
operator|->
name|ms_sm
operator|!=
name|NULL
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * We create the main range tree here, but we don't create the 	 * other range trees until metaslab_sync_done().  This serves 	 * two purposes: it allows metaslab_sync_done() to detect the 	 * addition of new space; and for debugging, it ensures that we'd 	 * data fault on any attempt to use this metaslab before it's ready. 	 */
name|ms
operator|->
name|ms_tree
operator|=
name|range_tree_create
argument_list|(
operator|&
name|metaslab_rt_ops
argument_list|,
name|ms
argument_list|,
operator|&
name|ms
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|metaslab_group_add
argument_list|(
name|mg
argument_list|,
name|ms
argument_list|)
expr_stmt|;
name|metaslab_set_fragmentation
argument_list|(
name|ms
argument_list|)
expr_stmt|;
comment|/* 	 * If we're opening an existing pool (txg == 0) or creating 	 * a new one (txg == TXG_INITIAL), all space is available now. 	 * If we're adding space to an existing pool, the new space 	 * does not become available until after this txg has synced. 	 * The metaslab's weight will also be initialized when we sync 	 * out this txg. This ensures that we don't attempt to allocate 	 * from it before we have initialized it completely. 	 */
if|if
condition|(
name|txg
operator|<=
name|TXG_INITIAL
condition|)
name|metaslab_sync_done
argument_list|(
name|ms
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * If metaslab_debug_load is set and we're initializing a metaslab 	 * that has an allocated space map object then load the its space 	 * map so that can verify frees. 	 */
if|if
condition|(
name|metaslab_debug_load
operator|&&
name|ms
operator|->
name|ms_sm
operator|!=
name|NULL
condition|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|ms
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|VERIFY0
argument_list|(
name|metaslab_load
argument_list|(
name|ms
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|ms
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|txg
operator|!=
literal|0
condition|)
block|{
name|vdev_dirty
argument_list|(
name|vd
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|,
name|txg
argument_list|)
expr_stmt|;
name|vdev_dirty
argument_list|(
name|vd
argument_list|,
name|VDD_METASLAB
argument_list|,
name|ms
argument_list|,
name|txg
argument_list|)
expr_stmt|;
block|}
operator|*
name|msp
operator|=
name|ms
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|void
name|metaslab_fini
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|metaslab_group_t
modifier|*
name|mg
init|=
name|msp
operator|->
name|ms_group
decl_stmt|;
name|metaslab_group_remove
argument_list|(
name|mg
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|VERIFY
argument_list|(
name|msp
operator|->
name|ms_group
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|vdev_space_update
argument_list|(
name|mg
operator|->
name|mg_vd
argument_list|,
operator|-
name|space_map_allocated
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
argument_list|,
literal|0
argument_list|,
operator|-
name|msp
operator|->
name|ms_size
argument_list|)
expr_stmt|;
name|space_map_close
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
expr_stmt|;
name|metaslab_unload
argument_list|(
name|msp
argument_list|)
expr_stmt|;
name|range_tree_destroy
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|)
expr_stmt|;
name|range_tree_destroy
argument_list|(
name|msp
operator|->
name|ms_freeingtree
argument_list|)
expr_stmt|;
name|range_tree_destroy
argument_list|(
name|msp
operator|->
name|ms_freedtree
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|t
init|=
literal|0
init|;
name|t
operator|<
name|TXG_SIZE
condition|;
name|t
operator|++
control|)
block|{
name|range_tree_destroy
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
name|t
index|]
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|t
init|=
literal|0
init|;
name|t
operator|<
name|TXG_DEFER_SIZE
condition|;
name|t
operator|++
control|)
block|{
name|range_tree_destroy
argument_list|(
name|msp
operator|->
name|ms_defertree
index|[
name|t
index|]
argument_list|)
expr_stmt|;
block|}
name|ASSERT0
argument_list|(
name|msp
operator|->
name|ms_deferspace
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|msp
operator|->
name|ms_load_cv
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|msp
argument_list|,
sizeof|sizeof
argument_list|(
name|metaslab_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_define
define|#
directive|define
name|FRAGMENTATION_TABLE_SIZE
value|17
end_define

begin_comment
comment|/*  * This table defines a segment size based fragmentation metric that will  * allow each metaslab to derive its own fragmentation value. This is done  * by calculating the space in each bucket of the spacemap histogram and  * multiplying that by the fragmetation metric in this table. Doing  * this for all buckets and dividing it by the total amount of free  * space in this metaslab (i.e. the total free space in all buckets) gives  * us the fragmentation metric. This means that a high fragmentation metric  * equates to most of the free space being comprised of small segments.  * Conversely, if the metric is low, then most of the free space is in  * large segments. A 10% change in fragmentation equates to approximately  * double the number of segments.  *  * This table defines 0% fragmented space using 16MB segments. Testing has  * shown that segments that are greater than or equal to 16MB do not suffer  * from drastic performance problems. Using this value, we derive the rest  * of the table. Since the fragmentation value is never stored on disk, it  * is possible to change these calculations in the future.  */
end_comment

begin_decl_stmt
name|int
name|zfs_frag_table
index|[
name|FRAGMENTATION_TABLE_SIZE
index|]
init|=
block|{
literal|100
block|,
comment|/* 512B	*/
literal|100
block|,
comment|/* 1K	*/
literal|98
block|,
comment|/* 2K	*/
literal|95
block|,
comment|/* 4K	*/
literal|90
block|,
comment|/* 8K	*/
literal|80
block|,
comment|/* 16K	*/
literal|70
block|,
comment|/* 32K	*/
literal|60
block|,
comment|/* 64K	*/
literal|50
block|,
comment|/* 128K	*/
literal|40
block|,
comment|/* 256K	*/
literal|30
block|,
comment|/* 512K	*/
literal|20
block|,
comment|/* 1M	*/
literal|15
block|,
comment|/* 2M	*/
literal|10
block|,
comment|/* 4M	*/
literal|5
block|,
comment|/* 8M	*/
literal|0
comment|/* 16M	*/
block|}
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Calclate the metaslab's fragmentation metric. A return value  * of ZFS_FRAG_INVALID means that the metaslab has not been upgraded and does  * not support this metric. Otherwise, the return value should be in the  * range [0, 100].  */
end_comment

begin_function
specifier|static
name|void
name|metaslab_set_fragmentation
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|spa_t
modifier|*
name|spa
init|=
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_spa
decl_stmt|;
name|uint64_t
name|fragmentation
init|=
literal|0
decl_stmt|;
name|uint64_t
name|total
init|=
literal|0
decl_stmt|;
name|boolean_t
name|feature_enabled
init|=
name|spa_feature_is_enabled
argument_list|(
name|spa
argument_list|,
name|SPA_FEATURE_SPACEMAP_HISTOGRAM
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|feature_enabled
condition|)
block|{
name|msp
operator|->
name|ms_fragmentation
operator|=
name|ZFS_FRAG_INVALID
expr_stmt|;
return|return;
block|}
comment|/* 	 * A null space map means that the entire metaslab is free 	 * and thus is not fragmented. 	 */
if|if
condition|(
name|msp
operator|->
name|ms_sm
operator|==
name|NULL
condition|)
block|{
name|msp
operator|->
name|ms_fragmentation
operator|=
literal|0
expr_stmt|;
return|return;
block|}
comment|/* 	 * If this metaslab's space map has not been upgraded, flag it 	 * so that we upgrade next time we encounter it. 	 */
if|if
condition|(
name|msp
operator|->
name|ms_sm
operator|->
name|sm_dbuf
operator|->
name|db_size
operator|!=
sizeof|sizeof
argument_list|(
name|space_map_phys_t
argument_list|)
condition|)
block|{
name|uint64_t
name|txg
init|=
name|spa_syncing_txg
argument_list|(
name|spa
argument_list|)
decl_stmt|;
name|vdev_t
modifier|*
name|vd
init|=
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
decl_stmt|;
comment|/* 		 * If we've reached the final dirty txg, then we must 		 * be shutting down the pool. We don't want to dirty 		 * any data past this point so skip setting the condense 		 * flag. We can retry this action the next time the pool 		 * is imported. 		 */
if|if
condition|(
name|spa_writeable
argument_list|(
name|spa
argument_list|)
operator|&&
name|txg
operator|<
name|spa_final_dirty_txg
argument_list|(
name|spa
argument_list|)
condition|)
block|{
name|msp
operator|->
name|ms_condense_wanted
operator|=
name|B_TRUE
expr_stmt|;
name|vdev_dirty
argument_list|(
name|vd
argument_list|,
name|VDD_METASLAB
argument_list|,
name|msp
argument_list|,
name|txg
operator|+
literal|1
argument_list|)
expr_stmt|;
name|spa_dbgmsg
argument_list|(
name|spa
argument_list|,
literal|"txg %llu, requesting force condense: "
literal|"ms_id %llu, vdev_id %llu"
argument_list|,
name|txg
argument_list|,
name|msp
operator|->
name|ms_id
argument_list|,
name|vd
operator|->
name|vdev_id
argument_list|)
expr_stmt|;
block|}
name|msp
operator|->
name|ms_fragmentation
operator|=
name|ZFS_FRAG_INVALID
expr_stmt|;
return|return;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|SPACE_MAP_HISTOGRAM_SIZE
condition|;
name|i
operator|++
control|)
block|{
name|uint64_t
name|space
init|=
literal|0
decl_stmt|;
name|uint8_t
name|shift
init|=
name|msp
operator|->
name|ms_sm
operator|->
name|sm_shift
decl_stmt|;
name|int
name|idx
init|=
name|MIN
argument_list|(
name|shift
operator|-
name|SPA_MINBLOCKSHIFT
operator|+
name|i
argument_list|,
name|FRAGMENTATION_TABLE_SIZE
operator|-
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
operator|==
literal|0
condition|)
continue|continue;
name|space
operator|=
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
operator|<<
operator|(
name|i
operator|+
name|shift
operator|)
expr_stmt|;
name|total
operator|+=
name|space
expr_stmt|;
name|ASSERT3U
argument_list|(
name|idx
argument_list|,
operator|<
argument_list|,
name|FRAGMENTATION_TABLE_SIZE
argument_list|)
expr_stmt|;
name|fragmentation
operator|+=
name|space
operator|*
name|zfs_frag_table
index|[
name|idx
index|]
expr_stmt|;
block|}
if|if
condition|(
name|total
operator|>
literal|0
condition|)
name|fragmentation
operator|/=
name|total
expr_stmt|;
name|ASSERT3U
argument_list|(
name|fragmentation
argument_list|,
operator|<=
argument_list|,
literal|100
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_fragmentation
operator|=
name|fragmentation
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Compute a weight -- a selection preference value -- for the given metaslab.  * This is based on the amount of free space, the level of fragmentation,  * the LBA range, and whether the metaslab is loaded.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|metaslab_space_weight
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|metaslab_group_t
modifier|*
name|mg
init|=
name|msp
operator|->
name|ms_group
decl_stmt|;
name|vdev_t
modifier|*
name|vd
init|=
name|mg
operator|->
name|mg_vd
decl_stmt|;
name|uint64_t
name|weight
decl_stmt|,
name|space
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|vd
operator|->
name|vdev_removing
argument_list|)
expr_stmt|;
comment|/* 	 * The baseline weight is the metaslab's free space. 	 */
name|space
operator|=
name|msp
operator|->
name|ms_size
operator|-
name|space_map_allocated
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
expr_stmt|;
if|if
condition|(
name|metaslab_fragmentation_factor_enabled
operator|&&
name|msp
operator|->
name|ms_fragmentation
operator|!=
name|ZFS_FRAG_INVALID
condition|)
block|{
comment|/* 		 * Use the fragmentation information to inversely scale 		 * down the baseline weight. We need to ensure that we 		 * don't exclude this metaslab completely when it's 100% 		 * fragmented. To avoid this we reduce the fragmented value 		 * by 1. 		 */
name|space
operator|=
operator|(
name|space
operator|*
operator|(
literal|100
operator|-
operator|(
name|msp
operator|->
name|ms_fragmentation
operator|-
literal|1
operator|)
operator|)
operator|)
operator|/
literal|100
expr_stmt|;
comment|/* 		 * If space< SPA_MINBLOCKSIZE, then we will not allocate from 		 * this metaslab again. The fragmentation metric may have 		 * decreased the space to something smaller than 		 * SPA_MINBLOCKSIZE, so reset the space to SPA_MINBLOCKSIZE 		 * so that we can consume any remaining space. 		 */
if|if
condition|(
name|space
operator|>
literal|0
operator|&&
name|space
operator|<
name|SPA_MINBLOCKSIZE
condition|)
name|space
operator|=
name|SPA_MINBLOCKSIZE
expr_stmt|;
block|}
name|weight
operator|=
name|space
expr_stmt|;
comment|/* 	 * Modern disks have uniform bit density and constant angular velocity. 	 * Therefore, the outer recording zones are faster (higher bandwidth) 	 * than the inner zones by the ratio of outer to inner track diameter, 	 * which is typically around 2:1.  We account for this by assigning 	 * higher weight to lower metaslabs (multiplier ranging from 2x to 1x). 	 * In effect, this means that we'll select the metaslab with the most 	 * free bandwidth rather than simply the one with the most free space. 	 */
if|if
condition|(
name|metaslab_lba_weighting_enabled
condition|)
block|{
name|weight
operator|=
literal|2
operator|*
name|weight
operator|-
operator|(
name|msp
operator|->
name|ms_id
operator|*
name|weight
operator|)
operator|/
name|vd
operator|->
name|vdev_ms_count
expr_stmt|;
name|ASSERT
argument_list|(
name|weight
operator|>=
name|space
operator|&&
name|weight
operator|<=
literal|2
operator|*
name|space
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If this metaslab is one we're actively using, adjust its 	 * weight to make it preferable to any inactive metaslab so 	 * we'll polish it off. If the fragmentation on this metaslab 	 * has exceed our threshold, then don't mark it active. 	 */
if|if
condition|(
name|msp
operator|->
name|ms_loaded
operator|&&
name|msp
operator|->
name|ms_fragmentation
operator|!=
name|ZFS_FRAG_INVALID
operator|&&
name|msp
operator|->
name|ms_fragmentation
operator|<=
name|zfs_metaslab_fragmentation_threshold
condition|)
block|{
name|weight
operator||=
operator|(
name|msp
operator|->
name|ms_weight
operator|&
name|METASLAB_ACTIVE_MASK
operator|)
expr_stmt|;
block|}
name|WEIGHT_SET_SPACEBASED
argument_list|(
name|weight
argument_list|)
expr_stmt|;
return|return
operator|(
name|weight
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return the weight of the specified metaslab, according to the segment-based  * weighting algorithm. The metaslab must be loaded. This function can  * be called within a sync pass since it relies only on the metaslab's  * range tree which is always accurate when the metaslab is loaded.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|metaslab_weight_from_range_tree
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|uint64_t
name|weight
init|=
literal|0
decl_stmt|;
name|uint32_t
name|segments
init|=
literal|0
decl_stmt|;
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_loaded
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
name|RANGE_TREE_HISTOGRAM_SIZE
operator|-
literal|1
init|;
name|i
operator|>=
name|SPA_MINBLOCKSHIFT
condition|;
name|i
operator|--
control|)
block|{
name|uint8_t
name|shift
init|=
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_ashift
decl_stmt|;
name|int
name|max_idx
init|=
name|SPACE_MAP_HISTOGRAM_SIZE
operator|+
name|shift
operator|-
literal|1
decl_stmt|;
name|segments
operator|<<=
literal|1
expr_stmt|;
name|segments
operator|+=
name|msp
operator|->
name|ms_tree
operator|->
name|rt_histogram
index|[
name|i
index|]
expr_stmt|;
comment|/* 		 * The range tree provides more precision than the space map 		 * and must be downgraded so that all values fit within the 		 * space map's histogram. This allows us to compare loaded 		 * vs. unloaded metaslabs to determine which metaslab is 		 * considered "best". 		 */
if|if
condition|(
name|i
operator|>
name|max_idx
condition|)
continue|continue;
if|if
condition|(
name|segments
operator|!=
literal|0
condition|)
block|{
name|WEIGHT_SET_COUNT
argument_list|(
name|weight
argument_list|,
name|segments
argument_list|)
expr_stmt|;
name|WEIGHT_SET_INDEX
argument_list|(
name|weight
argument_list|,
name|i
argument_list|)
expr_stmt|;
name|WEIGHT_SET_ACTIVE
argument_list|(
name|weight
argument_list|,
literal|0
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
return|return
operator|(
name|weight
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Calculate the weight based on the on-disk histogram. This should only  * be called after a sync pass has completely finished since the on-disk  * information is updated in metaslab_sync().  */
end_comment

begin_function
specifier|static
name|uint64_t
name|metaslab_weight_from_spacemap
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|uint64_t
name|weight
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|SPACE_MAP_HISTOGRAM_SIZE
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
if|if
condition|(
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
operator|!=
literal|0
condition|)
block|{
name|WEIGHT_SET_COUNT
argument_list|(
name|weight
argument_list|,
name|msp
operator|->
name|ms_sm
operator|->
name|sm_phys
operator|->
name|smp_histogram
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|WEIGHT_SET_INDEX
argument_list|(
name|weight
argument_list|,
name|i
operator|+
name|msp
operator|->
name|ms_sm
operator|->
name|sm_shift
argument_list|)
expr_stmt|;
name|WEIGHT_SET_ACTIVE
argument_list|(
name|weight
argument_list|,
literal|0
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
return|return
operator|(
name|weight
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Compute a segment-based weight for the specified metaslab. The weight  * is determined by highest bucket in the histogram. The information  * for the highest bucket is encoded into the weight value.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|metaslab_segment_weight
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|metaslab_group_t
modifier|*
name|mg
init|=
name|msp
operator|->
name|ms_group
decl_stmt|;
name|uint64_t
name|weight
init|=
literal|0
decl_stmt|;
name|uint8_t
name|shift
init|=
name|mg
operator|->
name|mg_vd
operator|->
name|vdev_ashift
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * The metaslab is completely free. 	 */
if|if
condition|(
name|space_map_allocated
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
operator|==
literal|0
condition|)
block|{
name|int
name|idx
init|=
name|highbit64
argument_list|(
name|msp
operator|->
name|ms_size
argument_list|)
operator|-
literal|1
decl_stmt|;
name|int
name|max_idx
init|=
name|SPACE_MAP_HISTOGRAM_SIZE
operator|+
name|shift
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|idx
operator|<
name|max_idx
condition|)
block|{
name|WEIGHT_SET_COUNT
argument_list|(
name|weight
argument_list|,
literal|1ULL
argument_list|)
expr_stmt|;
name|WEIGHT_SET_INDEX
argument_list|(
name|weight
argument_list|,
name|idx
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|WEIGHT_SET_COUNT
argument_list|(
name|weight
argument_list|,
literal|1ULL
operator|<<
operator|(
name|idx
operator|-
name|max_idx
operator|)
argument_list|)
expr_stmt|;
name|WEIGHT_SET_INDEX
argument_list|(
name|weight
argument_list|,
name|max_idx
argument_list|)
expr_stmt|;
block|}
name|WEIGHT_SET_ACTIVE
argument_list|(
name|weight
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|WEIGHT_IS_SPACEBASED
argument_list|(
name|weight
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|weight
operator|)
return|;
block|}
name|ASSERT3U
argument_list|(
name|msp
operator|->
name|ms_sm
operator|->
name|sm_dbuf
operator|->
name|db_size
argument_list|,
operator|==
argument_list|,
sizeof|sizeof
argument_list|(
name|space_map_phys_t
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the metaslab is fully allocated then just make the weight 0. 	 */
if|if
condition|(
name|space_map_allocated
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
operator|==
name|msp
operator|->
name|ms_size
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* 	 * If the metaslab is already loaded, then use the range tree to 	 * determine the weight. Otherwise, we rely on the space map information 	 * to generate the weight. 	 */
if|if
condition|(
name|msp
operator|->
name|ms_loaded
condition|)
block|{
name|weight
operator|=
name|metaslab_weight_from_range_tree
argument_list|(
name|msp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|weight
operator|=
name|metaslab_weight_from_spacemap
argument_list|(
name|msp
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If the metaslab was active the last time we calculated its weight 	 * then keep it active. We want to consume the entire region that 	 * is associated with this weight. 	 */
if|if
condition|(
name|msp
operator|->
name|ms_activation_weight
operator|!=
literal|0
operator|&&
name|weight
operator|!=
literal|0
condition|)
name|WEIGHT_SET_ACTIVE
argument_list|(
name|weight
argument_list|,
name|WEIGHT_GET_ACTIVE
argument_list|(
name|msp
operator|->
name|ms_weight
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|weight
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Determine if we should attempt to allocate from this metaslab. If the  * metaslab has a maximum size then we can quickly determine if the desired  * allocation size can be satisfied. Otherwise, if we're using segment-based  * weighting then we can determine the maximum allocation that this metaslab  * can accommodate based on the index encoded in the weight. If we're using  * space-based weights then rely on the entire weight (excluding the weight  * type bit).  */
end_comment

begin_function
name|boolean_t
name|metaslab_should_allocate
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|asize
parameter_list|)
block|{
name|boolean_t
name|should_allocate
decl_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_max_size
operator|!=
literal|0
condition|)
return|return
operator|(
name|msp
operator|->
name|ms_max_size
operator|>=
name|asize
operator|)
return|;
if|if
condition|(
operator|!
name|WEIGHT_IS_SPACEBASED
argument_list|(
name|msp
operator|->
name|ms_weight
argument_list|)
condition|)
block|{
comment|/* 		 * The metaslab segment weight indicates segments in the 		 * range [2^i, 2^(i+1)), where i is the index in the weight. 		 * Since the asize might be in the middle of the range, we 		 * should attempt the allocation if asize< 2^(i+1). 		 */
name|should_allocate
operator|=
operator|(
name|asize
operator|<
literal|1ULL
operator|<<
operator|(
name|WEIGHT_GET_INDEX
argument_list|(
name|msp
operator|->
name|ms_weight
argument_list|)
operator|+
literal|1
operator|)
operator|)
expr_stmt|;
block|}
else|else
block|{
name|should_allocate
operator|=
operator|(
name|asize
operator|<=
operator|(
name|msp
operator|->
name|ms_weight
operator|&
operator|~
name|METASLAB_WEIGHT_TYPE
operator|)
operator|)
expr_stmt|;
block|}
return|return
operator|(
name|should_allocate
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|metaslab_weight
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|vdev_t
modifier|*
name|vd
init|=
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
decl_stmt|;
name|spa_t
modifier|*
name|spa
init|=
name|vd
operator|->
name|vdev_spa
decl_stmt|;
name|uint64_t
name|weight
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * This vdev is in the process of being removed so there is nothing 	 * for us to do here. 	 */
if|if
condition|(
name|vd
operator|->
name|vdev_removing
condition|)
block|{
name|ASSERT0
argument_list|(
name|space_map_allocated
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|vd
operator|->
name|vdev_ms_shift
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|metaslab_set_fragmentation
argument_list|(
name|msp
argument_list|)
expr_stmt|;
comment|/* 	 * Update the maximum size if the metaslab is loaded. This will 	 * ensure that we get an accurate maximum size if newly freed space 	 * has been added back into the free tree. 	 */
if|if
condition|(
name|msp
operator|->
name|ms_loaded
condition|)
name|msp
operator|->
name|ms_max_size
operator|=
name|metaslab_block_maxsize
argument_list|(
name|msp
argument_list|)
expr_stmt|;
comment|/* 	 * Segment-based weighting requires space map histogram support. 	 */
if|if
condition|(
name|zfs_metaslab_segment_weight_enabled
operator|&&
name|spa_feature_is_enabled
argument_list|(
name|spa
argument_list|,
name|SPA_FEATURE_SPACEMAP_HISTOGRAM
argument_list|)
operator|&&
operator|(
name|msp
operator|->
name|ms_sm
operator|==
name|NULL
operator|||
name|msp
operator|->
name|ms_sm
operator|->
name|sm_dbuf
operator|->
name|db_size
operator|==
sizeof|sizeof
argument_list|(
name|space_map_phys_t
argument_list|)
operator|)
condition|)
block|{
name|weight
operator|=
name|metaslab_segment_weight
argument_list|(
name|msp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|weight
operator|=
name|metaslab_space_weight
argument_list|(
name|msp
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|weight
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|metaslab_activate
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|activation_weight
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|msp
operator|->
name|ms_weight
operator|&
name|METASLAB_ACTIVE_MASK
operator|)
operator|==
literal|0
condition|)
block|{
name|metaslab_load_wait
argument_list|(
name|msp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|msp
operator|->
name|ms_loaded
condition|)
block|{
name|int
name|error
init|=
name|metaslab_load
argument_list|(
name|msp
argument_list|)
decl_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|metaslab_group_sort
argument_list|(
name|msp
operator|->
name|ms_group
argument_list|,
name|msp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
block|}
name|msp
operator|->
name|ms_activation_weight
operator|=
name|msp
operator|->
name|ms_weight
expr_stmt|;
name|metaslab_group_sort
argument_list|(
name|msp
operator|->
name|ms_group
argument_list|,
name|msp
argument_list|,
name|msp
operator|->
name|ms_weight
operator||
name|activation_weight
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_loaded
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_weight
operator|&
name|METASLAB_ACTIVE_MASK
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|metaslab_passivate
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|weight
parameter_list|)
block|{
name|uint64_t
name|size
init|=
name|weight
operator|&
operator|~
name|METASLAB_WEIGHT_TYPE
decl_stmt|;
comment|/* 	 * If size< SPA_MINBLOCKSIZE, then we will not allocate from 	 * this metaslab again.  In that case, it had better be empty, 	 * or we would be leaving space on the table. 	 */
name|ASSERT
argument_list|(
name|size
operator|>=
name|SPA_MINBLOCKSIZE
operator|||
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|)
operator|==
literal|0
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|weight
operator|&
name|METASLAB_ACTIVE_MASK
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_activation_weight
operator|=
literal|0
expr_stmt|;
name|metaslab_group_sort
argument_list|(
name|msp
operator|->
name|ms_group
argument_list|,
name|msp
argument_list|,
name|weight
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|(
name|msp
operator|->
name|ms_weight
operator|&
name|METASLAB_ACTIVE_MASK
operator|)
operator|==
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Segment-based metaslabs are activated once and remain active until  * we either fail an allocation attempt (similar to space-based metaslabs)  * or have exhausted the free space in zfs_metaslab_switch_threshold  * buckets since the metaslab was activated. This function checks to see  * if we've exhaused the zfs_metaslab_switch_threshold buckets in the  * metaslab and passivates it proactively. This will allow us to select a  * metaslabs with larger contiguous region if any remaining within this  * metaslab group. If we're in sync pass> 1, then we continue using this  * metaslab so that we don't dirty more block and cause more sync passes.  */
end_comment

begin_function
name|void
name|metaslab_segment_may_passivate
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|spa_t
modifier|*
name|spa
init|=
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_spa
decl_stmt|;
if|if
condition|(
name|WEIGHT_IS_SPACEBASED
argument_list|(
name|msp
operator|->
name|ms_weight
argument_list|)
operator|||
name|spa_sync_pass
argument_list|(
name|spa
argument_list|)
operator|>
literal|1
condition|)
return|return;
comment|/* 	 * Since we are in the middle of a sync pass, the most accurate 	 * information that is accessible to us is the in-core range tree 	 * histogram; calculate the new weight based on that information. 	 */
name|uint64_t
name|weight
init|=
name|metaslab_weight_from_range_tree
argument_list|(
name|msp
argument_list|)
decl_stmt|;
name|int
name|activation_idx
init|=
name|WEIGHT_GET_INDEX
argument_list|(
name|msp
operator|->
name|ms_activation_weight
argument_list|)
decl_stmt|;
name|int
name|current_idx
init|=
name|WEIGHT_GET_INDEX
argument_list|(
name|weight
argument_list|)
decl_stmt|;
if|if
condition|(
name|current_idx
operator|<=
name|activation_idx
operator|-
name|zfs_metaslab_switch_threshold
condition|)
name|metaslab_passivate
argument_list|(
name|msp
argument_list|,
name|weight
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|metaslab_preload
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|metaslab_t
modifier|*
name|msp
init|=
name|arg
decl_stmt|;
name|spa_t
modifier|*
name|spa
init|=
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_spa
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_group
operator|->
name|mg_lock
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|metaslab_load_wait
argument_list|(
name|msp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|msp
operator|->
name|ms_loaded
condition|)
operator|(
name|void
operator|)
name|metaslab_load
argument_list|(
name|msp
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_selected_txg
operator|=
name|spa_syncing_txg
argument_list|(
name|spa
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|metaslab_group_preload
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|)
block|{
name|spa_t
modifier|*
name|spa
init|=
name|mg
operator|->
name|mg_vd
operator|->
name|vdev_spa
decl_stmt|;
name|metaslab_t
modifier|*
name|msp
decl_stmt|;
name|avl_tree_t
modifier|*
name|t
init|=
operator|&
name|mg
operator|->
name|mg_metaslab_tree
decl_stmt|;
name|int
name|m
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|spa_shutting_down
argument_list|(
name|spa
argument_list|)
operator|||
operator|!
name|metaslab_preload_enabled
condition|)
block|{
name|taskq_wait
argument_list|(
name|mg
operator|->
name|mg_taskq
argument_list|)
expr_stmt|;
return|return;
block|}
name|mutex_enter
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
comment|/* 	 * Load the next potential metaslabs 	 */
for|for
control|(
name|msp
operator|=
name|avl_first
argument_list|(
name|t
argument_list|)
init|;
name|msp
operator|!=
name|NULL
condition|;
name|msp
operator|=
name|AVL_NEXT
argument_list|(
name|t
argument_list|,
name|msp
argument_list|)
control|)
block|{
comment|/* 		 * We preload only the maximum number of metaslabs specified 		 * by metaslab_preload_limit. If a metaslab is being forced 		 * to condense then we preload it too. This will ensure 		 * that force condensing happens in the next txg. 		 */
if|if
condition|(
operator|++
name|m
operator|>
name|metaslab_preload_limit
operator|&&
operator|!
name|msp
operator|->
name|ms_condense_wanted
condition|)
block|{
continue|continue;
block|}
name|VERIFY
argument_list|(
name|taskq_dispatch
argument_list|(
name|mg
operator|->
name|mg_taskq
argument_list|,
name|metaslab_preload
argument_list|,
name|msp
argument_list|,
name|TQ_SLEEP
argument_list|)
operator|!=
name|NULL
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Determine if the space map's on-disk footprint is past our tolerance  * for inefficiency. We would like to use the following criteria to make  * our decision:  *  * 1. The size of the space map object should not dramatically increase as a  * result of writing out the free space range tree.  *  * 2. The minimal on-disk space map representation is zfs_condense_pct/100  * times the size than the free space range tree representation  * (i.e. zfs_condense_pct = 110 and in-core = 1MB, minimal = 1.1.MB).  *  * 3. The on-disk size of the space map should actually decrease.  *  * Checking the first condition is tricky since we don't want to walk  * the entire AVL tree calculating the estimated on-disk size. Instead we  * use the size-ordered range tree in the metaslab and calculate the  * size required to write out the largest segment in our free tree. If the  * size required to represent that segment on disk is larger than the space  * map object then we avoid condensing this map.  *  * To determine the second criterion we use a best-case estimate and assume  * each segment can be represented on-disk as a single 64-bit entry. We refer  * to this best-case estimate as the space map's minimal form.  *  * Unfortunately, we cannot compute the on-disk size of the space map in this  * context because we cannot accurately compute the effects of compression, etc.  * Instead, we apply the heuristic described in the block comment for  * zfs_metaslab_condense_block_threshold - we only condense if the space used  * is greater than a threshold number of blocks.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|metaslab_should_condense
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|)
block|{
name|space_map_t
modifier|*
name|sm
init|=
name|msp
operator|->
name|ms_sm
decl_stmt|;
name|range_seg_t
modifier|*
name|rs
decl_stmt|;
name|uint64_t
name|size
decl_stmt|,
name|entries
decl_stmt|,
name|segsz
decl_stmt|,
name|object_size
decl_stmt|,
name|optimal_size
decl_stmt|,
name|record_size
decl_stmt|;
name|dmu_object_info_t
name|doi
decl_stmt|;
name|uint64_t
name|vdev_blocksize
init|=
literal|1
operator|<<
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_ashift
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_loaded
argument_list|)
expr_stmt|;
comment|/* 	 * Use the ms_size_tree range tree, which is ordered by size, to 	 * obtain the largest segment in the free tree. We always condense 	 * metaslabs that are empty and metaslabs for which a condense 	 * request has been made. 	 */
name|rs
operator|=
name|avl_last
argument_list|(
operator|&
name|msp
operator|->
name|ms_size_tree
argument_list|)
expr_stmt|;
if|if
condition|(
name|rs
operator|==
name|NULL
operator|||
name|msp
operator|->
name|ms_condense_wanted
condition|)
return|return
operator|(
name|B_TRUE
operator|)
return|;
comment|/* 	 * Calculate the number of 64-bit entries this segment would 	 * require when written to disk. If this single segment would be 	 * larger on-disk than the entire current on-disk structure, then 	 * clearly condensing will increase the on-disk structure size. 	 */
name|size
operator|=
operator|(
name|rs
operator|->
name|rs_end
operator|-
name|rs
operator|->
name|rs_start
operator|)
operator|>>
name|sm
operator|->
name|sm_shift
expr_stmt|;
name|entries
operator|=
name|size
operator|/
operator|(
name|MIN
argument_list|(
name|size
argument_list|,
name|SM_RUN_MAX
argument_list|)
operator|)
expr_stmt|;
name|segsz
operator|=
name|entries
operator|*
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
expr_stmt|;
name|optimal_size
operator|=
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
operator|*
name|avl_numnodes
argument_list|(
operator|&
name|msp
operator|->
name|ms_tree
operator|->
name|rt_root
argument_list|)
expr_stmt|;
name|object_size
operator|=
name|space_map_length
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
expr_stmt|;
name|dmu_object_info_from_db
argument_list|(
name|sm
operator|->
name|sm_dbuf
argument_list|,
operator|&
name|doi
argument_list|)
expr_stmt|;
name|record_size
operator|=
name|MAX
argument_list|(
name|doi
operator|.
name|doi_data_block_size
argument_list|,
name|vdev_blocksize
argument_list|)
expr_stmt|;
return|return
operator|(
name|segsz
operator|<=
name|object_size
operator|&&
name|object_size
operator|>=
operator|(
name|optimal_size
operator|*
name|zfs_condense_pct
operator|/
literal|100
operator|)
operator|&&
name|object_size
operator|>
name|zfs_metaslab_condense_block_threshold
operator|*
name|record_size
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Condense the on-disk space map representation to its minimized form.  * The minimized form consists of a small number of allocations followed by  * the entries of the free range tree.  */
end_comment

begin_function
specifier|static
name|void
name|metaslab_condense
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|txg
parameter_list|,
name|dmu_tx_t
modifier|*
name|tx
parameter_list|)
block|{
name|spa_t
modifier|*
name|spa
init|=
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_spa
decl_stmt|;
name|range_tree_t
modifier|*
name|condense_tree
decl_stmt|;
name|space_map_t
modifier|*
name|sm
init|=
name|msp
operator|->
name|ms_sm
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|spa_sync_pass
argument_list|(
name|spa
argument_list|)
argument_list|,
operator|==
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_loaded
argument_list|)
expr_stmt|;
name|spa_dbgmsg
argument_list|(
name|spa
argument_list|,
literal|"condensing: txg %llu, msp[%llu] %p, vdev id %llu, "
literal|"spa %s, smp size %llu, segments %lu, forcing condense=%s"
argument_list|,
name|txg
argument_list|,
name|msp
operator|->
name|ms_id
argument_list|,
name|msp
argument_list|,
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_id
argument_list|,
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_spa
operator|->
name|spa_name
argument_list|,
name|space_map_length
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
argument_list|,
name|avl_numnodes
argument_list|(
operator|&
name|msp
operator|->
name|ms_tree
operator|->
name|rt_root
argument_list|)
argument_list|,
name|msp
operator|->
name|ms_condense_wanted
condition|?
literal|"TRUE"
else|:
literal|"FALSE"
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_condense_wanted
operator|=
name|B_FALSE
expr_stmt|;
comment|/* 	 * Create an range tree that is 100% allocated. We remove segments 	 * that have been freed in this txg, any deferred frees that exist, 	 * and any allocation in the future. Removing segments should be 	 * a relatively inexpensive operation since we expect these trees to 	 * have a small number of nodes. 	 */
name|condense_tree
operator|=
name|range_tree_create
argument_list|(
name|NULL
argument_list|,
name|NULL
argument_list|,
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|range_tree_add
argument_list|(
name|condense_tree
argument_list|,
name|msp
operator|->
name|ms_start
argument_list|,
name|msp
operator|->
name|ms_size
argument_list|)
expr_stmt|;
comment|/* 	 * Remove what's been freed in this txg from the condense_tree. 	 * Since we're in sync_pass 1, we know that all the frees from 	 * this txg are in the freeingtree. 	 */
name|range_tree_walk
argument_list|(
name|msp
operator|->
name|ms_freeingtree
argument_list|,
name|range_tree_remove
argument_list|,
name|condense_tree
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|t
init|=
literal|0
init|;
name|t
operator|<
name|TXG_DEFER_SIZE
condition|;
name|t
operator|++
control|)
block|{
name|range_tree_walk
argument_list|(
name|msp
operator|->
name|ms_defertree
index|[
name|t
index|]
argument_list|,
name|range_tree_remove
argument_list|,
name|condense_tree
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|t
init|=
literal|1
init|;
name|t
operator|<
name|TXG_CONCURRENT_STATES
condition|;
name|t
operator|++
control|)
block|{
name|range_tree_walk
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
operator|(
name|txg
operator|+
name|t
operator|)
operator|&
name|TXG_MASK
index|]
argument_list|,
name|range_tree_remove
argument_list|,
name|condense_tree
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * We're about to drop the metaslab's lock thus allowing 	 * other consumers to change it's content. Set the 	 * metaslab's ms_condensing flag to ensure that 	 * allocations on this metaslab do not occur while we're 	 * in the middle of committing it to disk. This is only critical 	 * for the ms_tree as all other range trees use per txg 	 * views of their content. 	 */
name|msp
operator|->
name|ms_condensing
operator|=
name|B_TRUE
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|space_map_truncate
argument_list|(
name|sm
argument_list|,
name|tx
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
comment|/* 	 * While we would ideally like to create a space map representation 	 * that consists only of allocation records, doing so can be 	 * prohibitively expensive because the in-core free tree can be 	 * large, and therefore computationally expensive to subtract 	 * from the condense_tree. Instead we sync out two trees, a cheap 	 * allocation only tree followed by the in-core free tree. While not 	 * optimal, this is typically close to optimal, and much cheaper to 	 * compute. 	 */
name|space_map_write
argument_list|(
name|sm
argument_list|,
name|condense_tree
argument_list|,
name|SM_ALLOC
argument_list|,
name|tx
argument_list|)
expr_stmt|;
name|range_tree_vacate
argument_list|(
name|condense_tree
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|range_tree_destroy
argument_list|(
name|condense_tree
argument_list|)
expr_stmt|;
name|space_map_write
argument_list|(
name|sm
argument_list|,
name|msp
operator|->
name|ms_tree
argument_list|,
name|SM_FREE
argument_list|,
name|tx
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_condensing
operator|=
name|B_FALSE
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Write a metaslab to disk in the context of the specified transaction group.  */
end_comment

begin_function
name|void
name|metaslab_sync
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|txg
parameter_list|)
block|{
name|metaslab_group_t
modifier|*
name|mg
init|=
name|msp
operator|->
name|ms_group
decl_stmt|;
name|vdev_t
modifier|*
name|vd
init|=
name|mg
operator|->
name|mg_vd
decl_stmt|;
name|spa_t
modifier|*
name|spa
init|=
name|vd
operator|->
name|vdev_spa
decl_stmt|;
name|objset_t
modifier|*
name|mos
init|=
name|spa_meta_objset
argument_list|(
name|spa
argument_list|)
decl_stmt|;
name|range_tree_t
modifier|*
name|alloctree
init|=
name|msp
operator|->
name|ms_alloctree
index|[
name|txg
operator|&
name|TXG_MASK
index|]
decl_stmt|;
name|dmu_tx_t
modifier|*
name|tx
decl_stmt|;
name|uint64_t
name|object
init|=
name|space_map_object
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|vd
operator|->
name|vdev_ishole
argument_list|)
expr_stmt|;
comment|/* 	 * This metaslab has just been added so there's no work to do now. 	 */
if|if
condition|(
name|msp
operator|->
name|ms_freeingtree
operator|==
name|NULL
condition|)
block|{
name|ASSERT3P
argument_list|(
name|alloctree
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
return|return;
block|}
name|ASSERT3P
argument_list|(
name|alloctree
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|msp
operator|->
name|ms_freeingtree
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|msp
operator|->
name|ms_freedtree
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 	 * Normally, we don't want to process a metaslab if there 	 * are no allocations or frees to perform. However, if the metaslab 	 * is being forced to condense and it's loaded, we need to let it 	 * through. 	 */
if|if
condition|(
name|range_tree_space
argument_list|(
name|alloctree
argument_list|)
operator|==
literal|0
operator|&&
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_freeingtree
argument_list|)
operator|==
literal|0
operator|&&
operator|!
operator|(
name|msp
operator|->
name|ms_loaded
operator|&&
name|msp
operator|->
name|ms_condense_wanted
operator|)
condition|)
return|return;
name|VERIFY
argument_list|(
name|txg
operator|<=
name|spa_final_dirty_txg
argument_list|(
name|spa
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * The only state that can actually be changing concurrently with 	 * metaslab_sync() is the metaslab's ms_tree.  No other thread can 	 * be modifying this txg's alloctree, freeingtree, freedtree, or 	 * space_map_phys_t. Therefore, we only hold ms_lock to satify 	 * space map ASSERTs. We drop it whenever we call into the DMU, 	 * because the DMU can call down to us (e.g. via zio_free()) at 	 * any time. 	 */
name|tx
operator|=
name|dmu_tx_create_assigned
argument_list|(
name|spa_get_dsl
argument_list|(
name|spa
argument_list|)
argument_list|,
name|txg
argument_list|)
expr_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_sm
operator|==
name|NULL
condition|)
block|{
name|uint64_t
name|new_object
decl_stmt|;
name|new_object
operator|=
name|space_map_alloc
argument_list|(
name|mos
argument_list|,
name|tx
argument_list|)
expr_stmt|;
name|VERIFY3U
argument_list|(
name|new_object
argument_list|,
operator|!=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|VERIFY0
argument_list|(
name|space_map_open
argument_list|(
operator|&
name|msp
operator|->
name|ms_sm
argument_list|,
name|mos
argument_list|,
name|new_object
argument_list|,
name|msp
operator|->
name|ms_start
argument_list|,
name|msp
operator|->
name|ms_size
argument_list|,
name|vd
operator|->
name|vdev_ashift
argument_list|,
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_sm
operator|!=
name|NULL
argument_list|)
expr_stmt|;
block|}
name|mutex_enter
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
comment|/* 	 * Note: metaslab_condense() clears the space map's histogram. 	 * Therefore we must verify and remove this histogram before 	 * condensing. 	 */
name|metaslab_group_histogram_verify
argument_list|(
name|mg
argument_list|)
expr_stmt|;
name|metaslab_class_histogram_verify
argument_list|(
name|mg
operator|->
name|mg_class
argument_list|)
expr_stmt|;
name|metaslab_group_histogram_remove
argument_list|(
name|mg
argument_list|,
name|msp
argument_list|)
expr_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_loaded
operator|&&
name|spa_sync_pass
argument_list|(
name|spa
argument_list|)
operator|==
literal|1
operator|&&
name|metaslab_should_condense
argument_list|(
name|msp
argument_list|)
condition|)
block|{
name|metaslab_condense
argument_list|(
name|msp
argument_list|,
name|txg
argument_list|,
name|tx
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|space_map_write
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|,
name|alloctree
argument_list|,
name|SM_ALLOC
argument_list|,
name|tx
argument_list|)
expr_stmt|;
name|space_map_write
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|,
name|msp
operator|->
name|ms_freeingtree
argument_list|,
name|SM_FREE
argument_list|,
name|tx
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|msp
operator|->
name|ms_loaded
condition|)
block|{
comment|/* 		 * When the space map is loaded, we have an accruate 		 * histogram in the range tree. This gives us an opportunity 		 * to bring the space map's histogram up-to-date so we clear 		 * it first before updating it. 		 */
name|space_map_histogram_clear
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
expr_stmt|;
name|space_map_histogram_add
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|,
name|msp
operator|->
name|ms_tree
argument_list|,
name|tx
argument_list|)
expr_stmt|;
comment|/* 		 * Since we've cleared the histogram we need to add back 		 * any free space that has already been processed, plus 		 * any deferred space. This allows the on-disk histogram 		 * to accurately reflect all free space even if some space 		 * is not yet available for allocation (i.e. deferred). 		 */
name|space_map_histogram_add
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|,
name|msp
operator|->
name|ms_freedtree
argument_list|,
name|tx
argument_list|)
expr_stmt|;
comment|/* 		 * Add back any deferred free space that has not been 		 * added back into the in-core free tree yet. This will 		 * ensure that we don't end up with a space map histogram 		 * that is completely empty unless the metaslab is fully 		 * allocated. 		 */
for|for
control|(
name|int
name|t
init|=
literal|0
init|;
name|t
operator|<
name|TXG_DEFER_SIZE
condition|;
name|t
operator|++
control|)
block|{
name|space_map_histogram_add
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|,
name|msp
operator|->
name|ms_defertree
index|[
name|t
index|]
argument_list|,
name|tx
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * Always add the free space from this sync pass to the space 	 * map histogram. We want to make sure that the on-disk histogram 	 * accounts for all free space. If the space map is not loaded, 	 * then we will lose some accuracy but will correct it the next 	 * time we load the space map. 	 */
name|space_map_histogram_add
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|,
name|msp
operator|->
name|ms_freeingtree
argument_list|,
name|tx
argument_list|)
expr_stmt|;
name|metaslab_group_histogram_add
argument_list|(
name|mg
argument_list|,
name|msp
argument_list|)
expr_stmt|;
name|metaslab_group_histogram_verify
argument_list|(
name|mg
argument_list|)
expr_stmt|;
name|metaslab_class_histogram_verify
argument_list|(
name|mg
operator|->
name|mg_class
argument_list|)
expr_stmt|;
comment|/* 	 * For sync pass 1, we avoid traversing this txg's free range tree 	 * and instead will just swap the pointers for freeingtree and 	 * freedtree. We can safely do this since the freed_tree is 	 * guaranteed to be empty on the initial pass. 	 */
if|if
condition|(
name|spa_sync_pass
argument_list|(
name|spa
argument_list|)
operator|==
literal|1
condition|)
block|{
name|range_tree_swap
argument_list|(
operator|&
name|msp
operator|->
name|ms_freeingtree
argument_list|,
operator|&
name|msp
operator|->
name|ms_freedtree
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|range_tree_vacate
argument_list|(
name|msp
operator|->
name|ms_freeingtree
argument_list|,
name|range_tree_add
argument_list|,
name|msp
operator|->
name|ms_freedtree
argument_list|)
expr_stmt|;
block|}
name|range_tree_vacate
argument_list|(
name|alloctree
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
name|txg
operator|&
name|TXG_MASK
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
name|TXG_CLEAN
argument_list|(
name|txg
argument_list|)
operator|&
name|TXG_MASK
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_freeingtree
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|space_map_object
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
condition|)
block|{
name|object
operator|=
name|space_map_object
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
expr_stmt|;
name|dmu_write
argument_list|(
name|mos
argument_list|,
name|vd
operator|->
name|vdev_ms_array
argument_list|,
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
operator|*
name|msp
operator|->
name|ms_id
argument_list|,
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
argument_list|,
operator|&
name|object
argument_list|,
name|tx
argument_list|)
expr_stmt|;
block|}
name|dmu_tx_commit
argument_list|(
name|tx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Called after a transaction group has completely synced to mark  * all of the metaslab's free space as usable.  */
end_comment

begin_function
name|void
name|metaslab_sync_done
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|txg
parameter_list|)
block|{
name|metaslab_group_t
modifier|*
name|mg
init|=
name|msp
operator|->
name|ms_group
decl_stmt|;
name|vdev_t
modifier|*
name|vd
init|=
name|mg
operator|->
name|mg_vd
decl_stmt|;
name|spa_t
modifier|*
name|spa
init|=
name|vd
operator|->
name|vdev_spa
decl_stmt|;
name|range_tree_t
modifier|*
modifier|*
name|defer_tree
decl_stmt|;
name|int64_t
name|alloc_delta
decl_stmt|,
name|defer_delta
decl_stmt|;
name|boolean_t
name|defer_allowed
init|=
name|B_TRUE
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|vd
operator|->
name|vdev_ishole
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
comment|/* 	 * If this metaslab is just becoming available, initialize its 	 * range trees and add its capacity to the vdev. 	 */
if|if
condition|(
name|msp
operator|->
name|ms_freedtree
operator|==
name|NULL
condition|)
block|{
for|for
control|(
name|int
name|t
init|=
literal|0
init|;
name|t
operator|<
name|TXG_SIZE
condition|;
name|t
operator|++
control|)
block|{
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
name|t
index|]
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_alloctree
index|[
name|t
index|]
operator|=
name|range_tree_create
argument_list|(
name|NULL
argument_list|,
name|msp
argument_list|,
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
block|}
name|ASSERT3P
argument_list|(
name|msp
operator|->
name|ms_freeingtree
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_freeingtree
operator|=
name|range_tree_create
argument_list|(
name|NULL
argument_list|,
name|msp
argument_list|,
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|msp
operator|->
name|ms_freedtree
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_freedtree
operator|=
name|range_tree_create
argument_list|(
name|NULL
argument_list|,
name|msp
argument_list|,
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|t
init|=
literal|0
init|;
name|t
operator|<
name|TXG_DEFER_SIZE
condition|;
name|t
operator|++
control|)
block|{
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_defertree
index|[
name|t
index|]
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_defertree
index|[
name|t
index|]
operator|=
name|range_tree_create
argument_list|(
name|NULL
argument_list|,
name|msp
argument_list|,
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
block|}
name|vdev_space_update
argument_list|(
name|vd
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|msp
operator|->
name|ms_size
argument_list|)
expr_stmt|;
block|}
name|defer_tree
operator|=
operator|&
name|msp
operator|->
name|ms_defertree
index|[
name|txg
operator|%
name|TXG_DEFER_SIZE
index|]
expr_stmt|;
name|uint64_t
name|free_space
init|=
name|metaslab_class_get_space
argument_list|(
name|spa_normal_class
argument_list|(
name|spa
argument_list|)
argument_list|)
operator|-
name|metaslab_class_get_alloc
argument_list|(
name|spa_normal_class
argument_list|(
name|spa
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|free_space
operator|<=
name|spa_get_slop_space
argument_list|(
name|spa
argument_list|)
condition|)
block|{
name|defer_allowed
operator|=
name|B_FALSE
expr_stmt|;
block|}
name|defer_delta
operator|=
literal|0
expr_stmt|;
name|alloc_delta
operator|=
name|space_map_alloc_delta
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
expr_stmt|;
if|if
condition|(
name|defer_allowed
condition|)
block|{
name|defer_delta
operator|=
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_freedtree
argument_list|)
operator|-
name|range_tree_space
argument_list|(
operator|*
name|defer_tree
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|defer_delta
operator|-=
name|range_tree_space
argument_list|(
operator|*
name|defer_tree
argument_list|)
expr_stmt|;
block|}
name|vdev_space_update
argument_list|(
name|vd
argument_list|,
name|alloc_delta
operator|+
name|defer_delta
argument_list|,
name|defer_delta
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * If there's a metaslab_load() in progress, wait for it to complete 	 * so that we have a consistent view of the in-core space map. 	 */
name|metaslab_load_wait
argument_list|(
name|msp
argument_list|)
expr_stmt|;
comment|/* 	 * Move the frees from the defer_tree back to the free 	 * range tree (if it's loaded). Swap the freed_tree and the 	 * defer_tree -- this is safe to do because we've just emptied out 	 * the defer_tree. 	 */
name|range_tree_vacate
argument_list|(
operator|*
name|defer_tree
argument_list|,
name|msp
operator|->
name|ms_loaded
condition|?
name|range_tree_add
else|:
name|NULL
argument_list|,
name|msp
operator|->
name|ms_tree
argument_list|)
expr_stmt|;
if|if
condition|(
name|defer_allowed
condition|)
block|{
name|range_tree_swap
argument_list|(
operator|&
name|msp
operator|->
name|ms_freedtree
argument_list|,
name|defer_tree
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|range_tree_vacate
argument_list|(
name|msp
operator|->
name|ms_freedtree
argument_list|,
name|msp
operator|->
name|ms_loaded
condition|?
name|range_tree_add
else|:
name|NULL
argument_list|,
name|msp
operator|->
name|ms_tree
argument_list|)
expr_stmt|;
block|}
name|space_map_update
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_deferspace
operator|+=
name|defer_delta
expr_stmt|;
name|ASSERT3S
argument_list|(
name|msp
operator|->
name|ms_deferspace
argument_list|,
operator|>=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|ASSERT3S
argument_list|(
name|msp
operator|->
name|ms_deferspace
argument_list|,
operator|<=
argument_list|,
name|msp
operator|->
name|ms_size
argument_list|)
expr_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_deferspace
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * Keep syncing this metaslab until all deferred frees 		 * are back in circulation. 		 */
name|vdev_dirty
argument_list|(
name|vd
argument_list|,
name|VDD_METASLAB
argument_list|,
name|msp
argument_list|,
name|txg
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Calculate the new weights before unloading any metaslabs. 	 * This will give us the most accurate weighting. 	 */
name|metaslab_group_sort
argument_list|(
name|mg
argument_list|,
name|msp
argument_list|,
name|metaslab_weight
argument_list|(
name|msp
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the metaslab is loaded and we've not tried to load or allocate 	 * from it in 'metaslab_unload_delay' txgs, then unload it. 	 */
if|if
condition|(
name|msp
operator|->
name|ms_loaded
operator|&&
name|msp
operator|->
name|ms_selected_txg
operator|+
name|metaslab_unload_delay
operator|<
name|txg
condition|)
block|{
for|for
control|(
name|int
name|t
init|=
literal|1
init|;
name|t
operator|<
name|TXG_CONCURRENT_STATES
condition|;
name|t
operator|++
control|)
block|{
name|VERIFY0
argument_list|(
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
operator|(
name|txg
operator|+
name|t
operator|)
operator|&
name|TXG_MASK
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|metaslab_debug_unload
condition|)
name|metaslab_unload
argument_list|(
name|msp
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|metaslab_sync_reassess
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|)
block|{
name|metaslab_group_alloc_update
argument_list|(
name|mg
argument_list|)
expr_stmt|;
name|mg
operator|->
name|mg_fragmentation
operator|=
name|metaslab_group_fragmentation
argument_list|(
name|mg
argument_list|)
expr_stmt|;
comment|/* 	 * Preload the next potential metaslabs 	 */
name|metaslab_group_preload
argument_list|(
name|mg
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|metaslab_distance
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|dva_t
modifier|*
name|dva
parameter_list|)
block|{
name|uint64_t
name|ms_shift
init|=
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_ms_shift
decl_stmt|;
name|uint64_t
name|offset
init|=
name|DVA_GET_OFFSET
argument_list|(
name|dva
argument_list|)
operator|>>
name|ms_shift
decl_stmt|;
name|uint64_t
name|start
init|=
name|msp
operator|->
name|ms_id
decl_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_group
operator|->
name|mg_vd
operator|->
name|vdev_id
operator|!=
name|DVA_GET_VDEV
argument_list|(
name|dva
argument_list|)
condition|)
return|return
operator|(
literal|1ULL
operator|<<
literal|63
operator|)
return|;
if|if
condition|(
name|offset
operator|<
name|start
condition|)
return|return
operator|(
operator|(
name|start
operator|-
name|offset
operator|)
operator|<<
name|ms_shift
operator|)
return|;
if|if
condition|(
name|offset
operator|>
name|start
condition|)
return|return
operator|(
operator|(
name|offset
operator|-
name|start
operator|)
operator|<<
name|ms_shift
operator|)
return|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * ==========================================================================  * Metaslab allocation tracing facility  * ==========================================================================  */
end_comment

begin_decl_stmt
name|kstat_t
modifier|*
name|metaslab_trace_ksp
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|kstat_named_t
name|metaslab_trace_over_limit
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|metaslab_alloc_trace_init
parameter_list|(
name|void
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|metaslab_alloc_trace_cache
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|metaslab_alloc_trace_cache
operator|=
name|kmem_cache_create
argument_list|(
literal|"metaslab_alloc_trace_cache"
argument_list|,
sizeof|sizeof
argument_list|(
name|metaslab_alloc_trace_t
argument_list|)
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|metaslab_trace_ksp
operator|=
name|kstat_create
argument_list|(
literal|"zfs"
argument_list|,
literal|0
argument_list|,
literal|"metaslab_trace_stats"
argument_list|,
literal|"misc"
argument_list|,
name|KSTAT_TYPE_NAMED
argument_list|,
literal|1
argument_list|,
name|KSTAT_FLAG_VIRTUAL
argument_list|)
expr_stmt|;
if|if
condition|(
name|metaslab_trace_ksp
operator|!=
name|NULL
condition|)
block|{
name|metaslab_trace_ksp
operator|->
name|ks_data
operator|=
operator|&
name|metaslab_trace_over_limit
expr_stmt|;
name|kstat_named_init
argument_list|(
operator|&
name|metaslab_trace_over_limit
argument_list|,
literal|"metaslab_trace_over_limit"
argument_list|,
name|KSTAT_DATA_UINT64
argument_list|)
expr_stmt|;
name|kstat_install
argument_list|(
name|metaslab_trace_ksp
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|metaslab_alloc_trace_fini
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|metaslab_trace_ksp
operator|!=
name|NULL
condition|)
block|{
name|kstat_delete
argument_list|(
name|metaslab_trace_ksp
argument_list|)
expr_stmt|;
name|metaslab_trace_ksp
operator|=
name|NULL
expr_stmt|;
block|}
name|kmem_cache_destroy
argument_list|(
name|metaslab_alloc_trace_cache
argument_list|)
expr_stmt|;
name|metaslab_alloc_trace_cache
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Add an allocation trace element to the allocation tracing list.  */
end_comment

begin_function
specifier|static
name|void
name|metaslab_trace_add
parameter_list|(
name|zio_alloc_list_t
modifier|*
name|zal
parameter_list|,
name|metaslab_group_t
modifier|*
name|mg
parameter_list|,
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|psize
parameter_list|,
name|uint32_t
name|dva_id
parameter_list|,
name|uint64_t
name|offset
parameter_list|)
block|{
if|if
condition|(
operator|!
name|metaslab_trace_enabled
condition|)
return|return;
comment|/* 	 * When the tracing list reaches its maximum we remove 	 * the second element in the list before adding a new one. 	 * By removing the second element we preserve the original 	 * entry as a clue to what allocations steps have already been 	 * performed. 	 */
if|if
condition|(
name|zal
operator|->
name|zal_size
operator|==
name|metaslab_trace_max_entries
condition|)
block|{
name|metaslab_alloc_trace_t
modifier|*
name|mat_next
decl_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
name|panic
argument_list|(
literal|"too many entries in allocation list"
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|atomic_inc_64
argument_list|(
operator|&
name|metaslab_trace_over_limit
operator|.
name|value
operator|.
name|ui64
argument_list|)
expr_stmt|;
name|zal
operator|->
name|zal_size
operator|--
expr_stmt|;
name|mat_next
operator|=
name|list_next
argument_list|(
operator|&
name|zal
operator|->
name|zal_list
argument_list|,
name|list_head
argument_list|(
operator|&
name|zal
operator|->
name|zal_list
argument_list|)
argument_list|)
expr_stmt|;
name|list_remove
argument_list|(
operator|&
name|zal
operator|->
name|zal_list
argument_list|,
name|mat_next
argument_list|)
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|metaslab_alloc_trace_cache
argument_list|,
name|mat_next
argument_list|)
expr_stmt|;
block|}
name|metaslab_alloc_trace_t
modifier|*
name|mat
init|=
name|kmem_cache_alloc
argument_list|(
name|metaslab_alloc_trace_cache
argument_list|,
name|KM_SLEEP
argument_list|)
decl_stmt|;
name|list_link_init
argument_list|(
operator|&
name|mat
operator|->
name|mat_list_node
argument_list|)
expr_stmt|;
name|mat
operator|->
name|mat_mg
operator|=
name|mg
expr_stmt|;
name|mat
operator|->
name|mat_msp
operator|=
name|msp
expr_stmt|;
name|mat
operator|->
name|mat_size
operator|=
name|psize
expr_stmt|;
name|mat
operator|->
name|mat_dva_id
operator|=
name|dva_id
expr_stmt|;
name|mat
operator|->
name|mat_offset
operator|=
name|offset
expr_stmt|;
name|mat
operator|->
name|mat_weight
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|msp
operator|!=
name|NULL
condition|)
name|mat
operator|->
name|mat_weight
operator|=
name|msp
operator|->
name|ms_weight
expr_stmt|;
comment|/* 	 * The list is part of the zio so locking is not required. Only 	 * a single thread will perform allocations for a given zio. 	 */
name|list_insert_tail
argument_list|(
operator|&
name|zal
operator|->
name|zal_list
argument_list|,
name|mat
argument_list|)
expr_stmt|;
name|zal
operator|->
name|zal_size
operator|++
expr_stmt|;
name|ASSERT3U
argument_list|(
name|zal
operator|->
name|zal_size
argument_list|,
operator|<=
argument_list|,
name|metaslab_trace_max_entries
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|metaslab_trace_init
parameter_list|(
name|zio_alloc_list_t
modifier|*
name|zal
parameter_list|)
block|{
name|list_create
argument_list|(
operator|&
name|zal
operator|->
name|zal_list
argument_list|,
sizeof|sizeof
argument_list|(
name|metaslab_alloc_trace_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|metaslab_alloc_trace_t
argument_list|,
name|mat_list_node
argument_list|)
argument_list|)
expr_stmt|;
name|zal
operator|->
name|zal_size
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
name|void
name|metaslab_trace_fini
parameter_list|(
name|zio_alloc_list_t
modifier|*
name|zal
parameter_list|)
block|{
name|metaslab_alloc_trace_t
modifier|*
name|mat
decl_stmt|;
while|while
condition|(
operator|(
name|mat
operator|=
name|list_remove_head
argument_list|(
operator|&
name|zal
operator|->
name|zal_list
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
name|kmem_cache_free
argument_list|(
name|metaslab_alloc_trace_cache
argument_list|,
name|mat
argument_list|)
expr_stmt|;
name|list_destroy
argument_list|(
operator|&
name|zal
operator|->
name|zal_list
argument_list|)
expr_stmt|;
name|zal
operator|->
name|zal_size
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * ==========================================================================  * Metaslab block operations  * ==========================================================================  */
end_comment

begin_function
specifier|static
name|void
name|metaslab_group_alloc_increment
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|uint64_t
name|vdev
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|flags
operator|&
name|METASLAB_ASYNC_ALLOC
operator|)
operator|||
name|flags
operator|&
name|METASLAB_DONT_THROTTLE
condition|)
return|return;
name|metaslab_group_t
modifier|*
name|mg
init|=
name|vdev_lookup_top
argument_list|(
name|spa
argument_list|,
name|vdev
argument_list|)
operator|->
name|vdev_mg
decl_stmt|;
if|if
condition|(
operator|!
name|mg
operator|->
name|mg_class
operator|->
name|mc_alloc_throttle_enabled
condition|)
return|return;
operator|(
name|void
operator|)
name|refcount_add
argument_list|(
operator|&
name|mg
operator|->
name|mg_alloc_queue_depth
argument_list|,
name|tag
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|metaslab_group_alloc_decrement
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|uint64_t
name|vdev
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|flags
operator|&
name|METASLAB_ASYNC_ALLOC
operator|)
operator|||
name|flags
operator|&
name|METASLAB_DONT_THROTTLE
condition|)
return|return;
name|metaslab_group_t
modifier|*
name|mg
init|=
name|vdev_lookup_top
argument_list|(
name|spa
argument_list|,
name|vdev
argument_list|)
operator|->
name|vdev_mg
decl_stmt|;
if|if
condition|(
operator|!
name|mg
operator|->
name|mg_class
operator|->
name|mc_alloc_throttle_enabled
condition|)
return|return;
operator|(
name|void
operator|)
name|refcount_remove
argument_list|(
operator|&
name|mg
operator|->
name|mg_alloc_queue_depth
argument_list|,
name|tag
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|metaslab_group_alloc_verify
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
specifier|const
name|blkptr_t
modifier|*
name|bp
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|ZFS_DEBUG
specifier|const
name|dva_t
modifier|*
name|dva
init|=
name|bp
operator|->
name|blk_dva
decl_stmt|;
name|int
name|ndvas
init|=
name|BP_GET_NDVAS
argument_list|(
name|bp
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|d
init|=
literal|0
init|;
name|d
operator|<
name|ndvas
condition|;
name|d
operator|++
control|)
block|{
name|uint64_t
name|vdev
init|=
name|DVA_GET_VDEV
argument_list|(
operator|&
name|dva
index|[
name|d
index|]
argument_list|)
decl_stmt|;
name|metaslab_group_t
modifier|*
name|mg
init|=
name|vdev_lookup_top
argument_list|(
name|spa
argument_list|,
name|vdev
argument_list|)
operator|->
name|vdev_mg
decl_stmt|;
name|VERIFY
argument_list|(
name|refcount_not_held
argument_list|(
operator|&
name|mg
operator|->
name|mg_alloc_queue_depth
argument_list|,
name|tag
argument_list|)
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|metaslab_block_alloc
parameter_list|(
name|metaslab_t
modifier|*
name|msp
parameter_list|,
name|uint64_t
name|size
parameter_list|,
name|uint64_t
name|txg
parameter_list|)
block|{
name|uint64_t
name|start
decl_stmt|;
name|range_tree_t
modifier|*
name|rt
init|=
name|msp
operator|->
name|ms_tree
decl_stmt|;
name|metaslab_class_t
modifier|*
name|mc
init|=
name|msp
operator|->
name|ms_group
operator|->
name|mg_class
decl_stmt|;
name|VERIFY
argument_list|(
operator|!
name|msp
operator|->
name|ms_condensing
argument_list|)
expr_stmt|;
name|start
operator|=
name|mc
operator|->
name|mc_ops
operator|->
name|msop_alloc
argument_list|(
name|msp
argument_list|,
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|start
operator|!=
operator|-
literal|1ULL
condition|)
block|{
name|metaslab_group_t
modifier|*
name|mg
init|=
name|msp
operator|->
name|ms_group
decl_stmt|;
name|vdev_t
modifier|*
name|vd
init|=
name|mg
operator|->
name|mg_vd
decl_stmt|;
name|VERIFY0
argument_list|(
name|P2PHASE
argument_list|(
name|start
argument_list|,
literal|1ULL
operator|<<
name|vd
operator|->
name|vdev_ashift
argument_list|)
argument_list|)
expr_stmt|;
name|VERIFY0
argument_list|(
name|P2PHASE
argument_list|(
name|size
argument_list|,
literal|1ULL
operator|<<
name|vd
operator|->
name|vdev_ashift
argument_list|)
argument_list|)
expr_stmt|;
name|VERIFY3U
argument_list|(
name|range_tree_space
argument_list|(
name|rt
argument_list|)
operator|-
name|size
argument_list|,
operator|<=
argument_list|,
name|msp
operator|->
name|ms_size
argument_list|)
expr_stmt|;
name|range_tree_remove
argument_list|(
name|rt
argument_list|,
name|start
argument_list|,
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
name|txg
operator|&
name|TXG_MASK
index|]
argument_list|)
operator|==
literal|0
condition|)
name|vdev_dirty
argument_list|(
name|mg
operator|->
name|mg_vd
argument_list|,
name|VDD_METASLAB
argument_list|,
name|msp
argument_list|,
name|txg
argument_list|)
expr_stmt|;
name|range_tree_add
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
name|txg
operator|&
name|TXG_MASK
index|]
argument_list|,
name|start
argument_list|,
name|size
argument_list|)
expr_stmt|;
comment|/* Track the last successful allocation */
name|msp
operator|->
name|ms_alloc_txg
operator|=
name|txg
expr_stmt|;
name|metaslab_verify_space
argument_list|(
name|msp
argument_list|,
name|txg
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Now that we've attempted the allocation we need to update the 	 * metaslab's maximum block size since it may have changed. 	 */
name|msp
operator|->
name|ms_max_size
operator|=
name|metaslab_block_maxsize
argument_list|(
name|msp
argument_list|)
expr_stmt|;
return|return
operator|(
name|start
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|metaslab_group_alloc_normal
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|,
name|zio_alloc_list_t
modifier|*
name|zal
parameter_list|,
name|uint64_t
name|asize
parameter_list|,
name|uint64_t
name|txg
parameter_list|,
name|uint64_t
name|min_distance
parameter_list|,
name|dva_t
modifier|*
name|dva
parameter_list|,
name|int
name|d
parameter_list|)
block|{
name|metaslab_t
modifier|*
name|msp
init|=
name|NULL
decl_stmt|;
name|uint64_t
name|offset
init|=
operator|-
literal|1ULL
decl_stmt|;
name|uint64_t
name|activation_weight
decl_stmt|;
name|uint64_t
name|target_distance
decl_stmt|;
name|int
name|i
decl_stmt|;
name|activation_weight
operator|=
name|METASLAB_WEIGHT_PRIMARY
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|d
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|DVA_GET_VDEV
argument_list|(
operator|&
name|dva
index|[
name|i
index|]
argument_list|)
operator|==
name|mg
operator|->
name|mg_vd
operator|->
name|vdev_id
condition|)
block|{
name|activation_weight
operator|=
name|METASLAB_WEIGHT_SECONDARY
expr_stmt|;
break|break;
block|}
block|}
name|metaslab_t
modifier|*
name|search
init|=
name|kmem_alloc
argument_list|(
sizeof|sizeof
argument_list|(
operator|*
name|search
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
decl_stmt|;
name|search
operator|->
name|ms_weight
operator|=
name|UINT64_MAX
expr_stmt|;
name|search
operator|->
name|ms_start
operator|=
literal|0
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|boolean_t
name|was_active
decl_stmt|;
name|avl_tree_t
modifier|*
name|t
init|=
operator|&
name|mg
operator|->
name|mg_metaslab_tree
decl_stmt|;
name|avl_index_t
name|idx
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
comment|/* 		 * Find the metaslab with the highest weight that is less 		 * than what we've already tried.  In the common case, this 		 * means that we will examine each metaslab at most once. 		 * Note that concurrent callers could reorder metaslabs 		 * by activation/passivation once we have dropped the mg_lock. 		 * If a metaslab is activated by another thread, and we fail 		 * to allocate from the metaslab we have selected, we may 		 * not try the newly-activated metaslab, and instead activate 		 * another metaslab.  This is not optimal, but generally 		 * does not cause any problems (a possible exception being 		 * if every metaslab is completely full except for the 		 * the newly-activated metaslab which we fail to examine). 		 */
name|msp
operator|=
name|avl_find
argument_list|(
name|t
argument_list|,
name|search
argument_list|,
operator|&
name|idx
argument_list|)
expr_stmt|;
if|if
condition|(
name|msp
operator|==
name|NULL
condition|)
name|msp
operator|=
name|avl_nearest
argument_list|(
name|t
argument_list|,
name|idx
argument_list|,
name|AVL_AFTER
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|msp
operator|!=
name|NULL
condition|;
name|msp
operator|=
name|AVL_NEXT
argument_list|(
name|t
argument_list|,
name|msp
argument_list|)
control|)
block|{
if|if
condition|(
operator|!
name|metaslab_should_allocate
argument_list|(
name|msp
argument_list|,
name|asize
argument_list|)
condition|)
block|{
name|metaslab_trace_add
argument_list|(
name|zal
argument_list|,
name|mg
argument_list|,
name|msp
argument_list|,
name|asize
argument_list|,
name|d
argument_list|,
name|TRACE_TOO_SMALL
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 			 * If the selected metaslab is condensing, skip it. 			 */
if|if
condition|(
name|msp
operator|->
name|ms_condensing
condition|)
continue|continue;
name|was_active
operator|=
name|msp
operator|->
name|ms_weight
operator|&
name|METASLAB_ACTIVE_MASK
expr_stmt|;
if|if
condition|(
name|activation_weight
operator|==
name|METASLAB_WEIGHT_PRIMARY
condition|)
break|break;
name|target_distance
operator|=
name|min_distance
operator|+
operator|(
name|space_map_allocated
argument_list|(
name|msp
operator|->
name|ms_sm
argument_list|)
operator|!=
literal|0
condition|?
literal|0
else|:
name|min_distance
operator|>>
literal|1
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|d
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|metaslab_distance
argument_list|(
name|msp
argument_list|,
operator|&
name|dva
index|[
name|i
index|]
argument_list|)
operator|<
name|target_distance
condition|)
break|break;
block|}
if|if
condition|(
name|i
operator|==
name|d
condition|)
break|break;
block|}
name|mutex_exit
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|msp
operator|==
name|NULL
condition|)
block|{
name|kmem_free
argument_list|(
name|search
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|search
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
operator|-
literal|1ULL
operator|)
return|;
block|}
name|search
operator|->
name|ms_weight
operator|=
name|msp
operator|->
name|ms_weight
expr_stmt|;
name|search
operator|->
name|ms_start
operator|=
name|msp
operator|->
name|ms_start
operator|+
literal|1
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
comment|/* 		 * Ensure that the metaslab we have selected is still 		 * capable of handling our request. It's possible that 		 * another thread may have changed the weight while we 		 * were blocked on the metaslab lock. We check the 		 * active status first to see if we need to reselect 		 * a new metaslab. 		 */
if|if
condition|(
name|was_active
operator|&&
operator|!
operator|(
name|msp
operator|->
name|ms_weight
operator|&
name|METASLAB_ACTIVE_MASK
operator|)
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|(
name|msp
operator|->
name|ms_weight
operator|&
name|METASLAB_WEIGHT_SECONDARY
operator|)
operator|&&
name|activation_weight
operator|==
name|METASLAB_WEIGHT_PRIMARY
condition|)
block|{
name|metaslab_passivate
argument_list|(
name|msp
argument_list|,
name|msp
operator|->
name|ms_weight
operator|&
operator|~
name|METASLAB_ACTIVE_MASK
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|metaslab_activate
argument_list|(
name|msp
argument_list|,
name|activation_weight
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|msp
operator|->
name|ms_selected_txg
operator|=
name|txg
expr_stmt|;
comment|/* 		 * Now that we have the lock, recheck to see if we should 		 * continue to use this metaslab for this allocation. The 		 * the metaslab is now loaded so metaslab_should_allocate() can 		 * accurately determine if the allocation attempt should 		 * proceed. 		 */
if|if
condition|(
operator|!
name|metaslab_should_allocate
argument_list|(
name|msp
argument_list|,
name|asize
argument_list|)
condition|)
block|{
comment|/* Passivate this metaslab and select a new one. */
name|metaslab_trace_add
argument_list|(
name|zal
argument_list|,
name|mg
argument_list|,
name|msp
argument_list|,
name|asize
argument_list|,
name|d
argument_list|,
name|TRACE_TOO_SMALL
argument_list|)
expr_stmt|;
goto|goto
name|next
goto|;
block|}
comment|/* 		 * If this metaslab is currently condensing then pick again as 		 * we can't manipulate this metaslab until it's committed 		 * to disk. 		 */
if|if
condition|(
name|msp
operator|->
name|ms_condensing
condition|)
block|{
name|metaslab_trace_add
argument_list|(
name|zal
argument_list|,
name|mg
argument_list|,
name|msp
argument_list|,
name|asize
argument_list|,
name|d
argument_list|,
name|TRACE_CONDENSING
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|offset
operator|=
name|metaslab_block_alloc
argument_list|(
name|msp
argument_list|,
name|asize
argument_list|,
name|txg
argument_list|)
expr_stmt|;
name|metaslab_trace_add
argument_list|(
name|zal
argument_list|,
name|mg
argument_list|,
name|msp
argument_list|,
name|asize
argument_list|,
name|d
argument_list|,
name|offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|offset
operator|!=
operator|-
literal|1ULL
condition|)
block|{
comment|/* Proactively passivate the metaslab, if needed */
name|metaslab_segment_may_passivate
argument_list|(
name|msp
argument_list|)
expr_stmt|;
break|break;
block|}
name|next
label|:
name|ASSERT
argument_list|(
name|msp
operator|->
name|ms_loaded
argument_list|)
expr_stmt|;
comment|/* 		 * We were unable to allocate from this metaslab so determine 		 * a new weight for this metaslab. Now that we have loaded 		 * the metaslab we can provide a better hint to the metaslab 		 * selector. 		 * 		 * For space-based metaslabs, we use the maximum block size. 		 * This information is only available when the metaslab 		 * is loaded and is more accurate than the generic free 		 * space weight that was calculated by metaslab_weight(). 		 * This information allows us to quickly compare the maximum 		 * available allocation in the metaslab to the allocation 		 * size being requested. 		 * 		 * For segment-based metaslabs, determine the new weight 		 * based on the highest bucket in the range tree. We 		 * explicitly use the loaded segment weight (i.e. the range 		 * tree histogram) since it contains the space that is 		 * currently available for allocation and is accurate 		 * even within a sync pass. 		 */
if|if
condition|(
name|WEIGHT_IS_SPACEBASED
argument_list|(
name|msp
operator|->
name|ms_weight
argument_list|)
condition|)
block|{
name|uint64_t
name|weight
init|=
name|metaslab_block_maxsize
argument_list|(
name|msp
argument_list|)
decl_stmt|;
name|WEIGHT_SET_SPACEBASED
argument_list|(
name|weight
argument_list|)
expr_stmt|;
name|metaslab_passivate
argument_list|(
name|msp
argument_list|,
name|weight
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|metaslab_passivate
argument_list|(
name|msp
argument_list|,
name|metaslab_weight_from_range_tree
argument_list|(
name|msp
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * We have just failed an allocation attempt, check 		 * that metaslab_should_allocate() agrees. Otherwise, 		 * we may end up in an infinite loop retrying the same 		 * metaslab. 		 */
name|ASSERT
argument_list|(
operator|!
name|metaslab_should_allocate
argument_list|(
name|msp
argument_list|,
name|asize
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|search
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|search
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|offset
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|metaslab_group_alloc
parameter_list|(
name|metaslab_group_t
modifier|*
name|mg
parameter_list|,
name|zio_alloc_list_t
modifier|*
name|zal
parameter_list|,
name|uint64_t
name|asize
parameter_list|,
name|uint64_t
name|txg
parameter_list|,
name|uint64_t
name|min_distance
parameter_list|,
name|dva_t
modifier|*
name|dva
parameter_list|,
name|int
name|d
parameter_list|)
block|{
name|uint64_t
name|offset
decl_stmt|;
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_initialized
argument_list|)
expr_stmt|;
name|offset
operator|=
name|metaslab_group_alloc_normal
argument_list|(
name|mg
argument_list|,
name|zal
argument_list|,
name|asize
argument_list|,
name|txg
argument_list|,
name|min_distance
argument_list|,
name|dva
argument_list|,
name|d
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|offset
operator|==
operator|-
literal|1ULL
condition|)
block|{
name|mg
operator|->
name|mg_failed_allocations
operator|++
expr_stmt|;
name|metaslab_trace_add
argument_list|(
name|zal
argument_list|,
name|mg
argument_list|,
name|NULL
argument_list|,
name|asize
argument_list|,
name|d
argument_list|,
name|TRACE_GROUP_FAILURE
argument_list|)
expr_stmt|;
if|if
condition|(
name|asize
operator|==
name|SPA_GANGBLOCKSIZE
condition|)
block|{
comment|/* 			 * This metaslab group was unable to allocate 			 * the minimum gang block size so it must be out of 			 * space. We must notify the allocation throttle 			 * to start skipping allocation attempts to this 			 * metaslab group until more space becomes available. 			 * Note: this failure cannot be caused by the 			 * allocation throttle since the allocation throttle 			 * is only responsible for skipping devices and 			 * not failing block allocations. 			 */
name|mg
operator|->
name|mg_no_free_space
operator|=
name|B_TRUE
expr_stmt|;
block|}
block|}
name|mg
operator|->
name|mg_allocations
operator|++
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|mg
operator|->
name|mg_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|offset
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * If we have to write a ditto block (i.e. more than one DVA for a given BP)  * on the same vdev as an existing DVA of this BP, then try to allocate it  * at least (vdev_asize / (2 ^ ditto_same_vdev_distance_shift)) away from the  * existing DVAs.  */
end_comment

begin_decl_stmt
name|int
name|ditto_same_vdev_distance_shift
init|=
literal|3
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Allocate a block for the specified i/o.  */
end_comment

begin_function
specifier|static
name|int
name|metaslab_alloc_dva
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|metaslab_class_t
modifier|*
name|mc
parameter_list|,
name|uint64_t
name|psize
parameter_list|,
name|dva_t
modifier|*
name|dva
parameter_list|,
name|int
name|d
parameter_list|,
name|dva_t
modifier|*
name|hintdva
parameter_list|,
name|uint64_t
name|txg
parameter_list|,
name|int
name|flags
parameter_list|,
name|zio_alloc_list_t
modifier|*
name|zal
parameter_list|)
block|{
name|metaslab_group_t
modifier|*
name|mg
decl_stmt|,
modifier|*
name|rotor
decl_stmt|;
name|vdev_t
modifier|*
name|vd
decl_stmt|;
name|boolean_t
name|try_hard
init|=
name|B_FALSE
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|DVA_IS_VALID
argument_list|(
operator|&
name|dva
index|[
name|d
index|]
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * For testing, make some blocks above a certain size be gang blocks. 	 */
if|if
condition|(
name|psize
operator|>=
name|metaslab_gang_bang
operator|&&
operator|(
name|ddi_get_lbolt
argument_list|()
operator|&
literal|3
operator|)
operator|==
literal|0
condition|)
block|{
name|metaslab_trace_add
argument_list|(
name|zal
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|psize
argument_list|,
name|d
argument_list|,
name|TRACE_FORCE_GANG
argument_list|)
expr_stmt|;
return|return
operator|(
name|SET_ERROR
argument_list|(
name|ENOSPC
argument_list|)
operator|)
return|;
block|}
comment|/* 	 * Start at the rotor and loop through all mgs until we find something. 	 * Note that there's no locking on mc_rotor or mc_aliquot because 	 * nothing actually breaks if we miss a few updates -- we just won't 	 * allocate quite as evenly.  It all balances out over time. 	 * 	 * If we are doing ditto or log blocks, try to spread them across 	 * consecutive vdevs.  If we're forced to reuse a vdev before we've 	 * allocated all of our ditto blocks, then try and spread them out on 	 * that vdev as much as possible.  If it turns out to not be possible, 	 * gradually lower our standards until anything becomes acceptable. 	 * Also, allocating on consecutive vdevs (as opposed to random vdevs) 	 * gives us hope of containing our fault domains to something we're 	 * able to reason about.  Otherwise, any two top-level vdev failures 	 * will guarantee the loss of data.  With consecutive allocation, 	 * only two adjacent top-level vdev failures will result in data loss. 	 * 	 * If we are doing gang blocks (hintdva is non-NULL), try to keep 	 * ourselves on the same vdev as our gang block header.  That 	 * way, we can hope for locality in vdev_cache, plus it makes our 	 * fault domains something tractable. 	 */
if|if
condition|(
name|hintdva
condition|)
block|{
name|vd
operator|=
name|vdev_lookup_top
argument_list|(
name|spa
argument_list|,
name|DVA_GET_VDEV
argument_list|(
operator|&
name|hintdva
index|[
name|d
index|]
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 		 * It's possible the vdev we're using as the hint no 		 * longer exists (i.e. removed). Consult the rotor when 		 * all else fails. 		 */
if|if
condition|(
name|vd
operator|!=
name|NULL
condition|)
block|{
name|mg
operator|=
name|vd
operator|->
name|vdev_mg
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|METASLAB_HINTBP_AVOID
operator|&&
name|mg
operator|->
name|mg_next
operator|!=
name|NULL
condition|)
name|mg
operator|=
name|mg
operator|->
name|mg_next
expr_stmt|;
block|}
else|else
block|{
name|mg
operator|=
name|mc
operator|->
name|mc_rotor
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|d
operator|!=
literal|0
condition|)
block|{
name|vd
operator|=
name|vdev_lookup_top
argument_list|(
name|spa
argument_list|,
name|DVA_GET_VDEV
argument_list|(
operator|&
name|dva
index|[
name|d
operator|-
literal|1
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|mg
operator|=
name|vd
operator|->
name|vdev_mg
operator|->
name|mg_next
expr_stmt|;
block|}
else|else
block|{
name|mg
operator|=
name|mc
operator|->
name|mc_rotor
expr_stmt|;
block|}
comment|/* 	 * If the hint put us into the wrong metaslab class, or into a 	 * metaslab group that has been passivated, just follow the rotor. 	 */
if|if
condition|(
name|mg
operator|->
name|mg_class
operator|!=
name|mc
operator|||
name|mg
operator|->
name|mg_activation_count
operator|<=
literal|0
condition|)
name|mg
operator|=
name|mc
operator|->
name|mc_rotor
expr_stmt|;
name|rotor
operator|=
name|mg
expr_stmt|;
name|top
label|:
do|do
block|{
name|boolean_t
name|allocatable
decl_stmt|;
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_activation_count
operator|==
literal|1
argument_list|)
expr_stmt|;
name|vd
operator|=
name|mg
operator|->
name|mg_vd
expr_stmt|;
comment|/* 		 * Don't allocate from faulted devices. 		 */
if|if
condition|(
name|try_hard
condition|)
block|{
name|spa_config_enter
argument_list|(
name|spa
argument_list|,
name|SCL_ZIO
argument_list|,
name|FTAG
argument_list|,
name|RW_READER
argument_list|)
expr_stmt|;
name|allocatable
operator|=
name|vdev_allocatable
argument_list|(
name|vd
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_ZIO
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|allocatable
operator|=
name|vdev_allocatable
argument_list|(
name|vd
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Determine if the selected metaslab group is eligible 		 * for allocations. If we're ganging then don't allow 		 * this metaslab group to skip allocations since that would 		 * inadvertently return ENOSPC and suspend the pool 		 * even though space is still available. 		 */
if|if
condition|(
name|allocatable
operator|&&
operator|!
name|GANG_ALLOCATION
argument_list|(
name|flags
argument_list|)
operator|&&
operator|!
name|try_hard
condition|)
block|{
name|allocatable
operator|=
name|metaslab_group_allocatable
argument_list|(
name|mg
argument_list|,
name|rotor
argument_list|,
name|psize
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|allocatable
condition|)
block|{
name|metaslab_trace_add
argument_list|(
name|zal
argument_list|,
name|mg
argument_list|,
name|NULL
argument_list|,
name|psize
argument_list|,
name|d
argument_list|,
name|TRACE_NOT_ALLOCATABLE
argument_list|)
expr_stmt|;
goto|goto
name|next
goto|;
block|}
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_initialized
argument_list|)
expr_stmt|;
comment|/* 		 * Avoid writing single-copy data to a failing, 		 * non-redundant vdev, unless we've already tried all 		 * other vdevs. 		 */
if|if
condition|(
operator|(
name|vd
operator|->
name|vdev_stat
operator|.
name|vs_write_errors
operator|>
literal|0
operator|||
name|vd
operator|->
name|vdev_state
operator|<
name|VDEV_STATE_HEALTHY
operator|)
operator|&&
name|d
operator|==
literal|0
operator|&&
operator|!
name|try_hard
operator|&&
name|vd
operator|->
name|vdev_children
operator|==
literal|0
condition|)
block|{
name|metaslab_trace_add
argument_list|(
name|zal
argument_list|,
name|mg
argument_list|,
name|NULL
argument_list|,
name|psize
argument_list|,
name|d
argument_list|,
name|TRACE_VDEV_ERROR
argument_list|)
expr_stmt|;
goto|goto
name|next
goto|;
block|}
name|ASSERT
argument_list|(
name|mg
operator|->
name|mg_class
operator|==
name|mc
argument_list|)
expr_stmt|;
comment|/* 		 * If we don't need to try hard, then require that the 		 * block be 1/8th of the device away from any other DVAs 		 * in this BP.  If we are trying hard, allow any offset 		 * to be used (distance=0). 		 */
name|uint64_t
name|distance
init|=
literal|0
decl_stmt|;
if|if
condition|(
operator|!
name|try_hard
condition|)
block|{
name|distance
operator|=
name|vd
operator|->
name|vdev_asize
operator|>>
name|ditto_same_vdev_distance_shift
expr_stmt|;
if|if
condition|(
name|distance
operator|<=
operator|(
literal|1ULL
operator|<<
name|vd
operator|->
name|vdev_ms_shift
operator|)
condition|)
name|distance
operator|=
literal|0
expr_stmt|;
block|}
name|uint64_t
name|asize
init|=
name|vdev_psize_to_asize
argument_list|(
name|vd
argument_list|,
name|psize
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
name|P2PHASE
argument_list|(
name|asize
argument_list|,
literal|1ULL
operator|<<
name|vd
operator|->
name|vdev_ashift
argument_list|)
operator|==
literal|0
argument_list|)
expr_stmt|;
name|uint64_t
name|offset
init|=
name|metaslab_group_alloc
argument_list|(
name|mg
argument_list|,
name|zal
argument_list|,
name|asize
argument_list|,
name|txg
argument_list|,
name|distance
argument_list|,
name|dva
argument_list|,
name|d
argument_list|)
decl_stmt|;
if|if
condition|(
name|offset
operator|!=
operator|-
literal|1ULL
condition|)
block|{
comment|/* 			 * If we've just selected this metaslab group, 			 * figure out whether the corresponding vdev is 			 * over- or under-used relative to the pool, 			 * and set an allocation bias to even it out. 			 */
if|if
condition|(
name|mc
operator|->
name|mc_aliquot
operator|==
literal|0
operator|&&
name|metaslab_bias_enabled
condition|)
block|{
name|vdev_stat_t
modifier|*
name|vs
init|=
operator|&
name|vd
operator|->
name|vdev_stat
decl_stmt|;
name|int64_t
name|vu
decl_stmt|,
name|cu
decl_stmt|;
name|vu
operator|=
operator|(
name|vs
operator|->
name|vs_alloc
operator|*
literal|100
operator|)
operator|/
operator|(
name|vs
operator|->
name|vs_space
operator|+
literal|1
operator|)
expr_stmt|;
name|cu
operator|=
operator|(
name|mc
operator|->
name|mc_alloc
operator|*
literal|100
operator|)
operator|/
operator|(
name|mc
operator|->
name|mc_space
operator|+
literal|1
operator|)
expr_stmt|;
comment|/* 				 * Calculate how much more or less we should 				 * try to allocate from this device during 				 * this iteration around the rotor. 				 * For example, if a device is 80% full 				 * and the pool is 20% full then we should 				 * reduce allocations by 60% on this device. 				 * 				 * mg_bias = (20 - 80) * 512K / 100 = -307K 				 * 				 * This reduces allocations by 307K for this 				 * iteration. 				 */
name|mg
operator|->
name|mg_bias
operator|=
operator|(
operator|(
name|cu
operator|-
name|vu
operator|)
operator|*
operator|(
name|int64_t
operator|)
name|mg
operator|->
name|mg_aliquot
operator|)
operator|/
literal|100
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|metaslab_bias_enabled
condition|)
block|{
name|mg
operator|->
name|mg_bias
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|atomic_add_64_nv
argument_list|(
operator|&
name|mc
operator|->
name|mc_aliquot
argument_list|,
name|asize
argument_list|)
operator|>=
name|mg
operator|->
name|mg_aliquot
operator|+
name|mg
operator|->
name|mg_bias
condition|)
block|{
name|mc
operator|->
name|mc_rotor
operator|=
name|mg
operator|->
name|mg_next
expr_stmt|;
name|mc
operator|->
name|mc_aliquot
operator|=
literal|0
expr_stmt|;
block|}
name|DVA_SET_VDEV
argument_list|(
operator|&
name|dva
index|[
name|d
index|]
argument_list|,
name|vd
operator|->
name|vdev_id
argument_list|)
expr_stmt|;
name|DVA_SET_OFFSET
argument_list|(
operator|&
name|dva
index|[
name|d
index|]
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|DVA_SET_GANG
argument_list|(
operator|&
name|dva
index|[
name|d
index|]
argument_list|,
operator|!
operator|!
operator|(
name|flags
operator|&
name|METASLAB_GANG_HEADER
operator|)
argument_list|)
expr_stmt|;
name|DVA_SET_ASIZE
argument_list|(
operator|&
name|dva
index|[
name|d
index|]
argument_list|,
name|asize
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|next
label|:
name|mc
operator|->
name|mc_rotor
operator|=
name|mg
operator|->
name|mg_next
expr_stmt|;
name|mc
operator|->
name|mc_aliquot
operator|=
literal|0
expr_stmt|;
block|}
do|while
condition|(
operator|(
name|mg
operator|=
name|mg
operator|->
name|mg_next
operator|)
operator|!=
name|rotor
condition|)
do|;
comment|/* 	 * If we haven't tried hard, do so now. 	 */
if|if
condition|(
operator|!
name|try_hard
condition|)
block|{
name|try_hard
operator|=
name|B_TRUE
expr_stmt|;
goto|goto
name|top
goto|;
block|}
name|bzero
argument_list|(
operator|&
name|dva
index|[
name|d
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|dva_t
argument_list|)
argument_list|)
expr_stmt|;
name|metaslab_trace_add
argument_list|(
name|zal
argument_list|,
name|rotor
argument_list|,
name|NULL
argument_list|,
name|psize
argument_list|,
name|d
argument_list|,
name|TRACE_ENOSPC
argument_list|)
expr_stmt|;
return|return
operator|(
name|SET_ERROR
argument_list|(
name|ENOSPC
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Free the block represented by DVA in the context of the specified  * transaction group.  */
end_comment

begin_function
specifier|static
name|void
name|metaslab_free_dva
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
specifier|const
name|dva_t
modifier|*
name|dva
parameter_list|,
name|uint64_t
name|txg
parameter_list|,
name|boolean_t
name|now
parameter_list|)
block|{
name|uint64_t
name|vdev
init|=
name|DVA_GET_VDEV
argument_list|(
name|dva
argument_list|)
decl_stmt|;
name|uint64_t
name|offset
init|=
name|DVA_GET_OFFSET
argument_list|(
name|dva
argument_list|)
decl_stmt|;
name|uint64_t
name|size
init|=
name|DVA_GET_ASIZE
argument_list|(
name|dva
argument_list|)
decl_stmt|;
name|vdev_t
modifier|*
name|vd
decl_stmt|;
name|metaslab_t
modifier|*
name|msp
decl_stmt|;
name|ASSERT
argument_list|(
name|DVA_IS_VALID
argument_list|(
name|dva
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|txg
operator|>
name|spa_freeze_txg
argument_list|(
name|spa
argument_list|)
condition|)
return|return;
if|if
condition|(
operator|(
name|vd
operator|=
name|vdev_lookup_top
argument_list|(
name|spa
argument_list|,
name|vdev
argument_list|)
operator|)
operator|==
name|NULL
operator|||
operator|(
name|offset
operator|>>
name|vd
operator|->
name|vdev_ms_shift
operator|)
operator|>=
name|vd
operator|->
name|vdev_ms_count
condition|)
block|{
name|cmn_err
argument_list|(
name|CE_WARN
argument_list|,
literal|"metaslab_free_dva(): bad DVA %llu:%llu"
argument_list|,
operator|(
name|u_longlong_t
operator|)
name|vdev
argument_list|,
operator|(
name|u_longlong_t
operator|)
name|offset
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
literal|0
argument_list|)
expr_stmt|;
return|return;
block|}
name|msp
operator|=
name|vd
operator|->
name|vdev_ms
index|[
name|offset
operator|>>
name|vd
operator|->
name|vdev_ms_shift
index|]
expr_stmt|;
if|if
condition|(
name|DVA_GET_GANG
argument_list|(
name|dva
argument_list|)
condition|)
name|size
operator|=
name|vdev_psize_to_asize
argument_list|(
name|vd
argument_list|,
name|SPA_GANGBLOCKSIZE
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|now
condition|)
block|{
name|range_tree_remove
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
name|txg
operator|&
name|TXG_MASK
index|]
argument_list|,
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|VERIFY
argument_list|(
operator|!
name|msp
operator|->
name|ms_condensing
argument_list|)
expr_stmt|;
name|VERIFY3U
argument_list|(
name|offset
argument_list|,
operator|>=
argument_list|,
name|msp
operator|->
name|ms_start
argument_list|)
expr_stmt|;
name|VERIFY3U
argument_list|(
name|offset
operator|+
name|size
argument_list|,
operator|<=
argument_list|,
name|msp
operator|->
name|ms_start
operator|+
name|msp
operator|->
name|ms_size
argument_list|)
expr_stmt|;
name|VERIFY3U
argument_list|(
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|)
operator|+
name|size
argument_list|,
operator|<=
argument_list|,
name|msp
operator|->
name|ms_size
argument_list|)
expr_stmt|;
name|VERIFY0
argument_list|(
name|P2PHASE
argument_list|(
name|offset
argument_list|,
literal|1ULL
operator|<<
name|vd
operator|->
name|vdev_ashift
argument_list|)
argument_list|)
expr_stmt|;
name|VERIFY0
argument_list|(
name|P2PHASE
argument_list|(
name|size
argument_list|,
literal|1ULL
operator|<<
name|vd
operator|->
name|vdev_ashift
argument_list|)
argument_list|)
expr_stmt|;
name|range_tree_add
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|,
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|msp
operator|->
name|ms_max_size
operator|=
name|metaslab_block_maxsize
argument_list|(
name|msp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|VERIFY3U
argument_list|(
name|txg
argument_list|,
operator|==
argument_list|,
name|spa
operator|->
name|spa_syncing_txg
argument_list|)
expr_stmt|;
if|if
condition|(
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_freeingtree
argument_list|)
operator|==
literal|0
condition|)
name|vdev_dirty
argument_list|(
name|vd
argument_list|,
name|VDD_METASLAB
argument_list|,
name|msp
argument_list|,
name|txg
argument_list|)
expr_stmt|;
name|range_tree_add
argument_list|(
name|msp
operator|->
name|ms_freeingtree
argument_list|,
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Intent log support: upon opening the pool after a crash, notify the SPA  * of blocks that the intent log has allocated for immediate write, but  * which are still considered free by the SPA because the last transaction  * group didn't commit yet.  */
end_comment

begin_function
specifier|static
name|int
name|metaslab_claim_dva
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
specifier|const
name|dva_t
modifier|*
name|dva
parameter_list|,
name|uint64_t
name|txg
parameter_list|)
block|{
name|uint64_t
name|vdev
init|=
name|DVA_GET_VDEV
argument_list|(
name|dva
argument_list|)
decl_stmt|;
name|uint64_t
name|offset
init|=
name|DVA_GET_OFFSET
argument_list|(
name|dva
argument_list|)
decl_stmt|;
name|uint64_t
name|size
init|=
name|DVA_GET_ASIZE
argument_list|(
name|dva
argument_list|)
decl_stmt|;
name|vdev_t
modifier|*
name|vd
decl_stmt|;
name|metaslab_t
modifier|*
name|msp
decl_stmt|;
name|int
name|error
init|=
literal|0
decl_stmt|;
name|ASSERT
argument_list|(
name|DVA_IS_VALID
argument_list|(
name|dva
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|vd
operator|=
name|vdev_lookup_top
argument_list|(
name|spa
argument_list|,
name|vdev
argument_list|)
operator|)
operator|==
name|NULL
operator|||
operator|(
name|offset
operator|>>
name|vd
operator|->
name|vdev_ms_shift
operator|)
operator|>=
name|vd
operator|->
name|vdev_ms_count
condition|)
return|return
operator|(
name|SET_ERROR
argument_list|(
name|ENXIO
argument_list|)
operator|)
return|;
name|msp
operator|=
name|vd
operator|->
name|vdev_ms
index|[
name|offset
operator|>>
name|vd
operator|->
name|vdev_ms_shift
index|]
expr_stmt|;
if|if
condition|(
name|DVA_GET_GANG
argument_list|(
name|dva
argument_list|)
condition|)
name|size
operator|=
name|vdev_psize_to_asize
argument_list|(
name|vd
argument_list|,
name|SPA_GANGBLOCKSIZE
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|txg
operator|!=
literal|0
operator|&&
name|spa_writeable
argument_list|(
name|spa
argument_list|)
operator|)
operator|||
operator|!
name|msp
operator|->
name|ms_loaded
condition|)
name|error
operator|=
name|metaslab_activate
argument_list|(
name|msp
argument_list|,
name|METASLAB_WEIGHT_SECONDARY
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|==
literal|0
operator|&&
operator|!
name|range_tree_contains
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|,
name|offset
argument_list|,
name|size
argument_list|)
condition|)
name|error
operator|=
name|SET_ERROR
argument_list|(
name|ENOENT
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|||
name|txg
operator|==
literal|0
condition|)
block|{
comment|/* txg == 0 indicates dry run */
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|VERIFY
argument_list|(
operator|!
name|msp
operator|->
name|ms_condensing
argument_list|)
expr_stmt|;
name|VERIFY0
argument_list|(
name|P2PHASE
argument_list|(
name|offset
argument_list|,
literal|1ULL
operator|<<
name|vd
operator|->
name|vdev_ashift
argument_list|)
argument_list|)
expr_stmt|;
name|VERIFY0
argument_list|(
name|P2PHASE
argument_list|(
name|size
argument_list|,
literal|1ULL
operator|<<
name|vd
operator|->
name|vdev_ashift
argument_list|)
argument_list|)
expr_stmt|;
name|VERIFY3U
argument_list|(
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|)
operator|-
name|size
argument_list|,
operator|<=
argument_list|,
name|msp
operator|->
name|ms_size
argument_list|)
expr_stmt|;
name|range_tree_remove
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|,
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|spa_writeable
argument_list|(
name|spa
argument_list|)
condition|)
block|{
comment|/* don't dirty if we're zdb(1M) */
if|if
condition|(
name|range_tree_space
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
name|txg
operator|&
name|TXG_MASK
index|]
argument_list|)
operator|==
literal|0
condition|)
name|vdev_dirty
argument_list|(
name|vd
argument_list|,
name|VDD_METASLAB
argument_list|,
name|msp
argument_list|,
name|txg
argument_list|)
expr_stmt|;
name|range_tree_add
argument_list|(
name|msp
operator|->
name|ms_alloctree
index|[
name|txg
operator|&
name|TXG_MASK
index|]
argument_list|,
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|msp
operator|->
name|ms_lock
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Reserve some allocation slots. The reservation system must be called  * before we call into the allocator. If there aren't any available slots  * then the I/O will be throttled until an I/O completes and its slots are  * freed up. The function returns true if it was successful in placing  * the reservation.  */
end_comment

begin_function
name|boolean_t
name|metaslab_class_throttle_reserve
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|,
name|int
name|slots
parameter_list|,
name|zio_t
modifier|*
name|zio
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|uint64_t
name|available_slots
init|=
literal|0
decl_stmt|;
name|boolean_t
name|slot_reserved
init|=
name|B_FALSE
decl_stmt|;
name|ASSERT
argument_list|(
name|mc
operator|->
name|mc_alloc_throttle_enabled
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|mc
operator|->
name|mc_lock
argument_list|)
expr_stmt|;
name|uint64_t
name|reserved_slots
init|=
name|refcount_count
argument_list|(
operator|&
name|mc
operator|->
name|mc_alloc_slots
argument_list|)
decl_stmt|;
if|if
condition|(
name|reserved_slots
operator|<
name|mc
operator|->
name|mc_alloc_max_slots
condition|)
name|available_slots
operator|=
name|mc
operator|->
name|mc_alloc_max_slots
operator|-
name|reserved_slots
expr_stmt|;
if|if
condition|(
name|slots
operator|<=
name|available_slots
operator|||
name|GANG_ALLOCATION
argument_list|(
name|flags
argument_list|)
condition|)
block|{
comment|/* 		 * We reserve the slots individually so that we can unreserve 		 * them individually when an I/O completes. 		 */
for|for
control|(
name|int
name|d
init|=
literal|0
init|;
name|d
operator|<
name|slots
condition|;
name|d
operator|++
control|)
block|{
name|reserved_slots
operator|=
name|refcount_add
argument_list|(
operator|&
name|mc
operator|->
name|mc_alloc_slots
argument_list|,
name|zio
argument_list|)
expr_stmt|;
block|}
name|zio
operator|->
name|io_flags
operator||=
name|ZIO_FLAG_IO_ALLOCATING
expr_stmt|;
name|slot_reserved
operator|=
name|B_TRUE
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|mc
operator|->
name|mc_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|slot_reserved
operator|)
return|;
block|}
end_function

begin_function
name|void
name|metaslab_class_throttle_unreserve
parameter_list|(
name|metaslab_class_t
modifier|*
name|mc
parameter_list|,
name|int
name|slots
parameter_list|,
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|mc
operator|->
name|mc_alloc_throttle_enabled
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|mc
operator|->
name|mc_lock
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|d
init|=
literal|0
init|;
name|d
operator|<
name|slots
condition|;
name|d
operator|++
control|)
block|{
operator|(
name|void
operator|)
name|refcount_remove
argument_list|(
operator|&
name|mc
operator|->
name|mc_alloc_slots
argument_list|,
name|zio
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|mc
operator|->
name|mc_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|metaslab_alloc
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|metaslab_class_t
modifier|*
name|mc
parameter_list|,
name|uint64_t
name|psize
parameter_list|,
name|blkptr_t
modifier|*
name|bp
parameter_list|,
name|int
name|ndvas
parameter_list|,
name|uint64_t
name|txg
parameter_list|,
name|blkptr_t
modifier|*
name|hintbp
parameter_list|,
name|int
name|flags
parameter_list|,
name|zio_alloc_list_t
modifier|*
name|zal
parameter_list|,
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|dva_t
modifier|*
name|dva
init|=
name|bp
operator|->
name|blk_dva
decl_stmt|;
name|dva_t
modifier|*
name|hintdva
init|=
name|hintbp
operator|->
name|blk_dva
decl_stmt|;
name|int
name|error
init|=
literal|0
decl_stmt|;
name|ASSERT
argument_list|(
name|bp
operator|->
name|blk_birth
operator|==
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|BP_PHYSICAL_BIRTH
argument_list|(
name|bp
argument_list|)
operator|==
literal|0
argument_list|)
expr_stmt|;
name|spa_config_enter
argument_list|(
name|spa
argument_list|,
name|SCL_ALLOC
argument_list|,
name|FTAG
argument_list|,
name|RW_READER
argument_list|)
expr_stmt|;
if|if
condition|(
name|mc
operator|->
name|mc_rotor
operator|==
name|NULL
condition|)
block|{
comment|/* no vdevs in this class */
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_ALLOC
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
return|return
operator|(
name|SET_ERROR
argument_list|(
name|ENOSPC
argument_list|)
operator|)
return|;
block|}
name|ASSERT
argument_list|(
name|ndvas
operator|>
literal|0
operator|&&
name|ndvas
operator|<=
name|spa_max_replication
argument_list|(
name|spa
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|BP_GET_NDVAS
argument_list|(
name|bp
argument_list|)
operator|==
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hintbp
operator|==
name|NULL
operator|||
name|ndvas
operator|<=
name|BP_GET_NDVAS
argument_list|(
name|hintbp
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|zal
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|d
init|=
literal|0
init|;
name|d
operator|<
name|ndvas
condition|;
name|d
operator|++
control|)
block|{
name|error
operator|=
name|metaslab_alloc_dva
argument_list|(
name|spa
argument_list|,
name|mc
argument_list|,
name|psize
argument_list|,
name|dva
argument_list|,
name|d
argument_list|,
name|hintdva
argument_list|,
name|txg
argument_list|,
name|flags
argument_list|,
name|zal
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
for|for
control|(
name|d
operator|--
init|;
name|d
operator|>=
literal|0
condition|;
name|d
operator|--
control|)
block|{
name|metaslab_free_dva
argument_list|(
name|spa
argument_list|,
operator|&
name|dva
index|[
name|d
index|]
argument_list|,
name|txg
argument_list|,
name|B_TRUE
argument_list|)
expr_stmt|;
name|metaslab_group_alloc_decrement
argument_list|(
name|spa
argument_list|,
name|DVA_GET_VDEV
argument_list|(
operator|&
name|dva
index|[
name|d
index|]
argument_list|)
argument_list|,
name|zio
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|dva
index|[
name|d
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|dva_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_ALLOC
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
else|else
block|{
comment|/* 			 * Update the metaslab group's queue depth 			 * based on the newly allocated dva. 			 */
name|metaslab_group_alloc_increment
argument_list|(
name|spa
argument_list|,
name|DVA_GET_VDEV
argument_list|(
operator|&
name|dva
index|[
name|d
index|]
argument_list|)
argument_list|,
name|zio
argument_list|,
name|flags
argument_list|)
expr_stmt|;
block|}
block|}
name|ASSERT
argument_list|(
name|error
operator|==
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|BP_GET_NDVAS
argument_list|(
name|bp
argument_list|)
operator|==
name|ndvas
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_ALLOC
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
name|BP_SET_BIRTH
argument_list|(
name|bp
argument_list|,
name|txg
argument_list|,
name|txg
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|void
name|metaslab_free
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
specifier|const
name|blkptr_t
modifier|*
name|bp
parameter_list|,
name|uint64_t
name|txg
parameter_list|,
name|boolean_t
name|now
parameter_list|)
block|{
specifier|const
name|dva_t
modifier|*
name|dva
init|=
name|bp
operator|->
name|blk_dva
decl_stmt|;
name|int
name|ndvas
init|=
name|BP_GET_NDVAS
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|BP_IS_HOLE
argument_list|(
name|bp
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|now
operator|||
name|bp
operator|->
name|blk_birth
operator|>=
name|spa_syncing_txg
argument_list|(
name|spa
argument_list|)
argument_list|)
expr_stmt|;
name|spa_config_enter
argument_list|(
name|spa
argument_list|,
name|SCL_FREE
argument_list|,
name|FTAG
argument_list|,
name|RW_READER
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|d
init|=
literal|0
init|;
name|d
operator|<
name|ndvas
condition|;
name|d
operator|++
control|)
name|metaslab_free_dva
argument_list|(
name|spa
argument_list|,
operator|&
name|dva
index|[
name|d
index|]
argument_list|,
name|txg
argument_list|,
name|now
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_FREE
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|metaslab_claim
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
specifier|const
name|blkptr_t
modifier|*
name|bp
parameter_list|,
name|uint64_t
name|txg
parameter_list|)
block|{
specifier|const
name|dva_t
modifier|*
name|dva
init|=
name|bp
operator|->
name|blk_dva
decl_stmt|;
name|int
name|ndvas
init|=
name|BP_GET_NDVAS
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|int
name|error
init|=
literal|0
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|BP_IS_HOLE
argument_list|(
name|bp
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|txg
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * First do a dry run to make sure all DVAs are claimable, 		 * so we don't have to unwind from partial failures below. 		 */
if|if
condition|(
operator|(
name|error
operator|=
name|metaslab_claim
argument_list|(
name|spa
argument_list|,
name|bp
argument_list|,
literal|0
argument_list|)
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|error
operator|)
return|;
block|}
name|spa_config_enter
argument_list|(
name|spa
argument_list|,
name|SCL_ALLOC
argument_list|,
name|FTAG
argument_list|,
name|RW_READER
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|d
init|=
literal|0
init|;
name|d
operator|<
name|ndvas
condition|;
name|d
operator|++
control|)
if|if
condition|(
operator|(
name|error
operator|=
name|metaslab_claim_dva
argument_list|(
name|spa
argument_list|,
operator|&
name|dva
index|[
name|d
index|]
argument_list|,
name|txg
argument_list|)
operator|)
operator|!=
literal|0
condition|)
break|break;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_ALLOC
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|error
operator|==
literal|0
operator|||
name|txg
operator|==
literal|0
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
name|void
name|metaslab_check_free
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
specifier|const
name|blkptr_t
modifier|*
name|bp
parameter_list|)
block|{
if|if
condition|(
operator|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_ZIO_FREE
operator|)
operator|==
literal|0
condition|)
return|return;
name|spa_config_enter
argument_list|(
name|spa
argument_list|,
name|SCL_VDEV
argument_list|,
name|FTAG
argument_list|,
name|RW_READER
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|BP_GET_NDVAS
argument_list|(
name|bp
argument_list|)
condition|;
name|i
operator|++
control|)
block|{
name|uint64_t
name|vdev
init|=
name|DVA_GET_VDEV
argument_list|(
operator|&
name|bp
operator|->
name|blk_dva
index|[
name|i
index|]
argument_list|)
decl_stmt|;
name|vdev_t
modifier|*
name|vd
init|=
name|vdev_lookup_top
argument_list|(
name|spa
argument_list|,
name|vdev
argument_list|)
decl_stmt|;
name|uint64_t
name|offset
init|=
name|DVA_GET_OFFSET
argument_list|(
operator|&
name|bp
operator|->
name|blk_dva
index|[
name|i
index|]
argument_list|)
decl_stmt|;
name|uint64_t
name|size
init|=
name|DVA_GET_ASIZE
argument_list|(
operator|&
name|bp
operator|->
name|blk_dva
index|[
name|i
index|]
argument_list|)
decl_stmt|;
name|metaslab_t
modifier|*
name|msp
init|=
name|vd
operator|->
name|vdev_ms
index|[
name|offset
operator|>>
name|vd
operator|->
name|vdev_ms_shift
index|]
decl_stmt|;
if|if
condition|(
name|msp
operator|->
name|ms_loaded
condition|)
name|range_tree_verify
argument_list|(
name|msp
operator|->
name|ms_tree
argument_list|,
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|range_tree_verify
argument_list|(
name|msp
operator|->
name|ms_freeingtree
argument_list|,
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|range_tree_verify
argument_list|(
name|msp
operator|->
name|ms_freedtree
argument_list|,
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|TXG_DEFER_SIZE
condition|;
name|j
operator|++
control|)
name|range_tree_verify
argument_list|(
name|msp
operator|->
name|ms_defertree
index|[
name|j
index|]
argument_list|,
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_VDEV
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
block|}
end_function

end_unit

