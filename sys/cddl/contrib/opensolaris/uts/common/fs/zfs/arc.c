begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * CDDL HEADER START  *  * The contents of this file are subject to the terms of the  * Common Development and Distribution License (the "License").  * You may not use this file except in compliance with the License.  *  * You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE  * or http://www.opensolaris.org/os/licensing.  * See the License for the specific language governing permissions  * and limitations under the License.  *  * When distributing Covered Code, include this CDDL HEADER in each  * file and include the License file at usr/src/OPENSOLARIS.LICENSE.  * If applicable, add the following below this CDDL HEADER, with the  * fields enclosed by brackets "[]" replaced with your own identifying  * information: Portions Copyright [yyyy] [name of copyright owner]  *  * CDDL HEADER END  */
end_comment

begin_comment
comment|/*  * Copyright (c) 2005, 2010, Oracle and/or its affiliates. All rights reserved.  * Copyright (c) 2012, Joyent, Inc. All rights reserved.  * Copyright (c) 2011, 2015 by Delphix. All rights reserved.  * Copyright (c) 2014 by Saso Kiselkov. All rights reserved.  * Copyright 2015 Nexenta Systems, Inc.  All rights reserved.  */
end_comment

begin_comment
comment|/*  * DVA-based Adjustable Replacement Cache  *  * While much of the theory of operation used here is  * based on the self-tuning, low overhead replacement cache  * presented by Megiddo and Modha at FAST 2003, there are some  * significant differences:  *  * 1. The Megiddo and Modha model assumes any page is evictable.  * Pages in its cache cannot be "locked" into memory.  This makes  * the eviction algorithm simple: evict the last page in the list.  * This also make the performance characteristics easy to reason  * about.  Our cache is not so simple.  At any given moment, some  * subset of the blocks in the cache are un-evictable because we  * have handed out a reference to them.  Blocks are only evictable  * when there are no external references active.  This makes  * eviction far more problematic:  we choose to evict the evictable  * blocks that are the "lowest" in the list.  *  * There are times when it is not possible to evict the requested  * space.  In these circumstances we are unable to adjust the cache  * size.  To prevent the cache growing unbounded at these times we  * implement a "cache throttle" that slows the flow of new data  * into the cache until we can make space available.  *  * 2. The Megiddo and Modha model assumes a fixed cache size.  * Pages are evicted when the cache is full and there is a cache  * miss.  Our model has a variable sized cache.  It grows with  * high use, but also tries to react to memory pressure from the  * operating system: decreasing its size when system memory is  * tight.  *  * 3. The Megiddo and Modha model assumes a fixed page size. All  * elements of the cache are therefore exactly the same size.  So  * when adjusting the cache size following a cache miss, its simply  * a matter of choosing a single page to evict.  In our model, we  * have variable sized cache blocks (rangeing from 512 bytes to  * 128K bytes).  We therefore choose a set of blocks to evict to make  * space for a cache miss that approximates as closely as possible  * the space used by the new block.  *  * See also:  "ARC: A Self-Tuning, Low Overhead Replacement Cache"  * by N. Megiddo& D. Modha, FAST 2003  */
end_comment

begin_comment
comment|/*  * The locking model:  *  * A new reference to a cache buffer can be obtained in two  * ways: 1) via a hash table lookup using the DVA as a key,  * or 2) via one of the ARC lists.  The arc_read() interface  * uses method 1, while the internal arc algorithms for  * adjusting the cache use method 2.  We therefore provide two  * types of locks: 1) the hash table lock array, and 2) the  * arc list locks.  *  * Buffers do not have their own mutexes, rather they rely on the  * hash table mutexes for the bulk of their protection (i.e. most  * fields in the arc_buf_hdr_t are protected by these mutexes).  *  * buf_hash_find() returns the appropriate mutex (held) when it  * locates the requested buffer in the hash table.  It returns  * NULL for the mutex if the buffer was not in the table.  *  * buf_hash_remove() expects the appropriate hash mutex to be  * already held before it is invoked.  *  * Each arc state also has a mutex which is used to protect the  * buffer list associated with the state.  When attempting to  * obtain a hash table lock while holding an arc list lock you  * must use: mutex_tryenter() to avoid deadlock.  Also note that  * the active state mutex must be held before the ghost state mutex.  *  * Arc buffers may have an associated eviction callback function.  * This function will be invoked prior to removing the buffer (e.g.  * in arc_do_user_evicts()).  Note however that the data associated  * with the buffer may be evicted prior to the callback.  The callback  * must be made with *no locks held* (to prevent deadlock).  Additionally,  * the users of callbacks must ensure that their private data is  * protected from simultaneous callbacks from arc_clear_callback()  * and arc_do_user_evicts().  *  * Note that the majority of the performance stats are manipulated  * with atomic operations.  *  * The L2ARC uses the l2ad_mtx on each vdev for the following:  *  *	- L2ARC buflist creation  *	- L2ARC buflist eviction  *	- L2ARC write completion, which walks L2ARC buflists  *	- ARC header destruction, as it removes from L2ARC buflists  *	- ARC header release, as it removes from L2ARC buflists  */
end_comment

begin_include
include|#
directive|include
file|<sys/spa.h>
end_include

begin_include
include|#
directive|include
file|<sys/zio.h>
end_include

begin_include
include|#
directive|include
file|<sys/zio_compress.h>
end_include

begin_include
include|#
directive|include
file|<sys/zfs_context.h>
end_include

begin_include
include|#
directive|include
file|<sys/arc.h>
end_include

begin_include
include|#
directive|include
file|<sys/refcount.h>
end_include

begin_include
include|#
directive|include
file|<sys/vdev.h>
end_include

begin_include
include|#
directive|include
file|<sys/vdev_impl.h>
end_include

begin_include
include|#
directive|include
file|<sys/dsl_pool.h>
end_include

begin_include
include|#
directive|include
file|<sys/multilist.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|_KERNEL
end_ifdef

begin_include
include|#
directive|include
file|<sys/dnlc.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|<sys/callb.h>
end_include

begin_include
include|#
directive|include
file|<sys/kstat.h>
end_include

begin_include
include|#
directive|include
file|<sys/trim_map.h>
end_include

begin_include
include|#
directive|include
file|<zfs_fletcher.h>
end_include

begin_include
include|#
directive|include
file|<sys/sdt.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<machine/vmparam.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|illumos
end_ifdef

begin_ifndef
ifndef|#
directive|ifndef
name|_KERNEL
end_ifndef

begin_comment
comment|/* set with ZFS_DEBUG=watch, to enable watchpoints on frozen buffers */
end_comment

begin_decl_stmt
name|boolean_t
name|arc_watch
init|=
name|B_FALSE
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|arc_procfd
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* illumos */
end_comment

begin_decl_stmt
specifier|static
name|kmutex_t
name|arc_reclaim_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kcondvar_t
name|arc_reclaim_thread_cv
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|boolean_t
name|arc_reclaim_thread_exit
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kcondvar_t
name|arc_reclaim_waiters_cv
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kmutex_t
name|arc_user_evicts_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kcondvar_t
name|arc_user_evicts_cv
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|boolean_t
name|arc_user_evicts_thread_exit
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint_t
name|arc_reduce_dnlc_percent
init|=
literal|3
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * The number of headers to evict in arc_evict_state_impl() before  * dropping the sublist lock and evicting from another sublist. A lower  * value means we're more likely to evict the "correct" header (i.e. the  * oldest header in the arc state), but comes with higher overhead  * (i.e. more invocations of arc_evict_state_impl()).  */
end_comment

begin_decl_stmt
name|int
name|zfs_arc_evict_batch_limit
init|=
literal|10
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * The number of sublists used for each of the arc state lists. If this  * is not set to a suitable value by the user, it will be configured to  * the number of CPUs on the system in arc_init().  */
end_comment

begin_decl_stmt
name|int
name|zfs_arc_num_sublists_per_state
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* number of seconds before growing cache again */
end_comment

begin_decl_stmt
specifier|static
name|int
name|arc_grow_retry
init|=
literal|60
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* shift of arc_c for calculating overflow limit in arc_get_data_buf */
end_comment

begin_decl_stmt
name|int
name|zfs_arc_overflow_shift
init|=
literal|8
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* shift of arc_c for calculating both min and max arc_p */
end_comment

begin_decl_stmt
specifier|static
name|int
name|arc_p_min_shift
init|=
literal|4
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* log2(fraction of arc to reclaim) */
end_comment

begin_decl_stmt
specifier|static
name|int
name|arc_shrink_shift
init|=
literal|7
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * log2(fraction of ARC which must be free to allow growing).  * I.e. If there is less than arc_c>> arc_no_grow_shift free memory,  * when reading a new block into the ARC, we will evict an equal-sized block  * from the ARC.  *  * This must be less than arc_shrink_shift, so that when we shrink the ARC,  * we will still not allow it to grow.  */
end_comment

begin_decl_stmt
name|int
name|arc_no_grow_shift
init|=
literal|5
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * minimum lifespan of a prefetch block in clock ticks  * (initialized in arc_init())  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|arc_min_prefetch_lifespan
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * If this percent of memory is free, don't throttle.  */
end_comment

begin_decl_stmt
name|int
name|arc_lotsfree_percent
init|=
literal|10
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|arc_dead
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|boolean_t
name|zfs_prefetch_disable
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * The arc has filled available memory and has now warmed up.  */
end_comment

begin_decl_stmt
specifier|static
name|boolean_t
name|arc_warm
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * These tunables are for performance analysis.  */
end_comment

begin_decl_stmt
name|uint64_t
name|zfs_arc_max
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|zfs_arc_min
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|zfs_arc_meta_limit
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|zfs_arc_meta_min
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|zfs_arc_grow_retry
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|zfs_arc_shrink_shift
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|zfs_arc_p_min_shift
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|zfs_disable_dup_eviction
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|zfs_arc_average_blocksize
init|=
literal|8
operator|*
literal|1024
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* 8KB */
end_comment

begin_decl_stmt
name|u_int
name|zfs_arc_free_target
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|int
name|sysctl_vfs_zfs_arc_free_target
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sysctl_vfs_zfs_arc_meta_limit
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_ifdef
ifdef|#
directive|ifdef
name|_KERNEL
end_ifdef

begin_function
specifier|static
name|void
name|arc_free_target_init
parameter_list|(
name|void
modifier|*
name|unused
name|__unused
parameter_list|)
block|{
name|zfs_arc_free_target
operator|=
name|vm_pageout_wakeup_thresh
expr_stmt|;
block|}
end_function

begin_expr_stmt
name|SYSINIT
argument_list|(
name|arc_free_target_init
argument_list|,
name|SI_SUB_KTHREAD_PAGE
argument_list|,
name|SI_ORDER_ANY
argument_list|,
name|arc_free_target_init
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|TUNABLE_QUAD
argument_list|(
literal|"vfs.zfs.arc_max"
argument_list|,
operator|&
name|zfs_arc_max
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|TUNABLE_QUAD
argument_list|(
literal|"vfs.zfs.arc_min"
argument_list|,
operator|&
name|zfs_arc_min
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|TUNABLE_QUAD
argument_list|(
literal|"vfs.zfs.arc_meta_limit"
argument_list|,
operator|&
name|zfs_arc_meta_limit
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|TUNABLE_QUAD
argument_list|(
literal|"vfs.zfs.arc_meta_min"
argument_list|,
operator|&
name|zfs_arc_meta_min
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|TUNABLE_QUAD
argument_list|(
literal|"vfs.zfs.arc_average_blocksize"
argument_list|,
operator|&
name|zfs_arc_average_blocksize
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"vfs.zfs.arc_shrink_shift"
argument_list|,
operator|&
name|zfs_arc_shrink_shift
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_DECL
argument_list|(
name|_vfs_zfs
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_max
argument_list|,
name|CTLFLAG_RDTUN
argument_list|,
operator|&
name|zfs_arc_max
argument_list|,
literal|0
argument_list|,
literal|"Maximum ARC size"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_min
argument_list|,
name|CTLFLAG_RDTUN
argument_list|,
operator|&
name|zfs_arc_min
argument_list|,
literal|0
argument_list|,
literal|"Minimum ARC size"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_average_blocksize
argument_list|,
name|CTLFLAG_RDTUN
argument_list|,
operator|&
name|zfs_arc_average_blocksize
argument_list|,
literal|0
argument_list|,
literal|"ARC average blocksize"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_shrink_shift
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|arc_shrink_shift
argument_list|,
literal|0
argument_list|,
literal|"log2(fraction of arc to reclaim)"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * We don't have a tunable for arc_free_target due to the dependency on  * pagedaemon initialisation.  */
end_comment

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_free_target
argument_list|,
name|CTLTYPE_UINT
operator||
name|CTLFLAG_MPSAFE
operator||
name|CTLFLAG_RW
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|u_int
argument_list|)
argument_list|,
name|sysctl_vfs_zfs_arc_free_target
argument_list|,
literal|"IU"
argument_list|,
literal|"Desired number of free pages below which ARC triggers reclaim"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|sysctl_vfs_zfs_arc_free_target
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|u_int
name|val
decl_stmt|;
name|int
name|err
decl_stmt|;
name|val
operator|=
name|zfs_arc_free_target
expr_stmt|;
name|err
operator|=
name|sysctl_handle_int
argument_list|(
name|oidp
argument_list|,
operator|&
name|val
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|err
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|err
operator|)
return|;
if|if
condition|(
name|val
operator|<
name|minfree
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
if|if
condition|(
name|val
operator|>
name|cnt
operator|.
name|v_page_count
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|zfs_arc_free_target
operator|=
name|val
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Must be declared here, before the definition of corresponding kstat  * macro which uses the same names will confuse the compiler.  */
end_comment

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_meta_limit
argument_list|,
name|CTLTYPE_U64
operator||
name|CTLFLAG_MPSAFE
operator||
name|CTLFLAG_RW
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
argument_list|,
name|sysctl_vfs_zfs_arc_meta_limit
argument_list|,
literal|"QU"
argument_list|,
literal|"ARC metadata limit"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Note that buffers can be in one of 6 states:  *	ARC_anon	- anonymous (discussed below)  *	ARC_mru		- recently used, currently cached  *	ARC_mru_ghost	- recentely used, no longer in cache  *	ARC_mfu		- frequently used, currently cached  *	ARC_mfu_ghost	- frequently used, no longer in cache  *	ARC_l2c_only	- exists in L2ARC but not other states  * When there are no active references to the buffer, they are  * are linked onto a list in one of these arc states.  These are  * the only buffers that can be evicted or deleted.  Within each  * state there are multiple lists, one for meta-data and one for  * non-meta-data.  Meta-data (indirect blocks, blocks of dnodes,  * etc.) is tracked separately so that it can be managed more  * explicitly: favored over data, limited explicitly.  *  * Anonymous buffers are buffers that are not associated with  * a DVA.  These are buffers that hold dirty block copies  * before they are written to stable storage.  By definition,  * they are "ref'd" and are considered part of arc_mru  * that cannot be freed.  Generally, they will aquire a DVA  * as they are written and migrate onto the arc_mru list.  *  * The ARC_l2c_only state is for buffers that are in the second  * level ARC but no longer in any of the ARC_m* lists.  The second  * level ARC itself may also contain buffers that are in any of  * the ARC_m* states - meaning that a buffer can exist in two  * places.  The reason for the ARC_l2c_only state is to keep the  * buffer header in the hash table, so that reads that hit the  * second level ARC benefit from these fast lookups.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|arc_state
block|{
comment|/* 	 * list of evictable buffers 	 */
name|multilist_t
name|arcs_list
index|[
name|ARC_BUFC_NUMTYPES
index|]
decl_stmt|;
comment|/* 	 * total amount of evictable data in this state 	 */
name|uint64_t
name|arcs_lsize
index|[
name|ARC_BUFC_NUMTYPES
index|]
decl_stmt|;
comment|/* 	 * total amount of data in this state; this includes: evictable, 	 * non-evictable, ARC_BUFC_DATA, and ARC_BUFC_METADATA. 	 */
name|refcount_t
name|arcs_size
decl_stmt|;
block|}
name|arc_state_t
typedef|;
end_typedef

begin_comment
comment|/* The 6 states: */
end_comment

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_anon
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_mru
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_mru_ghost
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_mfu
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_mfu_ghost
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_l2c_only
decl_stmt|;
end_decl_stmt

begin_typedef
typedef|typedef
struct|struct
name|arc_stats
block|{
name|kstat_named_t
name|arcstat_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_demand_data_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_demand_data_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_demand_metadata_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_demand_metadata_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_prefetch_data_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_prefetch_data_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_prefetch_metadata_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_prefetch_metadata_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_mru_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_mru_ghost_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_mfu_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_mfu_ghost_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_allocated
decl_stmt|;
name|kstat_named_t
name|arcstat_deleted
decl_stmt|;
comment|/* 	 * Number of buffers that could not be evicted because the hash lock 	 * was held by another thread.  The lock may not necessarily be held 	 * by something using the same buffer, since hash locks are shared 	 * by multiple buffers. 	 */
name|kstat_named_t
name|arcstat_mutex_miss
decl_stmt|;
comment|/* 	 * Number of buffers skipped because they have I/O in progress, are 	 * indrect prefetch buffers that have not lived long enough, or are 	 * not from the spa we're trying to evict from. 	 */
name|kstat_named_t
name|arcstat_evict_skip
decl_stmt|;
comment|/* 	 * Number of times arc_evict_state() was unable to evict enough 	 * buffers to reach it's target amount. 	 */
name|kstat_named_t
name|arcstat_evict_not_enough
decl_stmt|;
name|kstat_named_t
name|arcstat_evict_l2_cached
decl_stmt|;
name|kstat_named_t
name|arcstat_evict_l2_eligible
decl_stmt|;
name|kstat_named_t
name|arcstat_evict_l2_ineligible
decl_stmt|;
name|kstat_named_t
name|arcstat_evict_l2_skip
decl_stmt|;
name|kstat_named_t
name|arcstat_hash_elements
decl_stmt|;
name|kstat_named_t
name|arcstat_hash_elements_max
decl_stmt|;
name|kstat_named_t
name|arcstat_hash_collisions
decl_stmt|;
name|kstat_named_t
name|arcstat_hash_chains
decl_stmt|;
name|kstat_named_t
name|arcstat_hash_chain_max
decl_stmt|;
name|kstat_named_t
name|arcstat_p
decl_stmt|;
name|kstat_named_t
name|arcstat_c
decl_stmt|;
name|kstat_named_t
name|arcstat_c_min
decl_stmt|;
name|kstat_named_t
name|arcstat_c_max
decl_stmt|;
name|kstat_named_t
name|arcstat_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by internal ARC structures necessary 	 * for tracking purposes; these structures are not actually 	 * backed by ARC buffers. This includes arc_buf_hdr_t structures 	 * (allocated via arc_buf_hdr_t_full and arc_buf_hdr_t_l2only 	 * caches), and arc_buf_t structures (allocated via arc_buf_t 	 * cache). 	 */
name|kstat_named_t
name|arcstat_hdr_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers of type equal to 	 * ARC_BUFC_DATA. This is generally consumed by buffers backing 	 * on disk user data (e.g. plain file contents). 	 */
name|kstat_named_t
name|arcstat_data_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers of type equal to 	 * ARC_BUFC_METADATA. This is generally consumed by buffers 	 * backing on disk data that is used for internal ZFS 	 * structures (e.g. ZAP, dnode, indirect blocks, etc). 	 */
name|kstat_named_t
name|arcstat_metadata_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by various buffers and structures 	 * not actually backed with ARC buffers. This includes bonus 	 * buffers (allocated directly via zio_buf_* functions), 	 * dmu_buf_impl_t structures (allocated via dmu_buf_impl_t 	 * cache), and dnode_t structures (allocated via dnode_t cache). 	 */
name|kstat_named_t
name|arcstat_other_size
decl_stmt|;
comment|/* 	 * Total number of bytes consumed by ARC buffers residing in the 	 * arc_anon state. This includes *all* buffers in the arc_anon 	 * state; e.g. data, metadata, evictable, and unevictable buffers 	 * are all included in this value. 	 */
name|kstat_named_t
name|arcstat_anon_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that meet the 	 * following criteria: backing buffers of type ARC_BUFC_DATA, 	 * residing in the arc_anon state, and are eligible for eviction 	 * (e.g. have no outstanding holds on the buffer). 	 */
name|kstat_named_t
name|arcstat_anon_evictable_data
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that meet the 	 * following criteria: backing buffers of type ARC_BUFC_METADATA, 	 * residing in the arc_anon state, and are eligible for eviction 	 * (e.g. have no outstanding holds on the buffer). 	 */
name|kstat_named_t
name|arcstat_anon_evictable_metadata
decl_stmt|;
comment|/* 	 * Total number of bytes consumed by ARC buffers residing in the 	 * arc_mru state. This includes *all* buffers in the arc_mru 	 * state; e.g. data, metadata, evictable, and unevictable buffers 	 * are all included in this value. 	 */
name|kstat_named_t
name|arcstat_mru_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that meet the 	 * following criteria: backing buffers of type ARC_BUFC_DATA, 	 * residing in the arc_mru state, and are eligible for eviction 	 * (e.g. have no outstanding holds on the buffer). 	 */
name|kstat_named_t
name|arcstat_mru_evictable_data
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that meet the 	 * following criteria: backing buffers of type ARC_BUFC_METADATA, 	 * residing in the arc_mru state, and are eligible for eviction 	 * (e.g. have no outstanding holds on the buffer). 	 */
name|kstat_named_t
name|arcstat_mru_evictable_metadata
decl_stmt|;
comment|/* 	 * Total number of bytes that *would have been* consumed by ARC 	 * buffers in the arc_mru_ghost state. The key thing to note 	 * here, is the fact that this size doesn't actually indicate 	 * RAM consumption. The ghost lists only consist of headers and 	 * don't actually have ARC buffers linked off of these headers. 	 * Thus, *if* the headers had associated ARC buffers, these 	 * buffers *would have* consumed this number of bytes. 	 */
name|kstat_named_t
name|arcstat_mru_ghost_size
decl_stmt|;
comment|/* 	 * Number of bytes that *would have been* consumed by ARC 	 * buffers that are eligible for eviction, of type 	 * ARC_BUFC_DATA, and linked off the arc_mru_ghost state. 	 */
name|kstat_named_t
name|arcstat_mru_ghost_evictable_data
decl_stmt|;
comment|/* 	 * Number of bytes that *would have been* consumed by ARC 	 * buffers that are eligible for eviction, of type 	 * ARC_BUFC_METADATA, and linked off the arc_mru_ghost state. 	 */
name|kstat_named_t
name|arcstat_mru_ghost_evictable_metadata
decl_stmt|;
comment|/* 	 * Total number of bytes consumed by ARC buffers residing in the 	 * arc_mfu state. This includes *all* buffers in the arc_mfu 	 * state; e.g. data, metadata, evictable, and unevictable buffers 	 * are all included in this value. 	 */
name|kstat_named_t
name|arcstat_mfu_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that are eligible for 	 * eviction, of type ARC_BUFC_DATA, and reside in the arc_mfu 	 * state. 	 */
name|kstat_named_t
name|arcstat_mfu_evictable_data
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that are eligible for 	 * eviction, of type ARC_BUFC_METADATA, and reside in the 	 * arc_mfu state. 	 */
name|kstat_named_t
name|arcstat_mfu_evictable_metadata
decl_stmt|;
comment|/* 	 * Total number of bytes that *would have been* consumed by ARC 	 * buffers in the arc_mfu_ghost state. See the comment above 	 * arcstat_mru_ghost_size for more details. 	 */
name|kstat_named_t
name|arcstat_mfu_ghost_size
decl_stmt|;
comment|/* 	 * Number of bytes that *would have been* consumed by ARC 	 * buffers that are eligible for eviction, of type 	 * ARC_BUFC_DATA, and linked off the arc_mfu_ghost state. 	 */
name|kstat_named_t
name|arcstat_mfu_ghost_evictable_data
decl_stmt|;
comment|/* 	 * Number of bytes that *would have been* consumed by ARC 	 * buffers that are eligible for eviction, of type 	 * ARC_BUFC_METADATA, and linked off the arc_mru_ghost state. 	 */
name|kstat_named_t
name|arcstat_mfu_ghost_evictable_metadata
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_feeds
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_rw_clash
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_read_bytes
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_bytes
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_writes_sent
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_writes_done
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_writes_error
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_writes_lock_retry
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_evict_lock_retry
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_evict_reading
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_evict_l1cached
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_free_on_write
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_cdata_free_on_write
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_abort_lowmem
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_cksum_bad
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_io_error
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_size
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_asize
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_hdr_size
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_compress_successes
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_compress_zeros
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_compress_failures
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_trylock_fail
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_passed_headroom
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_spa_mismatch
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_in_l2
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_hdr_io_in_progress
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_not_cacheable
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_full
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_buffer_iter
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_pios
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_buffer_bytes_scanned
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_buffer_list_iter
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_buffer_list_null_iter
decl_stmt|;
name|kstat_named_t
name|arcstat_memory_throttle_count
decl_stmt|;
name|kstat_named_t
name|arcstat_duplicate_buffers
decl_stmt|;
name|kstat_named_t
name|arcstat_duplicate_buffers_size
decl_stmt|;
name|kstat_named_t
name|arcstat_duplicate_reads
decl_stmt|;
name|kstat_named_t
name|arcstat_meta_used
decl_stmt|;
name|kstat_named_t
name|arcstat_meta_limit
decl_stmt|;
name|kstat_named_t
name|arcstat_meta_max
decl_stmt|;
name|kstat_named_t
name|arcstat_meta_min
decl_stmt|;
name|kstat_named_t
name|arcstat_sync_wait_for_async
decl_stmt|;
name|kstat_named_t
name|arcstat_demand_hit_predictive_prefetch
decl_stmt|;
block|}
name|arc_stats_t
typedef|;
end_typedef

begin_decl_stmt
specifier|static
name|arc_stats_t
name|arc_stats
init|=
block|{
block|{
literal|"hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"demand_data_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"demand_data_misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"demand_metadata_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"demand_metadata_misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"prefetch_data_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"prefetch_data_misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"prefetch_metadata_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"prefetch_metadata_misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_ghost_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_ghost_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"allocated"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"deleted"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mutex_miss"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_skip"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_not_enough"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_l2_cached"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_l2_eligible"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_l2_ineligible"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_l2_skip"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hash_elements"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hash_elements_max"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hash_collisions"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hash_chains"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hash_chain_max"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"p"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"c"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"c_min"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"c_max"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hdr_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"data_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"metadata_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"other_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"anon_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"anon_evictable_data"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"anon_evictable_metadata"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_evictable_data"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_evictable_metadata"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_ghost_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_ghost_evictable_data"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_ghost_evictable_metadata"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_evictable_data"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_evictable_metadata"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_ghost_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_ghost_evictable_data"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_ghost_evictable_metadata"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_feeds"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_rw_clash"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_read_bytes"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_bytes"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_writes_sent"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_writes_done"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_writes_error"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_writes_lock_retry"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_evict_lock_retry"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_evict_reading"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_evict_l1cached"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_free_on_write"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_cdata_free_on_write"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_abort_lowmem"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_cksum_bad"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_io_error"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_asize"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_hdr_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_compress_successes"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_compress_zeros"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_compress_failures"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_trylock_fail"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_passed_headroom"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_spa_mismatch"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_in_l2"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_io_in_progress"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_not_cacheable"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_full"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_buffer_iter"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_pios"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_buffer_bytes_scanned"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_buffer_list_iter"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_buffer_list_null_iter"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"memory_throttle_count"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"duplicate_buffers"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"duplicate_buffers_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"duplicate_reads"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"arc_meta_used"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"arc_meta_limit"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"arc_meta_max"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"arc_meta_min"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"sync_wait_for_async"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"demand_hit_predictive_prefetch"
block|,
name|KSTAT_DATA_UINT64
block|}
block|, }
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|ARCSTAT
parameter_list|(
name|stat
parameter_list|)
value|(arc_stats.stat.value.ui64)
end_define

begin_define
define|#
directive|define
name|ARCSTAT_INCR
parameter_list|(
name|stat
parameter_list|,
name|val
parameter_list|)
define|\
value|atomic_add_64(&arc_stats.stat.value.ui64, (val))
end_define

begin_define
define|#
directive|define
name|ARCSTAT_BUMP
parameter_list|(
name|stat
parameter_list|)
value|ARCSTAT_INCR(stat, 1)
end_define

begin_define
define|#
directive|define
name|ARCSTAT_BUMPDOWN
parameter_list|(
name|stat
parameter_list|)
value|ARCSTAT_INCR(stat, -1)
end_define

begin_define
define|#
directive|define
name|ARCSTAT_MAX
parameter_list|(
name|stat
parameter_list|,
name|val
parameter_list|)
value|{					\ 	uint64_t m;							\ 	while ((val)> (m = arc_stats.stat.value.ui64)&&		\ 	    (m != atomic_cas_64(&arc_stats.stat.value.ui64, m, (val))))	\ 		continue;						\ }
end_define

begin_define
define|#
directive|define
name|ARCSTAT_MAXSTAT
parameter_list|(
name|stat
parameter_list|)
define|\
value|ARCSTAT_MAX(stat##_max, arc_stats.stat.value.ui64)
end_define

begin_comment
comment|/*  * We define a macro to allow ARC hits/misses to be easily broken down by  * two separate conditions, giving a total of four different subtypes for  * each of hits and misses (so eight statistics total).  */
end_comment

begin_define
define|#
directive|define
name|ARCSTAT_CONDSTAT
parameter_list|(
name|cond1
parameter_list|,
name|stat1
parameter_list|,
name|notstat1
parameter_list|,
name|cond2
parameter_list|,
name|stat2
parameter_list|,
name|notstat2
parameter_list|,
name|stat
parameter_list|)
define|\
value|if (cond1) {							\ 		if (cond2) {						\ 			ARCSTAT_BUMP(arcstat_##stat1##_##stat2##_##stat); \ 		} else {						\ 			ARCSTAT_BUMP(arcstat_##stat1##_##notstat2##_##stat); \ 		}							\ 	} else {							\ 		if (cond2) {						\ 			ARCSTAT_BUMP(arcstat_##notstat1##_##stat2##_##stat); \ 		} else {						\ 			ARCSTAT_BUMP(arcstat_##notstat1##_##notstat2##_##stat);\ 		}							\ 	}
end_define

begin_decl_stmt
name|kstat_t
modifier|*
name|arc_ksp
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_anon
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_mru
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_mru_ghost
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_mfu
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_mfu_ghost
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_l2c_only
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * There are several ARC variables that are critical to export as kstats --  * but we don't want to have to grovel around in the kstat whenever we wish to  * manipulate them.  For these variables, we therefore define them to be in  * terms of the statistic variable.  This assures that we are not introducing  * the possibility of inconsistency by having shadow copies of the variables,  * while still allowing the code to be readable.  */
end_comment

begin_define
define|#
directive|define
name|arc_size
value|ARCSTAT(arcstat_size)
end_define

begin_comment
comment|/* actual total arc size */
end_comment

begin_define
define|#
directive|define
name|arc_p
value|ARCSTAT(arcstat_p)
end_define

begin_comment
comment|/* target size of MRU */
end_comment

begin_define
define|#
directive|define
name|arc_c
value|ARCSTAT(arcstat_c)
end_define

begin_comment
comment|/* target size of cache */
end_comment

begin_define
define|#
directive|define
name|arc_c_min
value|ARCSTAT(arcstat_c_min)
end_define

begin_comment
comment|/* min target cache size */
end_comment

begin_define
define|#
directive|define
name|arc_c_max
value|ARCSTAT(arcstat_c_max)
end_define

begin_comment
comment|/* max target cache size */
end_comment

begin_define
define|#
directive|define
name|arc_meta_limit
value|ARCSTAT(arcstat_meta_limit)
end_define

begin_comment
comment|/* max size for metadata */
end_comment

begin_define
define|#
directive|define
name|arc_meta_min
value|ARCSTAT(arcstat_meta_min)
end_define

begin_comment
comment|/* min size for metadata */
end_comment

begin_define
define|#
directive|define
name|arc_meta_used
value|ARCSTAT(arcstat_meta_used)
end_define

begin_comment
comment|/* size of metadata */
end_comment

begin_define
define|#
directive|define
name|arc_meta_max
value|ARCSTAT(arcstat_meta_max)
end_define

begin_comment
comment|/* max size of metadata */
end_comment

begin_define
define|#
directive|define
name|L2ARC_IS_VALID_COMPRESS
parameter_list|(
name|_c_
parameter_list|)
define|\
value|((_c_) == ZIO_COMPRESS_LZ4 || (_c_) == ZIO_COMPRESS_EMPTY)
end_define

begin_decl_stmt
specifier|static
name|int
name|arc_no_grow
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Don't try to grow cache size */
end_comment

begin_decl_stmt
specifier|static
name|uint64_t
name|arc_tempreserve
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|uint64_t
name|arc_loaned_bytes
decl_stmt|;
end_decl_stmt

begin_typedef
typedef|typedef
name|struct
name|arc_callback
name|arc_callback_t
typedef|;
end_typedef

begin_struct
struct|struct
name|arc_callback
block|{
name|void
modifier|*
name|acb_private
decl_stmt|;
name|arc_done_func_t
modifier|*
name|acb_done
decl_stmt|;
name|arc_buf_t
modifier|*
name|acb_buf
decl_stmt|;
name|zio_t
modifier|*
name|acb_zio_dummy
decl_stmt|;
name|arc_callback_t
modifier|*
name|acb_next
decl_stmt|;
block|}
struct|;
end_struct

begin_typedef
typedef|typedef
name|struct
name|arc_write_callback
name|arc_write_callback_t
typedef|;
end_typedef

begin_struct
struct|struct
name|arc_write_callback
block|{
name|void
modifier|*
name|awcb_private
decl_stmt|;
name|arc_done_func_t
modifier|*
name|awcb_ready
decl_stmt|;
name|arc_done_func_t
modifier|*
name|awcb_physdone
decl_stmt|;
name|arc_done_func_t
modifier|*
name|awcb_done
decl_stmt|;
name|arc_buf_t
modifier|*
name|awcb_buf
decl_stmt|;
block|}
struct|;
end_struct

begin_comment
comment|/*  * ARC buffers are separated into multiple structs as a memory saving measure:  *   - Common fields struct, always defined, and embedded within it:  *       - L2-only fields, always allocated but undefined when not in L2ARC  *       - L1-only fields, only allocated when in L1ARC  *  *           Buffer in L1                     Buffer only in L2  *    +------------------------+          +------------------------+  *    | arc_buf_hdr_t          |          | arc_buf_hdr_t          |  *    |                        |          |                        |  *    |                        |          |                        |  *    |                        |          |                        |  *    +------------------------+          +------------------------+  *    | l2arc_buf_hdr_t        |          | l2arc_buf_hdr_t        |  *    | (undefined if L1-only) |          |                        |  *    +------------------------+          +------------------------+  *    | l1arc_buf_hdr_t        |  *    |                        |  *    |                        |  *    |                        |  *    |                        |  *    +------------------------+  *  * Because it's possible for the L2ARC to become extremely large, we can wind  * up eating a lot of memory in L2ARC buffer headers, so the size of a header  * is minimized by only allocating the fields necessary for an L1-cached buffer  * when a header is actually in the L1 cache. The sub-headers (l1arc_buf_hdr and  * l2arc_buf_hdr) are embedded rather than allocated separately to save a couple  * words in pointers. arc_hdr_realloc() is used to switch a header between  * these two allocation states.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|l1arc_buf_hdr
block|{
name|kmutex_t
name|b_freeze_lock
decl_stmt|;
ifdef|#
directive|ifdef
name|ZFS_DEBUG
comment|/* 	 * used for debugging wtih kmem_flags - by allocating and freeing 	 * b_thawed when the buffer is thawed, we get a record of the stack 	 * trace that thawed it. 	 */
name|void
modifier|*
name|b_thawed
decl_stmt|;
endif|#
directive|endif
name|arc_buf_t
modifier|*
name|b_buf
decl_stmt|;
name|uint32_t
name|b_datacnt
decl_stmt|;
comment|/* for waiting on writes to complete */
name|kcondvar_t
name|b_cv
decl_stmt|;
comment|/* protected by arc state mutex */
name|arc_state_t
modifier|*
name|b_state
decl_stmt|;
name|multilist_node_t
name|b_arc_node
decl_stmt|;
comment|/* updated atomically */
name|clock_t
name|b_arc_access
decl_stmt|;
comment|/* self protecting */
name|refcount_t
name|b_refcnt
decl_stmt|;
name|arc_callback_t
modifier|*
name|b_acb
decl_stmt|;
comment|/* temporary buffer holder for in-flight compressed data */
name|void
modifier|*
name|b_tmp_cdata
decl_stmt|;
block|}
name|l1arc_buf_hdr_t
typedef|;
end_typedef

begin_typedef
typedef|typedef
name|struct
name|l2arc_dev
name|l2arc_dev_t
typedef|;
end_typedef

begin_typedef
typedef|typedef
struct|struct
name|l2arc_buf_hdr
block|{
comment|/* protected by arc_buf_hdr mutex */
name|l2arc_dev_t
modifier|*
name|b_dev
decl_stmt|;
comment|/* L2ARC device */
name|uint64_t
name|b_daddr
decl_stmt|;
comment|/* disk address, offset byte */
comment|/* real alloc'd buffer size depending on b_compress applied */
name|int32_t
name|b_asize
decl_stmt|;
name|uint8_t
name|b_compress
decl_stmt|;
name|list_node_t
name|b_l2node
decl_stmt|;
block|}
name|l2arc_buf_hdr_t
typedef|;
end_typedef

begin_struct
struct|struct
name|arc_buf_hdr
block|{
comment|/* protected by hash lock */
name|dva_t
name|b_dva
decl_stmt|;
name|uint64_t
name|b_birth
decl_stmt|;
comment|/* 	 * Even though this checksum is only set/verified when a buffer is in 	 * the L1 cache, it needs to be in the set of common fields because it 	 * must be preserved from the time before a buffer is written out to 	 * L2ARC until after it is read back in. 	 */
name|zio_cksum_t
modifier|*
name|b_freeze_cksum
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|b_hash_next
decl_stmt|;
name|arc_flags_t
name|b_flags
decl_stmt|;
comment|/* immutable */
name|int32_t
name|b_size
decl_stmt|;
name|uint64_t
name|b_spa
decl_stmt|;
comment|/* L2ARC fields. Undefined when not in L2ARC. */
name|l2arc_buf_hdr_t
name|b_l2hdr
decl_stmt|;
comment|/* L1ARC fields. Undefined when in l2arc_only state */
name|l1arc_buf_hdr_t
name|b_l1hdr
decl_stmt|;
block|}
struct|;
end_struct

begin_ifdef
ifdef|#
directive|ifdef
name|_KERNEL
end_ifdef

begin_function
specifier|static
name|int
name|sysctl_vfs_zfs_arc_meta_limit
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|uint64_t
name|val
decl_stmt|;
name|int
name|err
decl_stmt|;
name|val
operator|=
name|arc_meta_limit
expr_stmt|;
name|err
operator|=
name|sysctl_handle_64
argument_list|(
name|oidp
argument_list|,
operator|&
name|val
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|err
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|err
operator|)
return|;
if|if
condition|(
name|val
operator|<=
literal|0
operator|||
name|val
operator|>
name|arc_c_max
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|arc_meta_limit
operator|=
name|val
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|arc_buf_t
modifier|*
name|arc_eviction_list
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_buf_hdr_t
name|arc_eviction_hdr
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|GHOST_STATE
parameter_list|(
name|state
parameter_list|)
define|\
value|((state) == arc_mru_ghost || (state) == arc_mfu_ghost ||	\ 	(state) == arc_l2c_only)
end_define

begin_define
define|#
directive|define
name|HDR_IN_HASH_TABLE
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_IN_HASH_TABLE)
end_define

begin_define
define|#
directive|define
name|HDR_IO_IN_PROGRESS
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_IO_IN_PROGRESS)
end_define

begin_define
define|#
directive|define
name|HDR_IO_ERROR
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_IO_ERROR)
end_define

begin_define
define|#
directive|define
name|HDR_PREFETCH
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_PREFETCH)
end_define

begin_define
define|#
directive|define
name|HDR_FREED_IN_READ
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_FREED_IN_READ)
end_define

begin_define
define|#
directive|define
name|HDR_BUF_AVAILABLE
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_BUF_AVAILABLE)
end_define

begin_define
define|#
directive|define
name|HDR_L2CACHE
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_L2CACHE)
end_define

begin_define
define|#
directive|define
name|HDR_L2COMPRESS
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_L2COMPRESS)
end_define

begin_define
define|#
directive|define
name|HDR_L2_READING
parameter_list|(
name|hdr
parameter_list|)
define|\
value|(((hdr)->b_flags& ARC_FLAG_IO_IN_PROGRESS)&&	\ 	    ((hdr)->b_flags& ARC_FLAG_HAS_L2HDR))
end_define

begin_define
define|#
directive|define
name|HDR_L2_WRITING
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_L2_WRITING)
end_define

begin_define
define|#
directive|define
name|HDR_L2_EVICTED
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_L2_EVICTED)
end_define

begin_define
define|#
directive|define
name|HDR_L2_WRITE_HEAD
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_L2_WRITE_HEAD)
end_define

begin_define
define|#
directive|define
name|HDR_ISTYPE_METADATA
parameter_list|(
name|hdr
parameter_list|)
define|\
value|((hdr)->b_flags& ARC_FLAG_BUFC_METADATA)
end_define

begin_define
define|#
directive|define
name|HDR_ISTYPE_DATA
parameter_list|(
name|hdr
parameter_list|)
value|(!HDR_ISTYPE_METADATA(hdr))
end_define

begin_define
define|#
directive|define
name|HDR_HAS_L1HDR
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_HAS_L1HDR)
end_define

begin_define
define|#
directive|define
name|HDR_HAS_L2HDR
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_HAS_L2HDR)
end_define

begin_comment
comment|/*  * Other sizes  */
end_comment

begin_define
define|#
directive|define
name|HDR_FULL_SIZE
value|((int64_t)sizeof (arc_buf_hdr_t))
end_define

begin_define
define|#
directive|define
name|HDR_L2ONLY_SIZE
value|((int64_t)offsetof(arc_buf_hdr_t, b_l1hdr))
end_define

begin_comment
comment|/*  * Hash table routines  */
end_comment

begin_define
define|#
directive|define
name|HT_LOCK_PAD
value|CACHE_LINE_SIZE
end_define

begin_struct
struct|struct
name|ht_lock
block|{
name|kmutex_t
name|ht_lock
decl_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
name|unsigned
name|char
name|pad
index|[
operator|(
name|HT_LOCK_PAD
operator|-
sizeof|sizeof
argument_list|(
name|kmutex_t
argument_list|)
operator|)
index|]
decl_stmt|;
endif|#
directive|endif
block|}
struct|;
end_struct

begin_define
define|#
directive|define
name|BUF_LOCKS
value|256
end_define

begin_typedef
typedef|typedef
struct|struct
name|buf_hash_table
block|{
name|uint64_t
name|ht_mask
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
modifier|*
name|ht_table
decl_stmt|;
name|struct
name|ht_lock
name|ht_locks
index|[
name|BUF_LOCKS
index|]
name|__aligned
parameter_list|(
name|CACHE_LINE_SIZE
parameter_list|)
function_decl|;
block|}
name|buf_hash_table_t
typedef|;
end_typedef

begin_decl_stmt
specifier|static
name|buf_hash_table_t
name|buf_hash_table
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|BUF_HASH_INDEX
parameter_list|(
name|spa
parameter_list|,
name|dva
parameter_list|,
name|birth
parameter_list|)
define|\
value|(buf_hash(spa, dva, birth)& buf_hash_table.ht_mask)
end_define

begin_define
define|#
directive|define
name|BUF_HASH_LOCK_NTRY
parameter_list|(
name|idx
parameter_list|)
value|(buf_hash_table.ht_locks[idx& (BUF_LOCKS-1)])
end_define

begin_define
define|#
directive|define
name|BUF_HASH_LOCK
parameter_list|(
name|idx
parameter_list|)
value|(&(BUF_HASH_LOCK_NTRY(idx).ht_lock))
end_define

begin_define
define|#
directive|define
name|HDR_LOCK
parameter_list|(
name|hdr
parameter_list|)
define|\
value|(BUF_HASH_LOCK(BUF_HASH_INDEX(hdr->b_spa,&hdr->b_dva, hdr->b_birth)))
end_define

begin_decl_stmt
name|uint64_t
name|zfs_crc64_table
index|[
literal|256
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Level 2 ARC  */
end_comment

begin_define
define|#
directive|define
name|L2ARC_WRITE_SIZE
value|(8 * 1024 * 1024)
end_define

begin_comment
comment|/* initial write max */
end_comment

begin_define
define|#
directive|define
name|L2ARC_HEADROOM
value|2
end_define

begin_comment
comment|/* num of writes */
end_comment

begin_comment
comment|/*  * If we discover during ARC scan any buffers to be compressed, we boost  * our headroom for the next scanning cycle by this percentage multiple.  */
end_comment

begin_define
define|#
directive|define
name|L2ARC_HEADROOM_BOOST
value|200
end_define

begin_define
define|#
directive|define
name|L2ARC_FEED_SECS
value|1
end_define

begin_comment
comment|/* caching interval secs */
end_comment

begin_define
define|#
directive|define
name|L2ARC_FEED_MIN_MS
value|200
end_define

begin_comment
comment|/* min caching interval ms */
end_comment

begin_comment
comment|/*  * Used to distinguish headers that are being process by  * l2arc_write_buffers(), but have yet to be assigned to a l2arc disk  * address. This can happen when the header is added to the l2arc's list  * of buffers to write in the first stage of l2arc_write_buffers(), but  * has not yet been written out which happens in the second stage of  * l2arc_write_buffers().  */
end_comment

begin_define
define|#
directive|define
name|L2ARC_ADDR_UNSET
value|((uint64_t)(-1))
end_define

begin_define
define|#
directive|define
name|l2arc_writes_sent
value|ARCSTAT(arcstat_l2_writes_sent)
end_define

begin_define
define|#
directive|define
name|l2arc_writes_done
value|ARCSTAT(arcstat_l2_writes_done)
end_define

begin_comment
comment|/* L2ARC Performance Tunables */
end_comment

begin_decl_stmt
name|uint64_t
name|l2arc_write_max
init|=
name|L2ARC_WRITE_SIZE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* default max write size */
end_comment

begin_decl_stmt
name|uint64_t
name|l2arc_write_boost
init|=
name|L2ARC_WRITE_SIZE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* extra write during warmup */
end_comment

begin_decl_stmt
name|uint64_t
name|l2arc_headroom
init|=
name|L2ARC_HEADROOM
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* number of dev writes */
end_comment

begin_decl_stmt
name|uint64_t
name|l2arc_headroom_boost
init|=
name|L2ARC_HEADROOM_BOOST
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|l2arc_feed_secs
init|=
name|L2ARC_FEED_SECS
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* interval seconds */
end_comment

begin_decl_stmt
name|uint64_t
name|l2arc_feed_min_ms
init|=
name|L2ARC_FEED_MIN_MS
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* min interval milliseconds */
end_comment

begin_decl_stmt
name|boolean_t
name|l2arc_noprefetch
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* don't cache prefetch bufs */
end_comment

begin_decl_stmt
name|boolean_t
name|l2arc_feed_again
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* turbo warmup */
end_comment

begin_decl_stmt
name|boolean_t
name|l2arc_norw
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* no reads during writes */
end_comment

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_write_max
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_write_max
argument_list|,
literal|0
argument_list|,
literal|"max write size"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_write_boost
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_write_boost
argument_list|,
literal|0
argument_list|,
literal|"extra write during warmup"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_headroom
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_headroom
argument_list|,
literal|0
argument_list|,
literal|"number of dev writes"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_feed_secs
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_feed_secs
argument_list|,
literal|0
argument_list|,
literal|"interval seconds"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_feed_min_ms
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_feed_min_ms
argument_list|,
literal|0
argument_list|,
literal|"min interval milliseconds"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_noprefetch
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_noprefetch
argument_list|,
literal|0
argument_list|,
literal|"don't cache prefetch bufs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_feed_again
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_feed_again
argument_list|,
literal|0
argument_list|,
literal|"turbo warmup"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_norw
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_norw
argument_list|,
literal|0
argument_list|,
literal|"no reads during writes"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|anon_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_anon
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of anonymous state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|anon_metadata_lsize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_anon
operator|.
name|arcs_lsize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|,
literal|0
argument_list|,
literal|"size of anonymous state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|anon_data_lsize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_anon
operator|.
name|arcs_lsize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|,
literal|0
argument_list|,
literal|"size of anonymous state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of mru state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_metadata_lsize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru
operator|.
name|arcs_lsize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|,
literal|0
argument_list|,
literal|"size of metadata in mru state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_data_lsize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru
operator|.
name|arcs_lsize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|,
literal|0
argument_list|,
literal|"size of data in mru state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_ghost_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru_ghost
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of mru ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_ghost_metadata_lsize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru_ghost
operator|.
name|arcs_lsize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|,
literal|0
argument_list|,
literal|"size of metadata in mru ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_ghost_data_lsize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru_ghost
operator|.
name|arcs_lsize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|,
literal|0
argument_list|,
literal|"size of data in mru ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of mfu state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_metadata_lsize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu
operator|.
name|arcs_lsize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|,
literal|0
argument_list|,
literal|"size of metadata in mfu state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_data_lsize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu
operator|.
name|arcs_lsize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|,
literal|0
argument_list|,
literal|"size of data in mfu state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_ghost_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu_ghost
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of mfu ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_ghost_metadata_lsize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu_ghost
operator|.
name|arcs_lsize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|,
literal|0
argument_list|,
literal|"size of metadata in mfu ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_ghost_data_lsize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu_ghost
operator|.
name|arcs_lsize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|,
literal|0
argument_list|,
literal|"size of data in mfu ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2c_only_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_l2c_only
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of mru state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * L2ARC Internals  */
end_comment

begin_struct
struct|struct
name|l2arc_dev
block|{
name|vdev_t
modifier|*
name|l2ad_vdev
decl_stmt|;
comment|/* vdev */
name|spa_t
modifier|*
name|l2ad_spa
decl_stmt|;
comment|/* spa */
name|uint64_t
name|l2ad_hand
decl_stmt|;
comment|/* next write location */
name|uint64_t
name|l2ad_start
decl_stmt|;
comment|/* first addr on device */
name|uint64_t
name|l2ad_end
decl_stmt|;
comment|/* last addr on device */
name|boolean_t
name|l2ad_first
decl_stmt|;
comment|/* first sweep through */
name|boolean_t
name|l2ad_writing
decl_stmt|;
comment|/* currently writing */
name|kmutex_t
name|l2ad_mtx
decl_stmt|;
comment|/* lock for buffer list */
name|list_t
name|l2ad_buflist
decl_stmt|;
comment|/* buffer list */
name|list_node_t
name|l2ad_node
decl_stmt|;
comment|/* device list node */
name|refcount_t
name|l2ad_alloc
decl_stmt|;
comment|/* allocated bytes */
block|}
struct|;
end_struct

begin_decl_stmt
specifier|static
name|list_t
name|L2ARC_dev_list
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* device list */
end_comment

begin_decl_stmt
specifier|static
name|list_t
modifier|*
name|l2arc_dev_list
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* device list pointer */
end_comment

begin_decl_stmt
specifier|static
name|kmutex_t
name|l2arc_dev_mtx
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* device list mutex */
end_comment

begin_decl_stmt
specifier|static
name|l2arc_dev_t
modifier|*
name|l2arc_dev_last
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* last device used */
end_comment

begin_decl_stmt
specifier|static
name|list_t
name|L2ARC_free_on_write
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* free after write buf list */
end_comment

begin_decl_stmt
specifier|static
name|list_t
modifier|*
name|l2arc_free_on_write
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* free after write list ptr */
end_comment

begin_decl_stmt
specifier|static
name|kmutex_t
name|l2arc_free_on_write_mtx
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* mutex for list */
end_comment

begin_decl_stmt
specifier|static
name|uint64_t
name|l2arc_ndev
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* number of devices */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|l2arc_read_callback
block|{
name|arc_buf_t
modifier|*
name|l2rcb_buf
decl_stmt|;
comment|/* read buffer */
name|spa_t
modifier|*
name|l2rcb_spa
decl_stmt|;
comment|/* spa */
name|blkptr_t
name|l2rcb_bp
decl_stmt|;
comment|/* original blkptr */
name|zbookmark_phys_t
name|l2rcb_zb
decl_stmt|;
comment|/* original bookmark */
name|int
name|l2rcb_flags
decl_stmt|;
comment|/* original flags */
name|enum
name|zio_compress
name|l2rcb_compress
decl_stmt|;
comment|/* applied compress */
block|}
name|l2arc_read_callback_t
typedef|;
end_typedef

begin_typedef
typedef|typedef
struct|struct
name|l2arc_write_callback
block|{
name|l2arc_dev_t
modifier|*
name|l2wcb_dev
decl_stmt|;
comment|/* device info */
name|arc_buf_hdr_t
modifier|*
name|l2wcb_head
decl_stmt|;
comment|/* head of write buflist */
block|}
name|l2arc_write_callback_t
typedef|;
end_typedef

begin_typedef
typedef|typedef
struct|struct
name|l2arc_data_free
block|{
comment|/* protected by l2arc_free_on_write_mtx */
name|void
modifier|*
name|l2df_data
decl_stmt|;
name|size_t
name|l2df_size
decl_stmt|;
name|void
function_decl|(
modifier|*
name|l2df_func
function_decl|)
parameter_list|(
name|void
modifier|*
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
name|list_node_t
name|l2df_list_node
decl_stmt|;
block|}
name|l2arc_data_free_t
typedef|;
end_typedef

begin_decl_stmt
specifier|static
name|kmutex_t
name|l2arc_feed_thr_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kcondvar_t
name|l2arc_feed_thr_cv
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|uint8_t
name|l2arc_thread_exit
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|void
name|arc_get_data_buf
parameter_list|(
name|arc_buf_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|arc_access
parameter_list|(
name|arc_buf_hdr_t
modifier|*
parameter_list|,
name|kmutex_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|arc_is_overflowing
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|arc_buf_watch
parameter_list|(
name|arc_buf_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|arc_buf_contents_t
name|arc_buf_type
parameter_list|(
name|arc_buf_hdr_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|uint32_t
name|arc_bufc_to_flags
parameter_list|(
name|arc_buf_contents_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|l2arc_write_eligible
parameter_list|(
name|uint64_t
parameter_list|,
name|arc_buf_hdr_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|l2arc_read_done
parameter_list|(
name|zio_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|l2arc_compress_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|l2arc_decompress_zio
parameter_list|(
name|zio_t
modifier|*
parameter_list|,
name|arc_buf_hdr_t
modifier|*
parameter_list|,
name|enum
name|zio_compress
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|l2arc_release_cdata_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function
specifier|static
name|void
name|l2arc_trim
parameter_list|(
specifier|const
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|l2arc_dev_t
modifier|*
name|dev
init|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
operator|==
name|L2ARC_ADDR_UNSET
condition|)
return|return;
if|if
condition|(
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
operator|!=
literal|0
condition|)
block|{
name|trim_map_free
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
argument_list|,
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_compress
argument_list|,
operator|==
argument_list|,
name|ZIO_COMPRESS_EMPTY
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|buf_hash
parameter_list|(
name|uint64_t
name|spa
parameter_list|,
specifier|const
name|dva_t
modifier|*
name|dva
parameter_list|,
name|uint64_t
name|birth
parameter_list|)
block|{
name|uint8_t
modifier|*
name|vdva
init|=
operator|(
name|uint8_t
operator|*
operator|)
name|dva
decl_stmt|;
name|uint64_t
name|crc
init|=
operator|-
literal|1ULL
decl_stmt|;
name|int
name|i
decl_stmt|;
name|ASSERT
argument_list|(
name|zfs_crc64_table
index|[
literal|128
index|]
operator|==
name|ZFS_CRC64_POLY
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
sizeof|sizeof
argument_list|(
name|dva_t
argument_list|)
condition|;
name|i
operator|++
control|)
name|crc
operator|=
operator|(
name|crc
operator|>>
literal|8
operator|)
operator|^
name|zfs_crc64_table
index|[
operator|(
name|crc
operator|^
name|vdva
index|[
name|i
index|]
operator|)
operator|&
literal|0xFF
index|]
expr_stmt|;
name|crc
operator|^=
operator|(
name|spa
operator|>>
literal|8
operator|)
operator|^
name|birth
expr_stmt|;
return|return
operator|(
name|crc
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|BUF_EMPTY
parameter_list|(
name|buf
parameter_list|)
define|\
value|((buf)->b_dva.dva_word[0] == 0&&			\ 	(buf)->b_dva.dva_word[1] == 0)
end_define

begin_define
define|#
directive|define
name|BUF_EQUAL
parameter_list|(
name|spa
parameter_list|,
name|dva
parameter_list|,
name|birth
parameter_list|,
name|buf
parameter_list|)
define|\
value|((buf)->b_dva.dva_word[0] == (dva)->dva_word[0])&&	\ 	((buf)->b_dva.dva_word[1] == (dva)->dva_word[1])&&	\ 	((buf)->b_birth == birth)&& ((buf)->b_spa == spa)
end_define

begin_function
specifier|static
name|void
name|buf_discard_identity
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|hdr
operator|->
name|b_dva
operator|.
name|dva_word
index|[
literal|0
index|]
operator|=
literal|0
expr_stmt|;
name|hdr
operator|->
name|b_dva
operator|.
name|dva_word
index|[
literal|1
index|]
operator|=
literal|0
expr_stmt|;
name|hdr
operator|->
name|b_birth
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|arc_buf_hdr_t
modifier|*
name|buf_hash_find
parameter_list|(
name|uint64_t
name|spa
parameter_list|,
specifier|const
name|blkptr_t
modifier|*
name|bp
parameter_list|,
name|kmutex_t
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
specifier|const
name|dva_t
modifier|*
name|dva
init|=
name|BP_IDENTITY
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|uint64_t
name|birth
init|=
name|BP_PHYSICAL_BIRTH
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|uint64_t
name|idx
init|=
name|BUF_HASH_INDEX
argument_list|(
name|spa
argument_list|,
name|dva
argument_list|,
name|birth
argument_list|)
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|BUF_HASH_LOCK
argument_list|(
name|idx
argument_list|)
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
for|for
control|(
name|hdr
operator|=
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
init|;
name|hdr
operator|!=
name|NULL
condition|;
name|hdr
operator|=
name|hdr
operator|->
name|b_hash_next
control|)
block|{
if|if
condition|(
name|BUF_EQUAL
argument_list|(
name|spa
argument_list|,
name|dva
argument_list|,
name|birth
argument_list|,
name|hdr
argument_list|)
condition|)
block|{
operator|*
name|lockp
operator|=
name|hash_lock
expr_stmt|;
return|return
operator|(
name|hdr
operator|)
return|;
block|}
block|}
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
operator|*
name|lockp
operator|=
name|NULL
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Insert an entry into the hash table.  If there is already an element  * equal to elem in the hash table, then the already existing element  * will be returned and the new element will not be inserted.  * Otherwise returns NULL.  * If lockp == NULL, the caller is assumed to already hold the hash lock.  */
end_comment

begin_function
specifier|static
name|arc_buf_hdr_t
modifier|*
name|buf_hash_insert
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|uint64_t
name|idx
init|=
name|BUF_HASH_INDEX
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
operator|&
name|hdr
operator|->
name|b_dva
argument_list|,
name|hdr
operator|->
name|b_birth
argument_list|)
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|BUF_HASH_LOCK
argument_list|(
name|idx
argument_list|)
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|fhdr
decl_stmt|;
name|uint32_t
name|i
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|DVA_IS_EMPTY
argument_list|(
operator|&
name|hdr
operator|->
name|b_dva
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_birth
operator|!=
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|lockp
operator|!=
name|NULL
condition|)
block|{
operator|*
name|lockp
operator|=
name|hash_lock
expr_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|fhdr
operator|=
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
operator|,
name|i
operator|=
literal|0
init|;
name|fhdr
operator|!=
name|NULL
condition|;
name|fhdr
operator|=
name|fhdr
operator|->
name|b_hash_next
operator|,
name|i
operator|++
control|)
block|{
if|if
condition|(
name|BUF_EQUAL
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
operator|&
name|hdr
operator|->
name|b_dva
argument_list|,
name|hdr
operator|->
name|b_birth
argument_list|,
name|fhdr
argument_list|)
condition|)
return|return
operator|(
name|fhdr
operator|)
return|;
block|}
name|hdr
operator|->
name|b_hash_next
operator|=
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
expr_stmt|;
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
operator|=
name|hdr
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_IN_HASH_TABLE
expr_stmt|;
comment|/* collect some hash table performance data */
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_hash_collisions
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|==
literal|1
condition|)
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_hash_chains
argument_list|)
expr_stmt|;
name|ARCSTAT_MAX
argument_list|(
name|arcstat_hash_chain_max
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_hash_elements
argument_list|)
expr_stmt|;
name|ARCSTAT_MAXSTAT
argument_list|(
name|arcstat_hash_elements
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|buf_hash_remove
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|fhdr
decl_stmt|,
modifier|*
modifier|*
name|hdrp
decl_stmt|;
name|uint64_t
name|idx
init|=
name|BUF_HASH_INDEX
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
operator|&
name|hdr
operator|->
name|b_dva
argument_list|,
name|hdr
operator|->
name|b_birth
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|BUF_HASH_LOCK
argument_list|(
name|idx
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|hdrp
operator|=
operator|&
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
expr_stmt|;
while|while
condition|(
operator|(
name|fhdr
operator|=
operator|*
name|hdrp
operator|)
operator|!=
name|hdr
condition|)
block|{
name|ASSERT
argument_list|(
name|fhdr
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|hdrp
operator|=
operator|&
name|fhdr
operator|->
name|b_hash_next
expr_stmt|;
block|}
operator|*
name|hdrp
operator|=
name|hdr
operator|->
name|b_hash_next
expr_stmt|;
name|hdr
operator|->
name|b_hash_next
operator|=
name|NULL
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_IN_HASH_TABLE
expr_stmt|;
comment|/* collect some hash table performance data */
name|ARCSTAT_BUMPDOWN
argument_list|(
name|arcstat_hash_elements
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
operator|&&
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
operator|->
name|b_hash_next
operator|==
name|NULL
condition|)
name|ARCSTAT_BUMPDOWN
argument_list|(
name|arcstat_hash_chains
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Global data structures and functions for the buf kmem cache.  */
end_comment

begin_decl_stmt
specifier|static
name|kmem_cache_t
modifier|*
name|hdr_full_cache
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kmem_cache_t
modifier|*
name|hdr_l2only_cache
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kmem_cache_t
modifier|*
name|buf_cache
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|void
name|buf_fini
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|kmem_free
argument_list|(
name|buf_hash_table
operator|.
name|ht_table
argument_list|,
operator|(
name|buf_hash_table
operator|.
name|ht_mask
operator|+
literal|1
operator|)
operator|*
sizeof|sizeof
argument_list|(
name|void
operator|*
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|BUF_LOCKS
condition|;
name|i
operator|++
control|)
name|mutex_destroy
argument_list|(
operator|&
name|buf_hash_table
operator|.
name|ht_locks
index|[
name|i
index|]
operator|.
name|ht_lock
argument_list|)
expr_stmt|;
name|kmem_cache_destroy
argument_list|(
name|hdr_full_cache
argument_list|)
expr_stmt|;
name|kmem_cache_destroy
argument_list|(
name|hdr_l2only_cache
argument_list|)
expr_stmt|;
name|kmem_cache_destroy
argument_list|(
name|buf_cache
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Constructor callback - called when the cache is empty  * and a new buf is requested.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|int
name|hdr_full_cons
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|,
name|int
name|kmflag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|vbuf
decl_stmt|;
name|bzero
argument_list|(
name|hdr
argument_list|,
name|HDR_FULL_SIZE
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|multilist_link_init
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
expr_stmt|;
name|arc_space_consume
argument_list|(
name|HDR_FULL_SIZE
argument_list|,
name|ARC_SPACE_HDRS
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|int
name|hdr_l2only_cons
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|,
name|int
name|kmflag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|vbuf
decl_stmt|;
name|bzero
argument_list|(
name|hdr
argument_list|,
name|HDR_L2ONLY_SIZE
argument_list|)
expr_stmt|;
name|arc_space_consume
argument_list|(
name|HDR_L2ONLY_SIZE
argument_list|,
name|ARC_SPACE_L2HDRS
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|int
name|buf_cons
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|,
name|int
name|kmflag
parameter_list|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|vbuf
decl_stmt|;
name|bzero
argument_list|(
name|buf
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_t
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|arc_space_consume
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_t
argument_list|)
argument_list|,
name|ARC_SPACE_HDRS
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Destructor callback - called when a cached buf is  * no longer required.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|hdr_full_dest
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|vbuf
decl_stmt|;
name|ASSERT
argument_list|(
name|BUF_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_cv
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
name|HDR_FULL_SIZE
argument_list|,
name|ARC_SPACE_HDRS
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|hdr_l2only_dest
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|vbuf
decl_stmt|;
name|ASSERT
argument_list|(
name|BUF_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
name|HDR_L2ONLY_SIZE
argument_list|,
name|ARC_SPACE_L2HDRS
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|buf_dest
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|vbuf
decl_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_t
argument_list|)
argument_list|,
name|ARC_SPACE_HDRS
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Reclaim callback -- invoked when memory is low.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|hdr_recl
parameter_list|(
name|void
modifier|*
name|unused
parameter_list|)
block|{
name|dprintf
argument_list|(
literal|"hdr_recl called\n"
argument_list|)
expr_stmt|;
comment|/* 	 * umem calls the reclaim func when we destroy the buf cache, 	 * which is after we do arc_fini(). 	 */
if|if
condition|(
operator|!
name|arc_dead
condition|)
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|buf_init
parameter_list|(
name|void
parameter_list|)
block|{
name|uint64_t
modifier|*
name|ct
decl_stmt|;
name|uint64_t
name|hsize
init|=
literal|1ULL
operator|<<
literal|12
decl_stmt|;
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
comment|/* 	 * The hash table is big enough to fill all of physical memory 	 * with an average block size of zfs_arc_average_blocksize (default 8K). 	 * By default, the table will take up 	 * totalmem * sizeof(void*) / 8K (1MB per GB with 8-byte pointers). 	 */
while|while
condition|(
name|hsize
operator|*
name|zfs_arc_average_blocksize
operator|<
operator|(
name|uint64_t
operator|)
name|physmem
operator|*
name|PAGESIZE
condition|)
name|hsize
operator|<<=
literal|1
expr_stmt|;
name|retry
label|:
name|buf_hash_table
operator|.
name|ht_mask
operator|=
name|hsize
operator|-
literal|1
expr_stmt|;
name|buf_hash_table
operator|.
name|ht_table
operator|=
name|kmem_zalloc
argument_list|(
name|hsize
operator|*
sizeof|sizeof
argument_list|(
name|void
operator|*
argument_list|)
argument_list|,
name|KM_NOSLEEP
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf_hash_table
operator|.
name|ht_table
operator|==
name|NULL
condition|)
block|{
name|ASSERT
argument_list|(
name|hsize
operator|>
operator|(
literal|1ULL
operator|<<
literal|8
operator|)
argument_list|)
expr_stmt|;
name|hsize
operator|>>=
literal|1
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
name|hdr_full_cache
operator|=
name|kmem_cache_create
argument_list|(
literal|"arc_buf_hdr_t_full"
argument_list|,
name|HDR_FULL_SIZE
argument_list|,
literal|0
argument_list|,
name|hdr_full_cons
argument_list|,
name|hdr_full_dest
argument_list|,
name|hdr_recl
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|hdr_l2only_cache
operator|=
name|kmem_cache_create
argument_list|(
literal|"arc_buf_hdr_t_l2only"
argument_list|,
name|HDR_L2ONLY_SIZE
argument_list|,
literal|0
argument_list|,
name|hdr_l2only_cons
argument_list|,
name|hdr_l2only_dest
argument_list|,
name|hdr_recl
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|buf_cache
operator|=
name|kmem_cache_create
argument_list|(
literal|"arc_buf_t"
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_t
argument_list|)
argument_list|,
literal|0
argument_list|,
name|buf_cons
argument_list|,
name|buf_dest
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|256
condition|;
name|i
operator|++
control|)
for|for
control|(
name|ct
operator|=
name|zfs_crc64_table
operator|+
name|i
operator|,
operator|*
name|ct
operator|=
name|i
operator|,
name|j
operator|=
literal|8
init|;
name|j
operator|>
literal|0
condition|;
name|j
operator|--
control|)
operator|*
name|ct
operator|=
operator|(
operator|*
name|ct
operator|>>
literal|1
operator|)
operator|^
operator|(
operator|-
operator|(
operator|*
name|ct
operator|&
literal|1
operator|)
operator|&
name|ZFS_CRC64_POLY
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|BUF_LOCKS
condition|;
name|i
operator|++
control|)
block|{
name|mutex_init
argument_list|(
operator|&
name|buf_hash_table
operator|.
name|ht_locks
index|[
name|i
index|]
operator|.
name|ht_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Transition between the two allocation states for the arc_buf_hdr struct.  * The arc_buf_hdr struct can be allocated with (hdr_full_cache) or without  * (hdr_l2only_cache) the fields necessary for the L1 cache - the smaller  * version is used when a cache buffer is only in the L2ARC in order to reduce  * memory usage.  */
end_comment

begin_function
specifier|static
name|arc_buf_hdr_t
modifier|*
name|arc_hdr_realloc
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmem_cache_t
modifier|*
name|old
parameter_list|,
name|kmem_cache_t
modifier|*
name|new
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_buf_hdr_t
modifier|*
name|nhdr
decl_stmt|;
name|l2arc_dev_t
modifier|*
name|dev
init|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
decl_stmt|;
name|ASSERT
argument_list|(
operator|(
name|old
operator|==
name|hdr_full_cache
operator|&&
name|new
operator|==
name|hdr_l2only_cache
operator|)
operator|||
operator|(
name|old
operator|==
name|hdr_l2only_cache
operator|&&
name|new
operator|==
name|hdr_full_cache
operator|)
argument_list|)
expr_stmt|;
name|nhdr
operator|=
name|kmem_cache_alloc
argument_list|(
name|new
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|buf_hash_remove
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|hdr
argument_list|,
name|nhdr
argument_list|,
name|HDR_L2ONLY_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|new
operator|==
name|hdr_full_cache
condition|)
block|{
name|nhdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_HAS_L1HDR
expr_stmt|;
comment|/* 		 * arc_access and arc_change_state need to be aware that a 		 * header has just come out of L2ARC, so we set its state to 		 * l2c_only even though it's about to change. 		 */
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|=
name|arc_l2c_only
expr_stmt|;
comment|/* Verify previous threads set to NULL before freeing */
name|ASSERT3P
argument_list|(
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
argument_list|)
expr_stmt|;
comment|/* 		 * If we've reached here, We must have been called from 		 * arc_evict_hdr(), as such we should have already been 		 * removed from any ghost list we were previously on 		 * (which protects us from racing with arc_evict_state), 		 * thus no locking is needed during this check. 		 */
name|ASSERT
argument_list|(
operator|!
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 		 * A buffer must not be moved into the arc_l2c_only 		 * state if it's not finished being written out to the 		 * l2arc device. Otherwise, the b_l1hdr.b_tmp_cdata field 		 * might try to be accessed, even though it was removed. 		 */
name|VERIFY
argument_list|(
operator|!
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|VERIFY3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|ZFS_DEBUG
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|!=
name|NULL
condition|)
block|{
name|kmem_free
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|=
name|NULL
expr_stmt|;
block|}
endif|#
directive|endif
name|nhdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_HAS_L1HDR
expr_stmt|;
block|}
comment|/* 	 * The header has been reallocated so we need to re-insert it into any 	 * lists it was on. 	 */
operator|(
name|void
operator|)
name|buf_hash_insert
argument_list|(
name|nhdr
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|list_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_l2node
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * We must place the realloc'ed header back into the list at 	 * the same spot. Otherwise, if it's placed earlier in the list, 	 * l2arc_write_buffers() could find it during the function's 	 * write phase, and try to write it out to the l2arc. 	 */
name|list_insert_after
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|hdr
argument_list|,
name|nhdr
argument_list|)
expr_stmt|;
name|list_remove
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Since we're using the pointer address as the tag when 	 * incrementing and decrementing the l2ad_alloc refcount, we 	 * must remove the old pointer (that we're about to destroy) and 	 * add the new pointer to the refcount. Otherwise we'd remove 	 * the wrong pointer address when calling arc_hdr_destroy() later. 	 */
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_alloc
argument_list|,
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_alloc
argument_list|,
name|nhdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
argument_list|,
name|nhdr
argument_list|)
expr_stmt|;
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_freeze_cksum
operator|=
name|NULL
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|old
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
return|return
operator|(
name|nhdr
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|ARC_MINTIME
value|(hz>>4)
end_define

begin_comment
comment|/* 62 ms */
end_comment

begin_function
specifier|static
name|void
name|arc_cksum_verify
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|zio_cksum_t
name|zc
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_MODIFY
operator|)
condition|)
return|return;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_freeze_cksum
operator|==
name|NULL
operator|||
name|HDR_IO_ERROR
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
return|return;
block|}
name|fletcher_2_native
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|buf
operator|->
name|b_hdr
operator|->
name|b_size
argument_list|,
name|NULL
argument_list|,
operator|&
name|zc
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|ZIO_CHECKSUM_EQUAL
argument_list|(
operator|*
name|buf
operator|->
name|b_hdr
operator|->
name|b_freeze_cksum
argument_list|,
name|zc
argument_list|)
condition|)
name|panic
argument_list|(
literal|"buffer modified while frozen!"
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|arc_cksum_equal
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|zio_cksum_t
name|zc
decl_stmt|;
name|int
name|equal
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
name|fletcher_2_native
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|buf
operator|->
name|b_hdr
operator|->
name|b_size
argument_list|,
name|NULL
argument_list|,
operator|&
name|zc
argument_list|)
expr_stmt|;
name|equal
operator|=
name|ZIO_CHECKSUM_EQUAL
argument_list|(
operator|*
name|buf
operator|->
name|b_hdr
operator|->
name|b_freeze_cksum
argument_list|,
name|zc
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|equal
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_cksum_compute
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|boolean_t
name|force
parameter_list|)
block|{
if|if
condition|(
operator|!
name|force
operator|&&
operator|!
operator|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_MODIFY
operator|)
condition|)
return|return;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_freeze_cksum
operator|!=
name|NULL
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
return|return;
block|}
name|buf
operator|->
name|b_hdr
operator|->
name|b_freeze_cksum
operator|=
name|kmem_alloc
argument_list|(
sizeof|sizeof
argument_list|(
name|zio_cksum_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|fletcher_2_native
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|buf
operator|->
name|b_hdr
operator|->
name|b_size
argument_list|,
name|NULL
argument_list|,
name|buf
operator|->
name|b_hdr
operator|->
name|b_freeze_cksum
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
name|arc_buf_watch
argument_list|(
name|buf
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* illumos */
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|illumos
end_ifdef

begin_ifndef
ifndef|#
directive|ifndef
name|_KERNEL
end_ifndef

begin_typedef
typedef|typedef
struct|struct
name|procctl
block|{
name|long
name|cmd
decl_stmt|;
name|prwatch_t
name|prwatch
decl_stmt|;
block|}
name|procctl_t
typedef|;
end_typedef

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|arc_buf_unwatch
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
ifndef|#
directive|ifndef
name|_KERNEL
if|if
condition|(
name|arc_watch
condition|)
block|{
name|int
name|result
decl_stmt|;
name|procctl_t
name|ctl
decl_stmt|;
name|ctl
operator|.
name|cmd
operator|=
name|PCWATCH
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_vaddr
operator|=
operator|(
name|uintptr_t
operator|)
name|buf
operator|->
name|b_data
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_size
operator|=
literal|0
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_wflags
operator|=
literal|0
expr_stmt|;
name|result
operator|=
name|write
argument_list|(
name|arc_procfd
argument_list|,
operator|&
name|ctl
argument_list|,
sizeof|sizeof
argument_list|(
name|ctl
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|result
argument_list|,
operator|==
argument_list|,
sizeof|sizeof
argument_list|(
name|ctl
argument_list|)
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|arc_buf_watch
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
ifndef|#
directive|ifndef
name|_KERNEL
if|if
condition|(
name|arc_watch
condition|)
block|{
name|int
name|result
decl_stmt|;
name|procctl_t
name|ctl
decl_stmt|;
name|ctl
operator|.
name|cmd
operator|=
name|PCWATCH
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_vaddr
operator|=
operator|(
name|uintptr_t
operator|)
name|buf
operator|->
name|b_data
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_size
operator|=
name|buf
operator|->
name|b_hdr
operator|->
name|b_size
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_wflags
operator|=
name|WA_WRITE
expr_stmt|;
name|result
operator|=
name|write
argument_list|(
name|arc_procfd
argument_list|,
operator|&
name|ctl
argument_list|,
sizeof|sizeof
argument_list|(
name|ctl
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|result
argument_list|,
operator|==
argument_list|,
sizeof|sizeof
argument_list|(
name|ctl
argument_list|)
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* illumos */
end_comment

begin_function
specifier|static
name|arc_buf_contents_t
name|arc_buf_type
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
if|if
condition|(
name|HDR_ISTYPE_METADATA
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
return|return
operator|(
name|ARC_BUFC_METADATA
operator|)
return|;
block|}
else|else
block|{
return|return
operator|(
name|ARC_BUFC_DATA
operator|)
return|;
block|}
block|}
end_function

begin_function
specifier|static
name|uint32_t
name|arc_bufc_to_flags
parameter_list|(
name|arc_buf_contents_t
name|type
parameter_list|)
block|{
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|ARC_BUFC_DATA
case|:
comment|/* metadata field is 0 if buffer contains normal data */
return|return
operator|(
literal|0
operator|)
return|;
case|case
name|ARC_BUFC_METADATA
case|:
return|return
operator|(
name|ARC_FLAG_BUFC_METADATA
operator|)
return|;
default|default:
break|break;
block|}
name|panic
argument_list|(
literal|"undefined ARC buffer type!"
argument_list|)
expr_stmt|;
return|return
operator|(
operator|(
name|uint32_t
operator|)
operator|-
literal|1
operator|)
return|;
block|}
end_function

begin_function
name|void
name|arc_buf_thaw
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
if|if
condition|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_MODIFY
condition|)
block|{
if|if
condition|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|!=
name|arc_anon
condition|)
name|panic
argument_list|(
literal|"modifying non-anon buffer!"
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_IO_IN_PROGRESS
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
condition|)
name|panic
argument_list|(
literal|"modifying buffer while i/o in progress!"
argument_list|)
expr_stmt|;
name|arc_cksum_verify
argument_list|(
name|buf
argument_list|)
expr_stmt|;
block|}
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_freeze_cksum
operator|!=
name|NULL
condition|)
block|{
name|kmem_free
argument_list|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_freeze_cksum
argument_list|,
sizeof|sizeof
argument_list|(
name|zio_cksum_t
argument_list|)
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|->
name|b_freeze_cksum
operator|=
name|NULL
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|ZFS_DEBUG
if|if
condition|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_MODIFY
condition|)
block|{
if|if
condition|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|!=
name|NULL
condition|)
name|kmem_free
argument_list|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|=
name|kmem_alloc
argument_list|(
literal|1
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
name|arc_buf_unwatch
argument_list|(
name|buf
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* illumos */
block|}
end_function

begin_function
name|void
name|arc_buf_freeze
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_MODIFY
operator|)
condition|)
return|return;
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_freeze_cksum
operator|!=
name|NULL
operator|||
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
argument_list|)
expr_stmt|;
name|arc_cksum_compute
argument_list|(
name|buf
argument_list|,
name|B_FALSE
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|add_reference
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
name|hash_lock
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
if|if
condition|(
operator|(
name|refcount_add
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
operator|==
literal|1
operator|)
operator|&&
operator|(
name|state
operator|!=
name|arc_anon
operator|)
condition|)
block|{
comment|/* We don't use the L2-only state list. */
if|if
condition|(
name|state
operator|!=
name|arc_l2c_only
condition|)
block|{
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|uint64_t
name|delta
init|=
name|hdr
operator|->
name|b_size
operator|*
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
decl_stmt|;
name|multilist_t
modifier|*
name|list
init|=
operator|&
name|state
operator|->
name|arcs_list
index|[
name|type
index|]
decl_stmt|;
name|uint64_t
modifier|*
name|size
init|=
operator|&
name|state
operator|->
name|arcs_lsize
index|[
name|type
index|]
decl_stmt|;
name|multilist_remove
argument_list|(
name|list
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|state
argument_list|)
condition|)
block|{
name|ASSERT0
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|delta
operator|=
name|hdr
operator|->
name|b_size
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|delta
operator|>
literal|0
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
operator|*
name|size
argument_list|,
operator|>=
argument_list|,
name|delta
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
name|size
argument_list|,
operator|-
name|delta
argument_list|)
expr_stmt|;
block|}
comment|/* remove the prefetch flag if we get a reference */
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_PREFETCH
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|int
name|remove_reference
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
name|hash_lock
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|int
name|cnt
decl_stmt|;
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|state
operator|==
name|arc_anon
operator|||
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|GHOST_STATE
argument_list|(
name|state
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * arc_l2c_only counts as a ghost state so we don't need to explicitly 	 * check to prevent usage of the arc_l2c_only list. 	 */
if|if
condition|(
operator|(
operator|(
name|cnt
operator|=
name|refcount_remove
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|state
operator|!=
name|arc_anon
operator|)
condition|)
block|{
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|multilist_t
modifier|*
name|list
init|=
operator|&
name|state
operator|->
name|arcs_list
index|[
name|type
index|]
decl_stmt|;
name|uint64_t
modifier|*
name|size
init|=
operator|&
name|state
operator|->
name|arcs_lsize
index|[
name|type
index|]
decl_stmt|;
name|multilist_insert
argument_list|(
name|list
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|0
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
name|size
argument_list|,
name|hdr
operator|->
name|b_size
operator|*
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|cnt
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Move the supplied buffer to the indicated state. The hash lock  * for the buffer must be held by the caller.  */
end_comment

begin_function
specifier|static
name|void
name|arc_change_state
parameter_list|(
name|arc_state_t
modifier|*
name|new_state
parameter_list|,
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
name|hash_lock
parameter_list|)
block|{
name|arc_state_t
modifier|*
name|old_state
decl_stmt|;
name|int64_t
name|refcnt
decl_stmt|;
name|uint32_t
name|datacnt
decl_stmt|;
name|uint64_t
name|from_delta
decl_stmt|,
name|to_delta
decl_stmt|;
name|arc_buf_contents_t
name|buftype
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
comment|/* 	 * We almost always have an L1 hdr here, since we call arc_hdr_realloc() 	 * in arc_read() when bringing a buffer out of the L2ARC.  However, the 	 * L1 hdr doesn't always exist when we change state to arc_anon before 	 * destroying a header, in which case reallocating to add the L1 hdr is 	 * pointless. 	 */
if|if
condition|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|old_state
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
expr_stmt|;
name|refcnt
operator|=
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
expr_stmt|;
name|datacnt
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
expr_stmt|;
block|}
else|else
block|{
name|old_state
operator|=
name|arc_l2c_only
expr_stmt|;
name|refcnt
operator|=
literal|0
expr_stmt|;
name|datacnt
operator|=
literal|0
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|new_state
argument_list|,
operator|!=
argument_list|,
name|old_state
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcnt
operator|==
literal|0
operator|||
name|datacnt
operator|>
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|GHOST_STATE
argument_list|(
name|new_state
argument_list|)
operator|||
name|datacnt
operator|==
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|old_state
operator|!=
name|arc_anon
operator|||
name|datacnt
operator|<=
literal|1
argument_list|)
expr_stmt|;
name|from_delta
operator|=
name|to_delta
operator|=
name|datacnt
operator|*
name|hdr
operator|->
name|b_size
expr_stmt|;
comment|/* 	 * If this buffer is evictable, transfer it from the 	 * old state list to the new state list. 	 */
if|if
condition|(
name|refcnt
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|old_state
operator|!=
name|arc_anon
operator|&&
name|old_state
operator|!=
name|arc_l2c_only
condition|)
block|{
name|uint64_t
modifier|*
name|size
init|=
operator|&
name|old_state
operator|->
name|arcs_lsize
index|[
name|buftype
index|]
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|multilist_remove
argument_list|(
operator|&
name|old_state
operator|->
name|arcs_list
index|[
name|buftype
index|]
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
comment|/* 			 * If prefetching out of the ghost cache, 			 * we will have a non-zero datacnt. 			 */
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|old_state
argument_list|)
operator|&&
name|datacnt
operator|==
literal|0
condition|)
block|{
comment|/* ghost elements have a ghost size */
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|from_delta
operator|=
name|hdr
operator|->
name|b_size
expr_stmt|;
block|}
name|ASSERT3U
argument_list|(
operator|*
name|size
argument_list|,
operator|>=
argument_list|,
name|from_delta
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
name|size
argument_list|,
operator|-
name|from_delta
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|new_state
operator|!=
name|arc_anon
operator|&&
name|new_state
operator|!=
name|arc_l2c_only
condition|)
block|{
name|uint64_t
modifier|*
name|size
init|=
operator|&
name|new_state
operator|->
name|arcs_lsize
index|[
name|buftype
index|]
decl_stmt|;
comment|/* 			 * An L1 header always exists here, since if we're 			 * moving to some L1-cached state (i.e. not l2c_only or 			 * anonymous), we realloc the header to add an L1hdr 			 * beforehand. 			 */
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|multilist_insert
argument_list|(
operator|&
name|new_state
operator|->
name|arcs_list
index|[
name|buftype
index|]
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
comment|/* ghost elements have a ghost size */
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|new_state
argument_list|)
condition|)
block|{
name|ASSERT0
argument_list|(
name|datacnt
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|to_delta
operator|=
name|hdr
operator|->
name|b_size
expr_stmt|;
block|}
name|atomic_add_64
argument_list|(
name|size
argument_list|,
name|to_delta
argument_list|)
expr_stmt|;
block|}
block|}
name|ASSERT
argument_list|(
operator|!
name|BUF_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|new_state
operator|==
name|arc_anon
operator|&&
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
condition|)
name|buf_hash_remove
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* adjust state sizes (ignore arc_l2c_only) */
if|if
condition|(
name|to_delta
operator|&&
name|new_state
operator|!=
name|arc_l2c_only
condition|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|new_state
argument_list|)
condition|)
block|{
name|ASSERT0
argument_list|(
name|datacnt
argument_list|)
expr_stmt|;
comment|/* 			 * We moving a header to a ghost state, we first 			 * remove all arc buffers. Thus, we'll have a 			 * datacnt of zero, and no arc buffer to use for 			 * the reference. As a result, we use the arc 			 * header pointer for the reference. 			 */
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|new_state
operator|->
name|arcs_size
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT3U
argument_list|(
name|datacnt
argument_list|,
operator|!=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 			 * Each individual buffer holds a unique reference, 			 * thus we must remove each of these references one 			 * at a time. 			 */
for|for
control|(
name|arc_buf_t
modifier|*
name|buf
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
init|;
name|buf
operator|!=
name|NULL
condition|;
name|buf
operator|=
name|buf
operator|->
name|b_next
control|)
block|{
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|new_state
operator|->
name|arcs_size
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|from_delta
operator|&&
name|old_state
operator|!=
name|arc_l2c_only
condition|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|old_state
argument_list|)
condition|)
block|{
comment|/* 			 * When moving a header off of a ghost state, 			 * there's the possibility for datacnt to be 			 * non-zero. This is because we first add the 			 * arc buffer to the header prior to changing 			 * the header's state. Since we used the header 			 * for the reference when putting the header on 			 * the ghost state, we must balance that and use 			 * the header when removing off the ghost state 			 * (even though datacnt is non zero). 			 */
name|IMPLY
argument_list|(
name|datacnt
operator|==
literal|0
argument_list|,
name|new_state
operator|==
name|arc_anon
operator|||
name|new_state
operator|==
name|arc_l2c_only
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|old_state
operator|->
name|arcs_size
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT3P
argument_list|(
name|datacnt
argument_list|,
operator|!=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 			 * Each individual buffer holds a unique reference, 			 * thus we must remove each of these references one 			 * at a time. 			 */
for|for
control|(
name|arc_buf_t
modifier|*
name|buf
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
init|;
name|buf
operator|!=
name|NULL
condition|;
name|buf
operator|=
name|buf
operator|->
name|b_next
control|)
block|{
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|old_state
operator|->
name|arcs_size
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|=
name|new_state
expr_stmt|;
comment|/* 	 * L2 headers should never be on the L2 state list since they don't 	 * have L1 headers allocated. 	 */
name|ASSERT
argument_list|(
name|multilist_is_empty
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
operator|&&
name|multilist_is_empty
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|arc_space_consume
parameter_list|(
name|uint64_t
name|space
parameter_list|,
name|arc_space_type_t
name|type
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|type
operator|>=
literal|0
operator|&&
name|type
operator|<
name|ARC_SPACE_NUMTYPES
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|ARC_SPACE_DATA
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_data_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_META
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_metadata_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_OTHER
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_other_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_HDRS
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_hdr_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_L2HDRS
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_hdr_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|type
operator|!=
name|ARC_SPACE_DATA
condition|)
name|ARCSTAT_INCR
argument_list|(
name|arcstat_meta_used
argument_list|,
name|space
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|arc_space_return
parameter_list|(
name|uint64_t
name|space
parameter_list|,
name|arc_space_type_t
name|type
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|type
operator|>=
literal|0
operator|&&
name|type
operator|<
name|ARC_SPACE_NUMTYPES
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|ARC_SPACE_DATA
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_data_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_META
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_metadata_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_OTHER
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_other_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_HDRS
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_hdr_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_L2HDRS
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_hdr_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|type
operator|!=
name|ARC_SPACE_DATA
condition|)
block|{
name|ASSERT
argument_list|(
name|arc_meta_used
operator|>=
name|space
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_meta_max
operator|<
name|arc_meta_used
condition|)
name|arc_meta_max
operator|=
name|arc_meta_used
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_meta_used
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|arc_size
operator|>=
name|space
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|arc_buf_t
modifier|*
name|arc_buf_alloc
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|int32_t
name|size
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|,
name|arc_buf_contents_t
name|type
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|arc_buf_t
modifier|*
name|buf
decl_stmt|;
name|ASSERT3U
argument_list|(
name|size
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|kmem_cache_alloc
argument_list|(
name|hdr_full_cache
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|BUF_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_freeze_cksum
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_size
operator|=
name|size
expr_stmt|;
name|hdr
operator|->
name|b_spa
operator|=
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
expr_stmt|;
name|buf
operator|=
name|kmem_cache_alloc
argument_list|(
name|buf_cache
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|=
name|hdr
expr_stmt|;
name|buf
operator|->
name|b_data
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_efunc
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_private
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_next
operator|=
name|NULL
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator|=
name|arc_bufc_to_flags
argument_list|(
name|type
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_HAS_L1HDR
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|=
name|buf
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|=
name|arc_anon
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
literal|0
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|=
literal|1
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|=
name|NULL
expr_stmt|;
name|arc_get_data_buf
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
expr_stmt|;
return|return
operator|(
name|buf
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|char
modifier|*
name|arc_onloan_tag
init|=
literal|"onloan"
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Loan out an anonymous arc buffer. Loaned buffers are not counted as in  * flight data by arc_tempreserve_space() until they are "returned". Loaned  * buffers must be returned to the arc before they can be used by the DMU or  * freed.  */
end_comment

begin_function
name|arc_buf_t
modifier|*
name|arc_loan_buf
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|arc_buf_t
modifier|*
name|buf
decl_stmt|;
name|buf
operator|=
name|arc_buf_alloc
argument_list|(
name|spa
argument_list|,
name|size
argument_list|,
name|arc_onloan_tag
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_loaned_bytes
argument_list|,
name|size
argument_list|)
expr_stmt|;
return|return
operator|(
name|buf
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return a loaned arc buffer to the arc.  */
end_comment

begin_function
name|void
name|arc_return_buf
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|arc_onloan_tag
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_loaned_bytes
argument_list|,
operator|-
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Detach an arc_buf from a dbuf (tag) */
end_comment

begin_function
name|void
name|arc_loan_inuse_buf
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|arc_onloan_tag
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_efunc
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_private
operator|=
name|NULL
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_loaned_bytes
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|arc_buf_t
modifier|*
name|arc_buf_clone
parameter_list|(
name|arc_buf_t
modifier|*
name|from
parameter_list|)
block|{
name|arc_buf_t
modifier|*
name|buf
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|from
operator|->
name|b_hdr
decl_stmt|;
name|uint64_t
name|size
init|=
name|hdr
operator|->
name|b_size
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|!=
name|arc_anon
argument_list|)
expr_stmt|;
name|buf
operator|=
name|kmem_cache_alloc
argument_list|(
name|buf_cache
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|=
name|hdr
expr_stmt|;
name|buf
operator|->
name|b_data
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_efunc
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_private
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_next
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|=
name|buf
expr_stmt|;
name|arc_get_data_buf
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|from
operator|->
name|b_data
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|size
argument_list|)
expr_stmt|;
comment|/* 	 * This buffer already exists in the arc so create a duplicate 	 * copy for the caller.  If the buffer is associated with user data 	 * then track the size and number of duplicates.  These stats will be 	 * updated as duplicate buffers are created and destroyed. 	 */
if|if
condition|(
name|HDR_ISTYPE_DATA
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_duplicate_buffers
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_duplicate_buffers_size
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|+=
literal|1
expr_stmt|;
return|return
operator|(
name|buf
operator|)
return|;
block|}
end_function

begin_function
name|void
name|arc_buf_add_ref
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
comment|/* 	 * Check to see if this buffer is evicted.  Callers 	 * must verify b_data != NULL to know if the add_ref 	 * was successful. 	 */
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf
operator|->
name|b_data
operator|==
name|NULL
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
return|return;
block|}
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|buf
operator|->
name|b_hdr
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hash_lock
argument_list|,
operator|==
argument_list|,
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mru
operator|||
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mfu
argument_list|)
expr_stmt|;
name|add_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|tag
argument_list|)
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|arc__hit
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_access
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_hits
argument_list|)
expr_stmt|;
name|ARCSTAT_CONDSTAT
argument_list|(
operator|!
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|demand
argument_list|,
name|prefetch
argument_list|,
operator|!
name|HDR_ISTYPE_METADATA
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|data
argument_list|,
name|metadata
argument_list|,
name|hits
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_buf_free_on_write
parameter_list|(
name|void
modifier|*
name|data
parameter_list|,
name|size_t
name|size
parameter_list|,
name|void
function_decl|(
modifier|*
name|free_func
function_decl|)
parameter_list|(
name|void
modifier|*
parameter_list|,
name|size_t
parameter_list|)
parameter_list|)
block|{
name|l2arc_data_free_t
modifier|*
name|df
decl_stmt|;
name|df
operator|=
name|kmem_alloc
argument_list|(
sizeof|sizeof
argument_list|(
operator|*
name|df
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|df
operator|->
name|l2df_data
operator|=
name|data
expr_stmt|;
name|df
operator|->
name|l2df_size
operator|=
name|size
expr_stmt|;
name|df
operator|->
name|l2df_func
operator|=
name|free_func
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|)
expr_stmt|;
name|list_insert_head
argument_list|(
name|l2arc_free_on_write
argument_list|,
name|df
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Free the arc data buffer.  If it is an l2arc write in progress,  * the buffer is placed on l2arc_free_on_write to be freed later.  */
end_comment

begin_function
specifier|static
name|void
name|arc_buf_data_free
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
function_decl|(
modifier|*
name|free_func
function_decl|)
parameter_list|(
name|void
modifier|*
parameter_list|,
name|size_t
parameter_list|)
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
if|if
condition|(
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|arc_buf_free_on_write
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|,
name|free_func
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_free_on_write
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|free_func
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|arc_buf_l2_cdata_free
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|->
name|l2ad_mtx
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * The b_tmp_cdata field is linked off of the b_l1hdr, so if 	 * that doesn't exist, the header is in the arc_l2c_only state, 	 * and there isn't anything to free (it's already been freed). 	 */
if|if
condition|(
operator|!
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
return|return;
comment|/* 	 * The header isn't being written to the l2arc device, thus it 	 * shouldn't have a b_tmp_cdata to free. 	 */
if|if
condition|(
operator|!
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * The header does not have compression enabled. This can be due 	 * to the buffer not being compressible, or because we're 	 * freeing the buffer before the second phase of 	 * l2arc_write_buffer() has started (which does the compression 	 * step). In either case, b_tmp_cdata does not point to a 	 * separately compressed buffer, so there's nothing to free (it 	 * points to the same buffer as the arc_buf_t's b_data field). 	 */
if|if
condition|(
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_compress
operator|==
name|ZIO_COMPRESS_OFF
condition|)
block|{
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|=
name|NULL
expr_stmt|;
return|return;
block|}
comment|/* 	 * There's nothing to free since the buffer was all zero's and 	 * compressed to a zero length buffer. 	 */
if|if
condition|(
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_compress
operator|==
name|ZIO_COMPRESS_EMPTY
condition|)
block|{
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
return|return;
block|}
name|ASSERT
argument_list|(
name|L2ARC_IS_VALID_COMPRESS
argument_list|(
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_compress
argument_list|)
argument_list|)
expr_stmt|;
name|arc_buf_free_on_write
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|,
name|zio_data_buf_free
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_cdata_free_on_write
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Free up buf->b_data and if 'remove' is set, then pull the  * arc_buf_t off of the the arc_buf_hdr_t's list and free it.  */
end_comment

begin_function
specifier|static
name|void
name|arc_buf_destroy
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|boolean_t
name|remove
parameter_list|)
block|{
name|arc_buf_t
modifier|*
modifier|*
name|bufp
decl_stmt|;
comment|/* free up data associated with the buf */
if|if
condition|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
condition|)
block|{
name|arc_state_t
modifier|*
name|state
init|=
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|uint64_t
name|size
init|=
name|buf
operator|->
name|b_hdr
operator|->
name|b_size
decl_stmt|;
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
decl_stmt|;
name|arc_cksum_verify
argument_list|(
name|buf
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
name|arc_buf_unwatch
argument_list|(
name|buf
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* illumos */
if|if
condition|(
name|type
operator|==
name|ARC_BUFC_METADATA
condition|)
block|{
name|arc_buf_data_free
argument_list|(
name|buf
argument_list|,
name|zio_buf_free
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
name|size
argument_list|,
name|ARC_SPACE_META
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|type
operator|==
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|arc_buf_data_free
argument_list|(
name|buf
argument_list|,
name|zio_data_buf_free
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
name|size
argument_list|,
name|ARC_SPACE_DATA
argument_list|)
expr_stmt|;
block|}
comment|/* protected by hash lock, if in the hash table */
if|if
condition|(
name|multilist_link_active
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
condition|)
block|{
name|uint64_t
modifier|*
name|cnt
init|=
operator|&
name|state
operator|->
name|arcs_lsize
index|[
name|type
index|]
decl_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|state
operator|!=
name|arc_anon
operator|&&
name|state
operator|!=
name|arc_l2c_only
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
operator|*
name|cnt
argument_list|,
operator|>=
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
name|cnt
argument_list|,
operator|-
name|size
argument_list|)
expr_stmt|;
block|}
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|,
name|size
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_data
operator|=
name|NULL
expr_stmt|;
comment|/* 		 * If we're destroying a duplicate buffer make sure 		 * that the appropriate statistics are updated. 		 */
if|if
condition|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|1
operator|&&
name|HDR_ISTYPE_DATA
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMPDOWN
argument_list|(
name|arcstat_duplicate_buffers
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_duplicate_buffers_size
argument_list|,
operator|-
name|size
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|0
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|-=
literal|1
expr_stmt|;
block|}
comment|/* only remove the buf if requested */
if|if
condition|(
operator|!
name|remove
condition|)
return|return;
comment|/* remove the buf from the hdr list */
for|for
control|(
name|bufp
operator|=
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
init|;
operator|*
name|bufp
operator|!=
name|buf
condition|;
name|bufp
operator|=
operator|&
operator|(
operator|*
name|bufp
operator|)
operator|->
name|b_next
control|)
continue|continue;
operator|*
name|bufp
operator|=
name|buf
operator|->
name|b_next
expr_stmt|;
name|buf
operator|->
name|b_next
operator|=
name|NULL
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_efunc
operator|==
name|NULL
argument_list|)
expr_stmt|;
comment|/* clean up the buf */
name|buf
operator|->
name|b_hdr
operator|=
name|NULL
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|buf_cache
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_hdr_l2hdr_destroy
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|l2arc_buf_hdr_t
modifier|*
name|l2hdr
init|=
operator|&
name|hdr
operator|->
name|b_l2hdr
decl_stmt|;
name|l2arc_dev_t
modifier|*
name|dev
init|=
name|l2hdr
operator|->
name|b_dev
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|list_remove
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
comment|/* 	 * We don't want to leak the b_tmp_cdata buffer that was 	 * allocated in l2arc_write_buffers() 	 */
name|arc_buf_l2_cdata_free
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* 	 * If the l2hdr's b_daddr is equal to L2ARC_ADDR_UNSET, then 	 * this header is being processed by l2arc_write_buffers() (i.e. 	 * it's in the first stage of l2arc_write_buffers()). 	 * Re-affirming that truth here, just to serve as a reminder. If 	 * b_daddr does not equal L2ARC_ADDR_UNSET, then the header may or 	 * may not have its HDR_L2_WRITING flag set. (the write may have 	 * completed, in which case HDR_L2_WRITING will be false and the 	 * b_daddr field will point to the address of the buffer on disk). 	 */
name|IMPLY
argument_list|(
name|l2hdr
operator|->
name|b_daddr
operator|==
name|L2ARC_ADDR_UNSET
argument_list|,
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * If b_daddr is equal to L2ARC_ADDR_UNSET, we're racing with 	 * l2arc_write_buffers(). Since we've just removed this header 	 * from the l2arc buffer list, this header will never reach the 	 * second stage of l2arc_write_buffers(), which increments the 	 * accounting stats for this header. Thus, we must be careful 	 * not to decrement them for this header either. 	 */
if|if
condition|(
name|l2hdr
operator|->
name|b_daddr
operator|!=
name|L2ARC_ADDR_UNSET
condition|)
block|{
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_asize
argument_list|,
operator|-
name|l2hdr
operator|->
name|b_asize
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_size
argument_list|,
operator|-
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
name|vdev_space_update
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
operator|-
name|l2hdr
operator|->
name|b_asize
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_alloc
argument_list|,
name|l2hdr
operator|->
name|b_asize
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_HAS_L2HDR
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_hdr_destroy
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
if|if
condition|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|==
name|NULL
operator|||
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|,
operator|==
argument_list|,
name|arc_anon
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|l2arc_dev_t
modifier|*
name|dev
init|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
decl_stmt|;
name|boolean_t
name|buflist_held
init|=
name|MUTEX_HELD
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|buflist_held
condition|)
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 		 * Even though we checked this conditional above, we 		 * need to check this again now that we have the 		 * l2ad_mtx. This is because we could be racing with 		 * another thread calling l2arc_evict() which might have 		 * destroyed this header's L2 portion as we were waiting 		 * to acquire the l2ad_mtx. If that happens, we don't 		 * want to re-destroy the header's L2 portion. 		 */
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|l2arc_trim
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|arc_hdr_l2hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|buflist_held
condition|)
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|BUF_EMPTY
argument_list|(
name|hdr
argument_list|)
condition|)
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_freeze_cksum
operator|!=
name|NULL
condition|)
block|{
name|kmem_free
argument_list|(
name|hdr
operator|->
name|b_freeze_cksum
argument_list|,
sizeof|sizeof
argument_list|(
name|zio_cksum_t
argument_list|)
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_freeze_cksum
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
while|while
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
condition|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
decl_stmt|;
if|if
condition|(
name|buf
operator|->
name|b_efunc
operator|!=
name|NULL
condition|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_hdr
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|arc_buf_destroy
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|=
name|buf
operator|->
name|b_next
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|=
operator|&
name|arc_eviction_hdr
expr_stmt|;
name|buf
operator|->
name|b_next
operator|=
name|arc_eviction_list
expr_stmt|;
name|arc_eviction_list
operator|=
name|buf
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|cv_signal
argument_list|(
operator|&
name|arc_user_evicts_cv
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_buf_destroy
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
block|}
ifdef|#
directive|ifdef
name|ZFS_DEBUG
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|!=
name|NULL
condition|)
block|{
name|kmem_free
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|=
name|NULL
expr_stmt|;
block|}
endif|#
directive|endif
block|}
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_hash_next
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
operator|!
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|hdr_full_cache
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|kmem_cache_free
argument_list|(
name|hdr_l2only_cache
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|arc_buf_free
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|int
name|hashed
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|!=
name|arc_anon
decl_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_efunc
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|hashed
condition|)
block|{
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|buf
operator|->
name|b_hdr
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hash_lock
argument_list|,
operator|==
argument_list|,
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|remove_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|tag
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|1
condition|)
block|{
name|arc_buf_destroy
argument_list|(
name|buf
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|buf
operator|==
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_efunc
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_BUF_AVAILABLE
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|int
name|destroy_hdr
decl_stmt|;
comment|/* 		 * We are in the middle of an async write.  Don't destroy 		 * this buffer unless the write completes before we finish 		 * decrementing the reference count. 		 */
name|mutex_enter
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|remove_reference
argument_list|(
name|hdr
argument_list|,
name|NULL
argument_list|,
name|tag
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|destroy_hdr
operator|=
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|destroy_hdr
condition|)
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|remove_reference
argument_list|(
name|hdr
argument_list|,
name|NULL
argument_list|,
name|tag
argument_list|)
operator|>
literal|0
condition|)
name|arc_buf_destroy
argument_list|(
name|buf
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
else|else
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|boolean_t
name|arc_buf_remove_ref
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|boolean_t
name|no_callback
init|=
operator|(
name|buf
operator|->
name|b_efunc
operator|==
name|NULL
operator|)
decl_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
condition|)
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|==
literal|1
argument_list|)
expr_stmt|;
name|arc_buf_free
argument_list|(
name|buf
argument_list|,
name|tag
argument_list|)
expr_stmt|;
return|return
operator|(
name|no_callback
operator|)
return|;
block|}
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|buf
operator|->
name|b_hdr
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|0
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hash_lock
argument_list|,
operator|==
argument_list|,
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|!=
name|arc_anon
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|remove_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|tag
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|1
condition|)
block|{
if|if
condition|(
name|no_callback
condition|)
name|arc_buf_destroy
argument_list|(
name|buf
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|no_callback
condition|)
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|==
name|buf
operator|&&
name|buf
operator|->
name|b_next
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_efunc
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_BUF_AVAILABLE
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|no_callback
operator|||
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|1
operator|||
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|no_callback
operator|)
return|;
block|}
end_function

begin_function
name|int32_t
name|arc_buf_size
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
return|return
operator|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_size
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Called from the DMU to determine if the current buffer should be  * evicted. In order to ensure proper locking, the eviction must be initiated  * from the DMU. Return true if the buffer is associated with user data and  * duplicate buffers still exist.  */
end_comment

begin_function
name|boolean_t
name|arc_buf_eviction_needed
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|boolean_t
name|evict_needed
init|=
name|B_FALSE
decl_stmt|;
if|if
condition|(
name|zfs_disable_dup_eviction
condition|)
return|return
operator|(
name|B_FALSE
operator|)
return|;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|buf
operator|->
name|b_hdr
expr_stmt|;
if|if
condition|(
name|hdr
operator|==
name|NULL
condition|)
block|{
comment|/* 		 * We are in arc_do_user_evicts(); let that function 		 * perform the eviction. 		 */
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_data
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|buf
operator|->
name|b_data
operator|==
name|NULL
condition|)
block|{
comment|/* 		 * We have already been added to the arc eviction list; 		 * recommend eviction. 		 */
name|ASSERT3P
argument_list|(
name|hdr
argument_list|,
operator|==
argument_list|,
operator|&
name|arc_eviction_hdr
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_TRUE
operator|)
return|;
block|}
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|1
operator|&&
name|HDR_ISTYPE_DATA
argument_list|(
name|hdr
argument_list|)
condition|)
name|evict_needed
operator|=
name|B_TRUE
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|evict_needed
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict the arc_buf_hdr that is provided as a parameter. The resultant  * state of the header is dependent on it's state prior to entering this  * function. The following transitions are possible:  *  *    - arc_mru -> arc_mru_ghost  *    - arc_mfu -> arc_mfu_ghost  *    - arc_mru_ghost -> arc_l2c_only  *    - arc_mru_ghost -> deleted  *    - arc_mfu_ghost -> arc_l2c_only  *    - arc_mfu_ghost -> deleted  */
end_comment

begin_function
specifier|static
name|int64_t
name|arc_evict_hdr
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
name|hash_lock
parameter_list|)
block|{
name|arc_state_t
modifier|*
name|evicted_state
decl_stmt|,
modifier|*
name|state
decl_stmt|;
name|int64_t
name|bytes_evicted
init|=
literal|0
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|state
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|state
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|==
name|NULL
argument_list|)
expr_stmt|;
comment|/* 		 * l2arc_write_buffers() relies on a header's L1 portion 		 * (i.e. it's b_tmp_cdata field) during it's write phase. 		 * Thus, we cannot push a header onto the arc_l2c_only 		 * state (removing it's L1 piece) until the header is 		 * done being written to the l2arc. 		 */
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
operator|&&
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_evict_l2_skip
argument_list|)
expr_stmt|;
return|return
operator|(
name|bytes_evicted
operator|)
return|;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_deleted
argument_list|)
expr_stmt|;
name|bytes_evicted
operator|+=
name|hdr
operator|->
name|b_size
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|arc__delete
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
comment|/* 			 * This buffer is cached on the 2nd Level ARC; 			 * don't destroy the header. 			 */
name|arc_change_state
argument_list|(
name|arc_l2c_only
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
comment|/* 			 * dropping from L1+L2 cached to L2-only, 			 * realloc to remove the L1 header. 			 */
name|hdr
operator|=
name|arc_hdr_realloc
argument_list|(
name|hdr
argument_list|,
name|hdr_full_cache
argument_list|,
name|hdr_l2only_cache
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|bytes_evicted
operator|)
return|;
block|}
name|ASSERT
argument_list|(
name|state
operator|==
name|arc_mru
operator|||
name|state
operator|==
name|arc_mfu
argument_list|)
expr_stmt|;
name|evicted_state
operator|=
operator|(
name|state
operator|==
name|arc_mru
operator|)
condition|?
name|arc_mru_ghost
else|:
name|arc_mfu_ghost
expr_stmt|;
comment|/* prefetch buffers have a minimum lifespan */
if|if
condition|(
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
operator|||
operator|(
operator|(
name|hdr
operator|->
name|b_flags
operator|&
operator|(
name|ARC_FLAG_PREFETCH
operator||
name|ARC_FLAG_INDIRECT
operator|)
operator|)
operator|&&
name|ddi_get_lbolt
argument_list|()
operator|-
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|<
name|arc_min_prefetch_lifespan
operator|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_evict_skip
argument_list|)
expr_stmt|;
return|return
operator|(
name|bytes_evicted
operator|)
return|;
block|}
name|ASSERT0
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
while|while
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
condition|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
decl_stmt|;
if|if
condition|(
operator|!
name|mutex_tryenter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mutex_miss
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
condition|)
name|bytes_evicted
operator|+=
name|hdr
operator|->
name|b_size
expr_stmt|;
if|if
condition|(
name|buf
operator|->
name|b_efunc
operator|!=
name|NULL
condition|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
name|arc_buf_destroy
argument_list|(
name|buf
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|=
name|buf
operator|->
name|b_next
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|=
operator|&
name|arc_eviction_hdr
expr_stmt|;
name|buf
operator|->
name|b_next
operator|=
name|arc_eviction_list
expr_stmt|;
name|arc_eviction_list
operator|=
name|buf
expr_stmt|;
name|cv_signal
argument_list|(
operator|&
name|arc_user_evicts_cv
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|arc_buf_destroy
argument_list|(
name|buf
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_INCR
argument_list|(
name|arcstat_evict_l2_cached
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|l2arc_write_eligible
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
name|hdr
argument_list|)
condition|)
name|ARCSTAT_INCR
argument_list|(
name|arcstat_evict_l2_eligible
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
else|else
name|ARCSTAT_INCR
argument_list|(
name|arcstat_evict_l2_ineligible
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|==
literal|0
condition|)
block|{
name|arc_change_state
argument_list|(
name|evicted_state
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_IN_HASH_TABLE
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_BUF_AVAILABLE
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|arc__evict
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|bytes_evicted
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|arc_evict_state_impl
parameter_list|(
name|multilist_t
modifier|*
name|ml
parameter_list|,
name|int
name|idx
parameter_list|,
name|arc_buf_hdr_t
modifier|*
name|marker
parameter_list|,
name|uint64_t
name|spa
parameter_list|,
name|int64_t
name|bytes
parameter_list|)
block|{
name|multilist_sublist_t
modifier|*
name|mls
decl_stmt|;
name|uint64_t
name|bytes_evicted
init|=
literal|0
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|int
name|evict_count
init|=
literal|0
decl_stmt|;
name|ASSERT3P
argument_list|(
name|marker
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|IMPLY
argument_list|(
name|bytes
operator|<
literal|0
argument_list|,
name|bytes
operator|==
name|ARC_EVICT_ALL
argument_list|)
expr_stmt|;
name|mls
operator|=
name|multilist_sublist_lock
argument_list|(
name|ml
argument_list|,
name|idx
argument_list|)
expr_stmt|;
for|for
control|(
name|hdr
operator|=
name|multilist_sublist_prev
argument_list|(
name|mls
argument_list|,
name|marker
argument_list|)
init|;
name|hdr
operator|!=
name|NULL
condition|;
name|hdr
operator|=
name|multilist_sublist_prev
argument_list|(
name|mls
argument_list|,
name|marker
argument_list|)
control|)
block|{
if|if
condition|(
operator|(
name|bytes
operator|!=
name|ARC_EVICT_ALL
operator|&&
name|bytes_evicted
operator|>=
name|bytes
operator|)
operator|||
operator|(
name|evict_count
operator|>=
name|zfs_arc_evict_batch_limit
operator|)
condition|)
break|break;
comment|/* 		 * To keep our iteration location, move the marker 		 * forward. Since we're not holding hdr's hash lock, we 		 * must be very careful and not remove 'hdr' from the 		 * sublist. Otherwise, other consumers might mistake the 		 * 'hdr' as not being on a sublist when they call the 		 * multilist_link_active() function (they all rely on 		 * the hash lock protecting concurrent insertions and 		 * removals). multilist_sublist_move_forward() was 		 * specifically implemented to ensure this is the case 		 * (only 'marker' will be removed and re-inserted). 		 */
name|multilist_sublist_move_forward
argument_list|(
name|mls
argument_list|,
name|marker
argument_list|)
expr_stmt|;
comment|/* 		 * The only case where the b_spa field should ever be 		 * zero, is the marker headers inserted by 		 * arc_evict_state(). It's possible for multiple threads 		 * to be calling arc_evict_state() concurrently (e.g. 		 * dsl_pool_close() and zio_inject_fault()), so we must 		 * skip any markers we see from these other threads. 		 */
if|if
condition|(
name|hdr
operator|->
name|b_spa
operator|==
literal|0
condition|)
continue|continue;
comment|/* we're only interested in evicting buffers of a certain spa */
if|if
condition|(
name|spa
operator|!=
literal|0
operator|&&
name|hdr
operator|->
name|b_spa
operator|!=
name|spa
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_evict_skip
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* 		 * We aren't calling this function from any code path 		 * that would already be holding a hash lock, so we're 		 * asserting on this assumption to be defensive in case 		 * this ever changes. Without this check, it would be 		 * possible to incorrectly increment arcstat_mutex_miss 		 * below (e.g. if the code changed such that we called 		 * this function with a hash lock held). 		 */
name|ASSERT
argument_list|(
operator|!
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|mutex_tryenter
argument_list|(
name|hash_lock
argument_list|)
condition|)
block|{
name|uint64_t
name|evicted
init|=
name|arc_evict_hdr
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
decl_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|bytes_evicted
operator|+=
name|evicted
expr_stmt|;
comment|/* 			 * If evicted is zero, arc_evict_hdr() must have 			 * decided to skip this header, don't increment 			 * evict_count in this case. 			 */
if|if
condition|(
name|evicted
operator|!=
literal|0
condition|)
name|evict_count
operator|++
expr_stmt|;
comment|/* 			 * If arc_size isn't overflowing, signal any 			 * threads that might happen to be waiting. 			 * 			 * For each header evicted, we wake up a single 			 * thread. If we used cv_broadcast, we could 			 * wake up "too many" threads causing arc_size 			 * to significantly overflow arc_c; since 			 * arc_get_data_buf() doesn't check for overflow 			 * when it's woken up (it doesn't because it's 			 * possible for the ARC to be overflowing while 			 * full of un-evictable buffers, and the 			 * function should proceed in this case). 			 * 			 * If threads are left sleeping, due to not 			 * using cv_broadcast, they will be woken up 			 * just before arc_reclaim_thread() sleeps. 			 */
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|arc_is_overflowing
argument_list|()
condition|)
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mutex_miss
argument_list|)
expr_stmt|;
block|}
block|}
name|multilist_sublist_unlock
argument_list|(
name|mls
argument_list|)
expr_stmt|;
return|return
operator|(
name|bytes_evicted
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict buffers from the given arc state, until we've removed the  * specified number of bytes. Move the removed buffers to the  * appropriate evict state.  *  * This function makes a "best effort". It skips over any buffers  * it can't get a hash_lock on, and so, may not catch all candidates.  * It may also return without evicting as much space as requested.  *  * If bytes is specified using the special value ARC_EVICT_ALL, this  * will evict all available (i.e. unlocked and evictable) buffers from  * the given arc state; which is used by arc_flush().  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_evict_state
parameter_list|(
name|arc_state_t
modifier|*
name|state
parameter_list|,
name|uint64_t
name|spa
parameter_list|,
name|int64_t
name|bytes
parameter_list|,
name|arc_buf_contents_t
name|type
parameter_list|)
block|{
name|uint64_t
name|total_evicted
init|=
literal|0
decl_stmt|;
name|multilist_t
modifier|*
name|ml
init|=
operator|&
name|state
operator|->
name|arcs_list
index|[
name|type
index|]
decl_stmt|;
name|int
name|num_sublists
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
modifier|*
name|markers
decl_stmt|;
name|IMPLY
argument_list|(
name|bytes
operator|<
literal|0
argument_list|,
name|bytes
operator|==
name|ARC_EVICT_ALL
argument_list|)
expr_stmt|;
name|num_sublists
operator|=
name|multilist_get_num_sublists
argument_list|(
name|ml
argument_list|)
expr_stmt|;
comment|/* 	 * If we've tried to evict from each sublist, made some 	 * progress, but still have not hit the target number of bytes 	 * to evict, we want to keep trying. The markers allow us to 	 * pick up where we left off for each individual sublist, rather 	 * than starting from the tail each time. 	 */
name|markers
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
operator|*
name|markers
argument_list|)
operator|*
name|num_sublists
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|num_sublists
condition|;
name|i
operator|++
control|)
block|{
name|markers
index|[
name|i
index|]
operator|=
name|kmem_cache_alloc
argument_list|(
name|hdr_full_cache
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
comment|/* 		 * A b_spa of 0 is used to indicate that this header is 		 * a marker. This fact is used in arc_adjust_type() and 		 * arc_evict_state_impl(). 		 */
name|markers
index|[
name|i
index|]
operator|->
name|b_spa
operator|=
literal|0
expr_stmt|;
name|multilist_sublist_t
modifier|*
name|mls
init|=
name|multilist_sublist_lock
argument_list|(
name|ml
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|multilist_sublist_insert_tail
argument_list|(
name|mls
argument_list|,
name|markers
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|multilist_sublist_unlock
argument_list|(
name|mls
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * While we haven't hit our target number of bytes to evict, or 	 * we're evicting all available buffers. 	 */
while|while
condition|(
name|total_evicted
operator|<
name|bytes
operator|||
name|bytes
operator|==
name|ARC_EVICT_ALL
condition|)
block|{
comment|/* 		 * Start eviction using a randomly selected sublist, 		 * this is to try and evenly balance eviction across all 		 * sublists. Always starting at the same sublist 		 * (e.g. index 0) would cause evictions to favor certain 		 * sublists over others. 		 */
name|int
name|sublist_idx
init|=
name|multilist_get_random_index
argument_list|(
name|ml
argument_list|)
decl_stmt|;
name|uint64_t
name|scan_evicted
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|num_sublists
condition|;
name|i
operator|++
control|)
block|{
name|uint64_t
name|bytes_remaining
decl_stmt|;
name|uint64_t
name|bytes_evicted
decl_stmt|;
if|if
condition|(
name|bytes
operator|==
name|ARC_EVICT_ALL
condition|)
name|bytes_remaining
operator|=
name|ARC_EVICT_ALL
expr_stmt|;
elseif|else
if|if
condition|(
name|total_evicted
operator|<
name|bytes
condition|)
name|bytes_remaining
operator|=
name|bytes
operator|-
name|total_evicted
expr_stmt|;
else|else
break|break;
name|bytes_evicted
operator|=
name|arc_evict_state_impl
argument_list|(
name|ml
argument_list|,
name|sublist_idx
argument_list|,
name|markers
index|[
name|sublist_idx
index|]
argument_list|,
name|spa
argument_list|,
name|bytes_remaining
argument_list|)
expr_stmt|;
name|scan_evicted
operator|+=
name|bytes_evicted
expr_stmt|;
name|total_evicted
operator|+=
name|bytes_evicted
expr_stmt|;
comment|/* we've reached the end, wrap to the beginning */
if|if
condition|(
operator|++
name|sublist_idx
operator|>=
name|num_sublists
condition|)
name|sublist_idx
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 		 * If we didn't evict anything during this scan, we have 		 * no reason to believe we'll evict more during another 		 * scan, so break the loop. 		 */
if|if
condition|(
name|scan_evicted
operator|==
literal|0
condition|)
block|{
comment|/* This isn't possible, let's make that obvious */
name|ASSERT3S
argument_list|(
name|bytes
argument_list|,
operator|!=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 			 * When bytes is ARC_EVICT_ALL, the only way to 			 * break the loop is when scan_evicted is zero. 			 * In that case, we actually have evicted enough, 			 * so we don't want to increment the kstat. 			 */
if|if
condition|(
name|bytes
operator|!=
name|ARC_EVICT_ALL
condition|)
block|{
name|ASSERT3S
argument_list|(
name|total_evicted
argument_list|,
operator|<
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_evict_not_enough
argument_list|)
expr_stmt|;
block|}
break|break;
block|}
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|num_sublists
condition|;
name|i
operator|++
control|)
block|{
name|multilist_sublist_t
modifier|*
name|mls
init|=
name|multilist_sublist_lock
argument_list|(
name|ml
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|multilist_sublist_remove
argument_list|(
name|mls
argument_list|,
name|markers
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|multilist_sublist_unlock
argument_list|(
name|mls
argument_list|)
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|hdr_full_cache
argument_list|,
name|markers
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
name|kmem_free
argument_list|(
name|markers
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|markers
argument_list|)
operator|*
name|num_sublists
argument_list|)
expr_stmt|;
return|return
operator|(
name|total_evicted
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Flush all "evictable" data of the given type from the arc state  * specified. This will not evict any "active" buffers (i.e. referenced).  *  * When 'retry' is set to FALSE, the function will make a single pass  * over the state and evict any buffers that it can. Since it doesn't  * continually retry the eviction, it might end up leaving some buffers  * in the ARC due to lock misses.  *  * When 'retry' is set to TRUE, the function will continually retry the  * eviction until *all* evictable buffers have been removed from the  * state. As a result, if concurrent insertions into the state are  * allowed (e.g. if the ARC isn't shutting down), this function might  * wind up in an infinite loop, continually trying to evict buffers.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_flush_state
parameter_list|(
name|arc_state_t
modifier|*
name|state
parameter_list|,
name|uint64_t
name|spa
parameter_list|,
name|arc_buf_contents_t
name|type
parameter_list|,
name|boolean_t
name|retry
parameter_list|)
block|{
name|uint64_t
name|evicted
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|state
operator|->
name|arcs_lsize
index|[
name|type
index|]
operator|!=
literal|0
condition|)
block|{
name|evicted
operator|+=
name|arc_evict_state
argument_list|(
name|state
argument_list|,
name|spa
argument_list|,
name|ARC_EVICT_ALL
argument_list|,
name|type
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|retry
condition|)
break|break;
block|}
return|return
operator|(
name|evicted
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict the specified number of bytes from the state specified,  * restricting eviction to the spa and type given. This function  * prevents us from trying to evict more from a state's list than  * is "evictable", and to skip evicting altogether when passed a  * negative value for "bytes". In contrast, arc_evict_state() will  * evict everything it can, when passed a negative value for "bytes".  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_adjust_impl
parameter_list|(
name|arc_state_t
modifier|*
name|state
parameter_list|,
name|uint64_t
name|spa
parameter_list|,
name|int64_t
name|bytes
parameter_list|,
name|arc_buf_contents_t
name|type
parameter_list|)
block|{
name|int64_t
name|delta
decl_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
operator|&&
name|state
operator|->
name|arcs_lsize
index|[
name|type
index|]
operator|>
literal|0
condition|)
block|{
name|delta
operator|=
name|MIN
argument_list|(
name|state
operator|->
name|arcs_lsize
index|[
name|type
index|]
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
return|return
operator|(
name|arc_evict_state
argument_list|(
name|state
argument_list|,
name|spa
argument_list|,
name|delta
argument_list|,
name|type
argument_list|)
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict metadata buffers from the cache, such that arc_meta_used is  * capped by the arc_meta_limit tunable.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_adjust_meta
parameter_list|(
name|void
parameter_list|)
block|{
name|uint64_t
name|total_evicted
init|=
literal|0
decl_stmt|;
name|int64_t
name|target
decl_stmt|;
comment|/* 	 * If we're over the meta limit, we want to evict enough 	 * metadata to get back under the meta limit. We don't want to 	 * evict so much that we drop the MRU below arc_p, though. If 	 * we're over the meta limit more than we're over arc_p, we 	 * evict some from the MRU here, and some from the MFU below. 	 */
name|target
operator|=
name|MIN
argument_list|(
call|(
name|int64_t
call|)
argument_list|(
name|arc_meta_used
operator|-
name|arc_meta_limit
argument_list|)
argument_list|,
call|(
name|int64_t
call|)
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
operator|+
name|refcount_count
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
operator|-
name|arc_p
argument_list|)
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mru
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
comment|/* 	 * Similar to the above, we want to evict enough bytes to get us 	 * below the meta limit, but not so much as to drop us below the 	 * space alloted to the MFU (which is defined as arc_c - arc_p). 	 */
name|target
operator|=
name|MIN
argument_list|(
call|(
name|int64_t
call|)
argument_list|(
name|arc_meta_used
operator|-
name|arc_meta_limit
argument_list|)
argument_list|,
call|(
name|int64_t
call|)
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_size
argument_list|)
operator|-
operator|(
name|arc_c
operator|-
name|arc_p
operator|)
argument_list|)
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mfu
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
return|return
operator|(
name|total_evicted
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return the type of the oldest buffer in the given arc state  *  * This function will select a random sublist of type ARC_BUFC_DATA and  * a random sublist of type ARC_BUFC_METADATA. The tail of each sublist  * is compared, and the type which contains the "older" buffer will be  * returned.  */
end_comment

begin_function
specifier|static
name|arc_buf_contents_t
name|arc_adjust_type
parameter_list|(
name|arc_state_t
modifier|*
name|state
parameter_list|)
block|{
name|multilist_t
modifier|*
name|data_ml
init|=
operator|&
name|state
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
decl_stmt|;
name|multilist_t
modifier|*
name|meta_ml
init|=
operator|&
name|state
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
decl_stmt|;
name|int
name|data_idx
init|=
name|multilist_get_random_index
argument_list|(
name|data_ml
argument_list|)
decl_stmt|;
name|int
name|meta_idx
init|=
name|multilist_get_random_index
argument_list|(
name|meta_ml
argument_list|)
decl_stmt|;
name|multilist_sublist_t
modifier|*
name|data_mls
decl_stmt|;
name|multilist_sublist_t
modifier|*
name|meta_mls
decl_stmt|;
name|arc_buf_contents_t
name|type
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|data_hdr
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|meta_hdr
decl_stmt|;
comment|/* 	 * We keep the sublist lock until we're finished, to prevent 	 * the headers from being destroyed via arc_evict_state(). 	 */
name|data_mls
operator|=
name|multilist_sublist_lock
argument_list|(
name|data_ml
argument_list|,
name|data_idx
argument_list|)
expr_stmt|;
name|meta_mls
operator|=
name|multilist_sublist_lock
argument_list|(
name|meta_ml
argument_list|,
name|meta_idx
argument_list|)
expr_stmt|;
comment|/* 	 * These two loops are to ensure we skip any markers that 	 * might be at the tail of the lists due to arc_evict_state(). 	 */
for|for
control|(
name|data_hdr
operator|=
name|multilist_sublist_tail
argument_list|(
name|data_mls
argument_list|)
init|;
name|data_hdr
operator|!=
name|NULL
condition|;
name|data_hdr
operator|=
name|multilist_sublist_prev
argument_list|(
name|data_mls
argument_list|,
name|data_hdr
argument_list|)
control|)
block|{
if|if
condition|(
name|data_hdr
operator|->
name|b_spa
operator|!=
literal|0
condition|)
break|break;
block|}
for|for
control|(
name|meta_hdr
operator|=
name|multilist_sublist_tail
argument_list|(
name|meta_mls
argument_list|)
init|;
name|meta_hdr
operator|!=
name|NULL
condition|;
name|meta_hdr
operator|=
name|multilist_sublist_prev
argument_list|(
name|meta_mls
argument_list|,
name|meta_hdr
argument_list|)
control|)
block|{
if|if
condition|(
name|meta_hdr
operator|->
name|b_spa
operator|!=
literal|0
condition|)
break|break;
block|}
if|if
condition|(
name|data_hdr
operator|==
name|NULL
operator|&&
name|meta_hdr
operator|==
name|NULL
condition|)
block|{
name|type
operator|=
name|ARC_BUFC_DATA
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|data_hdr
operator|==
name|NULL
condition|)
block|{
name|ASSERT3P
argument_list|(
name|meta_hdr
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|type
operator|=
name|ARC_BUFC_METADATA
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|meta_hdr
operator|==
name|NULL
condition|)
block|{
name|ASSERT3P
argument_list|(
name|data_hdr
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|type
operator|=
name|ARC_BUFC_DATA
expr_stmt|;
block|}
else|else
block|{
name|ASSERT3P
argument_list|(
name|data_hdr
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|meta_hdr
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* The headers can't be on the sublist without an L1 header */
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|data_hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|meta_hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|data_hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|<
name|meta_hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
condition|)
block|{
name|type
operator|=
name|ARC_BUFC_DATA
expr_stmt|;
block|}
else|else
block|{
name|type
operator|=
name|ARC_BUFC_METADATA
expr_stmt|;
block|}
block|}
name|multilist_sublist_unlock
argument_list|(
name|meta_mls
argument_list|)
expr_stmt|;
name|multilist_sublist_unlock
argument_list|(
name|data_mls
argument_list|)
expr_stmt|;
return|return
operator|(
name|type
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict buffers from the cache, such that arc_size is capped by arc_c.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_adjust
parameter_list|(
name|void
parameter_list|)
block|{
name|uint64_t
name|total_evicted
init|=
literal|0
decl_stmt|;
name|uint64_t
name|bytes
decl_stmt|;
name|int64_t
name|target
decl_stmt|;
comment|/* 	 * If we're over arc_meta_limit, we want to correct that before 	 * potentially evicting data buffers below. 	 */
name|total_evicted
operator|+=
name|arc_adjust_meta
argument_list|()
expr_stmt|;
comment|/* 	 * Adjust MRU size 	 * 	 * If we're over the target cache size, we want to evict enough 	 * from the list to get back to our target size. We don't want 	 * to evict too much from the MRU, such that it drops below 	 * arc_p. So, if we're over our target cache size more than 	 * the MRU is over arc_p, we'll evict enough to get back to 	 * arc_p here, and then evict more from the MFU below. 	 */
name|target
operator|=
name|MIN
argument_list|(
call|(
name|int64_t
call|)
argument_list|(
name|arc_size
operator|-
name|arc_c
argument_list|)
argument_list|,
call|(
name|int64_t
call|)
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
operator|+
name|refcount_count
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
operator|+
name|arc_meta_used
operator|-
name|arc_p
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * If we're below arc_meta_min, always prefer to evict data. 	 * Otherwise, try to satisfy the requested number of bytes to 	 * evict from the type which contains older buffers; in an 	 * effort to keep newer buffers in the cache regardless of their 	 * type. If we cannot satisfy the number of bytes from this 	 * type, spill over into the next type. 	 */
if|if
condition|(
name|arc_adjust_type
argument_list|(
name|arc_mru
argument_list|)
operator|==
name|ARC_BUFC_METADATA
operator|&&
name|arc_meta_used
operator|>
name|arc_meta_min
condition|)
block|{
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mru
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
comment|/* 		 * If we couldn't evict our target number of bytes from 		 * metadata, we try to get the rest from data. 		 */
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mru
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mru
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
comment|/* 		 * If we couldn't evict our target number of bytes from 		 * data, we try to get the rest from metadata. 		 */
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mru
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Adjust MFU size 	 * 	 * Now that we've tried to evict enough from the MRU to get its 	 * size back to arc_p, if we're still above the target cache 	 * size, we evict the rest from the MFU. 	 */
name|target
operator|=
name|arc_size
operator|-
name|arc_c
expr_stmt|;
if|if
condition|(
name|arc_adjust_type
argument_list|(
name|arc_mfu
argument_list|)
operator|==
name|ARC_BUFC_METADATA
operator|&&
name|arc_meta_used
operator|>
name|arc_meta_min
condition|)
block|{
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mfu
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
comment|/* 		 * If we couldn't evict our target number of bytes from 		 * metadata, we try to get the rest from data. 		 */
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mfu
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mfu
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
comment|/* 		 * If we couldn't evict our target number of bytes from 		 * data, we try to get the rest from data. 		 */
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mfu
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Adjust ghost lists 	 * 	 * In addition to the above, the ARC also defines target values 	 * for the ghost lists. The sum of the mru list and mru ghost 	 * list should never exceed the target size of the cache, and 	 * the sum of the mru list, mfu list, mru ghost list, and mfu 	 * ghost list should never exceed twice the target size of the 	 * cache. The following logic enforces these limits on the ghost 	 * caches, and evicts from them as needed. 	 */
name|target
operator|=
name|refcount_count
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
operator|+
name|refcount_count
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_size
argument_list|)
operator|-
name|arc_c
expr_stmt|;
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mru_ghost
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mru_ghost
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
comment|/* 	 * We assume the sum of the mru list and mfu list is less than 	 * or equal to arc_c (we enforced this above), which means we 	 * can use the simpler of the two equations below: 	 * 	 *	mru + mfu + mru ghost + mfu ghost<= 2 * arc_c 	 *		    mru ghost + mfu ghost<= arc_c 	 */
name|target
operator|=
name|refcount_count
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_size
argument_list|)
operator|+
name|refcount_count
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_size
argument_list|)
operator|-
name|arc_c
expr_stmt|;
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mfu_ghost
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mfu_ghost
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
return|return
operator|(
name|total_evicted
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_do_user_evicts
parameter_list|(
name|void
parameter_list|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
while|while
condition|(
name|arc_eviction_list
operator|!=
name|NULL
condition|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|arc_eviction_list
decl_stmt|;
name|arc_eviction_list
operator|=
name|buf
operator|->
name|b_next
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|=
name|NULL
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf
operator|->
name|b_efunc
operator|!=
name|NULL
condition|)
name|VERIFY0
argument_list|(
name|buf
operator|->
name|b_efunc
argument_list|(
name|buf
operator|->
name|b_private
argument_list|)
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_efunc
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_private
operator|=
name|NULL
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|buf_cache
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|arc_flush
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|boolean_t
name|retry
parameter_list|)
block|{
name|uint64_t
name|guid
init|=
literal|0
decl_stmt|;
comment|/* 	 * If retry is TRUE, a spa must not be specified since we have 	 * no good way to determine if all of a spa's buffers have been 	 * evicted from an arc state. 	 */
name|ASSERT
argument_list|(
operator|!
name|retry
operator|||
name|spa
operator|==
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|spa
operator|!=
name|NULL
condition|)
name|guid
operator|=
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mru
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_DATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mru
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_METADATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mfu
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_DATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mfu
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_METADATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mru_ghost
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_DATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mru_ghost
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_METADATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mfu_ghost
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_DATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mfu_ghost
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_METADATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
name|arc_do_user_evicts
argument_list|()
expr_stmt|;
name|ASSERT
argument_list|(
name|spa
operator|||
name|arc_eviction_list
operator|==
name|NULL
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|arc_shrink
parameter_list|(
name|int64_t
name|to_free
parameter_list|)
block|{
if|if
condition|(
name|arc_c
operator|>
name|arc_c_min
condition|)
block|{
name|DTRACE_PROBE4
argument_list|(
name|arc__shrink
argument_list|,
name|uint64_t
argument_list|,
name|arc_c
argument_list|,
name|uint64_t
argument_list|,
name|arc_c_min
argument_list|,
name|uint64_t
argument_list|,
name|arc_p
argument_list|,
name|uint64_t
argument_list|,
name|to_free
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_c
operator|>
name|arc_c_min
operator|+
name|to_free
condition|)
name|atomic_add_64
argument_list|(
operator|&
name|arc_c
argument_list|,
operator|-
name|to_free
argument_list|)
expr_stmt|;
else|else
name|arc_c
operator|=
name|arc_c_min
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_p
argument_list|,
operator|-
operator|(
name|arc_p
operator|>>
name|arc_shrink_shift
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_c
operator|>
name|arc_size
condition|)
name|arc_c
operator|=
name|MAX
argument_list|(
name|arc_size
argument_list|,
name|arc_c_min
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_p
operator|>
name|arc_c
condition|)
name|arc_p
operator|=
operator|(
name|arc_c
operator|>>
literal|1
operator|)
expr_stmt|;
name|DTRACE_PROBE2
argument_list|(
name|arc__shrunk
argument_list|,
name|uint64_t
argument_list|,
name|arc_c
argument_list|,
name|uint64_t
argument_list|,
name|arc_p
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|arc_c
operator|>=
name|arc_c_min
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|(
name|int64_t
operator|)
name|arc_p
operator|>=
literal|0
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|arc_size
operator|>
name|arc_c
condition|)
block|{
name|DTRACE_PROBE2
argument_list|(
name|arc__shrink_adjust
argument_list|,
name|uint64_t
argument_list|,
name|arc_size
argument_list|,
name|uint64_t
argument_list|,
name|arc_c
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_adjust
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_decl_stmt
specifier|static
name|long
name|needfree
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_typedef
typedef|typedef
enum|enum
name|free_memory_reason_t
block|{
name|FMR_UNKNOWN
block|,
name|FMR_NEEDFREE
block|,
name|FMR_LOTSFREE
block|,
name|FMR_SWAPFS_MINFREE
block|,
name|FMR_PAGES_PP_MAXIMUM
block|,
name|FMR_HEAP_ARENA
block|,
name|FMR_ZIO_ARENA
block|,
name|FMR_ZIO_FRAG
block|, }
name|free_memory_reason_t
typedef|;
end_typedef

begin_decl_stmt
name|int64_t
name|last_free_memory
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|free_memory_reason_t
name|last_free_reason
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Additional reserve of pages for pp_reserve.  */
end_comment

begin_decl_stmt
name|int64_t
name|arc_pages_pp_reserve
init|=
literal|64
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Additional reserve of pages for swapfs.  */
end_comment

begin_decl_stmt
name|int64_t
name|arc_swapfs_reserve
init|=
literal|64
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Return the amount of memory that can be consumed before reclaim will be  * needed.  Positive if there is sufficient free memory, negative indicates  * the amount of memory that needs to be freed up.  */
end_comment

begin_function
specifier|static
name|int64_t
name|arc_available_memory
parameter_list|(
name|void
parameter_list|)
block|{
name|int64_t
name|lowest
init|=
name|INT64_MAX
decl_stmt|;
name|int64_t
name|n
decl_stmt|;
name|free_memory_reason_t
name|r
init|=
name|FMR_UNKNOWN
decl_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
if|if
condition|(
name|needfree
operator|>
literal|0
condition|)
block|{
name|n
operator|=
name|PAGESIZE
operator|*
operator|(
operator|-
name|needfree
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_NEEDFREE
expr_stmt|;
block|}
block|}
comment|/* 	 * Cooperate with pagedaemon when it's time for it to scan 	 * and reclaim some pages. 	 */
name|n
operator|=
name|PAGESIZE
operator|*
operator|(
operator|(
name|int64_t
operator|)
name|freemem
operator|-
name|zfs_arc_free_target
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_LOTSFREE
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|sun
comment|/* 	 * check that we're out of range of the pageout scanner.  It starts to 	 * schedule paging if freemem is less than lotsfree and needfree. 	 * lotsfree is the high-water mark for pageout, and needfree is the 	 * number of needed free pages.  We add extra pages here to make sure 	 * the scanner doesn't start up while we're freeing memory. 	 */
name|n
operator|=
name|PAGESIZE
operator|*
operator|(
name|freemem
operator|-
name|lotsfree
operator|-
name|needfree
operator|-
name|desfree
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_LOTSFREE
expr_stmt|;
block|}
comment|/* 	 * check to make sure that swapfs has enough space so that anon 	 * reservations can still succeed. anon_resvmem() checks that the 	 * availrmem is greater than swapfs_minfree, and the number of reserved 	 * swap pages.  We also add a bit of extra here just to prevent 	 * circumstances from getting really dire. 	 */
name|n
operator|=
name|PAGESIZE
operator|*
operator|(
name|availrmem
operator|-
name|swapfs_minfree
operator|-
name|swapfs_reserve
operator|-
name|desfree
operator|-
name|arc_swapfs_reserve
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_SWAPFS_MINFREE
expr_stmt|;
block|}
comment|/* 	 * Check that we have enough availrmem that memory locking (e.g., via 	 * mlock(3C) or memcntl(2)) can still succeed.  (pages_pp_maximum 	 * stores the number of pages that cannot be locked; when availrmem 	 * drops below pages_pp_maximum, page locking mechanisms such as 	 * page_pp_lock() will fail.) 	 */
name|n
operator|=
name|PAGESIZE
operator|*
operator|(
name|availrmem
operator|-
name|pages_pp_maximum
operator|-
name|arc_pages_pp_reserve
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_PAGES_PP_MAXIMUM
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* sun */
if|#
directive|if
name|defined
argument_list|(
name|__i386
argument_list|)
operator|||
operator|!
name|defined
argument_list|(
name|UMA_MD_SMALL_ALLOC
argument_list|)
comment|/* 	 * If we're on an i386 platform, it's possible that we'll exhaust the 	 * kernel heap space before we ever run out of available physical 	 * memory.  Most checks of the size of the heap_area compare against 	 * tune.t_minarmem, which is the minimum available real memory that we 	 * can have in the system.  However, this is generally fixed at 25 pages 	 * which is so low that it's useless.  In this comparison, we seek to 	 * calculate the total heap-size, and reclaim if more than 3/4ths of the 	 * heap is allocated.  (Or, in the calculation, if less than 1/4th is 	 * free) 	 */
name|n
operator|=
operator|(
name|int64_t
operator|)
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_FREE
argument_list|)
operator|-
operator|(
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_FREE
operator||
name|VMEM_ALLOC
argument_list|)
operator|>>
literal|2
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_HEAP_ARENA
expr_stmt|;
block|}
define|#
directive|define
name|zio_arena
value|NULL
else|#
directive|else
define|#
directive|define
name|zio_arena
value|heap_arena
endif|#
directive|endif
comment|/* 	 * If zio data pages are being allocated out of a separate heap segment, 	 * then enforce that the size of available vmem for this arena remains 	 * above about 1/16th free. 	 * 	 * Note: The 1/16th arena free requirement was put in place 	 * to aggressively evict memory from the arc in order to avoid 	 * memory fragmentation issues. 	 */
if|if
condition|(
name|zio_arena
operator|!=
name|NULL
condition|)
block|{
name|n
operator|=
operator|(
name|int64_t
operator|)
name|vmem_size
argument_list|(
name|zio_arena
argument_list|,
name|VMEM_FREE
argument_list|)
operator|-
operator|(
name|vmem_size
argument_list|(
name|zio_arena
argument_list|,
name|VMEM_ALLOC
argument_list|)
operator|>>
literal|4
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_ZIO_ARENA
expr_stmt|;
block|}
block|}
comment|/* 	 * Above limits know nothing about real level of KVA fragmentation. 	 * Start aggressive reclamation if too little sequential KVA left. 	 */
if|if
condition|(
name|lowest
operator|>
literal|0
condition|)
block|{
name|n
operator|=
operator|(
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_MAXFREE
argument_list|)
operator|<
name|zfs_max_recordsize
operator|)
condition|?
operator|-
operator|(
operator|(
name|int64_t
operator|)
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_ALLOC
argument_list|)
operator|>>
literal|4
operator|)
else|:
name|INT64_MAX
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_ZIO_FRAG
expr_stmt|;
block|}
block|}
else|#
directive|else
comment|/* _KERNEL */
comment|/* Every 100 calls, free a small amount */
if|if
condition|(
name|spa_get_random
argument_list|(
literal|100
argument_list|)
operator|==
literal|0
condition|)
name|lowest
operator|=
operator|-
literal|1024
expr_stmt|;
endif|#
directive|endif
comment|/* _KERNEL */
name|last_free_memory
operator|=
name|lowest
expr_stmt|;
name|last_free_reason
operator|=
name|r
expr_stmt|;
name|DTRACE_PROBE2
argument_list|(
name|arc__available_memory
argument_list|,
name|int64_t
argument_list|,
name|lowest
argument_list|,
name|int
argument_list|,
name|r
argument_list|)
expr_stmt|;
return|return
operator|(
name|lowest
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Determine if the system is under memory pressure and is asking  * to reclaim memory. A return value of TRUE indicates that the system  * is under memory pressure and that the arc should adjust accordingly.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|arc_reclaim_needed
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
name|arc_available_memory
argument_list|()
operator|<
literal|0
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|extern
name|kmem_cache_t
modifier|*
name|zio_buf_cache
index|[]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|kmem_cache_t
modifier|*
name|zio_data_buf_cache
index|[]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|kmem_cache_t
modifier|*
name|range_seg_cache
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|__noinline
name|void
name|arc_kmem_reap_now
parameter_list|(
name|void
parameter_list|)
block|{
name|size_t
name|i
decl_stmt|;
name|kmem_cache_t
modifier|*
name|prev_cache
init|=
name|NULL
decl_stmt|;
name|kmem_cache_t
modifier|*
name|prev_data_cache
init|=
name|NULL
decl_stmt|;
name|DTRACE_PROBE
argument_list|(
name|arc__kmem_reap_start
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
if|if
condition|(
name|arc_meta_used
operator|>=
name|arc_meta_limit
condition|)
block|{
comment|/* 		 * We are exceeding our meta-data cache limit. 		 * Purge some DNLC entries to release holds on meta-data. 		 */
name|dnlc_reduce_cache
argument_list|(
operator|(
name|void
operator|*
operator|)
operator|(
name|uintptr_t
operator|)
name|arc_reduce_dnlc_percent
argument_list|)
expr_stmt|;
block|}
if|#
directive|if
name|defined
argument_list|(
name|__i386
argument_list|)
comment|/* 	 * Reclaim unused memory from all kmem caches. 	 */
name|kmem_reap
argument_list|()
expr_stmt|;
endif|#
directive|endif
endif|#
directive|endif
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|SPA_MAXBLOCKSIZE
operator|>>
name|SPA_MINBLOCKSHIFT
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|zio_buf_cache
index|[
name|i
index|]
operator|!=
name|prev_cache
condition|)
block|{
name|prev_cache
operator|=
name|zio_buf_cache
index|[
name|i
index|]
expr_stmt|;
name|kmem_cache_reap_now
argument_list|(
name|zio_buf_cache
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|zio_data_buf_cache
index|[
name|i
index|]
operator|!=
name|prev_data_cache
condition|)
block|{
name|prev_data_cache
operator|=
name|zio_data_buf_cache
index|[
name|i
index|]
expr_stmt|;
name|kmem_cache_reap_now
argument_list|(
name|zio_data_buf_cache
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
name|kmem_cache_reap_now
argument_list|(
name|buf_cache
argument_list|)
expr_stmt|;
name|kmem_cache_reap_now
argument_list|(
name|hdr_full_cache
argument_list|)
expr_stmt|;
name|kmem_cache_reap_now
argument_list|(
name|hdr_l2only_cache
argument_list|)
expr_stmt|;
name|kmem_cache_reap_now
argument_list|(
name|range_seg_cache
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|sun
if|if
condition|(
name|zio_arena
operator|!=
name|NULL
condition|)
block|{
comment|/* 		 * Ask the vmem arena to reclaim unused memory from its 		 * quantum caches. 		 */
name|vmem_qcache_reap
argument_list|(
name|zio_arena
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|DTRACE_PROBE
argument_list|(
name|arc__kmem_reap_end
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Threads can block in arc_get_data_buf() waiting for this thread to evict  * enough data and signal them to proceed. When this happens, the threads in  * arc_get_data_buf() are sleeping while holding the hash lock for their  * particular arc header. Thus, we must be careful to never sleep on a  * hash lock in this thread. This is to prevent the following deadlock:  *  *  - Thread A sleeps on CV in arc_get_data_buf() holding hash lock "L",  *    waiting for the reclaim thread to signal it.  *  *  - arc_reclaim_thread() tries to acquire hash lock "L" using mutex_enter,  *    fails, and goes to sleep forever.  *  * This possible deadlock is avoided by always acquiring a hash lock  * using mutex_tryenter() from arc_reclaim_thread().  */
end_comment

begin_function
specifier|static
name|void
name|arc_reclaim_thread
parameter_list|(
name|void
modifier|*
name|dummy
name|__unused
parameter_list|)
block|{
name|clock_t
name|growtime
init|=
literal|0
decl_stmt|;
name|callb_cpr_t
name|cpr
decl_stmt|;
name|CALLB_CPR_INIT
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|,
name|callb_generic_cpr
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
while|while
condition|(
operator|!
name|arc_reclaim_thread_exit
condition|)
block|{
name|int64_t
name|free_memory
init|=
name|arc_available_memory
argument_list|()
decl_stmt|;
name|uint64_t
name|evicted
init|=
literal|0
decl_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|free_memory
operator|<
literal|0
condition|)
block|{
name|arc_no_grow
operator|=
name|B_TRUE
expr_stmt|;
name|arc_warm
operator|=
name|B_TRUE
expr_stmt|;
comment|/* 			 * Wait at least zfs_grow_retry (default 60) seconds 			 * before considering growing. 			 */
name|growtime
operator|=
name|ddi_get_lbolt
argument_list|()
operator|+
operator|(
name|arc_grow_retry
operator|*
name|hz
operator|)
expr_stmt|;
name|arc_kmem_reap_now
argument_list|()
expr_stmt|;
comment|/* 			 * If we are still low on memory, shrink the ARC 			 * so that we have arc_shrink_min free space. 			 */
name|free_memory
operator|=
name|arc_available_memory
argument_list|()
expr_stmt|;
name|int64_t
name|to_free
init|=
operator|(
name|arc_c
operator|>>
name|arc_shrink_shift
operator|)
operator|-
name|free_memory
decl_stmt|;
if|if
condition|(
name|to_free
operator|>
literal|0
condition|)
block|{
ifdef|#
directive|ifdef
name|_KERNEL
name|to_free
operator|=
name|MAX
argument_list|(
name|to_free
argument_list|,
name|ptob
argument_list|(
name|needfree
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|arc_shrink
argument_list|(
name|to_free
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|free_memory
operator|<
name|arc_c
operator|>>
name|arc_no_grow_shift
condition|)
block|{
name|arc_no_grow
operator|=
name|B_TRUE
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ddi_get_lbolt
argument_list|()
operator|>=
name|growtime
condition|)
block|{
name|arc_no_grow
operator|=
name|B_FALSE
expr_stmt|;
block|}
name|evicted
operator|=
name|arc_adjust
argument_list|()
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
comment|/* 		 * If evicted is zero, we couldn't evict anything via 		 * arc_adjust(). This could be due to hash lock 		 * collisions, but more likely due to the majority of 		 * arc buffers being unevictable. Therefore, even if 		 * arc_size is above arc_c, another pass is unlikely to 		 * be helpful and could potentially cause us to enter an 		 * infinite loop. 		 */
if|if
condition|(
name|arc_size
operator|<=
name|arc_c
operator|||
name|evicted
operator|==
literal|0
condition|)
block|{
ifdef|#
directive|ifdef
name|_KERNEL
name|needfree
operator|=
literal|0
expr_stmt|;
endif|#
directive|endif
comment|/* 			 * We're either no longer overflowing, or we 			 * can't evict anything more, so we should wake 			 * up any threads before we go to sleep. 			 */
name|cv_broadcast
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|)
expr_stmt|;
comment|/* 			 * Block until signaled, or after one second (we 			 * might need to perform arc_kmem_reap_now() 			 * even if we aren't being signalled) 			 */
name|CALLB_CPR_SAFE_BEGIN
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|cv_timedwait
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|,
name|hz
argument_list|)
expr_stmt|;
name|CALLB_CPR_SAFE_END
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
block|}
name|arc_reclaim_thread_exit
operator|=
name|FALSE
expr_stmt|;
name|cv_broadcast
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
name|CALLB_CPR_EXIT
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
comment|/* drops arc_reclaim_lock */
name|thread_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_user_evicts_thread
parameter_list|(
name|void
modifier|*
name|dummy
name|__unused
parameter_list|)
block|{
name|callb_cpr_t
name|cpr
decl_stmt|;
name|CALLB_CPR_INIT
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|arc_user_evicts_lock
argument_list|,
name|callb_generic_cpr
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
while|while
condition|(
operator|!
name|arc_user_evicts_thread_exit
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
name|arc_do_user_evicts
argument_list|()
expr_stmt|;
comment|/* 		 * This is necessary in order for the mdb ::arc dcmd to 		 * show up to date information. Since the ::arc command 		 * does not call the kstat's update function, without 		 * this call, the command may show stale stats for the 		 * anon, mru, mru_ghost, mfu, and mfu_ghost lists. Even 		 * with this change, the data might be up to 1 second 		 * out of date; but that should suffice. The arc_state_t 		 * structures can be queried directly if more accurate 		 * information is needed. 		 */
if|if
condition|(
name|arc_ksp
operator|!=
name|NULL
condition|)
name|arc_ksp
operator|->
name|ks_update
argument_list|(
name|arc_ksp
argument_list|,
name|KSTAT_READ
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
comment|/* 		 * Block until signaled, or after one second (we need to 		 * call the arc's kstat update function regularly). 		 */
name|CALLB_CPR_SAFE_BEGIN
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|cv_timedwait
argument_list|(
operator|&
name|arc_user_evicts_cv
argument_list|,
operator|&
name|arc_user_evicts_lock
argument_list|,
name|hz
argument_list|)
expr_stmt|;
name|CALLB_CPR_SAFE_END
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
block|}
name|arc_user_evicts_thread_exit
operator|=
name|FALSE
expr_stmt|;
name|cv_broadcast
argument_list|(
operator|&
name|arc_user_evicts_cv
argument_list|)
expr_stmt|;
name|CALLB_CPR_EXIT
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
comment|/* drops arc_user_evicts_lock */
name|thread_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Adapt arc info given the number of bytes we are trying to add and  * the state that we are comming from.  This function is only called  * when we are adding new content to the cache.  */
end_comment

begin_function
specifier|static
name|void
name|arc_adapt
parameter_list|(
name|int
name|bytes
parameter_list|,
name|arc_state_t
modifier|*
name|state
parameter_list|)
block|{
name|int
name|mult
decl_stmt|;
name|uint64_t
name|arc_p_min
init|=
operator|(
name|arc_c
operator|>>
name|arc_p_min_shift
operator|)
decl_stmt|;
name|int64_t
name|mrug_size
init|=
name|refcount_count
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_size
argument_list|)
decl_stmt|;
name|int64_t
name|mfug_size
init|=
name|refcount_count
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_size
argument_list|)
decl_stmt|;
if|if
condition|(
name|state
operator|==
name|arc_l2c_only
condition|)
return|return;
name|ASSERT
argument_list|(
name|bytes
operator|>
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * Adapt the target size of the MRU list: 	 *	- if we just hit in the MRU ghost list, then increase 	 *	  the target size of the MRU list. 	 *	- if we just hit in the MFU ghost list, then increase 	 *	  the target size of the MFU list by decreasing the 	 *	  target size of the MRU list. 	 */
if|if
condition|(
name|state
operator|==
name|arc_mru_ghost
condition|)
block|{
name|mult
operator|=
operator|(
name|mrug_size
operator|>=
name|mfug_size
operator|)
condition|?
literal|1
else|:
operator|(
name|mfug_size
operator|/
name|mrug_size
operator|)
expr_stmt|;
name|mult
operator|=
name|MIN
argument_list|(
name|mult
argument_list|,
literal|10
argument_list|)
expr_stmt|;
comment|/* avoid wild arc_p adjustment */
name|arc_p
operator|=
name|MIN
argument_list|(
name|arc_c
operator|-
name|arc_p_min
argument_list|,
name|arc_p
operator|+
name|bytes
operator|*
name|mult
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|state
operator|==
name|arc_mfu_ghost
condition|)
block|{
name|uint64_t
name|delta
decl_stmt|;
name|mult
operator|=
operator|(
name|mfug_size
operator|>=
name|mrug_size
operator|)
condition|?
literal|1
else|:
operator|(
name|mrug_size
operator|/
name|mfug_size
operator|)
expr_stmt|;
name|mult
operator|=
name|MIN
argument_list|(
name|mult
argument_list|,
literal|10
argument_list|)
expr_stmt|;
name|delta
operator|=
name|MIN
argument_list|(
name|bytes
operator|*
name|mult
argument_list|,
name|arc_p
argument_list|)
expr_stmt|;
name|arc_p
operator|=
name|MAX
argument_list|(
name|arc_p_min
argument_list|,
name|arc_p
operator|-
name|delta
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
operator|(
name|int64_t
operator|)
name|arc_p
operator|>=
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_reclaim_needed
argument_list|()
condition|)
block|{
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|arc_no_grow
condition|)
return|return;
if|if
condition|(
name|arc_c
operator|>=
name|arc_c_max
condition|)
return|return;
comment|/* 	 * If we're within (2 * maxblocksize) bytes of the target 	 * cache size, increment the target cache size 	 */
if|if
condition|(
name|arc_size
operator|>
name|arc_c
operator|-
operator|(
literal|2ULL
operator|<<
name|SPA_MAXBLOCKSHIFT
operator|)
condition|)
block|{
name|DTRACE_PROBE1
argument_list|(
name|arc__inc_adapt
argument_list|,
name|int
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_c
argument_list|,
operator|(
name|int64_t
operator|)
name|bytes
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_c
operator|>
name|arc_c_max
condition|)
name|arc_c
operator|=
name|arc_c_max
expr_stmt|;
elseif|else
if|if
condition|(
name|state
operator|==
name|arc_anon
condition|)
name|atomic_add_64
argument_list|(
operator|&
name|arc_p
argument_list|,
operator|(
name|int64_t
operator|)
name|bytes
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_p
operator|>
name|arc_c
condition|)
name|arc_p
operator|=
name|arc_c
expr_stmt|;
block|}
name|ASSERT
argument_list|(
operator|(
name|int64_t
operator|)
name|arc_p
operator|>=
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Check if arc_size has grown past our upper threshold, determined by  * zfs_arc_overflow_shift.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|arc_is_overflowing
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* Always allow at least one block of overflow */
name|uint64_t
name|overflow
init|=
name|MAX
argument_list|(
name|SPA_MAXBLOCKSIZE
argument_list|,
name|arc_c
operator|>>
name|zfs_arc_overflow_shift
argument_list|)
decl_stmt|;
return|return
operator|(
name|arc_size
operator|>=
name|arc_c
operator|+
name|overflow
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * The buffer, supplied as the first argument, needs a data block. If we  * are hitting the hard limit for the cache size, we must sleep, waiting  * for the eviction thread to catch up. If we're past the target size  * but below the hard limit, we'll only signal the reclaim thread and  * continue on.  */
end_comment

begin_function
specifier|static
name|void
name|arc_get_data_buf
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_state_t
modifier|*
name|state
init|=
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|uint64_t
name|size
init|=
name|buf
operator|->
name|b_hdr
operator|->
name|b_size
decl_stmt|;
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
decl_stmt|;
name|arc_adapt
argument_list|(
name|size
argument_list|,
name|state
argument_list|)
expr_stmt|;
comment|/* 	 * If arc_size is currently overflowing, and has grown past our 	 * upper limit, we must be adding data faster than the evict 	 * thread can evict. Thus, to ensure we don't compound the 	 * problem by adding more data and forcing arc_size to grow even 	 * further past it's target size, we halt and wait for the 	 * eviction thread to catch up. 	 * 	 * It's also possible that the reclaim thread is unable to evict 	 * enough buffers to get arc_size below the overflow limit (e.g. 	 * due to buffers being un-evictable, or hash lock collisions). 	 * In this case, we want to proceed regardless if we're 	 * overflowing; thus we don't use a while loop here. 	 */
if|if
condition|(
name|arc_is_overflowing
argument_list|()
condition|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
comment|/* 		 * Now that we've acquired the lock, we may no longer be 		 * over the overflow limit, lets check. 		 * 		 * We're ignoring the case of spurious wake ups. If that 		 * were to happen, it'd let this thread consume an ARC 		 * buffer before it should have (i.e. before we're under 		 * the overflow limit and were signalled by the reclaim 		 * thread). As long as that is a rare occurrence, it 		 * shouldn't cause any harm. 		 */
if|if
condition|(
name|arc_is_overflowing
argument_list|()
condition|)
block|{
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
name|cv_wait
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|type
operator|==
name|ARC_BUFC_METADATA
condition|)
block|{
name|buf
operator|->
name|b_data
operator|=
name|zio_buf_alloc
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|arc_space_consume
argument_list|(
name|size
argument_list|,
name|ARC_SPACE_META
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|type
operator|==
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_data
operator|=
name|zio_data_buf_alloc
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|arc_space_consume
argument_list|(
name|size
argument_list|,
name|ARC_SPACE_DATA
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Update the state size.  Note that ghost states have a 	 * "ghost size" and so don't need to be updated. 	 */
if|if
condition|(
operator|!
name|GHOST_STATE
argument_list|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|)
condition|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|,
name|size
argument_list|,
name|buf
argument_list|)
expr_stmt|;
comment|/* 		 * If this is reached via arc_read, the link is 		 * protected by the hash lock. If reached via 		 * arc_buf_alloc, the header should not be accessed by 		 * any other thread. And, if reached via arc_read_done, 		 * the hash lock will protect it if it's found in the 		 * hash table; otherwise no other thread should be 		 * trying to [add|remove]_reference it. 		 */
if|if
condition|(
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|->
name|arcs_lsize
index|[
name|type
index|]
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * If we are growing the cache, and we are adding anonymous 		 * data, and we have outgrown arc_p, update arc_p 		 */
if|if
condition|(
name|arc_size
operator|<
name|arc_c
operator|&&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
operator|&&
operator|(
name|refcount_count
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
operator|+
name|refcount_count
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
operator|>
name|arc_p
operator|)
condition|)
name|arc_p
operator|=
name|MIN
argument_list|(
name|arc_c
argument_list|,
name|arc_p
operator|+
name|size
argument_list|)
expr_stmt|;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_allocated
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine is called whenever a buffer is accessed.  * NOTE: the hash lock is dropped in this function.  */
end_comment

begin_function
specifier|static
name|void
name|arc_access
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
name|hash_lock
parameter_list|)
block|{
name|clock_t
name|now
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
condition|)
block|{
comment|/* 		 * This buffer is not in the cache, and does not 		 * appear in our "ghost" list.  Add the new buffer 		 * to the MRU state. 		 */
name|ASSERT0
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mru
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|arc_mru
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mru
condition|)
block|{
name|now
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
comment|/* 		 * If this buffer is here because of a prefetch, then either: 		 * - clear the flag if this is a "referencing" read 		 *   (any subsequent access will bump this into the MFU state). 		 * or 		 * - move the buffer to the head of the list if this is 		 *   another prefetch (to make it less likely to be evicted). 		 */
if|if
condition|(
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
if|if
condition|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|==
literal|0
condition|)
block|{
comment|/* link protected by hash lock */
name|ASSERT
argument_list|(
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_PREFETCH
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mru_hits
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|now
expr_stmt|;
return|return;
block|}
comment|/* 		 * This buffer has been "accessed" only once so far, 		 * but it is still in the cache. Move it to the MFU 		 * state. 		 */
if|if
condition|(
name|now
operator|>
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|+
name|ARC_MINTIME
condition|)
block|{
comment|/* 			 * More than 125ms have passed since we 			 * instantiated this buffer.  Move it to the 			 * most frequently used state. 			 */
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|now
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mfu
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|arc_mfu
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mru_hits
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mru_ghost
condition|)
block|{
name|arc_state_t
modifier|*
name|new_state
decl_stmt|;
comment|/* 		 * This buffer has been "accessed" recently, but 		 * was evicted from the cache.  Move it to the 		 * MFU state. 		 */
if|if
condition|(
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|new_state
operator|=
name|arc_mru
expr_stmt|;
if|if
condition|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|>
literal|0
condition|)
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_PREFETCH
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mru
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|new_state
operator|=
name|arc_mfu
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mfu
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
name|arc_change_state
argument_list|(
name|new_state
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mru_ghost_hits
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mfu
condition|)
block|{
comment|/* 		 * This buffer has been accessed more than once and is 		 * still in the cache.  Keep it in the MFU state. 		 * 		 * NOTE: an add_reference() that occurred when we did 		 * the arc_read() will have kicked this off the list. 		 * If it was a prefetch, we will explicitly move it to 		 * the head of the list now. 		 */
if|if
condition|(
operator|(
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
comment|/* link protected by hash_lock */
name|ASSERT
argument_list|(
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mfu_hits
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mfu_ghost
condition|)
block|{
name|arc_state_t
modifier|*
name|new_state
init|=
name|arc_mfu
decl_stmt|;
comment|/* 		 * This buffer has been accessed more than once but has 		 * been evicted from the cache.  Move it back to the 		 * MFU state. 		 */
if|if
condition|(
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
comment|/* 			 * This is a prefetch access... 			 * move this block back to the MRU state. 			 */
name|ASSERT0
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|new_state
operator|=
name|arc_mru
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mfu
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|new_state
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mfu_ghost_hits
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_l2c_only
condition|)
block|{
comment|/* 		 * This buffer is on the 2nd Level ARC. 		 */
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mfu
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|arc_mfu
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
operator|!
literal|"invalid arc state"
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/* a generic arc_done_func_t which you can use */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
name|void
name|arc_bcopy_func
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|,
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|arg
parameter_list|)
block|{
if|if
condition|(
name|zio
operator|==
name|NULL
operator|||
name|zio
operator|->
name|io_error
operator|==
literal|0
condition|)
name|bcopy
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|arg
argument_list|,
name|buf
operator|->
name|b_hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
name|VERIFY
argument_list|(
name|arc_buf_remove_ref
argument_list|(
name|buf
argument_list|,
name|arg
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* a generic arc_done_func_t */
end_comment

begin_function
name|void
name|arc_getbuf_func
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|,
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|arc_buf_t
modifier|*
modifier|*
name|bufp
init|=
name|arg
decl_stmt|;
if|if
condition|(
name|zio
operator|&&
name|zio
operator|->
name|io_error
condition|)
block|{
name|VERIFY
argument_list|(
name|arc_buf_remove_ref
argument_list|(
name|buf
argument_list|,
name|arg
argument_list|)
argument_list|)
expr_stmt|;
operator|*
name|bufp
operator|=
name|NULL
expr_stmt|;
block|}
else|else
block|{
operator|*
name|bufp
operator|=
name|buf
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_data
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|arc_read_done
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|arc_buf_t
modifier|*
name|buf
decl_stmt|;
name|arc_buf_t
modifier|*
name|abuf
decl_stmt|;
comment|/* buffer we're assigning to callback */
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|NULL
decl_stmt|;
name|arc_callback_t
modifier|*
name|callback_list
decl_stmt|,
modifier|*
name|acb
decl_stmt|;
name|int
name|freeable
init|=
name|FALSE
decl_stmt|;
name|buf
operator|=
name|zio
operator|->
name|io_private
expr_stmt|;
name|hdr
operator|=
name|buf
operator|->
name|b_hdr
expr_stmt|;
comment|/* 	 * The hdr was inserted into hash-table and removed from lists 	 * prior to starting I/O.  We should find this header, since 	 * it's in the hash table, and it should be legit since it's 	 * not possible to evict it during the I/O.  The only possible 	 * reason for it not to be found is if we were freed during the 	 * read. 	 */
if|if
condition|(
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_birth
argument_list|,
operator|==
argument_list|,
name|BP_PHYSICAL_BIRTH
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_dva
operator|.
name|dva_word
index|[
literal|0
index|]
argument_list|,
operator|==
argument_list|,
name|BP_IDENTITY
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|->
name|dva_word
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_dva
operator|.
name|dva_word
index|[
literal|1
index|]
argument_list|,
operator|==
argument_list|,
name|BP_IDENTITY
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|->
name|dva_word
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
name|arc_buf_hdr_t
modifier|*
name|found
init|=
name|buf_hash_find
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|,
operator|&
name|hash_lock
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|(
name|found
operator|==
name|NULL
operator|&&
name|HDR_FREED_IN_READ
argument_list|(
name|hdr
argument_list|)
operator|&&
name|hash_lock
operator|==
name|NULL
operator|)
operator|||
operator|(
name|found
operator|==
name|hdr
operator|&&
name|DVA_EQUAL
argument_list|(
operator|&
name|hdr
operator|->
name|b_dva
argument_list|,
name|BP_IDENTITY
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|)
operator|)
operator|||
operator|(
name|found
operator|==
name|hdr
operator|&&
name|HDR_L2_READING
argument_list|(
name|hdr
argument_list|)
operator|)
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_L2_EVICTED
expr_stmt|;
if|if
condition|(
name|l2arc_noprefetch
operator|&&
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
condition|)
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_L2CACHE
expr_stmt|;
comment|/* byteswap if necessary */
name|callback_list
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
expr_stmt|;
name|ASSERT
argument_list|(
name|callback_list
operator|!=
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|BP_SHOULD_BYTESWAP
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|&&
name|zio
operator|->
name|io_error
operator|==
literal|0
condition|)
block|{
name|dmu_object_byteswap_t
name|bswap
init|=
name|DMU_OT_BYTESWAP
argument_list|(
name|BP_GET_TYPE
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|)
decl_stmt|;
name|arc_byteswap_func_t
modifier|*
name|func
init|=
name|BP_GET_LEVEL
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|>
literal|0
condition|?
name|byteswap_uint64_array
else|:
name|dmu_ot_byteswap
index|[
name|bswap
index|]
operator|.
name|ob_func
decl_stmt|;
name|func
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
block|}
name|arc_cksum_compute
argument_list|(
name|buf
argument_list|,
name|B_FALSE
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
name|arc_buf_watch
argument_list|(
name|buf
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* illumos */
if|if
condition|(
name|hash_lock
operator|&&
name|zio
operator|->
name|io_error
operator|==
literal|0
operator|&&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
condition|)
block|{
comment|/* 		 * Only call arc_access on anonymous buffers.  This is because 		 * if we've issued an I/O for an evicted buffer, we've already 		 * called arc_access (to prevent any simultaneous readers from 		 * getting confused). 		 */
name|arc_access
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
block|}
comment|/* create copies of the data buffer for the callers */
name|abuf
operator|=
name|buf
expr_stmt|;
for|for
control|(
name|acb
operator|=
name|callback_list
init|;
name|acb
condition|;
name|acb
operator|=
name|acb
operator|->
name|acb_next
control|)
block|{
if|if
condition|(
name|acb
operator|->
name|acb_done
condition|)
block|{
if|if
condition|(
name|abuf
operator|==
name|NULL
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_duplicate_reads
argument_list|)
expr_stmt|;
name|abuf
operator|=
name|arc_buf_clone
argument_list|(
name|buf
argument_list|)
expr_stmt|;
block|}
name|acb
operator|->
name|acb_buf
operator|=
name|abuf
expr_stmt|;
name|abuf
operator|=
name|NULL
expr_stmt|;
block|}
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
operator|=
name|NULL
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_IO_IN_PROGRESS
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_BUF_AVAILABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|abuf
operator|==
name|buf
condition|)
block|{
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_efunc
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|==
literal|1
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_BUF_AVAILABLE
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|||
name|callback_list
operator|!=
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio
operator|->
name|io_error
operator|!=
literal|0
condition|)
block|{
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_IO_ERROR
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|!=
name|arc_anon
condition|)
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
condition|)
name|buf_hash_remove
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|freeable
operator|=
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Broadcast before we drop the hash_lock to avoid the possibility 	 * that the hdr (and hence the cv) might be freed before we get to 	 * the cv_broadcast(). 	 */
name|cv_broadcast
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_cv
argument_list|)
expr_stmt|;
if|if
condition|(
name|hash_lock
operator|!=
name|NULL
condition|)
block|{
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * This block was freed while we waited for the read to 		 * complete.  It has been removed from the hash table and 		 * moved to the anonymous state (so that it won't show up 		 * in the cache). 		 */
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|,
operator|==
argument_list|,
name|arc_anon
argument_list|)
expr_stmt|;
name|freeable
operator|=
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
expr_stmt|;
block|}
comment|/* execute each callback and free its structure */
while|while
condition|(
operator|(
name|acb
operator|=
name|callback_list
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|acb
operator|->
name|acb_done
condition|)
name|acb
operator|->
name|acb_done
argument_list|(
name|zio
argument_list|,
name|acb
operator|->
name|acb_buf
argument_list|,
name|acb
operator|->
name|acb_private
argument_list|)
expr_stmt|;
if|if
condition|(
name|acb
operator|->
name|acb_zio_dummy
operator|!=
name|NULL
condition|)
block|{
name|acb
operator|->
name|acb_zio_dummy
operator|->
name|io_error
operator|=
name|zio
operator|->
name|io_error
expr_stmt|;
name|zio_nowait
argument_list|(
name|acb
operator|->
name|acb_zio_dummy
argument_list|)
expr_stmt|;
block|}
name|callback_list
operator|=
name|acb
operator|->
name|acb_next
expr_stmt|;
name|kmem_free
argument_list|(
name|acb
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_callback_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|freeable
condition|)
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * "Read" the block at the specified DVA (in bp) via the  * cache.  If the block is found in the cache, invoke the provided  * callback immediately and return.  Note that the `zio' parameter  * in the callback will be NULL in this case, since no IO was  * required.  If the block is not in the cache pass the read request  * on to the spa with a substitute callback function, so that the  * requested block will be added to the cache.  *  * If a read request arrives for a block that has a read in-progress,  * either wait for the in-progress read to complete (and return the  * results); or, if this is a read with a "done" func, add a record  * to the read to invoke the "done" func when the read completes,  * and return; or just return.  *  * arc_read_done() will invoke all the requested "done" functions  * for readers of this block.  */
end_comment

begin_function
name|int
name|arc_read
parameter_list|(
name|zio_t
modifier|*
name|pio
parameter_list|,
name|spa_t
modifier|*
name|spa
parameter_list|,
specifier|const
name|blkptr_t
modifier|*
name|bp
parameter_list|,
name|arc_done_func_t
modifier|*
name|done
parameter_list|,
name|void
modifier|*
name|private
parameter_list|,
name|zio_priority_t
name|priority
parameter_list|,
name|int
name|zio_flags
parameter_list|,
name|arc_flags_t
modifier|*
name|arc_flags
parameter_list|,
specifier|const
name|zbookmark_phys_t
modifier|*
name|zb
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|NULL
decl_stmt|;
name|arc_buf_t
modifier|*
name|buf
init|=
name|NULL
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|NULL
decl_stmt|;
name|zio_t
modifier|*
name|rzio
decl_stmt|;
name|uint64_t
name|guid
init|=
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|BP_IS_EMBEDDED
argument_list|(
name|bp
argument_list|)
operator|||
name|BPE_GET_ETYPE
argument_list|(
name|bp
argument_list|)
operator|==
name|BP_EMBEDDED_TYPE_DATA
argument_list|)
expr_stmt|;
name|top
label|:
if|if
condition|(
operator|!
name|BP_IS_EMBEDDED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
comment|/* 		 * Embedded BP's have no DVA and require no I/O to "read". 		 * Create an anonymous arc buf to back it. 		 */
name|hdr
operator|=
name|buf_hash_find
argument_list|(
name|guid
argument_list|,
name|bp
argument_list|,
operator|&
name|hash_lock
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hdr
operator|!=
name|NULL
operator|&&
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
operator|&&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|0
condition|)
block|{
operator|*
name|arc_flags
operator||=
name|ARC_FLAG_CACHED
expr_stmt|;
if|if
condition|(
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
if|if
condition|(
operator|(
name|hdr
operator|->
name|b_flags
operator|&
name|ARC_FLAG_PRIO_ASYNC_READ
operator|)
operator|&&
name|priority
operator|==
name|ZIO_PRIORITY_SYNC_READ
condition|)
block|{
comment|/* 				 * This sync read must wait for an 				 * in-progress async read (e.g. a predictive 				 * prefetch).  Async reads are queued 				 * separately at the vdev_queue layer, so 				 * this is a form of priority inversion. 				 * Ideally, we would "inherit" the demand 				 * i/o's priority by moving the i/o from 				 * the async queue to the synchronous queue, 				 * but there is currently no mechanism to do 				 * so.  Track this so that we can evaluate 				 * the magnitude of this potential performance 				 * problem. 				 * 				 * Note that if the prefetch i/o is already 				 * active (has been issued to the device), 				 * the prefetch improved performance, because 				 * we issued it sooner than we would have 				 * without the prefetch. 				 */
name|DTRACE_PROBE1
argument_list|(
name|arc__sync__wait__for__async
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_sync_wait_for_async
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hdr
operator|->
name|b_flags
operator|&
name|ARC_FLAG_PREDICTIVE_PREFETCH
condition|)
block|{
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_PREDICTIVE_PREFETCH
expr_stmt|;
block|}
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_WAIT
condition|)
block|{
name|cv_wait
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_cv
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
goto|goto
name|top
goto|;
block|}
name|ASSERT
argument_list|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_NOWAIT
argument_list|)
expr_stmt|;
if|if
condition|(
name|done
condition|)
block|{
name|arc_callback_t
modifier|*
name|acb
init|=
name|NULL
decl_stmt|;
name|acb
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_callback_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|acb
operator|->
name|acb_done
operator|=
name|done
expr_stmt|;
name|acb
operator|->
name|acb_private
operator|=
name|private
expr_stmt|;
if|if
condition|(
name|pio
operator|!=
name|NULL
condition|)
name|acb
operator|->
name|acb_zio_dummy
operator|=
name|zio_null
argument_list|(
name|pio
argument_list|,
name|spa
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|zio_flags
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|acb
operator|->
name|acb_done
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|acb
operator|->
name|acb_next
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
operator|=
name|acb
expr_stmt|;
name|add_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|private
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mru
operator|||
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mfu
argument_list|)
expr_stmt|;
if|if
condition|(
name|done
condition|)
block|{
if|if
condition|(
name|hdr
operator|->
name|b_flags
operator|&
name|ARC_FLAG_PREDICTIVE_PREFETCH
condition|)
block|{
comment|/* 				 * This is a demand read which does not have to 				 * wait for i/o because we did a predictive 				 * prefetch i/o for it, which has completed. 				 */
name|DTRACE_PROBE1
argument_list|(
name|arc__demand__hit__predictive__prefetch
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_demand_hit_predictive_prefetch
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_PREDICTIVE_PREFETCH
expr_stmt|;
block|}
name|add_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|private
argument_list|)
expr_stmt|;
comment|/* 			 * If this block is already in use, create a new 			 * copy of the data so that we will be guaranteed 			 * that arc_release() will always succeed. 			 */
name|buf
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_data
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_BUF_AVAILABLE
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_efunc
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_BUF_AVAILABLE
expr_stmt|;
block|}
else|else
block|{
name|buf
operator|=
name|arc_buf_clone
argument_list|(
name|buf
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_PREFETCH
operator|&&
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|==
literal|0
condition|)
block|{
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_PREFETCH
expr_stmt|;
block|}
name|DTRACE_PROBE1
argument_list|(
name|arc__hit
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_access
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_L2CACHE
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2CACHE
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_L2COMPRESS
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2COMPRESS
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_hits
argument_list|)
expr_stmt|;
name|ARCSTAT_CONDSTAT
argument_list|(
operator|!
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|demand
argument_list|,
name|prefetch
argument_list|,
operator|!
name|HDR_ISTYPE_METADATA
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|data
argument_list|,
name|metadata
argument_list|,
name|hits
argument_list|)
expr_stmt|;
if|if
condition|(
name|done
condition|)
name|done
argument_list|(
name|NULL
argument_list|,
name|buf
argument_list|,
name|private
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|uint64_t
name|size
init|=
name|BP_GET_LSIZE
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|arc_callback_t
modifier|*
name|acb
decl_stmt|;
name|vdev_t
modifier|*
name|vd
init|=
name|NULL
decl_stmt|;
name|uint64_t
name|addr
init|=
literal|0
decl_stmt|;
name|boolean_t
name|devw
init|=
name|B_FALSE
decl_stmt|;
name|enum
name|zio_compress
name|b_compress
init|=
name|ZIO_COMPRESS_OFF
decl_stmt|;
name|int32_t
name|b_asize
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|hdr
operator|==
name|NULL
condition|)
block|{
comment|/* this block is not in the cache */
name|arc_buf_hdr_t
modifier|*
name|exists
init|=
name|NULL
decl_stmt|;
name|arc_buf_contents_t
name|type
init|=
name|BP_GET_BUFC_TYPE
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|buf
operator|=
name|arc_buf_alloc
argument_list|(
name|spa
argument_list|,
name|size
argument_list|,
name|private
argument_list|,
name|type
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|buf
operator|->
name|b_hdr
expr_stmt|;
if|if
condition|(
operator|!
name|BP_IS_EMBEDDED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|hdr
operator|->
name|b_dva
operator|=
operator|*
name|BP_IDENTITY
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_birth
operator|=
name|BP_PHYSICAL_BIRTH
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|exists
operator|=
name|buf_hash_insert
argument_list|(
name|hdr
argument_list|,
operator|&
name|hash_lock
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|exists
operator|!=
name|NULL
condition|)
block|{
comment|/* somebody beat us to the hash insert */
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_buf_remove_ref
argument_list|(
name|buf
argument_list|,
name|private
argument_list|)
expr_stmt|;
goto|goto
name|top
goto|;
comment|/* restart the IO request */
block|}
comment|/* 			 * If there is a callback, we pass our reference to 			 * it; otherwise we remove our reference. 			 */
if|if
condition|(
name|done
operator|==
name|NULL
condition|)
block|{
operator|(
name|void
operator|)
name|remove_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|private
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_PREFETCH
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_PREFETCH
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_L2CACHE
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2CACHE
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_L2COMPRESS
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2COMPRESS
expr_stmt|;
if|if
condition|(
name|BP_GET_LEVEL
argument_list|(
name|bp
argument_list|)
operator|>
literal|0
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_INDIRECT
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * This block is in the ghost cache. If it was L2-only 			 * (and thus didn't have an L1 hdr), we realloc the 			 * header to add an L1 hdr. 			 */
if|if
condition|(
operator|!
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|hdr
operator|=
name|arc_hdr_realloc
argument_list|(
name|hdr
argument_list|,
name|hdr_l2only_cache
argument_list|,
name|hdr_full_cache
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|GHOST_STATE
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 			 * If there is a callback, we pass a reference to it. 			 */
if|if
condition|(
name|done
operator|!=
name|NULL
condition|)
name|add_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|private
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_PREFETCH
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_PREFETCH
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_L2CACHE
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2CACHE
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_L2COMPRESS
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2COMPRESS
expr_stmt|;
name|buf
operator|=
name|kmem_cache_alloc
argument_list|(
name|buf_cache
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|=
name|hdr
expr_stmt|;
name|buf
operator|->
name|b_data
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_efunc
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_private
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_next
operator|=
name|NULL
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|=
name|buf
expr_stmt|;
name|ASSERT0
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|=
literal|1
expr_stmt|;
name|arc_get_data_buf
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|arc_access
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_PREDICTIVE_PREFETCH
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_PREDICTIVE_PREFETCH
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|GHOST_STATE
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|)
argument_list|)
expr_stmt|;
name|acb
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_callback_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|acb
operator|->
name|acb_done
operator|=
name|done
expr_stmt|;
name|acb
operator|->
name|acb_private
operator|=
name|private
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
operator|=
name|acb
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_IO_IN_PROGRESS
expr_stmt|;
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|(
name|vd
operator|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|->
name|l2ad_vdev
operator|)
operator|!=
name|NULL
condition|)
block|{
name|devw
operator|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|->
name|l2ad_writing
expr_stmt|;
name|addr
operator|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
expr_stmt|;
name|b_compress
operator|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_compress
expr_stmt|;
name|b_asize
operator|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
expr_stmt|;
comment|/* 			 * Lock out device removal. 			 */
if|if
condition|(
name|vdev_is_dead
argument_list|(
name|vd
argument_list|)
operator|||
operator|!
name|spa_config_tryenter
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|vd
argument_list|,
name|RW_READER
argument_list|)
condition|)
name|vd
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|hash_lock
operator|!=
name|NULL
condition|)
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
comment|/* 		 * At this point, we have a level 1 cache miss.  Try again in 		 * L2ARC if possible. 		 */
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_size
argument_list|,
operator|==
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|DTRACE_PROBE4
argument_list|(
name|arc__miss
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|,
name|blkptr_t
operator|*
argument_list|,
name|bp
argument_list|,
name|uint64_t
argument_list|,
name|size
argument_list|,
name|zbookmark_phys_t
operator|*
argument_list|,
name|zb
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_misses
argument_list|)
expr_stmt|;
name|ARCSTAT_CONDSTAT
argument_list|(
operator|!
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|demand
argument_list|,
name|prefetch
argument_list|,
operator|!
name|HDR_ISTYPE_METADATA
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|data
argument_list|,
name|metadata
argument_list|,
name|misses
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
name|curthread
operator|->
name|td_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|priority
operator|==
name|ZIO_PRIORITY_ASYNC_READ
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_PRIO_ASYNC_READ
expr_stmt|;
else|else
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_PRIO_ASYNC_READ
expr_stmt|;
if|if
condition|(
name|vd
operator|!=
name|NULL
operator|&&
name|l2arc_ndev
operator|!=
literal|0
operator|&&
operator|!
operator|(
name|l2arc_norw
operator|&&
name|devw
operator|)
condition|)
block|{
comment|/* 			 * Read from the L2ARC if the following are true: 			 * 1. The L2ARC vdev was previously cached. 			 * 2. This buffer still has L2ARC metadata. 			 * 3. This buffer isn't currently writing to the L2ARC. 			 * 4. The L2ARC entry wasn't evicted, which may 			 *    also have invalidated the vdev. 			 * 5. This isn't prefetch and l2arc_noprefetch is set. 			 */
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|!
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|!
name|HDR_L2_EVICTED
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|!
operator|(
name|l2arc_noprefetch
operator|&&
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
operator|)
condition|)
block|{
name|l2arc_read_callback_t
modifier|*
name|cb
decl_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|l2arc__hit
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_hits
argument_list|)
expr_stmt|;
name|cb
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|l2arc_read_callback_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|cb
operator|->
name|l2rcb_buf
operator|=
name|buf
expr_stmt|;
name|cb
operator|->
name|l2rcb_spa
operator|=
name|spa
expr_stmt|;
name|cb
operator|->
name|l2rcb_bp
operator|=
operator|*
name|bp
expr_stmt|;
name|cb
operator|->
name|l2rcb_zb
operator|=
operator|*
name|zb
expr_stmt|;
name|cb
operator|->
name|l2rcb_flags
operator|=
name|zio_flags
expr_stmt|;
name|cb
operator|->
name|l2rcb_compress
operator|=
name|b_compress
expr_stmt|;
name|ASSERT
argument_list|(
name|addr
operator|>=
name|VDEV_LABEL_START_SIZE
operator|&&
name|addr
operator|+
name|size
operator|<
name|vd
operator|->
name|vdev_psize
operator|-
name|VDEV_LABEL_END_SIZE
argument_list|)
expr_stmt|;
comment|/* 				 * l2arc read.  The SCL_L2ARC lock will be 				 * released by l2arc_read_done(). 				 * Issue a null zio if the underlying buffer 				 * was squashed to zero size by compression. 				 */
if|if
condition|(
name|b_compress
operator|==
name|ZIO_COMPRESS_EMPTY
condition|)
block|{
name|rzio
operator|=
name|zio_null
argument_list|(
name|pio
argument_list|,
name|spa
argument_list|,
name|vd
argument_list|,
name|l2arc_read_done
argument_list|,
name|cb
argument_list|,
name|zio_flags
operator||
name|ZIO_FLAG_DONT_CACHE
operator||
name|ZIO_FLAG_CANFAIL
operator||
name|ZIO_FLAG_DONT_PROPAGATE
operator||
name|ZIO_FLAG_DONT_RETRY
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|rzio
operator|=
name|zio_read_phys
argument_list|(
name|pio
argument_list|,
name|vd
argument_list|,
name|addr
argument_list|,
name|b_asize
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|ZIO_CHECKSUM_OFF
argument_list|,
name|l2arc_read_done
argument_list|,
name|cb
argument_list|,
name|priority
argument_list|,
name|zio_flags
operator||
name|ZIO_FLAG_DONT_CACHE
operator||
name|ZIO_FLAG_CANFAIL
operator||
name|ZIO_FLAG_DONT_PROPAGATE
operator||
name|ZIO_FLAG_DONT_RETRY
argument_list|,
name|B_FALSE
argument_list|)
expr_stmt|;
block|}
name|DTRACE_PROBE2
argument_list|(
name|l2arc__read
argument_list|,
name|vdev_t
operator|*
argument_list|,
name|vd
argument_list|,
name|zio_t
operator|*
argument_list|,
name|rzio
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_read_bytes
argument_list|,
name|b_asize
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_NOWAIT
condition|)
block|{
name|zio_nowait
argument_list|(
name|rzio
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|ASSERT
argument_list|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_WAIT
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio_wait
argument_list|(
name|rzio
argument_list|)
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* l2arc read error; goto zio_read() */
block|}
else|else
block|{
name|DTRACE_PROBE1
argument_list|(
name|l2arc__miss
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_misses
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
condition|)
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_rw_clash
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|vd
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|vd
operator|!=
name|NULL
condition|)
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|vd
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2arc_ndev
operator|!=
literal|0
condition|)
block|{
name|DTRACE_PROBE1
argument_list|(
name|l2arc__miss
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_misses
argument_list|)
expr_stmt|;
block|}
block|}
name|rzio
operator|=
name|zio_read
argument_list|(
name|pio
argument_list|,
name|spa
argument_list|,
name|bp
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|size
argument_list|,
name|arc_read_done
argument_list|,
name|buf
argument_list|,
name|priority
argument_list|,
name|zio_flags
argument_list|,
name|zb
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_WAIT
condition|)
return|return
operator|(
name|zio_wait
argument_list|(
name|rzio
argument_list|)
operator|)
return|;
name|ASSERT
argument_list|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_NOWAIT
argument_list|)
expr_stmt|;
name|zio_nowait
argument_list|(
name|rzio
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|void
name|arc_set_callback
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|arc_evict_func_t
modifier|*
name|func
parameter_list|,
name|void
modifier|*
name|private
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_hdr
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|!=
name|arc_anon
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|refcount_is_zero
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|||
name|func
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_efunc
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_BUF_AVAILABLE
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_efunc
operator|=
name|func
expr_stmt|;
name|buf
operator|->
name|b_private
operator|=
name|private
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Notify the arc that a block was freed, and thus will never be used again.  */
end_comment

begin_function
name|void
name|arc_freed
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
specifier|const
name|blkptr_t
modifier|*
name|bp
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|uint64_t
name|guid
init|=
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|BP_IS_EMBEDDED
argument_list|(
name|bp
argument_list|)
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|buf_hash_find
argument_list|(
name|guid
argument_list|,
name|bp
argument_list|,
operator|&
name|hash_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|==
name|NULL
condition|)
return|return;
if|if
condition|(
name|HDR_BUF_AVAILABLE
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
decl_stmt|;
name|add_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_BUF_AVAILABLE
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|arc_release
argument_list|(
name|buf
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_buf_remove_ref
argument_list|(
name|buf
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Clear the user eviction callback set by arc_set_callback(), first calling  * it if it exists.  Because the presence of a callback keeps an arc_buf cached  * clearing the callback may result in the arc_buf being destroyed.  However,  * it will not result in the *last* arc_buf being destroyed, hence the data  * will remain cached in the ARC. We make a copy of the arc buffer here so  * that we can process the callback without holding any locks.  *  * It's possible that the callback is already in the process of being cleared  * by another thread.  In this case we can not clear the callback.  *  * Returns B_TRUE if the callback was successfully called and cleared.  */
end_comment

begin_function
name|boolean_t
name|arc_clear_callback
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|arc_evict_func_t
modifier|*
name|efunc
init|=
name|buf
operator|->
name|b_efunc
decl_stmt|;
name|void
modifier|*
name|private
init|=
name|buf
operator|->
name|b_private
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|buf
operator|->
name|b_hdr
expr_stmt|;
if|if
condition|(
name|hdr
operator|==
name|NULL
condition|)
block|{
comment|/* 		 * We are in arc_do_user_evicts(). 		 */
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_data
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|buf
operator|->
name|b_data
operator|==
name|NULL
condition|)
block|{
comment|/* 		 * We are on the eviction list; process this buffer now 		 * but let arc_do_user_evicts() do the reaping. 		 */
name|buf
operator|->
name|b_efunc
operator|=
name|NULL
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|VERIFY0
argument_list|(
name|efunc
argument_list|(
name|private
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_TRUE
operator|)
return|;
block|}
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|buf
operator|->
name|b_hdr
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hash_lock
argument_list|,
operator|==
argument_list|,
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|,
operator|<
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mru
operator|||
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mfu
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_efunc
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_private
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|1
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|arc_buf_destroy
argument_list|(
name|buf
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|buf
operator|==
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_BUF_AVAILABLE
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|VERIFY0
argument_list|(
name|efunc
argument_list|(
name|private
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Release this buffer from the cache, making it an anonymous buffer.  This  * must be done after a read and prior to modifying the buffer contents.  * If the buffer has more than one reference, we must make  * a new hdr for the buffer.  */
end_comment

begin_function
name|void
name|arc_release
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
comment|/* 	 * It would be nice to assert that if it's DMU metadata (level> 	 * 0 || it's the dnode file), then it must be syncing context. 	 * But we don't know that information at this level. 	 */
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * We don't grab the hash lock prior to this check, because if 	 * the buffer's header is in the arc_anon state, it won't be 	 * linked into the hash table. 	 */
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|BUF_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
argument_list|,
operator|==
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|ASSERT3S
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|,
operator|==
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|list_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|buf
operator|->
name|b_efunc
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|buf
operator|->
name|b_private
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
literal|0
expr_stmt|;
name|arc_buf_thaw
argument_list|(
name|buf
argument_list|)
expr_stmt|;
return|return;
block|}
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
comment|/* 	 * This assignment is only valid as long as the hash_lock is 	 * held, we must be careful not to reference state or the 	 * b_state field after dropping the lock. 	 */
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|ASSERT3P
argument_list|(
name|hash_lock
argument_list|,
operator|==
argument_list|,
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|state
argument_list|,
operator|!=
argument_list|,
name|arc_anon
argument_list|)
expr_stmt|;
comment|/* this buffer is not on any list */
name|ASSERT
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|>
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 		 * We have to recheck this conditional again now that 		 * we're holding the l2ad_mtx to prevent a race with 		 * another thread which might be concurrently calling 		 * l2arc_evict(). In that case, l2arc_evict() might have 		 * destroyed the header's L2 portion as we were waiting 		 * to acquire the l2ad_mtx. 		 */
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|l2arc_trim
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|arc_hdr_l2hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Do we have more than one buf? 	 */
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|1
condition|)
block|{
name|arc_buf_hdr_t
modifier|*
name|nhdr
decl_stmt|;
name|arc_buf_t
modifier|*
modifier|*
name|bufp
decl_stmt|;
name|uint64_t
name|blksz
init|=
name|hdr
operator|->
name|b_size
decl_stmt|;
name|uint64_t
name|spa
init|=
name|hdr
operator|->
name|b_spa
decl_stmt|;
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|uint32_t
name|flags
init|=
name|hdr
operator|->
name|b_flags
decl_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|!=
name|buf
operator|||
name|buf
operator|->
name|b_next
operator|!=
name|NULL
argument_list|)
expr_stmt|;
comment|/* 		 * Pull the data off of this hdr and attach it to 		 * a new anonymous hdr. 		 */
operator|(
name|void
operator|)
name|remove_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|tag
argument_list|)
expr_stmt|;
name|bufp
operator|=
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
expr_stmt|;
while|while
condition|(
operator|*
name|bufp
operator|!=
name|buf
condition|)
name|bufp
operator|=
operator|&
operator|(
operator|*
name|bufp
operator|)
operator|->
name|b_next
expr_stmt|;
operator|*
name|bufp
operator|=
name|buf
operator|->
name|b_next
expr_stmt|;
name|buf
operator|->
name|b_next
operator|=
name|NULL
expr_stmt|;
name|ASSERT3P
argument_list|(
name|state
argument_list|,
operator|!=
argument_list|,
name|arc_l2c_only
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|,
name|buf
argument_list|)
expr_stmt|;
if|if
condition|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
condition|)
block|{
name|ASSERT3P
argument_list|(
name|state
argument_list|,
operator|!=
argument_list|,
name|arc_l2c_only
argument_list|)
expr_stmt|;
name|uint64_t
modifier|*
name|size
init|=
operator|&
name|state
operator|->
name|arcs_lsize
index|[
name|type
index|]
decl_stmt|;
name|ASSERT3U
argument_list|(
operator|*
name|size
argument_list|,
operator|>=
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
name|size
argument_list|,
operator|-
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * We're releasing a duplicate user data buffer, update 		 * our statistics accordingly. 		 */
if|if
condition|(
name|HDR_ISTYPE_DATA
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMPDOWN
argument_list|(
name|arcstat_duplicate_buffers
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_duplicate_buffers_size
argument_list|,
operator|-
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|-=
literal|1
expr_stmt|;
name|arc_cksum_verify
argument_list|(
name|buf
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
name|arc_buf_unwatch
argument_list|(
name|buf
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* illumos */
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|nhdr
operator|=
name|kmem_cache_alloc
argument_list|(
name|hdr_full_cache
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|nhdr
operator|->
name|b_size
operator|=
name|blksz
expr_stmt|;
name|nhdr
operator|->
name|b_spa
operator|=
name|spa
expr_stmt|;
name|nhdr
operator|->
name|b_flags
operator|=
name|flags
operator|&
name|ARC_FLAG_L2_WRITING
expr_stmt|;
name|nhdr
operator|->
name|b_flags
operator||=
name|arc_bufc_to_flags
argument_list|(
name|type
argument_list|)
expr_stmt|;
name|nhdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_HAS_L1HDR
expr_stmt|;
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|=
name|buf
expr_stmt|;
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|=
literal|1
expr_stmt|;
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|=
name|arc_anon
expr_stmt|;
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
literal|0
expr_stmt|;
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|=
name|NULL
expr_stmt|;
name|nhdr
operator|->
name|b_freeze_cksum
operator|=
name|NULL
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add
argument_list|(
operator|&
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|=
name|nhdr
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|,
name|blksz
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|==
literal|1
argument_list|)
expr_stmt|;
comment|/* protected by hash lock, or hdr is on arc_anon */
name|ASSERT
argument_list|(
operator|!
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
literal|0
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|arc_buf_thaw
argument_list|(
name|buf
argument_list|)
expr_stmt|;
block|}
name|buf
operator|->
name|b_efunc
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_private
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_function
name|int
name|arc_released
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|int
name|released
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|released
operator|=
operator|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
operator|&&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
operator|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|released
operator|)
return|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|ZFS_DEBUG
end_ifdef

begin_function
name|int
name|arc_referenced
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|int
name|referenced
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|referenced
operator|=
operator|(
name|refcount_count
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|referenced
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|void
name|arc_write_ready
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|arc_write_callback_t
modifier|*
name|callback
init|=
name|zio
operator|->
name|io_private
decl_stmt|;
name|arc_buf_t
modifier|*
name|buf
init|=
name|callback
operator|->
name|awcb_buf
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|refcount_is_zero
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|0
argument_list|)
expr_stmt|;
name|callback
operator|->
name|awcb_ready
argument_list|(
name|zio
argument_list|,
name|buf
argument_list|,
name|callback
operator|->
name|awcb_private
argument_list|)
expr_stmt|;
comment|/* 	 * If the IO is already in progress, then this is a re-write 	 * attempt, so we need to thaw and re-compute the cksum. 	 * It is the responsibility of the callback to handle the 	 * accounting for any re-write attempt. 	 */
if|if
condition|(
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_freeze_cksum
operator|!=
name|NULL
condition|)
block|{
name|kmem_free
argument_list|(
name|hdr
operator|->
name|b_freeze_cksum
argument_list|,
sizeof|sizeof
argument_list|(
name|zio_cksum_t
argument_list|)
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_freeze_cksum
operator|=
name|NULL
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
block|}
name|arc_cksum_compute
argument_list|(
name|buf
argument_list|,
name|B_FALSE
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_IO_IN_PROGRESS
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * The SPA calls this callback for each physical write that happens on behalf  * of a logical write.  See the comment in dbuf_write_physdone() for details.  */
end_comment

begin_function
specifier|static
name|void
name|arc_write_physdone
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|arc_write_callback_t
modifier|*
name|cb
init|=
name|zio
operator|->
name|io_private
decl_stmt|;
if|if
condition|(
name|cb
operator|->
name|awcb_physdone
operator|!=
name|NULL
condition|)
name|cb
operator|->
name|awcb_physdone
argument_list|(
name|zio
argument_list|,
name|cb
operator|->
name|awcb_buf
argument_list|,
name|cb
operator|->
name|awcb_private
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_write_done
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|arc_write_callback_t
modifier|*
name|callback
init|=
name|zio
operator|->
name|io_private
decl_stmt|;
name|arc_buf_t
modifier|*
name|buf
init|=
name|callback
operator|->
name|awcb_buf
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
operator|==
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio
operator|->
name|io_error
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|BP_IS_HOLE
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|||
name|BP_IS_EMBEDDED
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
condition|)
block|{
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|hdr
operator|->
name|b_dva
operator|=
operator|*
name|BP_IDENTITY
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_birth
operator|=
name|BP_PHYSICAL_BIRTH
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|BUF_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If the block to be written was all-zero or compressed enough to be 	 * embedded in the BP, no write was performed so there will be no 	 * dva/birth/checksum.  The buffer must therefore remain anonymous 	 * (and uncached). 	 */
if|if
condition|(
operator|!
name|BUF_EMPTY
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|arc_buf_hdr_t
modifier|*
name|exists
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|ASSERT
argument_list|(
name|zio
operator|->
name|io_error
operator|==
literal|0
argument_list|)
expr_stmt|;
name|arc_cksum_verify
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|exists
operator|=
name|buf_hash_insert
argument_list|(
name|hdr
argument_list|,
operator|&
name|hash_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|exists
operator|!=
name|NULL
condition|)
block|{
comment|/* 			 * This can only happen if we overwrite for 			 * sync-to-convergence, because we remove 			 * buffers from the hash table when we arc_free(). 			 */
if|if
condition|(
name|zio
operator|->
name|io_flags
operator|&
name|ZIO_FLAG_IO_REWRITE
condition|)
block|{
if|if
condition|(
operator|!
name|BP_EQUAL
argument_list|(
operator|&
name|zio
operator|->
name|io_bp_orig
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|)
condition|)
name|panic
argument_list|(
literal|"bad overwrite, hdr=%p exists=%p"
argument_list|,
operator|(
name|void
operator|*
operator|)
name|hdr
argument_list|,
operator|(
name|void
operator|*
operator|)
name|exists
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|exists
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|exists
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|arc_hdr_destroy
argument_list|(
name|exists
argument_list|)
expr_stmt|;
name|exists
operator|=
name|buf_hash_insert
argument_list|(
name|hdr
argument_list|,
operator|&
name|hash_lock
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|exists
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|zio
operator|->
name|io_flags
operator|&
name|ZIO_FLAG_NOPWRITE
condition|)
block|{
comment|/* nopwrite */
name|ASSERT
argument_list|(
name|zio
operator|->
name|io_prop
operator|.
name|zp_nopwrite
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|BP_EQUAL
argument_list|(
operator|&
name|zio
operator|->
name|io_bp_orig
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|)
condition|)
name|panic
argument_list|(
literal|"bad nopwrite, hdr=%p exists=%p"
argument_list|,
operator|(
name|void
operator|*
operator|)
name|hdr
argument_list|,
operator|(
name|void
operator|*
operator|)
name|exists
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Dedup */
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|==
literal|1
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|BP_GET_DEDUP
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|BP_GET_LEVEL
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|==
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_IO_IN_PROGRESS
expr_stmt|;
comment|/* if it's not anon, we are doing a scrub */
if|if
condition|(
name|exists
operator|==
name|NULL
operator|&&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
condition|)
name|arc_access
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_IO_IN_PROGRESS
expr_stmt|;
block|}
name|ASSERT
argument_list|(
operator|!
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|callback
operator|->
name|awcb_done
argument_list|(
name|zio
argument_list|,
name|buf
argument_list|,
name|callback
operator|->
name|awcb_private
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|callback
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_write_callback_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|zio_t
modifier|*
name|arc_write
parameter_list|(
name|zio_t
modifier|*
name|pio
parameter_list|,
name|spa_t
modifier|*
name|spa
parameter_list|,
name|uint64_t
name|txg
parameter_list|,
name|blkptr_t
modifier|*
name|bp
parameter_list|,
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|boolean_t
name|l2arc
parameter_list|,
name|boolean_t
name|l2arc_compress
parameter_list|,
specifier|const
name|zio_prop_t
modifier|*
name|zp
parameter_list|,
name|arc_done_func_t
modifier|*
name|ready
parameter_list|,
name|arc_done_func_t
modifier|*
name|physdone
parameter_list|,
name|arc_done_func_t
modifier|*
name|done
parameter_list|,
name|void
modifier|*
name|private
parameter_list|,
name|zio_priority_t
name|priority
parameter_list|,
name|int
name|zio_flags
parameter_list|,
specifier|const
name|zbookmark_phys_t
modifier|*
name|zb
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|arc_write_callback_t
modifier|*
name|callback
decl_stmt|;
name|zio_t
modifier|*
name|zio
decl_stmt|;
name|ASSERT
argument_list|(
name|ready
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|done
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_ERROR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
operator|==
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_datacnt
operator|>
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2arc
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2CACHE
expr_stmt|;
if|if
condition|(
name|l2arc_compress
condition|)
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2COMPRESS
expr_stmt|;
name|callback
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_write_callback_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|callback
operator|->
name|awcb_ready
operator|=
name|ready
expr_stmt|;
name|callback
operator|->
name|awcb_physdone
operator|=
name|physdone
expr_stmt|;
name|callback
operator|->
name|awcb_done
operator|=
name|done
expr_stmt|;
name|callback
operator|->
name|awcb_private
operator|=
name|private
expr_stmt|;
name|callback
operator|->
name|awcb_buf
operator|=
name|buf
expr_stmt|;
name|zio
operator|=
name|zio_write
argument_list|(
name|pio
argument_list|,
name|spa
argument_list|,
name|txg
argument_list|,
name|bp
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|,
name|zp
argument_list|,
name|arc_write_ready
argument_list|,
name|arc_write_physdone
argument_list|,
name|arc_write_done
argument_list|,
name|callback
argument_list|,
name|priority
argument_list|,
name|zio_flags
argument_list|,
name|zb
argument_list|)
expr_stmt|;
return|return
operator|(
name|zio
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|arc_memory_throttle
parameter_list|(
name|uint64_t
name|reserve
parameter_list|,
name|uint64_t
name|txg
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|_KERNEL
name|uint64_t
name|available_memory
init|=
name|ptob
argument_list|(
name|freemem
argument_list|)
decl_stmt|;
specifier|static
name|uint64_t
name|page_load
init|=
literal|0
decl_stmt|;
specifier|static
name|uint64_t
name|last_txg
init|=
literal|0
decl_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|__i386
argument_list|)
operator|||
operator|!
name|defined
argument_list|(
name|UMA_MD_SMALL_ALLOC
argument_list|)
name|available_memory
operator|=
name|MIN
argument_list|(
name|available_memory
argument_list|,
name|ptob
argument_list|(
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_FREE
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|freemem
operator|>
operator|(
name|uint64_t
operator|)
name|physmem
operator|*
name|arc_lotsfree_percent
operator|/
literal|100
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|if
condition|(
name|txg
operator|>
name|last_txg
condition|)
block|{
name|last_txg
operator|=
name|txg
expr_stmt|;
name|page_load
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * If we are in pageout, we know that memory is already tight, 	 * the arc is already going to be evicting, so we just want to 	 * continue to let page writes occur as quickly as possible. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
condition|)
block|{
if|if
condition|(
name|page_load
operator|>
name|MAX
argument_list|(
name|ptob
argument_list|(
name|minfree
argument_list|)
argument_list|,
name|available_memory
argument_list|)
operator|/
literal|4
condition|)
return|return
operator|(
name|SET_ERROR
argument_list|(
name|ERESTART
argument_list|)
operator|)
return|;
comment|/* Note: reserve is inflated, so we deflate */
name|page_load
operator|+=
name|reserve
operator|/
literal|8
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|page_load
operator|>
literal|0
operator|&&
name|arc_reclaim_needed
argument_list|()
condition|)
block|{
comment|/* memory is low, delay before restarting */
name|ARCSTAT_INCR
argument_list|(
name|arcstat_memory_throttle_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|SET_ERROR
argument_list|(
name|EAGAIN
argument_list|)
operator|)
return|;
block|}
name|page_load
operator|=
literal|0
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|void
name|arc_tempreserve_clear
parameter_list|(
name|uint64_t
name|reserve
parameter_list|)
block|{
name|atomic_add_64
argument_list|(
operator|&
name|arc_tempreserve
argument_list|,
operator|-
name|reserve
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|(
name|int64_t
operator|)
name|arc_tempreserve
operator|>=
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|arc_tempreserve_space
parameter_list|(
name|uint64_t
name|reserve
parameter_list|,
name|uint64_t
name|txg
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
name|uint64_t
name|anon_size
decl_stmt|;
if|if
condition|(
name|reserve
operator|>
name|arc_c
operator|/
literal|4
operator|&&
operator|!
name|arc_no_grow
condition|)
block|{
name|arc_c
operator|=
name|MIN
argument_list|(
name|arc_c_max
argument_list|,
name|reserve
operator|*
literal|4
argument_list|)
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|arc__set_reserve
argument_list|,
name|uint64_t
argument_list|,
name|arc_c
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|reserve
operator|>
name|arc_c
condition|)
return|return
operator|(
name|SET_ERROR
argument_list|(
name|ENOMEM
argument_list|)
operator|)
return|;
comment|/* 	 * Don't count loaned bufs as in flight dirty data to prevent long 	 * network delays from blocking transactions that are ready to be 	 * assigned to a txg. 	 */
name|anon_size
operator|=
name|MAX
argument_list|(
call|(
name|int64_t
call|)
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
operator|-
name|arc_loaned_bytes
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * Writes will, almost always, require additional memory allocations 	 * in order to compress/encrypt/etc the data.  We therefore need to 	 * make sure that there is sufficient available memory for this. 	 */
name|error
operator|=
name|arc_memory_throttle
argument_list|(
name|reserve
argument_list|,
name|txg
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
return|return
operator|(
name|error
operator|)
return|;
comment|/* 	 * Throttle writes when the amount of dirty data in the cache 	 * gets too large.  We try to keep the cache less than half full 	 * of dirty blocks so that our sync times don't grow too large. 	 * Note: if two requests come in concurrently, we might let them 	 * both succeed, when one of them should fail.  Not a huge deal. 	 */
if|if
condition|(
name|reserve
operator|+
name|arc_tempreserve
operator|+
name|anon_size
operator|>
name|arc_c
operator|/
literal|2
operator|&&
name|anon_size
operator|>
name|arc_c
operator|/
literal|4
condition|)
block|{
name|dprintf
argument_list|(
literal|"failing, arc_tempreserve=%lluK anon_meta=%lluK "
literal|"anon_data=%lluK tempreserve=%lluK arc_c=%lluK\n"
argument_list|,
name|arc_tempreserve
operator|>>
literal|10
argument_list|,
name|arc_anon
operator|->
name|arcs_lsize
index|[
name|ARC_BUFC_METADATA
index|]
operator|>>
literal|10
argument_list|,
name|arc_anon
operator|->
name|arcs_lsize
index|[
name|ARC_BUFC_DATA
index|]
operator|>>
literal|10
argument_list|,
name|reserve
operator|>>
literal|10
argument_list|,
name|arc_c
operator|>>
literal|10
argument_list|)
expr_stmt|;
return|return
operator|(
name|SET_ERROR
argument_list|(
name|ERESTART
argument_list|)
operator|)
return|;
block|}
name|atomic_add_64
argument_list|(
operator|&
name|arc_tempreserve
argument_list|,
name|reserve
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_kstat_update_state
parameter_list|(
name|arc_state_t
modifier|*
name|state
parameter_list|,
name|kstat_named_t
modifier|*
name|size
parameter_list|,
name|kstat_named_t
modifier|*
name|evict_data
parameter_list|,
name|kstat_named_t
modifier|*
name|evict_metadata
parameter_list|)
block|{
name|size
operator|->
name|value
operator|.
name|ui64
operator|=
name|refcount_count
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|evict_data
operator|->
name|value
operator|.
name|ui64
operator|=
name|state
operator|->
name|arcs_lsize
index|[
name|ARC_BUFC_DATA
index|]
expr_stmt|;
name|evict_metadata
operator|->
name|value
operator|.
name|ui64
operator|=
name|state
operator|->
name|arcs_lsize
index|[
name|ARC_BUFC_METADATA
index|]
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|arc_kstat_update
parameter_list|(
name|kstat_t
modifier|*
name|ksp
parameter_list|,
name|int
name|rw
parameter_list|)
block|{
name|arc_stats_t
modifier|*
name|as
init|=
name|ksp
operator|->
name|ks_data
decl_stmt|;
if|if
condition|(
name|rw
operator|==
name|KSTAT_WRITE
condition|)
block|{
return|return
operator|(
name|EACCES
operator|)
return|;
block|}
else|else
block|{
name|arc_kstat_update_state
argument_list|(
name|arc_anon
argument_list|,
operator|&
name|as
operator|->
name|arcstat_anon_size
argument_list|,
operator|&
name|as
operator|->
name|arcstat_anon_evictable_data
argument_list|,
operator|&
name|as
operator|->
name|arcstat_anon_evictable_metadata
argument_list|)
expr_stmt|;
name|arc_kstat_update_state
argument_list|(
name|arc_mru
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_size
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_evictable_data
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_evictable_metadata
argument_list|)
expr_stmt|;
name|arc_kstat_update_state
argument_list|(
name|arc_mru_ghost
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_ghost_size
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_ghost_evictable_data
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_ghost_evictable_metadata
argument_list|)
expr_stmt|;
name|arc_kstat_update_state
argument_list|(
name|arc_mfu
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_size
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_evictable_data
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_evictable_metadata
argument_list|)
expr_stmt|;
name|arc_kstat_update_state
argument_list|(
name|arc_mfu_ghost
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_ghost_size
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_ghost_evictable_data
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_ghost_evictable_metadata
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This function *must* return indices evenly distributed between all  * sublists of the multilist. This is needed due to how the ARC eviction  * code is laid out; arc_evict_state() assumes ARC buffers are evenly  * distributed between all sublists and uses this assumption when  * deciding which sublist to evict from and how much to evict from it.  */
end_comment

begin_function
name|unsigned
name|int
name|arc_state_multilist_index_func
parameter_list|(
name|multilist_t
modifier|*
name|ml
parameter_list|,
name|void
modifier|*
name|obj
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|obj
decl_stmt|;
comment|/* 	 * We rely on b_dva to generate evenly distributed index 	 * numbers using buf_hash below. So, as an added precaution, 	 * let's make sure we never add empty buffers to the arc lists. 	 */
name|ASSERT
argument_list|(
operator|!
name|BUF_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * The assumption here, is the hash value for a given 	 * arc_buf_hdr_t will remain constant throughout it's lifetime 	 * (i.e. it's b_spa, b_dva, and b_birth fields don't change). 	 * Thus, we don't need to store the header's sublist index 	 * on insertion, as this index can be recalculated on removal. 	 * 	 * Also, the low order bits of the hash value are thought to be 	 * distributed evenly. Otherwise, in the case that the multilist 	 * has a power of two number of sublists, each sublists' usage 	 * would not be evenly distributed. 	 */
return|return
operator|(
name|buf_hash
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
operator|&
name|hdr
operator|->
name|b_dva
argument_list|,
name|hdr
operator|->
name|b_birth
argument_list|)
operator|%
name|multilist_get_num_sublists
argument_list|(
name|ml
argument_list|)
operator|)
return|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|_KERNEL
end_ifdef

begin_decl_stmt
specifier|static
name|eventhandler_tag
name|arc_event_lowmem
init|=
name|NULL
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|void
name|arc_lowmem
parameter_list|(
name|void
modifier|*
name|arg
name|__unused
parameter_list|,
name|int
name|howto
name|__unused
parameter_list|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
comment|/* XXX: Memory deficit should be passed as argument. */
name|needfree
operator|=
name|btoc
argument_list|(
name|arc_c
operator|>>
name|arc_shrink_shift
argument_list|)
expr_stmt|;
name|DTRACE_PROBE
argument_list|(
name|arc__needfree
argument_list|)
expr_stmt|;
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
comment|/* 	 * It is unsafe to block here in arbitrary threads, because we can come 	 * here from ARC itself and may hold ARC locks and thus risk a deadlock 	 * with ARC reclaim thread. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
condition|)
operator|(
name|void
operator|)
name|cv_wait
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
name|void
name|arc_init
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|prefetch_tunable_set
init|=
literal|0
decl_stmt|;
name|mutex_init
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|arc_user_evicts_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* Convert seconds to clock ticks */
name|arc_min_prefetch_lifespan
operator|=
literal|1
operator|*
name|hz
expr_stmt|;
comment|/* Start out with 1/8 of all memory */
name|arc_c
operator|=
name|kmem_size
argument_list|()
operator|/
literal|8
expr_stmt|;
ifdef|#
directive|ifdef
name|sun
ifdef|#
directive|ifdef
name|_KERNEL
comment|/* 	 * On architectures where the physical memory can be larger 	 * than the addressable space (intel in 32-bit mode), we may 	 * need to limit the cache to 1/8 of VM size. 	 */
name|arc_c
operator|=
name|MIN
argument_list|(
name|arc_c
argument_list|,
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_ALLOC
operator||
name|VMEM_FREE
argument_list|)
operator|/
literal|8
argument_list|)
expr_stmt|;
endif|#
directive|endif
endif|#
directive|endif
comment|/* sun */
comment|/* set min cache to 1/32 of all memory, or 16MB, whichever is more */
name|arc_c_min
operator|=
name|MAX
argument_list|(
name|arc_c
operator|/
literal|4
argument_list|,
literal|16
operator|<<
literal|20
argument_list|)
expr_stmt|;
comment|/* set max to 1/2 of all memory, or all but 1GB, whichever is more */
if|if
condition|(
name|arc_c
operator|*
literal|8
operator|>=
literal|1
operator|<<
literal|30
condition|)
name|arc_c_max
operator|=
operator|(
name|arc_c
operator|*
literal|8
operator|)
operator|-
operator|(
literal|1
operator|<<
literal|30
operator|)
expr_stmt|;
else|else
name|arc_c_max
operator|=
name|arc_c_min
expr_stmt|;
name|arc_c_max
operator|=
name|MAX
argument_list|(
name|arc_c
operator|*
literal|5
argument_list|,
name|arc_c_max
argument_list|)
expr_stmt|;
comment|/* 	 * In userland, there's only the memory pressure that we artificially 	 * create (see arc_available_memory()).  Don't let arc_c get too 	 * small, because it can cause transactions to be larger than 	 * arc_c, causing arc_tempreserve_space() to fail. 	 */
ifndef|#
directive|ifndef
name|_KERNEL
name|arc_c_min
operator|=
name|arc_c_max
operator|/
literal|2
expr_stmt|;
endif|#
directive|endif
ifdef|#
directive|ifdef
name|_KERNEL
comment|/* 	 * Allow the tunables to override our calculations if they are 	 * reasonable (ie. over 16MB) 	 */
if|if
condition|(
name|zfs_arc_max
operator|>
literal|16
operator|<<
literal|20
operator|&&
name|zfs_arc_max
operator|<
name|kmem_size
argument_list|()
condition|)
name|arc_c_max
operator|=
name|zfs_arc_max
expr_stmt|;
if|if
condition|(
name|zfs_arc_min
operator|>
literal|16
operator|<<
literal|20
operator|&&
name|zfs_arc_min
operator|<=
name|arc_c_max
condition|)
name|arc_c_min
operator|=
name|zfs_arc_min
expr_stmt|;
endif|#
directive|endif
name|arc_c
operator|=
name|arc_c_max
expr_stmt|;
name|arc_p
operator|=
operator|(
name|arc_c
operator|>>
literal|1
operator|)
expr_stmt|;
comment|/* limit meta-data to 1/4 of the arc capacity */
name|arc_meta_limit
operator|=
name|arc_c_max
operator|/
literal|4
expr_stmt|;
comment|/* Allow the tunable to override if it is reasonable */
if|if
condition|(
name|zfs_arc_meta_limit
operator|>
literal|0
operator|&&
name|zfs_arc_meta_limit
operator|<=
name|arc_c_max
condition|)
name|arc_meta_limit
operator|=
name|zfs_arc_meta_limit
expr_stmt|;
if|if
condition|(
name|arc_c_min
operator|<
name|arc_meta_limit
operator|/
literal|2
operator|&&
name|zfs_arc_min
operator|==
literal|0
condition|)
name|arc_c_min
operator|=
name|arc_meta_limit
operator|/
literal|2
expr_stmt|;
if|if
condition|(
name|zfs_arc_meta_min
operator|>
literal|0
condition|)
block|{
name|arc_meta_min
operator|=
name|zfs_arc_meta_min
expr_stmt|;
block|}
else|else
block|{
name|arc_meta_min
operator|=
name|arc_c_min
operator|/
literal|2
expr_stmt|;
block|}
if|if
condition|(
name|zfs_arc_grow_retry
operator|>
literal|0
condition|)
name|arc_grow_retry
operator|=
name|zfs_arc_grow_retry
expr_stmt|;
if|if
condition|(
name|zfs_arc_shrink_shift
operator|>
literal|0
condition|)
name|arc_shrink_shift
operator|=
name|zfs_arc_shrink_shift
expr_stmt|;
comment|/* 	 * Ensure that arc_no_grow_shift is less than arc_shrink_shift. 	 */
if|if
condition|(
name|arc_no_grow_shift
operator|>=
name|arc_shrink_shift
condition|)
name|arc_no_grow_shift
operator|=
name|arc_shrink_shift
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|zfs_arc_p_min_shift
operator|>
literal|0
condition|)
name|arc_p_min_shift
operator|=
name|zfs_arc_p_min_shift
expr_stmt|;
if|if
condition|(
name|zfs_arc_num_sublists_per_state
operator|<
literal|1
condition|)
name|zfs_arc_num_sublists_per_state
operator|=
name|MAX
argument_list|(
name|max_ncpus
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* if kmem_flags are set, lets try to use less memory */
if|if
condition|(
name|kmem_debugging
argument_list|()
condition|)
name|arc_c
operator|=
name|arc_c
operator|/
literal|2
expr_stmt|;
if|if
condition|(
name|arc_c
operator|<
name|arc_c_min
condition|)
name|arc_c
operator|=
name|arc_c_min
expr_stmt|;
name|zfs_arc_min
operator|=
name|arc_c_min
expr_stmt|;
name|zfs_arc_max
operator|=
name|arc_c_max
expr_stmt|;
name|arc_anon
operator|=
operator|&
name|ARC_anon
expr_stmt|;
name|arc_mru
operator|=
operator|&
name|ARC_mru
expr_stmt|;
name|arc_mru_ghost
operator|=
operator|&
name|ARC_mru_ghost
expr_stmt|;
name|arc_mfu
operator|=
operator|&
name|ARC_mfu
expr_stmt|;
name|arc_mfu_ghost
operator|=
operator|&
name|ARC_mfu_ghost
expr_stmt|;
name|arc_l2c_only
operator|=
operator|&
name|ARC_l2c_only
expr_stmt|;
name|arc_size
operator|=
literal|0
expr_stmt|;
name|multilist_create
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|zfs_arc_num_sublists_per_state
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|multilist_create
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|zfs_arc_num_sublists_per_state
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|multilist_create
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|zfs_arc_num_sublists_per_state
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|multilist_create
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|zfs_arc_num_sublists_per_state
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|multilist_create
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|zfs_arc_num_sublists_per_state
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|multilist_create
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|zfs_arc_num_sublists_per_state
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|multilist_create
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|zfs_arc_num_sublists_per_state
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|multilist_create
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|zfs_arc_num_sublists_per_state
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|multilist_create
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|zfs_arc_num_sublists_per_state
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|multilist_create
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|zfs_arc_num_sublists_per_state
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|buf_init
argument_list|()
expr_stmt|;
name|arc_reclaim_thread_exit
operator|=
name|FALSE
expr_stmt|;
name|arc_user_evicts_thread_exit
operator|=
name|FALSE
expr_stmt|;
name|arc_eviction_list
operator|=
name|NULL
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|arc_eviction_hdr
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|)
expr_stmt|;
name|arc_ksp
operator|=
name|kstat_create
argument_list|(
literal|"zfs"
argument_list|,
literal|0
argument_list|,
literal|"arcstats"
argument_list|,
literal|"misc"
argument_list|,
name|KSTAT_TYPE_NAMED
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_stats
argument_list|)
operator|/
sizeof|sizeof
argument_list|(
name|kstat_named_t
argument_list|)
argument_list|,
name|KSTAT_FLAG_VIRTUAL
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_ksp
operator|!=
name|NULL
condition|)
block|{
name|arc_ksp
operator|->
name|ks_data
operator|=
operator|&
name|arc_stats
expr_stmt|;
name|arc_ksp
operator|->
name|ks_update
operator|=
name|arc_kstat_update
expr_stmt|;
name|kstat_install
argument_list|(
name|arc_ksp
argument_list|)
expr_stmt|;
block|}
operator|(
name|void
operator|)
name|thread_create
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|arc_reclaim_thread
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
operator|&
name|p0
argument_list|,
name|TS_RUN
argument_list|,
name|minclsyspri
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
name|arc_event_lowmem
operator|=
name|EVENTHANDLER_REGISTER
argument_list|(
name|vm_lowmem
argument_list|,
name|arc_lowmem
argument_list|,
name|NULL
argument_list|,
name|EVENTHANDLER_PRI_FIRST
argument_list|)
expr_stmt|;
endif|#
directive|endif
operator|(
name|void
operator|)
name|thread_create
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|arc_user_evicts_thread
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
operator|&
name|p0
argument_list|,
name|TS_RUN
argument_list|,
name|minclsyspri
argument_list|)
expr_stmt|;
name|arc_dead
operator|=
name|FALSE
expr_stmt|;
name|arc_warm
operator|=
name|B_FALSE
expr_stmt|;
comment|/* 	 * Calculate maximum amount of dirty data per pool. 	 * 	 * If it has been set by /etc/system, take that. 	 * Otherwise, use a percentage of physical memory defined by 	 * zfs_dirty_data_max_percent (default 10%) with a cap at 	 * zfs_dirty_data_max_max (default 4GB). 	 */
if|if
condition|(
name|zfs_dirty_data_max
operator|==
literal|0
condition|)
block|{
name|zfs_dirty_data_max
operator|=
name|ptob
argument_list|(
name|physmem
argument_list|)
operator|*
name|zfs_dirty_data_max_percent
operator|/
literal|100
expr_stmt|;
name|zfs_dirty_data_max
operator|=
name|MIN
argument_list|(
name|zfs_dirty_data_max
argument_list|,
name|zfs_dirty_data_max_max
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|_KERNEL
if|if
condition|(
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vfs.zfs.prefetch_disable"
argument_list|,
operator|&
name|zfs_prefetch_disable
argument_list|)
condition|)
name|prefetch_tunable_set
operator|=
literal|1
expr_stmt|;
ifdef|#
directive|ifdef
name|__i386__
if|if
condition|(
name|prefetch_tunable_set
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"ZFS NOTICE: Prefetch is disabled by default on i386 "
literal|"-- to enable,\n"
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"            add \"vfs.zfs.prefetch_disable=0\" "
literal|"to /boot/loader.conf.\n"
argument_list|)
expr_stmt|;
name|zfs_prefetch_disable
operator|=
literal|1
expr_stmt|;
block|}
else|#
directive|else
if|if
condition|(
operator|(
operator|(
operator|(
name|uint64_t
operator|)
name|physmem
operator|*
name|PAGESIZE
operator|)
operator|<
operator|(
literal|1ULL
operator|<<
literal|32
operator|)
operator|)
operator|&&
name|prefetch_tunable_set
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"ZFS NOTICE: Prefetch is disabled by default if less "
literal|"than 4GB of RAM is present;\n"
literal|"            to enable, add \"vfs.zfs.prefetch_disable=0\" "
literal|"to /boot/loader.conf.\n"
argument_list|)
expr_stmt|;
name|zfs_prefetch_disable
operator|=
literal|1
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* Warn about ZFS memory and address space requirements. */
if|if
condition|(
operator|(
operator|(
name|uint64_t
operator|)
name|physmem
operator|*
name|PAGESIZE
operator|)
operator|<
operator|(
literal|256
operator|+
literal|128
operator|+
literal|64
operator|)
operator|*
operator|(
literal|1
operator|<<
literal|20
operator|)
condition|)
block|{
name|printf
argument_list|(
literal|"ZFS WARNING: Recommended minimum RAM size is 512MB; "
literal|"expect unstable behavior.\n"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|kmem_size
argument_list|()
operator|<
literal|512
operator|*
operator|(
literal|1
operator|<<
literal|20
operator|)
condition|)
block|{
name|printf
argument_list|(
literal|"ZFS WARNING: Recommended minimum kmem_size is 512MB; "
literal|"expect unstable behavior.\n"
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"             Consider tuning vm.kmem_size and "
literal|"vm.kmem_size_max\n"
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"             in /boot/loader.conf.\n"
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|arc_fini
parameter_list|(
name|void
parameter_list|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
name|arc_reclaim_thread_exit
operator|=
name|TRUE
expr_stmt|;
comment|/* 	 * The reclaim thread will set arc_reclaim_thread_exit back to 	 * FALSE when it is finished exiting; we're waiting for that. 	 */
while|while
condition|(
name|arc_reclaim_thread_exit
condition|)
block|{
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
name|cv_wait
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
name|arc_user_evicts_thread_exit
operator|=
name|TRUE
expr_stmt|;
comment|/* 	 * The user evicts thread will set arc_user_evicts_thread_exit 	 * to FALSE when it is finished exiting; we're waiting for that. 	 */
while|while
condition|(
name|arc_user_evicts_thread_exit
condition|)
block|{
name|cv_signal
argument_list|(
operator|&
name|arc_user_evicts_cv
argument_list|)
expr_stmt|;
name|cv_wait
argument_list|(
operator|&
name|arc_user_evicts_cv
argument_list|,
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
comment|/* Use TRUE to ensure *all* buffers are evicted */
name|arc_flush
argument_list|(
name|NULL
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
name|arc_dead
operator|=
name|TRUE
expr_stmt|;
if|if
condition|(
name|arc_ksp
operator|!=
name|NULL
condition|)
block|{
name|kstat_delete
argument_list|(
name|arc_ksp
argument_list|)
expr_stmt|;
name|arc_ksp
operator|=
name|NULL
expr_stmt|;
block|}
name|mutex_destroy
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|arc_user_evicts_lock
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|arc_user_evicts_cv
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|buf_fini
argument_list|()
expr_stmt|;
name|ASSERT0
argument_list|(
name|arc_loaned_bytes
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
if|if
condition|(
name|arc_event_lowmem
operator|!=
name|NULL
condition|)
name|EVENTHANDLER_DEREGISTER
argument_list|(
name|vm_lowmem
argument_list|,
name|arc_event_lowmem
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  * Level 2 ARC  *  * The level 2 ARC (L2ARC) is a cache layer in-between main memory and disk.  * It uses dedicated storage devices to hold cached data, which are populated  * using large infrequent writes.  The main role of this cache is to boost  * the performance of random read workloads.  The intended L2ARC devices  * include short-stroked disks, solid state disks, and other media with  * substantially faster read latency than disk.  *  *                 +-----------------------+  *                 |         ARC           |  *                 +-----------------------+  *                    |         ^     ^  *                    |         |     |  *      l2arc_feed_thread()    arc_read()  *                    |         |     |  *                    |  l2arc read   |  *                    V         |     |  *               +---------------+    |  *               |     L2ARC     |    |  *               +---------------+    |  *                   |    ^           |  *          l2arc_write() |           |  *                   |    |           |  *                   V    |           |  *                 +-------+      +-------+  *                 | vdev  |      | vdev  |  *                 | cache |      | cache |  *                 +-------+      +-------+  *                 +=========+     .-----.  *                 :  L2ARC  :    |-_____-|  *                 : devices :    | Disks |  *                 +=========+    `-_____-'  *  * Read requests are satisfied from the following sources, in order:  *  *	1) ARC  *	2) vdev cache of L2ARC devices  *	3) L2ARC devices  *	4) vdev cache of disks  *	5) disks  *  * Some L2ARC device types exhibit extremely slow write performance.  * To accommodate for this there are some significant differences between  * the L2ARC and traditional cache design:  *  * 1. There is no eviction path from the ARC to the L2ARC.  Evictions from  * the ARC behave as usual, freeing buffers and placing headers on ghost  * lists.  The ARC does not send buffers to the L2ARC during eviction as  * this would add inflated write latencies for all ARC memory pressure.  *  * 2. The L2ARC attempts to cache data from the ARC before it is evicted.  * It does this by periodically scanning buffers from the eviction-end of  * the MFU and MRU ARC lists, copying them to the L2ARC devices if they are  * not already there. It scans until a headroom of buffers is satisfied,  * which itself is a buffer for ARC eviction. If a compressible buffer is  * found during scanning and selected for writing to an L2ARC device, we  * temporarily boost scanning headroom during the next scan cycle to make  * sure we adapt to compression effects (which might significantly reduce  * the data volume we write to L2ARC). The thread that does this is  * l2arc_feed_thread(), illustrated below; example sizes are included to  * provide a better sense of ratio than this diagram:  *  *	       head -->                        tail  *	        +---------------------+----------+  *	ARC_mfu |:::::#:::::::::::::::|o#o###o###|-->.   # already on L2ARC  *	        +---------------------+----------+   |   o L2ARC eligible  *	ARC_mru |:#:::::::::::::::::::|#o#ooo####|-->|   : ARC buffer  *	        +---------------------+----------+   |  *	             15.9 Gbytes      ^ 32 Mbytes    |  *	                           headroom          |  *	                                      l2arc_feed_thread()  *	                                             |  *	                 l2arc write hand<--[oooo]--'  *	                         |           8 Mbyte  *	                         |          write max  *	                         V  *		  +==============================+  *	L2ARC dev |####|#|###|###|    |####| ... |  *	          +==============================+  *	                     32 Gbytes  *  * 3. If an ARC buffer is copied to the L2ARC but then hit instead of  * evicted, then the L2ARC has cached a buffer much sooner than it probably  * needed to, potentially wasting L2ARC device bandwidth and storage.  It is  * safe to say that this is an uncommon case, since buffers at the end of  * the ARC lists have moved there due to inactivity.  *  * 4. If the ARC evicts faster than the L2ARC can maintain a headroom,  * then the L2ARC simply misses copying some buffers.  This serves as a  * pressure valve to prevent heavy read workloads from both stalling the ARC  * with waits and clogging the L2ARC with writes.  This also helps prevent  * the potential for the L2ARC to churn if it attempts to cache content too  * quickly, such as during backups of the entire pool.  *  * 5. After system boot and before the ARC has filled main memory, there are  * no evictions from the ARC and so the tails of the ARC_mfu and ARC_mru  * lists can remain mostly static.  Instead of searching from tail of these  * lists as pictured, the l2arc_feed_thread() will search from the list heads  * for eligible buffers, greatly increasing its chance of finding them.  *  * The L2ARC device write speed is also boosted during this time so that  * the L2ARC warms up faster.  Since there have been no ARC evictions yet,  * there are no L2ARC reads, and no fear of degrading read performance  * through increased writes.  *  * 6. Writes to the L2ARC devices are grouped and sent in-sequence, so that  * the vdev queue can aggregate them into larger and fewer writes.  Each  * device is written to in a rotor fashion, sweeping writes through  * available space then repeating.  *  * 7. The L2ARC does not store dirty content.  It never needs to flush  * write buffers back to disk based storage.  *  * 8. If an ARC buffer is written (and dirtied) which also exists in the  * L2ARC, the now stale L2ARC buffer is immediately dropped.  *  * The performance of the L2ARC can be tweaked by a number of tunables, which  * may be necessary for different workloads:  *  *	l2arc_write_max		max write bytes per interval  *	l2arc_write_boost	extra write bytes during device warmup  *	l2arc_noprefetch	skip caching prefetched buffers  *	l2arc_headroom		number of max device writes to precache  *	l2arc_headroom_boost	when we find compressed buffers during ARC  *				scanning, we multiply headroom by this  *				percentage factor for the next scan cycle,  *				since more compressed buffers are likely to  *				be present  *	l2arc_feed_secs		seconds between L2ARC writing  *  * Tunables may be removed or added as future performance improvements are  * integrated, and also may become zpool properties.  *  * There are three key functions that control how the L2ARC warms up:  *  *	l2arc_write_eligible()	check if a buffer is eligible to cache  *	l2arc_write_size()	calculate how much to write  *	l2arc_write_interval()	calculate sleep delay between writes  *  * These three functions determine what to write, how much, and how quickly  * to send writes.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|l2arc_write_eligible
parameter_list|(
name|uint64_t
name|spa_guid
parameter_list|,
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
comment|/* 	 * A buffer is *not* eligible for the L2ARC if it: 	 * 1. belongs to a different spa. 	 * 2. is already cached on the L2ARC. 	 * 3. has an I/O in progress (it may be an incomplete read). 	 * 4. is flagged not eligible (zfs property). 	 */
if|if
condition|(
name|hdr
operator|->
name|b_spa
operator|!=
name|spa_guid
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_spa_mismatch
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_in_l2
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
if|if
condition|(
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_hdr_io_in_progress
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
if|if
condition|(
operator|!
name|HDR_L2CACHE
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_not_cacheable
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
return|return
operator|(
name|B_TRUE
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|l2arc_write_size
parameter_list|(
name|void
parameter_list|)
block|{
name|uint64_t
name|size
decl_stmt|;
comment|/* 	 * Make sure our globals have meaningful values in case the user 	 * altered them. 	 */
name|size
operator|=
name|l2arc_write_max
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
block|{
name|cmn_err
argument_list|(
name|CE_NOTE
argument_list|,
literal|"Bad value for l2arc_write_max, value must "
literal|"be greater than zero, resetting it to the default (%d)"
argument_list|,
name|L2ARC_WRITE_SIZE
argument_list|)
expr_stmt|;
name|size
operator|=
name|l2arc_write_max
operator|=
name|L2ARC_WRITE_SIZE
expr_stmt|;
block|}
if|if
condition|(
name|arc_warm
operator|==
name|B_FALSE
condition|)
name|size
operator|+=
name|l2arc_write_boost
expr_stmt|;
return|return
operator|(
name|size
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|clock_t
name|l2arc_write_interval
parameter_list|(
name|clock_t
name|began
parameter_list|,
name|uint64_t
name|wanted
parameter_list|,
name|uint64_t
name|wrote
parameter_list|)
block|{
name|clock_t
name|interval
decl_stmt|,
name|next
decl_stmt|,
name|now
decl_stmt|;
comment|/* 	 * If the ARC lists are busy, increase our write rate; if the 	 * lists are stale, idle back.  This is achieved by checking 	 * how much we previously wrote - if it was more than half of 	 * what we wanted, schedule the next write much sooner. 	 */
if|if
condition|(
name|l2arc_feed_again
operator|&&
name|wrote
operator|>
operator|(
name|wanted
operator|/
literal|2
operator|)
condition|)
name|interval
operator|=
operator|(
name|hz
operator|*
name|l2arc_feed_min_ms
operator|)
operator|/
literal|1000
expr_stmt|;
else|else
name|interval
operator|=
name|hz
operator|*
name|l2arc_feed_secs
expr_stmt|;
name|now
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
name|next
operator|=
name|MAX
argument_list|(
name|now
argument_list|,
name|MIN
argument_list|(
name|now
operator|+
name|interval
argument_list|,
name|began
operator|+
name|interval
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|next
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Cycle through L2ARC devices.  This is how L2ARC load balances.  * If a device is returned, this also returns holding the spa config lock.  */
end_comment

begin_function
specifier|static
name|l2arc_dev_t
modifier|*
name|l2arc_dev_get_next
parameter_list|(
name|void
parameter_list|)
block|{
name|l2arc_dev_t
modifier|*
name|first
decl_stmt|,
modifier|*
name|next
init|=
name|NULL
decl_stmt|;
comment|/* 	 * Lock out the removal of spas (spa_namespace_lock), then removal 	 * of cache devices (l2arc_dev_mtx).  Once a device has been selected, 	 * both locks will be dropped and a spa config lock held instead. 	 */
name|mutex_enter
argument_list|(
operator|&
name|spa_namespace_lock
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
comment|/* if there are no vdevs, there is nothing to do */
if|if
condition|(
name|l2arc_ndev
operator|==
literal|0
condition|)
goto|goto
name|out
goto|;
name|first
operator|=
name|NULL
expr_stmt|;
name|next
operator|=
name|l2arc_dev_last
expr_stmt|;
do|do
block|{
comment|/* loop around the list looking for a non-faulted vdev */
if|if
condition|(
name|next
operator|==
name|NULL
condition|)
block|{
name|next
operator|=
name|list_head
argument_list|(
name|l2arc_dev_list
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|next
operator|=
name|list_next
argument_list|(
name|l2arc_dev_list
argument_list|,
name|next
argument_list|)
expr_stmt|;
if|if
condition|(
name|next
operator|==
name|NULL
condition|)
name|next
operator|=
name|list_head
argument_list|(
name|l2arc_dev_list
argument_list|)
expr_stmt|;
block|}
comment|/* if we have come back to the start, bail out */
if|if
condition|(
name|first
operator|==
name|NULL
condition|)
name|first
operator|=
name|next
expr_stmt|;
elseif|else
if|if
condition|(
name|next
operator|==
name|first
condition|)
break|break;
block|}
do|while
condition|(
name|vdev_is_dead
argument_list|(
name|next
operator|->
name|l2ad_vdev
argument_list|)
condition|)
do|;
comment|/* if we were unable to find any usable vdevs, return NULL */
if|if
condition|(
name|vdev_is_dead
argument_list|(
name|next
operator|->
name|l2ad_vdev
argument_list|)
condition|)
name|next
operator|=
name|NULL
expr_stmt|;
name|l2arc_dev_last
operator|=
name|next
expr_stmt|;
name|out
label|:
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Grab the config lock to prevent the 'next' device from being 	 * removed while we are writing to it. 	 */
if|if
condition|(
name|next
operator|!=
name|NULL
condition|)
name|spa_config_enter
argument_list|(
name|next
operator|->
name|l2ad_spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|next
argument_list|,
name|RW_READER
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|spa_namespace_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|next
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Free buffers that were tagged for destruction.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_do_free_on_write
parameter_list|()
block|{
name|list_t
modifier|*
name|buflist
decl_stmt|;
name|l2arc_data_free_t
modifier|*
name|df
decl_stmt|,
modifier|*
name|df_prev
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|)
expr_stmt|;
name|buflist
operator|=
name|l2arc_free_on_write
expr_stmt|;
for|for
control|(
name|df
operator|=
name|list_tail
argument_list|(
name|buflist
argument_list|)
init|;
name|df
condition|;
name|df
operator|=
name|df_prev
control|)
block|{
name|df_prev
operator|=
name|list_prev
argument_list|(
name|buflist
argument_list|,
name|df
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|df
operator|->
name|l2df_data
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|df
operator|->
name|l2df_func
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|df
operator|->
name|l2df_func
argument_list|(
name|df
operator|->
name|l2df_data
argument_list|,
name|df
operator|->
name|l2df_size
argument_list|)
expr_stmt|;
name|list_remove
argument_list|(
name|buflist
argument_list|,
name|df
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|df
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_data_free_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * A write to a cache device has completed.  Update all headers to allow  * reads from these buffers to begin.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_write_done
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|l2arc_write_callback_t
modifier|*
name|cb
decl_stmt|;
name|l2arc_dev_t
modifier|*
name|dev
decl_stmt|;
name|list_t
modifier|*
name|buflist
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|head
decl_stmt|,
modifier|*
name|hdr
decl_stmt|,
modifier|*
name|hdr_prev
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|int64_t
name|bytes_dropped
init|=
literal|0
decl_stmt|;
name|cb
operator|=
name|zio
operator|->
name|io_private
expr_stmt|;
name|ASSERT
argument_list|(
name|cb
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|dev
operator|=
name|cb
operator|->
name|l2wcb_dev
expr_stmt|;
name|ASSERT
argument_list|(
name|dev
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|head
operator|=
name|cb
operator|->
name|l2wcb_head
expr_stmt|;
name|ASSERT
argument_list|(
name|head
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|buflist
operator|=
operator|&
name|dev
operator|->
name|l2ad_buflist
expr_stmt|;
name|ASSERT
argument_list|(
name|buflist
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|DTRACE_PROBE2
argument_list|(
name|l2arc__iodone
argument_list|,
name|zio_t
operator|*
argument_list|,
name|zio
argument_list|,
name|l2arc_write_callback_t
operator|*
argument_list|,
name|cb
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio
operator|->
name|io_error
operator|!=
literal|0
condition|)
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_writes_error
argument_list|)
expr_stmt|;
comment|/* 	 * All writes completed, or an error was hit. 	 */
name|top
label|:
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
for|for
control|(
name|hdr
operator|=
name|list_prev
argument_list|(
name|buflist
argument_list|,
name|head
argument_list|)
init|;
name|hdr
condition|;
name|hdr
operator|=
name|hdr_prev
control|)
block|{
name|hdr_prev
operator|=
name|list_prev
argument_list|(
name|buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* 		 * We cannot use mutex_enter or else we can deadlock 		 * with l2arc_write_buffers (due to swapping the order 		 * the hash lock and l2ad_mtx are taken). 		 */
if|if
condition|(
operator|!
name|mutex_tryenter
argument_list|(
name|hash_lock
argument_list|)
condition|)
block|{
comment|/* 			 * Missed the hash lock. We must retry so we 			 * don't leave the ARC_FLAG_L2_WRITING bit set. 			 */
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_writes_lock_retry
argument_list|)
expr_stmt|;
comment|/* 			 * We don't want to rescan the headers we've 			 * already marked as having been written out, so 			 * we reinsert the head node so we can pick up 			 * where we left off. 			 */
name|list_remove
argument_list|(
name|buflist
argument_list|,
name|head
argument_list|)
expr_stmt|;
name|list_insert_after
argument_list|(
name|buflist
argument_list|,
name|hdr
argument_list|,
name|head
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 			 * We wait for the hash lock to become available 			 * to try and prevent busy waiting, and increase 			 * the chance we'll be able to acquire the lock 			 * the next time around. 			 */
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
goto|goto
name|top
goto|;
block|}
comment|/* 		 * We could not have been moved into the arc_l2c_only 		 * state while in-flight due to our ARC_FLAG_L2_WRITING 		 * bit being set. Let's just ensure that's being enforced. 		 */
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 		 * We may have allocated a buffer for L2ARC compression, 		 * we must release it to avoid leaking this data. 		 */
name|l2arc_release_cdata_buf
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio
operator|->
name|io_error
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * Error - drop L2ARC entry. 			 */
name|list_remove
argument_list|(
name|buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|l2arc_trim
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_HAS_L2HDR
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_asize
argument_list|,
operator|-
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_size
argument_list|,
operator|-
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
name|bytes_dropped
operator|+=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_alloc
argument_list|,
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Allow ARC to begin reads and ghost list evictions to 		 * this L2ARC entry. 		 */
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_FLAG_L2_WRITING
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
name|atomic_inc_64
argument_list|(
operator|&
name|l2arc_writes_done
argument_list|)
expr_stmt|;
name|list_remove
argument_list|(
name|buflist
argument_list|,
name|head
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_HAS_L1HDR
argument_list|(
name|head
argument_list|)
argument_list|)
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|hdr_l2only_cache
argument_list|,
name|head
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|vdev_space_update
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
operator|-
name|bytes_dropped
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|l2arc_do_free_on_write
argument_list|()
expr_stmt|;
name|kmem_free
argument_list|(
name|cb
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_write_callback_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * A read to a cache device completed.  Validate buffer contents before  * handing over to the regular ARC routines.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_read_done
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|l2arc_read_callback_t
modifier|*
name|cb
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|arc_buf_t
modifier|*
name|buf
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|int
name|equal
decl_stmt|;
name|ASSERT
argument_list|(
name|zio
operator|->
name|io_vd
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|zio
operator|->
name|io_flags
operator|&
name|ZIO_FLAG_DONT_PROPAGATE
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|zio
operator|->
name|io_spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|zio
operator|->
name|io_vd
argument_list|)
expr_stmt|;
name|cb
operator|=
name|zio
operator|->
name|io_private
expr_stmt|;
name|ASSERT
argument_list|(
name|cb
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|buf
operator|=
name|cb
operator|->
name|l2rcb_buf
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|buf
operator|->
name|b_hdr
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hash_lock
argument_list|,
operator|==
argument_list|,
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the buffer was compressed, decompress it first. 	 */
if|if
condition|(
name|cb
operator|->
name|l2rcb_compress
operator|!=
name|ZIO_COMPRESS_OFF
condition|)
name|l2arc_decompress_zio
argument_list|(
name|zio
argument_list|,
name|hdr
argument_list|,
name|cb
operator|->
name|l2rcb_compress
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|zio
operator|->
name|io_data
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|zio
operator|->
name|io_size
argument_list|,
operator|==
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|BP_GET_LSIZE
argument_list|(
operator|&
name|cb
operator|->
name|l2rcb_bp
argument_list|)
argument_list|,
operator|==
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
comment|/* 	 * Check this survived the L2ARC journey. 	 */
name|equal
operator|=
name|arc_cksum_equal
argument_list|(
name|buf
argument_list|)
expr_stmt|;
if|if
condition|(
name|equal
operator|&&
name|zio
operator|->
name|io_error
operator|==
literal|0
operator|&&
operator|!
name|HDR_L2_EVICTED
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|zio
operator|->
name|io_private
operator|=
name|buf
expr_stmt|;
name|zio
operator|->
name|io_bp_copy
operator|=
name|cb
operator|->
name|l2rcb_bp
expr_stmt|;
comment|/* XXX fix in L2ARC 2.0	*/
name|zio
operator|->
name|io_bp
operator|=
operator|&
name|zio
operator|->
name|io_bp_copy
expr_stmt|;
comment|/* XXX fix in L2ARC 2.0	*/
name|arc_read_done
argument_list|(
name|zio
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
comment|/* 		 * Buffer didn't survive caching.  Increment stats and 		 * reissue to the original storage device. 		 */
if|if
condition|(
name|zio
operator|->
name|io_error
operator|!=
literal|0
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_io_error
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|zio
operator|->
name|io_error
operator|=
name|SET_ERROR
argument_list|(
name|EIO
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|equal
condition|)
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_cksum_bad
argument_list|)
expr_stmt|;
comment|/* 		 * If there's no waiter, issue an async i/o to the primary 		 * storage now.  If there *is* a waiter, the caller must 		 * issue the i/o in a context where it's OK to block. 		 */
if|if
condition|(
name|zio
operator|->
name|io_waiter
operator|==
name|NULL
condition|)
block|{
name|zio_t
modifier|*
name|pio
init|=
name|zio_unique_parent
argument_list|(
name|zio
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|pio
operator|||
name|pio
operator|->
name|io_child_type
operator|==
name|ZIO_CHILD_LOGICAL
argument_list|)
expr_stmt|;
name|zio_nowait
argument_list|(
name|zio_read
argument_list|(
name|pio
argument_list|,
name|cb
operator|->
name|l2rcb_spa
argument_list|,
operator|&
name|cb
operator|->
name|l2rcb_bp
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|,
name|arc_read_done
argument_list|,
name|buf
argument_list|,
name|zio
operator|->
name|io_priority
argument_list|,
name|cb
operator|->
name|l2rcb_flags
argument_list|,
operator|&
name|cb
operator|->
name|l2rcb_zb
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|kmem_free
argument_list|(
name|cb
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_read_callback_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This is the list priority from which the L2ARC will search for pages to  * cache.  This is used within loops (0..3) to cycle through lists in the  * desired order.  This order can have a significant effect on cache  * performance.  *  * Currently the metadata lists are hit first, MFU then MRU, followed by  * the data lists.  This function returns a locked list, and also returns  * the lock pointer.  */
end_comment

begin_function
specifier|static
name|multilist_sublist_t
modifier|*
name|l2arc_sublist_lock
parameter_list|(
name|int
name|list_num
parameter_list|)
block|{
name|multilist_t
modifier|*
name|ml
init|=
name|NULL
decl_stmt|;
name|unsigned
name|int
name|idx
decl_stmt|;
name|ASSERT
argument_list|(
name|list_num
operator|>=
literal|0
operator|&&
name|list_num
operator|<=
literal|3
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|list_num
condition|)
block|{
case|case
literal|0
case|:
name|ml
operator|=
operator|&
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
expr_stmt|;
break|break;
case|case
literal|1
case|:
name|ml
operator|=
operator|&
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
expr_stmt|;
break|break;
case|case
literal|2
case|:
name|ml
operator|=
operator|&
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
expr_stmt|;
break|break;
case|case
literal|3
case|:
name|ml
operator|=
operator|&
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
expr_stmt|;
break|break;
block|}
comment|/* 	 * Return a randomly-selected sublist. This is acceptable 	 * because the caller feeds only a little bit of data for each 	 * call (8MB). Subsequent calls will result in different 	 * sublists being selected. 	 */
name|idx
operator|=
name|multilist_get_random_index
argument_list|(
name|ml
argument_list|)
expr_stmt|;
return|return
operator|(
name|multilist_sublist_lock
argument_list|(
name|ml
argument_list|,
name|idx
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict buffers from the device write hand to the distance specified in  * bytes.  This distance may span populated buffers, it may span nothing.  * This is clearing a region on the L2ARC device ready for writing.  * If the 'all' boolean is set, every buffer is evicted.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_evict
parameter_list|(
name|l2arc_dev_t
modifier|*
name|dev
parameter_list|,
name|uint64_t
name|distance
parameter_list|,
name|boolean_t
name|all
parameter_list|)
block|{
name|list_t
modifier|*
name|buflist
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|,
modifier|*
name|hdr_prev
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|uint64_t
name|taddr
decl_stmt|;
name|buflist
operator|=
operator|&
name|dev
operator|->
name|l2ad_buflist
expr_stmt|;
if|if
condition|(
operator|!
name|all
operator|&&
name|dev
operator|->
name|l2ad_first
condition|)
block|{
comment|/* 		 * This is the first sweep through the device.  There is 		 * nothing to evict. 		 */
return|return;
block|}
if|if
condition|(
name|dev
operator|->
name|l2ad_hand
operator|>=
operator|(
name|dev
operator|->
name|l2ad_end
operator|-
operator|(
literal|2
operator|*
name|distance
operator|)
operator|)
condition|)
block|{
comment|/* 		 * When nearing the end of the device, evict to the end 		 * before the device write hand jumps to the start. 		 */
name|taddr
operator|=
name|dev
operator|->
name|l2ad_end
expr_stmt|;
block|}
else|else
block|{
name|taddr
operator|=
name|dev
operator|->
name|l2ad_hand
operator|+
name|distance
expr_stmt|;
block|}
name|DTRACE_PROBE4
argument_list|(
name|l2arc__evict
argument_list|,
name|l2arc_dev_t
operator|*
argument_list|,
name|dev
argument_list|,
name|list_t
operator|*
argument_list|,
name|buflist
argument_list|,
name|uint64_t
argument_list|,
name|taddr
argument_list|,
name|boolean_t
argument_list|,
name|all
argument_list|)
expr_stmt|;
name|top
label|:
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
for|for
control|(
name|hdr
operator|=
name|list_tail
argument_list|(
name|buflist
argument_list|)
init|;
name|hdr
condition|;
name|hdr
operator|=
name|hdr_prev
control|)
block|{
name|hdr_prev
operator|=
name|list_prev
argument_list|(
name|buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* 		 * We cannot use mutex_enter or else we can deadlock 		 * with l2arc_write_buffers (due to swapping the order 		 * the hash lock and l2ad_mtx are taken). 		 */
if|if
condition|(
operator|!
name|mutex_tryenter
argument_list|(
name|hash_lock
argument_list|)
condition|)
block|{
comment|/* 			 * Missed the hash lock.  Retry. 			 */
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_evict_lock_retry
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
goto|goto
name|top
goto|;
block|}
if|if
condition|(
name|HDR_L2_WRITE_HEAD
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
comment|/* 			 * We hit a write head node.  Leave it for 			 * l2arc_write_done(). 			 */
name|list_remove
argument_list|(
name|buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|!
name|all
operator|&&
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|(
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
operator|>
name|taddr
operator|||
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
operator|<
name|dev
operator|->
name|l2ad_hand
operator|)
condition|)
block|{
comment|/* 			 * We've evicted to the target address, 			 * or the end of the device. 			 */
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
break|break;
block|}
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
operator|!
name|HDR_L2_READING
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 			 * This doesn't exist in the ARC.  Destroy. 			 * arc_hdr_destroy() will call list_remove() 			 * and decrement arcstat_l2_size. 			 */
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|!=
name|arc_l2c_only
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_evict_l1cached
argument_list|)
expr_stmt|;
comment|/* 			 * Invalidate issued or about to be issued 			 * reads, since we may be about to write 			 * over this location. 			 */
if|if
condition|(
name|HDR_L2_READING
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_evict_reading
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2_EVICTED
expr_stmt|;
block|}
comment|/* Ensure this header has finished being written */
name|ASSERT
argument_list|(
operator|!
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|arc_hdr_l2hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Find and write ARC buffers to the L2ARC device.  *  * An ARC_FLAG_L2_WRITING flag is set so that the L2ARC buffers are not valid  * for reading until they have completed writing.  * The headroom_boost is an in-out parameter used to maintain headroom boost  * state between calls to this function.  *  * Returns the number of bytes actually written (which may be smaller than  * the delta by which the device hand has changed due to alignment).  */
end_comment

begin_function
specifier|static
name|uint64_t
name|l2arc_write_buffers
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|l2arc_dev_t
modifier|*
name|dev
parameter_list|,
name|uint64_t
name|target_sz
parameter_list|,
name|boolean_t
modifier|*
name|headroom_boost
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|,
modifier|*
name|hdr_prev
decl_stmt|,
modifier|*
name|head
decl_stmt|;
name|uint64_t
name|write_asize
decl_stmt|,
name|write_sz
decl_stmt|,
name|headroom
decl_stmt|,
name|buf_compress_minsz
decl_stmt|;
name|void
modifier|*
name|buf_data
decl_stmt|;
name|boolean_t
name|full
decl_stmt|;
name|l2arc_write_callback_t
modifier|*
name|cb
decl_stmt|;
name|zio_t
modifier|*
name|pio
decl_stmt|,
modifier|*
name|wzio
decl_stmt|;
name|uint64_t
name|guid
init|=
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
decl_stmt|;
specifier|const
name|boolean_t
name|do_headroom_boost
init|=
operator|*
name|headroom_boost
decl_stmt|;
name|int
name|try
decl_stmt|;
name|ASSERT
argument_list|(
name|dev
operator|->
name|l2ad_vdev
operator|!=
name|NULL
argument_list|)
expr_stmt|;
comment|/* Lower the flag now, we might want to raise it again later. */
operator|*
name|headroom_boost
operator|=
name|B_FALSE
expr_stmt|;
name|pio
operator|=
name|NULL
expr_stmt|;
name|write_sz
operator|=
name|write_asize
operator|=
literal|0
expr_stmt|;
name|full
operator|=
name|B_FALSE
expr_stmt|;
name|head
operator|=
name|kmem_cache_alloc
argument_list|(
name|hdr_l2only_cache
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|head
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2_WRITE_HEAD
expr_stmt|;
name|head
operator|->
name|b_flags
operator||=
name|ARC_FLAG_HAS_L2HDR
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_buffer_iter
argument_list|)
expr_stmt|;
comment|/* 	 * We will want to try to compress buffers that are at least 2x the 	 * device sector size. 	 */
name|buf_compress_minsz
operator|=
literal|2
operator|<<
name|dev
operator|->
name|l2ad_vdev
operator|->
name|vdev_ashift
expr_stmt|;
comment|/* 	 * Copy buffers for L2ARC writing. 	 */
for|for
control|(
name|try
operator|=
literal|0
init|;
name|try
operator|<=
literal|3
condition|;
name|try
operator|++
control|)
block|{
name|multilist_sublist_t
modifier|*
name|mls
init|=
name|l2arc_sublist_lock
argument_list|(
name|try
argument_list|)
decl_stmt|;
name|uint64_t
name|passed_sz
init|=
literal|0
decl_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_buffer_list_iter
argument_list|)
expr_stmt|;
comment|/* 		 * L2ARC fast warmup. 		 * 		 * Until the ARC is warm and starts to evict, read from the 		 * head of the ARC lists rather than the tail. 		 */
if|if
condition|(
name|arc_warm
operator|==
name|B_FALSE
condition|)
name|hdr
operator|=
name|multilist_sublist_head
argument_list|(
name|mls
argument_list|)
expr_stmt|;
else|else
name|hdr
operator|=
name|multilist_sublist_tail
argument_list|(
name|mls
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|==
name|NULL
condition|)
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_buffer_list_null_iter
argument_list|)
expr_stmt|;
name|headroom
operator|=
name|target_sz
operator|*
name|l2arc_headroom
expr_stmt|;
if|if
condition|(
name|do_headroom_boost
condition|)
name|headroom
operator|=
operator|(
name|headroom
operator|*
name|l2arc_headroom_boost
operator|)
operator|/
literal|100
expr_stmt|;
for|for
control|(
init|;
name|hdr
condition|;
name|hdr
operator|=
name|hdr_prev
control|)
block|{
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|uint64_t
name|buf_sz
decl_stmt|;
name|uint64_t
name|buf_a_sz
decl_stmt|;
if|if
condition|(
name|arc_warm
operator|==
name|B_FALSE
condition|)
name|hdr_prev
operator|=
name|multilist_sublist_next
argument_list|(
name|mls
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
else|else
name|hdr_prev
operator|=
name|multilist_sublist_prev
argument_list|(
name|mls
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_write_buffer_bytes_scanned
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|mutex_tryenter
argument_list|(
name|hash_lock
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_trylock_fail
argument_list|)
expr_stmt|;
comment|/* 				 * Skip this buffer rather than waiting. 				 */
continue|continue;
block|}
name|passed_sz
operator|+=
name|hdr
operator|->
name|b_size
expr_stmt|;
if|if
condition|(
name|passed_sz
operator|>
name|headroom
condition|)
block|{
comment|/* 				 * Searched too far. 				 */
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_passed_headroom
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
operator|!
name|l2arc_write_eligible
argument_list|(
name|guid
argument_list|,
name|hdr
argument_list|)
condition|)
block|{
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 			 * Assume that the buffer is not going to be compressed 			 * and could take more space on disk because of a larger 			 * disk block size. 			 */
name|buf_sz
operator|=
name|hdr
operator|->
name|b_size
expr_stmt|;
name|buf_a_sz
operator|=
name|vdev_psize_to_asize
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|buf_sz
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|write_asize
operator|+
name|buf_a_sz
operator|)
operator|>
name|target_sz
condition|)
block|{
name|full
operator|=
name|B_TRUE
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_full
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|pio
operator|==
name|NULL
condition|)
block|{
comment|/* 				 * Insert a dummy header on the buflist so 				 * l2arc_write_done() can find where the 				 * write buffers begin without searching. 				 */
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|list_insert_head
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|head
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|cb
operator|=
name|kmem_alloc
argument_list|(
sizeof|sizeof
argument_list|(
name|l2arc_write_callback_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|cb
operator|->
name|l2wcb_dev
operator|=
name|dev
expr_stmt|;
name|cb
operator|->
name|l2wcb_head
operator|=
name|head
expr_stmt|;
name|pio
operator|=
name|zio_root
argument_list|(
name|spa
argument_list|,
name|l2arc_write_done
argument_list|,
name|cb
argument_list|,
name|ZIO_FLAG_CANFAIL
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_pios
argument_list|)
expr_stmt|;
block|}
comment|/* 			 * Create and add a new L2ARC header. 			 */
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|=
name|dev
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_L2_WRITING
expr_stmt|;
comment|/* 			 * Temporarily stash the data buffer in b_tmp_cdata. 			 * The subsequent write step will pick it up from 			 * there. This is because can't access b_l1hdr.b_buf 			 * without holding the hash_lock, which we in turn 			 * can't access without holding the ARC list locks 			 * (which we want to avoid during compression/writing). 			 */
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_compress
operator|=
name|ZIO_COMPRESS_OFF
expr_stmt|;
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
operator|=
name|hdr
operator|->
name|b_size
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|->
name|b_data
expr_stmt|;
comment|/* 			 * Explicitly set the b_daddr field to a known 			 * value which means "invalid address". This 			 * enables us to differentiate which stage of 			 * l2arc_write_buffers() the particular header 			 * is in (e.g. this loop, or the one below). 			 * ARC_FLAG_L2_WRITING is not enough to make 			 * this distinction, and we need to know in 			 * order to do proper l2arc vdev accounting in 			 * arc_release() and arc_hdr_destroy(). 			 * 			 * Note, we can't use a new flag to distinguish 			 * the two stages because we don't hold the 			 * header's hash_lock below, in the second stage 			 * of this function. Thus, we can't simply 			 * change the b_flags field to denote that the 			 * IO has been sent. We can change the b_daddr 			 * field of the L2 portion, though, since we'll 			 * be holding the l2ad_mtx; which is why we're 			 * using it to denote the header's state change. 			 */
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
operator|=
name|L2ARC_ADDR_UNSET
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|ARC_FLAG_HAS_L2HDR
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|list_insert_head
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 			 * Compute and store the buffer cksum before 			 * writing.  On debug the cksum is verified first. 			 */
name|arc_cksum_verify
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|)
expr_stmt|;
name|arc_cksum_compute
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
name|B_TRUE
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|write_sz
operator|+=
name|buf_sz
expr_stmt|;
name|write_asize
operator|+=
name|buf_a_sz
expr_stmt|;
block|}
name|multilist_sublist_unlock
argument_list|(
name|mls
argument_list|)
expr_stmt|;
if|if
condition|(
name|full
operator|==
name|B_TRUE
condition|)
break|break;
block|}
comment|/* No buffers selected for writing? */
if|if
condition|(
name|pio
operator|==
name|NULL
condition|)
block|{
name|ASSERT0
argument_list|(
name|write_sz
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_HAS_L1HDR
argument_list|(
name|head
argument_list|)
argument_list|)
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|hdr_l2only_cache
argument_list|,
name|head
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Note that elsewhere in this file arcstat_l2_asize 	 * and the used space on l2ad_vdev are updated using b_asize, 	 * which is not necessarily rounded up to the device block size. 	 * Too keep accounting consistent we do the same here as well: 	 * stats_size accumulates the sum of b_asize of the written buffers, 	 * while write_asize accumulates the sum of b_asize rounded up 	 * to the device block size. 	 * The latter sum is used only to validate the corectness of the code. 	 */
name|uint64_t
name|stats_size
init|=
literal|0
decl_stmt|;
name|write_asize
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Now start writing the buffers. We're starting at the write head 	 * and work backwards, retracing the course of the buffer selector 	 * loop above. 	 */
for|for
control|(
name|hdr
operator|=
name|list_prev
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|head
argument_list|)
init|;
name|hdr
condition|;
name|hdr
operator|=
name|list_prev
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|hdr
argument_list|)
control|)
block|{
name|uint64_t
name|buf_sz
decl_stmt|;
comment|/* 		 * We rely on the L1 portion of the header below, so 		 * it's invalid for this header to have been evicted out 		 * of the ghost cache, prior to being written out. The 		 * ARC_FLAG_L2_WRITING bit ensures this won't happen. 		 */
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 		 * We shouldn't need to lock the buffer here, since we flagged 		 * it as ARC_FLAG_L2_WRITING in the previous step, but we must 		 * take care to only access its L2 cache parameters. In 		 * particular, hdr->l1hdr.b_buf may be invalid by now due to 		 * ARC eviction. 		 */
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
operator|=
name|dev
operator|->
name|l2ad_hand
expr_stmt|;
if|if
condition|(
operator|(
name|HDR_L2COMPRESS
argument_list|(
name|hdr
argument_list|)
operator|)
operator|&&
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
operator|>=
name|buf_compress_minsz
condition|)
block|{
if|if
condition|(
name|l2arc_compress_buf
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
comment|/* 				 * If compression succeeded, enable headroom 				 * boost on the next scan cycle. 				 */
operator|*
name|headroom_boost
operator|=
name|B_TRUE
expr_stmt|;
block|}
block|}
comment|/* 		 * Pick up the buffer data we had previously stashed away 		 * (and now potentially also compressed). 		 */
name|buf_data
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
expr_stmt|;
name|buf_sz
operator|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_asize
expr_stmt|;
comment|/* 		 * We need to do this regardless if buf_sz is zero or 		 * not, otherwise, when this l2hdr is evicted we'll 		 * remove a reference that was never added. 		 */
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_alloc
argument_list|,
name|buf_sz
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
comment|/* Compression may have squashed the buffer to zero length. */
if|if
condition|(
name|buf_sz
operator|!=
literal|0
condition|)
block|{
name|uint64_t
name|buf_a_sz
decl_stmt|;
name|wzio
operator|=
name|zio_write_phys
argument_list|(
name|pio
argument_list|,
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|dev
operator|->
name|l2ad_hand
argument_list|,
name|buf_sz
argument_list|,
name|buf_data
argument_list|,
name|ZIO_CHECKSUM_OFF
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|ZIO_PRIORITY_ASYNC_WRITE
argument_list|,
name|ZIO_FLAG_CANFAIL
argument_list|,
name|B_FALSE
argument_list|)
expr_stmt|;
name|DTRACE_PROBE2
argument_list|(
name|l2arc__write
argument_list|,
name|vdev_t
operator|*
argument_list|,
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|zio_t
operator|*
argument_list|,
name|wzio
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|zio_nowait
argument_list|(
name|wzio
argument_list|)
expr_stmt|;
name|stats_size
operator|+=
name|buf_sz
expr_stmt|;
comment|/* 			 * Keep the clock hand suitably device-aligned. 			 */
name|buf_a_sz
operator|=
name|vdev_psize_to_asize
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|buf_sz
argument_list|)
expr_stmt|;
name|write_asize
operator|+=
name|buf_a_sz
expr_stmt|;
name|dev
operator|->
name|l2ad_hand
operator|+=
name|buf_a_sz
expr_stmt|;
block|}
block|}
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|write_asize
argument_list|,
operator|<=
argument_list|,
name|target_sz
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_writes_sent
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_write_bytes
argument_list|,
name|write_asize
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_size
argument_list|,
name|write_sz
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_asize
argument_list|,
name|stats_size
argument_list|)
expr_stmt|;
name|vdev_space_update
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|stats_size
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * Bump device hand to the device start if it is approaching the end. 	 * l2arc_evict() will already have evicted ahead for this case. 	 */
if|if
condition|(
name|dev
operator|->
name|l2ad_hand
operator|>=
operator|(
name|dev
operator|->
name|l2ad_end
operator|-
name|target_sz
operator|)
condition|)
block|{
name|dev
operator|->
name|l2ad_hand
operator|=
name|dev
operator|->
name|l2ad_start
expr_stmt|;
name|dev
operator|->
name|l2ad_first
operator|=
name|B_FALSE
expr_stmt|;
block|}
name|dev
operator|->
name|l2ad_writing
operator|=
name|B_TRUE
expr_stmt|;
operator|(
name|void
operator|)
name|zio_wait
argument_list|(
name|pio
argument_list|)
expr_stmt|;
name|dev
operator|->
name|l2ad_writing
operator|=
name|B_FALSE
expr_stmt|;
return|return
operator|(
name|write_asize
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Compresses an L2ARC buffer.  * The data to be compressed must be prefilled in l1hdr.b_tmp_cdata and its  * size in l2hdr->b_asize. This routine tries to compress the data and  * depending on the compression result there are three possible outcomes:  * *) The buffer was incompressible. The original l2hdr contents were left  *    untouched and are ready for writing to an L2 device.  * *) The buffer was all-zeros, so there is no need to write it to an L2  *    device. To indicate this situation b_tmp_cdata is NULL'ed, b_asize is  *    set to zero and b_compress is set to ZIO_COMPRESS_EMPTY.  * *) Compression succeeded and b_tmp_cdata was replaced with a temporary  *    data buffer which holds the compressed data to be written, and b_asize  *    tells us how much data there is. b_compress is set to the appropriate  *    compression algorithm. Once writing is done, invoke  *    l2arc_release_cdata_buf on this l2hdr to free this temporary buffer.  *  * Returns B_TRUE if compression succeeded, or B_FALSE if it didn't (the  * buffer was incompressible).  */
end_comment

begin_function
specifier|static
name|boolean_t
name|l2arc_compress_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|void
modifier|*
name|cdata
decl_stmt|;
name|size_t
name|csize
decl_stmt|,
name|len
decl_stmt|,
name|rounded
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|l2arc_buf_hdr_t
modifier|*
name|l2hdr
init|=
operator|&
name|hdr
operator|->
name|b_l2hdr
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3S
argument_list|(
name|l2hdr
operator|->
name|b_compress
argument_list|,
operator|==
argument_list|,
name|ZIO_COMPRESS_OFF
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|len
operator|=
name|l2hdr
operator|->
name|b_asize
expr_stmt|;
name|cdata
operator|=
name|zio_data_buf_alloc
argument_list|(
name|len
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|cdata
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|csize
operator|=
name|zio_compress_data
argument_list|(
name|ZIO_COMPRESS_LZ4
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
argument_list|,
name|cdata
argument_list|,
name|l2hdr
operator|->
name|b_asize
argument_list|)
expr_stmt|;
if|if
condition|(
name|csize
operator|==
literal|0
condition|)
block|{
comment|/* zero block, indicate that there's nothing to write */
name|zio_data_buf_free
argument_list|(
name|cdata
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|l2hdr
operator|->
name|b_compress
operator|=
name|ZIO_COMPRESS_EMPTY
expr_stmt|;
name|l2hdr
operator|->
name|b_asize
operator|=
literal|0
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|=
name|NULL
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_compress_zeros
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_TRUE
operator|)
return|;
block|}
name|rounded
operator|=
name|P2ROUNDUP
argument_list|(
name|csize
argument_list|,
operator|(
name|size_t
operator|)
literal|1
operator|<<
name|l2hdr
operator|->
name|b_dev
operator|->
name|l2ad_vdev
operator|->
name|vdev_ashift
argument_list|)
expr_stmt|;
if|if
condition|(
name|rounded
operator|<
name|len
condition|)
block|{
comment|/* 		 * Compression succeeded, we'll keep the cdata around for 		 * writing and release it afterwards. 		 */
if|if
condition|(
name|rounded
operator|>
name|csize
condition|)
block|{
name|bzero
argument_list|(
operator|(
name|char
operator|*
operator|)
name|cdata
operator|+
name|csize
argument_list|,
name|rounded
operator|-
name|csize
argument_list|)
expr_stmt|;
name|csize
operator|=
name|rounded
expr_stmt|;
block|}
name|l2hdr
operator|->
name|b_compress
operator|=
name|ZIO_COMPRESS_LZ4
expr_stmt|;
name|l2hdr
operator|->
name|b_asize
operator|=
name|csize
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|=
name|cdata
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_compress_successes
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_TRUE
operator|)
return|;
block|}
else|else
block|{
comment|/* 		 * Compression failed, release the compressed buffer. 		 * l2hdr will be left unmodified. 		 */
name|zio_data_buf_free
argument_list|(
name|cdata
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_compress_failures
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
block|}
end_function

begin_comment
comment|/*  * Decompresses a zio read back from an l2arc device. On success, the  * underlying zio's io_data buffer is overwritten by the uncompressed  * version. On decompression error (corrupt compressed stream), the  * zio->io_error value is set to signal an I/O error.  *  * Please note that the compressed data stream is not checksummed, so  * if the underlying device is experiencing data corruption, we may feed  * corrupt data to the decompressor, so the decompressor needs to be  * able to handle this situation (LZ4 does).  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_decompress_zio
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|,
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|enum
name|zio_compress
name|c
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|L2ARC_IS_VALID_COMPRESS
argument_list|(
name|c
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio
operator|->
name|io_error
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * An io error has occured, just restore the original io 		 * size in preparation for a main pool read. 		 */
name|zio
operator|->
name|io_orig_size
operator|=
name|zio
operator|->
name|io_size
operator|=
name|hdr
operator|->
name|b_size
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|c
operator|==
name|ZIO_COMPRESS_EMPTY
condition|)
block|{
comment|/* 		 * An empty buffer results in a null zio, which means we 		 * need to fill its io_data after we're done restoring the 		 * buffer's contents. 		 */
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|->
name|b_data
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
name|zio
operator|->
name|io_data
operator|=
name|zio
operator|->
name|io_orig_data
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|->
name|b_data
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|zio
operator|->
name|io_data
operator|!=
name|NULL
argument_list|)
expr_stmt|;
comment|/* 		 * We copy the compressed data from the start of the arc buffer 		 * (the zio_read will have pulled in only what we need, the 		 * rest is garbage which we will overwrite at decompression) 		 * and then decompress back to the ARC data buffer. This way we 		 * can minimize copying by simply decompressing back over the 		 * original compressed data (rather than decompressing to an 		 * aux buffer and then copying back the uncompressed buffer, 		 * which is likely to be much larger). 		 */
name|uint64_t
name|csize
decl_stmt|;
name|void
modifier|*
name|cdata
decl_stmt|;
name|csize
operator|=
name|zio
operator|->
name|io_size
expr_stmt|;
name|cdata
operator|=
name|zio_data_buf_alloc
argument_list|(
name|csize
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|zio
operator|->
name|io_data
argument_list|,
name|cdata
argument_list|,
name|csize
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio_decompress_data
argument_list|(
name|c
argument_list|,
name|cdata
argument_list|,
name|zio
operator|->
name|io_data
argument_list|,
name|csize
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
operator|!=
literal|0
condition|)
name|zio
operator|->
name|io_error
operator|=
name|EIO
expr_stmt|;
name|zio_data_buf_free
argument_list|(
name|cdata
argument_list|,
name|csize
argument_list|)
expr_stmt|;
block|}
comment|/* Restore the expected uncompressed IO size. */
name|zio
operator|->
name|io_orig_size
operator|=
name|zio
operator|->
name|io_size
operator|=
name|hdr
operator|->
name|b_size
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Releases the temporary b_tmp_cdata buffer in an l2arc header structure.  * This buffer serves as a temporary holder of compressed data while  * the buffer entry is being written to an l2arc device. Once that is  * done, we can dispose of it.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_release_cdata_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|enum
name|zio_compress
name|comp
init|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_compress
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|comp
operator|==
name|ZIO_COMPRESS_OFF
operator|||
name|L2ARC_IS_VALID_COMPRESS
argument_list|(
name|comp
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|comp
operator|==
name|ZIO_COMPRESS_OFF
condition|)
block|{
comment|/* 		 * In this case, b_tmp_cdata points to the same buffer 		 * as the arc_buf_t's b_data field. We don't want to 		 * free it, since the arc_buf_t will handle that. 		 */
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|=
name|NULL
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|comp
operator|==
name|ZIO_COMPRESS_EMPTY
condition|)
block|{
comment|/* 		 * In this case, b_tmp_cdata was compressed to an empty 		 * buffer, thus there's nothing to free and b_tmp_cdata 		 * should have been set to NULL in l2arc_write_buffers(). 		 */
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * If the data was compressed, then we've allocated a 		 * temporary buffer for it, so now we need to release it. 		 */
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|zio_data_buf_free
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
argument_list|,
name|hdr
operator|->
name|b_size
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_tmp_cdata
operator|=
name|NULL
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * This thread feeds the L2ARC at regular intervals.  This is the beating  * heart of the L2ARC.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_feed_thread
parameter_list|(
name|void
modifier|*
name|dummy
name|__unused
parameter_list|)
block|{
name|callb_cpr_t
name|cpr
decl_stmt|;
name|l2arc_dev_t
modifier|*
name|dev
decl_stmt|;
name|spa_t
modifier|*
name|spa
decl_stmt|;
name|uint64_t
name|size
decl_stmt|,
name|wrote
decl_stmt|;
name|clock_t
name|begin
decl_stmt|,
name|next
init|=
name|ddi_get_lbolt
argument_list|()
decl_stmt|;
name|boolean_t
name|headroom_boost
init|=
name|B_FALSE
decl_stmt|;
name|CALLB_CPR_INIT
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|l2arc_feed_thr_lock
argument_list|,
name|callb_generic_cpr
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
while|while
condition|(
name|l2arc_thread_exit
operator|==
literal|0
condition|)
block|{
name|CALLB_CPR_SAFE_BEGIN
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|cv_timedwait
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|,
operator|&
name|l2arc_feed_thr_lock
argument_list|,
name|next
operator|-
name|ddi_get_lbolt
argument_list|()
argument_list|)
expr_stmt|;
name|CALLB_CPR_SAFE_END
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
name|next
operator|=
name|ddi_get_lbolt
argument_list|()
operator|+
name|hz
expr_stmt|;
comment|/* 		 * Quick check for L2ARC devices. 		 */
name|mutex_enter
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2arc_ndev
operator|==
literal|0
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
name|begin
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
comment|/* 		 * This selects the next l2arc device to write to, and in 		 * doing so the next spa to feed from: dev->l2ad_spa.   This 		 * will return NULL if there are now no l2arc devices or if 		 * they are all faulted. 		 * 		 * If a device is returned, its spa's config lock is also 		 * held to prevent device removal.  l2arc_dev_get_next() 		 * will grab and release l2arc_dev_mtx. 		 */
if|if
condition|(
operator|(
name|dev
operator|=
name|l2arc_dev_get_next
argument_list|()
operator|)
operator|==
name|NULL
condition|)
continue|continue;
name|spa
operator|=
name|dev
operator|->
name|l2ad_spa
expr_stmt|;
name|ASSERT
argument_list|(
name|spa
operator|!=
name|NULL
argument_list|)
expr_stmt|;
comment|/* 		 * If the pool is read-only then force the feed thread to 		 * sleep a little longer. 		 */
if|if
condition|(
operator|!
name|spa_writeable
argument_list|(
name|spa
argument_list|)
condition|)
block|{
name|next
operator|=
name|ddi_get_lbolt
argument_list|()
operator|+
literal|5
operator|*
name|l2arc_feed_secs
operator|*
name|hz
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|dev
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Avoid contributing to memory pressure. 		 */
if|if
condition|(
name|arc_reclaim_needed
argument_list|()
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_abort_lowmem
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|dev
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_feeds
argument_list|)
expr_stmt|;
name|size
operator|=
name|l2arc_write_size
argument_list|()
expr_stmt|;
comment|/* 		 * Evict L2ARC buffers that will be overwritten. 		 */
name|l2arc_evict
argument_list|(
name|dev
argument_list|,
name|size
argument_list|,
name|B_FALSE
argument_list|)
expr_stmt|;
comment|/* 		 * Write ARC buffers. 		 */
name|wrote
operator|=
name|l2arc_write_buffers
argument_list|(
name|spa
argument_list|,
name|dev
argument_list|,
name|size
argument_list|,
operator|&
name|headroom_boost
argument_list|)
expr_stmt|;
comment|/* 		 * Calculate interval between writes. 		 */
name|next
operator|=
name|l2arc_write_interval
argument_list|(
name|begin
argument_list|,
name|size
argument_list|,
name|wrote
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|dev
argument_list|)
expr_stmt|;
block|}
name|l2arc_thread_exit
operator|=
literal|0
expr_stmt|;
name|cv_broadcast
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|)
expr_stmt|;
name|CALLB_CPR_EXIT
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
comment|/* drops l2arc_feed_thr_lock */
name|thread_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|boolean_t
name|l2arc_vdev_present
parameter_list|(
name|vdev_t
modifier|*
name|vd
parameter_list|)
block|{
name|l2arc_dev_t
modifier|*
name|dev
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
for|for
control|(
name|dev
operator|=
name|list_head
argument_list|(
name|l2arc_dev_list
argument_list|)
init|;
name|dev
operator|!=
name|NULL
condition|;
name|dev
operator|=
name|list_next
argument_list|(
name|l2arc_dev_list
argument_list|,
name|dev
argument_list|)
control|)
block|{
if|if
condition|(
name|dev
operator|->
name|l2ad_vdev
operator|==
name|vd
condition|)
break|break;
block|}
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|dev
operator|!=
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Add a vdev for use by the L2ARC.  By this point the spa has already  * validated the vdev and opened it.  */
end_comment

begin_function
name|void
name|l2arc_add_vdev
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|vdev_t
modifier|*
name|vd
parameter_list|)
block|{
name|l2arc_dev_t
modifier|*
name|adddev
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|l2arc_vdev_present
argument_list|(
name|vd
argument_list|)
argument_list|)
expr_stmt|;
name|vdev_ashift_optimize
argument_list|(
name|vd
argument_list|)
expr_stmt|;
comment|/* 	 * Create a new l2arc device entry. 	 */
name|adddev
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|l2arc_dev_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|adddev
operator|->
name|l2ad_spa
operator|=
name|spa
expr_stmt|;
name|adddev
operator|->
name|l2ad_vdev
operator|=
name|vd
expr_stmt|;
name|adddev
operator|->
name|l2ad_start
operator|=
name|VDEV_LABEL_START_SIZE
expr_stmt|;
name|adddev
operator|->
name|l2ad_end
operator|=
name|VDEV_LABEL_START_SIZE
operator|+
name|vdev_get_min_asize
argument_list|(
name|vd
argument_list|)
expr_stmt|;
name|adddev
operator|->
name|l2ad_hand
operator|=
name|adddev
operator|->
name|l2ad_start
expr_stmt|;
name|adddev
operator|->
name|l2ad_first
operator|=
name|B_TRUE
expr_stmt|;
name|adddev
operator|->
name|l2ad_writing
operator|=
name|B_FALSE
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|adddev
operator|->
name|l2ad_mtx
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 	 * This is a list of all ARC buffers that are still valid on the 	 * device. 	 */
name|list_create
argument_list|(
operator|&
name|adddev
operator|->
name|l2ad_buflist
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l2hdr
operator|.
name|b_l2node
argument_list|)
argument_list|)
expr_stmt|;
name|vdev_space_update
argument_list|(
name|vd
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|adddev
operator|->
name|l2ad_end
operator|-
name|adddev
operator|->
name|l2ad_hand
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|adddev
operator|->
name|l2ad_alloc
argument_list|)
expr_stmt|;
comment|/* 	 * Add device to global list 	 */
name|mutex_enter
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
name|list_insert_head
argument_list|(
name|l2arc_dev_list
argument_list|,
name|adddev
argument_list|)
expr_stmt|;
name|atomic_inc_64
argument_list|(
operator|&
name|l2arc_ndev
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove a vdev from the L2ARC.  */
end_comment

begin_function
name|void
name|l2arc_remove_vdev
parameter_list|(
name|vdev_t
modifier|*
name|vd
parameter_list|)
block|{
name|l2arc_dev_t
modifier|*
name|dev
decl_stmt|,
modifier|*
name|nextdev
decl_stmt|,
modifier|*
name|remdev
init|=
name|NULL
decl_stmt|;
comment|/* 	 * Find the device by vdev 	 */
name|mutex_enter
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
for|for
control|(
name|dev
operator|=
name|list_head
argument_list|(
name|l2arc_dev_list
argument_list|)
init|;
name|dev
condition|;
name|dev
operator|=
name|nextdev
control|)
block|{
name|nextdev
operator|=
name|list_next
argument_list|(
name|l2arc_dev_list
argument_list|,
name|dev
argument_list|)
expr_stmt|;
if|if
condition|(
name|vd
operator|==
name|dev
operator|->
name|l2ad_vdev
condition|)
block|{
name|remdev
operator|=
name|dev
expr_stmt|;
break|break;
block|}
block|}
name|ASSERT
argument_list|(
name|remdev
operator|!=
name|NULL
argument_list|)
expr_stmt|;
comment|/* 	 * Remove device from global list 	 */
name|list_remove
argument_list|(
name|l2arc_dev_list
argument_list|,
name|remdev
argument_list|)
expr_stmt|;
name|l2arc_dev_last
operator|=
name|NULL
expr_stmt|;
comment|/* may have been invalidated */
name|atomic_dec_64
argument_list|(
operator|&
name|l2arc_ndev
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Clear all buflists and ARC references.  L2ARC device flush. 	 */
name|l2arc_evict
argument_list|(
name|remdev
argument_list|,
literal|0
argument_list|,
name|B_TRUE
argument_list|)
expr_stmt|;
name|list_destroy
argument_list|(
operator|&
name|remdev
operator|->
name|l2ad_buflist
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|remdev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|remdev
operator|->
name|l2ad_alloc
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|remdev
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_dev_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|l2arc_init
parameter_list|(
name|void
parameter_list|)
block|{
name|l2arc_thread_exit
operator|=
literal|0
expr_stmt|;
name|l2arc_ndev
operator|=
literal|0
expr_stmt|;
name|l2arc_writes_sent
operator|=
literal|0
expr_stmt|;
name|l2arc_writes_done
operator|=
literal|0
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|l2arc_feed_thr_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|l2arc_dev_list
operator|=
operator|&
name|L2ARC_dev_list
expr_stmt|;
name|l2arc_free_on_write
operator|=
operator|&
name|L2ARC_free_on_write
expr_stmt|;
name|list_create
argument_list|(
name|l2arc_dev_list
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_dev_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|l2arc_dev_t
argument_list|,
name|l2ad_node
argument_list|)
argument_list|)
expr_stmt|;
name|list_create
argument_list|(
name|l2arc_free_on_write
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_data_free_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|l2arc_data_free_t
argument_list|,
name|l2df_list_node
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|l2arc_fini
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * This is called from dmu_fini(), which is called from spa_fini(); 	 * Because of this, we can assume that all l2arc devices have 	 * already been removed when the pools themselves were removed. 	 */
name|l2arc_do_free_on_write
argument_list|()
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|)
expr_stmt|;
name|list_destroy
argument_list|(
name|l2arc_dev_list
argument_list|)
expr_stmt|;
name|list_destroy
argument_list|(
name|l2arc_free_on_write
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|l2arc_start
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|spa_mode_global
operator|&
name|FWRITE
operator|)
condition|)
return|return;
operator|(
name|void
operator|)
name|thread_create
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|l2arc_feed_thread
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
operator|&
name|p0
argument_list|,
name|TS_RUN
argument_list|,
name|minclsyspri
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|l2arc_stop
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|spa_mode_global
operator|&
name|FWRITE
operator|)
condition|)
return|return;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
name|cv_signal
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|)
expr_stmt|;
comment|/* kick thread out of startup */
name|l2arc_thread_exit
operator|=
literal|1
expr_stmt|;
while|while
condition|(
name|l2arc_thread_exit
operator|!=
literal|0
condition|)
name|cv_wait
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|,
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
block|}
end_function

end_unit

