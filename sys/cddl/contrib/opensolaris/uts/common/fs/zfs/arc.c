begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * CDDL HEADER START  *  * The contents of this file are subject to the terms of the  * Common Development and Distribution License (the "License").  * You may not use this file except in compliance with the License.  *  * You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE  * or http://www.opensolaris.org/os/licensing.  * See the License for the specific language governing permissions  * and limitations under the License.  *  * When distributing Covered Code, include this CDDL HEADER in each  * file and include the License file at usr/src/OPENSOLARIS.LICENSE.  * If applicable, add the following below this CDDL HEADER, with the  * fields enclosed by brackets "[]" replaced with your own identifying  * information: Portions Copyright [yyyy] [name of copyright owner]  *  * CDDL HEADER END  */
end_comment

begin_comment
comment|/*  * Copyright (c) 2005, 2010, Oracle and/or its affiliates. All rights reserved.  * Copyright (c) 2012, Joyent, Inc. All rights reserved.  * Copyright (c) 2011, 2017 by Delphix. All rights reserved.  * Copyright (c) 2014 by Saso Kiselkov. All rights reserved.  * Copyright 2015 Nexenta Systems, Inc.  All rights reserved.  */
end_comment

begin_comment
comment|/*  * DVA-based Adjustable Replacement Cache  *  * While much of the theory of operation used here is  * based on the self-tuning, low overhead replacement cache  * presented by Megiddo and Modha at FAST 2003, there are some  * significant differences:  *  * 1. The Megiddo and Modha model assumes any page is evictable.  * Pages in its cache cannot be "locked" into memory.  This makes  * the eviction algorithm simple: evict the last page in the list.  * This also make the performance characteristics easy to reason  * about.  Our cache is not so simple.  At any given moment, some  * subset of the blocks in the cache are un-evictable because we  * have handed out a reference to them.  Blocks are only evictable  * when there are no external references active.  This makes  * eviction far more problematic:  we choose to evict the evictable  * blocks that are the "lowest" in the list.  *  * There are times when it is not possible to evict the requested  * space.  In these circumstances we are unable to adjust the cache  * size.  To prevent the cache growing unbounded at these times we  * implement a "cache throttle" that slows the flow of new data  * into the cache until we can make space available.  *  * 2. The Megiddo and Modha model assumes a fixed cache size.  * Pages are evicted when the cache is full and there is a cache  * miss.  Our model has a variable sized cache.  It grows with  * high use, but also tries to react to memory pressure from the  * operating system: decreasing its size when system memory is  * tight.  *  * 3. The Megiddo and Modha model assumes a fixed page size. All  * elements of the cache are therefore exactly the same size.  So  * when adjusting the cache size following a cache miss, its simply  * a matter of choosing a single page to evict.  In our model, we  * have variable sized cache blocks (rangeing from 512 bytes to  * 128K bytes).  We therefore choose a set of blocks to evict to make  * space for a cache miss that approximates as closely as possible  * the space used by the new block.  *  * See also:  "ARC: A Self-Tuning, Low Overhead Replacement Cache"  * by N. Megiddo& D. Modha, FAST 2003  */
end_comment

begin_comment
comment|/*  * The locking model:  *  * A new reference to a cache buffer can be obtained in two  * ways: 1) via a hash table lookup using the DVA as a key,  * or 2) via one of the ARC lists.  The arc_read() interface  * uses method 1, while the internal ARC algorithms for  * adjusting the cache use method 2.  We therefore provide two  * types of locks: 1) the hash table lock array, and 2) the  * ARC list locks.  *  * Buffers do not have their own mutexes, rather they rely on the  * hash table mutexes for the bulk of their protection (i.e. most  * fields in the arc_buf_hdr_t are protected by these mutexes).  *  * buf_hash_find() returns the appropriate mutex (held) when it  * locates the requested buffer in the hash table.  It returns  * NULL for the mutex if the buffer was not in the table.  *  * buf_hash_remove() expects the appropriate hash mutex to be  * already held before it is invoked.  *  * Each ARC state also has a mutex which is used to protect the  * buffer list associated with the state.  When attempting to  * obtain a hash table lock while holding an ARC list lock you  * must use: mutex_tryenter() to avoid deadlock.  Also note that  * the active state mutex must be held before the ghost state mutex.  *  * Note that the majority of the performance stats are manipulated  * with atomic operations.  *  * The L2ARC uses the l2ad_mtx on each vdev for the following:  *  *	- L2ARC buflist creation  *	- L2ARC buflist eviction  *	- L2ARC write completion, which walks L2ARC buflists  *	- ARC header destruction, as it removes from L2ARC buflists  *	- ARC header release, as it removes from L2ARC buflists  */
end_comment

begin_comment
comment|/*  * ARC operation:  *  * Every block that is in the ARC is tracked by an arc_buf_hdr_t structure.  * This structure can point either to a block that is still in the cache or to  * one that is only accessible in an L2 ARC device, or it can provide  * information about a block that was recently evicted. If a block is  * only accessible in the L2ARC, then the arc_buf_hdr_t only has enough  * information to retrieve it from the L2ARC device. This information is  * stored in the l2arc_buf_hdr_t sub-structure of the arc_buf_hdr_t. A block  * that is in this state cannot access the data directly.  *  * Blocks that are actively being referenced or have not been evicted  * are cached in the L1ARC. The L1ARC (l1arc_buf_hdr_t) is a structure within  * the arc_buf_hdr_t that will point to the data block in memory. A block can  * only be read by a consumer if it has an l1arc_buf_hdr_t. The L1ARC  * caches data in two ways -- in a list of ARC buffers (arc_buf_t) and  * also in the arc_buf_hdr_t's private physical data block pointer (b_pdata).  *  * The L1ARC's data pointer may or may not be uncompressed. The ARC has the  * ability to store the physical data (b_pdata) associated with the DVA of the  * arc_buf_hdr_t. Since the b_pdata is a copy of the on-disk physical block,  * it will match its on-disk compression characteristics. This behavior can be  * disabled by setting 'zfs_compressed_arc_enabled' to B_FALSE. When the  * compressed ARC functionality is disabled, the b_pdata will point to an  * uncompressed version of the on-disk data.  *  * Data in the L1ARC is not accessed by consumers of the ARC directly. Each  * arc_buf_hdr_t can have multiple ARC buffers (arc_buf_t) which reference it.  * Each ARC buffer (arc_buf_t) is being actively accessed by a specific ARC  * consumer. The ARC will provide references to this data and will keep it  * cached until it is no longer in use. The ARC caches only the L1ARC's physical  * data block and will evict any arc_buf_t that is no longer referenced. The  * amount of memory consumed by the arc_buf_ts' data buffers can be seen via the  * "overhead_size" kstat.  *  * Depending on the consumer, an arc_buf_t can be requested in uncompressed or  * compressed form. The typical case is that consumers will want uncompressed  * data, and when that happens a new data buffer is allocated where the data is  * decompressed for them to use. Currently the only consumer who wants  * compressed arc_buf_t's is "zfs send", when it streams data exactly as it  * exists on disk. When this happens, the arc_buf_t's data buffer is shared  * with the arc_buf_hdr_t.  *  * Here is a diagram showing an arc_buf_hdr_t referenced by two arc_buf_t's. The  * first one is owned by a compressed send consumer (and therefore references  * the same compressed data buffer as the arc_buf_hdr_t) and the second could be  * used by any other consumer (and has its own uncompressed copy of the data  * buffer).  *  *   arc_buf_hdr_t  *   +-----------+  *   | fields    |  *   | common to |  *   | L1- and   |  *   | L2ARC     |  *   +-----------+  *   | l2arc_buf_hdr_t  *   |           |  *   +-----------+  *   | l1arc_buf_hdr_t  *   |           |              arc_buf_t  *   | b_buf     +------------>+-----------+      arc_buf_t  *   | b_pdata   +-+           |b_next     +---->+-----------+  *   +-----------+ |           |-----------|     |b_next     +-->NULL  *                 |           |b_comp = T |     +-----------+  *                 |           |b_data     +-+   |b_comp = F |  *                 |           +-----------+ |   |b_data     +-+  *                 +->+------+               |   +-----------+ |  *        compressed  |      |               |                 |  *           data     |      |<--------------+                 | uncompressed  *                    +------+          compressed,            |     data  *                                        shared               +-->+------+  *                                         data                    |      |  *                                                                 |      |  *                                                                 +------+  *  * When a consumer reads a block, the ARC must first look to see if the  * arc_buf_hdr_t is cached. If the hdr is cached then the ARC allocates a new  * arc_buf_t and either copies uncompressed data into a new data buffer from an  * existing uncompressed arc_buf_t, decompresses the hdr's b_pdata buffer into a  * new data buffer, or shares the hdr's b_pdata buffer, depending on whether the  * hdr is compressed and the desired compression characteristics of the  * arc_buf_t consumer. If the arc_buf_t ends up sharing data with the  * arc_buf_hdr_t and both of them are uncompressed then the arc_buf_t must be  * the last buffer in the hdr's b_buf list, however a shared compressed buf can  * be anywhere in the hdr's list.  *  * The diagram below shows an example of an uncompressed ARC hdr that is  * sharing its data with an arc_buf_t (note that the shared uncompressed buf is  * the last element in the buf list):  *  *                arc_buf_hdr_t  *                +-----------+  *                |           |  *                |           |  *                |           |  *                +-----------+  * l2arc_buf_hdr_t|           |  *                |           |  *                +-----------+  * l1arc_buf_hdr_t|           |  *                |           |                 arc_buf_t    (shared)  *                |    b_buf  +------------>+---------+      arc_buf_t  *                |           |             |b_next   +---->+---------+  *                |  b_pdata  +-+           |---------|     |b_next   +-->NULL  *                +-----------+ |           |         |     +---------+  *                              |           |b_data   +-+   |         |  *                              |           +---------+ |   |b_data   +-+  *                              +->+------+             |   +---------+ |  *                                 |      |             |               |  *                   uncompressed  |      |             |               |  *                        data     +------+             |               |  *                                    ^                 +->+------+     |  *                                    |       uncompressed |      |     |  *                                    |           data     |      |     |  *                                    |                    +------+     |  *                                    +---------------------------------+  *  * Writing to the ARC requires that the ARC first discard the hdr's b_pdata  * since the physical block is about to be rewritten. The new data contents  * will be contained in the arc_buf_t. As the I/O pipeline performs the write,  * it may compress the data before writing it to disk. The ARC will be called  * with the transformed data and will bcopy the transformed on-disk block into  * a newly allocated b_pdata. Writes are always done into buffers which have  * either been loaned (and hence are new and don't have other readers) or  * buffers which have been released (and hence have their own hdr, if there  * were originally other readers of the buf's original hdr). This ensures that  * the ARC only needs to update a single buf and its hdr after a write occurs.  *  * When the L2ARC is in use, it will also take advantage of the b_pdata. The  * L2ARC will always write the contents of b_pdata to the L2ARC. This means  * that when compressed ARC is enabled that the L2ARC blocks are identical  * to the on-disk block in the main data pool. This provides a significant  * advantage since the ARC can leverage the bp's checksum when reading from the  * L2ARC to determine if the contents are valid. However, if the compressed  * ARC is disabled, then the L2ARC's block must be transformed to look  * like the physical block in the main data pool before comparing the  * checksum and determining its validity.  */
end_comment

begin_include
include|#
directive|include
file|<sys/spa.h>
end_include

begin_include
include|#
directive|include
file|<sys/zio.h>
end_include

begin_include
include|#
directive|include
file|<sys/spa_impl.h>
end_include

begin_include
include|#
directive|include
file|<sys/zio_compress.h>
end_include

begin_include
include|#
directive|include
file|<sys/zio_checksum.h>
end_include

begin_include
include|#
directive|include
file|<sys/zfs_context.h>
end_include

begin_include
include|#
directive|include
file|<sys/arc.h>
end_include

begin_include
include|#
directive|include
file|<sys/refcount.h>
end_include

begin_include
include|#
directive|include
file|<sys/vdev.h>
end_include

begin_include
include|#
directive|include
file|<sys/vdev_impl.h>
end_include

begin_include
include|#
directive|include
file|<sys/dsl_pool.h>
end_include

begin_include
include|#
directive|include
file|<sys/multilist.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|_KERNEL
end_ifdef

begin_include
include|#
directive|include
file|<sys/dnlc.h>
end_include

begin_include
include|#
directive|include
file|<sys/racct.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|<sys/callb.h>
end_include

begin_include
include|#
directive|include
file|<sys/kstat.h>
end_include

begin_include
include|#
directive|include
file|<sys/trim_map.h>
end_include

begin_include
include|#
directive|include
file|<zfs_fletcher.h>
end_include

begin_include
include|#
directive|include
file|<sys/sdt.h>
end_include

begin_include
include|#
directive|include
file|<machine/vmparam.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|illumos
end_ifdef

begin_ifndef
ifndef|#
directive|ifndef
name|_KERNEL
end_ifndef

begin_comment
comment|/* set with ZFS_DEBUG=watch, to enable watchpoints on frozen buffers */
end_comment

begin_decl_stmt
name|boolean_t
name|arc_watch
init|=
name|B_FALSE
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|arc_procfd
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* illumos */
end_comment

begin_decl_stmt
specifier|static
name|kmutex_t
name|arc_reclaim_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kcondvar_t
name|arc_reclaim_thread_cv
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|boolean_t
name|arc_reclaim_thread_exit
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kcondvar_t
name|arc_reclaim_waiters_cv
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kmutex_t
name|arc_dnlc_evicts_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kcondvar_t
name|arc_dnlc_evicts_cv
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|boolean_t
name|arc_dnlc_evicts_thread_exit
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint_t
name|arc_reduce_dnlc_percent
init|=
literal|3
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * The number of headers to evict in arc_evict_state_impl() before  * dropping the sublist lock and evicting from another sublist. A lower  * value means we're more likely to evict the "correct" header (i.e. the  * oldest header in the arc state), but comes with higher overhead  * (i.e. more invocations of arc_evict_state_impl()).  */
end_comment

begin_decl_stmt
name|int
name|zfs_arc_evict_batch_limit
init|=
literal|10
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* number of seconds before growing cache again */
end_comment

begin_decl_stmt
specifier|static
name|int
name|arc_grow_retry
init|=
literal|60
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* shift of arc_c for calculating overflow limit in arc_get_data_buf */
end_comment

begin_decl_stmt
name|int
name|zfs_arc_overflow_shift
init|=
literal|8
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* shift of arc_c for calculating both min and max arc_p */
end_comment

begin_decl_stmt
specifier|static
name|int
name|arc_p_min_shift
init|=
literal|4
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* log2(fraction of arc to reclaim) */
end_comment

begin_decl_stmt
specifier|static
name|int
name|arc_shrink_shift
init|=
literal|7
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * log2(fraction of ARC which must be free to allow growing).  * I.e. If there is less than arc_c>> arc_no_grow_shift free memory,  * when reading a new block into the ARC, we will evict an equal-sized block  * from the ARC.  *  * This must be less than arc_shrink_shift, so that when we shrink the ARC,  * we will still not allow it to grow.  */
end_comment

begin_decl_stmt
name|int
name|arc_no_grow_shift
init|=
literal|5
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * minimum lifespan of a prefetch block in clock ticks  * (initialized in arc_init())  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|arc_min_prefetch_lifespan
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * If this percent of memory is free, don't throttle.  */
end_comment

begin_decl_stmt
name|int
name|arc_lotsfree_percent
init|=
literal|10
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|arc_dead
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|boolean_t
name|zfs_prefetch_disable
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * The arc has filled available memory and has now warmed up.  */
end_comment

begin_decl_stmt
specifier|static
name|boolean_t
name|arc_warm
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * These tunables are for performance analysis.  */
end_comment

begin_decl_stmt
name|uint64_t
name|zfs_arc_max
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|zfs_arc_min
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|zfs_arc_meta_limit
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|zfs_arc_meta_min
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|zfs_arc_grow_retry
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|zfs_arc_shrink_shift
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|zfs_arc_p_min_shift
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|zfs_arc_average_blocksize
init|=
literal|8
operator|*
literal|1024
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* 8KB */
end_comment

begin_decl_stmt
name|u_int
name|zfs_arc_free_target
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Absolute min for arc min / max is 16MB. */
end_comment

begin_decl_stmt
specifier|static
name|uint64_t
name|arc_abs_min
init|=
literal|16
operator|<<
literal|20
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|boolean_t
name|zfs_compressed_arc_enabled
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|int
name|sysctl_vfs_zfs_arc_free_target
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sysctl_vfs_zfs_arc_meta_limit
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sysctl_vfs_zfs_arc_max
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sysctl_vfs_zfs_arc_min
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_if
if|#
directive|if
name|defined
argument_list|(
name|__FreeBSD__
argument_list|)
operator|&&
name|defined
argument_list|(
name|_KERNEL
argument_list|)
end_if

begin_function
specifier|static
name|void
name|arc_free_target_init
parameter_list|(
name|void
modifier|*
name|unused
name|__unused
parameter_list|)
block|{
name|zfs_arc_free_target
operator|=
name|vm_pageout_wakeup_thresh
expr_stmt|;
block|}
end_function

begin_expr_stmt
name|SYSINIT
argument_list|(
name|arc_free_target_init
argument_list|,
name|SI_SUB_KTHREAD_PAGE
argument_list|,
name|SI_ORDER_ANY
argument_list|,
name|arc_free_target_init
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|TUNABLE_QUAD
argument_list|(
literal|"vfs.zfs.arc_meta_limit"
argument_list|,
operator|&
name|zfs_arc_meta_limit
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|TUNABLE_QUAD
argument_list|(
literal|"vfs.zfs.arc_meta_min"
argument_list|,
operator|&
name|zfs_arc_meta_min
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"vfs.zfs.arc_shrink_shift"
argument_list|,
operator|&
name|zfs_arc_shrink_shift
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_DECL
argument_list|(
name|_vfs_zfs
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_max
argument_list|,
name|CTLTYPE_U64
operator||
name|CTLFLAG_RWTUN
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
argument_list|,
name|sysctl_vfs_zfs_arc_max
argument_list|,
literal|"QU"
argument_list|,
literal|"Maximum ARC size"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_min
argument_list|,
name|CTLTYPE_U64
operator||
name|CTLFLAG_RWTUN
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
argument_list|,
name|sysctl_vfs_zfs_arc_min
argument_list|,
literal|"QU"
argument_list|,
literal|"Minimum ARC size"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_average_blocksize
argument_list|,
name|CTLFLAG_RDTUN
argument_list|,
operator|&
name|zfs_arc_average_blocksize
argument_list|,
literal|0
argument_list|,
literal|"ARC average blocksize"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_shrink_shift
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|arc_shrink_shift
argument_list|,
literal|0
argument_list|,
literal|"log2(fraction of arc to reclaim)"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|compressed_arc_enabled
argument_list|,
name|CTLFLAG_RDTUN
argument_list|,
operator|&
name|zfs_compressed_arc_enabled
argument_list|,
literal|0
argument_list|,
literal|"Enable compressed ARC"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * We don't have a tunable for arc_free_target due to the dependency on  * pagedaemon initialisation.  */
end_comment

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_free_target
argument_list|,
name|CTLTYPE_UINT
operator||
name|CTLFLAG_MPSAFE
operator||
name|CTLFLAG_RW
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|u_int
argument_list|)
argument_list|,
name|sysctl_vfs_zfs_arc_free_target
argument_list|,
literal|"IU"
argument_list|,
literal|"Desired number of free pages below which ARC triggers reclaim"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|sysctl_vfs_zfs_arc_free_target
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|u_int
name|val
decl_stmt|;
name|int
name|err
decl_stmt|;
name|val
operator|=
name|zfs_arc_free_target
expr_stmt|;
name|err
operator|=
name|sysctl_handle_int
argument_list|(
name|oidp
argument_list|,
operator|&
name|val
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|err
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|err
operator|)
return|;
if|if
condition|(
name|val
operator|<
name|minfree
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
if|if
condition|(
name|val
operator|>
name|vm_cnt
operator|.
name|v_page_count
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|zfs_arc_free_target
operator|=
name|val
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Must be declared here, before the definition of corresponding kstat  * macro which uses the same names will confuse the compiler.  */
end_comment

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|arc_meta_limit
argument_list|,
name|CTLTYPE_U64
operator||
name|CTLFLAG_MPSAFE
operator||
name|CTLFLAG_RW
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|uint64_t
argument_list|)
argument_list|,
name|sysctl_vfs_zfs_arc_meta_limit
argument_list|,
literal|"QU"
argument_list|,
literal|"ARC metadata limit"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Note that buffers can be in one of 6 states:  *	ARC_anon	- anonymous (discussed below)  *	ARC_mru		- recently used, currently cached  *	ARC_mru_ghost	- recentely used, no longer in cache  *	ARC_mfu		- frequently used, currently cached  *	ARC_mfu_ghost	- frequently used, no longer in cache  *	ARC_l2c_only	- exists in L2ARC but not other states  * When there are no active references to the buffer, they are  * are linked onto a list in one of these arc states.  These are  * the only buffers that can be evicted or deleted.  Within each  * state there are multiple lists, one for meta-data and one for  * non-meta-data.  Meta-data (indirect blocks, blocks of dnodes,  * etc.) is tracked separately so that it can be managed more  * explicitly: favored over data, limited explicitly.  *  * Anonymous buffers are buffers that are not associated with  * a DVA.  These are buffers that hold dirty block copies  * before they are written to stable storage.  By definition,  * they are "ref'd" and are considered part of arc_mru  * that cannot be freed.  Generally, they will aquire a DVA  * as they are written and migrate onto the arc_mru list.  *  * The ARC_l2c_only state is for buffers that are in the second  * level ARC but no longer in any of the ARC_m* lists.  The second  * level ARC itself may also contain buffers that are in any of  * the ARC_m* states - meaning that a buffer can exist in two  * places.  The reason for the ARC_l2c_only state is to keep the  * buffer header in the hash table, so that reads that hit the  * second level ARC benefit from these fast lookups.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|arc_state
block|{
comment|/* 	 * list of evictable buffers 	 */
name|multilist_t
modifier|*
name|arcs_list
index|[
name|ARC_BUFC_NUMTYPES
index|]
decl_stmt|;
comment|/* 	 * total amount of evictable data in this state 	 */
name|refcount_t
name|arcs_esize
index|[
name|ARC_BUFC_NUMTYPES
index|]
decl_stmt|;
comment|/* 	 * total amount of data in this state; this includes: evictable, 	 * non-evictable, ARC_BUFC_DATA, and ARC_BUFC_METADATA. 	 */
name|refcount_t
name|arcs_size
decl_stmt|;
block|}
name|arc_state_t
typedef|;
end_typedef

begin_comment
comment|/* The 6 states: */
end_comment

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_anon
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_mru
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_mru_ghost
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_mfu
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_mfu_ghost
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
name|ARC_l2c_only
decl_stmt|;
end_decl_stmt

begin_typedef
typedef|typedef
struct|struct
name|arc_stats
block|{
name|kstat_named_t
name|arcstat_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_demand_data_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_demand_data_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_demand_metadata_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_demand_metadata_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_prefetch_data_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_prefetch_data_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_prefetch_metadata_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_prefetch_metadata_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_mru_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_mru_ghost_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_mfu_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_mfu_ghost_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_allocated
decl_stmt|;
name|kstat_named_t
name|arcstat_deleted
decl_stmt|;
comment|/* 	 * Number of buffers that could not be evicted because the hash lock 	 * was held by another thread.  The lock may not necessarily be held 	 * by something using the same buffer, since hash locks are shared 	 * by multiple buffers. 	 */
name|kstat_named_t
name|arcstat_mutex_miss
decl_stmt|;
comment|/* 	 * Number of buffers skipped because they have I/O in progress, are 	 * indrect prefetch buffers that have not lived long enough, or are 	 * not from the spa we're trying to evict from. 	 */
name|kstat_named_t
name|arcstat_evict_skip
decl_stmt|;
comment|/* 	 * Number of times arc_evict_state() was unable to evict enough 	 * buffers to reach it's target amount. 	 */
name|kstat_named_t
name|arcstat_evict_not_enough
decl_stmt|;
name|kstat_named_t
name|arcstat_evict_l2_cached
decl_stmt|;
name|kstat_named_t
name|arcstat_evict_l2_eligible
decl_stmt|;
name|kstat_named_t
name|arcstat_evict_l2_ineligible
decl_stmt|;
name|kstat_named_t
name|arcstat_evict_l2_skip
decl_stmt|;
name|kstat_named_t
name|arcstat_hash_elements
decl_stmt|;
name|kstat_named_t
name|arcstat_hash_elements_max
decl_stmt|;
name|kstat_named_t
name|arcstat_hash_collisions
decl_stmt|;
name|kstat_named_t
name|arcstat_hash_chains
decl_stmt|;
name|kstat_named_t
name|arcstat_hash_chain_max
decl_stmt|;
name|kstat_named_t
name|arcstat_p
decl_stmt|;
name|kstat_named_t
name|arcstat_c
decl_stmt|;
name|kstat_named_t
name|arcstat_c_min
decl_stmt|;
name|kstat_named_t
name|arcstat_c_max
decl_stmt|;
name|kstat_named_t
name|arcstat_size
decl_stmt|;
comment|/* 	 * Number of compressed bytes stored in the arc_buf_hdr_t's b_pdata. 	 * Note that the compressed bytes may match the uncompressed bytes 	 * if the block is either not compressed or compressed arc is disabled. 	 */
name|kstat_named_t
name|arcstat_compressed_size
decl_stmt|;
comment|/* 	 * Uncompressed size of the data stored in b_pdata. If compressed 	 * arc is disabled then this value will be identical to the stat 	 * above. 	 */
name|kstat_named_t
name|arcstat_uncompressed_size
decl_stmt|;
comment|/* 	 * Number of bytes stored in all the arc_buf_t's. This is classified 	 * as "overhead" since this data is typically short-lived and will 	 * be evicted from the arc when it becomes unreferenced unless the 	 * zfs_keep_uncompressed_metadata or zfs_keep_uncompressed_level 	 * values have been set (see comment in dbuf.c for more information). 	 */
name|kstat_named_t
name|arcstat_overhead_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by internal ARC structures necessary 	 * for tracking purposes; these structures are not actually 	 * backed by ARC buffers. This includes arc_buf_hdr_t structures 	 * (allocated via arc_buf_hdr_t_full and arc_buf_hdr_t_l2only 	 * caches), and arc_buf_t structures (allocated via arc_buf_t 	 * cache). 	 */
name|kstat_named_t
name|arcstat_hdr_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers of type equal to 	 * ARC_BUFC_DATA. This is generally consumed by buffers backing 	 * on disk user data (e.g. plain file contents). 	 */
name|kstat_named_t
name|arcstat_data_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers of type equal to 	 * ARC_BUFC_METADATA. This is generally consumed by buffers 	 * backing on disk data that is used for internal ZFS 	 * structures (e.g. ZAP, dnode, indirect blocks, etc). 	 */
name|kstat_named_t
name|arcstat_metadata_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by various buffers and structures 	 * not actually backed with ARC buffers. This includes bonus 	 * buffers (allocated directly via zio_buf_* functions), 	 * dmu_buf_impl_t structures (allocated via dmu_buf_impl_t 	 * cache), and dnode_t structures (allocated via dnode_t cache). 	 */
name|kstat_named_t
name|arcstat_other_size
decl_stmt|;
comment|/* 	 * Total number of bytes consumed by ARC buffers residing in the 	 * arc_anon state. This includes *all* buffers in the arc_anon 	 * state; e.g. data, metadata, evictable, and unevictable buffers 	 * are all included in this value. 	 */
name|kstat_named_t
name|arcstat_anon_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that meet the 	 * following criteria: backing buffers of type ARC_BUFC_DATA, 	 * residing in the arc_anon state, and are eligible for eviction 	 * (e.g. have no outstanding holds on the buffer). 	 */
name|kstat_named_t
name|arcstat_anon_evictable_data
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that meet the 	 * following criteria: backing buffers of type ARC_BUFC_METADATA, 	 * residing in the arc_anon state, and are eligible for eviction 	 * (e.g. have no outstanding holds on the buffer). 	 */
name|kstat_named_t
name|arcstat_anon_evictable_metadata
decl_stmt|;
comment|/* 	 * Total number of bytes consumed by ARC buffers residing in the 	 * arc_mru state. This includes *all* buffers in the arc_mru 	 * state; e.g. data, metadata, evictable, and unevictable buffers 	 * are all included in this value. 	 */
name|kstat_named_t
name|arcstat_mru_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that meet the 	 * following criteria: backing buffers of type ARC_BUFC_DATA, 	 * residing in the arc_mru state, and are eligible for eviction 	 * (e.g. have no outstanding holds on the buffer). 	 */
name|kstat_named_t
name|arcstat_mru_evictable_data
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that meet the 	 * following criteria: backing buffers of type ARC_BUFC_METADATA, 	 * residing in the arc_mru state, and are eligible for eviction 	 * (e.g. have no outstanding holds on the buffer). 	 */
name|kstat_named_t
name|arcstat_mru_evictable_metadata
decl_stmt|;
comment|/* 	 * Total number of bytes that *would have been* consumed by ARC 	 * buffers in the arc_mru_ghost state. The key thing to note 	 * here, is the fact that this size doesn't actually indicate 	 * RAM consumption. The ghost lists only consist of headers and 	 * don't actually have ARC buffers linked off of these headers. 	 * Thus, *if* the headers had associated ARC buffers, these 	 * buffers *would have* consumed this number of bytes. 	 */
name|kstat_named_t
name|arcstat_mru_ghost_size
decl_stmt|;
comment|/* 	 * Number of bytes that *would have been* consumed by ARC 	 * buffers that are eligible for eviction, of type 	 * ARC_BUFC_DATA, and linked off the arc_mru_ghost state. 	 */
name|kstat_named_t
name|arcstat_mru_ghost_evictable_data
decl_stmt|;
comment|/* 	 * Number of bytes that *would have been* consumed by ARC 	 * buffers that are eligible for eviction, of type 	 * ARC_BUFC_METADATA, and linked off the arc_mru_ghost state. 	 */
name|kstat_named_t
name|arcstat_mru_ghost_evictable_metadata
decl_stmt|;
comment|/* 	 * Total number of bytes consumed by ARC buffers residing in the 	 * arc_mfu state. This includes *all* buffers in the arc_mfu 	 * state; e.g. data, metadata, evictable, and unevictable buffers 	 * are all included in this value. 	 */
name|kstat_named_t
name|arcstat_mfu_size
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that are eligible for 	 * eviction, of type ARC_BUFC_DATA, and reside in the arc_mfu 	 * state. 	 */
name|kstat_named_t
name|arcstat_mfu_evictable_data
decl_stmt|;
comment|/* 	 * Number of bytes consumed by ARC buffers that are eligible for 	 * eviction, of type ARC_BUFC_METADATA, and reside in the 	 * arc_mfu state. 	 */
name|kstat_named_t
name|arcstat_mfu_evictable_metadata
decl_stmt|;
comment|/* 	 * Total number of bytes that *would have been* consumed by ARC 	 * buffers in the arc_mfu_ghost state. See the comment above 	 * arcstat_mru_ghost_size for more details. 	 */
name|kstat_named_t
name|arcstat_mfu_ghost_size
decl_stmt|;
comment|/* 	 * Number of bytes that *would have been* consumed by ARC 	 * buffers that are eligible for eviction, of type 	 * ARC_BUFC_DATA, and linked off the arc_mfu_ghost state. 	 */
name|kstat_named_t
name|arcstat_mfu_ghost_evictable_data
decl_stmt|;
comment|/* 	 * Number of bytes that *would have been* consumed by ARC 	 * buffers that are eligible for eviction, of type 	 * ARC_BUFC_METADATA, and linked off the arc_mru_ghost state. 	 */
name|kstat_named_t
name|arcstat_mfu_ghost_evictable_metadata
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_hits
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_misses
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_feeds
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_rw_clash
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_read_bytes
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_bytes
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_writes_sent
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_writes_done
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_writes_error
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_writes_lock_retry
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_evict_lock_retry
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_evict_reading
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_evict_l1cached
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_free_on_write
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_abort_lowmem
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_cksum_bad
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_io_error
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_size
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_asize
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_hdr_size
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_trylock_fail
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_passed_headroom
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_spa_mismatch
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_in_l2
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_hdr_io_in_progress
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_not_cacheable
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_full
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_buffer_iter
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_pios
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_buffer_bytes_scanned
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_buffer_list_iter
decl_stmt|;
name|kstat_named_t
name|arcstat_l2_write_buffer_list_null_iter
decl_stmt|;
name|kstat_named_t
name|arcstat_memory_throttle_count
decl_stmt|;
name|kstat_named_t
name|arcstat_meta_used
decl_stmt|;
name|kstat_named_t
name|arcstat_meta_limit
decl_stmt|;
name|kstat_named_t
name|arcstat_meta_max
decl_stmt|;
name|kstat_named_t
name|arcstat_meta_min
decl_stmt|;
name|kstat_named_t
name|arcstat_sync_wait_for_async
decl_stmt|;
name|kstat_named_t
name|arcstat_demand_hit_predictive_prefetch
decl_stmt|;
block|}
name|arc_stats_t
typedef|;
end_typedef

begin_decl_stmt
specifier|static
name|arc_stats_t
name|arc_stats
init|=
block|{
block|{
literal|"hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"demand_data_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"demand_data_misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"demand_metadata_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"demand_metadata_misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"prefetch_data_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"prefetch_data_misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"prefetch_metadata_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"prefetch_metadata_misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_ghost_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_ghost_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"allocated"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"deleted"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mutex_miss"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_skip"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_not_enough"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_l2_cached"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_l2_eligible"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_l2_ineligible"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"evict_l2_skip"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hash_elements"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hash_elements_max"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hash_collisions"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hash_chains"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hash_chain_max"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"p"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"c"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"c_min"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"c_max"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"compressed_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"uncompressed_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"overhead_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"hdr_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"data_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"metadata_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"other_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"anon_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"anon_evictable_data"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"anon_evictable_metadata"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_evictable_data"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_evictable_metadata"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_ghost_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_ghost_evictable_data"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mru_ghost_evictable_metadata"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_evictable_data"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_evictable_metadata"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_ghost_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_ghost_evictable_data"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"mfu_ghost_evictable_metadata"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_hits"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_misses"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_feeds"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_rw_clash"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_read_bytes"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_bytes"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_writes_sent"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_writes_done"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_writes_error"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_writes_lock_retry"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_evict_lock_retry"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_evict_reading"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_evict_l1cached"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_free_on_write"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_abort_lowmem"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_cksum_bad"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_io_error"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_asize"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_hdr_size"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_trylock_fail"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_passed_headroom"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_spa_mismatch"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_in_l2"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_io_in_progress"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_not_cacheable"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_full"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_buffer_iter"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_pios"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_buffer_bytes_scanned"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_buffer_list_iter"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"l2_write_buffer_list_null_iter"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"memory_throttle_count"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"arc_meta_used"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"arc_meta_limit"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"arc_meta_max"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"arc_meta_min"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"sync_wait_for_async"
block|,
name|KSTAT_DATA_UINT64
block|}
block|,
block|{
literal|"demand_hit_predictive_prefetch"
block|,
name|KSTAT_DATA_UINT64
block|}
block|, }
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|ARCSTAT
parameter_list|(
name|stat
parameter_list|)
value|(arc_stats.stat.value.ui64)
end_define

begin_define
define|#
directive|define
name|ARCSTAT_INCR
parameter_list|(
name|stat
parameter_list|,
name|val
parameter_list|)
define|\
value|atomic_add_64(&arc_stats.stat.value.ui64, (val))
end_define

begin_define
define|#
directive|define
name|ARCSTAT_BUMP
parameter_list|(
name|stat
parameter_list|)
value|ARCSTAT_INCR(stat, 1)
end_define

begin_define
define|#
directive|define
name|ARCSTAT_BUMPDOWN
parameter_list|(
name|stat
parameter_list|)
value|ARCSTAT_INCR(stat, -1)
end_define

begin_define
define|#
directive|define
name|ARCSTAT_MAX
parameter_list|(
name|stat
parameter_list|,
name|val
parameter_list|)
value|{					\ 	uint64_t m;							\ 	while ((val)> (m = arc_stats.stat.value.ui64)&&		\ 	    (m != atomic_cas_64(&arc_stats.stat.value.ui64, m, (val))))	\ 		continue;						\ }
end_define

begin_define
define|#
directive|define
name|ARCSTAT_MAXSTAT
parameter_list|(
name|stat
parameter_list|)
define|\
value|ARCSTAT_MAX(stat##_max, arc_stats.stat.value.ui64)
end_define

begin_comment
comment|/*  * We define a macro to allow ARC hits/misses to be easily broken down by  * two separate conditions, giving a total of four different subtypes for  * each of hits and misses (so eight statistics total).  */
end_comment

begin_define
define|#
directive|define
name|ARCSTAT_CONDSTAT
parameter_list|(
name|cond1
parameter_list|,
name|stat1
parameter_list|,
name|notstat1
parameter_list|,
name|cond2
parameter_list|,
name|stat2
parameter_list|,
name|notstat2
parameter_list|,
name|stat
parameter_list|)
define|\
value|if (cond1) {							\ 		if (cond2) {						\ 			ARCSTAT_BUMP(arcstat_##stat1##_##stat2##_##stat); \ 		} else {						\ 			ARCSTAT_BUMP(arcstat_##stat1##_##notstat2##_##stat); \ 		}							\ 	} else {							\ 		if (cond2) {						\ 			ARCSTAT_BUMP(arcstat_##notstat1##_##stat2##_##stat); \ 		} else {						\ 			ARCSTAT_BUMP(arcstat_##notstat1##_##notstat2##_##stat);\ 		}							\ 	}
end_define

begin_decl_stmt
name|kstat_t
modifier|*
name|arc_ksp
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_anon
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_mru
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_mru_ghost
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_mfu
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_mfu_ghost
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|arc_state_t
modifier|*
name|arc_l2c_only
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * There are several ARC variables that are critical to export as kstats --  * but we don't want to have to grovel around in the kstat whenever we wish to  * manipulate them.  For these variables, we therefore define them to be in  * terms of the statistic variable.  This assures that we are not introducing  * the possibility of inconsistency by having shadow copies of the variables,  * while still allowing the code to be readable.  */
end_comment

begin_define
define|#
directive|define
name|arc_size
value|ARCSTAT(arcstat_size)
end_define

begin_comment
comment|/* actual total arc size */
end_comment

begin_define
define|#
directive|define
name|arc_p
value|ARCSTAT(arcstat_p)
end_define

begin_comment
comment|/* target size of MRU */
end_comment

begin_define
define|#
directive|define
name|arc_c
value|ARCSTAT(arcstat_c)
end_define

begin_comment
comment|/* target size of cache */
end_comment

begin_define
define|#
directive|define
name|arc_c_min
value|ARCSTAT(arcstat_c_min)
end_define

begin_comment
comment|/* min target cache size */
end_comment

begin_define
define|#
directive|define
name|arc_c_max
value|ARCSTAT(arcstat_c_max)
end_define

begin_comment
comment|/* max target cache size */
end_comment

begin_define
define|#
directive|define
name|arc_meta_limit
value|ARCSTAT(arcstat_meta_limit)
end_define

begin_comment
comment|/* max size for metadata */
end_comment

begin_define
define|#
directive|define
name|arc_meta_min
value|ARCSTAT(arcstat_meta_min)
end_define

begin_comment
comment|/* min size for metadata */
end_comment

begin_define
define|#
directive|define
name|arc_meta_used
value|ARCSTAT(arcstat_meta_used)
end_define

begin_comment
comment|/* size of metadata */
end_comment

begin_define
define|#
directive|define
name|arc_meta_max
value|ARCSTAT(arcstat_meta_max)
end_define

begin_comment
comment|/* max size of metadata */
end_comment

begin_comment
comment|/* compressed size of entire arc */
end_comment

begin_define
define|#
directive|define
name|arc_compressed_size
value|ARCSTAT(arcstat_compressed_size)
end_define

begin_comment
comment|/* uncompressed size of entire arc */
end_comment

begin_define
define|#
directive|define
name|arc_uncompressed_size
value|ARCSTAT(arcstat_uncompressed_size)
end_define

begin_comment
comment|/* number of bytes in the arc from arc_buf_t's */
end_comment

begin_define
define|#
directive|define
name|arc_overhead_size
value|ARCSTAT(arcstat_overhead_size)
end_define

begin_decl_stmt
specifier|static
name|int
name|arc_no_grow
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Don't try to grow cache size */
end_comment

begin_decl_stmt
specifier|static
name|uint64_t
name|arc_tempreserve
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|uint64_t
name|arc_loaned_bytes
decl_stmt|;
end_decl_stmt

begin_typedef
typedef|typedef
name|struct
name|arc_callback
name|arc_callback_t
typedef|;
end_typedef

begin_struct
struct|struct
name|arc_callback
block|{
name|void
modifier|*
name|acb_private
decl_stmt|;
name|arc_done_func_t
modifier|*
name|acb_done
decl_stmt|;
name|arc_buf_t
modifier|*
name|acb_buf
decl_stmt|;
name|boolean_t
name|acb_compressed
decl_stmt|;
name|zio_t
modifier|*
name|acb_zio_dummy
decl_stmt|;
name|arc_callback_t
modifier|*
name|acb_next
decl_stmt|;
block|}
struct|;
end_struct

begin_typedef
typedef|typedef
name|struct
name|arc_write_callback
name|arc_write_callback_t
typedef|;
end_typedef

begin_struct
struct|struct
name|arc_write_callback
block|{
name|void
modifier|*
name|awcb_private
decl_stmt|;
name|arc_done_func_t
modifier|*
name|awcb_ready
decl_stmt|;
name|arc_done_func_t
modifier|*
name|awcb_children_ready
decl_stmt|;
name|arc_done_func_t
modifier|*
name|awcb_physdone
decl_stmt|;
name|arc_done_func_t
modifier|*
name|awcb_done
decl_stmt|;
name|arc_buf_t
modifier|*
name|awcb_buf
decl_stmt|;
block|}
struct|;
end_struct

begin_comment
comment|/*  * ARC buffers are separated into multiple structs as a memory saving measure:  *   - Common fields struct, always defined, and embedded within it:  *       - L2-only fields, always allocated but undefined when not in L2ARC  *       - L1-only fields, only allocated when in L1ARC  *  *           Buffer in L1                     Buffer only in L2  *    +------------------------+          +------------------------+  *    | arc_buf_hdr_t          |          | arc_buf_hdr_t          |  *    |                        |          |                        |  *    |                        |          |                        |  *    |                        |          |                        |  *    +------------------------+          +------------------------+  *    | l2arc_buf_hdr_t        |          | l2arc_buf_hdr_t        |  *    | (undefined if L1-only) |          |                        |  *    +------------------------+          +------------------------+  *    | l1arc_buf_hdr_t        |  *    |                        |  *    |                        |  *    |                        |  *    |                        |  *    +------------------------+  *  * Because it's possible for the L2ARC to become extremely large, we can wind  * up eating a lot of memory in L2ARC buffer headers, so the size of a header  * is minimized by only allocating the fields necessary for an L1-cached buffer  * when a header is actually in the L1 cache. The sub-headers (l1arc_buf_hdr and  * l2arc_buf_hdr) are embedded rather than allocated separately to save a couple  * words in pointers. arc_hdr_realloc() is used to switch a header between  * these two allocation states.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|l1arc_buf_hdr
block|{
name|kmutex_t
name|b_freeze_lock
decl_stmt|;
name|zio_cksum_t
modifier|*
name|b_freeze_cksum
decl_stmt|;
ifdef|#
directive|ifdef
name|ZFS_DEBUG
comment|/* 	 * Used for debugging with kmem_flags - by allocating and freeing 	 * b_thawed when the buffer is thawed, we get a record of the stack 	 * trace that thawed it. 	 */
name|void
modifier|*
name|b_thawed
decl_stmt|;
endif|#
directive|endif
name|arc_buf_t
modifier|*
name|b_buf
decl_stmt|;
name|uint32_t
name|b_bufcnt
decl_stmt|;
comment|/* for waiting on writes to complete */
name|kcondvar_t
name|b_cv
decl_stmt|;
name|uint8_t
name|b_byteswap
decl_stmt|;
comment|/* protected by arc state mutex */
name|arc_state_t
modifier|*
name|b_state
decl_stmt|;
name|multilist_node_t
name|b_arc_node
decl_stmt|;
comment|/* updated atomically */
name|clock_t
name|b_arc_access
decl_stmt|;
comment|/* self protecting */
name|refcount_t
name|b_refcnt
decl_stmt|;
name|arc_callback_t
modifier|*
name|b_acb
decl_stmt|;
name|void
modifier|*
name|b_pdata
decl_stmt|;
block|}
name|l1arc_buf_hdr_t
typedef|;
end_typedef

begin_typedef
typedef|typedef
name|struct
name|l2arc_dev
name|l2arc_dev_t
typedef|;
end_typedef

begin_typedef
typedef|typedef
struct|struct
name|l2arc_buf_hdr
block|{
comment|/* protected by arc_buf_hdr mutex */
name|l2arc_dev_t
modifier|*
name|b_dev
decl_stmt|;
comment|/* L2ARC device */
name|uint64_t
name|b_daddr
decl_stmt|;
comment|/* disk address, offset byte */
name|list_node_t
name|b_l2node
decl_stmt|;
block|}
name|l2arc_buf_hdr_t
typedef|;
end_typedef

begin_struct
struct|struct
name|arc_buf_hdr
block|{
comment|/* protected by hash lock */
name|dva_t
name|b_dva
decl_stmt|;
name|uint64_t
name|b_birth
decl_stmt|;
name|arc_buf_contents_t
name|b_type
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|b_hash_next
decl_stmt|;
name|arc_flags_t
name|b_flags
decl_stmt|;
comment|/* 	 * This field stores the size of the data buffer after 	 * compression, and is set in the arc's zio completion handlers. 	 * It is in units of SPA_MINBLOCKSIZE (e.g. 1 == 512 bytes). 	 * 	 * While the block pointers can store up to 32MB in their psize 	 * field, we can only store up to 32MB minus 512B. This is due 	 * to the bp using a bias of 1, whereas we use a bias of 0 (i.e. 	 * a field of zeros represents 512B in the bp). We can't use a 	 * bias of 1 since we need to reserve a psize of zero, here, to 	 * represent holes and embedded blocks. 	 * 	 * This isn't a problem in practice, since the maximum size of a 	 * buffer is limited to 16MB, so we never need to store 32MB in 	 * this field. Even in the upstream illumos code base, the 	 * maximum size of a buffer is limited to 16MB. 	 */
name|uint16_t
name|b_psize
decl_stmt|;
comment|/* 	 * This field stores the size of the data buffer before 	 * compression, and cannot change once set. It is in units 	 * of SPA_MINBLOCKSIZE (e.g. 2 == 1024 bytes) 	 */
name|uint16_t
name|b_lsize
decl_stmt|;
comment|/* immutable */
name|uint64_t
name|b_spa
decl_stmt|;
comment|/* immutable */
comment|/* L2ARC fields. Undefined when not in L2ARC. */
name|l2arc_buf_hdr_t
name|b_l2hdr
decl_stmt|;
comment|/* L1ARC fields. Undefined when in l2arc_only state */
name|l1arc_buf_hdr_t
name|b_l1hdr
decl_stmt|;
block|}
struct|;
end_struct

begin_if
if|#
directive|if
name|defined
argument_list|(
name|__FreeBSD__
argument_list|)
operator|&&
name|defined
argument_list|(
name|_KERNEL
argument_list|)
end_if

begin_function
specifier|static
name|int
name|sysctl_vfs_zfs_arc_meta_limit
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|uint64_t
name|val
decl_stmt|;
name|int
name|err
decl_stmt|;
name|val
operator|=
name|arc_meta_limit
expr_stmt|;
name|err
operator|=
name|sysctl_handle_64
argument_list|(
name|oidp
argument_list|,
operator|&
name|val
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|err
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|err
operator|)
return|;
if|if
condition|(
name|val
operator|<=
literal|0
operator|||
name|val
operator|>
name|arc_c_max
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|arc_meta_limit
operator|=
name|val
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|sysctl_vfs_zfs_arc_max
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|uint64_t
name|val
decl_stmt|;
name|int
name|err
decl_stmt|;
name|val
operator|=
name|zfs_arc_max
expr_stmt|;
name|err
operator|=
name|sysctl_handle_64
argument_list|(
name|oidp
argument_list|,
operator|&
name|val
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|err
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|err
operator|)
return|;
if|if
condition|(
name|zfs_arc_max
operator|==
literal|0
condition|)
block|{
comment|/* Loader tunable so blindly set */
name|zfs_arc_max
operator|=
name|val
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
if|if
condition|(
name|val
operator|<
name|arc_abs_min
operator|||
name|val
operator|>
name|kmem_size
argument_list|()
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
if|if
condition|(
name|val
operator|<
name|arc_c_min
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
if|if
condition|(
name|zfs_arc_meta_limit
operator|>
literal|0
operator|&&
name|val
operator|<
name|zfs_arc_meta_limit
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|arc_c_max
operator|=
name|val
expr_stmt|;
name|arc_c
operator|=
name|arc_c_max
expr_stmt|;
name|arc_p
operator|=
operator|(
name|arc_c
operator|>>
literal|1
operator|)
expr_stmt|;
if|if
condition|(
name|zfs_arc_meta_limit
operator|==
literal|0
condition|)
block|{
comment|/* limit meta-data to 1/4 of the arc capacity */
name|arc_meta_limit
operator|=
name|arc_c_max
operator|/
literal|4
expr_stmt|;
block|}
comment|/* if kmem_flags are set, lets try to use less memory */
if|if
condition|(
name|kmem_debugging
argument_list|()
condition|)
name|arc_c
operator|=
name|arc_c
operator|/
literal|2
expr_stmt|;
name|zfs_arc_max
operator|=
name|arc_c
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|sysctl_vfs_zfs_arc_min
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|uint64_t
name|val
decl_stmt|;
name|int
name|err
decl_stmt|;
name|val
operator|=
name|zfs_arc_min
expr_stmt|;
name|err
operator|=
name|sysctl_handle_64
argument_list|(
name|oidp
argument_list|,
operator|&
name|val
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|err
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|err
operator|)
return|;
if|if
condition|(
name|zfs_arc_min
operator|==
literal|0
condition|)
block|{
comment|/* Loader tunable so blindly set */
name|zfs_arc_min
operator|=
name|val
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
if|if
condition|(
name|val
operator|<
name|arc_abs_min
operator|||
name|val
operator|>
name|arc_c_max
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|arc_c_min
operator|=
name|val
expr_stmt|;
if|if
condition|(
name|zfs_arc_meta_min
operator|==
literal|0
condition|)
name|arc_meta_min
operator|=
name|arc_c_min
operator|/
literal|2
expr_stmt|;
if|if
condition|(
name|arc_c
operator|<
name|arc_c_min
condition|)
name|arc_c
operator|=
name|arc_c_min
expr_stmt|;
name|zfs_arc_min
operator|=
name|arc_c_min
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|GHOST_STATE
parameter_list|(
name|state
parameter_list|)
define|\
value|((state) == arc_mru_ghost || (state) == arc_mfu_ghost ||	\ 	(state) == arc_l2c_only)
end_define

begin_define
define|#
directive|define
name|HDR_IN_HASH_TABLE
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_IN_HASH_TABLE)
end_define

begin_define
define|#
directive|define
name|HDR_IO_IN_PROGRESS
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_IO_IN_PROGRESS)
end_define

begin_define
define|#
directive|define
name|HDR_IO_ERROR
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_IO_ERROR)
end_define

begin_define
define|#
directive|define
name|HDR_PREFETCH
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_PREFETCH)
end_define

begin_define
define|#
directive|define
name|HDR_COMPRESSION_ENABLED
parameter_list|(
name|hdr
parameter_list|)
define|\
value|((hdr)->b_flags& ARC_FLAG_COMPRESSED_ARC)
end_define

begin_define
define|#
directive|define
name|HDR_L2CACHE
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_L2CACHE)
end_define

begin_define
define|#
directive|define
name|HDR_L2_READING
parameter_list|(
name|hdr
parameter_list|)
define|\
value|(((hdr)->b_flags& ARC_FLAG_IO_IN_PROGRESS)&&	\ 	((hdr)->b_flags& ARC_FLAG_HAS_L2HDR))
end_define

begin_define
define|#
directive|define
name|HDR_L2_WRITING
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_L2_WRITING)
end_define

begin_define
define|#
directive|define
name|HDR_L2_EVICTED
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_L2_EVICTED)
end_define

begin_define
define|#
directive|define
name|HDR_L2_WRITE_HEAD
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_L2_WRITE_HEAD)
end_define

begin_define
define|#
directive|define
name|HDR_SHARED_DATA
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_SHARED_DATA)
end_define

begin_define
define|#
directive|define
name|HDR_ISTYPE_METADATA
parameter_list|(
name|hdr
parameter_list|)
define|\
value|((hdr)->b_flags& ARC_FLAG_BUFC_METADATA)
end_define

begin_define
define|#
directive|define
name|HDR_ISTYPE_DATA
parameter_list|(
name|hdr
parameter_list|)
value|(!HDR_ISTYPE_METADATA(hdr))
end_define

begin_define
define|#
directive|define
name|HDR_HAS_L1HDR
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_HAS_L1HDR)
end_define

begin_define
define|#
directive|define
name|HDR_HAS_L2HDR
parameter_list|(
name|hdr
parameter_list|)
value|((hdr)->b_flags& ARC_FLAG_HAS_L2HDR)
end_define

begin_comment
comment|/* For storing compression mode in b_flags */
end_comment

begin_define
define|#
directive|define
name|HDR_COMPRESS_OFFSET
value|(highbit64(ARC_FLAG_COMPRESS_0) - 1)
end_define

begin_define
define|#
directive|define
name|HDR_GET_COMPRESS
parameter_list|(
name|hdr
parameter_list|)
value|((enum zio_compress)BF32_GET((hdr)->b_flags, \ 	HDR_COMPRESS_OFFSET, SPA_COMPRESSBITS))
end_define

begin_define
define|#
directive|define
name|HDR_SET_COMPRESS
parameter_list|(
name|hdr
parameter_list|,
name|cmp
parameter_list|)
value|BF32_SET((hdr)->b_flags, \ 	HDR_COMPRESS_OFFSET, SPA_COMPRESSBITS, (cmp));
end_define

begin_define
define|#
directive|define
name|ARC_BUF_LAST
parameter_list|(
name|buf
parameter_list|)
value|((buf)->b_next == NULL)
end_define

begin_define
define|#
directive|define
name|ARC_BUF_SHARED
parameter_list|(
name|buf
parameter_list|)
value|((buf)->b_flags& ARC_BUF_FLAG_SHARED)
end_define

begin_define
define|#
directive|define
name|ARC_BUF_COMPRESSED
parameter_list|(
name|buf
parameter_list|)
value|((buf)->b_flags& ARC_BUF_FLAG_COMPRESSED)
end_define

begin_comment
comment|/*  * Other sizes  */
end_comment

begin_define
define|#
directive|define
name|HDR_FULL_SIZE
value|((int64_t)sizeof (arc_buf_hdr_t))
end_define

begin_define
define|#
directive|define
name|HDR_L2ONLY_SIZE
value|((int64_t)offsetof(arc_buf_hdr_t, b_l1hdr))
end_define

begin_comment
comment|/*  * Hash table routines  */
end_comment

begin_define
define|#
directive|define
name|HT_LOCK_PAD
value|CACHE_LINE_SIZE
end_define

begin_struct
struct|struct
name|ht_lock
block|{
name|kmutex_t
name|ht_lock
decl_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
name|unsigned
name|char
name|pad
index|[
operator|(
name|HT_LOCK_PAD
operator|-
sizeof|sizeof
argument_list|(
name|kmutex_t
argument_list|)
operator|)
index|]
decl_stmt|;
endif|#
directive|endif
block|}
struct|;
end_struct

begin_define
define|#
directive|define
name|BUF_LOCKS
value|256
end_define

begin_typedef
typedef|typedef
struct|struct
name|buf_hash_table
block|{
name|uint64_t
name|ht_mask
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
modifier|*
name|ht_table
decl_stmt|;
name|struct
name|ht_lock
name|ht_locks
index|[
name|BUF_LOCKS
index|]
name|__aligned
parameter_list|(
name|CACHE_LINE_SIZE
parameter_list|)
function_decl|;
block|}
name|buf_hash_table_t
typedef|;
end_typedef

begin_decl_stmt
specifier|static
name|buf_hash_table_t
name|buf_hash_table
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|BUF_HASH_INDEX
parameter_list|(
name|spa
parameter_list|,
name|dva
parameter_list|,
name|birth
parameter_list|)
define|\
value|(buf_hash(spa, dva, birth)& buf_hash_table.ht_mask)
end_define

begin_define
define|#
directive|define
name|BUF_HASH_LOCK_NTRY
parameter_list|(
name|idx
parameter_list|)
value|(buf_hash_table.ht_locks[idx& (BUF_LOCKS-1)])
end_define

begin_define
define|#
directive|define
name|BUF_HASH_LOCK
parameter_list|(
name|idx
parameter_list|)
value|(&(BUF_HASH_LOCK_NTRY(idx).ht_lock))
end_define

begin_define
define|#
directive|define
name|HDR_LOCK
parameter_list|(
name|hdr
parameter_list|)
define|\
value|(BUF_HASH_LOCK(BUF_HASH_INDEX(hdr->b_spa,&hdr->b_dva, hdr->b_birth)))
end_define

begin_decl_stmt
name|uint64_t
name|zfs_crc64_table
index|[
literal|256
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Level 2 ARC  */
end_comment

begin_define
define|#
directive|define
name|L2ARC_WRITE_SIZE
value|(8 * 1024 * 1024)
end_define

begin_comment
comment|/* initial write max */
end_comment

begin_define
define|#
directive|define
name|L2ARC_HEADROOM
value|2
end_define

begin_comment
comment|/* num of writes */
end_comment

begin_comment
comment|/*  * If we discover during ARC scan any buffers to be compressed, we boost  * our headroom for the next scanning cycle by this percentage multiple.  */
end_comment

begin_define
define|#
directive|define
name|L2ARC_HEADROOM_BOOST
value|200
end_define

begin_define
define|#
directive|define
name|L2ARC_FEED_SECS
value|1
end_define

begin_comment
comment|/* caching interval secs */
end_comment

begin_define
define|#
directive|define
name|L2ARC_FEED_MIN_MS
value|200
end_define

begin_comment
comment|/* min caching interval ms */
end_comment

begin_define
define|#
directive|define
name|l2arc_writes_sent
value|ARCSTAT(arcstat_l2_writes_sent)
end_define

begin_define
define|#
directive|define
name|l2arc_writes_done
value|ARCSTAT(arcstat_l2_writes_done)
end_define

begin_comment
comment|/* L2ARC Performance Tunables */
end_comment

begin_decl_stmt
name|uint64_t
name|l2arc_write_max
init|=
name|L2ARC_WRITE_SIZE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* default max write size */
end_comment

begin_decl_stmt
name|uint64_t
name|l2arc_write_boost
init|=
name|L2ARC_WRITE_SIZE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* extra write during warmup */
end_comment

begin_decl_stmt
name|uint64_t
name|l2arc_headroom
init|=
name|L2ARC_HEADROOM
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* number of dev writes */
end_comment

begin_decl_stmt
name|uint64_t
name|l2arc_headroom_boost
init|=
name|L2ARC_HEADROOM_BOOST
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|l2arc_feed_secs
init|=
name|L2ARC_FEED_SECS
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* interval seconds */
end_comment

begin_decl_stmt
name|uint64_t
name|l2arc_feed_min_ms
init|=
name|L2ARC_FEED_MIN_MS
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* min interval milliseconds */
end_comment

begin_decl_stmt
name|boolean_t
name|l2arc_noprefetch
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* don't cache prefetch bufs */
end_comment

begin_decl_stmt
name|boolean_t
name|l2arc_feed_again
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* turbo warmup */
end_comment

begin_decl_stmt
name|boolean_t
name|l2arc_norw
init|=
name|B_TRUE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* no reads during writes */
end_comment

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_write_max
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_write_max
argument_list|,
literal|0
argument_list|,
literal|"max write size"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_write_boost
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_write_boost
argument_list|,
literal|0
argument_list|,
literal|"extra write during warmup"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_headroom
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_headroom
argument_list|,
literal|0
argument_list|,
literal|"number of dev writes"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_feed_secs
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_feed_secs
argument_list|,
literal|0
argument_list|,
literal|"interval seconds"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_feed_min_ms
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_feed_min_ms
argument_list|,
literal|0
argument_list|,
literal|"min interval milliseconds"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_noprefetch
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_noprefetch
argument_list|,
literal|0
argument_list|,
literal|"don't cache prefetch bufs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_feed_again
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_feed_again
argument_list|,
literal|0
argument_list|,
literal|"turbo warmup"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2arc_norw
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|l2arc_norw
argument_list|,
literal|0
argument_list|,
literal|"no reads during writes"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|anon_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_anon
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of anonymous state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|anon_metadata_esize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_anon
operator|.
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of anonymous state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|anon_data_esize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_anon
operator|.
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of anonymous state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of mru state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_metadata_esize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru
operator|.
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of metadata in mru state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_data_esize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru
operator|.
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of data in mru state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_ghost_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru_ghost
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of mru ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_ghost_metadata_esize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru_ghost
operator|.
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of metadata in mru ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mru_ghost_data_esize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mru_ghost
operator|.
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of data in mru ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of mfu state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_metadata_esize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu
operator|.
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of metadata in mfu state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_data_esize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu
operator|.
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of data in mfu state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_ghost_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu_ghost
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of mfu ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_ghost_metadata_esize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu_ghost
operator|.
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of metadata in mfu ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mfu_ghost_data_esize
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_mfu_ghost
operator|.
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of data in mfu ghost state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_UQUAD
argument_list|(
name|_vfs_zfs
argument_list|,
name|OID_AUTO
argument_list|,
name|l2c_only_size
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ARC_l2c_only
operator|.
name|arcs_size
operator|.
name|rc_count
argument_list|,
literal|0
argument_list|,
literal|"size of mru state"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * L2ARC Internals  */
end_comment

begin_struct
struct|struct
name|l2arc_dev
block|{
name|vdev_t
modifier|*
name|l2ad_vdev
decl_stmt|;
comment|/* vdev */
name|spa_t
modifier|*
name|l2ad_spa
decl_stmt|;
comment|/* spa */
name|uint64_t
name|l2ad_hand
decl_stmt|;
comment|/* next write location */
name|uint64_t
name|l2ad_start
decl_stmt|;
comment|/* first addr on device */
name|uint64_t
name|l2ad_end
decl_stmt|;
comment|/* last addr on device */
name|boolean_t
name|l2ad_first
decl_stmt|;
comment|/* first sweep through */
name|boolean_t
name|l2ad_writing
decl_stmt|;
comment|/* currently writing */
name|kmutex_t
name|l2ad_mtx
decl_stmt|;
comment|/* lock for buffer list */
name|list_t
name|l2ad_buflist
decl_stmt|;
comment|/* buffer list */
name|list_node_t
name|l2ad_node
decl_stmt|;
comment|/* device list node */
name|refcount_t
name|l2ad_alloc
decl_stmt|;
comment|/* allocated bytes */
block|}
struct|;
end_struct

begin_decl_stmt
specifier|static
name|list_t
name|L2ARC_dev_list
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* device list */
end_comment

begin_decl_stmt
specifier|static
name|list_t
modifier|*
name|l2arc_dev_list
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* device list pointer */
end_comment

begin_decl_stmt
specifier|static
name|kmutex_t
name|l2arc_dev_mtx
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* device list mutex */
end_comment

begin_decl_stmt
specifier|static
name|l2arc_dev_t
modifier|*
name|l2arc_dev_last
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* last device used */
end_comment

begin_decl_stmt
specifier|static
name|list_t
name|L2ARC_free_on_write
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* free after write buf list */
end_comment

begin_decl_stmt
specifier|static
name|list_t
modifier|*
name|l2arc_free_on_write
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* free after write list ptr */
end_comment

begin_decl_stmt
specifier|static
name|kmutex_t
name|l2arc_free_on_write_mtx
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* mutex for list */
end_comment

begin_decl_stmt
specifier|static
name|uint64_t
name|l2arc_ndev
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* number of devices */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|l2arc_read_callback
block|{
name|arc_buf_hdr_t
modifier|*
name|l2rcb_hdr
decl_stmt|;
comment|/* read header */
name|blkptr_t
name|l2rcb_bp
decl_stmt|;
comment|/* original blkptr */
name|zbookmark_phys_t
name|l2rcb_zb
decl_stmt|;
comment|/* original bookmark */
name|int
name|l2rcb_flags
decl_stmt|;
comment|/* original flags */
name|void
modifier|*
name|l2rcb_data
decl_stmt|;
comment|/* temporary buffer */
block|}
name|l2arc_read_callback_t
typedef|;
end_typedef

begin_typedef
typedef|typedef
struct|struct
name|l2arc_write_callback
block|{
name|l2arc_dev_t
modifier|*
name|l2wcb_dev
decl_stmt|;
comment|/* device info */
name|arc_buf_hdr_t
modifier|*
name|l2wcb_head
decl_stmt|;
comment|/* head of write buflist */
block|}
name|l2arc_write_callback_t
typedef|;
end_typedef

begin_typedef
typedef|typedef
struct|struct
name|l2arc_data_free
block|{
comment|/* protected by l2arc_free_on_write_mtx */
name|void
modifier|*
name|l2df_data
decl_stmt|;
name|size_t
name|l2df_size
decl_stmt|;
name|arc_buf_contents_t
name|l2df_type
decl_stmt|;
name|list_node_t
name|l2df_list_node
decl_stmt|;
block|}
name|l2arc_data_free_t
typedef|;
end_typedef

begin_decl_stmt
specifier|static
name|kmutex_t
name|l2arc_feed_thr_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kcondvar_t
name|l2arc_feed_thr_cv
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|uint8_t
name|l2arc_thread_exit
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|void
modifier|*
name|arc_get_data_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
parameter_list|,
name|uint64_t
parameter_list|,
name|void
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|arc_free_data_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
parameter_list|,
name|void
modifier|*
parameter_list|,
name|uint64_t
parameter_list|,
name|void
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|arc_hdr_free_pdata
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|arc_hdr_alloc_pdata
parameter_list|(
name|arc_buf_hdr_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|arc_access
parameter_list|(
name|arc_buf_hdr_t
modifier|*
parameter_list|,
name|kmutex_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|arc_is_overflowing
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|arc_buf_watch
parameter_list|(
name|arc_buf_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|arc_buf_contents_t
name|arc_buf_type
parameter_list|(
name|arc_buf_hdr_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|uint32_t
name|arc_bufc_to_flags
parameter_list|(
name|arc_buf_contents_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
specifier|inline
name|void
name|arc_hdr_set_flags
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|arc_flags_t
name|flags
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
specifier|inline
name|void
name|arc_hdr_clear_flags
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|arc_flags_t
name|flags
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|l2arc_write_eligible
parameter_list|(
name|uint64_t
parameter_list|,
name|arc_buf_hdr_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|l2arc_read_done
parameter_list|(
name|zio_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function
specifier|static
name|void
name|l2arc_trim
parameter_list|(
specifier|const
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|l2arc_dev_t
modifier|*
name|dev
init|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|trim_map_free
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
argument_list|,
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|buf_hash
parameter_list|(
name|uint64_t
name|spa
parameter_list|,
specifier|const
name|dva_t
modifier|*
name|dva
parameter_list|,
name|uint64_t
name|birth
parameter_list|)
block|{
name|uint8_t
modifier|*
name|vdva
init|=
operator|(
name|uint8_t
operator|*
operator|)
name|dva
decl_stmt|;
name|uint64_t
name|crc
init|=
operator|-
literal|1ULL
decl_stmt|;
name|int
name|i
decl_stmt|;
name|ASSERT
argument_list|(
name|zfs_crc64_table
index|[
literal|128
index|]
operator|==
name|ZFS_CRC64_POLY
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
sizeof|sizeof
argument_list|(
name|dva_t
argument_list|)
condition|;
name|i
operator|++
control|)
name|crc
operator|=
operator|(
name|crc
operator|>>
literal|8
operator|)
operator|^
name|zfs_crc64_table
index|[
operator|(
name|crc
operator|^
name|vdva
index|[
name|i
index|]
operator|)
operator|&
literal|0xFF
index|]
expr_stmt|;
name|crc
operator|^=
operator|(
name|spa
operator|>>
literal|8
operator|)
operator|^
name|birth
expr_stmt|;
return|return
operator|(
name|crc
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|HDR_EMPTY
parameter_list|(
name|hdr
parameter_list|)
define|\
value|((hdr)->b_dva.dva_word[0] == 0&&			\ 	(hdr)->b_dva.dva_word[1] == 0)
end_define

begin_define
define|#
directive|define
name|HDR_EQUAL
parameter_list|(
name|spa
parameter_list|,
name|dva
parameter_list|,
name|birth
parameter_list|,
name|hdr
parameter_list|)
define|\
value|((hdr)->b_dva.dva_word[0] == (dva)->dva_word[0])&&	\ 	((hdr)->b_dva.dva_word[1] == (dva)->dva_word[1])&&	\ 	((hdr)->b_birth == birth)&& ((hdr)->b_spa == spa)
end_define

begin_function
specifier|static
name|void
name|buf_discard_identity
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|hdr
operator|->
name|b_dva
operator|.
name|dva_word
index|[
literal|0
index|]
operator|=
literal|0
expr_stmt|;
name|hdr
operator|->
name|b_dva
operator|.
name|dva_word
index|[
literal|1
index|]
operator|=
literal|0
expr_stmt|;
name|hdr
operator|->
name|b_birth
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|arc_buf_hdr_t
modifier|*
name|buf_hash_find
parameter_list|(
name|uint64_t
name|spa
parameter_list|,
specifier|const
name|blkptr_t
modifier|*
name|bp
parameter_list|,
name|kmutex_t
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
specifier|const
name|dva_t
modifier|*
name|dva
init|=
name|BP_IDENTITY
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|uint64_t
name|birth
init|=
name|BP_PHYSICAL_BIRTH
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|uint64_t
name|idx
init|=
name|BUF_HASH_INDEX
argument_list|(
name|spa
argument_list|,
name|dva
argument_list|,
name|birth
argument_list|)
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|BUF_HASH_LOCK
argument_list|(
name|idx
argument_list|)
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
for|for
control|(
name|hdr
operator|=
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
init|;
name|hdr
operator|!=
name|NULL
condition|;
name|hdr
operator|=
name|hdr
operator|->
name|b_hash_next
control|)
block|{
if|if
condition|(
name|HDR_EQUAL
argument_list|(
name|spa
argument_list|,
name|dva
argument_list|,
name|birth
argument_list|,
name|hdr
argument_list|)
condition|)
block|{
operator|*
name|lockp
operator|=
name|hash_lock
expr_stmt|;
return|return
operator|(
name|hdr
operator|)
return|;
block|}
block|}
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
operator|*
name|lockp
operator|=
name|NULL
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Insert an entry into the hash table.  If there is already an element  * equal to elem in the hash table, then the already existing element  * will be returned and the new element will not be inserted.  * Otherwise returns NULL.  * If lockp == NULL, the caller is assumed to already hold the hash lock.  */
end_comment

begin_function
specifier|static
name|arc_buf_hdr_t
modifier|*
name|buf_hash_insert
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|uint64_t
name|idx
init|=
name|BUF_HASH_INDEX
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
operator|&
name|hdr
operator|->
name|b_dva
argument_list|,
name|hdr
operator|->
name|b_birth
argument_list|)
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|BUF_HASH_LOCK
argument_list|(
name|idx
argument_list|)
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|fhdr
decl_stmt|;
name|uint32_t
name|i
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|DVA_IS_EMPTY
argument_list|(
operator|&
name|hdr
operator|->
name|b_dva
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_birth
operator|!=
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|lockp
operator|!=
name|NULL
condition|)
block|{
operator|*
name|lockp
operator|=
name|hash_lock
expr_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|fhdr
operator|=
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
operator|,
name|i
operator|=
literal|0
init|;
name|fhdr
operator|!=
name|NULL
condition|;
name|fhdr
operator|=
name|fhdr
operator|->
name|b_hash_next
operator|,
name|i
operator|++
control|)
block|{
if|if
condition|(
name|HDR_EQUAL
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
operator|&
name|hdr
operator|->
name|b_dva
argument_list|,
name|hdr
operator|->
name|b_birth
argument_list|,
name|fhdr
argument_list|)
condition|)
return|return
operator|(
name|fhdr
operator|)
return|;
block|}
name|hdr
operator|->
name|b_hash_next
operator|=
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
expr_stmt|;
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
operator|=
name|hdr
expr_stmt|;
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_IN_HASH_TABLE
argument_list|)
expr_stmt|;
comment|/* collect some hash table performance data */
if|if
condition|(
name|i
operator|>
literal|0
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_hash_collisions
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|==
literal|1
condition|)
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_hash_chains
argument_list|)
expr_stmt|;
name|ARCSTAT_MAX
argument_list|(
name|arcstat_hash_chain_max
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_hash_elements
argument_list|)
expr_stmt|;
name|ARCSTAT_MAXSTAT
argument_list|(
name|arcstat_hash_elements
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|buf_hash_remove
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|fhdr
decl_stmt|,
modifier|*
modifier|*
name|hdrp
decl_stmt|;
name|uint64_t
name|idx
init|=
name|BUF_HASH_INDEX
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
operator|&
name|hdr
operator|->
name|b_dva
argument_list|,
name|hdr
operator|->
name|b_birth
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|BUF_HASH_LOCK
argument_list|(
name|idx
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|hdrp
operator|=
operator|&
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
expr_stmt|;
while|while
condition|(
operator|(
name|fhdr
operator|=
operator|*
name|hdrp
operator|)
operator|!=
name|hdr
condition|)
block|{
name|ASSERT3P
argument_list|(
name|fhdr
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|hdrp
operator|=
operator|&
name|fhdr
operator|->
name|b_hash_next
expr_stmt|;
block|}
operator|*
name|hdrp
operator|=
name|hdr
operator|->
name|b_hash_next
expr_stmt|;
name|hdr
operator|->
name|b_hash_next
operator|=
name|NULL
expr_stmt|;
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_IN_HASH_TABLE
argument_list|)
expr_stmt|;
comment|/* collect some hash table performance data */
name|ARCSTAT_BUMPDOWN
argument_list|(
name|arcstat_hash_elements
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
operator|&&
name|buf_hash_table
operator|.
name|ht_table
index|[
name|idx
index|]
operator|->
name|b_hash_next
operator|==
name|NULL
condition|)
name|ARCSTAT_BUMPDOWN
argument_list|(
name|arcstat_hash_chains
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Global data structures and functions for the buf kmem cache.  */
end_comment

begin_decl_stmt
specifier|static
name|kmem_cache_t
modifier|*
name|hdr_full_cache
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kmem_cache_t
modifier|*
name|hdr_l2only_cache
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|kmem_cache_t
modifier|*
name|buf_cache
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|void
name|buf_fini
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|kmem_free
argument_list|(
name|buf_hash_table
operator|.
name|ht_table
argument_list|,
operator|(
name|buf_hash_table
operator|.
name|ht_mask
operator|+
literal|1
operator|)
operator|*
sizeof|sizeof
argument_list|(
name|void
operator|*
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|BUF_LOCKS
condition|;
name|i
operator|++
control|)
name|mutex_destroy
argument_list|(
operator|&
name|buf_hash_table
operator|.
name|ht_locks
index|[
name|i
index|]
operator|.
name|ht_lock
argument_list|)
expr_stmt|;
name|kmem_cache_destroy
argument_list|(
name|hdr_full_cache
argument_list|)
expr_stmt|;
name|kmem_cache_destroy
argument_list|(
name|hdr_l2only_cache
argument_list|)
expr_stmt|;
name|kmem_cache_destroy
argument_list|(
name|buf_cache
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Constructor callback - called when the cache is empty  * and a new buf is requested.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|int
name|hdr_full_cons
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|,
name|int
name|kmflag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|vbuf
decl_stmt|;
name|bzero
argument_list|(
name|hdr
argument_list|,
name|HDR_FULL_SIZE
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|multilist_link_init
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
expr_stmt|;
name|arc_space_consume
argument_list|(
name|HDR_FULL_SIZE
argument_list|,
name|ARC_SPACE_HDRS
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|int
name|hdr_l2only_cons
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|,
name|int
name|kmflag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|vbuf
decl_stmt|;
name|bzero
argument_list|(
name|hdr
argument_list|,
name|HDR_L2ONLY_SIZE
argument_list|)
expr_stmt|;
name|arc_space_consume
argument_list|(
name|HDR_L2ONLY_SIZE
argument_list|,
name|ARC_SPACE_L2HDRS
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|int
name|buf_cons
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|,
name|int
name|kmflag
parameter_list|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|vbuf
decl_stmt|;
name|bzero
argument_list|(
name|buf
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_t
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|arc_space_consume
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_t
argument_list|)
argument_list|,
name|ARC_SPACE_HDRS
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Destructor callback - called when a cached buf is  * no longer required.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|hdr_full_dest
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|vbuf
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_cv
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
name|HDR_FULL_SIZE
argument_list|,
name|ARC_SPACE_HDRS
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|hdr_l2only_dest
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|vbuf
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
name|HDR_L2ONLY_SIZE
argument_list|,
name|ARC_SPACE_L2HDRS
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|buf_dest
parameter_list|(
name|void
modifier|*
name|vbuf
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|vbuf
decl_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_t
argument_list|)
argument_list|,
name|ARC_SPACE_HDRS
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Reclaim callback -- invoked when memory is low.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|hdr_recl
parameter_list|(
name|void
modifier|*
name|unused
parameter_list|)
block|{
name|dprintf
argument_list|(
literal|"hdr_recl called\n"
argument_list|)
expr_stmt|;
comment|/* 	 * umem calls the reclaim func when we destroy the buf cache, 	 * which is after we do arc_fini(). 	 */
if|if
condition|(
operator|!
name|arc_dead
condition|)
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|buf_init
parameter_list|(
name|void
parameter_list|)
block|{
name|uint64_t
modifier|*
name|ct
decl_stmt|;
name|uint64_t
name|hsize
init|=
literal|1ULL
operator|<<
literal|12
decl_stmt|;
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
comment|/* 	 * The hash table is big enough to fill all of physical memory 	 * with an average block size of zfs_arc_average_blocksize (default 8K). 	 * By default, the table will take up 	 * totalmem * sizeof(void*) / 8K (1MB per GB with 8-byte pointers). 	 */
while|while
condition|(
name|hsize
operator|*
name|zfs_arc_average_blocksize
operator|<
operator|(
name|uint64_t
operator|)
name|physmem
operator|*
name|PAGESIZE
condition|)
name|hsize
operator|<<=
literal|1
expr_stmt|;
name|retry
label|:
name|buf_hash_table
operator|.
name|ht_mask
operator|=
name|hsize
operator|-
literal|1
expr_stmt|;
name|buf_hash_table
operator|.
name|ht_table
operator|=
name|kmem_zalloc
argument_list|(
name|hsize
operator|*
sizeof|sizeof
argument_list|(
name|void
operator|*
argument_list|)
argument_list|,
name|KM_NOSLEEP
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf_hash_table
operator|.
name|ht_table
operator|==
name|NULL
condition|)
block|{
name|ASSERT
argument_list|(
name|hsize
operator|>
operator|(
literal|1ULL
operator|<<
literal|8
operator|)
argument_list|)
expr_stmt|;
name|hsize
operator|>>=
literal|1
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
name|hdr_full_cache
operator|=
name|kmem_cache_create
argument_list|(
literal|"arc_buf_hdr_t_full"
argument_list|,
name|HDR_FULL_SIZE
argument_list|,
literal|0
argument_list|,
name|hdr_full_cons
argument_list|,
name|hdr_full_dest
argument_list|,
name|hdr_recl
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|hdr_l2only_cache
operator|=
name|kmem_cache_create
argument_list|(
literal|"arc_buf_hdr_t_l2only"
argument_list|,
name|HDR_L2ONLY_SIZE
argument_list|,
literal|0
argument_list|,
name|hdr_l2only_cons
argument_list|,
name|hdr_l2only_dest
argument_list|,
name|hdr_recl
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|buf_cache
operator|=
name|kmem_cache_create
argument_list|(
literal|"arc_buf_t"
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_t
argument_list|)
argument_list|,
literal|0
argument_list|,
name|buf_cons
argument_list|,
name|buf_dest
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|256
condition|;
name|i
operator|++
control|)
for|for
control|(
name|ct
operator|=
name|zfs_crc64_table
operator|+
name|i
operator|,
operator|*
name|ct
operator|=
name|i
operator|,
name|j
operator|=
literal|8
init|;
name|j
operator|>
literal|0
condition|;
name|j
operator|--
control|)
operator|*
name|ct
operator|=
operator|(
operator|*
name|ct
operator|>>
literal|1
operator|)
operator|^
operator|(
operator|-
operator|(
operator|*
name|ct
operator|&
literal|1
operator|)
operator|&
name|ZFS_CRC64_POLY
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|BUF_LOCKS
condition|;
name|i
operator|++
control|)
block|{
name|mutex_init
argument_list|(
operator|&
name|buf_hash_table
operator|.
name|ht_locks
index|[
name|i
index|]
operator|.
name|ht_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * This is the size that the buf occupies in memory. If the buf is compressed,  * it will correspond to the compressed size. You should use this method of  * getting the buf size unless you explicitly need the logical size.  */
end_comment

begin_function
name|int32_t
name|arc_buf_size
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
return|return
operator|(
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|?
name|HDR_GET_PSIZE
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
else|:
name|HDR_GET_LSIZE
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|int32_t
name|arc_buf_lsize
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
return|return
operator|(
name|HDR_GET_LSIZE
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|enum
name|zio_compress
name|arc_get_compression
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
return|return
operator|(
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|?
name|HDR_GET_COMPRESS
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
else|:
name|ZIO_COMPRESS_OFF
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|ARC_MINTIME
value|(hz>>4)
end_define

begin_comment
comment|/* 62 ms */
end_comment

begin_function
specifier|static
specifier|inline
name|boolean_t
name|arc_buf_is_shared
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|boolean_t
name|shared
init|=
operator|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
operator|&&
name|buf
operator|->
name|b_data
operator|==
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|)
decl_stmt|;
name|IMPLY
argument_list|(
name|shared
argument_list|,
name|HDR_SHARED_DATA
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
argument_list|)
expr_stmt|;
name|IMPLY
argument_list|(
name|shared
argument_list|,
name|ARC_BUF_SHARED
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|IMPLY
argument_list|(
name|shared
argument_list|,
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
operator|||
name|ARC_BUF_LAST
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * It would be nice to assert arc_can_share() too, but the "hdr isn't 	 * already being shared" requirement prevents us from doing that. 	 */
return|return
operator|(
name|shared
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Free the checksum associated with this header. If there is no checksum, this  * is a no-op.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|arc_cksum_free
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
operator|!=
name|NULL
condition|)
block|{
name|kmem_free
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
argument_list|,
sizeof|sizeof
argument_list|(
name|zio_cksum_t
argument_list|)
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
operator|=
name|NULL
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return true iff at least one of the bufs on hdr is not compressed.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|arc_hdr_has_uncompressed_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
for|for
control|(
name|arc_buf_t
modifier|*
name|b
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
init|;
name|b
operator|!=
name|NULL
condition|;
name|b
operator|=
name|b
operator|->
name|b_next
control|)
block|{
if|if
condition|(
operator|!
name|ARC_BUF_COMPRESSED
argument_list|(
name|b
argument_list|)
condition|)
block|{
return|return
operator|(
name|B_TRUE
operator|)
return|;
block|}
block|}
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * If we've turned on the ZFS_DEBUG_MODIFY flag, verify that the buf's data  * matches the checksum that is stored in the hdr. If there is no checksum,  * or if the buf is compressed, this is a no-op.  */
end_comment

begin_function
specifier|static
name|void
name|arc_cksum_verify
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|zio_cksum_t
name|zc
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_MODIFY
operator|)
condition|)
return|return;
if|if
condition|(
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
operator|==
name|NULL
operator|||
name|arc_hdr_has_uncompressed_buf
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
operator|==
name|NULL
operator|||
name|HDR_IO_ERROR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
return|return;
block|}
name|fletcher_2_native
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
name|NULL
argument_list|,
operator|&
name|zc
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|ZIO_CHECKSUM_EQUAL
argument_list|(
operator|*
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
argument_list|,
name|zc
argument_list|)
condition|)
name|panic
argument_list|(
literal|"buffer modified while frozen!"
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|boolean_t
name|arc_cksum_is_equal
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|enum
name|zio_compress
name|compress
init|=
name|BP_GET_COMPRESS
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
decl_stmt|;
name|boolean_t
name|valid_cksum
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|BP_IS_EMBEDDED
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|)
expr_stmt|;
name|VERIFY3U
argument_list|(
name|BP_GET_PSIZE
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|,
operator|==
argument_list|,
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * We rely on the blkptr's checksum to determine if the block 	 * is valid or not. When compressed arc is enabled, the l2arc 	 * writes the block to the l2arc just as it appears in the pool. 	 * This allows us to use the blkptr's checksum to validate the 	 * data that we just read off of the l2arc without having to store 	 * a separate checksum in the arc_buf_hdr_t. However, if compressed 	 * arc is disabled, then the data written to the l2arc is always 	 * uncompressed and won't match the block as it exists in the main 	 * pool. When this is the case, we must first compress it if it is 	 * compressed on the main pool before we can validate the checksum. 	 */
if|if
condition|(
operator|!
name|HDR_COMPRESSION_ENABLED
argument_list|(
name|hdr
argument_list|)
operator|&&
name|compress
operator|!=
name|ZIO_COMPRESS_OFF
condition|)
block|{
name|ASSERT3U
argument_list|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|==
argument_list|,
name|ZIO_COMPRESS_OFF
argument_list|)
expr_stmt|;
name|uint64_t
name|lsize
init|=
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|uint64_t
name|csize
decl_stmt|;
name|void
modifier|*
name|cbuf
init|=
name|zio_buf_alloc
argument_list|(
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
decl_stmt|;
name|csize
operator|=
name|zio_compress_data
argument_list|(
name|compress
argument_list|,
name|zio
operator|->
name|io_data
argument_list|,
name|cbuf
argument_list|,
name|lsize
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|csize
argument_list|,
operator|<=
argument_list|,
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|csize
operator|<
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
comment|/* 			 * Compressed blocks are always a multiple of the 			 * smallest ashift in the pool. Ideally, we would 			 * like to round up the csize to the next 			 * spa_min_ashift but that value may have changed 			 * since the block was last written. Instead, 			 * we rely on the fact that the hdr's psize 			 * was set to the psize of the block when it was 			 * last written. We set the csize to that value 			 * and zero out any part that should not contain 			 * data. 			 */
name|bzero
argument_list|(
operator|(
name|char
operator|*
operator|)
name|cbuf
operator|+
name|csize
argument_list|,
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
operator|-
name|csize
argument_list|)
expr_stmt|;
name|csize
operator|=
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
name|zio_push_transform
argument_list|(
name|zio
argument_list|,
name|cbuf
argument_list|,
name|csize
argument_list|,
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Block pointers always store the checksum for the logical data. 	 * If the block pointer has the gang bit set, then the checksum 	 * it represents is for the reconstituted data and not for an 	 * individual gang member. The zio pipeline, however, must be able to 	 * determine the checksum of each of the gang constituents so it 	 * treats the checksum comparison differently than what we need 	 * for l2arc blocks. This prevents us from using the 	 * zio_checksum_error() interface directly. Instead we must call the 	 * zio_checksum_error_impl() so that we can ensure the checksum is 	 * generated using the correct checksum algorithm and accounts for the 	 * logical I/O size and not just a gang fragment. 	 */
name|valid_cksum
operator|=
operator|(
name|zio_checksum_error_impl
argument_list|(
name|zio
operator|->
name|io_spa
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|,
name|BP_GET_CHECKSUM
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|,
name|zio
operator|->
name|io_data
argument_list|,
name|zio
operator|->
name|io_size
argument_list|,
name|zio
operator|->
name|io_offset
argument_list|,
name|NULL
argument_list|)
operator|==
literal|0
operator|)
expr_stmt|;
name|zio_pop_transforms
argument_list|(
name|zio
argument_list|)
expr_stmt|;
return|return
operator|(
name|valid_cksum
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Given a buf full of data, if ZFS_DEBUG_MODIFY is enabled this computes a  * checksum and attaches it to the buf's hdr so that we can ensure that the buf  * isn't modified later on. If buf is compressed or there is already a checksum  * on the hdr, this is a no-op (we only checksum uncompressed bufs).  */
end_comment

begin_function
specifier|static
name|void
name|arc_cksum_compute
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_MODIFY
operator|)
condition|)
return|return;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
operator|!=
name|NULL
condition|)
block|{
name|ASSERT
argument_list|(
name|arc_hdr_has_uncompressed_buf
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
return|return;
block|}
elseif|else
if|if
condition|(
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
return|return;
block|}
name|ASSERT
argument_list|(
operator|!
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
operator|=
name|kmem_alloc
argument_list|(
sizeof|sizeof
argument_list|(
name|zio_cksum_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|fletcher_2_native
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
name|arc_buf_watch
argument_list|(
name|buf
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|illumos
end_ifdef

begin_ifndef
ifndef|#
directive|ifndef
name|_KERNEL
end_ifndef

begin_typedef
typedef|typedef
struct|struct
name|procctl
block|{
name|long
name|cmd
decl_stmt|;
name|prwatch_t
name|prwatch
decl_stmt|;
block|}
name|procctl_t
typedef|;
end_typedef

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|arc_buf_unwatch
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
ifndef|#
directive|ifndef
name|_KERNEL
if|if
condition|(
name|arc_watch
condition|)
block|{
name|int
name|result
decl_stmt|;
name|procctl_t
name|ctl
decl_stmt|;
name|ctl
operator|.
name|cmd
operator|=
name|PCWATCH
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_vaddr
operator|=
operator|(
name|uintptr_t
operator|)
name|buf
operator|->
name|b_data
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_size
operator|=
literal|0
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_wflags
operator|=
literal|0
expr_stmt|;
name|result
operator|=
name|write
argument_list|(
name|arc_procfd
argument_list|,
operator|&
name|ctl
argument_list|,
sizeof|sizeof
argument_list|(
name|ctl
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|result
argument_list|,
operator|==
argument_list|,
sizeof|sizeof
argument_list|(
name|ctl
argument_list|)
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|arc_buf_watch
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
ifndef|#
directive|ifndef
name|_KERNEL
if|if
condition|(
name|arc_watch
condition|)
block|{
name|int
name|result
decl_stmt|;
name|procctl_t
name|ctl
decl_stmt|;
name|ctl
operator|.
name|cmd
operator|=
name|PCWATCH
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_vaddr
operator|=
operator|(
name|uintptr_t
operator|)
name|buf
operator|->
name|b_data
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_size
operator|=
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|ctl
operator|.
name|prwatch
operator|.
name|pr_wflags
operator|=
name|WA_WRITE
expr_stmt|;
name|result
operator|=
name|write
argument_list|(
name|arc_procfd
argument_list|,
operator|&
name|ctl
argument_list|,
sizeof|sizeof
argument_list|(
name|ctl
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|result
argument_list|,
operator|==
argument_list|,
sizeof|sizeof
argument_list|(
name|ctl
argument_list|)
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* illumos */
end_comment

begin_function
specifier|static
name|arc_buf_contents_t
name|arc_buf_type
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|arc_buf_contents_t
name|type
decl_stmt|;
if|if
condition|(
name|HDR_ISTYPE_METADATA
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|type
operator|=
name|ARC_BUFC_METADATA
expr_stmt|;
block|}
else|else
block|{
name|type
operator|=
name|ARC_BUFC_DATA
expr_stmt|;
block|}
name|VERIFY3U
argument_list|(
name|hdr
operator|->
name|b_type
argument_list|,
operator|==
argument_list|,
name|type
argument_list|)
expr_stmt|;
return|return
operator|(
name|type
operator|)
return|;
block|}
end_function

begin_function
name|boolean_t
name|arc_is_metadata
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
return|return
operator|(
name|HDR_ISTYPE_METADATA
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|)
operator|!=
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|uint32_t
name|arc_bufc_to_flags
parameter_list|(
name|arc_buf_contents_t
name|type
parameter_list|)
block|{
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|ARC_BUFC_DATA
case|:
comment|/* metadata field is 0 if buffer contains normal data */
return|return
operator|(
literal|0
operator|)
return|;
case|case
name|ARC_BUFC_METADATA
case|:
return|return
operator|(
name|ARC_FLAG_BUFC_METADATA
operator|)
return|;
default|default:
break|break;
block|}
name|panic
argument_list|(
literal|"undefined ARC buffer type!"
argument_list|)
expr_stmt|;
return|return
operator|(
operator|(
name|uint32_t
operator|)
operator|-
literal|1
operator|)
return|;
block|}
end_function

begin_function
name|void
name|arc_buf_thaw
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|,
operator|==
argument_list|,
name|arc_anon
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_cksum_verify
argument_list|(
name|buf
argument_list|)
expr_stmt|;
comment|/* 	 * Compressed buffers do not manipulate the b_freeze_cksum or 	 * allocate b_thawed. 	 */
if|if
condition|(
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
operator|==
name|NULL
operator|||
name|arc_hdr_has_uncompressed_buf
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_cksum_free
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|ZFS_DEBUG
if|if
condition|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_MODIFY
condition|)
block|{
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|!=
name|NULL
condition|)
name|kmem_free
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|=
name|kmem_alloc
argument_list|(
literal|1
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|mutex_exit
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_lock
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
name|arc_buf_unwatch
argument_list|(
name|buf
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|arc_buf_freeze
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|zfs_flags
operator|&
name|ZFS_DEBUG_MODIFY
operator|)
condition|)
return|return;
if|if
condition|(
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
operator|==
name|NULL
operator|||
name|arc_hdr_has_uncompressed_buf
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
operator|!=
name|NULL
operator|||
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
argument_list|)
expr_stmt|;
name|arc_cksum_compute
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * The arc_buf_hdr_t's b_flags should never be modified directly. Instead,  * the following functions should be used to ensure that the flags are  * updated in a thread-safe way. When manipulating the flags either  * the hash_lock must be held or the hdr must be undiscoverable. This  * ensures that we're not racing with any other threads when updating  * the flags.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|arc_hdr_set_flags
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|arc_flags_t
name|flags
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
operator|||
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator||=
name|flags
expr_stmt|;
block|}
end_function

begin_function
specifier|static
specifier|inline
name|void
name|arc_hdr_clear_flags
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|arc_flags_t
name|flags
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
operator|||
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator|&=
operator|~
name|flags
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Setting the compression bits in the arc_buf_hdr_t's b_flags is  * done in a special way since we have to clear and set bits  * at the same time. Consumers that wish to set the compression bits  * must use this function to ensure that the flags are updated in  * thread-safe manner.  */
end_comment

begin_function
specifier|static
name|void
name|arc_hdr_set_compress
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|enum
name|zio_compress
name|cmp
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
operator|||
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Holes and embedded blocks will always have a psize = 0 so 	 * we ignore the compression of the blkptr and set the 	 * arc_buf_hdr_t's compression to ZIO_COMPRESS_OFF. 	 * Holes and embedded blocks remain anonymous so we don't 	 * want to uncompress them. Mark them as uncompressed. 	 */
if|if
condition|(
operator|!
name|zfs_compressed_arc_enabled
operator|||
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
operator|==
literal|0
condition|)
block|{
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_COMPRESSED_ARC
argument_list|)
expr_stmt|;
name|HDR_SET_COMPRESS
argument_list|(
name|hdr
argument_list|,
name|ZIO_COMPRESS_OFF
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_COMPRESSION_ENABLED
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|==
argument_list|,
name|ZIO_COMPRESS_OFF
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_COMPRESSED_ARC
argument_list|)
expr_stmt|;
name|HDR_SET_COMPRESS
argument_list|(
name|hdr
argument_list|,
name|cmp
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|==
argument_list|,
name|cmp
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_COMPRESSION_ENABLED
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Looks for another buf on the same hdr which has the data decompressed, copies  * from it, and returns true. If no such buf exists, returns false.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|arc_buf_try_copy_decompressed_data
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|boolean_t
name|copied
init|=
name|B_FALSE
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|arc_buf_t
modifier|*
name|from
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
init|;
name|from
operator|!=
name|NULL
condition|;
name|from
operator|=
name|from
operator|->
name|b_next
control|)
block|{
comment|/* can't use our own data buffer */
if|if
condition|(
name|from
operator|==
name|buf
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
operator|!
name|ARC_BUF_COMPRESSED
argument_list|(
name|from
argument_list|)
condition|)
block|{
name|bcopy
argument_list|(
name|from
operator|->
name|b_data
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|copied
operator|=
name|B_TRUE
expr_stmt|;
break|break;
block|}
block|}
comment|/* 	 * There were no decompressed bufs, so there should not be a 	 * checksum on the hdr either. 	 */
name|EQUIV
argument_list|(
operator|!
name|copied
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
operator|==
name|NULL
argument_list|)
expr_stmt|;
return|return
operator|(
name|copied
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Given a buf that has a data buffer attached to it, this function will  * efficiently fill the buf with data of the specified compression setting from  * the hdr and update the hdr's b_freeze_cksum if necessary. If the buf and hdr  * are already sharing a data buf, no copy is performed.  *  * If the buf is marked as compressed but uncompressed data was requested, this  * will allocate a new data buffer for the buf, remove that flag, and fill the  * buf with uncompressed data. You can't request a compressed buf on a hdr with  * uncompressed data, and (since we haven't added support for it yet) if you  * want compressed data your buf must already be marked as compressed and have  * the correct-sized data buffer.  */
end_comment

begin_function
specifier|static
name|int
name|arc_buf_fill
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|boolean_t
name|compressed
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|boolean_t
name|hdr_compressed
init|=
operator|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
operator|!=
name|ZIO_COMPRESS_OFF
operator|)
decl_stmt|;
name|dmu_object_byteswap_t
name|bswap
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_byteswap
decl_stmt|;
name|ASSERT3P
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|IMPLY
argument_list|(
name|compressed
argument_list|,
name|hdr_compressed
argument_list|)
expr_stmt|;
name|IMPLY
argument_list|(
name|compressed
argument_list|,
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr_compressed
operator|==
name|compressed
condition|)
block|{
if|if
condition|(
operator|!
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|bcopy
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|hdr_compressed
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|compressed
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|!=
argument_list|,
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 		 * If the buf is sharing its data with the hdr, unlink it and 		 * allocate a new data buffer for the buf. 		 */
if|if
condition|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
comment|/* We need to give the buf it's own b_data */
name|buf
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_BUF_FLAG_SHARED
expr_stmt|;
name|buf
operator|->
name|b_data
operator|=
name|arc_get_data_buf
argument_list|(
name|hdr
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_SHARED_DATA
argument_list|)
expr_stmt|;
comment|/* Previously overhead was 0; just add new overhead */
name|ARCSTAT_INCR
argument_list|(
name|arcstat_overhead_size
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|)
block|{
comment|/* We need to reallocate the buf's b_data */
name|arc_free_data_buf
argument_list|(
name|hdr
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_data
operator|=
name|arc_get_data_buf
argument_list|(
name|hdr
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
comment|/* We increased the size of b_data; update overhead */
name|ARCSTAT_INCR
argument_list|(
name|arcstat_overhead_size
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
operator|-
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Regardless of the buf's previous compression settings, it 		 * should not be compressed at the end of this function. 		 */
name|buf
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_BUF_FLAG_COMPRESSED
expr_stmt|;
comment|/* 		 * Try copying the data from another buf which already has a 		 * decompressed version. If that's not possible, it's time to 		 * bite the bullet and decompress the data from the hdr. 		 */
if|if
condition|(
name|arc_buf_try_copy_decompressed_data
argument_list|(
name|buf
argument_list|)
condition|)
block|{
comment|/* Skip byteswapping and checksumming (already done) */
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
else|else
block|{
name|int
name|error
init|=
name|zio_decompress_data
argument_list|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
decl_stmt|;
comment|/* 			 * Absent hardware errors or software bugs, this should 			 * be impossible, but log it anyway so we can debug it. 			 */
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|zfs_dbgmsg
argument_list|(
literal|"hdr %p, compress %d, psize %d, lsize %d"
argument_list|,
name|hdr
argument_list|,
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|SET_ERROR
argument_list|(
name|EIO
argument_list|)
operator|)
return|;
block|}
block|}
block|}
comment|/* Byteswap the buf's data if necessary */
if|if
condition|(
name|bswap
operator|!=
name|DMU_BSWAP_NUMFUNCS
condition|)
block|{
name|ASSERT
argument_list|(
operator|!
name|HDR_SHARED_DATA
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|bswap
argument_list|,
operator|<
argument_list|,
name|DMU_BSWAP_NUMFUNCS
argument_list|)
expr_stmt|;
name|dmu_ot_byteswap
index|[
name|bswap
index|]
operator|.
name|ob_func
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* Compute the hdr's checksum if necessary */
name|arc_cksum_compute
argument_list|(
name|buf
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|int
name|arc_decompress
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
return|return
operator|(
name|arc_buf_fill
argument_list|(
name|buf
argument_list|,
name|B_FALSE
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return the size of the block, b_pdata, that is stored in the arc_buf_hdr_t.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_hdr_size
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|uint64_t
name|size
decl_stmt|;
if|if
condition|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
operator|!=
name|ZIO_COMPRESS_OFF
operator|&&
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
operator|>
literal|0
condition|)
block|{
name|size
operator|=
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT3U
argument_list|(
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|!=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|size
operator|=
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|size
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Increment the amount of evictable space in the arc_state_t's refcount.  * We account for the space used by the hdr and the arc buf individually  * so that we can add and remove them from the refcount individually.  */
end_comment

begin_function
specifier|static
name|void
name|arc_evictable_space_increment
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|arc_state_t
modifier|*
name|state
parameter_list|)
block|{
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|state
argument_list|)
condition|)
block|{
name|ASSERT0
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
return|return;
block|}
name|ASSERT
argument_list|(
operator|!
name|GHOST_STATE
argument_list|(
name|state
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|!=
name|NULL
condition|)
block|{
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|arc_buf_t
modifier|*
name|buf
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
init|;
name|buf
operator|!=
name|NULL
condition|;
name|buf
operator|=
name|buf
operator|->
name|b_next
control|)
block|{
if|if
condition|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
condition|)
continue|continue;
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Decrement the amount of evictable space in the arc_state_t's refcount.  * We account for the space used by the hdr and the arc buf individually  * so that we can add and remove them from the refcount individually.  */
end_comment

begin_function
specifier|static
name|void
name|arc_evictable_space_decrement
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|arc_state_t
modifier|*
name|state
parameter_list|)
block|{
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|state
argument_list|)
condition|)
block|{
name|ASSERT0
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
return|return;
block|}
name|ASSERT
argument_list|(
operator|!
name|GHOST_STATE
argument_list|(
name|state
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|!=
name|NULL
condition|)
block|{
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|arc_buf_t
modifier|*
name|buf
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
init|;
name|buf
operator|!=
name|NULL
condition|;
name|buf
operator|=
name|buf
operator|->
name|b_next
control|)
block|{
if|if
condition|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
condition|)
continue|continue;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Add a reference to this hdr indicating that someone is actively  * referencing that memory. When the refcount transitions from 0 to 1,  * we remove it from the respective arc_state_t list to indicate that  * it is not evictable.  */
end_comment

begin_function
specifier|static
name|void
name|add_reference
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
if|if
condition|(
operator|(
name|refcount_add
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
operator|==
literal|1
operator|)
operator|&&
operator|(
name|state
operator|!=
name|arc_anon
operator|)
condition|)
block|{
comment|/* We don't use the L2-only state list. */
if|if
condition|(
name|state
operator|!=
name|arc_l2c_only
condition|)
block|{
name|multilist_remove
argument_list|(
name|state
operator|->
name|arcs_list
index|[
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
index|]
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_evictable_space_decrement
argument_list|(
name|hdr
argument_list|,
name|state
argument_list|)
expr_stmt|;
block|}
comment|/* remove the prefetch flag if we get a reference */
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_PREFETCH
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Remove a reference from this hdr. When the reference transitions from  * 1 to 0 and we're not anonymous, then we add this hdr to the arc_state_t's  * list making it eligible for eviction.  */
end_comment

begin_function
specifier|static
name|int
name|remove_reference
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
name|hash_lock
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|int
name|cnt
decl_stmt|;
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|state
operator|==
name|arc_anon
operator|||
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|GHOST_STATE
argument_list|(
name|state
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * arc_l2c_only counts as a ghost state so we don't need to explicitly 	 * check to prevent usage of the arc_l2c_only list. 	 */
if|if
condition|(
operator|(
operator|(
name|cnt
operator|=
name|refcount_remove
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|state
operator|!=
name|arc_anon
operator|)
condition|)
block|{
name|multilist_insert
argument_list|(
name|state
operator|->
name|arcs_list
index|[
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
index|]
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|arc_evictable_space_increment
argument_list|(
name|hdr
argument_list|,
name|state
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|cnt
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Move the supplied buffer to the indicated state. The hash lock  * for the buffer must be held by the caller.  */
end_comment

begin_function
specifier|static
name|void
name|arc_change_state
parameter_list|(
name|arc_state_t
modifier|*
name|new_state
parameter_list|,
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
name|hash_lock
parameter_list|)
block|{
name|arc_state_t
modifier|*
name|old_state
decl_stmt|;
name|int64_t
name|refcnt
decl_stmt|;
name|uint32_t
name|bufcnt
decl_stmt|;
name|boolean_t
name|update_old
decl_stmt|,
name|update_new
decl_stmt|;
name|arc_buf_contents_t
name|buftype
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
comment|/* 	 * We almost always have an L1 hdr here, since we call arc_hdr_realloc() 	 * in arc_read() when bringing a buffer out of the L2ARC.  However, the 	 * L1 hdr doesn't always exist when we change state to arc_anon before 	 * destroying a header, in which case reallocating to add the L1 hdr is 	 * pointless. 	 */
if|if
condition|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|old_state
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
expr_stmt|;
name|refcnt
operator|=
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
expr_stmt|;
name|bufcnt
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
expr_stmt|;
name|update_old
operator|=
operator|(
name|bufcnt
operator|>
literal|0
operator|||
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|!=
name|NULL
operator|)
expr_stmt|;
block|}
else|else
block|{
name|old_state
operator|=
name|arc_l2c_only
expr_stmt|;
name|refcnt
operator|=
literal|0
expr_stmt|;
name|bufcnt
operator|=
literal|0
expr_stmt|;
name|update_old
operator|=
name|B_FALSE
expr_stmt|;
block|}
name|update_new
operator|=
name|update_old
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|new_state
argument_list|,
operator|!=
argument_list|,
name|old_state
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|GHOST_STATE
argument_list|(
name|new_state
argument_list|)
operator|||
name|bufcnt
operator|==
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|old_state
operator|!=
name|arc_anon
operator|||
name|bufcnt
operator|<=
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * If this buffer is evictable, transfer it from the 	 * old state list to the new state list. 	 */
if|if
condition|(
name|refcnt
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|old_state
operator|!=
name|arc_anon
operator|&&
name|old_state
operator|!=
name|arc_l2c_only
condition|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|multilist_remove
argument_list|(
name|old_state
operator|->
name|arcs_list
index|[
name|buftype
index|]
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|old_state
argument_list|)
condition|)
block|{
name|ASSERT0
argument_list|(
name|bufcnt
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|update_old
operator|=
name|B_TRUE
expr_stmt|;
block|}
name|arc_evictable_space_decrement
argument_list|(
name|hdr
argument_list|,
name|old_state
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|new_state
operator|!=
name|arc_anon
operator|&&
name|new_state
operator|!=
name|arc_l2c_only
condition|)
block|{
comment|/* 			 * An L1 header always exists here, since if we're 			 * moving to some L1-cached state (i.e. not l2c_only or 			 * anonymous), we realloc the header to add an L1hdr 			 * beforehand. 			 */
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|multilist_insert
argument_list|(
name|new_state
operator|->
name|arcs_list
index|[
name|buftype
index|]
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|new_state
argument_list|)
condition|)
block|{
name|ASSERT0
argument_list|(
name|bufcnt
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|update_new
operator|=
name|B_TRUE
expr_stmt|;
block|}
name|arc_evictable_space_increment
argument_list|(
name|hdr
argument_list|,
name|new_state
argument_list|)
expr_stmt|;
block|}
block|}
name|ASSERT
argument_list|(
operator|!
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|new_state
operator|==
name|arc_anon
operator|&&
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
condition|)
name|buf_hash_remove
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* adjust state sizes (ignore arc_l2c_only) */
if|if
condition|(
name|update_new
operator|&&
name|new_state
operator|!=
name|arc_l2c_only
condition|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|new_state
argument_list|)
condition|)
block|{
name|ASSERT0
argument_list|(
name|bufcnt
argument_list|)
expr_stmt|;
comment|/* 			 * When moving a header to a ghost state, we first 			 * remove all arc buffers. Thus, we'll have a 			 * bufcnt of zero, and no arc buffer to use for 			 * the reference. As a result, we use the arc 			 * header pointer for the reference. 			 */
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|new_state
operator|->
name|arcs_size
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|uint32_t
name|buffers
init|=
literal|0
decl_stmt|;
comment|/* 			 * Each individual buffer holds a unique reference, 			 * thus we must remove each of these references one 			 * at a time. 			 */
for|for
control|(
name|arc_buf_t
modifier|*
name|buf
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
init|;
name|buf
operator|!=
name|NULL
condition|;
name|buf
operator|=
name|buf
operator|->
name|b_next
control|)
block|{
name|ASSERT3U
argument_list|(
name|bufcnt
argument_list|,
operator|!=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|buffers
operator|++
expr_stmt|;
comment|/* 				 * When the arc_buf_t is sharing the data 				 * block with the hdr, the owner of the 				 * reference belongs to the hdr. Only 				 * add to the refcount if the arc_buf_t is 				 * not shared. 				 */
if|if
condition|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
condition|)
continue|continue;
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|new_state
operator|->
name|arcs_size
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
name|ASSERT3U
argument_list|(
name|bufcnt
argument_list|,
operator|==
argument_list|,
name|buffers
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|!=
name|NULL
condition|)
block|{
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|new_state
operator|->
name|arcs_size
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|GHOST_STATE
argument_list|(
name|old_state
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|update_old
operator|&&
name|old_state
operator|!=
name|arc_l2c_only
condition|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|old_state
argument_list|)
condition|)
block|{
name|ASSERT0
argument_list|(
name|bufcnt
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 			 * When moving a header off of a ghost state, 			 * the header will not contain any arc buffers. 			 * We use the arc header pointer for the reference 			 * which is exactly what we did when we put the 			 * header on the ghost state. 			 */
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|old_state
operator|->
name|arcs_size
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|uint32_t
name|buffers
init|=
literal|0
decl_stmt|;
comment|/* 			 * Each individual buffer holds a unique reference, 			 * thus we must remove each of these references one 			 * at a time. 			 */
for|for
control|(
name|arc_buf_t
modifier|*
name|buf
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
init|;
name|buf
operator|!=
name|NULL
condition|;
name|buf
operator|=
name|buf
operator|->
name|b_next
control|)
block|{
name|ASSERT3U
argument_list|(
name|bufcnt
argument_list|,
operator|!=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|buffers
operator|++
expr_stmt|;
comment|/* 				 * When the arc_buf_t is sharing the data 				 * block with the hdr, the owner of the 				 * reference belongs to the hdr. Only 				 * add to the refcount if the arc_buf_t is 				 * not shared. 				 */
if|if
condition|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
condition|)
continue|continue;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|old_state
operator|->
name|arcs_size
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
name|ASSERT3U
argument_list|(
name|bufcnt
argument_list|,
operator|==
argument_list|,
name|buffers
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|old_state
operator|->
name|arcs_size
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|=
name|new_state
expr_stmt|;
comment|/* 	 * L2 headers should never be on the L2 state list since they don't 	 * have L1 headers allocated. 	 */
name|ASSERT
argument_list|(
name|multilist_is_empty
argument_list|(
name|arc_l2c_only
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
operator|&&
name|multilist_is_empty
argument_list|(
name|arc_l2c_only
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|arc_space_consume
parameter_list|(
name|uint64_t
name|space
parameter_list|,
name|arc_space_type_t
name|type
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|type
operator|>=
literal|0
operator|&&
name|type
operator|<
name|ARC_SPACE_NUMTYPES
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|ARC_SPACE_DATA
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_data_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_META
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_metadata_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_OTHER
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_other_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_HDRS
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_hdr_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_L2HDRS
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_hdr_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|type
operator|!=
name|ARC_SPACE_DATA
condition|)
name|ARCSTAT_INCR
argument_list|(
name|arcstat_meta_used
argument_list|,
name|space
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_size
argument_list|,
name|space
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|arc_space_return
parameter_list|(
name|uint64_t
name|space
parameter_list|,
name|arc_space_type_t
name|type
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|type
operator|>=
literal|0
operator|&&
name|type
operator|<
name|ARC_SPACE_NUMTYPES
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|ARC_SPACE_DATA
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_data_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_META
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_metadata_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_OTHER
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_other_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_HDRS
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_hdr_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
break|break;
case|case
name|ARC_SPACE_L2HDRS
case|:
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_hdr_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|type
operator|!=
name|ARC_SPACE_DATA
condition|)
block|{
name|ASSERT
argument_list|(
name|arc_meta_used
operator|>=
name|space
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_meta_max
operator|<
name|arc_meta_used
condition|)
name|arc_meta_max
operator|=
name|arc_meta_used
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_meta_used
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|arc_size
operator|>=
name|space
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_size
argument_list|,
operator|-
name|space
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Given a hdr and a buf, returns whether that buf can share its b_data buffer  * with the hdr's b_pdata.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|arc_can_share
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
comment|/* 	 * The criteria for sharing a hdr's data are: 	 * 1. the hdr's compression matches the buf's compression 	 * 2. the hdr doesn't need to be byteswapped 	 * 3. the hdr isn't already being shared 	 * 4. the buf is either compressed or it is the last buf in the hdr list 	 * 	 * Criterion #4 maintains the invariant that shared uncompressed 	 * bufs must be the final buf in the hdr's b_buf list. Reading this, you 	 * might ask, "if a compressed buf is allocated first, won't that be the 	 * last thing in the list?", but in that case it's impossible to create 	 * a shared uncompressed buf anyway (because the hdr must be compressed 	 * to have the compressed buf). You might also think that #3 is 	 * sufficient to make this guarantee, however it's possible 	 * (specifically in the rare L2ARC write race mentioned in 	 * arc_buf_alloc_impl()) there will be an existing uncompressed buf that 	 * is sharable, but wasn't at the time of its allocation. Rather than 	 * allow a new shared uncompressed buf to be created and then shuffle 	 * the list around to make it the last element, this simply disallows 	 * sharing if the new buf isn't the first to be added. 	 */
name|ASSERT3P
argument_list|(
name|buf
operator|->
name|b_hdr
argument_list|,
operator|==
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|boolean_t
name|hdr_compressed
init|=
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
operator|!=
name|ZIO_COMPRESS_OFF
decl_stmt|;
name|boolean_t
name|buf_compressed
init|=
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
operator|!=
literal|0
decl_stmt|;
return|return
operator|(
name|buf_compressed
operator|==
name|hdr_compressed
operator|&&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_byteswap
operator|==
name|DMU_BSWAP_NUMFUNCS
operator|&&
operator|!
name|HDR_SHARED_DATA
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|(
name|ARC_BUF_LAST
argument_list|(
name|buf
argument_list|)
operator|||
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
operator|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Allocate a buf for this hdr. If you care about the data that's in the hdr,  * or if you want a compressed buffer, pass those flags in. Returns 0 if the  * copy was made successfully, or an error code otherwise.  */
end_comment

begin_function
specifier|static
name|int
name|arc_buf_alloc_impl
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|,
name|boolean_t
name|compressed
parameter_list|,
name|boolean_t
name|fill
parameter_list|,
name|arc_buf_t
modifier|*
modifier|*
name|ret
parameter_list|)
block|{
name|arc_buf_t
modifier|*
name|buf
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|VERIFY
argument_list|(
name|hdr
operator|->
name|b_type
operator|==
name|ARC_BUFC_DATA
operator|||
name|hdr
operator|->
name|b_type
operator|==
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|ret
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
operator|*
name|ret
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|buf
operator|=
operator|*
name|ret
operator|=
name|kmem_cache_alloc
argument_list|(
name|buf_cache
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|=
name|hdr
expr_stmt|;
name|buf
operator|->
name|b_data
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_next
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
expr_stmt|;
name|buf
operator|->
name|b_flags
operator|=
literal|0
expr_stmt|;
name|add_reference
argument_list|(
name|hdr
argument_list|,
name|tag
argument_list|)
expr_stmt|;
comment|/* 	 * We're about to change the hdr's b_flags. We must either 	 * hold the hash_lock or be undiscoverable. 	 */
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
operator|||
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Only honor requests for compressed bufs if the hdr is actually 	 * compressed. 	 */
if|if
condition|(
name|compressed
operator|&&
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
operator|!=
name|ZIO_COMPRESS_OFF
condition|)
name|buf
operator|->
name|b_flags
operator||=
name|ARC_BUF_FLAG_COMPRESSED
expr_stmt|;
comment|/* 	 * If the hdr's data can be shared then we share the data buffer and 	 * set the appropriate bit in the hdr's b_flags to indicate the hdr is 	 * sharing it's b_pdata with the arc_buf_t. Otherwise, we allocate a new 	 * buffer to store the buf's data. 	 * 	 * There is one additional restriction here because we're sharing 	 * hdr -> buf instead of the usual buf -> hdr: the hdr can't be actively 	 * involved in an L2ARC write, because if this buf is used by an 	 * arc_write() then the hdr's data buffer will be released when the 	 * write completes, even though the L2ARC write might still be using it. 	 */
name|boolean_t
name|can_share
init|=
name|arc_can_share
argument_list|(
name|hdr
argument_list|,
name|buf
argument_list|)
operator|&&
operator|!
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
comment|/* Set up b_data and sharing */
if|if
condition|(
name|can_share
condition|)
block|{
name|buf
operator|->
name|b_data
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
expr_stmt|;
name|buf
operator|->
name|b_flags
operator||=
name|ARC_BUF_FLAG_SHARED
expr_stmt|;
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_SHARED_DATA
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|buf
operator|->
name|b_data
operator|=
name|arc_get_data_buf
argument_list|(
name|hdr
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_overhead_size
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|VERIFY3P
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|=
name|buf
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|+=
literal|1
expr_stmt|;
comment|/* 	 * If the user wants the data from the hdr, we need to either copy or 	 * decompress the data. 	 */
if|if
condition|(
name|fill
condition|)
block|{
return|return
operator|(
name|arc_buf_fill
argument_list|(
name|buf
argument_list|,
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
operator|!=
literal|0
argument_list|)
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|char
modifier|*
name|arc_onloan_tag
init|=
literal|"onloan"
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
specifier|inline
name|void
name|arc_loaned_bytes_update
parameter_list|(
name|int64_t
name|delta
parameter_list|)
block|{
name|atomic_add_64
argument_list|(
operator|&
name|arc_loaned_bytes
argument_list|,
name|delta
argument_list|)
expr_stmt|;
comment|/* assert that it did not wrap around */
name|ASSERT3S
argument_list|(
name|atomic_add_64_nv
argument_list|(
operator|&
name|arc_loaned_bytes
argument_list|,
literal|0
argument_list|)
argument_list|,
operator|>=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Loan out an anonymous arc buffer. Loaned buffers are not counted as in  * flight data by arc_tempreserve_space() until they are "returned". Loaned  * buffers must be returned to the arc before they can be used by the DMU or  * freed.  */
end_comment

begin_function
name|arc_buf_t
modifier|*
name|arc_loan_buf
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|boolean_t
name|is_metadata
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|arc_alloc_buf
argument_list|(
name|spa
argument_list|,
name|arc_onloan_tag
argument_list|,
name|is_metadata
condition|?
name|ARC_BUFC_METADATA
else|:
name|ARC_BUFC_DATA
argument_list|,
name|size
argument_list|)
decl_stmt|;
name|arc_loaned_bytes_update
argument_list|(
name|size
argument_list|)
expr_stmt|;
return|return
operator|(
name|buf
operator|)
return|;
block|}
end_function

begin_function
name|arc_buf_t
modifier|*
name|arc_loan_compressed_buf
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|uint64_t
name|psize
parameter_list|,
name|uint64_t
name|lsize
parameter_list|,
name|enum
name|zio_compress
name|compression_type
parameter_list|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|arc_alloc_compressed_buf
argument_list|(
name|spa
argument_list|,
name|arc_onloan_tag
argument_list|,
name|psize
argument_list|,
name|lsize
argument_list|,
name|compression_type
argument_list|)
decl_stmt|;
name|arc_loaned_bytes_update
argument_list|(
name|psize
argument_list|)
expr_stmt|;
return|return
operator|(
name|buf
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return a loaned arc buffer to the arc.  */
end_comment

begin_function
name|void
name|arc_return_buf
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|ASSERT3P
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|arc_onloan_tag
argument_list|)
expr_stmt|;
name|arc_loaned_bytes_update
argument_list|(
operator|-
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Detach an arc_buf from a dbuf (tag) */
end_comment

begin_function
name|void
name|arc_loan_inuse_buf
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|ASSERT3P
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|arc_onloan_tag
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
expr_stmt|;
name|arc_loaned_bytes_update
argument_list|(
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|l2arc_free_data_on_write
parameter_list|(
name|void
modifier|*
name|data
parameter_list|,
name|size_t
name|size
parameter_list|,
name|arc_buf_contents_t
name|type
parameter_list|)
block|{
name|l2arc_data_free_t
modifier|*
name|df
init|=
name|kmem_alloc
argument_list|(
sizeof|sizeof
argument_list|(
operator|*
name|df
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
decl_stmt|;
name|df
operator|->
name|l2df_data
operator|=
name|data
expr_stmt|;
name|df
operator|->
name|l2df_size
operator|=
name|size
expr_stmt|;
name|df
operator|->
name|l2df_type
operator|=
name|type
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|)
expr_stmt|;
name|list_insert_head
argument_list|(
name|l2arc_free_on_write
argument_list|,
name|df
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_hdr_free_on_write
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|uint64_t
name|size
init|=
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
comment|/* protected by hash lock, if in the hash table */
if|if
condition|(
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|state
operator|!=
name|arc_anon
operator|&&
name|state
operator|!=
name|arc_l2c_only
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|,
name|size
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|,
name|size
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
name|type
operator|==
name|ARC_BUFC_METADATA
condition|)
block|{
name|arc_space_return
argument_list|(
name|size
argument_list|,
name|ARC_SPACE_META
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|type
operator|==
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
name|size
argument_list|,
name|ARC_SPACE_DATA
argument_list|)
expr_stmt|;
block|}
name|l2arc_free_data_on_write
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|size
argument_list|,
name|type
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Share the arc_buf_t's data with the hdr. Whenever we are sharing the  * data buffer, we transfer the refcount ownership to the hdr and update  * the appropriate kstats.  */
end_comment

begin_function
specifier|static
name|void
name|arc_share_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|ASSERT
argument_list|(
name|arc_can_share
argument_list|(
name|hdr
argument_list|,
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
operator|||
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Start sharing the data buffer. We transfer the 	 * refcount ownership to the hdr since it always owns 	 * the refcount whenever an arc_buf_t is shared. 	 */
name|refcount_transfer_ownership
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|,
name|buf
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|=
name|buf
operator|->
name|b_data
expr_stmt|;
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_SHARED_DATA
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_flags
operator||=
name|ARC_BUF_FLAG_SHARED
expr_stmt|;
comment|/* 	 * Since we've transferred ownership to the hdr we need 	 * to increment its compressed and uncompressed kstats and 	 * decrement the overhead size. 	 */
name|ARCSTAT_INCR
argument_list|(
name|arcstat_compressed_size
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_uncompressed_size
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_overhead_size
argument_list|,
operator|-
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_unshare_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|ASSERT
argument_list|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
operator|||
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * We are no longer sharing this buffer so we need 	 * to transfer its ownership to the rightful owner. 	 */
name|refcount_transfer_ownership
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|,
name|hdr
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_SHARED_DATA
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|=
name|NULL
expr_stmt|;
name|buf
operator|->
name|b_flags
operator|&=
operator|~
name|ARC_BUF_FLAG_SHARED
expr_stmt|;
comment|/* 	 * Since the buffer is no longer shared between 	 * the arc buf and the hdr, count it as overhead. 	 */
name|ARCSTAT_INCR
argument_list|(
name|arcstat_compressed_size
argument_list|,
operator|-
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_uncompressed_size
argument_list|,
operator|-
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_overhead_size
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove an arc_buf_t from the hdr's buf list and return the last  * arc_buf_t on the list. If no buffers remain on the list then return  * NULL.  */
end_comment

begin_function
specifier|static
name|arc_buf_t
modifier|*
name|arc_buf_remove
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
operator|||
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_buf_t
modifier|*
modifier|*
name|bufp
init|=
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
decl_stmt|;
name|arc_buf_t
modifier|*
name|lastbuf
init|=
name|NULL
decl_stmt|;
comment|/* 	 * Remove the buf from the hdr list and locate the last 	 * remaining buffer on the list. 	 */
while|while
condition|(
operator|*
name|bufp
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
operator|*
name|bufp
operator|==
name|buf
condition|)
operator|*
name|bufp
operator|=
name|buf
operator|->
name|b_next
expr_stmt|;
comment|/* 		 * If we've removed a buffer in the middle of 		 * the list then update the lastbuf and update 		 * bufp. 		 */
if|if
condition|(
operator|*
name|bufp
operator|!=
name|NULL
condition|)
block|{
name|lastbuf
operator|=
operator|*
name|bufp
expr_stmt|;
name|bufp
operator|=
operator|&
operator|(
operator|*
name|bufp
operator|)
operator|->
name|b_next
expr_stmt|;
block|}
block|}
name|buf
operator|->
name|b_next
operator|=
name|NULL
expr_stmt|;
name|ASSERT3P
argument_list|(
name|lastbuf
argument_list|,
operator|!=
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|IMPLY
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|>
literal|0
argument_list|,
name|lastbuf
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|IMPLY
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|>
literal|0
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|!=
name|NULL
argument_list|)
expr_stmt|;
name|IMPLY
argument_list|(
name|lastbuf
operator|!=
name|NULL
argument_list|,
name|ARC_BUF_LAST
argument_list|(
name|lastbuf
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|lastbuf
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Free up buf->b_data and pull the arc_buf_t off of the the arc_buf_hdr_t's  * list and free it.  */
end_comment

begin_function
specifier|static
name|void
name|arc_buf_destroy_impl
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
comment|/* 	 * Free up the data associated with the buf but only if we're not 	 * sharing this with the hdr. If we are sharing it with the hdr, the 	 * hdr is responsible for doing the free. 	 */
if|if
condition|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
condition|)
block|{
comment|/* 		 * We're about to change the hdr's b_flags. We must either 		 * hold the hash_lock or be undiscoverable. 		 */
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
operator|||
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_cksum_verify
argument_list|(
name|buf
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
name|arc_buf_unwatch
argument_list|(
name|buf
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_SHARED_DATA
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|uint64_t
name|size
init|=
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
decl_stmt|;
name|arc_free_data_buf
argument_list|(
name|hdr
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|size
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_overhead_size
argument_list|,
operator|-
name|size
argument_list|)
expr_stmt|;
block|}
name|buf
operator|->
name|b_data
operator|=
name|NULL
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|>
literal|0
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|-=
literal|1
expr_stmt|;
block|}
name|arc_buf_t
modifier|*
name|lastbuf
init|=
name|arc_buf_remove
argument_list|(
name|hdr
argument_list|,
name|buf
argument_list|)
decl_stmt|;
if|if
condition|(
name|ARC_BUF_SHARED
argument_list|(
name|buf
argument_list|)
operator|&&
operator|!
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|)
block|{
comment|/* 		 * If the current arc_buf_t is sharing its data buffer with the 		 * hdr, then reassign the hdr's b_pdata to share it with the new 		 * buffer at the end of the list. The shared buffer is always 		 * the last one on the hdr's buffer list. 		 * 		 * There is an equivalent case for compressed bufs, but since 		 * they aren't guaranteed to be the last buf in the list and 		 * that is an exceedingly rare case, we just allow that space be 		 * wasted temporarily. 		 */
if|if
condition|(
name|lastbuf
operator|!=
name|NULL
condition|)
block|{
comment|/* Only one buf can be shared at once */
name|VERIFY
argument_list|(
operator|!
name|arc_buf_is_shared
argument_list|(
name|lastbuf
argument_list|)
argument_list|)
expr_stmt|;
comment|/* hdr is uncompressed so can't have compressed buf */
name|VERIFY
argument_list|(
operator|!
name|ARC_BUF_COMPRESSED
argument_list|(
name|lastbuf
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|arc_hdr_free_pdata
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* 			 * We must setup a new shared block between the 			 * last buffer and the hdr. The data would have 			 * been allocated by the arc buf so we need to transfer 			 * ownership to the hdr since it's now being shared. 			 */
name|arc_share_buf
argument_list|(
name|hdr
argument_list|,
name|lastbuf
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|HDR_SHARED_DATA
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
comment|/* 		 * Uncompressed shared buffers are always at the end 		 * of the list. Compressed buffers don't have the 		 * same requirements. This makes it hard to 		 * simply assert that the lastbuf is shared so 		 * we rely on the hdr's compression flags to determine 		 * if we have a compressed, shared buffer. 		 */
name|ASSERT3P
argument_list|(
name|lastbuf
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|arc_buf_is_shared
argument_list|(
name|lastbuf
argument_list|)
operator|||
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
operator|!=
name|ZIO_COMPRESS_OFF
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Free the checksum if we're removing the last uncompressed buf from 	 * this hdr. 	 */
if|if
condition|(
operator|!
name|arc_hdr_has_uncompressed_buf
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|arc_cksum_free
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
comment|/* clean up the buf */
name|buf
operator|->
name|b_hdr
operator|=
name|NULL
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|buf_cache
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_hdr_alloc_pdata
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|ASSERT3U
argument_list|(
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_SHARED_DATA
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|=
name|arc_get_data_buf
argument_list|(
name|hdr
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_byteswap
operator|=
name|DMU_BSWAP_NUMFUNCS
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_compressed_size
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_uncompressed_size
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_hdr_free_pdata
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 	 * If the hdr is currently being written to the l2arc then 	 * we defer freeing the data by adding it to the l2arc_free_on_write 	 * list. The l2arc will free the data once it's finished 	 * writing it to the l2arc device. 	 */
if|if
condition|(
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|arc_hdr_free_on_write
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_free_on_write
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_free_data_buf
argument_list|(
name|hdr
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|=
name|NULL
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_byteswap
operator|=
name|DMU_BSWAP_NUMFUNCS
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_compressed_size
argument_list|,
operator|-
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_uncompressed_size
argument_list|,
operator|-
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|arc_buf_hdr_t
modifier|*
name|arc_hdr_alloc
parameter_list|(
name|uint64_t
name|spa
parameter_list|,
name|int32_t
name|psize
parameter_list|,
name|int32_t
name|lsize
parameter_list|,
name|enum
name|zio_compress
name|compression_type
parameter_list|,
name|arc_buf_contents_t
name|type
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|VERIFY
argument_list|(
name|type
operator|==
name|ARC_BUFC_DATA
operator|||
name|type
operator|==
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|kmem_cache_alloc
argument_list|(
name|hdr_full_cache
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|HDR_SET_PSIZE
argument_list|(
name|hdr
argument_list|,
name|psize
argument_list|)
expr_stmt|;
name|HDR_SET_LSIZE
argument_list|(
name|hdr
argument_list|,
name|lsize
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_spa
operator|=
name|spa
expr_stmt|;
name|hdr
operator|->
name|b_type
operator|=
name|type
expr_stmt|;
name|hdr
operator|->
name|b_flags
operator|=
literal|0
expr_stmt|;
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|arc_bufc_to_flags
argument_list|(
name|type
argument_list|)
operator||
name|ARC_FLAG_HAS_L1HDR
argument_list|)
expr_stmt|;
name|arc_hdr_set_compress
argument_list|(
name|hdr
argument_list|,
name|compression_type
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|=
name|arc_anon
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
literal|0
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|=
literal|0
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|=
name|NULL
expr_stmt|;
comment|/* 	 * Allocate the hdr's buffer. This will contain either 	 * the compressed or uncompressed data depending on the block 	 * it references and compressed arc enablement. 	 */
name|arc_hdr_alloc_pdata
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|hdr
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Transition between the two allocation states for the arc_buf_hdr struct.  * The arc_buf_hdr struct can be allocated with (hdr_full_cache) or without  * (hdr_l2only_cache) the fields necessary for the L1 cache - the smaller  * version is used when a cache buffer is only in the L2ARC in order to reduce  * memory usage.  */
end_comment

begin_function
specifier|static
name|arc_buf_hdr_t
modifier|*
name|arc_hdr_realloc
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmem_cache_t
modifier|*
name|old
parameter_list|,
name|kmem_cache_t
modifier|*
name|new
parameter_list|)
block|{
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_buf_hdr_t
modifier|*
name|nhdr
decl_stmt|;
name|l2arc_dev_t
modifier|*
name|dev
init|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
decl_stmt|;
name|ASSERT
argument_list|(
operator|(
name|old
operator|==
name|hdr_full_cache
operator|&&
name|new
operator|==
name|hdr_l2only_cache
operator|)
operator|||
operator|(
name|old
operator|==
name|hdr_l2only_cache
operator|&&
name|new
operator|==
name|hdr_full_cache
operator|)
argument_list|)
expr_stmt|;
name|nhdr
operator|=
name|kmem_cache_alloc
argument_list|(
name|new
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|buf_hash_remove
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|hdr
argument_list|,
name|nhdr
argument_list|,
name|HDR_L2ONLY_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|new
operator|==
name|hdr_full_cache
condition|)
block|{
name|arc_hdr_set_flags
argument_list|(
name|nhdr
argument_list|,
name|ARC_FLAG_HAS_L1HDR
argument_list|)
expr_stmt|;
comment|/* 		 * arc_access and arc_change_state need to be aware that a 		 * header has just come out of L2ARC, so we set its state to 		 * l2c_only even though it's about to change. 		 */
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|=
name|arc_l2c_only
expr_stmt|;
comment|/* Verify previous threads set to NULL before freeing */
name|ASSERT3P
argument_list|(
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 		 * If we've reached here, We must have been called from 		 * arc_evict_hdr(), as such we should have already been 		 * removed from any ghost list we were previously on 		 * (which protects us from racing with arc_evict_state), 		 * thus no locking is needed during this check. 		 */
name|ASSERT
argument_list|(
operator|!
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 		 * A buffer must not be moved into the arc_l2c_only 		 * state if it's not finished being written out to the 		 * l2arc device. Otherwise, the b_l1hdr.b_pdata field 		 * might try to be accessed, even though it was removed. 		 */
name|VERIFY
argument_list|(
operator|!
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|VERIFY3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|ZFS_DEBUG
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|!=
name|NULL
condition|)
block|{
name|kmem_free
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|=
name|NULL
expr_stmt|;
block|}
endif|#
directive|endif
name|arc_hdr_clear_flags
argument_list|(
name|nhdr
argument_list|,
name|ARC_FLAG_HAS_L1HDR
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * The header has been reallocated so we need to re-insert it into any 	 * lists it was on. 	 */
operator|(
name|void
operator|)
name|buf_hash_insert
argument_list|(
name|nhdr
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|list_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_l2node
argument_list|)
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * We must place the realloc'ed header back into the list at 	 * the same spot. Otherwise, if it's placed earlier in the list, 	 * l2arc_write_buffers() could find it during the function's 	 * write phase, and try to write it out to the l2arc. 	 */
name|list_insert_after
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|hdr
argument_list|,
name|nhdr
argument_list|)
expr_stmt|;
name|list_remove
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Since we're using the pointer address as the tag when 	 * incrementing and decrementing the l2ad_alloc refcount, we 	 * must remove the old pointer (that we're about to destroy) and 	 * add the new pointer to the refcount. Otherwise we'd remove 	 * the wrong pointer address when calling arc_hdr_destroy() later. 	 */
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_alloc
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_alloc
argument_list|,
name|arc_hdr_size
argument_list|(
name|nhdr
argument_list|)
argument_list|,
name|nhdr
argument_list|)
expr_stmt|;
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|old
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
return|return
operator|(
name|nhdr
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Allocate a new arc_buf_hdr_t and arc_buf_t and return the buf to the caller.  * The buf is returned thawed since we expect the consumer to modify it.  */
end_comment

begin_function
name|arc_buf_t
modifier|*
name|arc_alloc_buf
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|,
name|arc_buf_contents_t
name|type
parameter_list|,
name|int32_t
name|size
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|arc_hdr_alloc
argument_list|(
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
argument_list|,
name|size
argument_list|,
name|size
argument_list|,
name|ZIO_COMPRESS_OFF
argument_list|,
name|type
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|arc_buf_t
modifier|*
name|buf
init|=
name|NULL
decl_stmt|;
name|VERIFY0
argument_list|(
name|arc_buf_alloc_impl
argument_list|(
name|hdr
argument_list|,
name|tag
argument_list|,
name|B_FALSE
argument_list|,
name|B_FALSE
argument_list|,
operator|&
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|arc_buf_thaw
argument_list|(
name|buf
argument_list|)
expr_stmt|;
return|return
operator|(
name|buf
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Allocate a compressed buf in the same manner as arc_alloc_buf. Don't use this  * for bufs containing metadata.  */
end_comment

begin_function
name|arc_buf_t
modifier|*
name|arc_alloc_compressed_buf
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|,
name|uint64_t
name|psize
parameter_list|,
name|uint64_t
name|lsize
parameter_list|,
name|enum
name|zio_compress
name|compression_type
parameter_list|)
block|{
name|ASSERT3U
argument_list|(
name|lsize
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|lsize
argument_list|,
operator|>=
argument_list|,
name|psize
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|compression_type
operator|>
name|ZIO_COMPRESS_OFF
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|compression_type
operator|<
name|ZIO_COMPRESS_FUNCTIONS
argument_list|)
expr_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|arc_hdr_alloc
argument_list|(
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
argument_list|,
name|psize
argument_list|,
name|lsize
argument_list|,
name|compression_type
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|MUTEX_HELD
argument_list|(
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|arc_buf_t
modifier|*
name|buf
init|=
name|NULL
decl_stmt|;
name|VERIFY0
argument_list|(
name|arc_buf_alloc_impl
argument_list|(
name|hdr
argument_list|,
name|tag
argument_list|,
name|B_TRUE
argument_list|,
name|B_FALSE
argument_list|,
operator|&
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|arc_buf_thaw
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
return|return
operator|(
name|buf
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_hdr_l2hdr_destroy
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
name|l2arc_buf_hdr_t
modifier|*
name|l2hdr
init|=
operator|&
name|hdr
operator|->
name|b_l2hdr
decl_stmt|;
name|l2arc_dev_t
modifier|*
name|dev
init|=
name|l2hdr
operator|->
name|b_dev
decl_stmt|;
name|uint64_t
name|asize
init|=
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|list_remove
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_asize
argument_list|,
operator|-
name|asize
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_size
argument_list|,
operator|-
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|vdev_space_update
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
operator|-
name|asize
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_alloc
argument_list|,
name|asize
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_HAS_L2HDR
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_hdr_destroy
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
if|if
condition|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|==
name|NULL
operator|||
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|>
literal|0
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|,
operator|==
argument_list|,
name|arc_anon
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
condition|)
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|l2arc_dev_t
modifier|*
name|dev
init|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
decl_stmt|;
name|boolean_t
name|buflist_held
init|=
name|MUTEX_HELD
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|buflist_held
condition|)
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 		 * Even though we checked this conditional above, we 		 * need to check this again now that we have the 		 * l2ad_mtx. This is because we could be racing with 		 * another thread calling l2arc_evict() which might have 		 * destroyed this header's L2 portion as we were waiting 		 * to acquire the l2ad_mtx. If that happens, we don't 		 * want to re-destroy the header's L2 portion. 		 */
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|l2arc_trim
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|arc_hdr_l2hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|buflist_held
condition|)
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|arc_cksum_free
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
while|while
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|!=
name|NULL
condition|)
name|arc_buf_destroy_impl
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|ZFS_DEBUG
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|!=
name|NULL
condition|)
block|{
name|kmem_free
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_thawed
operator|=
name|NULL
expr_stmt|;
block|}
endif|#
directive|endif
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|!=
name|NULL
condition|)
block|{
name|arc_hdr_free_pdata
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
block|}
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_hash_next
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
operator|!
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|hdr_full_cache
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|kmem_cache_free
argument_list|(
name|hdr_l2only_cache
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|arc_buf_destroy
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
condition|)
block|{
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
argument_list|,
operator|==
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|VERIFY0
argument_list|(
name|remove_reference
argument_list|(
name|hdr
argument_list|,
name|NULL
argument_list|,
name|tag
argument_list|)
argument_list|)
expr_stmt|;
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
return|return;
block|}
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
argument_list|,
operator|==
argument_list|,
name|buf
operator|->
name|b_hdr
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|>
literal|0
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hash_lock
argument_list|,
operator|==
argument_list|,
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|,
operator|!=
argument_list|,
name|arc_anon
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|remove_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|tag
argument_list|)
expr_stmt|;
name|arc_buf_destroy_impl
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Evict the arc_buf_hdr that is provided as a parameter. The resultant  * state of the header is dependent on it's state prior to entering this  * function. The following transitions are possible:  *  *    - arc_mru -> arc_mru_ghost  *    - arc_mfu -> arc_mfu_ghost  *    - arc_mru_ghost -> arc_l2c_only  *    - arc_mru_ghost -> deleted  *    - arc_mfu_ghost -> arc_l2c_only  *    - arc_mfu_ghost -> deleted  */
end_comment

begin_function
specifier|static
name|int64_t
name|arc_evict_hdr
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
name|hash_lock
parameter_list|)
block|{
name|arc_state_t
modifier|*
name|evicted_state
decl_stmt|,
modifier|*
name|state
decl_stmt|;
name|int64_t
name|bytes_evicted
init|=
literal|0
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|state
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
expr_stmt|;
if|if
condition|(
name|GHOST_STATE
argument_list|(
name|state
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 		 * l2arc_write_buffers() relies on a header's L1 portion 		 * (i.e. its b_pdata field) during its write phase. 		 * Thus, we cannot push a header onto the arc_l2c_only 		 * state (removing it's L1 piece) until the header is 		 * done being written to the l2arc. 		 */
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
operator|&&
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_evict_l2_skip
argument_list|)
expr_stmt|;
return|return
operator|(
name|bytes_evicted
operator|)
return|;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_deleted
argument_list|)
expr_stmt|;
name|bytes_evicted
operator|+=
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|arc__delete
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
comment|/* 			 * This buffer is cached on the 2nd Level ARC; 			 * don't destroy the header. 			 */
name|arc_change_state
argument_list|(
name|arc_l2c_only
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
comment|/* 			 * dropping from L1+L2 cached to L2-only, 			 * realloc to remove the L1 header. 			 */
name|hdr
operator|=
name|arc_hdr_realloc
argument_list|(
name|hdr
argument_list|,
name|hdr_full_cache
argument_list|,
name|hdr_l2only_cache
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|bytes_evicted
operator|)
return|;
block|}
name|ASSERT
argument_list|(
name|state
operator|==
name|arc_mru
operator|||
name|state
operator|==
name|arc_mfu
argument_list|)
expr_stmt|;
name|evicted_state
operator|=
operator|(
name|state
operator|==
name|arc_mru
operator|)
condition|?
name|arc_mru_ghost
else|:
name|arc_mfu_ghost
expr_stmt|;
comment|/* prefetch buffers have a minimum lifespan */
if|if
condition|(
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
operator|||
operator|(
operator|(
name|hdr
operator|->
name|b_flags
operator|&
operator|(
name|ARC_FLAG_PREFETCH
operator||
name|ARC_FLAG_INDIRECT
operator|)
operator|)
operator|&&
name|ddi_get_lbolt
argument_list|()
operator|-
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|<
name|arc_min_prefetch_lifespan
operator|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_evict_skip
argument_list|)
expr_stmt|;
return|return
operator|(
name|bytes_evicted
operator|)
return|;
block|}
name|ASSERT0
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
while|while
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
condition|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
decl_stmt|;
if|if
condition|(
operator|!
name|mutex_tryenter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mutex_miss
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
condition|)
name|bytes_evicted
operator|+=
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|arc_buf_destroy_impl
argument_list|(
name|buf
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_INCR
argument_list|(
name|arcstat_evict_l2_cached
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|l2arc_write_eligible
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_INCR
argument_list|(
name|arcstat_evict_l2_eligible
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ARCSTAT_INCR
argument_list|(
name|arcstat_evict_l2_ineligible
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|==
literal|0
condition|)
block|{
name|arc_cksum_free
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|bytes_evicted
operator|+=
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* 		 * If this hdr is being evicted and has a compressed 		 * buffer then we discard it here before we change states. 		 * This ensures that the accounting is updated correctly 		 * in arc_free_data_buf(). 		 */
name|arc_hdr_free_pdata
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|evicted_state
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_IN_HASH_TABLE
argument_list|)
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|arc__evict
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|bytes_evicted
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|arc_evict_state_impl
parameter_list|(
name|multilist_t
modifier|*
name|ml
parameter_list|,
name|int
name|idx
parameter_list|,
name|arc_buf_hdr_t
modifier|*
name|marker
parameter_list|,
name|uint64_t
name|spa
parameter_list|,
name|int64_t
name|bytes
parameter_list|)
block|{
name|multilist_sublist_t
modifier|*
name|mls
decl_stmt|;
name|uint64_t
name|bytes_evicted
init|=
literal|0
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|int
name|evict_count
init|=
literal|0
decl_stmt|;
name|ASSERT3P
argument_list|(
name|marker
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|IMPLY
argument_list|(
name|bytes
operator|<
literal|0
argument_list|,
name|bytes
operator|==
name|ARC_EVICT_ALL
argument_list|)
expr_stmt|;
name|mls
operator|=
name|multilist_sublist_lock
argument_list|(
name|ml
argument_list|,
name|idx
argument_list|)
expr_stmt|;
for|for
control|(
name|hdr
operator|=
name|multilist_sublist_prev
argument_list|(
name|mls
argument_list|,
name|marker
argument_list|)
init|;
name|hdr
operator|!=
name|NULL
condition|;
name|hdr
operator|=
name|multilist_sublist_prev
argument_list|(
name|mls
argument_list|,
name|marker
argument_list|)
control|)
block|{
if|if
condition|(
operator|(
name|bytes
operator|!=
name|ARC_EVICT_ALL
operator|&&
name|bytes_evicted
operator|>=
name|bytes
operator|)
operator|||
operator|(
name|evict_count
operator|>=
name|zfs_arc_evict_batch_limit
operator|)
condition|)
break|break;
comment|/* 		 * To keep our iteration location, move the marker 		 * forward. Since we're not holding hdr's hash lock, we 		 * must be very careful and not remove 'hdr' from the 		 * sublist. Otherwise, other consumers might mistake the 		 * 'hdr' as not being on a sublist when they call the 		 * multilist_link_active() function (they all rely on 		 * the hash lock protecting concurrent insertions and 		 * removals). multilist_sublist_move_forward() was 		 * specifically implemented to ensure this is the case 		 * (only 'marker' will be removed and re-inserted). 		 */
name|multilist_sublist_move_forward
argument_list|(
name|mls
argument_list|,
name|marker
argument_list|)
expr_stmt|;
comment|/* 		 * The only case where the b_spa field should ever be 		 * zero, is the marker headers inserted by 		 * arc_evict_state(). It's possible for multiple threads 		 * to be calling arc_evict_state() concurrently (e.g. 		 * dsl_pool_close() and zio_inject_fault()), so we must 		 * skip any markers we see from these other threads. 		 */
if|if
condition|(
name|hdr
operator|->
name|b_spa
operator|==
literal|0
condition|)
continue|continue;
comment|/* we're only interested in evicting buffers of a certain spa */
if|if
condition|(
name|spa
operator|!=
literal|0
operator|&&
name|hdr
operator|->
name|b_spa
operator|!=
name|spa
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_evict_skip
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* 		 * We aren't calling this function from any code path 		 * that would already be holding a hash lock, so we're 		 * asserting on this assumption to be defensive in case 		 * this ever changes. Without this check, it would be 		 * possible to incorrectly increment arcstat_mutex_miss 		 * below (e.g. if the code changed such that we called 		 * this function with a hash lock held). 		 */
name|ASSERT
argument_list|(
operator|!
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|mutex_tryenter
argument_list|(
name|hash_lock
argument_list|)
condition|)
block|{
name|uint64_t
name|evicted
init|=
name|arc_evict_hdr
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
decl_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|bytes_evicted
operator|+=
name|evicted
expr_stmt|;
comment|/* 			 * If evicted is zero, arc_evict_hdr() must have 			 * decided to skip this header, don't increment 			 * evict_count in this case. 			 */
if|if
condition|(
name|evicted
operator|!=
literal|0
condition|)
name|evict_count
operator|++
expr_stmt|;
comment|/* 			 * If arc_size isn't overflowing, signal any 			 * threads that might happen to be waiting. 			 * 			 * For each header evicted, we wake up a single 			 * thread. If we used cv_broadcast, we could 			 * wake up "too many" threads causing arc_size 			 * to significantly overflow arc_c; since 			 * arc_get_data_buf() doesn't check for overflow 			 * when it's woken up (it doesn't because it's 			 * possible for the ARC to be overflowing while 			 * full of un-evictable buffers, and the 			 * function should proceed in this case). 			 * 			 * If threads are left sleeping, due to not 			 * using cv_broadcast, they will be woken up 			 * just before arc_reclaim_thread() sleeps. 			 */
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|arc_is_overflowing
argument_list|()
condition|)
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mutex_miss
argument_list|)
expr_stmt|;
block|}
block|}
name|multilist_sublist_unlock
argument_list|(
name|mls
argument_list|)
expr_stmt|;
return|return
operator|(
name|bytes_evicted
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict buffers from the given arc state, until we've removed the  * specified number of bytes. Move the removed buffers to the  * appropriate evict state.  *  * This function makes a "best effort". It skips over any buffers  * it can't get a hash_lock on, and so, may not catch all candidates.  * It may also return without evicting as much space as requested.  *  * If bytes is specified using the special value ARC_EVICT_ALL, this  * will evict all available (i.e. unlocked and evictable) buffers from  * the given arc state; which is used by arc_flush().  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_evict_state
parameter_list|(
name|arc_state_t
modifier|*
name|state
parameter_list|,
name|uint64_t
name|spa
parameter_list|,
name|int64_t
name|bytes
parameter_list|,
name|arc_buf_contents_t
name|type
parameter_list|)
block|{
name|uint64_t
name|total_evicted
init|=
literal|0
decl_stmt|;
name|multilist_t
modifier|*
name|ml
init|=
name|state
operator|->
name|arcs_list
index|[
name|type
index|]
decl_stmt|;
name|int
name|num_sublists
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
modifier|*
name|markers
decl_stmt|;
name|IMPLY
argument_list|(
name|bytes
operator|<
literal|0
argument_list|,
name|bytes
operator|==
name|ARC_EVICT_ALL
argument_list|)
expr_stmt|;
name|num_sublists
operator|=
name|multilist_get_num_sublists
argument_list|(
name|ml
argument_list|)
expr_stmt|;
comment|/* 	 * If we've tried to evict from each sublist, made some 	 * progress, but still have not hit the target number of bytes 	 * to evict, we want to keep trying. The markers allow us to 	 * pick up where we left off for each individual sublist, rather 	 * than starting from the tail each time. 	 */
name|markers
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
operator|*
name|markers
argument_list|)
operator|*
name|num_sublists
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|num_sublists
condition|;
name|i
operator|++
control|)
block|{
name|markers
index|[
name|i
index|]
operator|=
name|kmem_cache_alloc
argument_list|(
name|hdr_full_cache
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
comment|/* 		 * A b_spa of 0 is used to indicate that this header is 		 * a marker. This fact is used in arc_adjust_type() and 		 * arc_evict_state_impl(). 		 */
name|markers
index|[
name|i
index|]
operator|->
name|b_spa
operator|=
literal|0
expr_stmt|;
name|multilist_sublist_t
modifier|*
name|mls
init|=
name|multilist_sublist_lock
argument_list|(
name|ml
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|multilist_sublist_insert_tail
argument_list|(
name|mls
argument_list|,
name|markers
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|multilist_sublist_unlock
argument_list|(
name|mls
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * While we haven't hit our target number of bytes to evict, or 	 * we're evicting all available buffers. 	 */
while|while
condition|(
name|total_evicted
operator|<
name|bytes
operator|||
name|bytes
operator|==
name|ARC_EVICT_ALL
condition|)
block|{
comment|/* 		 * Start eviction using a randomly selected sublist, 		 * this is to try and evenly balance eviction across all 		 * sublists. Always starting at the same sublist 		 * (e.g. index 0) would cause evictions to favor certain 		 * sublists over others. 		 */
name|int
name|sublist_idx
init|=
name|multilist_get_random_index
argument_list|(
name|ml
argument_list|)
decl_stmt|;
name|uint64_t
name|scan_evicted
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|num_sublists
condition|;
name|i
operator|++
control|)
block|{
name|uint64_t
name|bytes_remaining
decl_stmt|;
name|uint64_t
name|bytes_evicted
decl_stmt|;
if|if
condition|(
name|bytes
operator|==
name|ARC_EVICT_ALL
condition|)
name|bytes_remaining
operator|=
name|ARC_EVICT_ALL
expr_stmt|;
elseif|else
if|if
condition|(
name|total_evicted
operator|<
name|bytes
condition|)
name|bytes_remaining
operator|=
name|bytes
operator|-
name|total_evicted
expr_stmt|;
else|else
break|break;
name|bytes_evicted
operator|=
name|arc_evict_state_impl
argument_list|(
name|ml
argument_list|,
name|sublist_idx
argument_list|,
name|markers
index|[
name|sublist_idx
index|]
argument_list|,
name|spa
argument_list|,
name|bytes_remaining
argument_list|)
expr_stmt|;
name|scan_evicted
operator|+=
name|bytes_evicted
expr_stmt|;
name|total_evicted
operator|+=
name|bytes_evicted
expr_stmt|;
comment|/* we've reached the end, wrap to the beginning */
if|if
condition|(
operator|++
name|sublist_idx
operator|>=
name|num_sublists
condition|)
name|sublist_idx
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 		 * If we didn't evict anything during this scan, we have 		 * no reason to believe we'll evict more during another 		 * scan, so break the loop. 		 */
if|if
condition|(
name|scan_evicted
operator|==
literal|0
condition|)
block|{
comment|/* This isn't possible, let's make that obvious */
name|ASSERT3S
argument_list|(
name|bytes
argument_list|,
operator|!=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 			 * When bytes is ARC_EVICT_ALL, the only way to 			 * break the loop is when scan_evicted is zero. 			 * In that case, we actually have evicted enough, 			 * so we don't want to increment the kstat. 			 */
if|if
condition|(
name|bytes
operator|!=
name|ARC_EVICT_ALL
condition|)
block|{
name|ASSERT3S
argument_list|(
name|total_evicted
argument_list|,
operator|<
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_evict_not_enough
argument_list|)
expr_stmt|;
block|}
break|break;
block|}
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|num_sublists
condition|;
name|i
operator|++
control|)
block|{
name|multilist_sublist_t
modifier|*
name|mls
init|=
name|multilist_sublist_lock
argument_list|(
name|ml
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|multilist_sublist_remove
argument_list|(
name|mls
argument_list|,
name|markers
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|multilist_sublist_unlock
argument_list|(
name|mls
argument_list|)
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|hdr_full_cache
argument_list|,
name|markers
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
name|kmem_free
argument_list|(
name|markers
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|markers
argument_list|)
operator|*
name|num_sublists
argument_list|)
expr_stmt|;
return|return
operator|(
name|total_evicted
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Flush all "evictable" data of the given type from the arc state  * specified. This will not evict any "active" buffers (i.e. referenced).  *  * When 'retry' is set to B_FALSE, the function will make a single pass  * over the state and evict any buffers that it can. Since it doesn't  * continually retry the eviction, it might end up leaving some buffers  * in the ARC due to lock misses.  *  * When 'retry' is set to B_TRUE, the function will continually retry the  * eviction until *all* evictable buffers have been removed from the  * state. As a result, if concurrent insertions into the state are  * allowed (e.g. if the ARC isn't shutting down), this function might  * wind up in an infinite loop, continually trying to evict buffers.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_flush_state
parameter_list|(
name|arc_state_t
modifier|*
name|state
parameter_list|,
name|uint64_t
name|spa
parameter_list|,
name|arc_buf_contents_t
name|type
parameter_list|,
name|boolean_t
name|retry
parameter_list|)
block|{
name|uint64_t
name|evicted
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|refcount_count
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|evicted
operator|+=
name|arc_evict_state
argument_list|(
name|state
argument_list|,
name|spa
argument_list|,
name|ARC_EVICT_ALL
argument_list|,
name|type
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|retry
condition|)
break|break;
block|}
return|return
operator|(
name|evicted
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict the specified number of bytes from the state specified,  * restricting eviction to the spa and type given. This function  * prevents us from trying to evict more from a state's list than  * is "evictable", and to skip evicting altogether when passed a  * negative value for "bytes". In contrast, arc_evict_state() will  * evict everything it can, when passed a negative value for "bytes".  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_adjust_impl
parameter_list|(
name|arc_state_t
modifier|*
name|state
parameter_list|,
name|uint64_t
name|spa
parameter_list|,
name|int64_t
name|bytes
parameter_list|,
name|arc_buf_contents_t
name|type
parameter_list|)
block|{
name|int64_t
name|delta
decl_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
operator|&&
name|refcount_count
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|)
operator|>
literal|0
condition|)
block|{
name|delta
operator|=
name|MIN
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|)
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
return|return
operator|(
name|arc_evict_state
argument_list|(
name|state
argument_list|,
name|spa
argument_list|,
name|delta
argument_list|,
name|type
argument_list|)
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict metadata buffers from the cache, such that arc_meta_used is  * capped by the arc_meta_limit tunable.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_adjust_meta
parameter_list|(
name|void
parameter_list|)
block|{
name|uint64_t
name|total_evicted
init|=
literal|0
decl_stmt|;
name|int64_t
name|target
decl_stmt|;
comment|/* 	 * If we're over the meta limit, we want to evict enough 	 * metadata to get back under the meta limit. We don't want to 	 * evict so much that we drop the MRU below arc_p, though. If 	 * we're over the meta limit more than we're over arc_p, we 	 * evict some from the MRU here, and some from the MFU below. 	 */
name|target
operator|=
name|MIN
argument_list|(
call|(
name|int64_t
call|)
argument_list|(
name|arc_meta_used
operator|-
name|arc_meta_limit
argument_list|)
argument_list|,
call|(
name|int64_t
call|)
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
operator|+
name|refcount_count
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
operator|-
name|arc_p
argument_list|)
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mru
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
comment|/* 	 * Similar to the above, we want to evict enough bytes to get us 	 * below the meta limit, but not so much as to drop us below the 	 * space allotted to the MFU (which is defined as arc_c - arc_p). 	 */
name|target
operator|=
name|MIN
argument_list|(
call|(
name|int64_t
call|)
argument_list|(
name|arc_meta_used
operator|-
name|arc_meta_limit
argument_list|)
argument_list|,
call|(
name|int64_t
call|)
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_size
argument_list|)
operator|-
operator|(
name|arc_c
operator|-
name|arc_p
operator|)
argument_list|)
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mfu
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
return|return
operator|(
name|total_evicted
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return the type of the oldest buffer in the given arc state  *  * This function will select a random sublist of type ARC_BUFC_DATA and  * a random sublist of type ARC_BUFC_METADATA. The tail of each sublist  * is compared, and the type which contains the "older" buffer will be  * returned.  */
end_comment

begin_function
specifier|static
name|arc_buf_contents_t
name|arc_adjust_type
parameter_list|(
name|arc_state_t
modifier|*
name|state
parameter_list|)
block|{
name|multilist_t
modifier|*
name|data_ml
init|=
name|state
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
decl_stmt|;
name|multilist_t
modifier|*
name|meta_ml
init|=
name|state
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
decl_stmt|;
name|int
name|data_idx
init|=
name|multilist_get_random_index
argument_list|(
name|data_ml
argument_list|)
decl_stmt|;
name|int
name|meta_idx
init|=
name|multilist_get_random_index
argument_list|(
name|meta_ml
argument_list|)
decl_stmt|;
name|multilist_sublist_t
modifier|*
name|data_mls
decl_stmt|;
name|multilist_sublist_t
modifier|*
name|meta_mls
decl_stmt|;
name|arc_buf_contents_t
name|type
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|data_hdr
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|meta_hdr
decl_stmt|;
comment|/* 	 * We keep the sublist lock until we're finished, to prevent 	 * the headers from being destroyed via arc_evict_state(). 	 */
name|data_mls
operator|=
name|multilist_sublist_lock
argument_list|(
name|data_ml
argument_list|,
name|data_idx
argument_list|)
expr_stmt|;
name|meta_mls
operator|=
name|multilist_sublist_lock
argument_list|(
name|meta_ml
argument_list|,
name|meta_idx
argument_list|)
expr_stmt|;
comment|/* 	 * These two loops are to ensure we skip any markers that 	 * might be at the tail of the lists due to arc_evict_state(). 	 */
for|for
control|(
name|data_hdr
operator|=
name|multilist_sublist_tail
argument_list|(
name|data_mls
argument_list|)
init|;
name|data_hdr
operator|!=
name|NULL
condition|;
name|data_hdr
operator|=
name|multilist_sublist_prev
argument_list|(
name|data_mls
argument_list|,
name|data_hdr
argument_list|)
control|)
block|{
if|if
condition|(
name|data_hdr
operator|->
name|b_spa
operator|!=
literal|0
condition|)
break|break;
block|}
for|for
control|(
name|meta_hdr
operator|=
name|multilist_sublist_tail
argument_list|(
name|meta_mls
argument_list|)
init|;
name|meta_hdr
operator|!=
name|NULL
condition|;
name|meta_hdr
operator|=
name|multilist_sublist_prev
argument_list|(
name|meta_mls
argument_list|,
name|meta_hdr
argument_list|)
control|)
block|{
if|if
condition|(
name|meta_hdr
operator|->
name|b_spa
operator|!=
literal|0
condition|)
break|break;
block|}
if|if
condition|(
name|data_hdr
operator|==
name|NULL
operator|&&
name|meta_hdr
operator|==
name|NULL
condition|)
block|{
name|type
operator|=
name|ARC_BUFC_DATA
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|data_hdr
operator|==
name|NULL
condition|)
block|{
name|ASSERT3P
argument_list|(
name|meta_hdr
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|type
operator|=
name|ARC_BUFC_METADATA
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|meta_hdr
operator|==
name|NULL
condition|)
block|{
name|ASSERT3P
argument_list|(
name|data_hdr
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|type
operator|=
name|ARC_BUFC_DATA
expr_stmt|;
block|}
else|else
block|{
name|ASSERT3P
argument_list|(
name|data_hdr
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|meta_hdr
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* The headers can't be on the sublist without an L1 header */
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|data_hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|meta_hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|data_hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|<
name|meta_hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
condition|)
block|{
name|type
operator|=
name|ARC_BUFC_DATA
expr_stmt|;
block|}
else|else
block|{
name|type
operator|=
name|ARC_BUFC_METADATA
expr_stmt|;
block|}
block|}
name|multilist_sublist_unlock
argument_list|(
name|meta_mls
argument_list|)
expr_stmt|;
name|multilist_sublist_unlock
argument_list|(
name|data_mls
argument_list|)
expr_stmt|;
return|return
operator|(
name|type
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict buffers from the cache, such that arc_size is capped by arc_c.  */
end_comment

begin_function
specifier|static
name|uint64_t
name|arc_adjust
parameter_list|(
name|void
parameter_list|)
block|{
name|uint64_t
name|total_evicted
init|=
literal|0
decl_stmt|;
name|uint64_t
name|bytes
decl_stmt|;
name|int64_t
name|target
decl_stmt|;
comment|/* 	 * If we're over arc_meta_limit, we want to correct that before 	 * potentially evicting data buffers below. 	 */
name|total_evicted
operator|+=
name|arc_adjust_meta
argument_list|()
expr_stmt|;
comment|/* 	 * Adjust MRU size 	 * 	 * If we're over the target cache size, we want to evict enough 	 * from the list to get back to our target size. We don't want 	 * to evict too much from the MRU, such that it drops below 	 * arc_p. So, if we're over our target cache size more than 	 * the MRU is over arc_p, we'll evict enough to get back to 	 * arc_p here, and then evict more from the MFU below. 	 */
name|target
operator|=
name|MIN
argument_list|(
call|(
name|int64_t
call|)
argument_list|(
name|arc_size
operator|-
name|arc_c
argument_list|)
argument_list|,
call|(
name|int64_t
call|)
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
operator|+
name|refcount_count
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
operator|+
name|arc_meta_used
operator|-
name|arc_p
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * If we're below arc_meta_min, always prefer to evict data. 	 * Otherwise, try to satisfy the requested number of bytes to 	 * evict from the type which contains older buffers; in an 	 * effort to keep newer buffers in the cache regardless of their 	 * type. If we cannot satisfy the number of bytes from this 	 * type, spill over into the next type. 	 */
if|if
condition|(
name|arc_adjust_type
argument_list|(
name|arc_mru
argument_list|)
operator|==
name|ARC_BUFC_METADATA
operator|&&
name|arc_meta_used
operator|>
name|arc_meta_min
condition|)
block|{
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mru
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
comment|/* 		 * If we couldn't evict our target number of bytes from 		 * metadata, we try to get the rest from data. 		 */
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mru
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mru
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
comment|/* 		 * If we couldn't evict our target number of bytes from 		 * data, we try to get the rest from metadata. 		 */
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mru
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Adjust MFU size 	 * 	 * Now that we've tried to evict enough from the MRU to get its 	 * size back to arc_p, if we're still above the target cache 	 * size, we evict the rest from the MFU. 	 */
name|target
operator|=
name|arc_size
operator|-
name|arc_c
expr_stmt|;
if|if
condition|(
name|arc_adjust_type
argument_list|(
name|arc_mfu
argument_list|)
operator|==
name|ARC_BUFC_METADATA
operator|&&
name|arc_meta_used
operator|>
name|arc_meta_min
condition|)
block|{
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mfu
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
comment|/* 		 * If we couldn't evict our target number of bytes from 		 * metadata, we try to get the rest from data. 		 */
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mfu
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mfu
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
comment|/* 		 * If we couldn't evict our target number of bytes from 		 * data, we try to get the rest from data. 		 */
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mfu
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Adjust ghost lists 	 * 	 * In addition to the above, the ARC also defines target values 	 * for the ghost lists. The sum of the mru list and mru ghost 	 * list should never exceed the target size of the cache, and 	 * the sum of the mru list, mfu list, mru ghost list, and mfu 	 * ghost list should never exceed twice the target size of the 	 * cache. The following logic enforces these limits on the ghost 	 * caches, and evicts from them as needed. 	 */
name|target
operator|=
name|refcount_count
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
operator|+
name|refcount_count
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_size
argument_list|)
operator|-
name|arc_c
expr_stmt|;
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mru_ghost
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mru_ghost
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
comment|/* 	 * We assume the sum of the mru list and mfu list is less than 	 * or equal to arc_c (we enforced this above), which means we 	 * can use the simpler of the two equations below: 	 * 	 *	mru + mfu + mru ghost + mfu ghost<= 2 * arc_c 	 *		    mru ghost + mfu ghost<= arc_c 	 */
name|target
operator|=
name|refcount_count
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_size
argument_list|)
operator|+
name|refcount_count
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_size
argument_list|)
operator|-
name|arc_c
expr_stmt|;
name|bytes
operator|=
name|arc_adjust_impl
argument_list|(
name|arc_mfu_ghost
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|total_evicted
operator|+=
name|bytes
expr_stmt|;
name|target
operator|-=
name|bytes
expr_stmt|;
name|total_evicted
operator|+=
name|arc_adjust_impl
argument_list|(
name|arc_mfu_ghost
argument_list|,
literal|0
argument_list|,
name|target
argument_list|,
name|ARC_BUFC_METADATA
argument_list|)
expr_stmt|;
return|return
operator|(
name|total_evicted
operator|)
return|;
block|}
end_function

begin_function
name|void
name|arc_flush
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|boolean_t
name|retry
parameter_list|)
block|{
name|uint64_t
name|guid
init|=
literal|0
decl_stmt|;
comment|/* 	 * If retry is B_TRUE, a spa must not be specified since we have 	 * no good way to determine if all of a spa's buffers have been 	 * evicted from an arc state. 	 */
name|ASSERT
argument_list|(
operator|!
name|retry
operator|||
name|spa
operator|==
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|spa
operator|!=
name|NULL
condition|)
name|guid
operator|=
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mru
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_DATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mru
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_METADATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mfu
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_DATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mfu
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_METADATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mru_ghost
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_DATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mru_ghost
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_METADATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mfu_ghost
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_DATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_flush_state
argument_list|(
name|arc_mfu_ghost
argument_list|,
name|guid
argument_list|,
name|ARC_BUFC_METADATA
argument_list|,
name|retry
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|arc_shrink
parameter_list|(
name|int64_t
name|to_free
parameter_list|)
block|{
if|if
condition|(
name|arc_c
operator|>
name|arc_c_min
condition|)
block|{
name|DTRACE_PROBE4
argument_list|(
name|arc__shrink
argument_list|,
name|uint64_t
argument_list|,
name|arc_c
argument_list|,
name|uint64_t
argument_list|,
name|arc_c_min
argument_list|,
name|uint64_t
argument_list|,
name|arc_p
argument_list|,
name|uint64_t
argument_list|,
name|to_free
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_c
operator|>
name|arc_c_min
operator|+
name|to_free
condition|)
name|atomic_add_64
argument_list|(
operator|&
name|arc_c
argument_list|,
operator|-
name|to_free
argument_list|)
expr_stmt|;
else|else
name|arc_c
operator|=
name|arc_c_min
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_p
argument_list|,
operator|-
operator|(
name|arc_p
operator|>>
name|arc_shrink_shift
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_c
operator|>
name|arc_size
condition|)
name|arc_c
operator|=
name|MAX
argument_list|(
name|arc_size
argument_list|,
name|arc_c_min
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_p
operator|>
name|arc_c
condition|)
name|arc_p
operator|=
operator|(
name|arc_c
operator|>>
literal|1
operator|)
expr_stmt|;
name|DTRACE_PROBE2
argument_list|(
name|arc__shrunk
argument_list|,
name|uint64_t
argument_list|,
name|arc_c
argument_list|,
name|uint64_t
argument_list|,
name|arc_p
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|arc_c
operator|>=
name|arc_c_min
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|(
name|int64_t
operator|)
name|arc_p
operator|>=
literal|0
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|arc_size
operator|>
name|arc_c
condition|)
block|{
name|DTRACE_PROBE2
argument_list|(
name|arc__shrink_adjust
argument_list|,
name|uint64_t
argument_list|,
name|arc_size
argument_list|,
name|uint64_t
argument_list|,
name|arc_c
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|arc_adjust
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_decl_stmt
specifier|static
name|long
name|needfree
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_typedef
typedef|typedef
enum|enum
name|free_memory_reason_t
block|{
name|FMR_UNKNOWN
block|,
name|FMR_NEEDFREE
block|,
name|FMR_LOTSFREE
block|,
name|FMR_SWAPFS_MINFREE
block|,
name|FMR_PAGES_PP_MAXIMUM
block|,
name|FMR_HEAP_ARENA
block|,
name|FMR_ZIO_ARENA
block|,
name|FMR_ZIO_FRAG
block|, }
name|free_memory_reason_t
typedef|;
end_typedef

begin_decl_stmt
name|int64_t
name|last_free_memory
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|free_memory_reason_t
name|last_free_reason
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Additional reserve of pages for pp_reserve.  */
end_comment

begin_decl_stmt
name|int64_t
name|arc_pages_pp_reserve
init|=
literal|64
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Additional reserve of pages for swapfs.  */
end_comment

begin_decl_stmt
name|int64_t
name|arc_swapfs_reserve
init|=
literal|64
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Return the amount of memory that can be consumed before reclaim will be  * needed.  Positive if there is sufficient free memory, negative indicates  * the amount of memory that needs to be freed up.  */
end_comment

begin_function
specifier|static
name|int64_t
name|arc_available_memory
parameter_list|(
name|void
parameter_list|)
block|{
name|int64_t
name|lowest
init|=
name|INT64_MAX
decl_stmt|;
name|int64_t
name|n
decl_stmt|;
name|free_memory_reason_t
name|r
init|=
name|FMR_UNKNOWN
decl_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
if|if
condition|(
name|needfree
operator|>
literal|0
condition|)
block|{
name|n
operator|=
name|PAGESIZE
operator|*
operator|(
operator|-
name|needfree
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_NEEDFREE
expr_stmt|;
block|}
block|}
comment|/* 	 * Cooperate with pagedaemon when it's time for it to scan 	 * and reclaim some pages. 	 */
name|n
operator|=
name|PAGESIZE
operator|*
operator|(
operator|(
name|int64_t
operator|)
name|freemem
operator|-
name|zfs_arc_free_target
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_LOTSFREE
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|illumos
comment|/* 	 * check that we're out of range of the pageout scanner.  It starts to 	 * schedule paging if freemem is less than lotsfree and needfree. 	 * lotsfree is the high-water mark for pageout, and needfree is the 	 * number of needed free pages.  We add extra pages here to make sure 	 * the scanner doesn't start up while we're freeing memory. 	 */
name|n
operator|=
name|PAGESIZE
operator|*
operator|(
name|freemem
operator|-
name|lotsfree
operator|-
name|needfree
operator|-
name|desfree
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_LOTSFREE
expr_stmt|;
block|}
comment|/* 	 * check to make sure that swapfs has enough space so that anon 	 * reservations can still succeed. anon_resvmem() checks that the 	 * availrmem is greater than swapfs_minfree, and the number of reserved 	 * swap pages.  We also add a bit of extra here just to prevent 	 * circumstances from getting really dire. 	 */
name|n
operator|=
name|PAGESIZE
operator|*
operator|(
name|availrmem
operator|-
name|swapfs_minfree
operator|-
name|swapfs_reserve
operator|-
name|desfree
operator|-
name|arc_swapfs_reserve
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_SWAPFS_MINFREE
expr_stmt|;
block|}
comment|/* 	 * Check that we have enough availrmem that memory locking (e.g., via 	 * mlock(3C) or memcntl(2)) can still succeed.  (pages_pp_maximum 	 * stores the number of pages that cannot be locked; when availrmem 	 * drops below pages_pp_maximum, page locking mechanisms such as 	 * page_pp_lock() will fail.) 	 */
name|n
operator|=
name|PAGESIZE
operator|*
operator|(
name|availrmem
operator|-
name|pages_pp_maximum
operator|-
name|arc_pages_pp_reserve
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_PAGES_PP_MAXIMUM
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* illumos */
if|#
directive|if
name|defined
argument_list|(
name|__i386
argument_list|)
operator|||
operator|!
name|defined
argument_list|(
name|UMA_MD_SMALL_ALLOC
argument_list|)
comment|/* 	 * If we're on an i386 platform, it's possible that we'll exhaust the 	 * kernel heap space before we ever run out of available physical 	 * memory.  Most checks of the size of the heap_area compare against 	 * tune.t_minarmem, which is the minimum available real memory that we 	 * can have in the system.  However, this is generally fixed at 25 pages 	 * which is so low that it's useless.  In this comparison, we seek to 	 * calculate the total heap-size, and reclaim if more than 3/4ths of the 	 * heap is allocated.  (Or, in the calculation, if less than 1/4th is 	 * free) 	 */
name|n
operator|=
operator|(
name|int64_t
operator|)
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_FREE
argument_list|)
operator|-
operator|(
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_FREE
operator||
name|VMEM_ALLOC
argument_list|)
operator|>>
literal|2
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_HEAP_ARENA
expr_stmt|;
block|}
define|#
directive|define
name|zio_arena
value|NULL
else|#
directive|else
define|#
directive|define
name|zio_arena
value|heap_arena
endif|#
directive|endif
comment|/* 	 * If zio data pages are being allocated out of a separate heap segment, 	 * then enforce that the size of available vmem for this arena remains 	 * above about 1/16th free. 	 * 	 * Note: The 1/16th arena free requirement was put in place 	 * to aggressively evict memory from the arc in order to avoid 	 * memory fragmentation issues. 	 */
if|if
condition|(
name|zio_arena
operator|!=
name|NULL
condition|)
block|{
name|n
operator|=
operator|(
name|int64_t
operator|)
name|vmem_size
argument_list|(
name|zio_arena
argument_list|,
name|VMEM_FREE
argument_list|)
operator|-
operator|(
name|vmem_size
argument_list|(
name|zio_arena
argument_list|,
name|VMEM_ALLOC
argument_list|)
operator|>>
literal|4
operator|)
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_ZIO_ARENA
expr_stmt|;
block|}
block|}
comment|/* 	 * Above limits know nothing about real level of KVA fragmentation. 	 * Start aggressive reclamation if too little sequential KVA left. 	 */
if|if
condition|(
name|lowest
operator|>
literal|0
condition|)
block|{
name|n
operator|=
operator|(
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_MAXFREE
argument_list|)
operator|<
name|SPA_MAXBLOCKSIZE
operator|)
condition|?
operator|-
operator|(
operator|(
name|int64_t
operator|)
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_ALLOC
argument_list|)
operator|>>
literal|4
operator|)
else|:
name|INT64_MAX
expr_stmt|;
if|if
condition|(
name|n
operator|<
name|lowest
condition|)
block|{
name|lowest
operator|=
name|n
expr_stmt|;
name|r
operator|=
name|FMR_ZIO_FRAG
expr_stmt|;
block|}
block|}
else|#
directive|else
comment|/* _KERNEL */
comment|/* Every 100 calls, free a small amount */
if|if
condition|(
name|spa_get_random
argument_list|(
literal|100
argument_list|)
operator|==
literal|0
condition|)
name|lowest
operator|=
operator|-
literal|1024
expr_stmt|;
endif|#
directive|endif
comment|/* _KERNEL */
name|last_free_memory
operator|=
name|lowest
expr_stmt|;
name|last_free_reason
operator|=
name|r
expr_stmt|;
name|DTRACE_PROBE2
argument_list|(
name|arc__available_memory
argument_list|,
name|int64_t
argument_list|,
name|lowest
argument_list|,
name|int
argument_list|,
name|r
argument_list|)
expr_stmt|;
return|return
operator|(
name|lowest
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Determine if the system is under memory pressure and is asking  * to reclaim memory. A return value of B_TRUE indicates that the system  * is under memory pressure and that the arc should adjust accordingly.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|arc_reclaim_needed
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
name|arc_available_memory
argument_list|()
operator|<
literal|0
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|extern
name|kmem_cache_t
modifier|*
name|zio_buf_cache
index|[]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|kmem_cache_t
modifier|*
name|zio_data_buf_cache
index|[]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|kmem_cache_t
modifier|*
name|range_seg_cache
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|__noinline
name|void
name|arc_kmem_reap_now
parameter_list|(
name|void
parameter_list|)
block|{
name|size_t
name|i
decl_stmt|;
name|kmem_cache_t
modifier|*
name|prev_cache
init|=
name|NULL
decl_stmt|;
name|kmem_cache_t
modifier|*
name|prev_data_cache
init|=
name|NULL
decl_stmt|;
name|DTRACE_PROBE
argument_list|(
name|arc__kmem_reap_start
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
if|if
condition|(
name|arc_meta_used
operator|>=
name|arc_meta_limit
condition|)
block|{
comment|/* 		 * We are exceeding our meta-data cache limit. 		 * Purge some DNLC entries to release holds on meta-data. 		 */
name|dnlc_reduce_cache
argument_list|(
operator|(
name|void
operator|*
operator|)
operator|(
name|uintptr_t
operator|)
name|arc_reduce_dnlc_percent
argument_list|)
expr_stmt|;
block|}
if|#
directive|if
name|defined
argument_list|(
name|__i386
argument_list|)
comment|/* 	 * Reclaim unused memory from all kmem caches. 	 */
name|kmem_reap
argument_list|()
expr_stmt|;
endif|#
directive|endif
endif|#
directive|endif
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|SPA_MAXBLOCKSIZE
operator|>>
name|SPA_MINBLOCKSHIFT
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|zio_buf_cache
index|[
name|i
index|]
operator|!=
name|prev_cache
condition|)
block|{
name|prev_cache
operator|=
name|zio_buf_cache
index|[
name|i
index|]
expr_stmt|;
name|kmem_cache_reap_now
argument_list|(
name|zio_buf_cache
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|zio_data_buf_cache
index|[
name|i
index|]
operator|!=
name|prev_data_cache
condition|)
block|{
name|prev_data_cache
operator|=
name|zio_data_buf_cache
index|[
name|i
index|]
expr_stmt|;
name|kmem_cache_reap_now
argument_list|(
name|zio_data_buf_cache
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
name|kmem_cache_reap_now
argument_list|(
name|buf_cache
argument_list|)
expr_stmt|;
name|kmem_cache_reap_now
argument_list|(
name|hdr_full_cache
argument_list|)
expr_stmt|;
name|kmem_cache_reap_now
argument_list|(
name|hdr_l2only_cache
argument_list|)
expr_stmt|;
name|kmem_cache_reap_now
argument_list|(
name|range_seg_cache
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
if|if
condition|(
name|zio_arena
operator|!=
name|NULL
condition|)
block|{
comment|/* 		 * Ask the vmem arena to reclaim unused memory from its 		 * quantum caches. 		 */
name|vmem_qcache_reap
argument_list|(
name|zio_arena
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|DTRACE_PROBE
argument_list|(
name|arc__kmem_reap_end
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Threads can block in arc_get_data_buf() waiting for this thread to evict  * enough data and signal them to proceed. When this happens, the threads in  * arc_get_data_buf() are sleeping while holding the hash lock for their  * particular arc header. Thus, we must be careful to never sleep on a  * hash lock in this thread. This is to prevent the following deadlock:  *  *  - Thread A sleeps on CV in arc_get_data_buf() holding hash lock "L",  *    waiting for the reclaim thread to signal it.  *  *  - arc_reclaim_thread() tries to acquire hash lock "L" using mutex_enter,  *    fails, and goes to sleep forever.  *  * This possible deadlock is avoided by always acquiring a hash lock  * using mutex_tryenter() from arc_reclaim_thread().  */
end_comment

begin_function
specifier|static
name|void
name|arc_reclaim_thread
parameter_list|(
name|void
modifier|*
name|dummy
name|__unused
parameter_list|)
block|{
name|hrtime_t
name|growtime
init|=
literal|0
decl_stmt|;
name|callb_cpr_t
name|cpr
decl_stmt|;
name|CALLB_CPR_INIT
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|,
name|callb_generic_cpr
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
while|while
condition|(
operator|!
name|arc_reclaim_thread_exit
condition|)
block|{
name|uint64_t
name|evicted
init|=
literal|0
decl_stmt|;
comment|/* 		 * This is necessary in order for the mdb ::arc dcmd to 		 * show up to date information. Since the ::arc command 		 * does not call the kstat's update function, without 		 * this call, the command may show stale stats for the 		 * anon, mru, mru_ghost, mfu, and mfu_ghost lists. Even 		 * with this change, the data might be up to 1 second 		 * out of date; but that should suffice. The arc_state_t 		 * structures can be queried directly if more accurate 		 * information is needed. 		 */
if|if
condition|(
name|arc_ksp
operator|!=
name|NULL
condition|)
name|arc_ksp
operator|->
name|ks_update
argument_list|(
name|arc_ksp
argument_list|,
name|KSTAT_READ
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
comment|/* 		 * We call arc_adjust() before (possibly) calling 		 * arc_kmem_reap_now(), so that we can wake up 		 * arc_get_data_buf() sooner. 		 */
name|evicted
operator|=
name|arc_adjust
argument_list|()
expr_stmt|;
name|int64_t
name|free_memory
init|=
name|arc_available_memory
argument_list|()
decl_stmt|;
if|if
condition|(
name|free_memory
operator|<
literal|0
condition|)
block|{
name|arc_no_grow
operator|=
name|B_TRUE
expr_stmt|;
name|arc_warm
operator|=
name|B_TRUE
expr_stmt|;
comment|/* 			 * Wait at least zfs_grow_retry (default 60) seconds 			 * before considering growing. 			 */
name|growtime
operator|=
name|gethrtime
argument_list|()
operator|+
name|SEC2NSEC
argument_list|(
name|arc_grow_retry
argument_list|)
expr_stmt|;
name|arc_kmem_reap_now
argument_list|()
expr_stmt|;
comment|/* 			 * If we are still low on memory, shrink the ARC 			 * so that we have arc_shrink_min free space. 			 */
name|free_memory
operator|=
name|arc_available_memory
argument_list|()
expr_stmt|;
name|int64_t
name|to_free
init|=
operator|(
name|arc_c
operator|>>
name|arc_shrink_shift
operator|)
operator|-
name|free_memory
decl_stmt|;
if|if
condition|(
name|to_free
operator|>
literal|0
condition|)
block|{
ifdef|#
directive|ifdef
name|_KERNEL
name|to_free
operator|=
name|MAX
argument_list|(
name|to_free
argument_list|,
name|ptob
argument_list|(
name|needfree
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|arc_shrink
argument_list|(
name|to_free
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|free_memory
operator|<
name|arc_c
operator|>>
name|arc_no_grow_shift
condition|)
block|{
name|arc_no_grow
operator|=
name|B_TRUE
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|gethrtime
argument_list|()
operator|>=
name|growtime
condition|)
block|{
name|arc_no_grow
operator|=
name|B_FALSE
expr_stmt|;
block|}
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
comment|/* 		 * If evicted is zero, we couldn't evict anything via 		 * arc_adjust(). This could be due to hash lock 		 * collisions, but more likely due to the majority of 		 * arc buffers being unevictable. Therefore, even if 		 * arc_size is above arc_c, another pass is unlikely to 		 * be helpful and could potentially cause us to enter an 		 * infinite loop. 		 */
if|if
condition|(
name|arc_size
operator|<=
name|arc_c
operator|||
name|evicted
operator|==
literal|0
condition|)
block|{
ifdef|#
directive|ifdef
name|_KERNEL
name|needfree
operator|=
literal|0
expr_stmt|;
endif|#
directive|endif
comment|/* 			 * We're either no longer overflowing, or we 			 * can't evict anything more, so we should wake 			 * up any threads before we go to sleep. 			 */
name|cv_broadcast
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|)
expr_stmt|;
comment|/* 			 * Block until signaled, or after one second (we 			 * might need to perform arc_kmem_reap_now() 			 * even if we aren't being signalled) 			 */
name|CALLB_CPR_SAFE_BEGIN
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|cv_timedwait_hires
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|,
name|SEC2NSEC
argument_list|(
literal|1
argument_list|)
argument_list|,
name|MSEC2NSEC
argument_list|(
literal|1
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|CALLB_CPR_SAFE_END
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
block|}
name|arc_reclaim_thread_exit
operator|=
name|B_FALSE
expr_stmt|;
name|cv_broadcast
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
name|CALLB_CPR_EXIT
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
comment|/* drops arc_reclaim_lock */
name|thread_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_decl_stmt
specifier|static
name|u_int
name|arc_dnlc_evicts_arg
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|struct
name|vfsops
name|zfs_vfsops
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|void
name|arc_dnlc_evicts_thread
parameter_list|(
name|void
modifier|*
name|dummy
name|__unused
parameter_list|)
block|{
name|callb_cpr_t
name|cpr
decl_stmt|;
name|u_int
name|percent
decl_stmt|;
name|CALLB_CPR_INIT
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|arc_dnlc_evicts_lock
argument_list|,
name|callb_generic_cpr
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
while|while
condition|(
operator|!
name|arc_dnlc_evicts_thread_exit
condition|)
block|{
name|CALLB_CPR_SAFE_BEGIN
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|cv_wait
argument_list|(
operator|&
name|arc_dnlc_evicts_cv
argument_list|,
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
name|CALLB_CPR_SAFE_END
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_dnlc_evicts_arg
operator|!=
literal|0
condition|)
block|{
name|percent
operator|=
name|arc_dnlc_evicts_arg
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
name|vnlru_free
argument_list|(
name|desiredvnodes
operator|*
name|percent
operator|/
literal|100
argument_list|,
operator|&
name|zfs_vfsops
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|mutex_enter
argument_list|(
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
comment|/* 			 * Clear our token only after vnlru_free() 			 * pass is done, to avoid false queueing of 			 * the requests. 			 */
name|arc_dnlc_evicts_arg
operator|=
literal|0
expr_stmt|;
block|}
block|}
name|arc_dnlc_evicts_thread_exit
operator|=
name|FALSE
expr_stmt|;
name|cv_broadcast
argument_list|(
operator|&
name|arc_dnlc_evicts_cv
argument_list|)
expr_stmt|;
name|CALLB_CPR_EXIT
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
name|thread_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|dnlc_reduce_cache
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|u_int
name|percent
decl_stmt|;
name|percent
operator|=
operator|(
name|u_int
operator|)
operator|(
name|uintptr_t
operator|)
name|arg
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_dnlc_evicts_arg
operator|==
literal|0
condition|)
block|{
name|arc_dnlc_evicts_arg
operator|=
name|percent
expr_stmt|;
name|cv_broadcast
argument_list|(
operator|&
name|arc_dnlc_evicts_cv
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Adapt arc info given the number of bytes we are trying to add and  * the state that we are comming from.  This function is only called  * when we are adding new content to the cache.  */
end_comment

begin_function
specifier|static
name|void
name|arc_adapt
parameter_list|(
name|int
name|bytes
parameter_list|,
name|arc_state_t
modifier|*
name|state
parameter_list|)
block|{
name|int
name|mult
decl_stmt|;
name|uint64_t
name|arc_p_min
init|=
operator|(
name|arc_c
operator|>>
name|arc_p_min_shift
operator|)
decl_stmt|;
name|int64_t
name|mrug_size
init|=
name|refcount_count
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_size
argument_list|)
decl_stmt|;
name|int64_t
name|mfug_size
init|=
name|refcount_count
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_size
argument_list|)
decl_stmt|;
if|if
condition|(
name|state
operator|==
name|arc_l2c_only
condition|)
return|return;
name|ASSERT
argument_list|(
name|bytes
operator|>
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * Adapt the target size of the MRU list: 	 *	- if we just hit in the MRU ghost list, then increase 	 *	  the target size of the MRU list. 	 *	- if we just hit in the MFU ghost list, then increase 	 *	  the target size of the MFU list by decreasing the 	 *	  target size of the MRU list. 	 */
if|if
condition|(
name|state
operator|==
name|arc_mru_ghost
condition|)
block|{
name|mult
operator|=
operator|(
name|mrug_size
operator|>=
name|mfug_size
operator|)
condition|?
literal|1
else|:
operator|(
name|mfug_size
operator|/
name|mrug_size
operator|)
expr_stmt|;
name|mult
operator|=
name|MIN
argument_list|(
name|mult
argument_list|,
literal|10
argument_list|)
expr_stmt|;
comment|/* avoid wild arc_p adjustment */
name|arc_p
operator|=
name|MIN
argument_list|(
name|arc_c
operator|-
name|arc_p_min
argument_list|,
name|arc_p
operator|+
name|bytes
operator|*
name|mult
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|state
operator|==
name|arc_mfu_ghost
condition|)
block|{
name|uint64_t
name|delta
decl_stmt|;
name|mult
operator|=
operator|(
name|mfug_size
operator|>=
name|mrug_size
operator|)
condition|?
literal|1
else|:
operator|(
name|mrug_size
operator|/
name|mfug_size
operator|)
expr_stmt|;
name|mult
operator|=
name|MIN
argument_list|(
name|mult
argument_list|,
literal|10
argument_list|)
expr_stmt|;
name|delta
operator|=
name|MIN
argument_list|(
name|bytes
operator|*
name|mult
argument_list|,
name|arc_p
argument_list|)
expr_stmt|;
name|arc_p
operator|=
name|MAX
argument_list|(
name|arc_p_min
argument_list|,
name|arc_p
operator|-
name|delta
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
operator|(
name|int64_t
operator|)
name|arc_p
operator|>=
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_reclaim_needed
argument_list|()
condition|)
block|{
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|arc_no_grow
condition|)
return|return;
if|if
condition|(
name|arc_c
operator|>=
name|arc_c_max
condition|)
return|return;
comment|/* 	 * If we're within (2 * maxblocksize) bytes of the target 	 * cache size, increment the target cache size 	 */
if|if
condition|(
name|arc_size
operator|>
name|arc_c
operator|-
operator|(
literal|2ULL
operator|<<
name|SPA_MAXBLOCKSHIFT
operator|)
condition|)
block|{
name|DTRACE_PROBE1
argument_list|(
name|arc__inc_adapt
argument_list|,
name|int
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|atomic_add_64
argument_list|(
operator|&
name|arc_c
argument_list|,
operator|(
name|int64_t
operator|)
name|bytes
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_c
operator|>
name|arc_c_max
condition|)
name|arc_c
operator|=
name|arc_c_max
expr_stmt|;
elseif|else
if|if
condition|(
name|state
operator|==
name|arc_anon
condition|)
name|atomic_add_64
argument_list|(
operator|&
name|arc_p
argument_list|,
operator|(
name|int64_t
operator|)
name|bytes
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_p
operator|>
name|arc_c
condition|)
name|arc_p
operator|=
name|arc_c
expr_stmt|;
block|}
name|ASSERT
argument_list|(
operator|(
name|int64_t
operator|)
name|arc_p
operator|>=
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Check if arc_size has grown past our upper threshold, determined by  * zfs_arc_overflow_shift.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|arc_is_overflowing
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* Always allow at least one block of overflow */
name|uint64_t
name|overflow
init|=
name|MAX
argument_list|(
name|SPA_MAXBLOCKSIZE
argument_list|,
name|arc_c
operator|>>
name|zfs_arc_overflow_shift
argument_list|)
decl_stmt|;
return|return
operator|(
name|arc_size
operator|>=
name|arc_c
operator|+
name|overflow
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Allocate a block and return it to the caller. If we are hitting the  * hard limit for the cache size, we must sleep, waiting for the eviction  * thread to catch up. If we're past the target size but below the hard  * limit, we'll only signal the reclaim thread and continue on.  */
end_comment

begin_function
specifier|static
name|void
modifier|*
name|arc_get_data_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|uint64_t
name|size
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|void
modifier|*
name|datap
init|=
name|NULL
decl_stmt|;
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|arc_adapt
argument_list|(
name|size
argument_list|,
name|state
argument_list|)
expr_stmt|;
comment|/* 	 * If arc_size is currently overflowing, and has grown past our 	 * upper limit, we must be adding data faster than the evict 	 * thread can evict. Thus, to ensure we don't compound the 	 * problem by adding more data and forcing arc_size to grow even 	 * further past it's target size, we halt and wait for the 	 * eviction thread to catch up. 	 * 	 * It's also possible that the reclaim thread is unable to evict 	 * enough buffers to get arc_size below the overflow limit (e.g. 	 * due to buffers being un-evictable, or hash lock collisions). 	 * In this case, we want to proceed regardless if we're 	 * overflowing; thus we don't use a while loop here. 	 */
if|if
condition|(
name|arc_is_overflowing
argument_list|()
condition|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
comment|/* 		 * Now that we've acquired the lock, we may no longer be 		 * over the overflow limit, lets check. 		 * 		 * We're ignoring the case of spurious wake ups. If that 		 * were to happen, it'd let this thread consume an ARC 		 * buffer before it should have (i.e. before we're under 		 * the overflow limit and were signalled by the reclaim 		 * thread). As long as that is a rare occurrence, it 		 * shouldn't cause any harm. 		 */
if|if
condition|(
name|arc_is_overflowing
argument_list|()
condition|)
block|{
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
name|cv_wait
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
name|VERIFY3U
argument_list|(
name|hdr
operator|->
name|b_type
argument_list|,
operator|==
argument_list|,
name|type
argument_list|)
expr_stmt|;
if|if
condition|(
name|type
operator|==
name|ARC_BUFC_METADATA
condition|)
block|{
name|datap
operator|=
name|zio_buf_alloc
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|arc_space_consume
argument_list|(
name|size
argument_list|,
name|ARC_SPACE_META
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|type
operator|==
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|datap
operator|=
name|zio_data_buf_alloc
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|arc_space_consume
argument_list|(
name|size
argument_list|,
name|ARC_SPACE_DATA
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Update the state size.  Note that ghost states have a 	 * "ghost size" and so don't need to be updated. 	 */
if|if
condition|(
operator|!
name|GHOST_STATE
argument_list|(
name|state
argument_list|)
condition|)
block|{
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|,
name|size
argument_list|,
name|tag
argument_list|)
expr_stmt|;
comment|/* 		 * If this is reached via arc_read, the link is 		 * protected by the hash lock. If reached via 		 * arc_buf_alloc, the header should not be accessed by 		 * any other thread. And, if reached via arc_read_done, 		 * the hash lock will protect it if it's found in the 		 * hash table; otherwise no other thread should be 		 * trying to [add|remove]_reference it. 		 */
if|if
condition|(
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|,
name|size
argument_list|,
name|tag
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * If we are growing the cache, and we are adding anonymous 		 * data, and we have outgrown arc_p, update arc_p 		 */
if|if
condition|(
name|arc_size
operator|<
name|arc_c
operator|&&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
operator|&&
operator|(
name|refcount_count
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
operator|+
name|refcount_count
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
operator|>
name|arc_p
operator|)
condition|)
name|arc_p
operator|=
name|MIN
argument_list|(
name|arc_c
argument_list|,
name|arc_p
operator|+
name|size
argument_list|)
expr_stmt|;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_allocated
argument_list|)
expr_stmt|;
return|return
operator|(
name|datap
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Free the arc data buffer.  */
end_comment

begin_function
specifier|static
name|void
name|arc_free_data_buf
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|void
modifier|*
name|data
parameter_list|,
name|uint64_t
name|size
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
comment|/* protected by hash lock, if in the hash table */
if|if
condition|(
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|state
operator|!=
name|arc_anon
operator|&&
name|state
operator|!=
name|arc_l2c_only
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|,
name|size
argument_list|,
name|tag
argument_list|)
expr_stmt|;
block|}
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|,
name|size
argument_list|,
name|tag
argument_list|)
expr_stmt|;
name|VERIFY3U
argument_list|(
name|hdr
operator|->
name|b_type
argument_list|,
operator|==
argument_list|,
name|type
argument_list|)
expr_stmt|;
if|if
condition|(
name|type
operator|==
name|ARC_BUFC_METADATA
condition|)
block|{
name|zio_buf_free
argument_list|(
name|data
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
name|size
argument_list|,
name|ARC_SPACE_META
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|type
operator|==
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|zio_data_buf_free
argument_list|(
name|data
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|arc_space_return
argument_list|(
name|size
argument_list|,
name|ARC_SPACE_DATA
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * This routine is called whenever a buffer is accessed.  * NOTE: the hash lock is dropped in this function.  */
end_comment

begin_function
specifier|static
name|void
name|arc_access
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|kmutex_t
modifier|*
name|hash_lock
parameter_list|)
block|{
name|clock_t
name|now
decl_stmt|;
name|ASSERT
argument_list|(
name|MUTEX_HELD
argument_list|(
name|hash_lock
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
condition|)
block|{
comment|/* 		 * This buffer is not in the cache, and does not 		 * appear in our "ghost" list.  Add the new buffer 		 * to the MRU state. 		 */
name|ASSERT0
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mru
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|arc_mru
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mru
condition|)
block|{
name|now
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
comment|/* 		 * If this buffer is here because of a prefetch, then either: 		 * - clear the flag if this is a "referencing" read 		 *   (any subsequent access will bump this into the MFU state). 		 * or 		 * - move the buffer to the head of the list if this is 		 *   another prefetch (to make it less likely to be evicted). 		 */
if|if
condition|(
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
if|if
condition|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|==
literal|0
condition|)
block|{
comment|/* link protected by hash lock */
name|ASSERT
argument_list|(
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_PREFETCH
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mru_hits
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|now
expr_stmt|;
return|return;
block|}
comment|/* 		 * This buffer has been "accessed" only once so far, 		 * but it is still in the cache. Move it to the MFU 		 * state. 		 */
if|if
condition|(
name|now
operator|>
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|+
name|ARC_MINTIME
condition|)
block|{
comment|/* 			 * More than 125ms have passed since we 			 * instantiated this buffer.  Move it to the 			 * most frequently used state. 			 */
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|now
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mfu
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|arc_mfu
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mru_hits
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mru_ghost
condition|)
block|{
name|arc_state_t
modifier|*
name|new_state
decl_stmt|;
comment|/* 		 * This buffer has been "accessed" recently, but 		 * was evicted from the cache.  Move it to the 		 * MFU state. 		 */
if|if
condition|(
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|new_state
operator|=
name|arc_mru
expr_stmt|;
if|if
condition|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|>
literal|0
condition|)
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_PREFETCH
argument_list|)
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mru
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|new_state
operator|=
name|arc_mfu
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mfu
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
name|arc_change_state
argument_list|(
name|new_state
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mru_ghost_hits
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mfu
condition|)
block|{
comment|/* 		 * This buffer has been accessed more than once and is 		 * still in the cache.  Keep it in the MFU state. 		 * 		 * NOTE: an add_reference() that occurred when we did 		 * the arc_read() will have kicked this off the list. 		 * If it was a prefetch, we will explicitly move it to 		 * the head of the list now. 		 */
if|if
condition|(
operator|(
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
comment|/* link protected by hash_lock */
name|ASSERT
argument_list|(
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mfu_hits
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mfu_ghost
condition|)
block|{
name|arc_state_t
modifier|*
name|new_state
init|=
name|arc_mfu
decl_stmt|;
comment|/* 		 * This buffer has been accessed more than once but has 		 * been evicted from the cache.  Move it back to the 		 * MFU state. 		 */
if|if
condition|(
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
comment|/* 			 * This is a prefetch access... 			 * move this block back to the MRU state. 			 */
name|ASSERT0
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|new_state
operator|=
name|arc_mru
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mfu
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|new_state
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_mfu_ghost_hits
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_l2c_only
condition|)
block|{
comment|/* 		 * This buffer is on the 2nd Level ARC. 		 */
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|new_state__mfu
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|arc_mfu
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
operator|!
literal|"invalid arc state"
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/* a generic arc_done_func_t which you can use */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
name|void
name|arc_bcopy_func
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|,
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|arg
parameter_list|)
block|{
if|if
condition|(
name|zio
operator|==
name|NULL
operator|||
name|zio
operator|->
name|io_error
operator|==
literal|0
condition|)
name|bcopy
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|arg
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|arc_buf_destroy
argument_list|(
name|buf
argument_list|,
name|arg
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* a generic arc_done_func_t */
end_comment

begin_function
name|void
name|arc_getbuf_func
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|,
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|arc_buf_t
modifier|*
modifier|*
name|bufp
init|=
name|arg
decl_stmt|;
if|if
condition|(
name|zio
operator|&&
name|zio
operator|->
name|io_error
condition|)
block|{
name|arc_buf_destroy
argument_list|(
name|buf
argument_list|,
name|arg
argument_list|)
expr_stmt|;
operator|*
name|bufp
operator|=
name|NULL
expr_stmt|;
block|}
else|else
block|{
operator|*
name|bufp
operator|=
name|buf
expr_stmt|;
name|ASSERT
argument_list|(
name|buf
operator|->
name|b_data
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|arc_hdr_verify
parameter_list|(
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|,
name|blkptr_t
modifier|*
name|bp
parameter_list|)
block|{
if|if
condition|(
name|BP_IS_HOLE
argument_list|(
name|bp
argument_list|)
operator|||
name|BP_IS_EMBEDDED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|ASSERT3U
argument_list|(
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|==
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|==
argument_list|,
name|ZIO_COMPRESS_OFF
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|HDR_COMPRESSION_ENABLED
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT3U
argument_list|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|==
argument_list|,
name|BP_GET_COMPRESS
argument_list|(
name|bp
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|ASSERT3U
argument_list|(
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|==
argument_list|,
name|BP_GET_LSIZE
argument_list|(
name|bp
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|==
argument_list|,
name|BP_GET_PSIZE
argument_list|(
name|bp
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|arc_read_done
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|zio
operator|->
name|io_private
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|NULL
decl_stmt|;
name|arc_callback_t
modifier|*
name|callback_list
decl_stmt|;
name|arc_callback_t
modifier|*
name|acb
decl_stmt|;
name|boolean_t
name|freeable
init|=
name|B_FALSE
decl_stmt|;
name|boolean_t
name|no_zio_error
init|=
operator|(
name|zio
operator|->
name|io_error
operator|==
literal|0
operator|)
decl_stmt|;
comment|/* 	 * The hdr was inserted into hash-table and removed from lists 	 * prior to starting I/O.  We should find this header, since 	 * it's in the hash table, and it should be legit since it's 	 * not possible to evict it during the I/O.  The only possible 	 * reason for it not to be found is if we were freed during the 	 * read. 	 */
if|if
condition|(
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_birth
argument_list|,
operator|==
argument_list|,
name|BP_PHYSICAL_BIRTH
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_dva
operator|.
name|dva_word
index|[
literal|0
index|]
argument_list|,
operator|==
argument_list|,
name|BP_IDENTITY
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|->
name|dva_word
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_dva
operator|.
name|dva_word
index|[
literal|1
index|]
argument_list|,
operator|==
argument_list|,
name|BP_IDENTITY
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|->
name|dva_word
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
name|arc_buf_hdr_t
modifier|*
name|found
init|=
name|buf_hash_find
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|,
operator|&
name|hash_lock
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|(
name|found
operator|==
name|hdr
operator|&&
name|DVA_EQUAL
argument_list|(
operator|&
name|hdr
operator|->
name|b_dva
argument_list|,
name|BP_IDENTITY
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|)
operator|)
operator|||
operator|(
name|found
operator|==
name|hdr
operator|&&
name|HDR_L2_READING
argument_list|(
name|hdr
argument_list|)
operator|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hash_lock
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|no_zio_error
condition|)
block|{
comment|/* byteswap if necessary */
if|if
condition|(
name|BP_SHOULD_BYTESWAP
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
condition|)
block|{
if|if
condition|(
name|BP_GET_LEVEL
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|>
literal|0
condition|)
block|{
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_byteswap
operator|=
name|DMU_BSWAP_UINT64
expr_stmt|;
block|}
else|else
block|{
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_byteswap
operator|=
name|DMU_OT_BYTESWAP
argument_list|(
name|BP_GET_TYPE
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_byteswap
operator|=
name|DMU_BSWAP_NUMFUNCS
expr_stmt|;
block|}
block|}
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_L2_EVICTED
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2arc_noprefetch
operator|&&
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
condition|)
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_L2CACHE
argument_list|)
expr_stmt|;
name|callback_list
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
expr_stmt|;
name|ASSERT3P
argument_list|(
name|callback_list
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|hash_lock
operator|&&
name|no_zio_error
operator|&&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
condition|)
block|{
comment|/* 		 * Only call arc_access on anonymous buffers.  This is because 		 * if we've issued an I/O for an evicted buffer, we've already 		 * called arc_access (to prevent any simultaneous readers from 		 * getting confused). 		 */
name|arc_access
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If a read request has a callback (i.e. acb_done is not NULL), then we 	 * make a buf containing the data according to the parameters which were 	 * passed in. The implementation of arc_buf_alloc_impl() ensures that we 	 * aren't needlessly decompressing the data multiple times. 	 */
name|int
name|callback_cnt
init|=
literal|0
decl_stmt|;
for|for
control|(
name|acb
operator|=
name|callback_list
init|;
name|acb
operator|!=
name|NULL
condition|;
name|acb
operator|=
name|acb
operator|->
name|acb_next
control|)
block|{
if|if
condition|(
operator|!
name|acb
operator|->
name|acb_done
condition|)
continue|continue;
comment|/* This is a demand read since prefetches don't use callbacks */
name|callback_cnt
operator|++
expr_stmt|;
name|int
name|error
init|=
name|arc_buf_alloc_impl
argument_list|(
name|hdr
argument_list|,
name|acb
operator|->
name|acb_private
argument_list|,
name|acb
operator|->
name|acb_compressed
argument_list|,
name|no_zio_error
argument_list|,
operator|&
name|acb
operator|->
name|acb_buf
argument_list|)
decl_stmt|;
if|if
condition|(
name|no_zio_error
condition|)
block|{
name|zio
operator|->
name|io_error
operator|=
name|error
expr_stmt|;
block|}
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
operator|=
name|NULL
expr_stmt|;
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_IO_IN_PROGRESS
argument_list|)
expr_stmt|;
if|if
condition|(
name|callback_cnt
operator|==
literal|0
condition|)
block|{
name|ASSERT
argument_list|(
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|||
name|callback_list
operator|!=
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|no_zio_error
condition|)
block|{
name|arc_hdr_verify
argument_list|(
name|hdr
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_IO_ERROR
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|!=
name|arc_anon
condition|)
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
condition|)
name|buf_hash_remove
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|freeable
operator|=
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Broadcast before we drop the hash_lock to avoid the possibility 	 * that the hdr (and hence the cv) might be freed before we get to 	 * the cv_broadcast(). 	 */
name|cv_broadcast
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_cv
argument_list|)
expr_stmt|;
if|if
condition|(
name|hash_lock
operator|!=
name|NULL
condition|)
block|{
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * This block was freed while we waited for the read to 		 * complete.  It has been removed from the hash table and 		 * moved to the anonymous state (so that it won't show up 		 * in the cache). 		 */
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|,
operator|==
argument_list|,
name|arc_anon
argument_list|)
expr_stmt|;
name|freeable
operator|=
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
expr_stmt|;
block|}
comment|/* execute each callback and free its structure */
while|while
condition|(
operator|(
name|acb
operator|=
name|callback_list
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|acb
operator|->
name|acb_done
condition|)
name|acb
operator|->
name|acb_done
argument_list|(
name|zio
argument_list|,
name|acb
operator|->
name|acb_buf
argument_list|,
name|acb
operator|->
name|acb_private
argument_list|)
expr_stmt|;
if|if
condition|(
name|acb
operator|->
name|acb_zio_dummy
operator|!=
name|NULL
condition|)
block|{
name|acb
operator|->
name|acb_zio_dummy
operator|->
name|io_error
operator|=
name|zio
operator|->
name|io_error
expr_stmt|;
name|zio_nowait
argument_list|(
name|acb
operator|->
name|acb_zio_dummy
argument_list|)
expr_stmt|;
block|}
name|callback_list
operator|=
name|acb
operator|->
name|acb_next
expr_stmt|;
name|kmem_free
argument_list|(
name|acb
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_callback_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|freeable
condition|)
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * "Read" the block at the specified DVA (in bp) via the  * cache.  If the block is found in the cache, invoke the provided  * callback immediately and return.  Note that the `zio' parameter  * in the callback will be NULL in this case, since no IO was  * required.  If the block is not in the cache pass the read request  * on to the spa with a substitute callback function, so that the  * requested block will be added to the cache.  *  * If a read request arrives for a block that has a read in-progress,  * either wait for the in-progress read to complete (and return the  * results); or, if this is a read with a "done" func, add a record  * to the read to invoke the "done" func when the read completes,  * and return; or just return.  *  * arc_read_done() will invoke all the requested "done" functions  * for readers of this block.  */
end_comment

begin_function
name|int
name|arc_read
parameter_list|(
name|zio_t
modifier|*
name|pio
parameter_list|,
name|spa_t
modifier|*
name|spa
parameter_list|,
specifier|const
name|blkptr_t
modifier|*
name|bp
parameter_list|,
name|arc_done_func_t
modifier|*
name|done
parameter_list|,
name|void
modifier|*
name|private
parameter_list|,
name|zio_priority_t
name|priority
parameter_list|,
name|int
name|zio_flags
parameter_list|,
name|arc_flags_t
modifier|*
name|arc_flags
parameter_list|,
specifier|const
name|zbookmark_phys_t
modifier|*
name|zb
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|NULL
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|NULL
decl_stmt|;
name|zio_t
modifier|*
name|rzio
decl_stmt|;
name|uint64_t
name|guid
init|=
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
decl_stmt|;
name|boolean_t
name|compressed_read
init|=
operator|(
name|zio_flags
operator|&
name|ZIO_FLAG_RAW
operator|)
operator|!=
literal|0
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|BP_IS_EMBEDDED
argument_list|(
name|bp
argument_list|)
operator|||
name|BPE_GET_ETYPE
argument_list|(
name|bp
argument_list|)
operator|==
name|BP_EMBEDDED_TYPE_DATA
argument_list|)
expr_stmt|;
name|top
label|:
if|if
condition|(
operator|!
name|BP_IS_EMBEDDED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
comment|/* 		 * Embedded BP's have no DVA and require no I/O to "read". 		 * Create an anonymous arc buf to back it. 		 */
name|hdr
operator|=
name|buf_hash_find
argument_list|(
name|guid
argument_list|,
name|bp
argument_list|,
operator|&
name|hash_lock
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hdr
operator|!=
name|NULL
operator|&&
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
operator|&&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|!=
name|NULL
condition|)
block|{
name|arc_buf_t
modifier|*
name|buf
init|=
name|NULL
decl_stmt|;
operator|*
name|arc_flags
operator||=
name|ARC_FLAG_CACHED
expr_stmt|;
if|if
condition|(
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
if|if
condition|(
operator|(
name|hdr
operator|->
name|b_flags
operator|&
name|ARC_FLAG_PRIO_ASYNC_READ
operator|)
operator|&&
name|priority
operator|==
name|ZIO_PRIORITY_SYNC_READ
condition|)
block|{
comment|/* 				 * This sync read must wait for an 				 * in-progress async read (e.g. a predictive 				 * prefetch).  Async reads are queued 				 * separately at the vdev_queue layer, so 				 * this is a form of priority inversion. 				 * Ideally, we would "inherit" the demand 				 * i/o's priority by moving the i/o from 				 * the async queue to the synchronous queue, 				 * but there is currently no mechanism to do 				 * so.  Track this so that we can evaluate 				 * the magnitude of this potential performance 				 * problem. 				 * 				 * Note that if the prefetch i/o is already 				 * active (has been issued to the device), 				 * the prefetch improved performance, because 				 * we issued it sooner than we would have 				 * without the prefetch. 				 */
name|DTRACE_PROBE1
argument_list|(
name|arc__sync__wait__for__async
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_sync_wait_for_async
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hdr
operator|->
name|b_flags
operator|&
name|ARC_FLAG_PREDICTIVE_PREFETCH
condition|)
block|{
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_PREDICTIVE_PREFETCH
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_WAIT
condition|)
block|{
name|cv_wait
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_cv
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
goto|goto
name|top
goto|;
block|}
name|ASSERT
argument_list|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_NOWAIT
argument_list|)
expr_stmt|;
if|if
condition|(
name|done
condition|)
block|{
name|arc_callback_t
modifier|*
name|acb
init|=
name|NULL
decl_stmt|;
name|acb
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_callback_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|acb
operator|->
name|acb_done
operator|=
name|done
expr_stmt|;
name|acb
operator|->
name|acb_private
operator|=
name|private
expr_stmt|;
name|acb
operator|->
name|acb_compressed
operator|=
name|compressed_read
expr_stmt|;
if|if
condition|(
name|pio
operator|!=
name|NULL
condition|)
name|acb
operator|->
name|acb_zio_dummy
operator|=
name|zio_null
argument_list|(
name|pio
argument_list|,
name|spa
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|zio_flags
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|acb
operator|->
name|acb_done
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|acb
operator|->
name|acb_next
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
operator|=
name|acb
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mru
operator|||
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_mfu
argument_list|)
expr_stmt|;
if|if
condition|(
name|done
condition|)
block|{
if|if
condition|(
name|hdr
operator|->
name|b_flags
operator|&
name|ARC_FLAG_PREDICTIVE_PREFETCH
condition|)
block|{
comment|/* 				 * This is a demand read which does not have to 				 * wait for i/o because we did a predictive 				 * prefetch i/o for it, which has completed. 				 */
name|DTRACE_PROBE1
argument_list|(
name|arc__demand__hit__predictive__prefetch
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_demand_hit_predictive_prefetch
argument_list|)
expr_stmt|;
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_PREDICTIVE_PREFETCH
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
operator|!
name|BP_IS_EMBEDDED
argument_list|(
name|bp
argument_list|)
operator|||
operator|!
name|BP_IS_HOLE
argument_list|(
name|bp
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Get a buf with the desired data in it. */
name|VERIFY0
argument_list|(
name|arc_buf_alloc_impl
argument_list|(
name|hdr
argument_list|,
name|private
argument_list|,
name|compressed_read
argument_list|,
name|B_TRUE
argument_list|,
operator|&
name|buf
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_PREFETCH
operator|&&
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|==
literal|0
condition|)
block|{
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_PREFETCH
argument_list|)
expr_stmt|;
block|}
name|DTRACE_PROBE1
argument_list|(
name|arc__hit
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|arc_access
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_L2CACHE
condition|)
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_L2CACHE
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_hits
argument_list|)
expr_stmt|;
name|ARCSTAT_CONDSTAT
argument_list|(
operator|!
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|demand
argument_list|,
name|prefetch
argument_list|,
operator|!
name|HDR_ISTYPE_METADATA
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|data
argument_list|,
name|metadata
argument_list|,
name|hits
argument_list|)
expr_stmt|;
if|if
condition|(
name|done
condition|)
name|done
argument_list|(
name|NULL
argument_list|,
name|buf
argument_list|,
name|private
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|uint64_t
name|lsize
init|=
name|BP_GET_LSIZE
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|uint64_t
name|psize
init|=
name|BP_GET_PSIZE
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|arc_callback_t
modifier|*
name|acb
decl_stmt|;
name|vdev_t
modifier|*
name|vd
init|=
name|NULL
decl_stmt|;
name|uint64_t
name|addr
init|=
literal|0
decl_stmt|;
name|boolean_t
name|devw
init|=
name|B_FALSE
decl_stmt|;
name|uint64_t
name|size
decl_stmt|;
if|if
condition|(
name|hdr
operator|==
name|NULL
condition|)
block|{
comment|/* this block is not in the cache */
name|arc_buf_hdr_t
modifier|*
name|exists
init|=
name|NULL
decl_stmt|;
name|arc_buf_contents_t
name|type
init|=
name|BP_GET_BUFC_TYPE
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|hdr
operator|=
name|arc_hdr_alloc
argument_list|(
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
argument_list|,
name|psize
argument_list|,
name|lsize
argument_list|,
name|BP_GET_COMPRESS
argument_list|(
name|bp
argument_list|)
argument_list|,
name|type
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|BP_IS_EMBEDDED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|hdr
operator|->
name|b_dva
operator|=
operator|*
name|BP_IDENTITY
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_birth
operator|=
name|BP_PHYSICAL_BIRTH
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|exists
operator|=
name|buf_hash_insert
argument_list|(
name|hdr
argument_list|,
operator|&
name|hash_lock
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|exists
operator|!=
name|NULL
condition|)
block|{
comment|/* somebody beat us to the hash insert */
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
goto|goto
name|top
goto|;
comment|/* restart the IO request */
block|}
block|}
else|else
block|{
comment|/* 			 * This block is in the ghost cache. If it was L2-only 			 * (and thus didn't have an L1 hdr), we realloc the 			 * header to add an L1 hdr. 			 */
if|if
condition|(
operator|!
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|hdr
operator|=
name|arc_hdr_realloc
argument_list|(
name|hdr
argument_list|,
name|hdr_l2only_cache
argument_list|,
name|hdr_full_cache
argument_list|)
expr_stmt|;
block|}
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|GHOST_STATE
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_freeze_cksum
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 			 * This is a delicate dance that we play here. 			 * This hdr is in the ghost list so we access it 			 * to move it out of the ghost list before we 			 * initiate the read. If it's a prefetch then 			 * it won't have a callback so we'll remove the 			 * reference that arc_buf_alloc_impl() created. We 			 * do this after we've called arc_access() to 			 * avoid hitting an assert in remove_reference(). 			 */
name|arc_access
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|arc_hdr_alloc_pdata
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|size
operator|=
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* 		 * If compression is enabled on the hdr, then will do 		 * RAW I/O and will store the compressed data in the hdr's 		 * data block. Otherwise, the hdr's data block will contain 		 * the uncompressed data. 		 */
if|if
condition|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
operator|!=
name|ZIO_COMPRESS_OFF
condition|)
block|{
name|zio_flags
operator||=
name|ZIO_FLAG_RAW
expr_stmt|;
block|}
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_PREFETCH
condition|)
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_PREFETCH
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_L2CACHE
condition|)
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_L2CACHE
argument_list|)
expr_stmt|;
if|if
condition|(
name|BP_GET_LEVEL
argument_list|(
name|bp
argument_list|)
operator|>
literal|0
condition|)
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_INDIRECT
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_PREDICTIVE_PREFETCH
condition|)
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_PREDICTIVE_PREFETCH
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|GHOST_STATE
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
argument_list|)
argument_list|)
expr_stmt|;
name|acb
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_callback_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|acb
operator|->
name|acb_done
operator|=
name|done
expr_stmt|;
name|acb
operator|->
name|acb_private
operator|=
name|private
expr_stmt|;
name|acb
operator|->
name|acb_compressed
operator|=
name|compressed_read
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
operator|=
name|acb
expr_stmt|;
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_IO_IN_PROGRESS
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|(
name|vd
operator|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|->
name|l2ad_vdev
operator|)
operator|!=
name|NULL
condition|)
block|{
name|devw
operator|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|->
name|l2ad_writing
expr_stmt|;
name|addr
operator|=
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
expr_stmt|;
comment|/* 			 * Lock out device removal. 			 */
if|if
condition|(
name|vdev_is_dead
argument_list|(
name|vd
argument_list|)
operator|||
operator|!
name|spa_config_tryenter
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|vd
argument_list|,
name|RW_READER
argument_list|)
condition|)
name|vd
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|priority
operator|==
name|ZIO_PRIORITY_ASYNC_READ
condition|)
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_PRIO_ASYNC_READ
argument_list|)
expr_stmt|;
else|else
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_PRIO_ASYNC_READ
argument_list|)
expr_stmt|;
if|if
condition|(
name|hash_lock
operator|!=
name|NULL
condition|)
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
comment|/* 		 * At this point, we have a level 1 cache miss.  Try again in 		 * L2ARC if possible. 		 */
name|ASSERT3U
argument_list|(
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|==
argument_list|,
name|lsize
argument_list|)
expr_stmt|;
name|DTRACE_PROBE4
argument_list|(
name|arc__miss
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|,
name|blkptr_t
operator|*
argument_list|,
name|bp
argument_list|,
name|uint64_t
argument_list|,
name|lsize
argument_list|,
name|zbookmark_phys_t
operator|*
argument_list|,
name|zb
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_misses
argument_list|)
expr_stmt|;
name|ARCSTAT_CONDSTAT
argument_list|(
operator|!
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|demand
argument_list|,
name|prefetch
argument_list|,
operator|!
name|HDR_ISTYPE_METADATA
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|data
argument_list|,
name|metadata
argument_list|,
name|misses
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
ifdef|#
directive|ifdef
name|RACCT
if|if
condition|(
name|racct_enable
condition|)
block|{
name|PROC_LOCK
argument_list|(
name|curproc
argument_list|)
expr_stmt|;
name|racct_add_force
argument_list|(
name|curproc
argument_list|,
name|RACCT_READBPS
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|racct_add_force
argument_list|(
name|curproc
argument_list|,
name|RACCT_READIOPS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|curproc
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* RACCT */
name|curthread
operator|->
name|td_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|vd
operator|!=
name|NULL
operator|&&
name|l2arc_ndev
operator|!=
literal|0
operator|&&
operator|!
operator|(
name|l2arc_norw
operator|&&
name|devw
operator|)
condition|)
block|{
comment|/* 			 * Read from the L2ARC if the following are true: 			 * 1. The L2ARC vdev was previously cached. 			 * 2. This buffer still has L2ARC metadata. 			 * 3. This buffer isn't currently writing to the L2ARC. 			 * 4. The L2ARC entry wasn't evicted, which may 			 *    also have invalidated the vdev. 			 * 5. This isn't prefetch and l2arc_noprefetch is set. 			 */
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|!
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|!
name|HDR_L2_EVICTED
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|!
operator|(
name|l2arc_noprefetch
operator|&&
name|HDR_PREFETCH
argument_list|(
name|hdr
argument_list|)
operator|)
condition|)
block|{
name|l2arc_read_callback_t
modifier|*
name|cb
decl_stmt|;
name|void
modifier|*
name|b_data
decl_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|l2arc__hit
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_hits
argument_list|)
expr_stmt|;
name|cb
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|l2arc_read_callback_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|cb
operator|->
name|l2rcb_hdr
operator|=
name|hdr
expr_stmt|;
name|cb
operator|->
name|l2rcb_bp
operator|=
operator|*
name|bp
expr_stmt|;
name|cb
operator|->
name|l2rcb_zb
operator|=
operator|*
name|zb
expr_stmt|;
name|cb
operator|->
name|l2rcb_flags
operator|=
name|zio_flags
expr_stmt|;
name|uint64_t
name|asize
init|=
name|vdev_psize_to_asize
argument_list|(
name|vd
argument_list|,
name|size
argument_list|)
decl_stmt|;
if|if
condition|(
name|asize
operator|!=
name|size
condition|)
block|{
name|b_data
operator|=
name|zio_data_buf_alloc
argument_list|(
name|asize
argument_list|)
expr_stmt|;
name|cb
operator|->
name|l2rcb_data
operator|=
name|b_data
expr_stmt|;
block|}
else|else
block|{
name|b_data
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
expr_stmt|;
block|}
name|ASSERT
argument_list|(
name|addr
operator|>=
name|VDEV_LABEL_START_SIZE
operator|&&
name|addr
operator|+
name|asize
operator|<
name|vd
operator|->
name|vdev_psize
operator|-
name|VDEV_LABEL_END_SIZE
argument_list|)
expr_stmt|;
comment|/* 				 * l2arc read.  The SCL_L2ARC lock will be 				 * released by l2arc_read_done(). 				 * Issue a null zio if the underlying buffer 				 * was squashed to zero size by compression. 				 */
name|ASSERT3U
argument_list|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|!=
argument_list|,
name|ZIO_COMPRESS_EMPTY
argument_list|)
expr_stmt|;
name|rzio
operator|=
name|zio_read_phys
argument_list|(
name|pio
argument_list|,
name|vd
argument_list|,
name|addr
argument_list|,
name|asize
argument_list|,
name|b_data
argument_list|,
name|ZIO_CHECKSUM_OFF
argument_list|,
name|l2arc_read_done
argument_list|,
name|cb
argument_list|,
name|priority
argument_list|,
name|zio_flags
operator||
name|ZIO_FLAG_DONT_CACHE
operator||
name|ZIO_FLAG_CANFAIL
operator||
name|ZIO_FLAG_DONT_PROPAGATE
operator||
name|ZIO_FLAG_DONT_RETRY
argument_list|,
name|B_FALSE
argument_list|)
expr_stmt|;
name|DTRACE_PROBE2
argument_list|(
name|l2arc__read
argument_list|,
name|vdev_t
operator|*
argument_list|,
name|vd
argument_list|,
name|zio_t
operator|*
argument_list|,
name|rzio
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_read_bytes
argument_list|,
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_NOWAIT
condition|)
block|{
name|zio_nowait
argument_list|(
name|rzio
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|ASSERT
argument_list|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_WAIT
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio_wait
argument_list|(
name|rzio
argument_list|)
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* l2arc read error; goto zio_read() */
block|}
else|else
block|{
name|DTRACE_PROBE1
argument_list|(
name|l2arc__miss
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_misses
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
condition|)
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_rw_clash
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|vd
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|vd
operator|!=
name|NULL
condition|)
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|vd
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2arc_ndev
operator|!=
literal|0
condition|)
block|{
name|DTRACE_PROBE1
argument_list|(
name|l2arc__miss
argument_list|,
name|arc_buf_hdr_t
operator|*
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_misses
argument_list|)
expr_stmt|;
block|}
block|}
name|rzio
operator|=
name|zio_read
argument_list|(
name|pio
argument_list|,
name|spa
argument_list|,
name|bp
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|size
argument_list|,
name|arc_read_done
argument_list|,
name|hdr
argument_list|,
name|priority
argument_list|,
name|zio_flags
argument_list|,
name|zb
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_WAIT
condition|)
return|return
operator|(
name|zio_wait
argument_list|(
name|rzio
argument_list|)
operator|)
return|;
name|ASSERT
argument_list|(
operator|*
name|arc_flags
operator|&
name|ARC_FLAG_NOWAIT
argument_list|)
expr_stmt|;
name|zio_nowait
argument_list|(
name|rzio
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Notify the arc that a block was freed, and thus will never be used again.  */
end_comment

begin_function
name|void
name|arc_freed
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
specifier|const
name|blkptr_t
modifier|*
name|bp
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|uint64_t
name|guid
init|=
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|BP_IS_EMBEDDED
argument_list|(
name|bp
argument_list|)
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|buf_hash_find
argument_list|(
name|guid
argument_list|,
name|bp
argument_list|,
operator|&
name|hash_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|==
name|NULL
condition|)
return|return;
comment|/* 	 * We might be trying to free a block that is still doing I/O 	 * (i.e. prefetch) or has a reference (i.e. a dedup-ed, 	 * dmu_sync-ed block). If this block is being prefetched, then it 	 * would still have the ARC_FLAG_IO_IN_PROGRESS flag set on the hdr 	 * until the I/O completes. A block may also have a reference if it is 	 * part of a dedup-ed, dmu_synced write. The dmu_sync() function would 	 * have written the new block to its final resting place on disk but 	 * without the dedup flag set. This would have left the hdr in the MRU 	 * state and discoverable. When the txg finally syncs it detects that 	 * the block was overridden in open context and issues an override I/O. 	 * Since this is a dedup block, the override I/O will determine if the 	 * block is already in the DDT. If so, then it will replace the io_bp 	 * with the bp from the DDT and allow the I/O to finish. When the I/O 	 * reaches the done callback, dbuf_write_override_done, it will 	 * check to see if the io_bp and io_bp_override are identical. 	 * If they are not, then it indicates that the bp was replaced with 	 * the bp in the DDT and the override bp is freed. This allows 	 * us to arrive here with a reference on a block that is being 	 * freed. So if we have an I/O in progress, or a reference to 	 * this hdr, then we don't destroy the hdr. 	 */
if|if
condition|(
operator|!
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
operator|||
operator|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
operator|&&
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|)
condition|)
block|{
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Release this buffer from the cache, making it an anonymous buffer.  This  * must be done after a read and prior to modifying the buffer contents.  * If the buffer has more than one reference, we must make  * a new hdr for the buffer.  */
end_comment

begin_function
name|void
name|arc_release
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|void
modifier|*
name|tag
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
comment|/* 	 * It would be nice to assert that if it's DMU metadata (level> 	 * 0 || it's the dnode file), then it must be syncing context. 	 * But we don't know that information at this level. 	 */
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * We don't grab the hash lock prior to this check, because if 	 * the buffer's header is in the arc_anon state, it won't be 	 * linked into the hash table. 	 */
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IN_HASH_TABLE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
argument_list|,
operator|==
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|ASSERT3S
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|,
operator|==
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|list_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
literal|0
expr_stmt|;
comment|/* 		 * If the buf is being overridden then it may already 		 * have a hdr that is not empty. 		 */
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|arc_buf_thaw
argument_list|(
name|buf
argument_list|)
expr_stmt|;
return|return;
block|}
name|kmutex_t
modifier|*
name|hash_lock
init|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
comment|/* 	 * This assignment is only valid as long as the hash_lock is 	 * held, we must be careful not to reference state or the 	 * b_state field after dropping the lock. 	 */
name|arc_state_t
modifier|*
name|state
init|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
decl_stmt|;
name|ASSERT3P
argument_list|(
name|hash_lock
argument_list|,
operator|==
argument_list|,
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|state
argument_list|,
operator|!=
argument_list|,
name|arc_anon
argument_list|)
expr_stmt|;
comment|/* this buffer is not on any list */
name|ASSERT3S
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 		 * We have to recheck this conditional again now that 		 * we're holding the l2ad_mtx to prevent a race with 		 * another thread which might be concurrently calling 		 * l2arc_evict(). In that case, l2arc_evict() might have 		 * destroyed the header's L2 portion as we were waiting 		 * to acquire the l2ad_mtx. 		 */
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|l2arc_trim
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|arc_hdr_l2hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Do we have more than one buf? 	 */
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|>
literal|1
condition|)
block|{
name|arc_buf_hdr_t
modifier|*
name|nhdr
decl_stmt|;
name|uint64_t
name|spa
init|=
name|hdr
operator|->
name|b_spa
decl_stmt|;
name|uint64_t
name|psize
init|=
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|uint64_t
name|lsize
init|=
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|enum
name|zio_compress
name|compress
init|=
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|VERIFY3U
argument_list|(
name|hdr
operator|->
name|b_type
argument_list|,
operator|==
argument_list|,
name|type
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|!=
name|buf
operator|||
name|buf
operator|->
name|b_next
operator|!=
name|NULL
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|remove_reference
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|,
name|tag
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
operator|&&
operator|!
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|!=
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|ARC_BUF_LAST
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Pull the data off of this hdr and attach it to 		 * a new anonymous hdr. Also find the last buffer 		 * in the hdr's buffer list. 		 */
name|arc_buf_t
modifier|*
name|lastbuf
init|=
name|arc_buf_remove
argument_list|(
name|hdr
argument_list|,
name|buf
argument_list|)
decl_stmt|;
name|ASSERT3P
argument_list|(
name|lastbuf
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 		 * If the current arc_buf_t and the hdr are sharing their data 		 * buffer, then we must stop sharing that block. 		 */
if|if
condition|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|VERIFY
argument_list|(
operator|!
name|arc_buf_is_shared
argument_list|(
name|lastbuf
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 			 * First, sever the block sharing relationship between 			 * buf and the arc_buf_hdr_t. 			 */
name|arc_unshare_buf
argument_list|(
name|hdr
argument_list|,
name|buf
argument_list|)
expr_stmt|;
comment|/* 			 * Now we need to recreate the hdr's b_pdata. Since we 			 * have lastbuf handy, we try to share with it, but if 			 * we can't then we allocate a new b_pdata and copy the 			 * data from buf into it. 			 */
if|if
condition|(
name|arc_can_share
argument_list|(
name|hdr
argument_list|,
name|lastbuf
argument_list|)
condition|)
block|{
name|arc_share_buf
argument_list|(
name|hdr
argument_list|,
name|lastbuf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_hdr_alloc_pdata
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|psize
argument_list|)
expr_stmt|;
block|}
name|VERIFY3P
argument_list|(
name|lastbuf
operator|->
name|b_data
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|HDR_SHARED_DATA
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
comment|/* 			 * Uncompressed shared buffers are always at the end 			 * of the list. Compressed buffers don't have the 			 * same requirements. This makes it hard to 			 * simply assert that the lastbuf is shared so 			 * we rely on the hdr's compression flags to determine 			 * if we have a compressed, shared buffer. 			 */
name|ASSERT
argument_list|(
name|arc_buf_is_shared
argument_list|(
name|lastbuf
argument_list|)
operator|||
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
operator|!=
name|ZIO_COMPRESS_OFF
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|ARC_BUF_SHARED
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|state
argument_list|,
operator|!=
argument_list|,
name|arc_l2c_only
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
if|if
condition|(
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
condition|)
block|{
name|ASSERT3P
argument_list|(
name|state
argument_list|,
operator|!=
argument_list|,
name|arc_l2c_only
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|type
index|]
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|-=
literal|1
expr_stmt|;
name|arc_cksum_verify
argument_list|(
name|buf
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
name|arc_buf_unwatch
argument_list|(
name|buf
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
comment|/* 		 * Allocate a new hdr. The new hdr will contain a b_pdata 		 * buffer which will be freed in arc_write(). 		 */
name|nhdr
operator|=
name|arc_hdr_alloc
argument_list|(
name|spa
argument_list|,
name|psize
argument_list|,
name|lsize
argument_list|,
name|compress
argument_list|,
name|type
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|VERIFY3U
argument_list|(
name|nhdr
operator|->
name|b_type
argument_list|,
operator|==
argument_list|,
name|type
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_SHARED_DATA
argument_list|(
name|nhdr
argument_list|)
argument_list|)
expr_stmt|;
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_buf
operator|=
name|buf
expr_stmt|;
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|=
literal|1
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add
argument_list|(
operator|&
name|nhdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|,
name|tag
argument_list|)
expr_stmt|;
name|buf
operator|->
name|b_hdr
operator|=
name|nhdr
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|==
literal|1
argument_list|)
expr_stmt|;
comment|/* protected by hash lock, or hdr is on arc_anon */
name|ASSERT
argument_list|(
operator|!
name|multilist_link_active
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_arc_access
operator|=
literal|0
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|arc_buf_thaw
argument_list|(
name|buf
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|int
name|arc_released
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|int
name|released
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|released
operator|=
operator|(
name|buf
operator|->
name|b_data
operator|!=
name|NULL
operator|&&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
operator|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|released
operator|)
return|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|ZFS_DEBUG
end_ifdef

begin_function
name|int
name|arc_referenced
parameter_list|(
name|arc_buf_t
modifier|*
name|buf
parameter_list|)
block|{
name|int
name|referenced
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
name|referenced
operator|=
operator|(
name|refcount_count
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
operator|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|buf
operator|->
name|b_evict_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|referenced
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|void
name|arc_write_ready
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|arc_write_callback_t
modifier|*
name|callback
init|=
name|zio
operator|->
name|io_private
decl_stmt|;
name|arc_buf_t
modifier|*
name|buf
init|=
name|callback
operator|->
name|awcb_buf
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|uint64_t
name|psize
init|=
name|BP_IS_HOLE
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
condition|?
literal|0
else|:
name|BP_GET_PSIZE
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|refcount_is_zero
argument_list|(
operator|&
name|buf
operator|->
name|b_hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|>
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * If we're reexecuting this zio because the pool suspended, then 	 * cleanup any state that was previously set the first time the 	 * callback was invoked. 	 */
if|if
condition|(
name|zio
operator|->
name|io_flags
operator|&
name|ZIO_FLAG_REEXECUTED
condition|)
block|{
name|arc_cksum_free
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|illumos
name|arc_buf_unwatch
argument_list|(
name|buf
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|arc_unshare_buf
argument_list|(
name|hdr
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_hdr_free_pdata
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_SHARED_DATA
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|callback
operator|->
name|awcb_ready
argument_list|(
name|zio
argument_list|,
name|buf
argument_list|,
name|callback
operator|->
name|awcb_private
argument_list|)
expr_stmt|;
if|if
condition|(
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
condition|)
name|ASSERT
argument_list|(
name|zio
operator|->
name|io_flags
operator|&
name|ZIO_FLAG_REEXECUTED
argument_list|)
expr_stmt|;
name|arc_cksum_compute
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_IO_IN_PROGRESS
argument_list|)
expr_stmt|;
name|enum
name|zio_compress
name|compress
decl_stmt|;
if|if
condition|(
name|BP_IS_HOLE
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|||
name|BP_IS_EMBEDDED
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
condition|)
block|{
name|compress
operator|=
name|ZIO_COMPRESS_OFF
expr_stmt|;
block|}
else|else
block|{
name|ASSERT3U
argument_list|(
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|==
argument_list|,
name|BP_GET_LSIZE
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|)
expr_stmt|;
name|compress
operator|=
name|BP_GET_COMPRESS
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
expr_stmt|;
block|}
name|HDR_SET_PSIZE
argument_list|(
name|hdr
argument_list|,
name|psize
argument_list|)
expr_stmt|;
name|arc_hdr_set_compress
argument_list|(
name|hdr
argument_list|,
name|compress
argument_list|)
expr_stmt|;
comment|/* 	 * If the hdr is compressed, then copy the compressed 	 * zio contents into arc_buf_hdr_t. Otherwise, copy the original 	 * data buf into the hdr. Ideally, we would like to always copy the 	 * io_data into b_pdata but the user may have disabled compressed 	 * arc thus the on-disk block may or may not match what we maintain 	 * in the hdr's b_pdata field. 	 */
if|if
condition|(
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
operator|!=
name|ZIO_COMPRESS_OFF
operator|&&
operator|!
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|ASSERT3U
argument_list|(
name|BP_GET_COMPRESS
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|,
operator|!=
argument_list|,
name|ZIO_COMPRESS_OFF
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|psize
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|arc_hdr_alloc_pdata
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|zio
operator|->
name|io_data
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|psize
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT3P
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
operator|==
argument_list|,
name|zio
operator|->
name|io_orig_data
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|zio
operator|->
name|io_orig_size
argument_list|,
operator|==
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
argument_list|,
operator|==
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 		 * This hdr is not compressed so we're able to share 		 * the arc_buf_t data buffer with the hdr. 		 */
name|arc_share_buf
argument_list|(
name|hdr
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|ASSERT0
argument_list|(
name|bcmp
argument_list|(
name|zio
operator|->
name|io_orig_data
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|arc_hdr_verify
argument_list|(
name|hdr
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_write_children_ready
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|arc_write_callback_t
modifier|*
name|callback
init|=
name|zio
operator|->
name|io_private
decl_stmt|;
name|arc_buf_t
modifier|*
name|buf
init|=
name|callback
operator|->
name|awcb_buf
decl_stmt|;
name|callback
operator|->
name|awcb_children_ready
argument_list|(
name|zio
argument_list|,
name|buf
argument_list|,
name|callback
operator|->
name|awcb_private
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * The SPA calls this callback for each physical write that happens on behalf  * of a logical write.  See the comment in dbuf_write_physdone() for details.  */
end_comment

begin_function
specifier|static
name|void
name|arc_write_physdone
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|arc_write_callback_t
modifier|*
name|cb
init|=
name|zio
operator|->
name|io_private
decl_stmt|;
if|if
condition|(
name|cb
operator|->
name|awcb_physdone
operator|!=
name|NULL
condition|)
name|cb
operator|->
name|awcb_physdone
argument_list|(
name|zio
argument_list|,
name|cb
operator|->
name|awcb_buf
argument_list|,
name|cb
operator|->
name|awcb_private
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_write_done
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|arc_write_callback_t
modifier|*
name|callback
init|=
name|zio
operator|->
name|io_private
decl_stmt|;
name|arc_buf_t
modifier|*
name|buf
init|=
name|callback
operator|->
name|awcb_buf
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio
operator|->
name|io_error
operator|==
literal|0
condition|)
block|{
name|arc_hdr_verify
argument_list|(
name|hdr
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|BP_IS_HOLE
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|||
name|BP_IS_EMBEDDED
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
condition|)
block|{
name|buf_discard_identity
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|hdr
operator|->
name|b_dva
operator|=
operator|*
name|BP_IDENTITY
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
expr_stmt|;
name|hdr
operator|->
name|b_birth
operator|=
name|BP_PHYSICAL_BIRTH
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If the block to be written was all-zero or compressed enough to be 	 * embedded in the BP, no write was performed so there will be no 	 * dva/birth/checksum.  The buffer must therefore remain anonymous 	 * (and uncached). 	 */
if|if
condition|(
operator|!
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|arc_buf_hdr_t
modifier|*
name|exists
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|ASSERT3U
argument_list|(
name|zio
operator|->
name|io_error
argument_list|,
operator|==
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|arc_cksum_verify
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|exists
operator|=
name|buf_hash_insert
argument_list|(
name|hdr
argument_list|,
operator|&
name|hash_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|exists
operator|!=
name|NULL
condition|)
block|{
comment|/* 			 * This can only happen if we overwrite for 			 * sync-to-convergence, because we remove 			 * buffers from the hash table when we arc_free(). 			 */
if|if
condition|(
name|zio
operator|->
name|io_flags
operator|&
name|ZIO_FLAG_IO_REWRITE
condition|)
block|{
if|if
condition|(
operator|!
name|BP_EQUAL
argument_list|(
operator|&
name|zio
operator|->
name|io_bp_orig
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|)
condition|)
name|panic
argument_list|(
literal|"bad overwrite, hdr=%p exists=%p"
argument_list|,
operator|(
name|void
operator|*
operator|)
name|hdr
argument_list|,
operator|(
name|void
operator|*
operator|)
name|exists
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|refcount_is_zero
argument_list|(
operator|&
name|exists
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|exists
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|arc_hdr_destroy
argument_list|(
name|exists
argument_list|)
expr_stmt|;
name|exists
operator|=
name|buf_hash_insert
argument_list|(
name|hdr
argument_list|,
operator|&
name|hash_lock
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|exists
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|zio
operator|->
name|io_flags
operator|&
name|ZIO_FLAG_NOPWRITE
condition|)
block|{
comment|/* nopwrite */
name|ASSERT
argument_list|(
name|zio
operator|->
name|io_prop
operator|.
name|zp_nopwrite
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|BP_EQUAL
argument_list|(
operator|&
name|zio
operator|->
name|io_bp_orig
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|)
condition|)
name|panic
argument_list|(
literal|"bad nopwrite, hdr=%p exists=%p"
argument_list|,
operator|(
name|void
operator|*
operator|)
name|hdr
argument_list|,
operator|(
name|void
operator|*
operator|)
name|exists
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Dedup */
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
operator|==
literal|1
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|BP_GET_DEDUP
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|BP_GET_LEVEL
argument_list|(
name|zio
operator|->
name|io_bp
argument_list|)
operator|==
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_IO_IN_PROGRESS
argument_list|)
expr_stmt|;
comment|/* if it's not anon, we are doing a scrub */
if|if
condition|(
name|exists
operator|==
name|NULL
operator|&&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|==
name|arc_anon
condition|)
name|arc_access
argument_list|(
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_IO_IN_PROGRESS
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
operator|!
name|refcount_is_zero
argument_list|(
operator|&
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_refcnt
argument_list|)
argument_list|)
expr_stmt|;
name|callback
operator|->
name|awcb_done
argument_list|(
name|zio
argument_list|,
name|buf
argument_list|,
name|callback
operator|->
name|awcb_private
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|callback
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_write_callback_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|zio_t
modifier|*
name|arc_write
parameter_list|(
name|zio_t
modifier|*
name|pio
parameter_list|,
name|spa_t
modifier|*
name|spa
parameter_list|,
name|uint64_t
name|txg
parameter_list|,
name|blkptr_t
modifier|*
name|bp
parameter_list|,
name|arc_buf_t
modifier|*
name|buf
parameter_list|,
name|boolean_t
name|l2arc
parameter_list|,
specifier|const
name|zio_prop_t
modifier|*
name|zp
parameter_list|,
name|arc_done_func_t
modifier|*
name|ready
parameter_list|,
name|arc_done_func_t
modifier|*
name|children_ready
parameter_list|,
name|arc_done_func_t
modifier|*
name|physdone
parameter_list|,
name|arc_done_func_t
modifier|*
name|done
parameter_list|,
name|void
modifier|*
name|private
parameter_list|,
name|zio_priority_t
name|priority
parameter_list|,
name|int
name|zio_flags
parameter_list|,
specifier|const
name|zbookmark_phys_t
modifier|*
name|zb
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|buf
operator|->
name|b_hdr
decl_stmt|;
name|arc_write_callback_t
modifier|*
name|callback
decl_stmt|;
name|zio_t
modifier|*
name|zio
decl_stmt|;
name|zio_prop_t
name|localprop
init|=
operator|*
name|zp
decl_stmt|;
name|ASSERT3P
argument_list|(
name|ready
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|done
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_ERROR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_acb
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_bufcnt
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2arc
condition|)
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_L2CACHE
argument_list|)
expr_stmt|;
if|if
condition|(
name|ARC_BUF_COMPRESSED
argument_list|(
name|buf
argument_list|)
condition|)
block|{
comment|/* 		 * We're writing a pre-compressed buffer.  Make the 		 * compression algorithm requested by the zio_prop_t match 		 * the pre-compressed buffer's compression algorithm. 		 */
name|localprop
operator|.
name|zp_compress
operator|=
name|HDR_GET_COMPRESS
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|!=
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|zio_flags
operator||=
name|ZIO_FLAG_RAW
expr_stmt|;
block|}
name|callback
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_write_callback_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|callback
operator|->
name|awcb_ready
operator|=
name|ready
expr_stmt|;
name|callback
operator|->
name|awcb_children_ready
operator|=
name|children_ready
expr_stmt|;
name|callback
operator|->
name|awcb_physdone
operator|=
name|physdone
expr_stmt|;
name|callback
operator|->
name|awcb_done
operator|=
name|done
expr_stmt|;
name|callback
operator|->
name|awcb_private
operator|=
name|private
expr_stmt|;
name|callback
operator|->
name|awcb_buf
operator|=
name|buf
expr_stmt|;
comment|/* 	 * The hdr's b_pdata is now stale, free it now. A new data block 	 * will be allocated when the zio pipeline calls arc_write_ready(). 	 */
if|if
condition|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
operator|!=
name|NULL
condition|)
block|{
comment|/* 		 * If the buf is currently sharing the data block with 		 * the hdr then we need to break that relationship here. 		 * The hdr will remain with a NULL data pointer and the 		 * buf will take sole ownership of the block. 		 */
if|if
condition|(
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
condition|)
block|{
name|arc_unshare_buf
argument_list|(
name|hdr
argument_list|,
name|buf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|arc_hdr_free_pdata
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
name|VERIFY3P
argument_list|(
name|buf
operator|->
name|b_data
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|arc_hdr_set_compress
argument_list|(
name|hdr
argument_list|,
name|ZIO_COMPRESS_OFF
argument_list|)
expr_stmt|;
block|}
name|ASSERT
argument_list|(
operator|!
name|arc_buf_is_shared
argument_list|(
name|buf
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|==
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|zio
operator|=
name|zio_write
argument_list|(
name|pio
argument_list|,
name|spa
argument_list|,
name|txg
argument_list|,
name|bp
argument_list|,
name|buf
operator|->
name|b_data
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|arc_buf_size
argument_list|(
name|buf
argument_list|)
argument_list|,
operator|&
name|localprop
argument_list|,
name|arc_write_ready
argument_list|,
operator|(
name|children_ready
operator|!=
name|NULL
operator|)
condition|?
name|arc_write_children_ready
else|:
name|NULL
argument_list|,
name|arc_write_physdone
argument_list|,
name|arc_write_done
argument_list|,
name|callback
argument_list|,
name|priority
argument_list|,
name|zio_flags
argument_list|,
name|zb
argument_list|)
expr_stmt|;
return|return
operator|(
name|zio
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|arc_memory_throttle
parameter_list|(
name|uint64_t
name|reserve
parameter_list|,
name|uint64_t
name|txg
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|_KERNEL
name|uint64_t
name|available_memory
init|=
name|ptob
argument_list|(
name|freemem
argument_list|)
decl_stmt|;
specifier|static
name|uint64_t
name|page_load
init|=
literal|0
decl_stmt|;
specifier|static
name|uint64_t
name|last_txg
init|=
literal|0
decl_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|__i386
argument_list|)
operator|||
operator|!
name|defined
argument_list|(
name|UMA_MD_SMALL_ALLOC
argument_list|)
name|available_memory
operator|=
name|MIN
argument_list|(
name|available_memory
argument_list|,
name|ptob
argument_list|(
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_FREE
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|freemem
operator|>
operator|(
name|uint64_t
operator|)
name|physmem
operator|*
name|arc_lotsfree_percent
operator|/
literal|100
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|if
condition|(
name|txg
operator|>
name|last_txg
condition|)
block|{
name|last_txg
operator|=
name|txg
expr_stmt|;
name|page_load
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * If we are in pageout, we know that memory is already tight, 	 * the arc is already going to be evicting, so we just want to 	 * continue to let page writes occur as quickly as possible. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
condition|)
block|{
if|if
condition|(
name|page_load
operator|>
name|MAX
argument_list|(
name|ptob
argument_list|(
name|minfree
argument_list|)
argument_list|,
name|available_memory
argument_list|)
operator|/
literal|4
condition|)
return|return
operator|(
name|SET_ERROR
argument_list|(
name|ERESTART
argument_list|)
operator|)
return|;
comment|/* Note: reserve is inflated, so we deflate */
name|page_load
operator|+=
name|reserve
operator|/
literal|8
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|page_load
operator|>
literal|0
operator|&&
name|arc_reclaim_needed
argument_list|()
condition|)
block|{
comment|/* memory is low, delay before restarting */
name|ARCSTAT_INCR
argument_list|(
name|arcstat_memory_throttle_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|SET_ERROR
argument_list|(
name|EAGAIN
argument_list|)
operator|)
return|;
block|}
name|page_load
operator|=
literal|0
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|void
name|arc_tempreserve_clear
parameter_list|(
name|uint64_t
name|reserve
parameter_list|)
block|{
name|atomic_add_64
argument_list|(
operator|&
name|arc_tempreserve
argument_list|,
operator|-
name|reserve
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|(
name|int64_t
operator|)
name|arc_tempreserve
operator|>=
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|arc_tempreserve_space
parameter_list|(
name|uint64_t
name|reserve
parameter_list|,
name|uint64_t
name|txg
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
name|uint64_t
name|anon_size
decl_stmt|;
if|if
condition|(
name|reserve
operator|>
name|arc_c
operator|/
literal|4
operator|&&
operator|!
name|arc_no_grow
condition|)
block|{
name|arc_c
operator|=
name|MIN
argument_list|(
name|arc_c_max
argument_list|,
name|reserve
operator|*
literal|4
argument_list|)
expr_stmt|;
name|DTRACE_PROBE1
argument_list|(
name|arc__set_reserve
argument_list|,
name|uint64_t
argument_list|,
name|arc_c
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|reserve
operator|>
name|arc_c
condition|)
return|return
operator|(
name|SET_ERROR
argument_list|(
name|ENOMEM
argument_list|)
operator|)
return|;
comment|/* 	 * Don't count loaned bufs as in flight dirty data to prevent long 	 * network delays from blocking transactions that are ready to be 	 * assigned to a txg. 	 */
comment|/* assert that it has not wrapped around */
name|ASSERT3S
argument_list|(
name|atomic_add_64_nv
argument_list|(
operator|&
name|arc_loaned_bytes
argument_list|,
literal|0
argument_list|)
argument_list|,
operator|>=
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|anon_size
operator|=
name|MAX
argument_list|(
call|(
name|int64_t
call|)
argument_list|(
name|refcount_count
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
operator|-
name|arc_loaned_bytes
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * Writes will, almost always, require additional memory allocations 	 * in order to compress/encrypt/etc the data.  We therefore need to 	 * make sure that there is sufficient available memory for this. 	 */
name|error
operator|=
name|arc_memory_throttle
argument_list|(
name|reserve
argument_list|,
name|txg
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
return|return
operator|(
name|error
operator|)
return|;
comment|/* 	 * Throttle writes when the amount of dirty data in the cache 	 * gets too large.  We try to keep the cache less than half full 	 * of dirty blocks so that our sync times don't grow too large. 	 * Note: if two requests come in concurrently, we might let them 	 * both succeed, when one of them should fail.  Not a huge deal. 	 */
if|if
condition|(
name|reserve
operator|+
name|arc_tempreserve
operator|+
name|anon_size
operator|>
name|arc_c
operator|/
literal|2
operator|&&
name|anon_size
operator|>
name|arc_c
operator|/
literal|4
condition|)
block|{
name|uint64_t
name|meta_esize
init|=
name|refcount_count
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
decl_stmt|;
name|uint64_t
name|data_esize
init|=
name|refcount_count
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
decl_stmt|;
name|dprintf
argument_list|(
literal|"failing, arc_tempreserve=%lluK anon_meta=%lluK "
literal|"anon_data=%lluK tempreserve=%lluK arc_c=%lluK\n"
argument_list|,
name|arc_tempreserve
operator|>>
literal|10
argument_list|,
name|meta_esize
operator|>>
literal|10
argument_list|,
name|data_esize
operator|>>
literal|10
argument_list|,
name|reserve
operator|>>
literal|10
argument_list|,
name|arc_c
operator|>>
literal|10
argument_list|)
expr_stmt|;
return|return
operator|(
name|SET_ERROR
argument_list|(
name|ERESTART
argument_list|)
operator|)
return|;
block|}
name|atomic_add_64
argument_list|(
operator|&
name|arc_tempreserve
argument_list|,
name|reserve
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_kstat_update_state
parameter_list|(
name|arc_state_t
modifier|*
name|state
parameter_list|,
name|kstat_named_t
modifier|*
name|size
parameter_list|,
name|kstat_named_t
modifier|*
name|evict_data
parameter_list|,
name|kstat_named_t
modifier|*
name|evict_metadata
parameter_list|)
block|{
name|size
operator|->
name|value
operator|.
name|ui64
operator|=
name|refcount_count
argument_list|(
operator|&
name|state
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|evict_data
operator|->
name|value
operator|.
name|ui64
operator|=
name|refcount_count
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|evict_metadata
operator|->
name|value
operator|.
name|ui64
operator|=
name|refcount_count
argument_list|(
operator|&
name|state
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|arc_kstat_update
parameter_list|(
name|kstat_t
modifier|*
name|ksp
parameter_list|,
name|int
name|rw
parameter_list|)
block|{
name|arc_stats_t
modifier|*
name|as
init|=
name|ksp
operator|->
name|ks_data
decl_stmt|;
if|if
condition|(
name|rw
operator|==
name|KSTAT_WRITE
condition|)
block|{
return|return
operator|(
name|EACCES
operator|)
return|;
block|}
else|else
block|{
name|arc_kstat_update_state
argument_list|(
name|arc_anon
argument_list|,
operator|&
name|as
operator|->
name|arcstat_anon_size
argument_list|,
operator|&
name|as
operator|->
name|arcstat_anon_evictable_data
argument_list|,
operator|&
name|as
operator|->
name|arcstat_anon_evictable_metadata
argument_list|)
expr_stmt|;
name|arc_kstat_update_state
argument_list|(
name|arc_mru
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_size
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_evictable_data
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_evictable_metadata
argument_list|)
expr_stmt|;
name|arc_kstat_update_state
argument_list|(
name|arc_mru_ghost
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_ghost_size
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_ghost_evictable_data
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mru_ghost_evictable_metadata
argument_list|)
expr_stmt|;
name|arc_kstat_update_state
argument_list|(
name|arc_mfu
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_size
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_evictable_data
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_evictable_metadata
argument_list|)
expr_stmt|;
name|arc_kstat_update_state
argument_list|(
name|arc_mfu_ghost
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_ghost_size
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_ghost_evictable_data
argument_list|,
operator|&
name|as
operator|->
name|arcstat_mfu_ghost_evictable_metadata
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This function *must* return indices evenly distributed between all  * sublists of the multilist. This is needed due to how the ARC eviction  * code is laid out; arc_evict_state() assumes ARC buffers are evenly  * distributed between all sublists and uses this assumption when  * deciding which sublist to evict from and how much to evict from it.  */
end_comment

begin_function
name|unsigned
name|int
name|arc_state_multilist_index_func
parameter_list|(
name|multilist_t
modifier|*
name|ml
parameter_list|,
name|void
modifier|*
name|obj
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
init|=
name|obj
decl_stmt|;
comment|/* 	 * We rely on b_dva to generate evenly distributed index 	 * numbers using buf_hash below. So, as an added precaution, 	 * let's make sure we never add empty buffers to the arc lists. 	 */
name|ASSERT
argument_list|(
operator|!
name|HDR_EMPTY
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * The assumption here, is the hash value for a given 	 * arc_buf_hdr_t will remain constant throughout it's lifetime 	 * (i.e. it's b_spa, b_dva, and b_birth fields don't change). 	 * Thus, we don't need to store the header's sublist index 	 * on insertion, as this index can be recalculated on removal. 	 * 	 * Also, the low order bits of the hash value are thought to be 	 * distributed evenly. Otherwise, in the case that the multilist 	 * has a power of two number of sublists, each sublists' usage 	 * would not be evenly distributed. 	 */
return|return
operator|(
name|buf_hash
argument_list|(
name|hdr
operator|->
name|b_spa
argument_list|,
operator|&
name|hdr
operator|->
name|b_dva
argument_list|,
name|hdr
operator|->
name|b_birth
argument_list|)
operator|%
name|multilist_get_num_sublists
argument_list|(
name|ml
argument_list|)
operator|)
return|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|_KERNEL
end_ifdef

begin_decl_stmt
specifier|static
name|eventhandler_tag
name|arc_event_lowmem
init|=
name|NULL
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|void
name|arc_lowmem
parameter_list|(
name|void
modifier|*
name|arg
name|__unused
parameter_list|,
name|int
name|howto
name|__unused
parameter_list|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
comment|/* XXX: Memory deficit should be passed as argument. */
name|needfree
operator|=
name|btoc
argument_list|(
name|arc_c
operator|>>
name|arc_shrink_shift
argument_list|)
expr_stmt|;
name|DTRACE_PROBE
argument_list|(
name|arc__needfree
argument_list|)
expr_stmt|;
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
comment|/* 	 * It is unsafe to block here in arbitrary threads, because we can come 	 * here from ARC itself and may hold ARC locks and thus risk a deadlock 	 * with ARC reclaim thread. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
condition|)
operator|(
name|void
operator|)
name|cv_wait
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|void
name|arc_state_init
parameter_list|(
name|void
parameter_list|)
block|{
name|arc_anon
operator|=
operator|&
name|ARC_anon
expr_stmt|;
name|arc_mru
operator|=
operator|&
name|ARC_mru
expr_stmt|;
name|arc_mru_ghost
operator|=
operator|&
name|ARC_mru_ghost
expr_stmt|;
name|arc_mfu
operator|=
operator|&
name|ARC_mfu
expr_stmt|;
name|arc_mfu_ghost
operator|=
operator|&
name|ARC_mfu_ghost
expr_stmt|;
name|arc_l2c_only
operator|=
operator|&
name|ARC_l2c_only
expr_stmt|;
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
operator|=
name|multilist_create
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
operator|=
name|multilist_create
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|arc_mru_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
operator|=
name|multilist_create
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|arc_mru_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
operator|=
name|multilist_create
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
operator|=
name|multilist_create
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
operator|=
name|multilist_create
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|arc_mfu_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
operator|=
name|multilist_create
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|arc_mfu_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
operator|=
name|multilist_create
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|arc_l2c_only
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
operator|=
name|multilist_create
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|arc_l2c_only
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
operator|=
name|multilist_create
argument_list|(
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l1hdr
operator|.
name|b_arc_node
argument_list|)
argument_list|,
name|arc_state_multilist_index_func
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|arc_state_fini
parameter_list|(
name|void
parameter_list|)
block|{
name|refcount_destroy
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_esize
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_anon
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mru
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mru_ghost
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mfu
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_mfu_ghost
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|arc_l2c_only
operator|->
name|arcs_size
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
name|arc_mru_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
name|arc_mfu_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
name|arc_mru_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
name|multilist_destroy
argument_list|(
name|arc_mfu_ghost
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|uint64_t
name|arc_max_bytes
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
name|arc_c_max
operator|)
return|;
block|}
end_function

begin_function
name|void
name|arc_init
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|prefetch_tunable_set
init|=
literal|0
decl_stmt|;
comment|/* 	 * allmem is "all memory that we could possibly use". 	 */
ifdef|#
directive|ifdef
name|illumos
ifdef|#
directive|ifdef
name|_KERNEL
name|uint64_t
name|allmem
init|=
name|ptob
argument_list|(
name|physmem
operator|-
name|swapfs_minfree
argument_list|)
decl_stmt|;
else|#
directive|else
name|uint64_t
name|allmem
init|=
operator|(
name|physmem
operator|*
name|PAGESIZE
operator|)
operator|/
literal|2
decl_stmt|;
endif|#
directive|endif
else|#
directive|else
name|uint64_t
name|allmem
init|=
name|kmem_size
argument_list|()
decl_stmt|;
endif|#
directive|endif
name|mutex_init
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|arc_dnlc_evicts_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|arc_dnlc_evicts_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* Convert seconds to clock ticks */
name|arc_min_prefetch_lifespan
operator|=
literal|1
operator|*
name|hz
expr_stmt|;
comment|/* set min cache to 1/32 of all memory, or arc_abs_min, whichever is more */
name|arc_c_min
operator|=
name|MAX
argument_list|(
name|allmem
operator|/
literal|32
argument_list|,
name|arc_abs_min
argument_list|)
expr_stmt|;
comment|/* set max to 5/8 of all memory, or all but 1GB, whichever is more */
if|if
condition|(
name|allmem
operator|>=
literal|1
operator|<<
literal|30
condition|)
name|arc_c_max
operator|=
name|allmem
operator|-
operator|(
literal|1
operator|<<
literal|30
operator|)
expr_stmt|;
else|else
name|arc_c_max
operator|=
name|arc_c_min
expr_stmt|;
name|arc_c_max
operator|=
name|MAX
argument_list|(
name|allmem
operator|*
literal|5
operator|/
literal|8
argument_list|,
name|arc_c_max
argument_list|)
expr_stmt|;
comment|/* 	 * In userland, there's only the memory pressure that we artificially 	 * create (see arc_available_memory()).  Don't let arc_c get too 	 * small, because it can cause transactions to be larger than 	 * arc_c, causing arc_tempreserve_space() to fail. 	 */
ifndef|#
directive|ifndef
name|_KERNEL
name|arc_c_min
operator|=
name|arc_c_max
operator|/
literal|2
expr_stmt|;
endif|#
directive|endif
ifdef|#
directive|ifdef
name|_KERNEL
comment|/* 	 * Allow the tunables to override our calculations if they are 	 * reasonable. 	 */
if|if
condition|(
name|zfs_arc_max
operator|>
name|arc_abs_min
operator|&&
name|zfs_arc_max
operator|<
name|allmem
condition|)
block|{
name|arc_c_max
operator|=
name|zfs_arc_max
expr_stmt|;
name|arc_c_min
operator|=
name|MIN
argument_list|(
name|arc_c_min
argument_list|,
name|arc_c_max
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|zfs_arc_min
operator|>
name|arc_abs_min
operator|&&
name|zfs_arc_min
operator|<=
name|arc_c_max
condition|)
name|arc_c_min
operator|=
name|zfs_arc_min
expr_stmt|;
endif|#
directive|endif
name|arc_c
operator|=
name|arc_c_max
expr_stmt|;
name|arc_p
operator|=
operator|(
name|arc_c
operator|>>
literal|1
operator|)
expr_stmt|;
name|arc_size
operator|=
literal|0
expr_stmt|;
comment|/* limit meta-data to 1/4 of the arc capacity */
name|arc_meta_limit
operator|=
name|arc_c_max
operator|/
literal|4
expr_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
comment|/* 	 * Metadata is stored in the kernel's heap.  Don't let us 	 * use more than half the heap for the ARC. 	 */
name|arc_meta_limit
operator|=
name|MIN
argument_list|(
name|arc_meta_limit
argument_list|,
name|vmem_size
argument_list|(
name|heap_arena
argument_list|,
name|VMEM_ALLOC
operator||
name|VMEM_FREE
argument_list|)
operator|/
literal|2
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* Allow the tunable to override if it is reasonable */
if|if
condition|(
name|zfs_arc_meta_limit
operator|>
literal|0
operator|&&
name|zfs_arc_meta_limit
operator|<=
name|arc_c_max
condition|)
name|arc_meta_limit
operator|=
name|zfs_arc_meta_limit
expr_stmt|;
if|if
condition|(
name|arc_c_min
operator|<
name|arc_meta_limit
operator|/
literal|2
operator|&&
name|zfs_arc_min
operator|==
literal|0
condition|)
name|arc_c_min
operator|=
name|arc_meta_limit
operator|/
literal|2
expr_stmt|;
if|if
condition|(
name|zfs_arc_meta_min
operator|>
literal|0
condition|)
block|{
name|arc_meta_min
operator|=
name|zfs_arc_meta_min
expr_stmt|;
block|}
else|else
block|{
name|arc_meta_min
operator|=
name|arc_c_min
operator|/
literal|2
expr_stmt|;
block|}
if|if
condition|(
name|zfs_arc_grow_retry
operator|>
literal|0
condition|)
name|arc_grow_retry
operator|=
name|zfs_arc_grow_retry
expr_stmt|;
if|if
condition|(
name|zfs_arc_shrink_shift
operator|>
literal|0
condition|)
name|arc_shrink_shift
operator|=
name|zfs_arc_shrink_shift
expr_stmt|;
comment|/* 	 * Ensure that arc_no_grow_shift is less than arc_shrink_shift. 	 */
if|if
condition|(
name|arc_no_grow_shift
operator|>=
name|arc_shrink_shift
condition|)
name|arc_no_grow_shift
operator|=
name|arc_shrink_shift
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|zfs_arc_p_min_shift
operator|>
literal|0
condition|)
name|arc_p_min_shift
operator|=
name|zfs_arc_p_min_shift
expr_stmt|;
comment|/* if kmem_flags are set, lets try to use less memory */
if|if
condition|(
name|kmem_debugging
argument_list|()
condition|)
name|arc_c
operator|=
name|arc_c
operator|/
literal|2
expr_stmt|;
if|if
condition|(
name|arc_c
operator|<
name|arc_c_min
condition|)
name|arc_c
operator|=
name|arc_c_min
expr_stmt|;
name|zfs_arc_min
operator|=
name|arc_c_min
expr_stmt|;
name|zfs_arc_max
operator|=
name|arc_c_max
expr_stmt|;
name|arc_state_init
argument_list|()
expr_stmt|;
name|buf_init
argument_list|()
expr_stmt|;
name|arc_reclaim_thread_exit
operator|=
name|B_FALSE
expr_stmt|;
name|arc_dnlc_evicts_thread_exit
operator|=
name|FALSE
expr_stmt|;
name|arc_ksp
operator|=
name|kstat_create
argument_list|(
literal|"zfs"
argument_list|,
literal|0
argument_list|,
literal|"arcstats"
argument_list|,
literal|"misc"
argument_list|,
name|KSTAT_TYPE_NAMED
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_stats
argument_list|)
operator|/
sizeof|sizeof
argument_list|(
name|kstat_named_t
argument_list|)
argument_list|,
name|KSTAT_FLAG_VIRTUAL
argument_list|)
expr_stmt|;
if|if
condition|(
name|arc_ksp
operator|!=
name|NULL
condition|)
block|{
name|arc_ksp
operator|->
name|ks_data
operator|=
operator|&
name|arc_stats
expr_stmt|;
name|arc_ksp
operator|->
name|ks_update
operator|=
name|arc_kstat_update
expr_stmt|;
name|kstat_install
argument_list|(
name|arc_ksp
argument_list|)
expr_stmt|;
block|}
operator|(
name|void
operator|)
name|thread_create
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|arc_reclaim_thread
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
operator|&
name|p0
argument_list|,
name|TS_RUN
argument_list|,
name|minclsyspri
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
name|arc_event_lowmem
operator|=
name|EVENTHANDLER_REGISTER
argument_list|(
name|vm_lowmem
argument_list|,
name|arc_lowmem
argument_list|,
name|NULL
argument_list|,
name|EVENTHANDLER_PRI_FIRST
argument_list|)
expr_stmt|;
endif|#
directive|endif
operator|(
name|void
operator|)
name|thread_create
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|arc_dnlc_evicts_thread
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
operator|&
name|p0
argument_list|,
name|TS_RUN
argument_list|,
name|minclsyspri
argument_list|)
expr_stmt|;
name|arc_dead
operator|=
name|B_FALSE
expr_stmt|;
name|arc_warm
operator|=
name|B_FALSE
expr_stmt|;
comment|/* 	 * Calculate maximum amount of dirty data per pool. 	 * 	 * If it has been set by /etc/system, take that. 	 * Otherwise, use a percentage of physical memory defined by 	 * zfs_dirty_data_max_percent (default 10%) with a cap at 	 * zfs_dirty_data_max_max (default 4GB). 	 */
if|if
condition|(
name|zfs_dirty_data_max
operator|==
literal|0
condition|)
block|{
name|zfs_dirty_data_max
operator|=
name|ptob
argument_list|(
name|physmem
argument_list|)
operator|*
name|zfs_dirty_data_max_percent
operator|/
literal|100
expr_stmt|;
name|zfs_dirty_data_max
operator|=
name|MIN
argument_list|(
name|zfs_dirty_data_max
argument_list|,
name|zfs_dirty_data_max_max
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|_KERNEL
if|if
condition|(
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vfs.zfs.prefetch_disable"
argument_list|,
operator|&
name|zfs_prefetch_disable
argument_list|)
condition|)
name|prefetch_tunable_set
operator|=
literal|1
expr_stmt|;
ifdef|#
directive|ifdef
name|__i386__
if|if
condition|(
name|prefetch_tunable_set
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"ZFS NOTICE: Prefetch is disabled by default on i386 "
literal|"-- to enable,\n"
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"            add \"vfs.zfs.prefetch_disable=0\" "
literal|"to /boot/loader.conf.\n"
argument_list|)
expr_stmt|;
name|zfs_prefetch_disable
operator|=
literal|1
expr_stmt|;
block|}
else|#
directive|else
if|if
condition|(
operator|(
operator|(
operator|(
name|uint64_t
operator|)
name|physmem
operator|*
name|PAGESIZE
operator|)
operator|<
operator|(
literal|1ULL
operator|<<
literal|32
operator|)
operator|)
operator|&&
name|prefetch_tunable_set
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"ZFS NOTICE: Prefetch is disabled by default if less "
literal|"than 4GB of RAM is present;\n"
literal|"            to enable, add \"vfs.zfs.prefetch_disable=0\" "
literal|"to /boot/loader.conf.\n"
argument_list|)
expr_stmt|;
name|zfs_prefetch_disable
operator|=
literal|1
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* Warn about ZFS memory and address space requirements. */
if|if
condition|(
operator|(
operator|(
name|uint64_t
operator|)
name|physmem
operator|*
name|PAGESIZE
operator|)
operator|<
operator|(
literal|256
operator|+
literal|128
operator|+
literal|64
operator|)
operator|*
operator|(
literal|1
operator|<<
literal|20
operator|)
condition|)
block|{
name|printf
argument_list|(
literal|"ZFS WARNING: Recommended minimum RAM size is 512MB; "
literal|"expect unstable behavior.\n"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|allmem
operator|<
literal|512
operator|*
operator|(
literal|1
operator|<<
literal|20
operator|)
condition|)
block|{
name|printf
argument_list|(
literal|"ZFS WARNING: Recommended minimum kmem_size is 512MB; "
literal|"expect unstable behavior.\n"
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"             Consider tuning vm.kmem_size and "
literal|"vm.kmem_size_max\n"
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"             in /boot/loader.conf.\n"
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|arc_fini
parameter_list|(
name|void
parameter_list|)
block|{
name|mutex_enter
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
name|arc_reclaim_thread_exit
operator|=
name|B_TRUE
expr_stmt|;
comment|/* 	 * The reclaim thread will set arc_reclaim_thread_exit back to 	 * B_FALSE when it is finished exiting; we're waiting for that. 	 */
while|while
condition|(
name|arc_reclaim_thread_exit
condition|)
block|{
name|cv_signal
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
name|cv_wait
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|,
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
comment|/* Use B_TRUE to ensure *all* buffers are evicted */
name|arc_flush
argument_list|(
name|NULL
argument_list|,
name|B_TRUE
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
name|arc_dnlc_evicts_thread_exit
operator|=
name|TRUE
expr_stmt|;
comment|/* 	 * The user evicts thread will set arc_user_evicts_thread_exit 	 * to FALSE when it is finished exiting; we're waiting for that. 	 */
while|while
condition|(
name|arc_dnlc_evicts_thread_exit
condition|)
block|{
name|cv_signal
argument_list|(
operator|&
name|arc_dnlc_evicts_cv
argument_list|)
expr_stmt|;
name|cv_wait
argument_list|(
operator|&
name|arc_dnlc_evicts_cv
argument_list|,
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
name|arc_dead
operator|=
name|B_TRUE
expr_stmt|;
if|if
condition|(
name|arc_ksp
operator|!=
name|NULL
condition|)
block|{
name|kstat_delete
argument_list|(
name|arc_ksp
argument_list|)
expr_stmt|;
name|arc_ksp
operator|=
name|NULL
expr_stmt|;
block|}
name|mutex_destroy
argument_list|(
operator|&
name|arc_reclaim_lock
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|arc_reclaim_thread_cv
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|arc_reclaim_waiters_cv
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|arc_dnlc_evicts_lock
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|arc_dnlc_evicts_cv
argument_list|)
expr_stmt|;
name|arc_state_fini
argument_list|()
expr_stmt|;
name|buf_fini
argument_list|()
expr_stmt|;
name|ASSERT0
argument_list|(
name|arc_loaned_bytes
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|_KERNEL
if|if
condition|(
name|arc_event_lowmem
operator|!=
name|NULL
condition|)
name|EVENTHANDLER_DEREGISTER
argument_list|(
name|vm_lowmem
argument_list|,
name|arc_event_lowmem
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  * Level 2 ARC  *  * The level 2 ARC (L2ARC) is a cache layer in-between main memory and disk.  * It uses dedicated storage devices to hold cached data, which are populated  * using large infrequent writes.  The main role of this cache is to boost  * the performance of random read workloads.  The intended L2ARC devices  * include short-stroked disks, solid state disks, and other media with  * substantially faster read latency than disk.  *  *                 +-----------------------+  *                 |         ARC           |  *                 +-----------------------+  *                    |         ^     ^  *                    |         |     |  *      l2arc_feed_thread()    arc_read()  *                    |         |     |  *                    |  l2arc read   |  *                    V         |     |  *               +---------------+    |  *               |     L2ARC     |    |  *               +---------------+    |  *                   |    ^           |  *          l2arc_write() |           |  *                   |    |           |  *                   V    |           |  *                 +-------+      +-------+  *                 | vdev  |      | vdev  |  *                 | cache |      | cache |  *                 +-------+      +-------+  *                 +=========+     .-----.  *                 :  L2ARC  :    |-_____-|  *                 : devices :    | Disks |  *                 +=========+    `-_____-'  *  * Read requests are satisfied from the following sources, in order:  *  *	1) ARC  *	2) vdev cache of L2ARC devices  *	3) L2ARC devices  *	4) vdev cache of disks  *	5) disks  *  * Some L2ARC device types exhibit extremely slow write performance.  * To accommodate for this there are some significant differences between  * the L2ARC and traditional cache design:  *  * 1. There is no eviction path from the ARC to the L2ARC.  Evictions from  * the ARC behave as usual, freeing buffers and placing headers on ghost  * lists.  The ARC does not send buffers to the L2ARC during eviction as  * this would add inflated write latencies for all ARC memory pressure.  *  * 2. The L2ARC attempts to cache data from the ARC before it is evicted.  * It does this by periodically scanning buffers from the eviction-end of  * the MFU and MRU ARC lists, copying them to the L2ARC devices if they are  * not already there. It scans until a headroom of buffers is satisfied,  * which itself is a buffer for ARC eviction. If a compressible buffer is  * found during scanning and selected for writing to an L2ARC device, we  * temporarily boost scanning headroom during the next scan cycle to make  * sure we adapt to compression effects (which might significantly reduce  * the data volume we write to L2ARC). The thread that does this is  * l2arc_feed_thread(), illustrated below; example sizes are included to  * provide a better sense of ratio than this diagram:  *  *	       head -->                        tail  *	        +---------------------+----------+  *	ARC_mfu |:::::#:::::::::::::::|o#o###o###|-->.   # already on L2ARC  *	        +---------------------+----------+   |   o L2ARC eligible  *	ARC_mru |:#:::::::::::::::::::|#o#ooo####|-->|   : ARC buffer  *	        +---------------------+----------+   |  *	             15.9 Gbytes      ^ 32 Mbytes    |  *	                           headroom          |  *	                                      l2arc_feed_thread()  *	                                             |  *	                 l2arc write hand<--[oooo]--'  *	                         |           8 Mbyte  *	                         |          write max  *	                         V  *		  +==============================+  *	L2ARC dev |####|#|###|###|    |####| ... |  *	          +==============================+  *	                     32 Gbytes  *  * 3. If an ARC buffer is copied to the L2ARC but then hit instead of  * evicted, then the L2ARC has cached a buffer much sooner than it probably  * needed to, potentially wasting L2ARC device bandwidth and storage.  It is  * safe to say that this is an uncommon case, since buffers at the end of  * the ARC lists have moved there due to inactivity.  *  * 4. If the ARC evicts faster than the L2ARC can maintain a headroom,  * then the L2ARC simply misses copying some buffers.  This serves as a  * pressure valve to prevent heavy read workloads from both stalling the ARC  * with waits and clogging the L2ARC with writes.  This also helps prevent  * the potential for the L2ARC to churn if it attempts to cache content too  * quickly, such as during backups of the entire pool.  *  * 5. After system boot and before the ARC has filled main memory, there are  * no evictions from the ARC and so the tails of the ARC_mfu and ARC_mru  * lists can remain mostly static.  Instead of searching from tail of these  * lists as pictured, the l2arc_feed_thread() will search from the list heads  * for eligible buffers, greatly increasing its chance of finding them.  *  * The L2ARC device write speed is also boosted during this time so that  * the L2ARC warms up faster.  Since there have been no ARC evictions yet,  * there are no L2ARC reads, and no fear of degrading read performance  * through increased writes.  *  * 6. Writes to the L2ARC devices are grouped and sent in-sequence, so that  * the vdev queue can aggregate them into larger and fewer writes.  Each  * device is written to in a rotor fashion, sweeping writes through  * available space then repeating.  *  * 7. The L2ARC does not store dirty content.  It never needs to flush  * write buffers back to disk based storage.  *  * 8. If an ARC buffer is written (and dirtied) which also exists in the  * L2ARC, the now stale L2ARC buffer is immediately dropped.  *  * The performance of the L2ARC can be tweaked by a number of tunables, which  * may be necessary for different workloads:  *  *	l2arc_write_max		max write bytes per interval  *	l2arc_write_boost	extra write bytes during device warmup  *	l2arc_noprefetch	skip caching prefetched buffers  *	l2arc_headroom		number of max device writes to precache  *	l2arc_headroom_boost	when we find compressed buffers during ARC  *				scanning, we multiply headroom by this  *				percentage factor for the next scan cycle,  *				since more compressed buffers are likely to  *				be present  *	l2arc_feed_secs		seconds between L2ARC writing  *  * Tunables may be removed or added as future performance improvements are  * integrated, and also may become zpool properties.  *  * There are three key functions that control how the L2ARC warms up:  *  *	l2arc_write_eligible()	check if a buffer is eligible to cache  *	l2arc_write_size()	calculate how much to write  *	l2arc_write_interval()	calculate sleep delay between writes  *  * These three functions determine what to write, how much, and how quickly  * to send writes.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|l2arc_write_eligible
parameter_list|(
name|uint64_t
name|spa_guid
parameter_list|,
name|arc_buf_hdr_t
modifier|*
name|hdr
parameter_list|)
block|{
comment|/* 	 * A buffer is *not* eligible for the L2ARC if it: 	 * 1. belongs to a different spa. 	 * 2. is already cached on the L2ARC. 	 * 3. has an I/O in progress (it may be an incomplete read). 	 * 4. is flagged not eligible (zfs property). 	 */
if|if
condition|(
name|hdr
operator|->
name|b_spa
operator|!=
name|spa_guid
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_spa_mismatch
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
if|if
condition|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_in_l2
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
if|if
condition|(
name|HDR_IO_IN_PROGRESS
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_hdr_io_in_progress
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
if|if
condition|(
operator|!
name|HDR_L2CACHE
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_not_cacheable
argument_list|)
expr_stmt|;
return|return
operator|(
name|B_FALSE
operator|)
return|;
block|}
return|return
operator|(
name|B_TRUE
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|l2arc_write_size
parameter_list|(
name|void
parameter_list|)
block|{
name|uint64_t
name|size
decl_stmt|;
comment|/* 	 * Make sure our globals have meaningful values in case the user 	 * altered them. 	 */
name|size
operator|=
name|l2arc_write_max
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
block|{
name|cmn_err
argument_list|(
name|CE_NOTE
argument_list|,
literal|"Bad value for l2arc_write_max, value must "
literal|"be greater than zero, resetting it to the default (%d)"
argument_list|,
name|L2ARC_WRITE_SIZE
argument_list|)
expr_stmt|;
name|size
operator|=
name|l2arc_write_max
operator|=
name|L2ARC_WRITE_SIZE
expr_stmt|;
block|}
if|if
condition|(
name|arc_warm
operator|==
name|B_FALSE
condition|)
name|size
operator|+=
name|l2arc_write_boost
expr_stmt|;
return|return
operator|(
name|size
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|clock_t
name|l2arc_write_interval
parameter_list|(
name|clock_t
name|began
parameter_list|,
name|uint64_t
name|wanted
parameter_list|,
name|uint64_t
name|wrote
parameter_list|)
block|{
name|clock_t
name|interval
decl_stmt|,
name|next
decl_stmt|,
name|now
decl_stmt|;
comment|/* 	 * If the ARC lists are busy, increase our write rate; if the 	 * lists are stale, idle back.  This is achieved by checking 	 * how much we previously wrote - if it was more than half of 	 * what we wanted, schedule the next write much sooner. 	 */
if|if
condition|(
name|l2arc_feed_again
operator|&&
name|wrote
operator|>
operator|(
name|wanted
operator|/
literal|2
operator|)
condition|)
name|interval
operator|=
operator|(
name|hz
operator|*
name|l2arc_feed_min_ms
operator|)
operator|/
literal|1000
expr_stmt|;
else|else
name|interval
operator|=
name|hz
operator|*
name|l2arc_feed_secs
expr_stmt|;
name|now
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
name|next
operator|=
name|MAX
argument_list|(
name|now
argument_list|,
name|MIN
argument_list|(
name|now
operator|+
name|interval
argument_list|,
name|began
operator|+
name|interval
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|next
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Cycle through L2ARC devices.  This is how L2ARC load balances.  * If a device is returned, this also returns holding the spa config lock.  */
end_comment

begin_function
specifier|static
name|l2arc_dev_t
modifier|*
name|l2arc_dev_get_next
parameter_list|(
name|void
parameter_list|)
block|{
name|l2arc_dev_t
modifier|*
name|first
decl_stmt|,
modifier|*
name|next
init|=
name|NULL
decl_stmt|;
comment|/* 	 * Lock out the removal of spas (spa_namespace_lock), then removal 	 * of cache devices (l2arc_dev_mtx).  Once a device has been selected, 	 * both locks will be dropped and a spa config lock held instead. 	 */
name|mutex_enter
argument_list|(
operator|&
name|spa_namespace_lock
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
comment|/* if there are no vdevs, there is nothing to do */
if|if
condition|(
name|l2arc_ndev
operator|==
literal|0
condition|)
goto|goto
name|out
goto|;
name|first
operator|=
name|NULL
expr_stmt|;
name|next
operator|=
name|l2arc_dev_last
expr_stmt|;
do|do
block|{
comment|/* loop around the list looking for a non-faulted vdev */
if|if
condition|(
name|next
operator|==
name|NULL
condition|)
block|{
name|next
operator|=
name|list_head
argument_list|(
name|l2arc_dev_list
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|next
operator|=
name|list_next
argument_list|(
name|l2arc_dev_list
argument_list|,
name|next
argument_list|)
expr_stmt|;
if|if
condition|(
name|next
operator|==
name|NULL
condition|)
name|next
operator|=
name|list_head
argument_list|(
name|l2arc_dev_list
argument_list|)
expr_stmt|;
block|}
comment|/* if we have come back to the start, bail out */
if|if
condition|(
name|first
operator|==
name|NULL
condition|)
name|first
operator|=
name|next
expr_stmt|;
elseif|else
if|if
condition|(
name|next
operator|==
name|first
condition|)
break|break;
block|}
do|while
condition|(
name|vdev_is_dead
argument_list|(
name|next
operator|->
name|l2ad_vdev
argument_list|)
condition|)
do|;
comment|/* if we were unable to find any usable vdevs, return NULL */
if|if
condition|(
name|vdev_is_dead
argument_list|(
name|next
operator|->
name|l2ad_vdev
argument_list|)
condition|)
name|next
operator|=
name|NULL
expr_stmt|;
name|l2arc_dev_last
operator|=
name|next
expr_stmt|;
name|out
label|:
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Grab the config lock to prevent the 'next' device from being 	 * removed while we are writing to it. 	 */
if|if
condition|(
name|next
operator|!=
name|NULL
condition|)
name|spa_config_enter
argument_list|(
name|next
operator|->
name|l2ad_spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|next
argument_list|,
name|RW_READER
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|spa_namespace_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|next
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Free buffers that were tagged for destruction.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_do_free_on_write
parameter_list|()
block|{
name|list_t
modifier|*
name|buflist
decl_stmt|;
name|l2arc_data_free_t
modifier|*
name|df
decl_stmt|,
modifier|*
name|df_prev
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|)
expr_stmt|;
name|buflist
operator|=
name|l2arc_free_on_write
expr_stmt|;
for|for
control|(
name|df
operator|=
name|list_tail
argument_list|(
name|buflist
argument_list|)
init|;
name|df
condition|;
name|df
operator|=
name|df_prev
control|)
block|{
name|df_prev
operator|=
name|list_prev
argument_list|(
name|buflist
argument_list|,
name|df
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|df
operator|->
name|l2df_data
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|df
operator|->
name|l2df_type
operator|==
name|ARC_BUFC_METADATA
condition|)
block|{
name|zio_buf_free
argument_list|(
name|df
operator|->
name|l2df_data
argument_list|,
name|df
operator|->
name|l2df_size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|df
operator|->
name|l2df_type
operator|==
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|zio_data_buf_free
argument_list|(
name|df
operator|->
name|l2df_data
argument_list|,
name|df
operator|->
name|l2df_size
argument_list|)
expr_stmt|;
block|}
name|list_remove
argument_list|(
name|buflist
argument_list|,
name|df
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|df
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_data_free_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * A write to a cache device has completed.  Update all headers to allow  * reads from these buffers to begin.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_write_done
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|l2arc_write_callback_t
modifier|*
name|cb
decl_stmt|;
name|l2arc_dev_t
modifier|*
name|dev
decl_stmt|;
name|list_t
modifier|*
name|buflist
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|head
decl_stmt|,
modifier|*
name|hdr
decl_stmt|,
modifier|*
name|hdr_prev
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|int64_t
name|bytes_dropped
init|=
literal|0
decl_stmt|;
name|cb
operator|=
name|zio
operator|->
name|io_private
expr_stmt|;
name|ASSERT3P
argument_list|(
name|cb
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|dev
operator|=
name|cb
operator|->
name|l2wcb_dev
expr_stmt|;
name|ASSERT3P
argument_list|(
name|dev
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|head
operator|=
name|cb
operator|->
name|l2wcb_head
expr_stmt|;
name|ASSERT3P
argument_list|(
name|head
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|buflist
operator|=
operator|&
name|dev
operator|->
name|l2ad_buflist
expr_stmt|;
name|ASSERT3P
argument_list|(
name|buflist
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|DTRACE_PROBE2
argument_list|(
name|l2arc__iodone
argument_list|,
name|zio_t
operator|*
argument_list|,
name|zio
argument_list|,
name|l2arc_write_callback_t
operator|*
argument_list|,
name|cb
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio
operator|->
name|io_error
operator|!=
literal|0
condition|)
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_writes_error
argument_list|)
expr_stmt|;
comment|/* 	 * All writes completed, or an error was hit. 	 */
name|top
label|:
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
for|for
control|(
name|hdr
operator|=
name|list_prev
argument_list|(
name|buflist
argument_list|,
name|head
argument_list|)
init|;
name|hdr
condition|;
name|hdr
operator|=
name|hdr_prev
control|)
block|{
name|hdr_prev
operator|=
name|list_prev
argument_list|(
name|buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* 		 * We cannot use mutex_enter or else we can deadlock 		 * with l2arc_write_buffers (due to swapping the order 		 * the hash lock and l2ad_mtx are taken). 		 */
if|if
condition|(
operator|!
name|mutex_tryenter
argument_list|(
name|hash_lock
argument_list|)
condition|)
block|{
comment|/* 			 * Missed the hash lock. We must retry so we 			 * don't leave the ARC_FLAG_L2_WRITING bit set. 			 */
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_writes_lock_retry
argument_list|)
expr_stmt|;
comment|/* 			 * We don't want to rescan the headers we've 			 * already marked as having been written out, so 			 * we reinsert the head node so we can pick up 			 * where we left off. 			 */
name|list_remove
argument_list|(
name|buflist
argument_list|,
name|head
argument_list|)
expr_stmt|;
name|list_insert_after
argument_list|(
name|buflist
argument_list|,
name|hdr
argument_list|,
name|head
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
comment|/* 			 * We wait for the hash lock to become available 			 * to try and prevent busy waiting, and increase 			 * the chance we'll be able to acquire the lock 			 * the next time around. 			 */
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
goto|goto
name|top
goto|;
block|}
comment|/* 		 * We could not have been moved into the arc_l2c_only 		 * state while in-flight due to our ARC_FLAG_L2_WRITING 		 * bit being set. Let's just ensure that's being enforced. 		 */
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio
operator|->
name|io_error
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * Error - drop L2ARC entry. 			 */
name|list_remove
argument_list|(
name|buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|l2arc_trim
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_HAS_L2HDR
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_asize
argument_list|,
operator|-
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_size
argument_list|,
operator|-
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|bytes_dropped
operator|+=
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_remove_many
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_alloc
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Allow ARC to begin reads and ghost list evictions to 		 * this L2ARC entry. 		 */
name|arc_hdr_clear_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_L2_WRITING
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
name|atomic_inc_64
argument_list|(
operator|&
name|l2arc_writes_done
argument_list|)
expr_stmt|;
name|list_remove
argument_list|(
name|buflist
argument_list|,
name|head
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_HAS_L1HDR
argument_list|(
name|head
argument_list|)
argument_list|)
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|hdr_l2only_cache
argument_list|,
name|head
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|vdev_space_update
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
operator|-
name|bytes_dropped
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|l2arc_do_free_on_write
argument_list|()
expr_stmt|;
name|kmem_free
argument_list|(
name|cb
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_write_callback_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * A read to a cache device completed.  Validate buffer contents before  * handing over to the regular ARC routines.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_read_done
parameter_list|(
name|zio_t
modifier|*
name|zio
parameter_list|)
block|{
name|l2arc_read_callback_t
modifier|*
name|cb
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|boolean_t
name|valid_cksum
decl_stmt|;
name|ASSERT3P
argument_list|(
name|zio
operator|->
name|io_vd
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
name|zio
operator|->
name|io_flags
operator|&
name|ZIO_FLAG_DONT_PROPAGATE
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|zio
operator|->
name|io_spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|zio
operator|->
name|io_vd
argument_list|)
expr_stmt|;
name|cb
operator|=
name|zio
operator|->
name|io_private
expr_stmt|;
name|ASSERT3P
argument_list|(
name|cb
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|hdr
operator|=
name|cb
operator|->
name|l2rcb_hdr
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hash_lock
argument_list|,
operator|==
argument_list|,
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the data was read into a temporary buffer, 	 * move it and free the buffer. 	 */
if|if
condition|(
name|cb
operator|->
name|l2rcb_data
operator|!=
name|NULL
condition|)
block|{
name|ASSERT3U
argument_list|(
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|<
argument_list|,
name|zio
operator|->
name|io_size
argument_list|)
expr_stmt|;
if|if
condition|(
name|zio
operator|->
name|io_error
operator|==
literal|0
condition|)
block|{
name|bcopy
argument_list|(
name|cb
operator|->
name|l2rcb_data
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * The following must be done regardless of whether 		 * there was an error: 		 * - free the temporary buffer 		 * - point zio to the real ARC buffer 		 * - set zio size accordingly 		 * These are required because zio is either re-used for 		 * an I/O of the block in the case of the error 		 * or the zio is passed to arc_read_done() and it 		 * needs real data. 		 */
name|zio_data_buf_free
argument_list|(
name|cb
operator|->
name|l2rcb_data
argument_list|,
name|zio
operator|->
name|io_size
argument_list|)
expr_stmt|;
name|zio
operator|->
name|io_size
operator|=
name|zio
operator|->
name|io_orig_size
operator|=
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|zio
operator|->
name|io_data
operator|=
name|zio
operator|->
name|io_orig_data
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
expr_stmt|;
block|}
name|ASSERT3P
argument_list|(
name|zio
operator|->
name|io_data
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 	 * Check this survived the L2ARC journey. 	 */
name|ASSERT3P
argument_list|(
name|zio
operator|->
name|io_data
argument_list|,
operator|==
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|)
expr_stmt|;
name|zio
operator|->
name|io_bp_copy
operator|=
name|cb
operator|->
name|l2rcb_bp
expr_stmt|;
comment|/* XXX fix in L2ARC 2.0	*/
name|zio
operator|->
name|io_bp
operator|=
operator|&
name|zio
operator|->
name|io_bp_copy
expr_stmt|;
comment|/* XXX fix in L2ARC 2.0	*/
name|valid_cksum
operator|=
name|arc_cksum_is_equal
argument_list|(
name|hdr
argument_list|,
name|zio
argument_list|)
expr_stmt|;
if|if
condition|(
name|valid_cksum
operator|&&
name|zio
operator|->
name|io_error
operator|==
literal|0
operator|&&
operator|!
name|HDR_L2_EVICTED
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|zio
operator|->
name|io_private
operator|=
name|hdr
expr_stmt|;
name|arc_read_done
argument_list|(
name|zio
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
comment|/* 		 * Buffer didn't survive caching.  Increment stats and 		 * reissue to the original storage device. 		 */
if|if
condition|(
name|zio
operator|->
name|io_error
operator|!=
literal|0
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_io_error
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|zio
operator|->
name|io_error
operator|=
name|SET_ERROR
argument_list|(
name|EIO
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|valid_cksum
condition|)
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_cksum_bad
argument_list|)
expr_stmt|;
comment|/* 		 * If there's no waiter, issue an async i/o to the primary 		 * storage now.  If there *is* a waiter, the caller must 		 * issue the i/o in a context where it's OK to block. 		 */
if|if
condition|(
name|zio
operator|->
name|io_waiter
operator|==
name|NULL
condition|)
block|{
name|zio_t
modifier|*
name|pio
init|=
name|zio_unique_parent
argument_list|(
name|zio
argument_list|)
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|pio
operator|||
name|pio
operator|->
name|io_child_type
operator|==
name|ZIO_CHILD_LOGICAL
argument_list|)
expr_stmt|;
name|zio_nowait
argument_list|(
name|zio_read
argument_list|(
name|pio
argument_list|,
name|zio
operator|->
name|io_spa
argument_list|,
name|zio
operator|->
name|io_bp
argument_list|,
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|zio
operator|->
name|io_size
argument_list|,
name|arc_read_done
argument_list|,
name|hdr
argument_list|,
name|zio
operator|->
name|io_priority
argument_list|,
name|cb
operator|->
name|l2rcb_flags
argument_list|,
operator|&
name|cb
operator|->
name|l2rcb_zb
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|kmem_free
argument_list|(
name|cb
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_read_callback_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This is the list priority from which the L2ARC will search for pages to  * cache.  This is used within loops (0..3) to cycle through lists in the  * desired order.  This order can have a significant effect on cache  * performance.  *  * Currently the metadata lists are hit first, MFU then MRU, followed by  * the data lists.  This function returns a locked list, and also returns  * the lock pointer.  */
end_comment

begin_function
specifier|static
name|multilist_sublist_t
modifier|*
name|l2arc_sublist_lock
parameter_list|(
name|int
name|list_num
parameter_list|)
block|{
name|multilist_t
modifier|*
name|ml
init|=
name|NULL
decl_stmt|;
name|unsigned
name|int
name|idx
decl_stmt|;
name|ASSERT
argument_list|(
name|list_num
operator|>=
literal|0
operator|&&
name|list_num
operator|<=
literal|3
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|list_num
condition|)
block|{
case|case
literal|0
case|:
name|ml
operator|=
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
expr_stmt|;
break|break;
case|case
literal|1
case|:
name|ml
operator|=
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_METADATA
index|]
expr_stmt|;
break|break;
case|case
literal|2
case|:
name|ml
operator|=
name|arc_mfu
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
expr_stmt|;
break|break;
case|case
literal|3
case|:
name|ml
operator|=
name|arc_mru
operator|->
name|arcs_list
index|[
name|ARC_BUFC_DATA
index|]
expr_stmt|;
break|break;
block|}
comment|/* 	 * Return a randomly-selected sublist. This is acceptable 	 * because the caller feeds only a little bit of data for each 	 * call (8MB). Subsequent calls will result in different 	 * sublists being selected. 	 */
name|idx
operator|=
name|multilist_get_random_index
argument_list|(
name|ml
argument_list|)
expr_stmt|;
return|return
operator|(
name|multilist_sublist_lock
argument_list|(
name|ml
argument_list|,
name|idx
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Evict buffers from the device write hand to the distance specified in  * bytes.  This distance may span populated buffers, it may span nothing.  * This is clearing a region on the L2ARC device ready for writing.  * If the 'all' boolean is set, every buffer is evicted.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_evict
parameter_list|(
name|l2arc_dev_t
modifier|*
name|dev
parameter_list|,
name|uint64_t
name|distance
parameter_list|,
name|boolean_t
name|all
parameter_list|)
block|{
name|list_t
modifier|*
name|buflist
decl_stmt|;
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|,
modifier|*
name|hdr_prev
decl_stmt|;
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
name|uint64_t
name|taddr
decl_stmt|;
name|buflist
operator|=
operator|&
name|dev
operator|->
name|l2ad_buflist
expr_stmt|;
if|if
condition|(
operator|!
name|all
operator|&&
name|dev
operator|->
name|l2ad_first
condition|)
block|{
comment|/* 		 * This is the first sweep through the device.  There is 		 * nothing to evict. 		 */
return|return;
block|}
if|if
condition|(
name|dev
operator|->
name|l2ad_hand
operator|>=
operator|(
name|dev
operator|->
name|l2ad_end
operator|-
operator|(
literal|2
operator|*
name|distance
operator|)
operator|)
condition|)
block|{
comment|/* 		 * When nearing the end of the device, evict to the end 		 * before the device write hand jumps to the start. 		 */
name|taddr
operator|=
name|dev
operator|->
name|l2ad_end
expr_stmt|;
block|}
else|else
block|{
name|taddr
operator|=
name|dev
operator|->
name|l2ad_hand
operator|+
name|distance
expr_stmt|;
block|}
name|DTRACE_PROBE4
argument_list|(
name|l2arc__evict
argument_list|,
name|l2arc_dev_t
operator|*
argument_list|,
name|dev
argument_list|,
name|list_t
operator|*
argument_list|,
name|buflist
argument_list|,
name|uint64_t
argument_list|,
name|taddr
argument_list|,
name|boolean_t
argument_list|,
name|all
argument_list|)
expr_stmt|;
name|top
label|:
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
for|for
control|(
name|hdr
operator|=
name|list_tail
argument_list|(
name|buflist
argument_list|)
init|;
name|hdr
condition|;
name|hdr
operator|=
name|hdr_prev
control|)
block|{
name|hdr_prev
operator|=
name|list_prev
argument_list|(
name|buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
comment|/* 		 * We cannot use mutex_enter or else we can deadlock 		 * with l2arc_write_buffers (due to swapping the order 		 * the hash lock and l2ad_mtx are taken). 		 */
if|if
condition|(
operator|!
name|mutex_tryenter
argument_list|(
name|hash_lock
argument_list|)
condition|)
block|{
comment|/* 			 * Missed the hash lock.  Retry. 			 */
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_evict_lock_retry
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
goto|goto
name|top
goto|;
block|}
if|if
condition|(
name|HDR_L2_WRITE_HEAD
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
comment|/* 			 * We hit a write head node.  Leave it for 			 * l2arc_write_done(). 			 */
name|list_remove
argument_list|(
name|buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|!
name|all
operator|&&
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
operator|&&
operator|(
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
operator|>=
name|taddr
operator|||
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
operator|<
name|dev
operator|->
name|l2ad_hand
operator|)
condition|)
block|{
comment|/* 			 * We've evicted to the target address, 			 * or the end of the device. 			 */
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
break|break;
block|}
name|ASSERT
argument_list|(
name|HDR_HAS_L2HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ASSERT
argument_list|(
operator|!
name|HDR_L2_READING
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 			 * This doesn't exist in the ARC.  Destroy. 			 * arc_hdr_destroy() will call list_remove() 			 * and decrement arcstat_l2_size. 			 */
name|arc_change_state
argument_list|(
name|arc_anon
argument_list|,
name|hdr
argument_list|,
name|hash_lock
argument_list|)
expr_stmt|;
name|arc_hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_state
operator|!=
name|arc_l2c_only
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_evict_l1cached
argument_list|)
expr_stmt|;
comment|/* 			 * Invalidate issued or about to be issued 			 * reads, since we may be about to write 			 * over this location. 			 */
if|if
condition|(
name|HDR_L2_READING
argument_list|(
name|hdr
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_evict_reading
argument_list|)
expr_stmt|;
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_L2_EVICTED
argument_list|)
expr_stmt|;
block|}
comment|/* Ensure this header has finished being written */
name|ASSERT
argument_list|(
operator|!
name|HDR_L2_WRITING
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|arc_hdr_l2hdr_destroy
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
block|}
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Find and write ARC buffers to the L2ARC device.  *  * An ARC_FLAG_L2_WRITING flag is set so that the L2ARC buffers are not valid  * for reading until they have completed writing.  * The headroom_boost is an in-out parameter used to maintain headroom boost  * state between calls to this function.  *  * Returns the number of bytes actually written (which may be smaller than  * the delta by which the device hand has changed due to alignment).  */
end_comment

begin_function
specifier|static
name|uint64_t
name|l2arc_write_buffers
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|l2arc_dev_t
modifier|*
name|dev
parameter_list|,
name|uint64_t
name|target_sz
parameter_list|)
block|{
name|arc_buf_hdr_t
modifier|*
name|hdr
decl_stmt|,
modifier|*
name|hdr_prev
decl_stmt|,
modifier|*
name|head
decl_stmt|;
name|uint64_t
name|write_asize
decl_stmt|,
name|write_psize
decl_stmt|,
name|write_sz
decl_stmt|,
name|headroom
decl_stmt|;
name|boolean_t
name|full
decl_stmt|;
name|l2arc_write_callback_t
modifier|*
name|cb
decl_stmt|;
name|zio_t
modifier|*
name|pio
decl_stmt|,
modifier|*
name|wzio
decl_stmt|;
name|uint64_t
name|guid
init|=
name|spa_load_guid
argument_list|(
name|spa
argument_list|)
decl_stmt|;
name|int
name|try
decl_stmt|;
name|ASSERT3P
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|pio
operator|=
name|NULL
expr_stmt|;
name|write_sz
operator|=
name|write_asize
operator|=
name|write_psize
operator|=
literal|0
expr_stmt|;
name|full
operator|=
name|B_FALSE
expr_stmt|;
name|head
operator|=
name|kmem_cache_alloc
argument_list|(
name|hdr_l2only_cache
argument_list|,
name|KM_PUSHPAGE
argument_list|)
expr_stmt|;
name|arc_hdr_set_flags
argument_list|(
name|head
argument_list|,
name|ARC_FLAG_L2_WRITE_HEAD
operator||
name|ARC_FLAG_HAS_L2HDR
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_buffer_iter
argument_list|)
expr_stmt|;
comment|/* 	 * Copy buffers for L2ARC writing. 	 */
for|for
control|(
name|try
operator|=
literal|0
init|;
name|try
operator|<=
literal|3
condition|;
name|try
operator|++
control|)
block|{
name|multilist_sublist_t
modifier|*
name|mls
init|=
name|l2arc_sublist_lock
argument_list|(
name|try
argument_list|)
decl_stmt|;
name|uint64_t
name|passed_sz
init|=
literal|0
decl_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_buffer_list_iter
argument_list|)
expr_stmt|;
comment|/* 		 * L2ARC fast warmup. 		 * 		 * Until the ARC is warm and starts to evict, read from the 		 * head of the ARC lists rather than the tail. 		 */
if|if
condition|(
name|arc_warm
operator|==
name|B_FALSE
condition|)
name|hdr
operator|=
name|multilist_sublist_head
argument_list|(
name|mls
argument_list|)
expr_stmt|;
else|else
name|hdr
operator|=
name|multilist_sublist_tail
argument_list|(
name|mls
argument_list|)
expr_stmt|;
if|if
condition|(
name|hdr
operator|==
name|NULL
condition|)
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_buffer_list_null_iter
argument_list|)
expr_stmt|;
name|headroom
operator|=
name|target_sz
operator|*
name|l2arc_headroom
expr_stmt|;
if|if
condition|(
name|zfs_compressed_arc_enabled
condition|)
name|headroom
operator|=
operator|(
name|headroom
operator|*
name|l2arc_headroom_boost
operator|)
operator|/
literal|100
expr_stmt|;
for|for
control|(
init|;
name|hdr
condition|;
name|hdr
operator|=
name|hdr_prev
control|)
block|{
name|kmutex_t
modifier|*
name|hash_lock
decl_stmt|;
if|if
condition|(
name|arc_warm
operator|==
name|B_FALSE
condition|)
name|hdr_prev
operator|=
name|multilist_sublist_next
argument_list|(
name|mls
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
else|else
name|hdr_prev
operator|=
name|multilist_sublist_prev
argument_list|(
name|mls
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_write_buffer_bytes_scanned
argument_list|,
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|hash_lock
operator|=
name|HDR_LOCK
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|mutex_tryenter
argument_list|(
name|hash_lock
argument_list|)
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_trylock_fail
argument_list|)
expr_stmt|;
comment|/* 				 * Skip this buffer rather than waiting. 				 */
continue|continue;
block|}
name|passed_sz
operator|+=
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
if|if
condition|(
name|passed_sz
operator|>
name|headroom
condition|)
block|{
comment|/* 				 * Searched too far. 				 */
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_passed_headroom
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
operator|!
name|l2arc_write_eligible
argument_list|(
name|guid
argument_list|,
name|hdr
argument_list|)
condition|)
block|{
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 			 * We rely on the L1 portion of the header below, so 			 * it's invalid for this header to have been evicted out 			 * of the ghost cache, prior to being written out. The 			 * ARC_FLAG_L2_WRITING bit ensures this won't happen. 			 */
name|ASSERT
argument_list|(
name|HDR_HAS_L1HDR
argument_list|(
name|hdr
argument_list|)
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|HDR_GET_PSIZE
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|ASSERT3P
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ASSERT3U
argument_list|(
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
argument_list|,
operator|>
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|uint64_t
name|size
init|=
name|arc_hdr_size
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
name|uint64_t
name|asize
init|=
name|vdev_psize_to_asize
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|size
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|write_psize
operator|+
name|asize
operator|)
operator|>
name|target_sz
condition|)
block|{
name|full
operator|=
name|B_TRUE
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_full
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|pio
operator|==
name|NULL
condition|)
block|{
comment|/* 				 * Insert a dummy header on the buflist so 				 * l2arc_write_done() can find where the 				 * write buffers begin without searching. 				 */
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|list_insert_head
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|head
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|cb
operator|=
name|kmem_alloc
argument_list|(
sizeof|sizeof
argument_list|(
name|l2arc_write_callback_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|cb
operator|->
name|l2wcb_dev
operator|=
name|dev
expr_stmt|;
name|cb
operator|->
name|l2wcb_head
operator|=
name|head
expr_stmt|;
name|pio
operator|=
name|zio_root
argument_list|(
name|spa
argument_list|,
name|l2arc_write_done
argument_list|,
name|cb
argument_list|,
name|ZIO_FLAG_CANFAIL
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_write_pios
argument_list|)
expr_stmt|;
block|}
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_dev
operator|=
name|dev
expr_stmt|;
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
operator|=
name|dev
operator|->
name|l2ad_hand
expr_stmt|;
name|arc_hdr_set_flags
argument_list|(
name|hdr
argument_list|,
name|ARC_FLAG_L2_WRITING
operator||
name|ARC_FLAG_HAS_L2HDR
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|list_insert_head
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_buflist
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|refcount_add_many
argument_list|(
operator|&
name|dev
operator|->
name|l2ad_alloc
argument_list|,
name|size
argument_list|,
name|hdr
argument_list|)
expr_stmt|;
comment|/* 			 * Normally the L2ARC can use the hdr's data, but if 			 * we're sharing data between the hdr and one of its 			 * bufs, L2ARC needs its own copy of the data so that 			 * the ZIO below can't race with the buf consumer. To 			 * ensure that this copy will be available for the 			 * lifetime of the ZIO and be cleaned up afterwards, we 			 * add it to the l2arc_free_on_write queue. 			 */
name|void
modifier|*
name|to_write
decl_stmt|;
if|if
condition|(
operator|!
name|HDR_SHARED_DATA
argument_list|(
name|hdr
argument_list|)
operator|&&
name|size
operator|==
name|asize
condition|)
block|{
name|to_write
operator|=
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
expr_stmt|;
block|}
else|else
block|{
name|arc_buf_contents_t
name|type
init|=
name|arc_buf_type
argument_list|(
name|hdr
argument_list|)
decl_stmt|;
if|if
condition|(
name|type
operator|==
name|ARC_BUFC_METADATA
condition|)
block|{
name|to_write
operator|=
name|zio_buf_alloc
argument_list|(
name|asize
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT3U
argument_list|(
name|type
argument_list|,
operator|==
argument_list|,
name|ARC_BUFC_DATA
argument_list|)
expr_stmt|;
name|to_write
operator|=
name|zio_data_buf_alloc
argument_list|(
name|asize
argument_list|)
expr_stmt|;
block|}
name|bcopy
argument_list|(
name|hdr
operator|->
name|b_l1hdr
operator|.
name|b_pdata
argument_list|,
name|to_write
argument_list|,
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|asize
operator|!=
name|size
condition|)
name|bzero
argument_list|(
name|to_write
operator|+
name|size
argument_list|,
name|asize
operator|-
name|size
argument_list|)
expr_stmt|;
name|l2arc_free_data_on_write
argument_list|(
name|to_write
argument_list|,
name|asize
argument_list|,
name|type
argument_list|)
expr_stmt|;
block|}
name|wzio
operator|=
name|zio_write_phys
argument_list|(
name|pio
argument_list|,
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|hdr
operator|->
name|b_l2hdr
operator|.
name|b_daddr
argument_list|,
name|asize
argument_list|,
name|to_write
argument_list|,
name|ZIO_CHECKSUM_OFF
argument_list|,
name|NULL
argument_list|,
name|hdr
argument_list|,
name|ZIO_PRIORITY_ASYNC_WRITE
argument_list|,
name|ZIO_FLAG_CANFAIL
argument_list|,
name|B_FALSE
argument_list|)
expr_stmt|;
name|write_sz
operator|+=
name|HDR_GET_LSIZE
argument_list|(
name|hdr
argument_list|)
expr_stmt|;
name|DTRACE_PROBE2
argument_list|(
name|l2arc__write
argument_list|,
name|vdev_t
operator|*
argument_list|,
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|zio_t
operator|*
argument_list|,
name|wzio
argument_list|)
expr_stmt|;
name|write_asize
operator|+=
name|size
expr_stmt|;
name|write_psize
operator|+=
name|asize
expr_stmt|;
name|dev
operator|->
name|l2ad_hand
operator|+=
name|asize
expr_stmt|;
name|mutex_exit
argument_list|(
name|hash_lock
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|zio_nowait
argument_list|(
name|wzio
argument_list|)
expr_stmt|;
block|}
name|multilist_sublist_unlock
argument_list|(
name|mls
argument_list|)
expr_stmt|;
if|if
condition|(
name|full
operator|==
name|B_TRUE
condition|)
break|break;
block|}
comment|/* No buffers selected for writing? */
if|if
condition|(
name|pio
operator|==
name|NULL
condition|)
block|{
name|ASSERT0
argument_list|(
name|write_sz
argument_list|)
expr_stmt|;
name|ASSERT
argument_list|(
operator|!
name|HDR_HAS_L1HDR
argument_list|(
name|head
argument_list|)
argument_list|)
expr_stmt|;
name|kmem_cache_free
argument_list|(
name|hdr_l2only_cache
argument_list|,
name|head
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|ASSERT3U
argument_list|(
name|write_psize
argument_list|,
operator|<=
argument_list|,
name|target_sz
argument_list|)
expr_stmt|;
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_writes_sent
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_write_bytes
argument_list|,
name|write_asize
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_size
argument_list|,
name|write_sz
argument_list|)
expr_stmt|;
name|ARCSTAT_INCR
argument_list|(
name|arcstat_l2_asize
argument_list|,
name|write_asize
argument_list|)
expr_stmt|;
name|vdev_space_update
argument_list|(
name|dev
operator|->
name|l2ad_vdev
argument_list|,
name|write_asize
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * Bump device hand to the device start if it is approaching the end. 	 * l2arc_evict() will already have evicted ahead for this case. 	 */
if|if
condition|(
name|dev
operator|->
name|l2ad_hand
operator|>=
operator|(
name|dev
operator|->
name|l2ad_end
operator|-
name|target_sz
operator|)
condition|)
block|{
name|dev
operator|->
name|l2ad_hand
operator|=
name|dev
operator|->
name|l2ad_start
expr_stmt|;
name|dev
operator|->
name|l2ad_first
operator|=
name|B_FALSE
expr_stmt|;
block|}
name|dev
operator|->
name|l2ad_writing
operator|=
name|B_TRUE
expr_stmt|;
operator|(
name|void
operator|)
name|zio_wait
argument_list|(
name|pio
argument_list|)
expr_stmt|;
name|dev
operator|->
name|l2ad_writing
operator|=
name|B_FALSE
expr_stmt|;
return|return
operator|(
name|write_asize
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This thread feeds the L2ARC at regular intervals.  This is the beating  * heart of the L2ARC.  */
end_comment

begin_function
specifier|static
name|void
name|l2arc_feed_thread
parameter_list|(
name|void
modifier|*
name|dummy
name|__unused
parameter_list|)
block|{
name|callb_cpr_t
name|cpr
decl_stmt|;
name|l2arc_dev_t
modifier|*
name|dev
decl_stmt|;
name|spa_t
modifier|*
name|spa
decl_stmt|;
name|uint64_t
name|size
decl_stmt|,
name|wrote
decl_stmt|;
name|clock_t
name|begin
decl_stmt|,
name|next
init|=
name|ddi_get_lbolt
argument_list|()
decl_stmt|;
name|CALLB_CPR_INIT
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|l2arc_feed_thr_lock
argument_list|,
name|callb_generic_cpr
argument_list|,
name|FTAG
argument_list|)
expr_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
while|while
condition|(
name|l2arc_thread_exit
operator|==
literal|0
condition|)
block|{
name|CALLB_CPR_SAFE_BEGIN
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|cv_timedwait
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|,
operator|&
name|l2arc_feed_thr_lock
argument_list|,
name|next
operator|-
name|ddi_get_lbolt
argument_list|()
argument_list|)
expr_stmt|;
name|CALLB_CPR_SAFE_END
argument_list|(
operator|&
name|cpr
argument_list|,
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
name|next
operator|=
name|ddi_get_lbolt
argument_list|()
operator|+
name|hz
expr_stmt|;
comment|/* 		 * Quick check for L2ARC devices. 		 */
name|mutex_enter
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2arc_ndev
operator|==
literal|0
condition|)
block|{
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
name|begin
operator|=
name|ddi_get_lbolt
argument_list|()
expr_stmt|;
comment|/* 		 * This selects the next l2arc device to write to, and in 		 * doing so the next spa to feed from: dev->l2ad_spa.   This 		 * will return NULL if there are now no l2arc devices or if 		 * they are all faulted. 		 * 		 * If a device is returned, its spa's config lock is also 		 * held to prevent device removal.  l2arc_dev_get_next() 		 * will grab and release l2arc_dev_mtx. 		 */
if|if
condition|(
operator|(
name|dev
operator|=
name|l2arc_dev_get_next
argument_list|()
operator|)
operator|==
name|NULL
condition|)
continue|continue;
name|spa
operator|=
name|dev
operator|->
name|l2ad_spa
expr_stmt|;
name|ASSERT3P
argument_list|(
name|spa
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 		 * If the pool is read-only then force the feed thread to 		 * sleep a little longer. 		 */
if|if
condition|(
operator|!
name|spa_writeable
argument_list|(
name|spa
argument_list|)
condition|)
block|{
name|next
operator|=
name|ddi_get_lbolt
argument_list|()
operator|+
literal|5
operator|*
name|l2arc_feed_secs
operator|*
name|hz
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|dev
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Avoid contributing to memory pressure. 		 */
if|if
condition|(
name|arc_reclaim_needed
argument_list|()
condition|)
block|{
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_abort_lowmem
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|dev
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|ARCSTAT_BUMP
argument_list|(
name|arcstat_l2_feeds
argument_list|)
expr_stmt|;
name|size
operator|=
name|l2arc_write_size
argument_list|()
expr_stmt|;
comment|/* 		 * Evict L2ARC buffers that will be overwritten. 		 */
name|l2arc_evict
argument_list|(
name|dev
argument_list|,
name|size
argument_list|,
name|B_FALSE
argument_list|)
expr_stmt|;
comment|/* 		 * Write ARC buffers. 		 */
name|wrote
operator|=
name|l2arc_write_buffers
argument_list|(
name|spa
argument_list|,
name|dev
argument_list|,
name|size
argument_list|)
expr_stmt|;
comment|/* 		 * Calculate interval between writes. 		 */
name|next
operator|=
name|l2arc_write_interval
argument_list|(
name|begin
argument_list|,
name|size
argument_list|,
name|wrote
argument_list|)
expr_stmt|;
name|spa_config_exit
argument_list|(
name|spa
argument_list|,
name|SCL_L2ARC
argument_list|,
name|dev
argument_list|)
expr_stmt|;
block|}
name|l2arc_thread_exit
operator|=
literal|0
expr_stmt|;
name|cv_broadcast
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|)
expr_stmt|;
name|CALLB_CPR_EXIT
argument_list|(
operator|&
name|cpr
argument_list|)
expr_stmt|;
comment|/* drops l2arc_feed_thr_lock */
name|thread_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|boolean_t
name|l2arc_vdev_present
parameter_list|(
name|vdev_t
modifier|*
name|vd
parameter_list|)
block|{
name|l2arc_dev_t
modifier|*
name|dev
decl_stmt|;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
for|for
control|(
name|dev
operator|=
name|list_head
argument_list|(
name|l2arc_dev_list
argument_list|)
init|;
name|dev
operator|!=
name|NULL
condition|;
name|dev
operator|=
name|list_next
argument_list|(
name|l2arc_dev_list
argument_list|,
name|dev
argument_list|)
control|)
block|{
if|if
condition|(
name|dev
operator|->
name|l2ad_vdev
operator|==
name|vd
condition|)
break|break;
block|}
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|dev
operator|!=
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Add a vdev for use by the L2ARC.  By this point the spa has already  * validated the vdev and opened it.  */
end_comment

begin_function
name|void
name|l2arc_add_vdev
parameter_list|(
name|spa_t
modifier|*
name|spa
parameter_list|,
name|vdev_t
modifier|*
name|vd
parameter_list|)
block|{
name|l2arc_dev_t
modifier|*
name|adddev
decl_stmt|;
name|ASSERT
argument_list|(
operator|!
name|l2arc_vdev_present
argument_list|(
name|vd
argument_list|)
argument_list|)
expr_stmt|;
name|vdev_ashift_optimize
argument_list|(
name|vd
argument_list|)
expr_stmt|;
comment|/* 	 * Create a new l2arc device entry. 	 */
name|adddev
operator|=
name|kmem_zalloc
argument_list|(
sizeof|sizeof
argument_list|(
name|l2arc_dev_t
argument_list|)
argument_list|,
name|KM_SLEEP
argument_list|)
expr_stmt|;
name|adddev
operator|->
name|l2ad_spa
operator|=
name|spa
expr_stmt|;
name|adddev
operator|->
name|l2ad_vdev
operator|=
name|vd
expr_stmt|;
name|adddev
operator|->
name|l2ad_start
operator|=
name|VDEV_LABEL_START_SIZE
expr_stmt|;
name|adddev
operator|->
name|l2ad_end
operator|=
name|VDEV_LABEL_START_SIZE
operator|+
name|vdev_get_min_asize
argument_list|(
name|vd
argument_list|)
expr_stmt|;
name|adddev
operator|->
name|l2ad_hand
operator|=
name|adddev
operator|->
name|l2ad_start
expr_stmt|;
name|adddev
operator|->
name|l2ad_first
operator|=
name|B_TRUE
expr_stmt|;
name|adddev
operator|->
name|l2ad_writing
operator|=
name|B_FALSE
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|adddev
operator|->
name|l2ad_mtx
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 	 * This is a list of all ARC buffers that are still valid on the 	 * device. 	 */
name|list_create
argument_list|(
operator|&
name|adddev
operator|->
name|l2ad_buflist
argument_list|,
sizeof|sizeof
argument_list|(
name|arc_buf_hdr_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|arc_buf_hdr_t
argument_list|,
name|b_l2hdr
operator|.
name|b_l2node
argument_list|)
argument_list|)
expr_stmt|;
name|vdev_space_update
argument_list|(
name|vd
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|adddev
operator|->
name|l2ad_end
operator|-
name|adddev
operator|->
name|l2ad_hand
argument_list|)
expr_stmt|;
name|refcount_create
argument_list|(
operator|&
name|adddev
operator|->
name|l2ad_alloc
argument_list|)
expr_stmt|;
comment|/* 	 * Add device to global list 	 */
name|mutex_enter
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
name|list_insert_head
argument_list|(
name|l2arc_dev_list
argument_list|,
name|adddev
argument_list|)
expr_stmt|;
name|atomic_inc_64
argument_list|(
operator|&
name|l2arc_ndev
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove a vdev from the L2ARC.  */
end_comment

begin_function
name|void
name|l2arc_remove_vdev
parameter_list|(
name|vdev_t
modifier|*
name|vd
parameter_list|)
block|{
name|l2arc_dev_t
modifier|*
name|dev
decl_stmt|,
modifier|*
name|nextdev
decl_stmt|,
modifier|*
name|remdev
init|=
name|NULL
decl_stmt|;
comment|/* 	 * Find the device by vdev 	 */
name|mutex_enter
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
for|for
control|(
name|dev
operator|=
name|list_head
argument_list|(
name|l2arc_dev_list
argument_list|)
init|;
name|dev
condition|;
name|dev
operator|=
name|nextdev
control|)
block|{
name|nextdev
operator|=
name|list_next
argument_list|(
name|l2arc_dev_list
argument_list|,
name|dev
argument_list|)
expr_stmt|;
if|if
condition|(
name|vd
operator|==
name|dev
operator|->
name|l2ad_vdev
condition|)
block|{
name|remdev
operator|=
name|dev
expr_stmt|;
break|break;
block|}
block|}
name|ASSERT3P
argument_list|(
name|remdev
argument_list|,
operator|!=
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 	 * Remove device from global list 	 */
name|list_remove
argument_list|(
name|l2arc_dev_list
argument_list|,
name|remdev
argument_list|)
expr_stmt|;
name|l2arc_dev_last
operator|=
name|NULL
expr_stmt|;
comment|/* may have been invalidated */
name|atomic_dec_64
argument_list|(
operator|&
name|l2arc_ndev
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Clear all buflists and ARC references.  L2ARC device flush. 	 */
name|l2arc_evict
argument_list|(
name|remdev
argument_list|,
literal|0
argument_list|,
name|B_TRUE
argument_list|)
expr_stmt|;
name|list_destroy
argument_list|(
operator|&
name|remdev
operator|->
name|l2ad_buflist
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|remdev
operator|->
name|l2ad_mtx
argument_list|)
expr_stmt|;
name|refcount_destroy
argument_list|(
operator|&
name|remdev
operator|->
name|l2ad_alloc
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|remdev
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_dev_t
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|l2arc_init
parameter_list|(
name|void
parameter_list|)
block|{
name|l2arc_thread_exit
operator|=
literal|0
expr_stmt|;
name|l2arc_ndev
operator|=
literal|0
expr_stmt|;
name|l2arc_writes_sent
operator|=
literal|0
expr_stmt|;
name|l2arc_writes_done
operator|=
literal|0
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|l2arc_feed_thr_lock
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|cv_init
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|,
name|NULL
argument_list|,
name|CV_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|mutex_init
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|,
name|NULL
argument_list|,
name|MUTEX_DEFAULT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|l2arc_dev_list
operator|=
operator|&
name|L2ARC_dev_list
expr_stmt|;
name|l2arc_free_on_write
operator|=
operator|&
name|L2ARC_free_on_write
expr_stmt|;
name|list_create
argument_list|(
name|l2arc_dev_list
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_dev_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|l2arc_dev_t
argument_list|,
name|l2ad_node
argument_list|)
argument_list|)
expr_stmt|;
name|list_create
argument_list|(
name|l2arc_free_on_write
argument_list|,
sizeof|sizeof
argument_list|(
name|l2arc_data_free_t
argument_list|)
argument_list|,
name|offsetof
argument_list|(
name|l2arc_data_free_t
argument_list|,
name|l2df_list_node
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|l2arc_fini
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * This is called from dmu_fini(), which is called from spa_fini(); 	 * Because of this, we can assume that all l2arc devices have 	 * already been removed when the pools themselves were removed. 	 */
name|l2arc_do_free_on_write
argument_list|()
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
name|cv_destroy
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|l2arc_dev_mtx
argument_list|)
expr_stmt|;
name|mutex_destroy
argument_list|(
operator|&
name|l2arc_free_on_write_mtx
argument_list|)
expr_stmt|;
name|list_destroy
argument_list|(
name|l2arc_dev_list
argument_list|)
expr_stmt|;
name|list_destroy
argument_list|(
name|l2arc_free_on_write
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|l2arc_start
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|spa_mode_global
operator|&
name|FWRITE
operator|)
condition|)
return|return;
operator|(
name|void
operator|)
name|thread_create
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|l2arc_feed_thread
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
operator|&
name|p0
argument_list|,
name|TS_RUN
argument_list|,
name|minclsyspri
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|l2arc_stop
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|spa_mode_global
operator|&
name|FWRITE
operator|)
condition|)
return|return;
name|mutex_enter
argument_list|(
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
name|cv_signal
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|)
expr_stmt|;
comment|/* kick thread out of startup */
name|l2arc_thread_exit
operator|=
literal|1
expr_stmt|;
while|while
condition|(
name|l2arc_thread_exit
operator|!=
literal|0
condition|)
name|cv_wait
argument_list|(
operator|&
name|l2arc_feed_thr_cv
argument_list|,
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
name|mutex_exit
argument_list|(
operator|&
name|l2arc_feed_thr_lock
argument_list|)
expr_stmt|;
block|}
end_function

end_unit

