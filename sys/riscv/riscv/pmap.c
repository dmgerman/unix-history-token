begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * SPDX-License-Identifier: BSD-4-Clause  *  * Copyright (c) 1991 Regents of the University of California.  * All rights reserved.  * Copyright (c) 1994 John S. Dyson  * All rights reserved.  * Copyright (c) 1994 David Greenman  * All rights reserved.  * Copyright (c) 2003 Peter Wemm  * All rights reserved.  * Copyright (c) 2005-2010 Alan L. Cox<alc@cs.rice.edu>  * All rights reserved.  * Copyright (c) 2014 Andrew Turner  * All rights reserved.  * Copyright (c) 2014 The FreeBSD Foundation  * All rights reserved.  * Copyright (c) 2015-2017 Ruslan Bukin<br@bsdpad.com>  * All rights reserved.  *  * This code is derived from software contributed to Berkeley by  * the Systems Programming Group of the University of Utah Computer  * Science Department and William Jolitz of UUNET Technologies Inc.  *  * Portions of this software were developed by Andrew Turner under  * sponsorship from The FreeBSD Foundation.  *  * Portions of this software were developed by SRI International and the  * University of Cambridge Computer Laboratory under DARPA/AFRL contract  * FA8750-10-C-0237 ("CTSRD"), as part of the DARPA CRASH research programme.  *  * Portions of this software were developed by the University of Cambridge  * Computer Laboratory as part of the CTSRD Project, with support from the  * UK Higher Education Innovation Fund (HEIF).  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. All advertising materials mentioning features or use of this software  *    must display the following acknowledgement:  *	This product includes software developed by the University of  *	California, Berkeley and its contributors.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from:	@(#)pmap.c	7.7 (Berkeley)	5/12/91  */
end_comment

begin_comment
comment|/*-  * Copyright (c) 2003 Networks Associates Technology, Inc.  * All rights reserved.  *  * This software was developed for the FreeBSD Project by Jake Burkholder,  * Safeport Network Services, and Network Associates Laboratories, the  * Security Research Division of Network Associates, Inc. under  * DARPA/SPAWAR contract N66001-01-C-8035 ("CBOSS"), as part of the DARPA  * CHATS research program.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *	Manages physical address maps.  *  *	Since the information managed by this module is  *	also stored by the logical address mapping module,  *	this module may throw away valid virtual-to-physical  *	mappings at almost any time.  However, invalidations  *	of virtual-to-physical mappings must be done as  *	requested.  *  *	In order to cope with hardware architectures which  *	make virtual-to-physical map invalidates expensive,  *	this module may delay invalidate or reduced protection  *	operations until such time as they are actually  *	necessary.  This module is given full information as  *	to which processors are currently using which maps,  *	and to when physical maps must be made correct.  */
end_comment

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/bus.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mman.h>
end_include

begin_include
include|#
directive|include
file|<sys/msgbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmem.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_radix.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_reserv.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<machine/machdep.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_include
include|#
directive|include
file|<machine/pcb.h>
end_include

begin_define
define|#
directive|define
name|NPDEPG
value|(PAGE_SIZE/(sizeof (pd_entry_t)))
end_define

begin_define
define|#
directive|define
name|NUPDE
value|(NPDEPG * NPDEPG)
end_define

begin_define
define|#
directive|define
name|NUSERPGTBLS
value|(NUPDE + NPDEPG)
end_define

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|DIAGNOSTIC
argument_list|)
end_if

begin_ifdef
ifdef|#
directive|ifdef
name|__GNUC_GNU_INLINE__
end_ifdef

begin_define
define|#
directive|define
name|PMAP_INLINE
value|__attribute__((__gnu_inline__)) inline
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PMAP_INLINE
value|extern inline
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PMAP_INLINE
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|PV_STATS
end_ifdef

begin_define
define|#
directive|define
name|PV_STAT
parameter_list|(
name|x
parameter_list|)
value|do { x ; } while (0)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PV_STAT
parameter_list|(
name|x
parameter_list|)
value|do { } while (0)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|pmap_l2_pindex
parameter_list|(
name|v
parameter_list|)
value|((v)>> L2_SHIFT)
end_define

begin_define
define|#
directive|define
name|NPV_LIST_LOCKS
value|MAXCPU
end_define

begin_define
define|#
directive|define
name|PHYS_TO_PV_LIST_LOCK
parameter_list|(
name|pa
parameter_list|)
define|\
value|(&pv_list_locks[pa_index(pa) % NPV_LIST_LOCKS])
end_define

begin_define
define|#
directive|define
name|CHANGE_PV_LIST_LOCK_TO_PHYS
parameter_list|(
name|lockp
parameter_list|,
name|pa
parameter_list|)
value|do {	\ 	struct rwlock **_lockp = (lockp);		\ 	struct rwlock *_new_lock;			\ 							\ 	_new_lock = PHYS_TO_PV_LIST_LOCK(pa);		\ 	if (_new_lock != *_lockp) {			\ 		if (*_lockp != NULL)			\ 			rw_wunlock(*_lockp);		\ 		*_lockp = _new_lock;			\ 		rw_wlock(*_lockp);			\ 	}						\ } while (0)
end_define

begin_define
define|#
directive|define
name|CHANGE_PV_LIST_LOCK_TO_VM_PAGE
parameter_list|(
name|lockp
parameter_list|,
name|m
parameter_list|)
define|\
value|CHANGE_PV_LIST_LOCK_TO_PHYS(lockp, VM_PAGE_TO_PHYS(m))
end_define

begin_define
define|#
directive|define
name|RELEASE_PV_LIST_LOCK
parameter_list|(
name|lockp
parameter_list|)
value|do {	\ 	struct rwlock **_lockp = (lockp);		\ 							\ 	if (*_lockp != NULL) {				\ 		rw_wunlock(*_lockp);			\ 		*_lockp = NULL;				\ 	}						\ } while (0)
end_define

begin_define
define|#
directive|define
name|VM_PAGE_TO_PV_LIST_LOCK
parameter_list|(
name|m
parameter_list|)
define|\
value|PHYS_TO_PV_LIST_LOCK(VM_PAGE_TO_PHYS(m))
end_define

begin_comment
comment|/* The list of all the user pmaps */
end_comment

begin_expr_stmt
name|LIST_HEAD
argument_list|(
name|pmaplist
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|pmaplist
name|allpmaps
decl_stmt|;
end_decl_stmt

begin_expr_stmt
specifier|static
name|MALLOC_DEFINE
argument_list|(
name|M_VMPMAP
argument_list|,
literal|"pmap"
argument_list|,
literal|"PMAP L1"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|struct
name|pmap
name|kernel_pmap_store
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|virtual_avail
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* VA of first avail page (after kernel bss) */
end_comment

begin_decl_stmt
name|vm_offset_t
name|virtual_end
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* VA of last avail page (end of kernel AS) */
end_comment

begin_decl_stmt
name|vm_offset_t
name|kernel_vm_end
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|msgbuf
modifier|*
name|msgbufp
init|=
name|NULL
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_paddr_t
name|dmap_phys_base
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* The start of the dmap region */
end_comment

begin_decl_stmt
name|vm_paddr_t
name|dmap_phys_max
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* The limit of the dmap region */
end_comment

begin_decl_stmt
name|vm_offset_t
name|dmap_max_addr
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* The virtual address limit of the dmap */
end_comment

begin_comment
comment|/* This code assumes all L1 DMAP entries will be used */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
operator|(
name|DMAP_MIN_ADDRESS
operator|&
operator|~
name|L1_OFFSET
operator|)
operator|==
name|DMAP_MIN_ADDRESS
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
operator|(
name|DMAP_MAX_ADDRESS
operator|&
operator|~
name|L1_OFFSET
operator|)
operator|==
name|DMAP_MAX_ADDRESS
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|rwlock_padalign
name|pvh_global_lock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Data for the pv entry allocation mechanism  */
end_comment

begin_expr_stmt
specifier|static
name|TAILQ_HEAD
argument_list|(
argument|pch
argument_list|,
argument|pv_chunk
argument_list|)
name|pv_chunks
operator|=
name|TAILQ_HEAD_INITIALIZER
argument_list|(
name|pv_chunks
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|pv_chunks_mutex
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|rwlock
name|pv_list_locks
index|[
name|NPV_LIST_LOCKS
index|]
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|void
name|free_pv_chunk
parameter_list|(
name|struct
name|pv_chunk
modifier|*
name|pc
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|free_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pv_entry_t
name|pv
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|pv_entry_t
name|get_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|reclaim_pv_chunk
parameter_list|(
name|pmap_t
name|locked_pmap
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pvh_free
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|pv_entry_t
name|pmap_pvh_remove
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|pmap_enter_quick_locked
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|vm_page_t
name|mpte
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_remove_l3
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt_entry_t
modifier|*
name|l3
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|pd_entry_t
name|ptepde
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_try_insert_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|_pmap_alloc_l3
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_pindex_t
name|ptepindex
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|_pmap_unwire_l3
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_unuse_l3
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|pd_entry_t
parameter_list|,
name|struct
name|spglist
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * These load the old table data and store the new value.  * They need to be atomic as the System MMU may write to the table at  * the same time as the CPU.  */
end_comment

begin_define
define|#
directive|define
name|pmap_load_store
parameter_list|(
name|table
parameter_list|,
name|entry
parameter_list|)
value|atomic_swap_64(table, entry)
end_define

begin_define
define|#
directive|define
name|pmap_set
parameter_list|(
name|table
parameter_list|,
name|mask
parameter_list|)
value|atomic_set_64(table, mask)
end_define

begin_define
define|#
directive|define
name|pmap_load_clear
parameter_list|(
name|table
parameter_list|)
value|atomic_swap_64(table, 0)
end_define

begin_define
define|#
directive|define
name|pmap_load
parameter_list|(
name|table
parameter_list|)
value|(*table)
end_define

begin_comment
comment|/********************/
end_comment

begin_comment
comment|/* Inline functions */
end_comment

begin_comment
comment|/********************/
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pagecopy
parameter_list|(
name|void
modifier|*
name|s
parameter_list|,
name|void
modifier|*
name|d
parameter_list|)
block|{
name|memcpy
argument_list|(
name|d
argument_list|,
name|s
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pagezero
parameter_list|(
name|void
modifier|*
name|p
parameter_list|)
block|{
name|bzero
argument_list|(
name|p
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_define
define|#
directive|define
name|pmap_l1_index
parameter_list|(
name|va
parameter_list|)
value|(((va)>> L1_SHIFT)& Ln_ADDR_MASK)
end_define

begin_define
define|#
directive|define
name|pmap_l2_index
parameter_list|(
name|va
parameter_list|)
value|(((va)>> L2_SHIFT)& Ln_ADDR_MASK)
end_define

begin_define
define|#
directive|define
name|pmap_l3_index
parameter_list|(
name|va
parameter_list|)
value|(((va)>> L3_SHIFT)& Ln_ADDR_MASK)
end_define

begin_define
define|#
directive|define
name|PTE_TO_PHYS
parameter_list|(
name|pte
parameter_list|)
value|((pte>> PTE_PPN0_S) * PAGE_SIZE)
end_define

begin_function
specifier|static
name|__inline
name|pd_entry_t
modifier|*
name|pmap_l1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
return|return
operator|(
operator|&
name|pmap
operator|->
name|pm_l1
index|[
name|pmap_l1_index
argument_list|(
name|va
argument_list|)
index|]
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pd_entry_t
modifier|*
name|pmap_l1_to_l2
parameter_list|(
name|pd_entry_t
modifier|*
name|l1
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|vm_paddr_t
name|phys
decl_stmt|;
name|pd_entry_t
modifier|*
name|l2
decl_stmt|;
name|phys
operator|=
name|PTE_TO_PHYS
argument_list|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
argument_list|)
expr_stmt|;
name|l2
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|phys
argument_list|)
expr_stmt|;
return|return
operator|(
operator|&
name|l2
index|[
name|pmap_l2_index
argument_list|(
name|va
argument_list|)
index|]
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pd_entry_t
modifier|*
name|pmap_l2
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|l1
decl_stmt|;
name|l1
operator|=
name|pmap_l1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|l1
operator|==
name|NULL
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
if|if
condition|(
operator|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
operator|&
name|PTE_V
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
if|if
condition|(
operator|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
operator|&
name|PTE_RX
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
return|return
operator|(
name|pmap_l1_to_l2
argument_list|(
name|l1
argument_list|,
name|va
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pt_entry_t
modifier|*
name|pmap_l2_to_l3
parameter_list|(
name|pd_entry_t
modifier|*
name|l2
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|vm_paddr_t
name|phys
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|phys
operator|=
name|PTE_TO_PHYS
argument_list|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
argument_list|)
expr_stmt|;
name|l3
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|phys
argument_list|)
expr_stmt|;
return|return
operator|(
operator|&
name|l3
index|[
name|pmap_l3_index
argument_list|(
name|va
argument_list|)
index|]
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pt_entry_t
modifier|*
name|pmap_l3
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|l2
decl_stmt|;
name|l2
operator|=
name|pmap_l2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2
operator|==
name|NULL
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
if|if
condition|(
operator|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|&
name|PTE_V
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
if|if
condition|(
operator|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|&
name|PTE_RX
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
return|return
operator|(
name|pmap_l2_to_l3
argument_list|(
name|l2
argument_list|,
name|va
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|pmap_is_write
parameter_list|(
name|pt_entry_t
name|entry
parameter_list|)
block|{
return|return
operator|(
name|entry
operator|&
name|PTE_W
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|pmap_is_current
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
return|return
operator|(
operator|(
name|pmap
operator|==
name|pmap_kernel
argument_list|()
operator|)
operator|||
operator|(
name|pmap
operator|==
name|curthread
operator|->
name|td_proc
operator|->
name|p_vmspace
operator|->
name|vm_map
operator|.
name|pmap
operator|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|pmap_l3_valid
parameter_list|(
name|pt_entry_t
name|l3
parameter_list|)
block|{
return|return
operator|(
name|l3
operator|&
name|PTE_V
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|pmap_l3_valid_cacheable
parameter_list|(
name|pt_entry_t
name|l3
parameter_list|)
block|{
comment|/* TODO */
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|PTE_SYNC
parameter_list|(
name|pte
parameter_list|)
value|cpu_dcache_wb_range((vm_offset_t)pte, sizeof(*pte))
end_define

begin_comment
comment|/* Checks if the page is dirty. */
end_comment

begin_function
specifier|static
specifier|inline
name|int
name|pmap_page_dirty
parameter_list|(
name|pt_entry_t
name|pte
parameter_list|)
block|{
return|return
operator|(
name|pte
operator|&
name|PTE_D
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pmap_resident_count_inc
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|+=
name|count
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pmap_resident_count_dec
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|>=
name|count
argument_list|,
operator|(
literal|"pmap %p resident count underflow %ld %d"
operator|,
name|pmap
operator|,
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|,
name|count
operator|)
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|-=
name|count
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_distribute_l1
parameter_list|(
name|struct
name|pmap
modifier|*
name|pmap
parameter_list|,
name|vm_pindex_t
name|l1index
parameter_list|,
name|pt_entry_t
name|entry
parameter_list|)
block|{
name|struct
name|pmap
modifier|*
name|user_pmap
decl_stmt|;
name|pd_entry_t
modifier|*
name|l1
decl_stmt|;
comment|/* Distribute new kernel L1 entry to all the user pmaps */
if|if
condition|(
name|pmap
operator|!=
name|kernel_pmap
condition|)
return|return;
name|LIST_FOREACH
argument_list|(
argument|user_pmap
argument_list|,
argument|&allpmaps
argument_list|,
argument|pm_list
argument_list|)
block|{
name|l1
operator|=
operator|&
name|user_pmap
operator|->
name|pm_l1
index|[
name|l1index
index|]
expr_stmt|;
if|if
condition|(
name|entry
condition|)
name|pmap_load_store
argument_list|(
name|l1
argument_list|,
name|entry
argument_list|)
expr_stmt|;
else|else
name|pmap_load_clear
argument_list|(
name|l1
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|pt_entry_t
modifier|*
name|pmap_early_page_idx
parameter_list|(
name|vm_offset_t
name|l1pt
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|u_int
modifier|*
name|l1_slot
parameter_list|,
name|u_int
modifier|*
name|l2_slot
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|l2
decl_stmt|;
name|pd_entry_t
modifier|*
name|l1
decl_stmt|;
name|l1
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|l1pt
expr_stmt|;
operator|*
name|l1_slot
operator|=
operator|(
name|va
operator|>>
name|L1_SHIFT
operator|)
operator|&
name|Ln_ADDR_MASK
expr_stmt|;
comment|/* Check locore has used a table L1 map */
name|KASSERT
argument_list|(
operator|(
name|l1
index|[
operator|*
name|l1_slot
index|]
operator|&
name|PTE_RX
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"Invalid bootstrap L1 table"
operator|)
argument_list|)
expr_stmt|;
comment|/* Find the address of the L2 table */
name|l2
operator|=
operator|(
name|pt_entry_t
operator|*
operator|)
name|init_pt_va
expr_stmt|;
operator|*
name|l2_slot
operator|=
name|pmap_l2_index
argument_list|(
name|va
argument_list|)
expr_stmt|;
return|return
operator|(
name|l2
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|vm_paddr_t
name|pmap_early_vtophys
parameter_list|(
name|vm_offset_t
name|l1pt
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|u_int
name|l1_slot
decl_stmt|,
name|l2_slot
decl_stmt|;
name|pt_entry_t
modifier|*
name|l2
decl_stmt|;
name|u_int
name|ret
decl_stmt|;
name|l2
operator|=
name|pmap_early_page_idx
argument_list|(
name|l1pt
argument_list|,
name|va
argument_list|,
operator|&
name|l1_slot
argument_list|,
operator|&
name|l2_slot
argument_list|)
expr_stmt|;
comment|/* Check locore has used L2 superpages */
name|KASSERT
argument_list|(
operator|(
name|l2
index|[
name|l2_slot
index|]
operator|&
name|PTE_RX
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"Invalid bootstrap L2 table"
operator|)
argument_list|)
expr_stmt|;
comment|/* L2 is superpages */
name|ret
operator|=
operator|(
name|l2
index|[
name|l2_slot
index|]
operator|>>
name|PTE_PPN1_S
operator|)
operator|<<
name|L2_SHIFT
expr_stmt|;
name|ret
operator|+=
operator|(
name|va
operator|&
name|L2_OFFSET
operator|)
expr_stmt|;
return|return
operator|(
name|ret
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_bootstrap_dmap
parameter_list|(
name|vm_offset_t
name|kern_l1
parameter_list|,
name|vm_paddr_t
name|min_pa
parameter_list|,
name|vm_paddr_t
name|max_pa
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|pd_entry_t
modifier|*
name|l1
decl_stmt|;
name|u_int
name|l1_slot
decl_stmt|;
name|pt_entry_t
name|entry
decl_stmt|;
name|pn_t
name|pn
decl_stmt|;
name|pa
operator|=
name|dmap_phys_base
operator|=
name|min_pa
operator|&
operator|~
name|L1_OFFSET
expr_stmt|;
name|va
operator|=
name|DMAP_MIN_ADDRESS
expr_stmt|;
name|l1
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|kern_l1
expr_stmt|;
name|l1_slot
operator|=
name|pmap_l1_index
argument_list|(
name|DMAP_MIN_ADDRESS
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|va
operator|<
name|DMAP_MAX_ADDRESS
operator|&&
name|pa
operator|<
name|max_pa
condition|;
name|pa
operator|+=
name|L1_SIZE
operator|,
name|va
operator|+=
name|L1_SIZE
operator|,
name|l1_slot
operator|++
control|)
block|{
name|KASSERT
argument_list|(
name|l1_slot
operator|<
name|Ln_ENTRIES
argument_list|,
operator|(
literal|"Invalid L1 index"
operator|)
argument_list|)
expr_stmt|;
comment|/* superpages */
name|pn
operator|=
operator|(
name|pa
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|entry
operator|=
operator|(
name|PTE_V
operator||
name|PTE_RWX
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
operator|&
name|l1
index|[
name|l1_slot
index|]
argument_list|,
name|entry
argument_list|)
expr_stmt|;
block|}
comment|/* Set the upper limit of the DMAP region */
name|dmap_phys_max
operator|=
name|pa
expr_stmt|;
name|dmap_max_addr
operator|=
name|va
expr_stmt|;
name|cpu_dcache_wb_range
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|l1
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|cpu_tlb_flushID
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|vm_offset_t
name|pmap_bootstrap_l3
parameter_list|(
name|vm_offset_t
name|l1pt
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|l3_start
parameter_list|)
block|{
name|vm_offset_t
name|l2pt
decl_stmt|,
name|l3pt
decl_stmt|;
name|pt_entry_t
name|entry
decl_stmt|;
name|pd_entry_t
modifier|*
name|l2
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|u_int
name|l2_slot
decl_stmt|;
name|pn_t
name|pn
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|va
operator|&
name|L2_OFFSET
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"Invalid virtual address"
operator|)
argument_list|)
expr_stmt|;
name|l2
operator|=
name|pmap_l2
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|l2
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
operator|(
operator|(
name|uintptr_t
operator|)
name|l2
operator|&
operator|~
operator|(
name|PAGE_SIZE
operator|-
literal|1
operator|)
operator|)
expr_stmt|;
name|l2pt
operator|=
operator|(
name|vm_offset_t
operator|)
name|l2
expr_stmt|;
name|l2_slot
operator|=
name|pmap_l2_index
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|l3pt
operator|=
name|l3_start
expr_stmt|;
for|for
control|(
init|;
name|va
operator|<
name|VM_MAX_KERNEL_ADDRESS
condition|;
name|l2_slot
operator|++
operator|,
name|va
operator|+=
name|L2_SIZE
control|)
block|{
name|KASSERT
argument_list|(
name|l2_slot
operator|<
name|Ln_ENTRIES
argument_list|,
operator|(
literal|"Invalid L2 index"
operator|)
argument_list|)
expr_stmt|;
name|pa
operator|=
name|pmap_early_vtophys
argument_list|(
name|l1pt
argument_list|,
name|l3pt
argument_list|)
expr_stmt|;
name|pn
operator|=
operator|(
name|pa
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|entry
operator|=
operator|(
name|PTE_V
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
operator|&
name|l2
index|[
name|l2_slot
index|]
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|l3pt
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* Clean the L2 page table */
name|memset
argument_list|(
operator|(
name|void
operator|*
operator|)
name|l3_start
argument_list|,
literal|0
argument_list|,
name|l3pt
operator|-
name|l3_start
argument_list|)
expr_stmt|;
name|cpu_dcache_wb_range
argument_list|(
name|l3_start
argument_list|,
name|l3pt
operator|-
name|l3_start
argument_list|)
expr_stmt|;
name|cpu_dcache_wb_range
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|l2
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
return|return
operator|(
name|l3pt
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Bootstrap the system enough to run with virtual memory.  */
end_comment

begin_function
name|void
name|pmap_bootstrap
parameter_list|(
name|vm_offset_t
name|l1pt
parameter_list|,
name|vm_paddr_t
name|kernstart
parameter_list|,
name|vm_size_t
name|kernlen
parameter_list|)
block|{
name|u_int
name|l1_slot
decl_stmt|,
name|l2_slot
decl_stmt|,
name|avail_slot
decl_stmt|,
name|map_slot
decl_stmt|,
name|used_map_slot
decl_stmt|;
name|uint64_t
name|kern_delta
decl_stmt|;
name|pt_entry_t
modifier|*
name|l2
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|freemempos
decl_stmt|;
name|vm_offset_t
name|dpcpu
decl_stmt|,
name|msgbufpv
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|,
name|min_pa
decl_stmt|,
name|max_pa
decl_stmt|;
name|int
name|i
decl_stmt|;
name|kern_delta
operator|=
name|KERNBASE
operator|-
name|kernstart
expr_stmt|;
name|physmem
operator|=
literal|0
expr_stmt|;
name|printf
argument_list|(
literal|"pmap_bootstrap %lx %lx %lx\n"
argument_list|,
name|l1pt
argument_list|,
name|kernstart
argument_list|,
name|kernlen
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"%lx\n"
argument_list|,
name|l1pt
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"%lx\n"
argument_list|,
operator|(
name|KERNBASE
operator|>>
name|L1_SHIFT
operator|)
operator|&
name|Ln_ADDR_MASK
argument_list|)
expr_stmt|;
comment|/* Set this early so we can use the pagetable walking functions */
name|kernel_pmap_store
operator|.
name|pm_l1
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|l1pt
expr_stmt|;
name|PMAP_LOCK_INIT
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the global pv list lock. 	 */
name|rw_init
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
literal|"pmap pv global"
argument_list|)
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|allpmaps
argument_list|)
expr_stmt|;
comment|/* Assume the address we were loaded to is a valid physical address */
name|min_pa
operator|=
name|max_pa
operator|=
name|KERNBASE
operator|-
name|kern_delta
expr_stmt|;
comment|/* 	 * Find the minimum physical address. physmap is sorted, 	 * but may contain empty ranges. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
operator|(
name|physmap_idx
operator|*
literal|2
operator|)
condition|;
name|i
operator|+=
literal|2
control|)
block|{
if|if
condition|(
name|physmap
index|[
name|i
index|]
operator|==
name|physmap
index|[
name|i
operator|+
literal|1
index|]
condition|)
continue|continue;
if|if
condition|(
name|physmap
index|[
name|i
index|]
operator|<=
name|min_pa
condition|)
name|min_pa
operator|=
name|physmap
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|physmap
index|[
name|i
operator|+
literal|1
index|]
operator|>
name|max_pa
condition|)
name|max_pa
operator|=
name|physmap
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
block|}
name|printf
argument_list|(
literal|"physmap_idx %lx\n"
argument_list|,
name|physmap_idx
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"min_pa %lx\n"
argument_list|,
name|min_pa
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"max_pa %lx\n"
argument_list|,
name|max_pa
argument_list|)
expr_stmt|;
comment|/* Create a direct map region early so we can use it for pa -> va */
name|pmap_bootstrap_dmap
argument_list|(
name|l1pt
argument_list|,
name|min_pa
argument_list|,
name|max_pa
argument_list|)
expr_stmt|;
name|va
operator|=
name|KERNBASE
expr_stmt|;
name|pa
operator|=
name|KERNBASE
operator|-
name|kern_delta
expr_stmt|;
comment|/* 	 * Start to initialize phys_avail by copying from physmap 	 * up to the physical address KERNBASE points at. 	 */
name|map_slot
operator|=
name|avail_slot
operator|=
literal|0
expr_stmt|;
for|for
control|(
init|;
name|map_slot
operator|<
operator|(
name|physmap_idx
operator|*
literal|2
operator|)
condition|;
name|map_slot
operator|+=
literal|2
control|)
block|{
if|if
condition|(
name|physmap
index|[
name|map_slot
index|]
operator|==
name|physmap
index|[
name|map_slot
operator|+
literal|1
index|]
condition|)
continue|continue;
if|if
condition|(
name|physmap
index|[
name|map_slot
index|]
operator|<=
name|pa
operator|&&
name|physmap
index|[
name|map_slot
operator|+
literal|1
index|]
operator|>
name|pa
condition|)
break|break;
name|phys_avail
index|[
name|avail_slot
index|]
operator|=
name|physmap
index|[
name|map_slot
index|]
expr_stmt|;
name|phys_avail
index|[
name|avail_slot
operator|+
literal|1
index|]
operator|=
name|physmap
index|[
name|map_slot
operator|+
literal|1
index|]
expr_stmt|;
name|physmem
operator|+=
operator|(
name|phys_avail
index|[
name|avail_slot
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|avail_slot
index|]
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
name|avail_slot
operator|+=
literal|2
expr_stmt|;
block|}
comment|/* Add the memory before the kernel */
if|if
condition|(
name|physmap
index|[
name|avail_slot
index|]
operator|<
name|pa
condition|)
block|{
name|phys_avail
index|[
name|avail_slot
index|]
operator|=
name|physmap
index|[
name|map_slot
index|]
expr_stmt|;
name|phys_avail
index|[
name|avail_slot
operator|+
literal|1
index|]
operator|=
name|pa
expr_stmt|;
name|physmem
operator|+=
operator|(
name|phys_avail
index|[
name|avail_slot
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|avail_slot
index|]
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
name|avail_slot
operator|+=
literal|2
expr_stmt|;
block|}
name|used_map_slot
operator|=
name|map_slot
expr_stmt|;
comment|/* 	 * Read the page table to find out what is already mapped. 	 * This assumes we have mapped a block of memory from KERNBASE 	 * using a single L1 entry. 	 */
name|l2
operator|=
name|pmap_early_page_idx
argument_list|(
name|l1pt
argument_list|,
name|KERNBASE
argument_list|,
operator|&
name|l1_slot
argument_list|,
operator|&
name|l2_slot
argument_list|)
expr_stmt|;
comment|/* Sanity check the index, KERNBASE should be the first VA */
name|KASSERT
argument_list|(
name|l2_slot
operator|==
literal|0
argument_list|,
operator|(
literal|"The L2 index is non-zero"
operator|)
argument_list|)
expr_stmt|;
comment|/* Find how many pages we have mapped */
for|for
control|(
init|;
name|l2_slot
operator|<
name|Ln_ENTRIES
condition|;
name|l2_slot
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|l2
index|[
name|l2_slot
index|]
operator|&
name|PTE_V
operator|)
operator|==
literal|0
condition|)
break|break;
comment|/* Check locore used L2 superpages */
name|KASSERT
argument_list|(
operator|(
name|l2
index|[
name|l2_slot
index|]
operator|&
name|PTE_RX
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"Invalid bootstrap L2 table"
operator|)
argument_list|)
expr_stmt|;
name|va
operator|+=
name|L2_SIZE
expr_stmt|;
name|pa
operator|+=
name|L2_SIZE
expr_stmt|;
block|}
name|va
operator|=
name|roundup2
argument_list|(
name|va
argument_list|,
name|L2_SIZE
argument_list|)
expr_stmt|;
name|freemempos
operator|=
name|KERNBASE
operator|+
name|kernlen
expr_stmt|;
name|freemempos
operator|=
name|roundup2
argument_list|(
name|freemempos
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
comment|/* Create the l3 tables for the early devmap */
name|freemempos
operator|=
name|pmap_bootstrap_l3
argument_list|(
name|l1pt
argument_list|,
name|VM_MAX_KERNEL_ADDRESS
operator|-
name|L2_SIZE
argument_list|,
name|freemempos
argument_list|)
expr_stmt|;
name|cpu_tlb_flushID
argument_list|()
expr_stmt|;
define|#
directive|define
name|alloc_pages
parameter_list|(
name|var
parameter_list|,
name|np
parameter_list|)
define|\
value|(var) = freemempos;						\ 	freemempos += (np * PAGE_SIZE);					\ 	memset((char *)(var), 0, ((np) * PAGE_SIZE));
comment|/* Allocate dynamic per-cpu area. */
name|alloc_pages
argument_list|(
name|dpcpu
argument_list|,
name|DPCPU_SIZE
operator|/
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|dpcpu_init
argument_list|(
operator|(
name|void
operator|*
operator|)
name|dpcpu
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* Allocate memory for the msgbuf, e.g. for /sbin/dmesg */
name|alloc_pages
argument_list|(
name|msgbufpv
argument_list|,
name|round_page
argument_list|(
name|msgbufsize
argument_list|)
operator|/
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|msgbufp
operator|=
operator|(
name|void
operator|*
operator|)
name|msgbufpv
expr_stmt|;
name|virtual_avail
operator|=
name|roundup2
argument_list|(
name|freemempos
argument_list|,
name|L2_SIZE
argument_list|)
expr_stmt|;
name|virtual_end
operator|=
name|VM_MAX_KERNEL_ADDRESS
operator|-
name|L2_SIZE
expr_stmt|;
name|kernel_vm_end
operator|=
name|virtual_avail
expr_stmt|;
name|pa
operator|=
name|pmap_early_vtophys
argument_list|(
name|l1pt
argument_list|,
name|freemempos
argument_list|)
expr_stmt|;
comment|/* Finish initialising physmap */
name|map_slot
operator|=
name|used_map_slot
expr_stmt|;
for|for
control|(
init|;
name|avail_slot
operator|<
operator|(
name|PHYS_AVAIL_SIZE
operator|-
literal|2
operator|)
operator|&&
name|map_slot
operator|<
operator|(
name|physmap_idx
operator|*
literal|2
operator|)
condition|;
name|map_slot
operator|+=
literal|2
control|)
block|{
if|if
condition|(
name|physmap
index|[
name|map_slot
index|]
operator|==
name|physmap
index|[
name|map_slot
operator|+
literal|1
index|]
condition|)
block|{
continue|continue;
block|}
comment|/* Have we used the current range? */
if|if
condition|(
name|physmap
index|[
name|map_slot
operator|+
literal|1
index|]
operator|<=
name|pa
condition|)
block|{
continue|continue;
block|}
comment|/* Do we need to split the entry? */
if|if
condition|(
name|physmap
index|[
name|map_slot
index|]
operator|<
name|pa
condition|)
block|{
name|phys_avail
index|[
name|avail_slot
index|]
operator|=
name|pa
expr_stmt|;
name|phys_avail
index|[
name|avail_slot
operator|+
literal|1
index|]
operator|=
name|physmap
index|[
name|map_slot
operator|+
literal|1
index|]
expr_stmt|;
block|}
else|else
block|{
name|phys_avail
index|[
name|avail_slot
index|]
operator|=
name|physmap
index|[
name|map_slot
index|]
expr_stmt|;
name|phys_avail
index|[
name|avail_slot
operator|+
literal|1
index|]
operator|=
name|physmap
index|[
name|map_slot
operator|+
literal|1
index|]
expr_stmt|;
block|}
name|physmem
operator|+=
operator|(
name|phys_avail
index|[
name|avail_slot
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|avail_slot
index|]
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
name|avail_slot
operator|+=
literal|2
expr_stmt|;
block|}
name|phys_avail
index|[
name|avail_slot
index|]
operator|=
literal|0
expr_stmt|;
name|phys_avail
index|[
name|avail_slot
operator|+
literal|1
index|]
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Maxmem isn't the "maximum memory", it's one larger than the 	 * highest page of the physical address space.  It should be 	 * called something like "Maxphyspage". 	 */
name|Maxmem
operator|=
name|atop
argument_list|(
name|phys_avail
index|[
name|avail_slot
operator|-
literal|1
index|]
argument_list|)
expr_stmt|;
name|cpu_tlb_flushID
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Initialize a vm_page's machine-dependent fields.  */
end_comment

begin_function
name|void
name|pmap_page_init
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|TAILQ_INIT
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_memattr
operator|=
name|VM_MEMATTR_WRITE_BACK
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Initialize the pmap module.  *	Called by vm_init, to initialize any structures that the pmap  *	system needs to map virtual memory.  */
end_comment

begin_function
name|void
name|pmap_init
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
comment|/* 	 * Initialize the pv chunk list mutex. 	 */
name|mtx_init
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|,
literal|"pmap pv chunk list"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the pool of pv list locks. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPV_LIST_LOCKS
condition|;
name|i
operator|++
control|)
name|rw_init
argument_list|(
operator|&
name|pv_list_locks
index|[
name|i
index|]
argument_list|,
literal|"pmap pv list"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Normal, non-SMP, invalidation functions.  * We inline these within pmap.c for speed.  */
end_comment

begin_function
name|PMAP_INLINE
name|void
name|pmap_invalidate_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
comment|/* TODO */
name|sched_pin
argument_list|()
expr_stmt|;
asm|__asm __volatile("sfence.vma %0" :: "r" (va) : "memory");
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|PMAP_INLINE
name|void
name|pmap_invalidate_range
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
comment|/* TODO */
name|sched_pin
argument_list|()
expr_stmt|;
asm|__asm __volatile("sfence.vma");
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|PMAP_INLINE
name|void
name|pmap_invalidate_all
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
comment|/* TODO */
name|sched_pin
argument_list|()
expr_stmt|;
asm|__asm __volatile("sfence.vma");
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Routine:	pmap_extract  *	Function:  *		Extract the physical page address associated  *		with the given map/virtual_address pair.  */
end_comment

begin_function
name|vm_paddr_t
name|pmap_extract
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|l2p
decl_stmt|,
name|l2
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3p
decl_stmt|,
name|l3
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Start with the l2 tabel. We are unable to allocate 	 * pages in the l1 table. 	 */
name|l2p
operator|=
name|pmap_l2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2p
operator|!=
name|NULL
condition|)
block|{
name|l2
operator|=
name|pmap_load
argument_list|(
name|l2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|l2
operator|&
name|PTE_RX
operator|)
operator|==
literal|0
condition|)
block|{
name|l3p
operator|=
name|pmap_l2_to_l3
argument_list|(
name|l2p
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|l3p
operator|!=
name|NULL
condition|)
block|{
name|l3
operator|=
name|pmap_load
argument_list|(
name|l3p
argument_list|)
expr_stmt|;
name|pa
operator|=
name|PTE_TO_PHYS
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|pa
operator||=
operator|(
name|va
operator|&
name|L3_OFFSET
operator|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|/* L2 is superpages */
name|pa
operator|=
operator|(
name|l2
operator|>>
name|PTE_PPN1_S
operator|)
operator|<<
name|L2_SHIFT
expr_stmt|;
name|pa
operator||=
operator|(
name|va
operator|&
name|L2_OFFSET
operator|)
expr_stmt|;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Routine:	pmap_extract_and_hold  *	Function:  *		Atomically extract and hold the physical page  *		with the given pmap and virtual address pair  *		if that mapping permits the given protection.  */
end_comment

begin_function
name|vm_page_t
name|pmap_extract_and_hold
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|l3p
decl_stmt|,
name|l3
decl_stmt|;
name|vm_paddr_t
name|phys
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|l3p
operator|=
name|pmap_l3
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|l3p
operator|!=
name|NULL
operator|&&
operator|(
name|l3
operator|=
name|pmap_load
argument_list|(
name|l3p
argument_list|)
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|pmap_is_write
argument_list|(
name|l3
argument_list|)
operator|)
operator|||
operator|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
operator|)
condition|)
block|{
name|phys
operator|=
name|PTE_TO_PHYS
argument_list|(
name|l3
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|phys
argument_list|,
operator|&
name|pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|phys
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
name|PA_UNLOCK_COND
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
name|vm_paddr_t
name|pmap_kextract
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|l2
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
if|if
condition|(
name|va
operator|>=
name|DMAP_MIN_ADDRESS
operator|&&
name|va
operator|<
name|DMAP_MAX_ADDRESS
condition|)
block|{
name|pa
operator|=
name|DMAP_TO_PHYS
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|l2
operator|=
name|pmap_l2
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_kextract: No l2"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|&
name|PTE_RX
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* superpages */
name|pa
operator|=
operator|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|>>
name|PTE_PPN1_S
operator|)
operator|<<
name|L2_SHIFT
expr_stmt|;
name|pa
operator||=
operator|(
name|va
operator|&
name|L2_OFFSET
operator|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
name|l3
operator|=
name|pmap_l2_to_l3
argument_list|(
name|l2
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|l3
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_kextract: No l3..."
argument_list|)
expr_stmt|;
name|pa
operator|=
name|PTE_TO_PHYS
argument_list|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
argument_list|)
expr_stmt|;
name|pa
operator||=
operator|(
name|va
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
block|}
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/***************************************************  * Low level mapping routines.....  ***************************************************/
end_comment

begin_function
name|void
name|pmap_kenter_device
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|pt_entry_t
name|entry
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|pn_t
name|pn
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pa
operator|&
name|L3_OFFSET
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_kenter_device: Invalid physical address"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|sva
operator|&
name|L3_OFFSET
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_kenter_device: Invalid virtual address"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|size
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_kenter_device: Mapping is not page-sized"
operator|)
argument_list|)
expr_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
while|while
condition|(
name|size
operator|!=
literal|0
condition|)
block|{
name|l3
operator|=
name|pmap_l3
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|l3
operator|!=
name|NULL
argument_list|,
operator|(
literal|"Invalid page table, va: 0x%lx"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
name|pn
operator|=
operator|(
name|pa
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|entry
operator|=
operator|(
name|PTE_V
operator||
name|PTE_RWX
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
name|l3
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|size
operator|-=
name|PAGE_SIZE
expr_stmt|;
block|}
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove a page from the kernel pagetables.  * Note: not SMP coherent.  */
end_comment

begin_function
name|PMAP_INLINE
name|void
name|pmap_kremove
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|l3
operator|=
name|pmap_l3
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|l3
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_kremove: Invalid address"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_l3_valid_cacheable
argument_list|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
argument_list|)
condition|)
name|cpu_dcache_wb_range
argument_list|(
name|va
argument_list|,
name|L3_SIZE
argument_list|)
expr_stmt|;
name|pmap_load_clear
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_kremove_device
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|sva
operator|&
name|L3_OFFSET
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_kremove_device: Invalid virtual address"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|size
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_kremove_device: Mapping is not page-sized"
operator|)
argument_list|)
expr_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
while|while
condition|(
name|size
operator|!=
literal|0
condition|)
block|{
name|l3
operator|=
name|pmap_l3
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|l3
operator|!=
name|NULL
argument_list|,
operator|(
literal|"Invalid page table, va: 0x%lx"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
name|pmap_load_clear
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|size
operator|-=
name|PAGE_SIZE
expr_stmt|;
block|}
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Used to map a range of physical addresses into kernel  *	virtual address space.  *  *	The value passed in '*virt' is a suggested virtual address for  *	the mapping. Architectures which can support a direct-mapped  *	physical to virtual region can return the appropriate address  *	within that region, leaving '*virt' unchanged. Other  *	architectures should map the pages starting at '*virt' and  *	update '*virt' with the first usable address after the mapped  *	region.  */
end_comment

begin_function
name|vm_offset_t
name|pmap_map
parameter_list|(
name|vm_offset_t
modifier|*
name|virt
parameter_list|,
name|vm_paddr_t
name|start
parameter_list|,
name|vm_paddr_t
name|end
parameter_list|,
name|int
name|prot
parameter_list|)
block|{
return|return
name|PHYS_TO_DMAP
argument_list|(
name|start
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/*  * Add a list of wired pages to the kva  * this routine is only used for temporary  * kernel mappings that do not need to have  * page modification or references recorded.  * Note that old mappings are simply written  * over.  The page *must* be wired.  * Note: SMP coherent.  Uses a ranged shootdown IPI.  */
end_comment

begin_function
name|void
name|pmap_qenter
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|l3
decl_stmt|,
name|pa
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|pt_entry_t
name|entry
decl_stmt|;
name|pn_t
name|pn
decl_stmt|;
name|int
name|i
decl_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|ma
index|[
name|i
index|]
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pn
operator|=
operator|(
name|pa
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|l3
operator|=
name|pmap_l3
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|entry
operator|=
operator|(
name|PTE_V
operator||
name|PTE_RWX
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
name|l3
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|va
operator|+=
name|L3_SIZE
expr_stmt|;
block|}
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine tears out page mappings from the  * kernel -- it is meant only for temporary mappings.  * Note: SMP coherent.  Uses a ranged shootdown IPI.  */
end_comment

begin_function
name|void
name|pmap_qremove
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|KASSERT
argument_list|(
name|sva
operator|>=
name|VM_MIN_KERNEL_ADDRESS
argument_list|,
operator|(
literal|"usermode va %lx"
operator|,
name|sva
operator|)
argument_list|)
expr_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|l3
operator|=
name|pmap_l3
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|l3
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_kremove: Invalid address"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_l3_valid_cacheable
argument_list|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
argument_list|)
condition|)
name|cpu_dcache_wb_range
argument_list|(
name|va
argument_list|,
name|L3_SIZE
argument_list|)
expr_stmt|;
name|pmap_load_clear
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/***************************************************  * Page table page management routines.....  ***************************************************/
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_free_zero_pages
parameter_list|(
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
while|while
condition|(
operator|(
name|m
operator|=
name|SLIST_FIRST
argument_list|(
name|free
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|SLIST_REMOVE_HEAD
argument_list|(
name|free
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
comment|/* Preserve the page's PG_ZERO setting. */
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Schedule the specified unused page table page to be freed.  Specifically,  * add the page to the specified list of pages that will be released to the  * physical memory manager after the TLB has been updated.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_add_delayed_free_list
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|boolean_t
name|set_PG_ZERO
parameter_list|)
block|{
if|if
condition|(
name|set_PG_ZERO
condition|)
name|m
operator|->
name|flags
operator||=
name|PG_ZERO
expr_stmt|;
else|else
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|SLIST_INSERT_HEAD
argument_list|(
name|free
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Decrements a page table page's wire count, which is used to record the  * number of valid page table entries within the page.  If the wire count  * drops to zero, then the page table page is unmapped.  Returns TRUE if the  * page table page was unmapped and FALSE otherwise.  */
end_comment

begin_function
specifier|static
specifier|inline
name|boolean_t
name|pmap_unwire_l3
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
operator|--
name|m
operator|->
name|wire_count
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|_pmap_unwire_l3
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|free
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
block|{
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|_pmap_unwire_l3
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|vm_paddr_t
name|phys
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * unmap the page table page 	 */
if|if
condition|(
name|m
operator|->
name|pindex
operator|>=
name|NUPDE
condition|)
block|{
comment|/* PD page */
name|pd_entry_t
modifier|*
name|l1
decl_stmt|;
name|l1
operator|=
name|pmap_l1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pmap_load_clear
argument_list|(
name|l1
argument_list|)
expr_stmt|;
name|pmap_distribute_l1
argument_list|(
name|pmap
argument_list|,
name|pmap_l1_index
argument_list|(
name|va
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* PTE page */
name|pd_entry_t
modifier|*
name|l2
decl_stmt|;
name|l2
operator|=
name|pmap_l2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pmap_load_clear
argument_list|(
name|l2
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l2
argument_list|)
expr_stmt|;
block|}
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|pindex
operator|<
name|NUPDE
condition|)
block|{
name|pd_entry_t
modifier|*
name|l1
decl_stmt|;
comment|/* We just released a PT, unhold the matching PD */
name|vm_page_t
name|pdpg
decl_stmt|;
name|l1
operator|=
name|pmap_l1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|phys
operator|=
name|PTE_TO_PHYS
argument_list|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
argument_list|)
expr_stmt|;
name|pdpg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|phys
argument_list|)
expr_stmt|;
name|pmap_unwire_l3
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pdpg
argument_list|,
name|free
argument_list|)
expr_stmt|;
block|}
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * This is a release store so that the ordinary store unmapping 	 * the page table page is globally performed before TLB shoot- 	 * down is begun. 	 */
name|atomic_subtract_rel_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/*  	 * Put page on a list so that it is released after 	 * *ALL* TLB shootdown is done 	 */
name|pmap_add_delayed_free_list
argument_list|(
name|m
argument_list|,
name|free
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * After removing an l3 entry, this routine is used to  * conditionally free the page, and manage the hold/wire counts.  */
end_comment

begin_function
specifier|static
name|int
name|pmap_unuse_l3
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|ptepde
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|vm_paddr_t
name|phys
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
if|if
condition|(
name|va
operator|>=
name|VM_MAXUSER_ADDRESS
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|KASSERT
argument_list|(
name|ptepde
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_unuse_pt: ptepde != 0"
operator|)
argument_list|)
expr_stmt|;
name|phys
operator|=
name|PTE_TO_PHYS
argument_list|(
name|ptepde
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|phys
argument_list|)
expr_stmt|;
return|return
operator|(
name|pmap_unwire_l3
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|mpte
argument_list|,
name|free
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_pinit0
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|PMAP_LOCK_INIT
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pmap
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
argument_list|(
name|pmap
operator|->
name|pm_stats
argument_list|)
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_l1
operator|=
name|kernel_pmap
operator|->
name|pm_l1
expr_stmt|;
block|}
end_function

begin_function
name|int
name|pmap_pinit
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|vm_paddr_t
name|l1phys
decl_stmt|;
name|vm_page_t
name|l1pt
decl_stmt|;
comment|/* 	 * allocate the l1 page 	 */
while|while
condition|(
operator|(
name|l1pt
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0xdeadbeef
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
operator|)
operator|==
name|NULL
condition|)
name|VM_WAIT
expr_stmt|;
name|l1phys
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|l1pt
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_l1
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|l1phys
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|l1pt
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pagezero
argument_list|(
name|pmap
operator|->
name|pm_l1
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pmap
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
argument_list|(
name|pmap
operator|->
name|pm_stats
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Install kernel pagetables */
name|memcpy
argument_list|(
name|pmap
operator|->
name|pm_l1
argument_list|,
name|kernel_pmap
operator|->
name|pm_l1
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
comment|/* Add to the list of all user pmaps */
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|allpmaps
argument_list|,
name|pmap
argument_list|,
name|pm_list
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This routine is called if the desired page table page does not exist.  *  * If page table page allocation fails, this routine may sleep before  * returning NULL.  It sleeps only if a lock pointer was given.  *  * Note: If a page allocation fails at page table level two or three,  * one or two pages may be held during the wait, only to be released  * afterwards.  This conservative approach is easily argued to avoid  * race conditions.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|_pmap_alloc_l3
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_pindex_t
name|ptepindex
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|,
comment|/*pdppg, */
name|pdpg
decl_stmt|;
name|pt_entry_t
name|entry
decl_stmt|;
name|vm_paddr_t
name|phys
decl_stmt|;
name|pn_t
name|pn
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate a page table page. 	 */
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|ptepindex
argument_list|,
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|lockp
operator|!=
name|NULL
condition|)
block|{
name|RELEASE_PV_LIST_LOCK
argument_list|(
name|lockp
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Indicate the need to retry.  While waiting, the page table 		 * page may have been allocated. 		 */
return|return
operator|(
name|NULL
operator|)
return|;
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Map the pagetable page into the process address space, if 	 * it isn't already there. 	 */
if|if
condition|(
name|ptepindex
operator|>=
name|NUPDE
condition|)
block|{
name|pd_entry_t
modifier|*
name|l1
decl_stmt|;
name|vm_pindex_t
name|l1index
decl_stmt|;
name|l1index
operator|=
name|ptepindex
operator|-
name|NUPDE
expr_stmt|;
name|l1
operator|=
operator|&
name|pmap
operator|->
name|pm_l1
index|[
name|l1index
index|]
expr_stmt|;
name|pn
operator|=
operator|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|entry
operator|=
operator|(
name|PTE_V
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
name|l1
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|pmap_distribute_l1
argument_list|(
name|pmap
argument_list|,
name|l1index
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|vm_pindex_t
name|l1index
decl_stmt|;
name|pd_entry_t
modifier|*
name|l1
decl_stmt|,
modifier|*
name|l2
decl_stmt|;
name|l1index
operator|=
name|ptepindex
operator|>>
operator|(
name|L1_SHIFT
operator|-
name|L2_SHIFT
operator|)
expr_stmt|;
name|l1
operator|=
operator|&
name|pmap
operator|->
name|pm_l1
index|[
name|l1index
index|]
expr_stmt|;
if|if
condition|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
operator|==
literal|0
condition|)
block|{
comment|/* recurse for allocating page dir */
if|if
condition|(
name|_pmap_alloc_l3
argument_list|(
name|pmap
argument_list|,
name|NUPDE
operator|+
name|l1index
argument_list|,
name|lockp
argument_list|)
operator|==
name|NULL
condition|)
block|{
operator|--
name|m
operator|->
name|wire_count
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_free_zero
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
block|}
else|else
block|{
name|phys
operator|=
name|PTE_TO_PHYS
argument_list|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
argument_list|)
expr_stmt|;
name|pdpg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|phys
argument_list|)
expr_stmt|;
name|pdpg
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
name|phys
operator|=
name|PTE_TO_PHYS
argument_list|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
argument_list|)
expr_stmt|;
name|l2
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|phys
argument_list|)
expr_stmt|;
name|l2
operator|=
operator|&
name|l2
index|[
name|ptepindex
operator|&
name|Ln_ADDR_MASK
index|]
expr_stmt|;
name|pn
operator|=
operator|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|entry
operator|=
operator|(
name|PTE_V
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
name|l2
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l2
argument_list|)
expr_stmt|;
block|}
name|pmap_resident_count_inc
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|vm_page_t
name|pmap_alloc_l3
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|vm_pindex_t
name|ptepindex
decl_stmt|;
name|pd_entry_t
modifier|*
name|l2
decl_stmt|;
name|vm_paddr_t
name|phys
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
comment|/* 	 * Calculate pagetable page index 	 */
name|ptepindex
operator|=
name|pmap_l2_pindex
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|retry
label|:
comment|/* 	 * Get the page directory entry 	 */
name|l2
operator|=
name|pmap_l2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * If the page table page is mapped, we just increment the 	 * hold count, and activate it. 	 */
if|if
condition|(
name|l2
operator|!=
name|NULL
operator|&&
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|phys
operator|=
name|PTE_TO_PHYS
argument_list|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|phys
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Here if the pte page isn't mapped, or if it has been 		 * deallocated. 		 */
name|m
operator|=
name|_pmap_alloc_l3
argument_list|(
name|pmap
argument_list|,
name|ptepindex
argument_list|,
name|lockp
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
operator|&&
name|lockp
operator|!=
name|NULL
condition|)
goto|goto
name|retry
goto|;
block|}
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/***************************************************  * Pmap allocation/deallocation routines.  ***************************************************/
end_comment

begin_comment
comment|/*  * Release any resources held by the given physical map.  * Called when a pmap initialized by pmap_pinit is being released.  * Should only be called if the map contains no valid mappings.  */
end_comment

begin_function
name|void
name|pmap_release
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_release: pmap resident count %ld != 0"
operator|,
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|)
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|DMAP_TO_PHYS
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pmap
operator|->
name|pm_l1
argument_list|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|--
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_free_zero
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* Remove pmap from the allpmaps list */
name|LIST_REMOVE
argument_list|(
name|pmap
argument_list|,
name|pm_list
argument_list|)
expr_stmt|;
comment|/* Remove kernel pagetables */
name|bzero
argument_list|(
name|pmap
operator|->
name|pm_l1
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_if
if|#
directive|if
literal|0
end_if

begin_endif
unit|static int kvm_size(SYSCTL_HANDLER_ARGS) { 	unsigned long ksize = VM_MAX_KERNEL_ADDRESS - VM_MIN_KERNEL_ADDRESS;  	return sysctl_handle_long(oidp,&ksize, 0, req); } SYSCTL_PROC(_vm, OID_AUTO, kvm_size, CTLTYPE_LONG|CTLFLAG_RD,      0, 0, kvm_size, "LU", "Size of KVM");  static int kvm_free(SYSCTL_HANDLER_ARGS) { 	unsigned long kfree = VM_MAX_KERNEL_ADDRESS - kernel_vm_end;  	return sysctl_handle_long(oidp,&kfree, 0, req); } SYSCTL_PROC(_vm, OID_AUTO, kvm_free, CTLTYPE_LONG|CTLFLAG_RD,      0, 0, kvm_free, "LU", "Amount of KVM free");
endif|#
directive|endif
end_endif

begin_comment
comment|/* 0 */
end_comment

begin_comment
comment|/*  * grow the number of kernel page table entries, if needed  */
end_comment

begin_function
name|void
name|pmap_growkernel
parameter_list|(
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|vm_paddr_t
name|paddr
decl_stmt|;
name|vm_page_t
name|nkpg
decl_stmt|;
name|pd_entry_t
modifier|*
name|l1
decl_stmt|,
modifier|*
name|l2
decl_stmt|;
name|pt_entry_t
name|entry
decl_stmt|;
name|pn_t
name|pn
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|kernel_map
operator|->
name|system_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|addr
operator|=
name|roundup2
argument_list|(
name|addr
argument_list|,
name|L2_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|addr
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
name|addr
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
while|while
condition|(
name|kernel_vm_end
operator|<
name|addr
condition|)
block|{
name|l1
operator|=
name|pmap_l1
argument_list|(
name|kernel_pmap
argument_list|,
name|kernel_vm_end
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
operator|==
literal|0
condition|)
block|{
comment|/* We need a new PDP entry */
name|nkpg
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|kernel_vm_end
operator|>>
name|L1_SHIFT
argument_list|,
name|VM_ALLOC_INTERRUPT
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|nkpg
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_growkernel: no memory to grow kernel"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|nkpg
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|nkpg
argument_list|)
expr_stmt|;
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|nkpg
argument_list|)
expr_stmt|;
name|pn
operator|=
operator|(
name|paddr
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|entry
operator|=
operator|(
name|PTE_V
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
name|l1
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|pmap_distribute_l1
argument_list|(
name|kernel_pmap
argument_list|,
name|pmap_l1_index
argument_list|(
name|kernel_vm_end
argument_list|)
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l1
argument_list|)
expr_stmt|;
continue|continue;
comment|/* try again */
block|}
name|l2
operator|=
name|pmap_l1_to_l2
argument_list|(
name|l1
argument_list|,
name|kernel_vm_end
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|&
name|PTE_A
operator|)
operator|!=
literal|0
condition|)
block|{
name|kernel_vm_end
operator|=
operator|(
name|kernel_vm_end
operator|+
name|L2_SIZE
operator|)
operator|&
operator|~
name|L2_OFFSET
expr_stmt|;
if|if
condition|(
name|kernel_vm_end
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
block|{
name|kernel_vm_end
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
break|break;
block|}
continue|continue;
block|}
name|nkpg
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|kernel_vm_end
operator|>>
name|L2_SHIFT
argument_list|,
name|VM_ALLOC_INTERRUPT
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|nkpg
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_growkernel: no memory to grow kernel"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|nkpg
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_zero_page
argument_list|(
name|nkpg
argument_list|)
expr_stmt|;
block|}
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|nkpg
argument_list|)
expr_stmt|;
name|pn
operator|=
operator|(
name|paddr
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|entry
operator|=
operator|(
name|PTE_V
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
name|l2
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l2
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|kernel_pmap
argument_list|,
name|kernel_vm_end
argument_list|)
expr_stmt|;
name|kernel_vm_end
operator|=
operator|(
name|kernel_vm_end
operator|+
name|L2_SIZE
operator|)
operator|&
operator|~
name|L2_OFFSET
expr_stmt|;
if|if
condition|(
name|kernel_vm_end
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
block|{
name|kernel_vm_end
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
break|break;
block|}
block|}
block|}
end_function

begin_comment
comment|/***************************************************  * page management routines.  ***************************************************/
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|pv_chunk
argument_list|)
operator|==
name|PAGE_SIZE
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|_NPCM
operator|==
literal|3
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|_NPCPV
operator|==
literal|168
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
specifier|static
name|__inline
expr|struct
name|pv_chunk
operator|*
name|pv_to_chunk
argument_list|(
argument|pv_entry_t pv
argument_list|)
block|{
return|return
operator|(
operator|(
expr|struct
name|pv_chunk
operator|*
operator|)
operator|(
operator|(
name|uintptr_t
operator|)
name|pv
operator|&
operator|~
operator|(
name|uintptr_t
operator|)
name|PAGE_MASK
operator|)
operator|)
return|;
block|}
end_expr_stmt

begin_define
define|#
directive|define
name|PV_PMAP
parameter_list|(
name|pv
parameter_list|)
value|(pv_to_chunk(pv)->pc_pmap)
end_define

begin_define
define|#
directive|define
name|PC_FREE0
value|0xfffffffffffffffful
end_define

begin_define
define|#
directive|define
name|PC_FREE1
value|0xfffffffffffffffful
end_define

begin_define
define|#
directive|define
name|PC_FREE2
value|0x000000fffffffffful
end_define

begin_decl_stmt
specifier|static
specifier|const
name|uint64_t
name|pc_freemask
index|[
name|_NPCM
index|]
init|=
block|{
name|PC_FREE0
block|,
name|PC_FREE1
block|,
name|PC_FREE2
block|}
decl_stmt|;
end_decl_stmt

begin_if
if|#
directive|if
literal|0
end_if

begin_ifdef
ifdef|#
directive|ifdef
name|PV_STATS
end_ifdef

begin_endif
unit|static int pc_chunk_count, pc_chunk_allocs, pc_chunk_frees, pc_chunk_tryfail;  SYSCTL_INT(_vm_pmap, OID_AUTO, pc_chunk_count, CTLFLAG_RD,&pc_chunk_count, 0, 	"Current number of pv entry chunks"); SYSCTL_INT(_vm_pmap, OID_AUTO, pc_chunk_allocs, CTLFLAG_RD,&pc_chunk_allocs, 0, 	"Current number of pv entry chunks allocated"); SYSCTL_INT(_vm_pmap, OID_AUTO, pc_chunk_frees, CTLFLAG_RD,&pc_chunk_frees, 0, 	"Current number of pv entry chunks frees"); SYSCTL_INT(_vm_pmap, OID_AUTO, pc_chunk_tryfail, CTLFLAG_RD,&pc_chunk_tryfail, 0, 	"Number of times tried to get a chunk page but failed.");  static long pv_entry_frees, pv_entry_allocs, pv_entry_count; static int pv_entry_spare;  SYSCTL_LONG(_vm_pmap, OID_AUTO, pv_entry_frees, CTLFLAG_RD,&pv_entry_frees, 0, 	"Current number of pv entry frees"); SYSCTL_LONG(_vm_pmap, OID_AUTO, pv_entry_allocs, CTLFLAG_RD,&pv_entry_allocs, 0, 	"Current number of pv entry allocs"); SYSCTL_LONG(_vm_pmap, OID_AUTO, pv_entry_count, CTLFLAG_RD,&pv_entry_count, 0, 	"Current number of pv entries"); SYSCTL_INT(_vm_pmap, OID_AUTO, pv_entry_spare, CTLFLAG_RD,&pv_entry_spare, 0, 	"Current number of spare pv entries");
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* 0 */
end_comment

begin_comment
comment|/*  * We are in a serious low memory condition.  Resort to  * drastic measures to free some pages so we can allocate  * another pv entry chunk.  *  * Returns NULL if PV entries were reclaimed from the specified pmap.  *  * We do not, however, unmap 2mpages because subsequent accesses will  * allocate per-page pv entries until repromotion occurs, thereby  * exacerbating the shortage of free pv entries.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|reclaim_pv_chunk
parameter_list|(
name|pmap_t
name|locked_pmap
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|panic
argument_list|(
literal|"RISCVTODO: reclaim_pv_chunk"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * free the pv_entry back to the free list  */
end_comment

begin_function
specifier|static
name|void
name|free_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pv_entry_t
name|pv
parameter_list|)
block|{
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|int
name|idx
decl_stmt|,
name|field
decl_stmt|,
name|bit
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_LOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_frees
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_long
argument_list|(
operator|&
name|pv_entry_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|pc
operator|=
name|pv_to_chunk
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|idx
operator|=
name|pv
operator|-
operator|&
name|pc
operator|->
name|pc_pventry
index|[
literal|0
index|]
expr_stmt|;
name|field
operator|=
name|idx
operator|/
literal|64
expr_stmt|;
name|bit
operator|=
name|idx
operator|%
literal|64
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
literal|1ul
operator|<<
name|bit
expr_stmt|;
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|!=
name|PC_FREE0
operator|||
name|pc
operator|->
name|pc_map
index|[
literal|1
index|]
operator|!=
name|PC_FREE1
operator|||
name|pc
operator|->
name|pc_map
index|[
literal|2
index|]
operator|!=
name|PC_FREE2
condition|)
block|{
comment|/* 98% of the time, pc is already at the head of the list. */
if|if
condition|(
name|__predict_false
argument_list|(
name|pc
operator|!=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
argument_list|)
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|free_pv_chunk
argument_list|(
name|pc
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|free_pv_chunk
parameter_list|(
name|struct
name|pv_chunk
modifier|*
name|pc
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
name|_NPCPV
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_int
argument_list|(
operator|&
name|pc_chunk_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pc_chunk_frees
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
comment|/* entire chunk is free, return it */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|DMAP_TO_PHYS
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
argument_list|)
expr_stmt|;
if|#
directive|if
literal|0
comment|/* TODO: For minidump */
block|dump_drop_page(m->phys_addr);
endif|#
directive|endif
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
name|PQ_NONE
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Returns a new PV entry, allocating a new PV chunk from the system when  * needed.  If this PV chunk allocation fails and a PV list lock pointer was  * given, a PV chunk is reclaimed from an arbitrary pmap.  Otherwise, NULL is  * returned.  *  * The given PV list lock may be released.  */
end_comment

begin_function
specifier|static
name|pv_entry_t
name|get_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|int
name|bit
decl_stmt|,
name|field
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_LOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_allocs
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|retry
label|:
name|pc
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
if|if
condition|(
name|pc
operator|!=
name|NULL
condition|)
block|{
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
condition|)
block|{
name|bit
operator|=
name|ffsl
argument_list|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
argument_list|)
operator|-
literal|1
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|field
operator|<
name|_NPCM
condition|)
block|{
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|field
operator|*
literal|64
operator|+
name|bit
index|]
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&=
operator|~
operator|(
literal|1ul
operator|<<
name|bit
operator|)
expr_stmt|;
comment|/* If this was the last item, move it to tail */
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|==
literal|0
operator|&&
name|pc
operator|->
name|pc_map
index|[
literal|1
index|]
operator|==
literal|0
operator|&&
name|pc
operator|->
name|pc_map
index|[
literal|2
index|]
operator|==
literal|0
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
block|}
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
block|}
block|}
comment|/* No free items, allocate another chunk */
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|lockp
operator|==
name|NULL
condition|)
block|{
name|PV_STAT
argument_list|(
name|pc_chunk_tryfail
operator|++
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|m
operator|=
name|reclaim_pv_chunk
argument_list|(
name|pmap
argument_list|,
name|lockp
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
goto|goto
name|retry
goto|;
block|}
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pc_chunk_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pc_chunk_allocs
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
if|#
directive|if
literal|0
comment|/* TODO: This is for minidump */
block|dump_add_page(m->phys_addr);
endif|#
directive|endif
name|pc
operator|=
operator|(
name|void
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|m
operator|->
name|phys_addr
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_pmap
operator|=
name|pmap
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|=
name|PC_FREE0
operator|&
operator|~
literal|1ul
expr_stmt|;
comment|/* preallocated bit 0 */
name|pc
operator|->
name|pc_map
index|[
literal|1
index|]
operator|=
name|PC_FREE1
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
literal|2
index|]
operator|=
name|PC_FREE2
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
literal|0
index|]
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
name|_NPCPV
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * First find and then remove the pv entry for the specified pmap and virtual  * address from the specified pv list.  Returns the pv entry if found and NULL  * otherwise.  This operation can be performed on pv lists for either 4KB or  * 2MB page mappings.  */
end_comment

begin_function
specifier|static
name|__inline
name|pv_entry_t
name|pmap_pvh_remove
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_LOCKED
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|&&
name|va
operator|==
name|pv
operator|->
name|pv_va
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|pvh
operator|->
name|pv_gen
operator|++
expr_stmt|;
break|break;
block|}
block|}
return|return
operator|(
name|pv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * First find and then destroy the pv entry for the specified pmap and virtual  * address.  This operation can be performed on pv lists for either 4KB or 2MB  * page mappings.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_pvh_free
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
name|pvh
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pv
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_pvh_free: pv not found"
operator|)
argument_list|)
expr_stmt|;
name|free_pv_entry
argument_list|(
name|pmap
argument_list|,
name|pv
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Conditionally create the PV entry for a 4KB page mapping if the required  * memory can be allocated without resorting to reclamation.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_try_insert_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_LOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* Pass NULL instead of the lock pointer to disable reclamation. */
if|if
condition|(
operator|(
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|NULL
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_VM_PAGE
argument_list|(
name|lockp
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * pmap_remove_l3: do the things to unmap a page in a process  */
end_comment

begin_function
specifier|static
name|int
name|pmap_remove_l3
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt_entry_t
modifier|*
name|l3
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|l2e
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|pt_entry_t
name|old_l3
decl_stmt|;
name|vm_paddr_t
name|phys
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
operator|&&
name|pmap_l3_valid_cacheable
argument_list|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
argument_list|)
condition|)
name|cpu_dcache_wb_range
argument_list|(
name|va
argument_list|,
name|L3_SIZE
argument_list|)
expr_stmt|;
name|old_l3
operator|=
name|pmap_load_clear
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|old_l3
operator|&
name|PTE_SW_WIRED
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|-=
literal|1
expr_stmt|;
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|old_l3
operator|&
name|PTE_SW_MANAGED
condition|)
block|{
name|phys
operator|=
name|PTE_TO_PHYS
argument_list|(
name|old_l3
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|phys
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_page_dirty
argument_list|(
name|old_l3
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|old_l3
operator|&
name|PTE_A
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_VM_PAGE
argument_list|(
name|lockp
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|pmap_pvh_free
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|pmap_unuse_l3
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|l2e
argument_list|,
name|free
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Remove the given range of addresses from the specified map.  *  *	It is assumed that the start and end are properly  *	rounded to the page size.  */
end_comment

begin_function
name|void
name|pmap_remove
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|va_next
decl_stmt|;
name|pd_entry_t
modifier|*
name|l1
decl_stmt|,
modifier|*
name|l2
decl_stmt|;
name|pt_entry_t
name|l3_pte
decl_stmt|,
modifier|*
name|l3
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|int
name|anyvalid
decl_stmt|;
comment|/* 	 * Perform an unsynchronized read.  This is, however, safe. 	 */
if|if
condition|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
condition|)
return|return;
name|anyvalid
operator|=
literal|0
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|lock
operator|=
name|NULL
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|va_next
control|)
block|{
if|if
condition|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
condition|)
break|break;
name|l1
operator|=
name|pmap_l1
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|L1_SIZE
operator|)
operator|&
operator|~
name|L1_OFFSET
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Calculate index for next page table. 		 */
name|va_next
operator|=
operator|(
name|sva
operator|+
name|L2_SIZE
operator|)
operator|&
operator|~
name|L2_OFFSET
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
name|l2
operator|=
name|pmap_l1_to_l2
argument_list|(
name|l1
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2
operator|==
name|NULL
condition|)
continue|continue;
name|l3_pte
operator|=
name|pmap_load
argument_list|(
name|l2
argument_list|)
expr_stmt|;
comment|/* 		 * Weed out invalid mappings. 		 */
if|if
condition|(
name|l3_pte
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|&
name|PTE_RX
operator|)
operator|!=
literal|0
condition|)
continue|continue;
comment|/* 		 * Limit our scan to either the end of the va represented 		 * by the current page table page, or to the end of the 		 * range being removed. 		 */
if|if
condition|(
name|va_next
operator|>
name|eva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
name|va
operator|=
name|va_next
expr_stmt|;
for|for
control|(
name|l3
operator|=
name|pmap_l2_to_l3
argument_list|(
name|l2
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|va_next
condition|;
name|l3
operator|++
operator|,
name|sva
operator|+=
name|L3_SIZE
control|)
block|{
if|if
condition|(
name|l3
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"l3 == NULL"
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|va
operator|!=
name|va_next
condition|)
block|{
name|pmap_invalidate_range
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|va
operator|=
name|va_next
expr_stmt|;
block|}
continue|continue;
block|}
if|if
condition|(
name|va
operator|==
name|va_next
condition|)
name|va
operator|=
name|sva
expr_stmt|;
if|if
condition|(
name|pmap_remove_l3
argument_list|(
name|pmap
argument_list|,
name|l3
argument_list|,
name|sva
argument_list|,
name|l3_pte
argument_list|,
operator|&
name|free
argument_list|,
operator|&
name|lock
argument_list|)
condition|)
block|{
name|sva
operator|+=
name|L3_SIZE
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|va
operator|!=
name|va_next
condition|)
name|pmap_invalidate_range
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|sva
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|anyvalid
condition|)
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Routine:	pmap_remove_all  *	Function:  *		Removes this physical page from  *		all physical maps in which it resides.  *		Reflects back modify bits to the pager.  *  *	Notes:  *		Original versions of this routine were very  *		inefficient because they iteratively called  *		pmap_remove (slow...)  */
end_comment

begin_function
name|void
name|pmap_remove_all
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|,
name|tl3
decl_stmt|;
name|pd_entry_t
modifier|*
name|l2
decl_stmt|,
name|tl2
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_all: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|l2
operator|=
name|pmap_l2
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|l2
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_remove_all: no l2 table found"
operator|)
argument_list|)
expr_stmt|;
name|tl2
operator|=
name|pmap_load
argument_list|(
name|l2
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|tl2
operator|&
name|PTE_RX
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_all: found a table when expecting "
literal|"a block in %p's pv list"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|l3
operator|=
name|pmap_l2_to_l3
argument_list|(
name|l2
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
operator|&&
name|pmap_l3_valid_cacheable
argument_list|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
argument_list|)
condition|)
name|cpu_dcache_wb_range
argument_list|(
name|pv
operator|->
name|pv_va
argument_list|,
name|L3_SIZE
argument_list|)
expr_stmt|;
name|tl3
operator|=
name|pmap_load_clear
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
name|tl3
operator|&
name|PTE_SW_WIRED
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
if|if
condition|(
operator|(
name|tl3
operator|&
name|PTE_A
operator|)
operator|!=
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
comment|/* 		 * Update the vm_page_t clean and reference bits. 		 */
if|if
condition|(
name|pmap_page_dirty
argument_list|(
name|tl3
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_unuse_l3
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
name|pmap_load
argument_list|(
name|l2
argument_list|)
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
name|free_pv_entry
argument_list|(
name|pmap
argument_list|,
name|pv
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Set the physical protection on the  *	specified range of this map as requested.  */
end_comment

begin_function
name|void
name|pmap_protect
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|,
name|va_next
decl_stmt|;
name|pd_entry_t
modifier|*
name|l1
decl_stmt|,
modifier|*
name|l2
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3p
decl_stmt|,
name|l3
decl_stmt|;
name|pt_entry_t
name|entry
decl_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_READ
operator|)
operator|==
name|VM_PROT_NONE
condition|)
block|{
name|pmap_remove
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
name|VM_PROT_WRITE
condition|)
return|return;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|va_next
control|)
block|{
name|l1
operator|=
name|pmap_l1
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|L1_SIZE
operator|)
operator|&
operator|~
name|L1_OFFSET
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
name|va_next
operator|=
operator|(
name|sva
operator|+
name|L2_SIZE
operator|)
operator|&
operator|~
name|L2_OFFSET
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
name|l2
operator|=
name|pmap_l1_to_l2
argument_list|(
name|l1
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2
operator|==
name|NULL
condition|)
continue|continue;
if|if
condition|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|&
name|PTE_RX
operator|)
operator|!=
literal|0
condition|)
continue|continue;
if|if
condition|(
name|va_next
operator|>
name|eva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
name|va
operator|=
name|va_next
expr_stmt|;
for|for
control|(
name|l3p
operator|=
name|pmap_l2_to_l3
argument_list|(
name|l2
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|va_next
condition|;
name|l3p
operator|++
operator|,
name|sva
operator|+=
name|L3_SIZE
control|)
block|{
name|l3
operator|=
name|pmap_load
argument_list|(
name|l3p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_l3_valid
argument_list|(
name|l3
argument_list|)
condition|)
block|{
name|entry
operator|=
name|pmap_load
argument_list|(
name|l3p
argument_list|)
expr_stmt|;
name|entry
operator|&=
operator|~
operator|(
name|PTE_W
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
name|l3p
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3p
argument_list|)
expr_stmt|;
comment|/* XXX: Use pmap_invalidate_range */
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* TODO: Only invalidate entries we are touching */
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Insert the given physical page (p) at  *	the specified virtual address (v) in the  *	target physical map with the protection requested.  *  *	If specified, the page will be wired down, meaning  *	that the related pte can not be reclaimed.  *  *	NB:  This is the only routine which MAY NOT lazy-evaluate  *	or lose information.  That is, this routine must actually  *	insert this page into the given map NOW.  */
end_comment

begin_function
name|int
name|pmap_enter
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|u_int
name|flags
parameter_list|,
name|int8_t
name|psind
name|__unused
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pd_entry_t
modifier|*
name|l1
decl_stmt|,
modifier|*
name|l2
decl_stmt|;
name|pt_entry_t
name|new_l3
decl_stmt|,
name|orig_l3
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_paddr_t
name|opa
decl_stmt|,
name|pa
decl_stmt|,
name|l2_pa
decl_stmt|,
name|l3_pa
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|,
name|om
decl_stmt|,
name|l2_m
decl_stmt|,
name|l3_m
decl_stmt|;
name|boolean_t
name|nosleep
decl_stmt|;
name|pt_entry_t
name|entry
decl_stmt|;
name|pn_t
name|l2_pn
decl_stmt|;
name|pn_t
name|l3_pn
decl_stmt|;
name|pn_t
name|pn
decl_stmt|;
name|va
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|&&
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pn
operator|=
operator|(
name|pa
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|new_l3
operator|=
name|PTE_V
operator||
name|PTE_R
operator||
name|PTE_X
expr_stmt|;
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
name|new_l3
operator||=
name|PTE_W
expr_stmt|;
if|if
condition|(
operator|(
name|va
operator|>>
literal|63
operator|)
operator|==
literal|0
condition|)
name|new_l3
operator||=
name|PTE_U
expr_stmt|;
name|new_l3
operator||=
operator|(
name|pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|flags
operator|&
name|PMAP_ENTER_WIRED
operator|)
operator|!=
literal|0
condition|)
name|new_l3
operator||=
name|PTE_SW_WIRED
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_enter: %.16lx -> %.16lx"
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|NULL
expr_stmt|;
name|lock
operator|=
name|NULL
expr_stmt|;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
block|{
name|nosleep
operator|=
operator|(
name|flags
operator|&
name|PMAP_ENTER_NOSLEEP
operator|)
operator|!=
literal|0
expr_stmt|;
name|mpte
operator|=
name|pmap_alloc_l3
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|nosleep
condition|?
name|NULL
else|:
operator|&
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|==
name|NULL
operator|&&
name|nosleep
condition|)
block|{
name|CTR0
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_enter: mpte == NULL"
argument_list|)
expr_stmt|;
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_RESOURCE_SHORTAGE
operator|)
return|;
block|}
name|l3
operator|=
name|pmap_l3
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|l3
operator|=
name|pmap_l3
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* TODO: This is not optimal, but should mostly work */
if|if
condition|(
name|l3
operator|==
name|NULL
condition|)
block|{
name|l2
operator|=
name|pmap_l2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2
operator|==
name|NULL
condition|)
block|{
name|l2_m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|l2_m
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_enter: l2 pte_m == NULL"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|l2_m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|l2_m
argument_list|)
expr_stmt|;
name|l2_pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|l2_m
argument_list|)
expr_stmt|;
name|l2_pn
operator|=
operator|(
name|l2_pa
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|l1
operator|=
name|pmap_l1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|entry
operator|=
operator|(
name|PTE_V
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|l2_pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
name|l1
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|pmap_distribute_l1
argument_list|(
name|pmap
argument_list|,
name|pmap_l1_index
argument_list|(
name|va
argument_list|)
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l1
argument_list|)
expr_stmt|;
name|l2
operator|=
name|pmap_l1_to_l2
argument_list|(
name|l1
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|l2
operator|!=
name|NULL
argument_list|,
operator|(
literal|"No l2 table after allocating one"
operator|)
argument_list|)
expr_stmt|;
name|l3_m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|l3_m
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_enter: l3 pte_m == NULL"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|l3_m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|l3_m
argument_list|)
expr_stmt|;
name|l3_pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|l3_m
argument_list|)
expr_stmt|;
name|l3_pn
operator|=
operator|(
name|l3_pa
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
name|entry
operator|=
operator|(
name|PTE_V
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|l3_pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
name|pmap_load_store
argument_list|(
name|l2
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l2
argument_list|)
expr_stmt|;
name|l3
operator|=
name|pmap_l2_to_l3
argument_list|(
name|l2
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
name|om
operator|=
name|NULL
expr_stmt|;
name|orig_l3
operator|=
name|pmap_load
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|opa
operator|=
name|PTE_TO_PHYS
argument_list|(
name|orig_l3
argument_list|)
expr_stmt|;
comment|/* 	 * Is the specified virtual address already mapped? 	 */
if|if
condition|(
name|pmap_l3_valid
argument_list|(
name|orig_l3
argument_list|)
condition|)
block|{
comment|/* 		 * Wiring change, just update stats. We don't worry about 		 * wiring PT pages as they remain resident as long as there 		 * are valid mappings in them. Hence, if a user page is wired, 		 * the PT page will be also. 		 */
if|if
condition|(
operator|(
name|flags
operator|&
name|PMAP_ENTER_WIRED
operator|)
operator|!=
literal|0
operator|&&
operator|(
name|orig_l3
operator|&
name|PTE_SW_WIRED
operator|)
operator|==
literal|0
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|flags
operator|&
name|PMAP_ENTER_WIRED
operator|)
operator|==
literal|0
operator|&&
operator|(
name|orig_l3
operator|&
name|PTE_SW_WIRED
operator|)
operator|!=
literal|0
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
comment|/* 		 * Remove the extra PT page reference. 		 */
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|--
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|->
name|wire_count
operator|>
literal|0
argument_list|,
operator|(
literal|"pmap_enter: missing reference to page table page,"
literal|" va: 0x%lx"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Has the physical page changed? 		 */
if|if
condition|(
name|opa
operator|==
name|pa
condition|)
block|{
comment|/* 			 * No, might be a protection or wiring change. 			 */
if|if
condition|(
operator|(
name|orig_l3
operator|&
name|PTE_SW_MANAGED
operator|)
operator|!=
literal|0
condition|)
block|{
name|new_l3
operator||=
name|PTE_SW_MANAGED
expr_stmt|;
if|if
condition|(
name|pmap_is_write
argument_list|(
name|new_l3
argument_list|)
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
goto|goto
name|validate
goto|;
block|}
comment|/* Flush the cache, there might be uncommitted data in it */
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
operator|&&
name|pmap_l3_valid_cacheable
argument_list|(
name|orig_l3
argument_list|)
condition|)
name|cpu_dcache_wb_range
argument_list|(
name|va
argument_list|,
name|L3_SIZE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Increment the counters. 		 */
if|if
condition|(
operator|(
name|new_l3
operator|&
name|PTE_SW_WIRED
operator|)
operator|!=
literal|0
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
name|pmap_resident_count_inc
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Enter on the PV list if part of our managed memory. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|new_l3
operator||=
name|PTE_SW_MANAGED
expr_stmt|;
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_PHYS
argument_list|(
operator|&
name|lock
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
if|if
condition|(
name|pmap_is_write
argument_list|(
name|new_l3
argument_list|)
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Update the L3 entry. 	 */
if|if
condition|(
name|orig_l3
operator|!=
literal|0
condition|)
block|{
name|validate
label|:
name|orig_l3
operator|=
name|pmap_load_store
argument_list|(
name|l3
argument_list|,
name|new_l3
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|opa
operator|=
name|PTE_TO_PHYS
argument_list|(
name|orig_l3
argument_list|)
expr_stmt|;
if|if
condition|(
name|opa
operator|!=
name|pa
condition|)
block|{
if|if
condition|(
operator|(
name|orig_l3
operator|&
name|PTE_SW_MANAGED
operator|)
operator|!=
literal|0
condition|)
block|{
name|om
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|opa
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_page_dirty
argument_list|(
name|orig_l3
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|om
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|orig_l3
operator|&
name|PTE_A
operator|)
operator|!=
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|om
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_PHYS
argument_list|(
operator|&
name|lock
argument_list|,
name|opa
argument_list|)
expr_stmt|;
name|pmap_pvh_free
argument_list|(
operator|&
name|om
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|pmap_page_dirty
argument_list|(
name|orig_l3
argument_list|)
condition|)
block|{
if|if
condition|(
operator|(
name|orig_l3
operator|&
name|PTE_SW_MANAGED
operator|)
operator|!=
literal|0
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|pmap_load_store
argument_list|(
name|l3
argument_list|,
name|new_l3
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
block|}
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pmap
operator|!=
name|pmap_kernel
argument_list|()
operator|)
operator|&&
operator|(
name|pmap
operator|==
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
operator|)
condition|)
name|cpu_icache_sync_range
argument_list|(
name|va
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_SUCCESS
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Maps a sequence of resident pages belonging to the same object.  * The sequence begins with the given page m_start.  This page is  * mapped at the given virtual address start.  Each subsequent page is  * mapped at a virtual address that is offset from start by the same  * amount as the page is offset from m_start within the object.  The  * last page in the sequence is the page with the largest offset from  * m_start that can be mapped at a virtual address less than the given  * virtual address end.  Not every virtual page between start and end  * is mapped; only those for which a resident page exists with the  * corresponding offset from m_start are mapped.  */
end_comment

begin_function
name|void
name|pmap_enter_object
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|start
parameter_list|,
name|vm_offset_t
name|end
parameter_list|,
name|vm_page_t
name|m_start
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mpte
decl_stmt|;
name|vm_pindex_t
name|diff
decl_stmt|,
name|psize
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m_start
operator|->
name|object
argument_list|)
expr_stmt|;
name|psize
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|NULL
expr_stmt|;
name|m
operator|=
name|m_start
expr_stmt|;
name|lock
operator|=
name|NULL
expr_stmt|;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
while|while
condition|(
name|m
operator|!=
name|NULL
operator|&&
operator|(
name|diff
operator|=
name|m
operator|->
name|pindex
operator|-
name|m_start
operator|->
name|pindex
operator|)
operator|<
name|psize
condition|)
block|{
name|va
operator|=
name|start
operator|+
name|ptoa
argument_list|(
name|diff
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|pmap_enter_quick_locked
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
name|mpte
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|m
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * this code makes some *MAJOR* assumptions:  * 1. Current pmap& pmap exists.  * 2. Not wired.  * 3. Read access.  * 4. No page table pages.  * but is *MUCH* faster than pmap_enter...  */
end_comment

begin_function
name|void
name|pmap_enter_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|lock
operator|=
name|NULL
expr_stmt|;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|pmap_enter_quick_locked
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
name|NULL
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|vm_page_t
name|pmap_enter_quick_locked
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|vm_page_t
name|mpte
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|struct
name|spglist
name|free
decl_stmt|;
name|vm_paddr_t
name|phys
decl_stmt|;
name|pd_entry_t
modifier|*
name|l2
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|pt_entry_t
name|entry
decl_stmt|;
name|pn_t
name|pn
decl_stmt|;
name|KASSERT
argument_list|(
name|va
operator|<
name|kmi
operator|.
name|clean_sva
operator|||
name|va
operator|>=
name|kmi
operator|.
name|clean_eva
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_enter_quick_locked: managed mapping within the clean submap"
operator|)
argument_list|)
expr_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_LOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_enter_quick_locked: %p %lx"
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * In the case that a page table page is not 	 * resident, we are creating it here. 	 */
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
block|{
name|vm_pindex_t
name|l2pindex
decl_stmt|;
comment|/* 		 * Calculate pagetable page index 		 */
name|l2pindex
operator|=
name|pmap_l2_pindex
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|&&
operator|(
name|mpte
operator|->
name|pindex
operator|==
name|l2pindex
operator|)
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * Get the l2 entry 			 */
name|l2
operator|=
name|pmap_l2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 			 * If the page table page is mapped, we just increment 			 * the hold count, and activate it.  Otherwise, we 			 * attempt to allocate a page table page.  If this 			 * attempt fails, we don't retry.  Instead, we give up. 			 */
if|if
condition|(
name|l2
operator|!=
name|NULL
operator|&&
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|phys
operator|=
name|PTE_TO_PHYS
argument_list|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|phys
argument_list|)
expr_stmt|;
name|mpte
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* 				 * Pass NULL instead of the PV list lock 				 * pointer, because we don't intend to sleep. 				 */
name|mpte
operator|=
name|_pmap_alloc_l3
argument_list|(
name|pmap
argument_list|,
name|l2pindex
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|==
name|NULL
condition|)
return|return
operator|(
name|mpte
operator|)
return|;
block|}
block|}
name|l3
operator|=
operator|(
name|pt_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|mpte
argument_list|)
argument_list|)
expr_stmt|;
name|l3
operator|=
operator|&
name|l3
index|[
name|pmap_l3_index
argument_list|(
name|va
argument_list|)
index|]
expr_stmt|;
block|}
else|else
block|{
name|mpte
operator|=
name|NULL
expr_stmt|;
name|l3
operator|=
name|pmap_l3
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|l3
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_enter_quick_locked: No l3"
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|--
expr_stmt|;
name|mpte
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|mpte
operator|)
return|;
block|}
comment|/* 	 * Enter on the PV list if part of our managed memory. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|&&
operator|!
name|pmap_try_insert_pv_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|lockp
argument_list|)
condition|)
block|{
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_unwire_l3
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|mpte
argument_list|,
operator|&
name|free
argument_list|)
condition|)
block|{
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
name|mpte
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|mpte
operator|)
return|;
block|}
comment|/* 	 * Increment counters 	 */
name|pmap_resident_count_inc
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pn
operator|=
operator|(
name|pa
operator|/
name|PAGE_SIZE
operator|)
expr_stmt|;
comment|/* RISCVTODO: check permissions */
name|entry
operator|=
operator|(
name|PTE_V
operator||
name|PTE_RWX
operator|)
expr_stmt|;
name|entry
operator||=
operator|(
name|pn
operator|<<
name|PTE_PPN0_S
operator|)
expr_stmt|;
comment|/* 	 * Now validate mapping with RO protection 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|entry
operator||=
name|PTE_SW_MANAGED
expr_stmt|;
name|pmap_load_store
argument_list|(
name|l3
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
return|return
operator|(
name|mpte
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This code maps large physical mmap regions into the  * processor address space.  Note that some shortcuts  * are taken, but the code works.  */
end_comment

begin_function
name|void
name|pmap_object_init_pt
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|object
operator|->
name|type
operator|==
name|OBJT_DEVICE
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_SG
argument_list|,
operator|(
literal|"pmap_object_init_pt: non-device object"
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Clear the wired attribute from the mappings for the specified range of  *	addresses in the given pmap.  Every valid mapping within that range  *	must have the wired attribute set.  In contrast, invalid mappings  *	cannot have the wired attribute set, so they are ignored.  *  *	The wired attribute of the page table entry is not a hardware feature,  *	so there is no need to invalidate any TLB entries.  */
end_comment

begin_function
name|void
name|pmap_unwire
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|vm_offset_t
name|va_next
decl_stmt|;
name|pd_entry_t
modifier|*
name|l1
decl_stmt|,
modifier|*
name|l2
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|boolean_t
name|pv_lists_locked
decl_stmt|;
name|pv_lists_locked
operator|=
name|FALSE
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|va_next
control|)
block|{
name|l1
operator|=
name|pmap_l1
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_load
argument_list|(
name|l1
argument_list|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|L1_SIZE
operator|)
operator|&
operator|~
name|L1_OFFSET
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
name|va_next
operator|=
operator|(
name|sva
operator|+
name|L2_SIZE
operator|)
operator|&
operator|~
name|L2_OFFSET
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
name|l2
operator|=
name|pmap_l1_to_l2
argument_list|(
name|l1
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|va_next
operator|>
name|eva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|l3
operator|=
name|pmap_l2_to_l3
argument_list|(
name|l2
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|va_next
condition|;
name|l3
operator|++
operator|,
name|sva
operator|+=
name|L3_SIZE
control|)
block|{
if|if
condition|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
operator|&
name|PTE_SW_WIRED
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_unwire: l3 %#jx is missing "
literal|"PTE_SW_WIRED"
argument_list|,
operator|(
name|uintmax_t
operator|)
operator|*
name|l3
argument_list|)
expr_stmt|;
comment|/* 			 * PG_W must be cleared atomically.  Although the pmap 			 * lock synchronizes access to PG_W, another processor 			 * could be setting PG_M and/or PG_A concurrently. 			 */
name|atomic_clear_long
argument_list|(
name|l3
argument_list|,
name|PTE_SW_WIRED
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pv_lists_locked
condition|)
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Copy the range specified by src_addr/len  *	from the source map to the range dst_addr/len  *	in the destination map.  *  *	This routine is only advisory and need not do anything.  */
end_comment

begin_function
name|void
name|pmap_copy
parameter_list|(
name|pmap_t
name|dst_pmap
parameter_list|,
name|pmap_t
name|src_pmap
parameter_list|,
name|vm_offset_t
name|dst_addr
parameter_list|,
name|vm_size_t
name|len
parameter_list|,
name|vm_offset_t
name|src_addr
parameter_list|)
block|{  }
end_function

begin_comment
comment|/*  *	pmap_zero_page zeros the specified hardware page by mapping  *	the page into KVM and using bzero to clear its contents.  */
end_comment

begin_function
name|void
name|pmap_zero_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_offset_t
name|va
init|=
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
decl_stmt|;
name|pagezero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	pmap_zero_page_area zeros the specified hardware page by mapping   *	the page into KVM and using bzero to clear its contents.  *  *	off and size may not cover an area beyond a single hardware page.  */
end_comment

begin_function
name|void
name|pmap_zero_page_area
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_offset_t
name|va
init|=
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|off
operator|==
literal|0
operator|&&
name|size
operator|==
name|PAGE_SIZE
condition|)
name|pagezero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|)
expr_stmt|;
else|else
name|bzero
argument_list|(
operator|(
name|char
operator|*
operator|)
name|va
operator|+
name|off
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	pmap_copy_page copies the specified (machine independent)  *	page by mapping the page into virtual memory and using  *	bcopy to copy the page, one machine dependent page at a  *	time.  */
end_comment

begin_function
name|void
name|pmap_copy_page
parameter_list|(
name|vm_page_t
name|msrc
parameter_list|,
name|vm_page_t
name|mdst
parameter_list|)
block|{
name|vm_offset_t
name|src
init|=
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|msrc
argument_list|)
argument_list|)
decl_stmt|;
name|vm_offset_t
name|dst
init|=
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|mdst
argument_list|)
argument_list|)
decl_stmt|;
name|pagecopy
argument_list|(
operator|(
name|void
operator|*
operator|)
name|src
argument_list|,
operator|(
name|void
operator|*
operator|)
name|dst
argument_list|)
expr_stmt|;
block|}
end_function

begin_decl_stmt
name|int
name|unmapped_buf_allowed
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|pmap_copy_pages
parameter_list|(
name|vm_page_t
name|ma
index|[]
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
name|mb
index|[]
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
block|{
name|void
modifier|*
name|a_cp
decl_stmt|,
modifier|*
name|b_cp
decl_stmt|;
name|vm_page_t
name|m_a
decl_stmt|,
name|m_b
decl_stmt|;
name|vm_paddr_t
name|p_a
decl_stmt|,
name|p_b
decl_stmt|;
name|vm_offset_t
name|a_pg_offset
decl_stmt|,
name|b_pg_offset
decl_stmt|;
name|int
name|cnt
decl_stmt|;
while|while
condition|(
name|xfersize
operator|>
literal|0
condition|)
block|{
name|a_pg_offset
operator|=
name|a_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|m_a
operator|=
name|ma
index|[
name|a_offset
operator|>>
name|PAGE_SHIFT
index|]
expr_stmt|;
name|p_a
operator|=
name|m_a
operator|->
name|phys_addr
expr_stmt|;
name|b_pg_offset
operator|=
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|m_b
operator|=
name|mb
index|[
name|b_offset
operator|>>
name|PAGE_SHIFT
index|]
expr_stmt|;
name|p_b
operator|=
name|m_b
operator|->
name|phys_addr
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|xfersize
argument_list|,
name|PAGE_SIZE
operator|-
name|a_pg_offset
argument_list|)
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|cnt
argument_list|,
name|PAGE_SIZE
operator|-
name|b_pg_offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|__predict_false
argument_list|(
operator|!
name|PHYS_IN_DMAP
argument_list|(
name|p_a
argument_list|)
argument_list|)
condition|)
block|{
name|panic
argument_list|(
literal|"!DMAP a %lx"
argument_list|,
name|p_a
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|a_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|p_a
argument_list|)
operator|+
name|a_pg_offset
expr_stmt|;
block|}
if|if
condition|(
name|__predict_false
argument_list|(
operator|!
name|PHYS_IN_DMAP
argument_list|(
name|p_b
argument_list|)
argument_list|)
condition|)
block|{
name|panic
argument_list|(
literal|"!DMAP b %lx"
argument_list|,
name|p_b
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|b_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|p_b
argument_list|)
operator|+
name|b_pg_offset
expr_stmt|;
block|}
name|bcopy
argument_list|(
name|a_cp
argument_list|,
name|b_cp
argument_list|,
name|cnt
argument_list|)
expr_stmt|;
name|a_offset
operator|+=
name|cnt
expr_stmt|;
name|b_offset
operator|+=
name|cnt
expr_stmt|;
name|xfersize
operator|-=
name|cnt
expr_stmt|;
block|}
block|}
end_function

begin_function
name|vm_offset_t
name|pmap_quick_enter_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
return|return
operator|(
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_quick_remove_page
parameter_list|(
name|vm_offset_t
name|addr
parameter_list|)
block|{ }
end_function

begin_comment
comment|/*  * Returns true if the pmap's pv is one of the first  * 16 pvs linked to from this page.  This count may  * be changed upwards or downwards in the future; it  * is only necessary that true be returned for a small  * subset of pmaps for proper page aging.  */
end_comment

begin_function
name|boolean_t
name|pmap_page_exists_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|int
name|loops
init|=
literal|0
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_page_exists_quick: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|==
name|pmap
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
name|loops
operator|++
expr_stmt|;
if|if
condition|(
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_page_wired_mappings:  *  *	Return the number of managed mappings to the given physical page  *	that are wired.  */
end_comment

begin_function
name|int
name|pmap_page_wired_mappings
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|int
name|count
decl_stmt|,
name|md_gen
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|restart
label|:
name|count
operator|=
literal|0
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
block|}
name|l3
operator|=
name|pmap_l3
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
name|l3
operator|!=
name|NULL
operator|&&
operator|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
operator|&
name|PTE_SW_WIRED
operator|)
operator|!=
literal|0
condition|)
name|count
operator|++
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Destroy all managed, non-wired mappings in the given user-space  * pmap.  This pmap cannot be active on any processor besides the  * caller.  *  * This function cannot be applied to the kernel pmap.  Moreover, it  * is not intended for general use.  It is only to be used during  * process termination.  Consequently, it can be implemented in ways  * that make it faster than pmap_remove().  First, it can more quickly  * destroy mappings by iterating over the pmap's collection of PV  * entries, rather than searching the page table.  Second, it doesn't  * have to test and clear the page table entries atomically, because  * no processor is currently accessing the user address space.  In  * particular, a page table entry's dirty bit won't change state once  * this function starts.  */
end_comment

begin_function
name|void
name|pmap_remove_pages
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|pd_entry_t
name|ptepde
decl_stmt|,
modifier|*
name|l2
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|,
name|tl3
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|,
modifier|*
name|npc
decl_stmt|;
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|int64_t
name|bit
decl_stmt|;
name|uint64_t
name|inuse
decl_stmt|,
name|bitmask
decl_stmt|;
name|int
name|allfree
decl_stmt|,
name|field
decl_stmt|,
name|freed
decl_stmt|,
name|idx
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|lock
operator|=
name|NULL
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|pc
argument_list|,
argument|&pmap->pm_pvchunk
argument_list|,
argument|pc_list
argument_list|,
argument|npc
argument_list|)
block|{
name|allfree
operator|=
literal|1
expr_stmt|;
name|freed
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
name|inuse
operator|=
operator|~
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&
name|pc_freemask
index|[
name|field
index|]
expr_stmt|;
while|while
condition|(
name|inuse
operator|!=
literal|0
condition|)
block|{
name|bit
operator|=
name|ffsl
argument_list|(
name|inuse
argument_list|)
operator|-
literal|1
expr_stmt|;
name|bitmask
operator|=
literal|1UL
operator|<<
name|bit
expr_stmt|;
name|idx
operator|=
name|field
operator|*
literal|64
operator|+
name|bit
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|idx
index|]
expr_stmt|;
name|inuse
operator|&=
operator|~
name|bitmask
expr_stmt|;
name|l2
operator|=
name|pmap_l2
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|ptepde
operator|=
name|pmap_load
argument_list|(
name|l2
argument_list|)
expr_stmt|;
name|l3
operator|=
name|pmap_l2_to_l3
argument_list|(
name|l2
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|tl3
operator|=
name|pmap_load
argument_list|(
name|l3
argument_list|)
expr_stmt|;
comment|/*  * We cannot remove wired pages from a process' mapping at this time  */
if|if
condition|(
name|tl3
operator|&
name|PTE_SW_WIRED
condition|)
block|{
name|allfree
operator|=
literal|0
expr_stmt|;
continue|continue;
block|}
name|pa
operator|=
name|PTE_TO_PHYS
argument_list|(
name|tl3
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|phys_addr
operator|==
name|pa
argument_list|,
operator|(
literal|"vm_page_t %p phys_addr mismatch %016jx %016jx"
operator|,
name|m
operator|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|phys_addr
operator|,
operator|(
name|uintmax_t
operator|)
name|tl3
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
operator|||
name|m
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"pmap_remove_pages: bad l3 %#jx"
operator|,
operator|(
name|uintmax_t
operator|)
name|tl3
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
operator|&&
name|pmap_l3_valid_cacheable
argument_list|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
argument_list|)
condition|)
name|cpu_dcache_wb_range
argument_list|(
name|pv
operator|->
name|pv_va
argument_list|,
name|L3_SIZE
argument_list|)
expr_stmt|;
name|pmap_load_clear
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|PTE_SYNC
argument_list|(
name|l3
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
comment|/* 				 * Update the vm_page_t clean/reference bits. 				 */
if|if
condition|(
name|pmap_page_dirty
argument_list|(
name|tl3
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_VM_PAGE
argument_list|(
operator|&
name|lock
argument_list|,
name|m
argument_list|)
expr_stmt|;
comment|/* Mark free */
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
name|bitmask
expr_stmt|;
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
name|pmap_unuse_l3
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
name|ptepde
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
name|freed
operator|++
expr_stmt|;
block|}
block|}
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_frees
argument_list|,
name|freed
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
name|freed
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_long
argument_list|(
operator|&
name|pv_entry_count
argument_list|,
name|freed
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|allfree
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|free_pv_chunk
argument_list|(
name|pc
argument_list|)
expr_stmt|;
block|}
block|}
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This is used to check if a page has been accessed or modified. As we  * don't have a bit to see if it has been modified we have to assume it  * has been if the page is read/write.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_page_test_mappings
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|boolean_t
name|accessed
parameter_list|,
name|boolean_t
name|modified
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|,
name|mask
decl_stmt|,
name|value
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|int
name|md_gen
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|restart
label|:
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
block|}
name|l3
operator|=
name|pmap_l3
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|mask
operator|=
literal|0
expr_stmt|;
name|value
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|modified
condition|)
block|{
name|mask
operator||=
name|PTE_D
expr_stmt|;
name|value
operator||=
name|PTE_D
expr_stmt|;
block|}
if|if
condition|(
name|accessed
condition|)
block|{
name|mask
operator||=
name|PTE_A
expr_stmt|;
name|value
operator||=
name|PTE_A
expr_stmt|;
block|}
if|#
directive|if
literal|0
block|if (modified) { 			mask |= ATTR_AP_RW_BIT; 			value |= ATTR_AP(ATTR_AP_RW); 		} 		if (accessed) { 			mask |= ATTR_AF | ATTR_DESCR_MASK; 			value |= ATTR_AF | L3_PAGE; 		}
endif|#
directive|endif
name|rv
operator|=
operator|(
name|pmap_load
argument_list|(
name|l3
argument_list|)
operator|&
name|mask
operator|)
operator|==
name|value
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
condition|)
goto|goto
name|out
goto|;
block|}
name|out
label|:
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_modified:  *  *	Return whether or not the specified physical page was modified  *	in any physical maps.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_modified
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_is_modified: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not exclusive busied, then PGA_WRITEABLE cannot be 	 * concurrently set while the object is locked.  Thus, if PGA_WRITEABLE 	 * is clear, no PTEs can have PG_M set. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
return|return
operator|(
name|pmap_page_test_mappings
argument_list|(
name|m
argument_list|,
name|FALSE
argument_list|,
name|TRUE
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_prefaultable:  *  *	Return whether or not the specified virtual address is eligible  *	for prefault.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_prefaultable
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|l3
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|l3
operator|=
name|pmap_l3
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
name|l3
operator|!=
name|NULL
operator|&&
name|pmap_load
argument_list|(
name|l3
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_referenced:  *  *	Return whether or not the specified physical page was referenced  *	in any physical maps.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_referenced
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_is_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|pmap_page_test_mappings
argument_list|(
name|m
argument_list|,
name|TRUE
argument_list|,
name|FALSE
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Clear the write and modified bits in each of the given page's mappings.  */
end_comment

begin_function
name|void
name|pmap_remove_write
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|,
name|oldl3
decl_stmt|;
name|pt_entry_t
name|newl3
decl_stmt|;
name|int
name|md_gen
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_write: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not exclusive busied, then PGA_WRITEABLE cannot be 	 * set by another thread while the object is locked.  Thus, 	 * if PGA_WRITEABLE is clear, no page table entries need updating. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|retry_pv_loop
label|:
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
goto|goto
name|retry_pv_loop
goto|;
block|}
block|}
name|l3
operator|=
name|pmap_l3
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|retry
label|:
name|oldl3
operator|=
name|pmap_load
argument_list|(
name|l3
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_is_write
argument_list|(
name|oldl3
argument_list|)
condition|)
block|{
name|newl3
operator|=
name|oldl3
operator|&
operator|~
operator|(
name|PTE_W
operator|)
expr_stmt|;
if|if
condition|(
operator|!
name|atomic_cmpset_long
argument_list|(
name|l3
argument_list|,
name|oldl3
argument_list|,
name|newl3
argument_list|)
condition|)
goto|goto
name|retry
goto|;
comment|/* TODO: use pmap_page_dirty(oldl3) ? */
if|if
condition|(
operator|(
name|oldl3
operator|&
name|PTE_A
operator|)
operator|!=
literal|0
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|boolean_t
name|safe_to_clear_referenced
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt_entry_t
name|pte
parameter_list|)
block|{
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_ts_referenced:  *  *	Return a count of reference bits for a page, clearing those bits.  *	It is not necessary for every reference bit to be cleared, but it  *	is necessary that 0 only be returned when there are truly no  *	reference bits set.  *  *	As an optimization, update the page's dirty field if a modified bit is  *	found while counting reference bits.  This opportunistic update can be  *	performed at low cost and can eliminate the need for some future calls  *	to pmap_is_modified().  However, since this function stops after  *	finding PMAP_TS_REFERENCED_MAX reference bits, it may not detect some  *	dirty pages.  Those dirty pages will only be detected by a future call  *	to pmap_is_modified().  */
end_comment

begin_function
name|int
name|pmap_ts_referenced
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|,
name|pvf
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pd_entry_t
modifier|*
name|l2
decl_stmt|;
name|pt_entry_t
modifier|*
name|l3
decl_stmt|,
name|old_l3
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|int
name|cleared
decl_stmt|,
name|md_gen
decl_stmt|,
name|not_cleared
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_ts_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|cleared
operator|=
literal|0
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|lock
operator|=
name|PHYS_TO_PV_LIST_LOCK
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|retry
label|:
name|not_cleared
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|pvf
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|==
name|NULL
condition|)
goto|goto
name|out
goto|;
name|pv
operator|=
name|pvf
expr_stmt|;
do|do
block|{
if|if
condition|(
name|pvf
operator|==
name|NULL
condition|)
name|pvf
operator|=
name|pv
expr_stmt|;
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
block|}
name|l2
operator|=
name|pmap_l2
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pmap_load
argument_list|(
name|l2
argument_list|)
operator|&
name|PTE_RX
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_ts_referenced: found an invalid l2 table"
operator|)
argument_list|)
expr_stmt|;
name|l3
operator|=
name|pmap_l2_to_l3
argument_list|(
name|l2
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|old_l3
operator|=
name|pmap_load
argument_list|(
name|l3
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_page_dirty
argument_list|(
name|old_l3
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|old_l3
operator|&
name|PTE_A
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|safe_to_clear_referenced
argument_list|(
name|pmap
argument_list|,
name|old_l3
argument_list|)
condition|)
block|{
comment|/* 				 * TODO: We don't handle the access flag 				 * at all. We need to be able to set it in 				 * the exception handler. 				 */
name|panic
argument_list|(
literal|"RISCVTODO: safe_to_clear_referenced\n"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|old_l3
operator|&
name|PTE_SW_WIRED
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 				 * Wired pages cannot be paged out so 				 * doing accessed bit emulation for 				 * them is wasted effort. We do the 				 * hard work for unwired pages only. 				 */
name|pmap_remove_l3
argument_list|(
name|pmap
argument_list|,
name|l3
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
name|pmap_load
argument_list|(
name|l2
argument_list|)
argument_list|,
operator|&
name|free
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|cleared
operator|++
expr_stmt|;
if|if
condition|(
name|pvf
operator|==
name|pv
condition|)
name|pvf
operator|=
name|NULL
expr_stmt|;
name|pv
operator|=
name|NULL
expr_stmt|;
name|KASSERT
argument_list|(
name|lock
operator|==
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"inconsistent pv lock %p %p for page %p"
operator|,
name|lock
operator|,
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
name|not_cleared
operator|++
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Rotate the PV list if it has more than one entry. */
if|if
condition|(
name|pv
operator|!=
name|NULL
operator|&&
name|TAILQ_NEXT
argument_list|(
name|pv
argument_list|,
name|pv_next
argument_list|)
operator|!=
name|NULL
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
block|}
block|}
do|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|!=
name|pvf
operator|&&
name|cleared
operator|+
name|not_cleared
operator|<
name|PMAP_TS_REFERENCED_MAX
condition|)
do|;
name|out
label|:
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
return|return
operator|(
name|cleared
operator|+
name|not_cleared
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Apply the given advice to the specified range of addresses within the  *	given pmap.  Depending on the advice, clear the referenced and/or  *	modified flags in each mapping and set the mapped page's dirty field.  */
end_comment

begin_function
name|void
name|pmap_advise
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|int
name|advice
parameter_list|)
block|{ }
end_function

begin_comment
comment|/*  *	Clear the modify bits on the specified physical page.  */
end_comment

begin_function
name|void
name|pmap_clear_modify
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_clear_modify: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"pmap_clear_modify: page %p is exclusive busied"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not PGA_WRITEABLE, then no PTEs can have PG_M set. 	 * If the object containing the page is locked and the page is not 	 * exclusive busied, then PGA_WRITEABLE cannot be concurrently set. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
comment|/* RISCVTODO: We lack support for tracking if a page is modified */
block|}
end_function

begin_function
name|void
modifier|*
name|pmap_mapbios
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
return|return
operator|(
operator|(
name|void
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|pa
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_unmapbios
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{ }
end_function

begin_comment
comment|/*  * Sets the memory attribute for the specified page.  */
end_comment

begin_function
name|void
name|pmap_page_set_memattr
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|m
operator|->
name|md
operator|.
name|pv_memattr
operator|=
name|ma
expr_stmt|;
comment|/* 	 * RISCVTODO: Implement the below (from the amd64 pmap) 	 * If "m" is a normal page, update its direct mapping.  This update 	 * can be relied upon to perform any cache operations that are 	 * required for data coherence. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
name|PHYS_IN_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
condition|)
name|panic
argument_list|(
literal|"RISCVTODO: pmap_page_set_memattr"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * perform the pmap work for mincore  */
end_comment

begin_function
name|int
name|pmap_mincore
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|vm_paddr_t
modifier|*
name|locked_pa
parameter_list|)
block|{
name|panic
argument_list|(
literal|"RISCVTODO: pmap_mincore"
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_activate
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|uint64_t
name|reg
decl_stmt|;
name|critical_enter
argument_list|()
expr_stmt|;
name|pmap
operator|=
name|vmspace_pmap
argument_list|(
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_pcb
operator|->
name|pcb_l1addr
operator|=
name|vtophys
argument_list|(
name|pmap
operator|->
name|pm_l1
argument_list|)
expr_stmt|;
name|reg
operator|=
name|SATP_MODE_SV39
expr_stmt|;
name|reg
operator||=
operator|(
name|td
operator|->
name|td_pcb
operator|->
name|pcb_l1addr
operator|>>
name|PAGE_SHIFT
operator|)
expr_stmt|;
asm|__asm __volatile("csrw sptbr, %0" :: "r"(reg));
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|critical_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_sync_icache
parameter_list|(
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|sz
parameter_list|)
block|{
name|panic
argument_list|(
literal|"RISCVTODO: pmap_sync_icache"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Increase the starting virtual address of the given mapping if a  *	different alignment might result in more superpage mappings.  */
end_comment

begin_function
name|void
name|pmap_align_superpage
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_ooffset_t
name|offset
parameter_list|,
name|vm_offset_t
modifier|*
name|addr
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{ }
end_function

begin_comment
comment|/**  * Get the kernel virtual address of a set of physical pages. If there are  * physical addresses not covered by the DMAP perform a transient mapping  * that will be removed when calling pmap_unmap_io_transient.  *  * \param page        The pages the caller wishes to obtain the virtual  *                    address on the kernel memory map.  * \param vaddr       On return contains the kernel virtual memory address  *                    of the pages passed in the page parameter.  * \param count       Number of pages passed in.  * \param can_fault   TRUE if the thread using the mapped pages can take  *                    page faults, FALSE otherwise.  *  * \returns TRUE if the caller must call pmap_unmap_io_transient when  *          finished or FALSE otherwise.  *  */
end_comment

begin_function
name|boolean_t
name|pmap_map_io_transient
parameter_list|(
name|vm_page_t
name|page
index|[]
parameter_list|,
name|vm_offset_t
name|vaddr
index|[]
parameter_list|,
name|int
name|count
parameter_list|,
name|boolean_t
name|can_fault
parameter_list|)
block|{
name|vm_paddr_t
name|paddr
decl_stmt|;
name|boolean_t
name|needs_mapping
decl_stmt|;
name|int
name|error
decl_stmt|,
name|i
decl_stmt|;
comment|/* 	 * Allocate any KVA space that we need, this is done in a separate 	 * loop to prevent calling vmem_alloc while pinned. 	 */
name|needs_mapping
operator|=
name|FALSE
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|page
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|__predict_false
argument_list|(
name|paddr
operator|>=
name|DMAP_MAX_PHYSADDR
argument_list|)
condition|)
block|{
name|error
operator|=
name|vmem_alloc
argument_list|(
name|kernel_arena
argument_list|,
name|PAGE_SIZE
argument_list|,
name|M_BESTFIT
operator||
name|M_WAITOK
argument_list|,
operator|&
name|vaddr
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|error
operator|==
literal|0
argument_list|,
operator|(
literal|"vmem_alloc failed: %d"
operator|,
name|error
operator|)
argument_list|)
expr_stmt|;
name|needs_mapping
operator|=
name|TRUE
expr_stmt|;
block|}
else|else
block|{
name|vaddr
index|[
name|i
index|]
operator|=
name|PHYS_TO_DMAP
argument_list|(
name|paddr
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* Exit early if everything is covered by the DMAP */
if|if
condition|(
operator|!
name|needs_mapping
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
if|if
condition|(
operator|!
name|can_fault
condition|)
name|sched_pin
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|page
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|paddr
operator|>=
name|DMAP_MAX_PHYSADDR
condition|)
block|{
name|panic
argument_list|(
literal|"pmap_map_io_transient: TODO: Map out of DMAP data"
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|(
name|needs_mapping
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_unmap_io_transient
parameter_list|(
name|vm_page_t
name|page
index|[]
parameter_list|,
name|vm_offset_t
name|vaddr
index|[]
parameter_list|,
name|int
name|count
parameter_list|,
name|boolean_t
name|can_fault
parameter_list|)
block|{
name|vm_paddr_t
name|paddr
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
operator|!
name|can_fault
condition|)
name|sched_unpin
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|page
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|paddr
operator|>=
name|DMAP_MAX_PHYSADDR
condition|)
block|{
name|panic
argument_list|(
literal|"RISCVTODO: pmap_unmap_io_transient: Unmap data"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

end_unit

