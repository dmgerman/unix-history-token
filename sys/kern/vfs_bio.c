begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2004 Poul-Henning Kamp  * Copyright (c) 1994,1997 John S. Dyson  * Copyright (c) 2013 The FreeBSD Foundation  * All rights reserved.  *  * Portions of this software were developed by Konstantin Belousov  * under sponsorship from the FreeBSD Foundation.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  */
end_comment

begin_comment
comment|/*  * this file contains a new buffer I/O scheme implementing a coherent  * VM object and buffer cache scheme.  Pains have been taken to make  * sure that the performance degradation associated with schemes such  * as this is not realized.  *  * Author:  John S. Dyson  * Significant help during the development and debugging phases  * had been provided by David Greenman, also of the FreeBSD core team.  *  * see man buf(9) for more info.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/bio.h>
end_include

begin_include
include|#
directive|include
file|<sys/conf.h>
end_include

begin_include
include|#
directive|include
file|<sys/buf.h>
end_include

begin_include
include|#
directive|include
file|<sys/devicestat.h>
end_include

begin_include
include|#
directive|include
file|<sys/eventhandler.h>
end_include

begin_include
include|#
directive|include
file|<sys/fail.h>
end_include

begin_include
include|#
directive|include
file|<sys/limits.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mount.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/kthread.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmem.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<geom/geom.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|"opt_compat.h"
end_include

begin_include
include|#
directive|include
file|"opt_swap.h"
end_include

begin_expr_stmt
specifier|static
name|MALLOC_DEFINE
argument_list|(
name|M_BIOBUF
argument_list|,
literal|"biobuf"
argument_list|,
literal|"BIO buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|struct
name|bio_ops
name|bioops
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* I/O operation notification */
end_comment

begin_decl_stmt
name|struct
name|buf_ops
name|buf_ops_bio
init|=
block|{
operator|.
name|bop_name
operator|=
literal|"buf_ops_bio"
block|,
operator|.
name|bop_write
operator|=
name|bufwrite
block|,
operator|.
name|bop_strategy
operator|=
name|bufstrategy
block|,
operator|.
name|bop_sync
operator|=
name|bufsync
block|,
operator|.
name|bop_bdflush
operator|=
name|bufbdflush
block|, }
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * XXX buf is global because kern_shutdown.c and ffs_checkoverlap has  * carnal knowledge of buffers.  This knowledge should be moved to vfs_bio.c.  */
end_comment

begin_decl_stmt
name|struct
name|buf
modifier|*
name|buf
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* buffer header pool */
end_comment

begin_decl_stmt
name|caddr_t
name|unmapped_buf
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Used below and for softdep flushing threads in ufs/ffs/ffs_softdep.c */
end_comment

begin_decl_stmt
name|struct
name|proc
modifier|*
name|bufdaemonproc
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|int
name|inmem
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_hold_free_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|newbsize
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_hold_load_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_page_set_valid
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_page_set_validclean
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_clean_pages_dirty_buf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_setdirty_locked_object
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_vmio_release
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vfs_bio_clcheck
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
name|size
parameter_list|,
name|daddr_t
name|lblkno
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|buf_flush
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|flushbufqueues
parameter_list|(
name|struct
name|vnode
modifier|*
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|buf_daemon
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|bremfreel
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|bd_wakeup
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sysctl_runningspace
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_if
if|#
directive|if
name|defined
argument_list|(
name|COMPAT_FREEBSD4
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD5
argument_list|)
operator|||
expr|\
name|defined
argument_list|(
name|COMPAT_FREEBSD6
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD7
argument_list|)
end_if

begin_function_decl
specifier|static
name|int
name|sysctl_bufspace
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
name|int
name|vmiodirenable
init|=
name|TRUE
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|vmiodirenable
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vmiodirenable
argument_list|,
literal|0
argument_list|,
literal|"Use the VM system for directory writes"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|long
name|runningbufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|runningbufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|runningbufspace
argument_list|,
literal|0
argument_list|,
literal|"Amount of presently outstanding async buffer io"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|bufspace
decl_stmt|;
end_decl_stmt

begin_if
if|#
directive|if
name|defined
argument_list|(
name|COMPAT_FREEBSD4
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD5
argument_list|)
operator|||
expr|\
name|defined
argument_list|(
name|COMPAT_FREEBSD6
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD7
argument_list|)
end_if

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufspace
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_MPSAFE
operator||
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufspace
argument_list|,
literal|0
argument_list|,
name|sysctl_bufspace
argument_list|,
literal|"L"
argument_list|,
literal|"Virtual memory used for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_else
else|#
directive|else
end_else

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufspace
argument_list|,
literal|0
argument_list|,
literal|"Virtual memory used for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|long
name|unmapped_bufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|unmapped_bufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|unmapped_bufspace
argument_list|,
literal|0
argument_list|,
literal|"Amount of unmapped buffers, inclusive in the bufspace"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|maxbufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|maxbufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|maxbufspace
argument_list|,
literal|0
argument_list|,
literal|"Maximum allowed value of bufspace (including buf_daemon)"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|bufmallocspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufmallocspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufmallocspace
argument_list|,
literal|0
argument_list|,
literal|"Amount of malloced memory for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|maxbufmallocspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|maxmallocbufspace
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|maxbufmallocspace
argument_list|,
literal|0
argument_list|,
literal|"Maximum amount of malloced memory for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|lobufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lobufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|lobufspace
argument_list|,
literal|0
argument_list|,
literal|"Minimum amount of buffers we want to have"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|long
name|hibufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hibufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|hibufspace
argument_list|,
literal|0
argument_list|,
literal|"Maximum allowed value of bufspace (excluding buf_daemon)"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|bufreusecnt
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufreusecnt
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|bufreusecnt
argument_list|,
literal|0
argument_list|,
literal|"Number of times we have reused a buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|buffreekvacnt
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|buffreekvacnt
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|buffreekvacnt
argument_list|,
literal|0
argument_list|,
literal|"Number of times we have freed the KVA space from some buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|bufdefragcnt
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufdefragcnt
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|bufdefragcnt
argument_list|,
literal|0
argument_list|,
literal|"Number of times we have had to repeat buffer allocation to defragment"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|lorunningspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lorunningspace
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_MPSAFE
operator||
name|CTLFLAG_RW
argument_list|,
operator|&
name|lorunningspace
argument_list|,
literal|0
argument_list|,
name|sysctl_runningspace
argument_list|,
literal|"L"
argument_list|,
literal|"Minimum preferred space used for in-progress I/O"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|hirunningspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hirunningspace
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_MPSAFE
operator||
name|CTLFLAG_RW
argument_list|,
operator|&
name|hirunningspace
argument_list|,
literal|0
argument_list|,
name|sysctl_runningspace
argument_list|,
literal|"L"
argument_list|,
literal|"Maximum amount of space to use for in-progress I/O"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|dirtybufferflushes
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|dirtybufferflushes
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|dirtybufferflushes
argument_list|,
literal|0
argument_list|,
literal|"Number of bdwrite to bawrite conversions to limit dirty buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|bdwriteskip
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bdwriteskip
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|bdwriteskip
argument_list|,
literal|0
argument_list|,
literal|"Number of buffers supplied to bdwrite with snapshot deadlock risk"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|altbufferflushes
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|altbufferflushes
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|altbufferflushes
argument_list|,
literal|0
argument_list|,
literal|"Number of fsync flushes to limit dirty buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|recursiveflushes
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|recursiveflushes
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|recursiveflushes
argument_list|,
literal|0
argument_list|,
literal|"Number of flushes skipped due to being recursive"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|numdirtybuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|numdirtybuffers
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|numdirtybuffers
argument_list|,
literal|0
argument_list|,
literal|"Number of buffers that are dirty (has unwritten changes) at the moment"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|lodirtybuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lodirtybuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|lodirtybuffers
argument_list|,
literal|0
argument_list|,
literal|"How many buffers we want to have free before bufdaemon can sleep"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|hidirtybuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hidirtybuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|hidirtybuffers
argument_list|,
literal|0
argument_list|,
literal|"When the number of dirty buffers is considered severe"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|dirtybufthresh
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|dirtybufthresh
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|dirtybufthresh
argument_list|,
literal|0
argument_list|,
literal|"Number of bdwrite to bawrite conversions to clear dirty buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|numfreebuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|numfreebuffers
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|numfreebuffers
argument_list|,
literal|0
argument_list|,
literal|"Number of free buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|lofreebuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lofreebuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|lofreebuffers
argument_list|,
literal|0
argument_list|,
literal|"XXX Unused"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|hifreebuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hifreebuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|hifreebuffers
argument_list|,
literal|0
argument_list|,
literal|"XXX Complicatedly unused"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|getnewbufcalls
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|getnewbufcalls
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|getnewbufcalls
argument_list|,
literal|0
argument_list|,
literal|"Number of calls to getnewbuf"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|getnewbufrestarts
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|getnewbufrestarts
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|getnewbufrestarts
argument_list|,
literal|0
argument_list|,
literal|"Number of times getnewbuf has had to restart a buffer aquisition"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|mappingrestarts
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mappingrestarts
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|mappingrestarts
argument_list|,
literal|0
argument_list|,
literal|"Number of times getblk has had to restart a buffer mapping for "
literal|"unmapped buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|flushbufqtarget
init|=
literal|100
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|flushbufqtarget
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|flushbufqtarget
argument_list|,
literal|0
argument_list|,
literal|"Amount of work to do in flushbufqueues when helping bufdaemon"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|notbufdflushes
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|notbufdflushes
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|notbufdflushes
argument_list|,
literal|0
argument_list|,
literal|"Number of dirty buffer flushes done by the bufdaemon helpers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|barrierwrites
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|barrierwrites
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|barrierwrites
argument_list|,
literal|0
argument_list|,
literal|"Number of barrier writes"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|unmapped_buf_allowed
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|unmapped_buf_allowed
argument_list|,
literal|0
argument_list|,
literal|"Permit the use of the unmapped i/o"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Lock for the non-dirty bufqueues  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mtx_padalign
name|bqclean
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Lock for the dirty queue.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mtx_padalign
name|bqdirty
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * This lock synchronizes access to bd_request.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mtx_padalign
name|bdlock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * This lock protects the runningbufreq and synchronizes runningbufwakeup and  * waitrunningbufspace().  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mtx_padalign
name|rbreqlock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Lock that protects needsbuffer and the sleeps/wakeups surrounding it.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|rwlock_padalign
name|nblock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Lock that protects bdirtywait.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mtx_padalign
name|bdirtylock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Wakeup point for bufdaemon, as well as indicator of whether it is already  * active.  Set to 1 when the bufdaemon is already "on" the queue, 0 when it  * is idling.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|bd_request
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Request for the buf daemon to write more buffers than is indicated by  * lodirtybuf.  This may be necessary to push out excess dependencies or  * defragment the address space where a simple count of the number of dirty  * buffers is insufficient to characterize the demand for flushing them.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|bd_speedupreq
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * bogus page -- for I/O to/from partially complete buffers  * this is a temporary solution to the problem, but it is not  * really that bad.  it would be better to split the buffer  * for input in the case of buffers partially already in memory,  * but the code is intricate enough already.  */
end_comment

begin_decl_stmt
name|vm_page_t
name|bogus_page
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Synchronization (sleep/wakeup) variable for active buffer space requests.  * Set when wait starts, cleared prior to wakeup().  * Used in runningbufwakeup() and waitrunningbufspace().  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|runningbufreq
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*   * Synchronization (sleep/wakeup) variable for buffer requests.  * Can contain the VFS_BIO_NEED flags defined below; setting/clearing is done  * by and/or.  * Used in numdirtywakeup(), bufspacewakeup(), bufcountadd(), bwillwrite(),  * getnewbuf(), and getblk().  */
end_comment

begin_decl_stmt
specifier|static
specifier|volatile
name|int
name|needsbuffer
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Synchronization for bwillwrite() waiters.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|bdirtywait
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Definitions for the buffer free lists.  */
end_comment

begin_define
define|#
directive|define
name|BUFFER_QUEUES
value|5
end_define

begin_comment
comment|/* number of free buffer queues */
end_comment

begin_define
define|#
directive|define
name|QUEUE_NONE
value|0
end_define

begin_comment
comment|/* on no queue */
end_comment

begin_define
define|#
directive|define
name|QUEUE_CLEAN
value|1
end_define

begin_comment
comment|/* non-B_DELWRI buffers */
end_comment

begin_define
define|#
directive|define
name|QUEUE_DIRTY
value|2
end_define

begin_comment
comment|/* B_DELWRI buffers */
end_comment

begin_define
define|#
directive|define
name|QUEUE_EMPTYKVA
value|3
end_define

begin_comment
comment|/* empty buffer headers w/KVA assignment */
end_comment

begin_define
define|#
directive|define
name|QUEUE_EMPTY
value|4
end_define

begin_comment
comment|/* empty buffer headers */
end_comment

begin_define
define|#
directive|define
name|QUEUE_SENTINEL
value|1024
end_define

begin_comment
comment|/* not an queue index, but mark for sentinel */
end_comment

begin_comment
comment|/* Queues for free buffers with various properties */
end_comment

begin_expr_stmt
specifier|static
name|TAILQ_HEAD
argument_list|(
argument|bqueues
argument_list|,
argument|buf
argument_list|)
name|bufqueues
index|[
name|BUFFER_QUEUES
index|]
operator|=
block|{
block|{
literal|0
block|}
block|}
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|INVARIANTS
end_ifdef

begin_decl_stmt
specifier|static
name|int
name|bq_len
index|[
name|BUFFER_QUEUES
index|]
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Single global constant for BUF_WMESG, to avoid getting multiple references.  * buf_wmesg is referred from macros.  */
end_comment

begin_decl_stmt
specifier|const
name|char
modifier|*
name|buf_wmesg
init|=
name|BUF_WMESG
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|VFS_BIO_NEED_ANY
value|0x01
end_define

begin_comment
comment|/* any freeable buffer */
end_comment

begin_define
define|#
directive|define
name|VFS_BIO_NEED_FREE
value|0x04
end_define

begin_comment
comment|/* wait for free bufs, hi hysteresis */
end_comment

begin_define
define|#
directive|define
name|VFS_BIO_NEED_BUFSPACE
value|0x08
end_define

begin_comment
comment|/* wait for buf space, lo hysteresis */
end_comment

begin_function
specifier|static
name|int
name|sysctl_runningspace
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|long
name|value
decl_stmt|;
name|int
name|error
decl_stmt|;
name|value
operator|=
operator|*
operator|(
name|long
operator|*
operator|)
name|arg1
expr_stmt|;
name|error
operator|=
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
operator|&
name|value
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|error
operator|)
return|;
name|mtx_lock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|arg1
operator|==
operator|&
name|hirunningspace
condition|)
block|{
if|if
condition|(
name|value
operator|<
name|lorunningspace
condition|)
name|error
operator|=
name|EINVAL
expr_stmt|;
else|else
name|hirunningspace
operator|=
name|value
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
name|arg1
operator|==
operator|&
name|lorunningspace
argument_list|,
operator|(
literal|"%s: unknown arg1"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|value
operator|>
name|hirunningspace
condition|)
name|error
operator|=
name|EINVAL
expr_stmt|;
else|else
name|lorunningspace
operator|=
name|value
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_if
if|#
directive|if
name|defined
argument_list|(
name|COMPAT_FREEBSD4
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD5
argument_list|)
operator|||
expr|\
name|defined
argument_list|(
name|COMPAT_FREEBSD6
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD7
argument_list|)
end_if

begin_function
specifier|static
name|int
name|sysctl_bufspace
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|long
name|lvalue
decl_stmt|;
name|int
name|ivalue
decl_stmt|;
if|if
condition|(
sizeof|sizeof
argument_list|(
name|int
argument_list|)
operator|==
sizeof|sizeof
argument_list|(
name|long
argument_list|)
operator|||
name|req
operator|->
name|oldlen
operator|>=
sizeof|sizeof
argument_list|(
name|long
argument_list|)
condition|)
return|return
operator|(
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
name|arg1
argument_list|,
name|arg2
argument_list|,
name|req
argument_list|)
operator|)
return|;
name|lvalue
operator|=
operator|*
operator|(
name|long
operator|*
operator|)
name|arg1
expr_stmt|;
if|if
condition|(
name|lvalue
operator|>
name|INT_MAX
condition|)
comment|/* On overflow, still write out a long to trigger ENOMEM. */
return|return
operator|(
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
operator|&
name|lvalue
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
operator|)
return|;
name|ivalue
operator|=
name|lvalue
expr_stmt|;
return|return
operator|(
name|sysctl_handle_int
argument_list|(
name|oidp
argument_list|,
operator|&
name|ivalue
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  *	bqlock:  *  *	Return the appropriate queue lock based on the index.  */
end_comment

begin_function
specifier|static
specifier|inline
name|struct
name|mtx
modifier|*
name|bqlock
parameter_list|(
name|int
name|qindex
parameter_list|)
block|{
if|if
condition|(
name|qindex
operator|==
name|QUEUE_DIRTY
condition|)
return|return
operator|(
expr|struct
name|mtx
operator|*
operator|)
operator|(
operator|&
name|bqdirty
operator|)
return|;
return|return
operator|(
expr|struct
name|mtx
operator|*
operator|)
operator|(
operator|&
name|bqclean
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	bdirtywakeup:  *  *	Wakeup any bwillwrite() waiters.  */
end_comment

begin_function
specifier|static
name|void
name|bdirtywakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|bdirtylock
argument_list|)
expr_stmt|;
if|if
condition|(
name|bdirtywait
condition|)
block|{
name|bdirtywait
operator|=
literal|0
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|bdirtywait
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|bdirtylock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bdirtysub:  *  *	Decrement the numdirtybuffers count by one and wakeup any  *	threads blocked in bwillwrite().  */
end_comment

begin_function
specifier|static
name|void
name|bdirtysub
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|atomic_fetchadd_int
argument_list|(
operator|&
name|numdirtybuffers
argument_list|,
operator|-
literal|1
argument_list|)
operator|==
operator|(
name|lodirtybuffers
operator|+
name|hidirtybuffers
operator|)
operator|/
literal|2
condition|)
name|bdirtywakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bdirtyadd:  *  *	Increment the numdirtybuffers count by one and wakeup the buf   *	daemon if needed.  */
end_comment

begin_function
specifier|static
name|void
name|bdirtyadd
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * Only do the wakeup once as we cross the boundary.  The 	 * buf daemon will keep running until the condition clears. 	 */
if|if
condition|(
name|atomic_fetchadd_int
argument_list|(
operator|&
name|numdirtybuffers
argument_list|,
literal|1
argument_list|)
operator|==
operator|(
name|lodirtybuffers
operator|+
name|hidirtybuffers
operator|)
operator|/
literal|2
condition|)
name|bd_wakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufspacewakeup:  *  *	Called when buffer space is potentially available for recovery.  *	getnewbuf() will block on this flag when it is unable to free   *	sufficient buffer space.  Buffer space becomes recoverable when   *	bp's get placed back in the queues.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|bufspacewakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|need_wakeup
decl_stmt|,
name|on
decl_stmt|;
comment|/* 	 * If someone is waiting for BUF space, wake them up.  Even 	 * though we haven't freed the kva space yet, the waiting 	 * process will be able to now. 	 */
name|rw_rlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|need_wakeup
operator|=
literal|0
expr_stmt|;
name|on
operator|=
name|needsbuffer
expr_stmt|;
if|if
condition|(
operator|(
name|on
operator|&
name|VFS_BIO_NEED_BUFSPACE
operator|)
operator|==
literal|0
condition|)
break|break;
name|need_wakeup
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|atomic_cmpset_rel_int
argument_list|(
operator|&
name|needsbuffer
argument_list|,
name|on
argument_list|,
name|on
operator|&
operator|~
name|VFS_BIO_NEED_BUFSPACE
argument_list|)
condition|)
break|break;
block|}
if|if
condition|(
name|need_wakeup
condition|)
name|wakeup
argument_list|(
name|__DEVOLATILE
argument_list|(
name|void
operator|*
argument_list|,
operator|&
name|needsbuffer
argument_list|)
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	runningwakeup:  *  *	Wake up processes that are waiting on asynchronous writes to fall  *	below lorunningspace.  */
end_comment

begin_function
specifier|static
name|void
name|runningwakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|runningbufreq
condition|)
block|{
name|runningbufreq
operator|=
literal|0
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|runningbufreq
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	runningbufwakeup:  *  *	Decrement the outstanding write count according.  */
end_comment

begin_function
name|void
name|runningbufwakeup
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|long
name|space
decl_stmt|,
name|bspace
decl_stmt|;
name|bspace
operator|=
name|bp
operator|->
name|b_runningbufspace
expr_stmt|;
if|if
condition|(
name|bspace
operator|==
literal|0
condition|)
return|return;
name|space
operator|=
name|atomic_fetchadd_long
argument_list|(
operator|&
name|runningbufspace
argument_list|,
operator|-
name|bspace
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|space
operator|>=
name|bspace
argument_list|,
operator|(
literal|"runningbufspace underflow %ld %ld"
operator|,
name|space
operator|,
name|bspace
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_runningbufspace
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Only acquire the lock and wakeup on the transition from exceeding 	 * the threshold to falling below it. 	 */
if|if
condition|(
name|space
operator|<
name|lorunningspace
condition|)
return|return;
if|if
condition|(
name|space
operator|-
name|bspace
operator|>
name|lorunningspace
condition|)
return|return;
name|runningwakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufcountadd:  *  *	Called when a buffer has been added to one of the free queues to  *	account for the buffer and to wakeup anyone waiting for free buffers.  *	This typically occurs when large amounts of metadata are being handled  *	by the buffer cache ( else buffer space runs out first, usually ).  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|bufcountadd
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|mask
decl_stmt|,
name|need_wakeup
decl_stmt|,
name|old
decl_stmt|,
name|on
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INFREECNT
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"buf %p already counted as free"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INFREECNT
expr_stmt|;
name|old
operator|=
name|atomic_fetchadd_int
argument_list|(
operator|&
name|numfreebuffers
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|old
operator|>=
literal|0
operator|&&
name|old
operator|<
name|nbuf
argument_list|,
operator|(
literal|"numfreebuffers climbed to %d"
operator|,
name|old
operator|+
literal|1
operator|)
argument_list|)
expr_stmt|;
name|mask
operator|=
name|VFS_BIO_NEED_ANY
expr_stmt|;
if|if
condition|(
name|numfreebuffers
operator|>=
name|hifreebuffers
condition|)
name|mask
operator||=
name|VFS_BIO_NEED_FREE
expr_stmt|;
name|rw_rlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|need_wakeup
operator|=
literal|0
expr_stmt|;
name|on
operator|=
name|needsbuffer
expr_stmt|;
if|if
condition|(
name|on
operator|==
literal|0
condition|)
break|break;
name|need_wakeup
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|atomic_cmpset_rel_int
argument_list|(
operator|&
name|needsbuffer
argument_list|,
name|on
argument_list|,
name|on
operator|&
operator|~
name|mask
argument_list|)
condition|)
break|break;
block|}
if|if
condition|(
name|need_wakeup
condition|)
name|wakeup
argument_list|(
name|__DEVOLATILE
argument_list|(
name|void
operator|*
argument_list|,
operator|&
name|needsbuffer
argument_list|)
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufcountsub:  *  *	Decrement the numfreebuffers count as needed.  */
end_comment

begin_function
specifier|static
name|void
name|bufcountsub
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|old
decl_stmt|;
comment|/* 	 * Fixup numfreebuffers count.  If the buffer is invalid or not 	 * delayed-write, the buffer was free and we must decrement 	 * numfreebuffers. 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INFREECNT
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"buf %p not counted in numfreebuffers"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INFREECNT
expr_stmt|;
name|old
operator|=
name|atomic_fetchadd_int
argument_list|(
operator|&
name|numfreebuffers
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|old
operator|>
literal|0
argument_list|,
operator|(
literal|"numfreebuffers dropped to %d"
operator|,
name|old
operator|-
literal|1
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	waitrunningbufspace()  *  *	runningbufspace is a measure of the amount of I/O currently  *	running.  This routine is used in async-write situations to  *	prevent creating huge backups of pending writes to a device.  *	Only asynchronous writes are governed by this function.  *  *	This does NOT turn an async write into a sync write.  It waits    *	for earlier writes to complete and generally returns before the  *	caller's write has reached the device.  */
end_comment

begin_function
name|void
name|waitrunningbufspace
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
while|while
condition|(
name|runningbufspace
operator|>
name|hirunningspace
condition|)
block|{
name|runningbufreq
operator|=
literal|1
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|runningbufreq
argument_list|,
operator|&
name|rbreqlock
argument_list|,
name|PVM
argument_list|,
literal|"wdrain"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vfs_buf_test_cache:  *  *	Called when a buffer is extended.  This function clears the B_CACHE  *	bit if the newly extended portion of the buffer does not contain  *	valid data.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|vfs_buf_test_cache
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|foff
parameter_list|,
name|vm_offset_t
name|off
parameter_list|,
name|vm_offset_t
name|size
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
condition|)
block|{
name|int
name|base
init|=
operator|(
name|foff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
decl_stmt|;
if|if
condition|(
name|vm_page_is_valid
argument_list|(
name|m
argument_list|,
name|base
argument_list|,
name|size
argument_list|)
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/* Wake up the buffer daemon if necessary */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|bd_wakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|bd_request
operator|==
literal|0
condition|)
block|{
name|bd_request
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|bd_request
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * bd_speedup - speedup the buffer cache flushing code  */
end_comment

begin_function
name|void
name|bd_speedup
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|needwake
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
name|needwake
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|bd_speedupreq
operator|==
literal|0
operator|||
name|bd_request
operator|==
literal|0
condition|)
name|needwake
operator|=
literal|1
expr_stmt|;
name|bd_speedupreq
operator|=
literal|1
expr_stmt|;
name|bd_request
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|needwake
condition|)
name|wakeup
argument_list|(
operator|&
name|bd_request
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_ifndef
ifndef|#
directive|ifndef
name|NSWBUF_MIN
end_ifndef

begin_define
define|#
directive|define
name|NSWBUF_MIN
value|16
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|__i386__
end_ifdef

begin_define
define|#
directive|define
name|TRANSIENT_DENOM
value|5
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|TRANSIENT_DENOM
value|10
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Calculating buffer cache scaling values and reserve space for buffer  * headers.  This is called during low level kernel initialization and  * may be called more then once.  We CANNOT write to the memory area  * being reserved at this time.  */
end_comment

begin_function
name|caddr_t
name|kern_vfs_bio_buffer_alloc
parameter_list|(
name|caddr_t
name|v
parameter_list|,
name|long
name|physmem_est
parameter_list|)
block|{
name|int
name|tuned_nbuf
decl_stmt|;
name|long
name|maxbuf
decl_stmt|,
name|maxbuf_sz
decl_stmt|,
name|buf_sz
decl_stmt|,
name|biotmap_sz
decl_stmt|;
comment|/* 	 * physmem_est is in pages.  Convert it to kilobytes (assumes 	 * PAGE_SIZE is>= 1K) 	 */
name|physmem_est
operator|=
name|physmem_est
operator|*
operator|(
name|PAGE_SIZE
operator|/
literal|1024
operator|)
expr_stmt|;
comment|/* 	 * The nominal buffer size (and minimum KVA allocation) is BKVASIZE. 	 * For the first 64MB of ram nominally allocate sufficient buffers to 	 * cover 1/4 of our ram.  Beyond the first 64MB allocate additional 	 * buffers to cover 1/10 of our ram over 64MB.  When auto-sizing 	 * the buffer cache we limit the eventual kva reservation to 	 * maxbcache bytes. 	 * 	 * factor represents the 1/4 x ram conversion. 	 */
if|if
condition|(
name|nbuf
operator|==
literal|0
condition|)
block|{
name|int
name|factor
init|=
literal|4
operator|*
name|BKVASIZE
operator|/
literal|1024
decl_stmt|;
name|nbuf
operator|=
literal|50
expr_stmt|;
if|if
condition|(
name|physmem_est
operator|>
literal|4096
condition|)
name|nbuf
operator|+=
name|min
argument_list|(
operator|(
name|physmem_est
operator|-
literal|4096
operator|)
operator|/
name|factor
argument_list|,
literal|65536
operator|/
name|factor
argument_list|)
expr_stmt|;
if|if
condition|(
name|physmem_est
operator|>
literal|65536
condition|)
name|nbuf
operator|+=
name|min
argument_list|(
operator|(
name|physmem_est
operator|-
literal|65536
operator|)
operator|*
literal|2
operator|/
operator|(
name|factor
operator|*
literal|5
operator|)
argument_list|,
literal|32
operator|*
literal|1024
operator|*
literal|1024
operator|/
operator|(
name|factor
operator|*
literal|5
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|maxbcache
operator|&&
name|nbuf
operator|>
name|maxbcache
operator|/
name|BKVASIZE
condition|)
name|nbuf
operator|=
name|maxbcache
operator|/
name|BKVASIZE
expr_stmt|;
name|tuned_nbuf
operator|=
literal|1
expr_stmt|;
block|}
else|else
name|tuned_nbuf
operator|=
literal|0
expr_stmt|;
comment|/* XXX Avoid unsigned long overflows later on with maxbufspace. */
name|maxbuf
operator|=
operator|(
name|LONG_MAX
operator|/
literal|3
operator|)
operator|/
name|BKVASIZE
expr_stmt|;
if|if
condition|(
name|nbuf
operator|>
name|maxbuf
condition|)
block|{
if|if
condition|(
operator|!
name|tuned_nbuf
condition|)
name|printf
argument_list|(
literal|"Warning: nbufs lowered from %d to %ld\n"
argument_list|,
name|nbuf
argument_list|,
name|maxbuf
argument_list|)
expr_stmt|;
name|nbuf
operator|=
name|maxbuf
expr_stmt|;
block|}
comment|/* 	 * Ideal allocation size for the transient bio submap is 10% 	 * of the maximal space buffer map.  This roughly corresponds 	 * to the amount of the buffer mapped for typical UFS load. 	 * 	 * Clip the buffer map to reserve space for the transient 	 * BIOs, if its extent is bigger than 90% (80% on i386) of the 	 * maximum buffer map extent on the platform. 	 * 	 * The fall-back to the maxbuf in case of maxbcache unset, 	 * allows to not trim the buffer KVA for the architectures 	 * with ample KVA space. 	 */
if|if
condition|(
name|bio_transient_maxcnt
operator|==
literal|0
operator|&&
name|unmapped_buf_allowed
condition|)
block|{
name|maxbuf_sz
operator|=
name|maxbcache
operator|!=
literal|0
condition|?
name|maxbcache
else|:
name|maxbuf
operator|*
name|BKVASIZE
expr_stmt|;
name|buf_sz
operator|=
operator|(
name|long
operator|)
name|nbuf
operator|*
name|BKVASIZE
expr_stmt|;
if|if
condition|(
name|buf_sz
operator|<
name|maxbuf_sz
operator|/
name|TRANSIENT_DENOM
operator|*
operator|(
name|TRANSIENT_DENOM
operator|-
literal|1
operator|)
condition|)
block|{
comment|/* 			 * There is more KVA than memory.  Do not 			 * adjust buffer map size, and assign the rest 			 * of maxbuf to transient map. 			 */
name|biotmap_sz
operator|=
name|maxbuf_sz
operator|-
name|buf_sz
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * Buffer map spans all KVA we could afford on 			 * this platform.  Give 10% (20% on i386) of 			 * the buffer map to the transient bio map. 			 */
name|biotmap_sz
operator|=
name|buf_sz
operator|/
name|TRANSIENT_DENOM
expr_stmt|;
name|buf_sz
operator|-=
name|biotmap_sz
expr_stmt|;
block|}
if|if
condition|(
name|biotmap_sz
operator|/
name|INT_MAX
operator|>
name|MAXPHYS
condition|)
name|bio_transient_maxcnt
operator|=
name|INT_MAX
expr_stmt|;
else|else
name|bio_transient_maxcnt
operator|=
name|biotmap_sz
operator|/
name|MAXPHYS
expr_stmt|;
comment|/* 		 * Artifically limit to 1024 simultaneous in-flight I/Os 		 * using the transient mapping. 		 */
if|if
condition|(
name|bio_transient_maxcnt
operator|>
literal|1024
condition|)
name|bio_transient_maxcnt
operator|=
literal|1024
expr_stmt|;
if|if
condition|(
name|tuned_nbuf
condition|)
name|nbuf
operator|=
name|buf_sz
operator|/
name|BKVASIZE
expr_stmt|;
block|}
comment|/* 	 * swbufs are used as temporary holders for I/O, such as paging I/O. 	 * We have no less then 16 and no more then 256. 	 */
name|nswbuf
operator|=
name|min
argument_list|(
name|nbuf
operator|/
literal|4
argument_list|,
literal|256
argument_list|)
expr_stmt|;
name|TUNABLE_INT_FETCH
argument_list|(
literal|"kern.nswbuf"
argument_list|,
operator|&
name|nswbuf
argument_list|)
expr_stmt|;
if|if
condition|(
name|nswbuf
operator|<
name|NSWBUF_MIN
condition|)
name|nswbuf
operator|=
name|NSWBUF_MIN
expr_stmt|;
comment|/* 	 * Reserve space for the buffer cache buffers 	 */
name|swbuf
operator|=
operator|(
name|void
operator|*
operator|)
name|v
expr_stmt|;
name|v
operator|=
call|(
name|caddr_t
call|)
argument_list|(
name|swbuf
operator|+
name|nswbuf
argument_list|)
expr_stmt|;
name|buf
operator|=
operator|(
name|void
operator|*
operator|)
name|v
expr_stmt|;
name|v
operator|=
call|(
name|caddr_t
call|)
argument_list|(
name|buf
operator|+
name|nbuf
argument_list|)
expr_stmt|;
return|return
operator|(
name|v
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Initialize the buffer subsystem.  Called before use of any buffers. */
end_comment

begin_function
name|void
name|bufinit
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|i
decl_stmt|;
name|CTASSERT
argument_list|(
name|MAXBCACHEBUF
operator|>=
name|MAXBSIZE
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|bqclean
argument_list|,
literal|"bufq clean lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|bqdirty
argument_list|,
literal|"bufq dirty lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|rbreqlock
argument_list|,
literal|"runningbufspace lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|rw_init
argument_list|(
operator|&
name|nblock
argument_list|,
literal|"needsbuffer lock"
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|bdlock
argument_list|,
literal|"buffer daemon lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|bdirtylock
argument_list|,
literal|"dirty buf lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* next, make a null set of free lists */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|BUFFER_QUEUES
condition|;
name|i
operator|++
control|)
name|TAILQ_INIT
argument_list|(
operator|&
name|bufqueues
index|[
name|i
index|]
argument_list|)
expr_stmt|;
comment|/* finally, initialize each buffer header and stick on empty q */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nbuf
condition|;
name|i
operator|++
control|)
block|{
name|bp
operator|=
operator|&
name|buf
index|[
name|i
index|]
expr_stmt|;
name|bzero
argument_list|(
name|bp
argument_list|,
sizeof|sizeof
expr|*
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|=
name|B_INVAL
operator||
name|B_INFREECNT
expr_stmt|;
name|bp
operator|->
name|b_rcred
operator|=
name|NOCRED
expr_stmt|;
name|bp
operator|->
name|b_wcred
operator|=
name|NOCRED
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|bp
operator|->
name|b_xflags
operator|=
literal|0
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
expr_stmt|;
name|BUF_LOCKINIT
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTY
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|INVARIANTS
name|bq_len
index|[
name|QUEUE_EMPTY
index|]
operator|++
expr_stmt|;
endif|#
directive|endif
block|}
comment|/* 	 * maxbufspace is the absolute maximum amount of buffer space we are  	 * allowed to reserve in KVM and in real terms.  The absolute maximum 	 * is nominally used by buf_daemon.  hibufspace is the nominal maximum 	 * used by most other processes.  The differential is required to  	 * ensure that buf_daemon is able to run when other processes might  	 * be blocked waiting for buffer space. 	 * 	 * maxbufspace is based on BKVASIZE.  Allocating buffers larger then 	 * this may result in KVM fragmentation which is not handled optimally 	 * by the system. 	 */
name|maxbufspace
operator|=
operator|(
name|long
operator|)
name|nbuf
operator|*
name|BKVASIZE
expr_stmt|;
name|hibufspace
operator|=
name|lmax
argument_list|(
literal|3
operator|*
name|maxbufspace
operator|/
literal|4
argument_list|,
name|maxbufspace
operator|-
name|MAXBCACHEBUF
operator|*
literal|10
argument_list|)
expr_stmt|;
name|lobufspace
operator|=
name|hibufspace
operator|-
name|MAXBCACHEBUF
expr_stmt|;
comment|/* 	 * Note: The 16 MiB upper limit for hirunningspace was chosen 	 * arbitrarily and may need further tuning. It corresponds to 	 * 128 outstanding write IO requests (if IO size is 128 KiB), 	 * which fits with many RAID controllers' tagged queuing limits. 	 * The lower 1 MiB limit is the historical upper limit for 	 * hirunningspace. 	 */
name|hirunningspace
operator|=
name|lmax
argument_list|(
name|lmin
argument_list|(
name|roundup
argument_list|(
name|hibufspace
operator|/
literal|64
argument_list|,
name|MAXBCACHEBUF
argument_list|)
argument_list|,
literal|16
operator|*
literal|1024
operator|*
literal|1024
argument_list|)
argument_list|,
literal|1024
operator|*
literal|1024
argument_list|)
expr_stmt|;
name|lorunningspace
operator|=
name|roundup
argument_list|(
operator|(
name|hirunningspace
operator|*
literal|2
operator|)
operator|/
literal|3
argument_list|,
name|MAXBCACHEBUF
argument_list|)
expr_stmt|;
comment|/*  * Limit the amount of malloc memory since it is wired permanently into  * the kernel space.  Even though this is accounted for in the buffer  * allocation, we don't want the malloced region to grow uncontrolled.  * The malloc scheme improves memory utilization significantly on average  * (small) directories.  */
name|maxbufmallocspace
operator|=
name|hibufspace
operator|/
literal|20
expr_stmt|;
comment|/*  * Reduce the chance of a deadlock occuring by limiting the number  * of delayed-write dirty buffers we allow to stack up.  */
name|hidirtybuffers
operator|=
name|nbuf
operator|/
literal|4
operator|+
literal|20
expr_stmt|;
name|dirtybufthresh
operator|=
name|hidirtybuffers
operator|*
literal|9
operator|/
literal|10
expr_stmt|;
name|numdirtybuffers
operator|=
literal|0
expr_stmt|;
comment|/*  * To support extreme low-memory systems, make sure hidirtybuffers cannot  * eat up all available buffer space.  This occurs when our minimum cannot  * be met.  We try to size hidirtybuffers to 3/4 our buffer space assuming  * BKVASIZE'd buffers.  */
while|while
condition|(
operator|(
name|long
operator|)
name|hidirtybuffers
operator|*
name|BKVASIZE
operator|>
literal|3
operator|*
name|hibufspace
operator|/
literal|4
condition|)
block|{
name|hidirtybuffers
operator|>>=
literal|1
expr_stmt|;
block|}
name|lodirtybuffers
operator|=
name|hidirtybuffers
operator|/
literal|2
expr_stmt|;
comment|/*  * Try to keep the number of free buffers in the specified range,  * and give special processes (e.g. like buf_daemon) access to an   * emergency reserve.  */
name|lofreebuffers
operator|=
name|nbuf
operator|/
literal|18
operator|+
literal|5
expr_stmt|;
name|hifreebuffers
operator|=
literal|2
operator|*
name|lofreebuffers
expr_stmt|;
name|numfreebuffers
operator|=
name|nbuf
expr_stmt|;
name|bogus_page
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_WIRED
argument_list|)
expr_stmt|;
name|unmapped_buf
operator|=
operator|(
name|caddr_t
operator|)
name|kva_alloc
argument_list|(
name|MAXPHYS
argument_list|)
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|INVARIANTS
end_ifdef

begin_function
specifier|static
specifier|inline
name|void
name|vfs_buf_check_mapped
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"mapped buf %p %x"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_flags
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_kvabase
operator|!=
name|unmapped_buf
argument_list|,
operator|(
literal|"mapped buf: b_kvabase was not updated %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_data
operator|!=
name|unmapped_buf
argument_list|,
operator|(
literal|"mapped buf: b_data was not updated %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
specifier|inline
name|void
name|vfs_buf_check_unmapped
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|==
name|B_UNMAPPED
argument_list|,
operator|(
literal|"unmapped buf %p %x"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_flags
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_kvabase
operator|==
name|unmapped_buf
argument_list|,
operator|(
literal|"unmapped buf: corrupted b_kvabase %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_data
operator|==
name|unmapped_buf
argument_list|,
operator|(
literal|"unmapped buf: corrupted b_data %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_define
define|#
directive|define
name|BUF_CHECK_MAPPED
parameter_list|(
name|bp
parameter_list|)
value|vfs_buf_check_mapped(bp)
end_define

begin_define
define|#
directive|define
name|BUF_CHECK_UNMAPPED
parameter_list|(
name|bp
parameter_list|)
value|vfs_buf_check_unmapped(bp)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|BUF_CHECK_MAPPED
parameter_list|(
name|bp
parameter_list|)
value|do {} while (0)
end_define

begin_define
define|#
directive|define
name|BUF_CHECK_UNMAPPED
parameter_list|(
name|bp
parameter_list|)
value|do {} while (0)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|void
name|bpmap_qenter
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * bp->b_data is relative to bp->b_offset, but 	 * bp->b_offset may be offset into the first page. 	 */
name|bp
operator|->
name|b_data
operator|=
operator|(
name|caddr_t
operator|)
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
call|(
name|caddr_t
call|)
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator||
call|(
name|vm_offset_t
call|)
argument_list|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * bfreekva() - free the kva allocation for a buffer.  *  *	Since this call frees up buffer space, we call bufspacewakeup().  */
end_comment

begin_function
specifier|static
name|void
name|bfreekva
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_kvasize
operator|==
literal|0
condition|)
return|return;
name|atomic_add_int
argument_list|(
operator|&
name|buffreekvacnt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|atomic_subtract_long
argument_list|(
operator|&
name|bufspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|==
literal|0
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|vmem_free
argument_list|(
name|buffer_arena
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_kvabase
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_KVAALLOC
operator|)
operator|!=
literal|0
condition|)
block|{
name|vmem_free
argument_list|(
name|buffer_arena
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_kvaalloc
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
block|}
name|atomic_subtract_long
argument_list|(
operator|&
name|unmapped_bufspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_UNMAPPED
operator||
name|B_KVAALLOC
operator|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_kvasize
operator|=
literal|0
expr_stmt|;
name|bufspacewakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	binsfree:  *  *	Insert the buffer into the appropriate free list.  */
end_comment

begin_function
specifier|static
name|void
name|binsfree
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|qindex
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|olock
decl_stmt|,
modifier|*
name|nlock
decl_stmt|;
name|BUF_ASSERT_XLOCKED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|nlock
operator|=
name|bqlock
argument_list|(
name|qindex
argument_list|)
expr_stmt|;
comment|/* Handle delayed bremfree() processing. */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
condition|)
block|{
name|olock
operator|=
name|bqlock
argument_list|(
name|bp
operator|->
name|b_qindex
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|olock
argument_list|)
expr_stmt|;
name|bremfreel
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|olock
operator|!=
name|nlock
condition|)
block|{
name|mtx_unlock
argument_list|(
name|olock
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|nlock
argument_list|)
expr_stmt|;
block|}
block|}
else|else
name|mtx_lock
argument_list|(
name|nlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
condition|)
name|panic
argument_list|(
literal|"binsfree: free buffer onto another queue???"
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|qindex
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_AGE
condition|)
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|INVARIANTS
name|bq_len
index|[
name|bp
operator|->
name|b_qindex
index|]
operator|++
expr_stmt|;
endif|#
directive|endif
name|mtx_unlock
argument_list|(
name|nlock
argument_list|)
expr_stmt|;
comment|/* 	 * Something we can maybe free or reuse. 	 */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|||
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
condition|)
name|bufcountadd
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bremfree:  *  *	Mark the buffer for removal from the appropriate free list.  *	  */
end_comment

begin_function
name|void
name|bremfree
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bremfree(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"bremfree: buffer %p already marked for delayed removal."
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bremfree: buffer %p not on a queue."
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_XLOCKED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_REMFREE
expr_stmt|;
name|bufcountsub
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bremfreef:  *  *	Force an immediate removal from a free list.  Used only in nfs when  *	it abuses the b_freelist pointer.  */
end_comment

begin_function
name|void
name|bremfreef
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|qlock
decl_stmt|;
name|qlock
operator|=
name|bqlock
argument_list|(
name|bp
operator|->
name|b_qindex
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|qlock
argument_list|)
expr_stmt|;
name|bremfreel
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|qlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bremfreel:  *  *	Removes a buffer from the free list, must be called with the  *	correct qlock held.  */
end_comment

begin_function
specifier|static
name|void
name|bremfreel
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bremfreel(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bremfreel: buffer %p not on a queue."
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_XLOCKED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
name|bqlock
argument_list|(
name|bp
operator|->
name|b_qindex
argument_list|)
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|INVARIANTS
name|KASSERT
argument_list|(
name|bq_len
index|[
name|bp
operator|->
name|b_qindex
index|]
operator|>=
literal|1
argument_list|,
operator|(
literal|"queue %d underflow"
operator|,
name|bp
operator|->
name|b_qindex
operator|)
argument_list|)
expr_stmt|;
name|bq_len
index|[
name|bp
operator|->
name|b_qindex
index|]
operator|--
expr_stmt|;
endif|#
directive|endif
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_NONE
expr_stmt|;
comment|/* 	 * If this was a delayed bremfree() we only need to remove the buffer 	 * from the queue and return the stats are already done. 	 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_REMFREE
expr_stmt|;
return|return;
block|}
name|bufcountsub
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Attempt to initiate asynchronous I/O on read-ahead blocks.  We must  * clear BIO_ERROR and B_INVAL prior to initiating I/O . If B_CACHE is set,  * the buffer is valid and we do not have to do anything.  */
end_comment

begin_function
name|void
name|breada
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
modifier|*
name|rablkno
parameter_list|,
name|int
modifier|*
name|rabsize
parameter_list|,
name|int
name|cnt
parameter_list|,
name|struct
name|ucred
modifier|*
name|cred
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|rabp
decl_stmt|;
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|cnt
condition|;
name|i
operator|++
operator|,
name|rablkno
operator|++
operator|,
name|rabsize
operator|++
control|)
block|{
if|if
condition|(
name|inmem
argument_list|(
name|vp
argument_list|,
operator|*
name|rablkno
argument_list|)
condition|)
continue|continue;
name|rabp
operator|=
name|getblk
argument_list|(
name|vp
argument_list|,
operator|*
name|rablkno
argument_list|,
operator|*
name|rabsize
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|rabp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|TD_IS_IDLETHREAD
argument_list|(
name|curthread
argument_list|)
condition|)
name|curthread
operator|->
name|td_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
name|rabp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
name|rabp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INVAL
expr_stmt|;
name|rabp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|rabp
operator|->
name|b_iocmd
operator|=
name|BIO_READ
expr_stmt|;
if|if
condition|(
name|rabp
operator|->
name|b_rcred
operator|==
name|NOCRED
operator|&&
name|cred
operator|!=
name|NOCRED
condition|)
name|rabp
operator|->
name|b_rcred
operator|=
name|crhold
argument_list|(
name|cred
argument_list|)
expr_stmt|;
name|vfs_busy_pages
argument_list|(
name|rabp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|BUF_KERNPROC
argument_list|(
name|rabp
argument_list|)
expr_stmt|;
name|rabp
operator|->
name|b_iooffset
operator|=
name|dbtob
argument_list|(
name|rabp
operator|->
name|b_blkno
argument_list|)
expr_stmt|;
name|bstrategy
argument_list|(
name|rabp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|brelse
argument_list|(
name|rabp
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * Entry point for bread() and breadn() via #defines in sys/buf.h.  *  * Get a buffer with the specified data.  Look in the cache first.  We  * must clear BIO_ERROR and B_INVAL prior to initiating I/O.  If B_CACHE  * is set, the buffer is valid and we do not have to do anything, see  * getblk(). Also starts asynchronous I/O on read-ahead blocks.  */
end_comment

begin_function
name|int
name|breadn_flags
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|daddr_t
modifier|*
name|rablkno
parameter_list|,
name|int
modifier|*
name|rabsize
parameter_list|,
name|int
name|cnt
parameter_list|,
name|struct
name|ucred
modifier|*
name|cred
parameter_list|,
name|int
name|flags
parameter_list|,
name|struct
name|buf
modifier|*
modifier|*
name|bpp
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|rv
init|=
literal|0
decl_stmt|,
name|readwait
init|=
literal|0
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"breadn(%p, %jd, %d)"
argument_list|,
name|vp
argument_list|,
name|blkno
argument_list|,
name|size
argument_list|)
expr_stmt|;
comment|/* 	 * Can only return NULL if GB_LOCK_NOWAIT flag is specified. 	 */
operator|*
name|bpp
operator|=
name|bp
operator|=
name|getblk
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|,
name|size
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|==
name|NULL
condition|)
return|return
operator|(
name|EBUSY
operator|)
return|;
comment|/* if not found in cache, do some I/O */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|TD_IS_IDLETHREAD
argument_list|(
name|curthread
argument_list|)
condition|)
name|curthread
operator|->
name|td_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
name|bp
operator|->
name|b_iocmd
operator|=
name|BIO_READ
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INVAL
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_rcred
operator|==
name|NOCRED
operator|&&
name|cred
operator|!=
name|NOCRED
condition|)
name|bp
operator|->
name|b_rcred
operator|=
name|crhold
argument_list|(
name|cred
argument_list|)
expr_stmt|;
name|vfs_busy_pages
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_iooffset
operator|=
name|dbtob
argument_list|(
name|bp
operator|->
name|b_blkno
argument_list|)
expr_stmt|;
name|bstrategy
argument_list|(
name|bp
argument_list|)
expr_stmt|;
operator|++
name|readwait
expr_stmt|;
block|}
name|breada
argument_list|(
name|vp
argument_list|,
name|rablkno
argument_list|,
name|rabsize
argument_list|,
name|cnt
argument_list|,
name|cred
argument_list|)
expr_stmt|;
if|if
condition|(
name|readwait
condition|)
block|{
name|rv
operator|=
name|bufwait
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Write, release buffer on completion.  (Done by iodone  * if async).  Do not bother writing anything if the buffer  * is invalid.  *  * Note that we set B_CACHE here, indicating that buffer is  * fully valid and thus cacheable.  This is true even of NFS  * now so we set it generally.  This could be set either here   * or in biodone() since the I/O is synchronous.  We put it  * here.  */
end_comment

begin_function
name|int
name|bufwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|oldflags
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|long
name|space
decl_stmt|;
name|int
name|vp_md
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bufwrite(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_flag
operator|&
name|BO_DEAD
operator|)
operator|!=
literal|0
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
operator||
name|B_RELBUF
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENXIO
operator|)
return|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_BARRIER
condition|)
name|barrierwrites
operator|++
expr_stmt|;
name|oldflags
operator|=
name|bp
operator|->
name|b_flags
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_pin_count
operator|>
literal|0
condition|)
name|bunpin_wait
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
operator|)
argument_list|,
operator|(
literal|"FFS background buffer should not get here %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
if|if
condition|(
name|vp
condition|)
name|vp_md
operator|=
name|vp
operator|->
name|v_vflag
operator|&
name|VV_MD
expr_stmt|;
else|else
name|vp_md
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Mark the buffer clean.  Increment the bufobj write count 	 * before bundirty() call, to prevent other thread from seeing 	 * empty dirty list and zero counter for writes in progress, 	 * falsely indicating that the bufobj is clean. 	 */
name|bufobj_wref
argument_list|(
name|bp
operator|->
name|b_bufobj
argument_list|)
expr_stmt|;
name|bundirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
name|bp
operator|->
name|b_iocmd
operator|=
name|BIO_WRITE
expr_stmt|;
name|vfs_busy_pages
argument_list|(
name|bp
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * Normal bwrites pipeline writes 	 */
name|bp
operator|->
name|b_runningbufspace
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|space
operator|=
name|atomic_fetchadd_long
argument_list|(
operator|&
name|runningbufspace
argument_list|,
name|bp
operator|->
name|b_runningbufspace
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|TD_IS_IDLETHREAD
argument_list|(
name|curthread
argument_list|)
condition|)
name|curthread
operator|->
name|td_ru
operator|.
name|ru_oublock
operator|++
expr_stmt|;
if|if
condition|(
name|oldflags
operator|&
name|B_ASYNC
condition|)
name|BUF_KERNPROC
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_iooffset
operator|=
name|dbtob
argument_list|(
name|bp
operator|->
name|b_blkno
argument_list|)
expr_stmt|;
name|bstrategy
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|oldflags
operator|&
name|B_ASYNC
operator|)
operator|==
literal|0
condition|)
block|{
name|int
name|rtval
init|=
name|bufwait
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|rtval
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|space
operator|>
name|hirunningspace
condition|)
block|{
comment|/* 		 * don't allow the async write to saturate the I/O 		 * system.  We will not deadlock here because 		 * we are blocking waiting for I/O that is already in-progress 		 * to complete. We do not block here if it is the update 		 * or syncer daemon trying to clean up as that can lead 		 * to deadlock. 		 */
if|if
condition|(
operator|(
name|curthread
operator|->
name|td_pflags
operator|&
name|TDP_NORUNNINGBUF
operator|)
operator|==
literal|0
operator|&&
operator|!
name|vp_md
condition|)
name|waitrunningbufspace
argument_list|()
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|void
name|bufbdflush
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|,
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|nbp
decl_stmt|;
if|if
condition|(
name|bo
operator|->
name|bo_dirty
operator|.
name|bv_cnt
operator|>
name|dirtybufthresh
operator|+
literal|10
condition|)
block|{
operator|(
name|void
operator|)
name|VOP_FSYNC
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|MNT_NOWAIT
argument_list|,
name|curthread
argument_list|)
expr_stmt|;
name|altbufferflushes
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bo
operator|->
name|bo_dirty
operator|.
name|bv_cnt
operator|>
name|dirtybufthresh
condition|)
block|{
name|BO_LOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
comment|/* 		 * Try to find a buffer to flush. 		 */
name|TAILQ_FOREACH
argument_list|(
argument|nbp
argument_list|,
argument|&bo->bo_dirty.bv_hd
argument_list|,
argument|b_bobufs
argument_list|)
block|{
if|if
condition|(
operator|(
name|nbp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
operator|)
operator|||
name|BUF_LOCK
argument_list|(
name|nbp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|NULL
argument_list|)
condition|)
continue|continue;
if|if
condition|(
name|bp
operator|==
name|nbp
condition|)
name|panic
argument_list|(
literal|"bdwrite: found ourselves"
argument_list|)
expr_stmt|;
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
comment|/* Don't countdeps with the bo lock held. */
if|if
condition|(
name|buf_countdeps
argument_list|(
name|nbp
argument_list|,
literal|0
argument_list|)
condition|)
block|{
name|BO_LOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|BUF_UNLOCK
argument_list|(
name|nbp
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|nbp
operator|->
name|b_flags
operator|&
name|B_CLUSTEROK
condition|)
block|{
name|vfs_bio_awrite
argument_list|(
name|nbp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bremfree
argument_list|(
name|nbp
argument_list|)
expr_stmt|;
name|bawrite
argument_list|(
name|nbp
argument_list|)
expr_stmt|;
block|}
name|dirtybufferflushes
operator|++
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|nbp
operator|==
name|NULL
condition|)
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Delayed write. (Buffer is marked dirty).  Do not bother writing  * anything if the buffer is marked invalid.  *  * Note that since the buffer must be completely valid, we can safely  * set B_CACHE.  In fact, we have to set B_CACHE here rather then in  * biodone() in order to prevent getblk from writing the buffer  * out synchronously.  */
end_comment

begin_function
name|void
name|bdwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
init|=
name|curthread
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|struct
name|bufobj
modifier|*
name|bo
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bdwrite(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|!=
name|NULL
argument_list|,
operator|(
literal|"No b_bufobj %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_BARRIER
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"Barrier request in delayed write %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * If we have too many dirty buffers, don't create any more. 	 * If we are wildly over our limit, then force a complete 	 * cleanup. Otherwise, just keep the situation from getting 	 * out of control. Note that we have to avoid a recursive 	 * disaster and not try to clean up after our own cleanup! 	 */
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
name|bo
operator|=
name|bp
operator|->
name|b_bufobj
expr_stmt|;
if|if
condition|(
operator|(
name|td
operator|->
name|td_pflags
operator|&
operator|(
name|TDP_COWINPROGRESS
operator||
name|TDP_INBDFLUSH
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|td
operator|->
name|td_pflags
operator||=
name|TDP_INBDFLUSH
expr_stmt|;
name|BO_BDFLUSH
argument_list|(
name|bo
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_pflags
operator|&=
operator|~
name|TDP_INBDFLUSH
expr_stmt|;
block|}
else|else
name|recursiveflushes
operator|++
expr_stmt|;
name|bdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * Set B_CACHE, indicating that the buffer is fully valid.  This is 	 * true even of NFS now. 	 */
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
comment|/* 	 * This bmap keeps the system from needing to do the bmap later, 	 * perhaps when the system is attempting to do a sync.  Since it 	 * is likely that the indirect block -- or whatever other datastructure 	 * that the filesystem needs is still in memory now, it is a good 	 * thing to do this.  Note also, that if the pageout daemon is 	 * requesting a sync -- there might not be enough memory to do 	 * the bmap then...  So, this is important to do. 	 */
if|if
condition|(
name|vp
operator|->
name|v_type
operator|!=
name|VCHR
operator|&&
name|bp
operator|->
name|b_lblkno
operator|==
name|bp
operator|->
name|b_blkno
condition|)
block|{
name|VOP_BMAP
argument_list|(
name|vp
argument_list|,
name|bp
operator|->
name|b_lblkno
argument_list|,
name|NULL
argument_list|,
operator|&
name|bp
operator|->
name|b_blkno
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Set the *dirty* buffer range based upon the VM system dirty 	 * pages. 	 * 	 * Mark the buffer pages as clean.  We need to do this here to 	 * satisfy the vnode_pager and the pageout daemon, so that it 	 * thinks that the pages have been "cleaned".  Note that since 	 * the pages are in a delayed write buffer -- the VFS layer 	 * "will" see that the pages get written out on the next sync, 	 * or perhaps the cluster will be completed. 	 */
name|vfs_clean_pages_dirty_buf
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * note: we cannot initiate I/O from a bdwrite even if we wanted to, 	 * due to the softdep code. 	 */
block|}
end_function

begin_comment
comment|/*  *	bdirty:  *  *	Turn buffer into delayed write request.  We must clear BIO_READ and  *	B_RELBUF, and we must set B_DELWRI.  We reassign the buffer to   *	itself to properly update it in the dirty/clean lists.  We mark it  *	B_DONE to ensure that any asynchronization of the buffer properly  *	clears B_DONE ( else a panic will occur later ).    *  *	bdirty() is kinda like bdwrite() - we have to clear B_INVAL which  *	might have been set pre-getblk().  Unlike bwrite/bdwrite, bdirty()  *	should only be called if the buffer is known-good.  *  *	Since the buffer is not on a queue, we do not update the numfreebuffers  *	count.  *  *	The buffer must be on QUEUE_NONE.  */
end_comment

begin_function
name|void
name|bdirty
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bdirty(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|!=
name|NULL
argument_list|,
operator|(
literal|"No b_bufobj %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
operator|||
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bdirty: buffer %p still on queue %d"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_qindex
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_RELBUF
operator|)
expr_stmt|;
name|bp
operator|->
name|b_iocmd
operator|=
name|BIO_WRITE
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
comment|/* XXX B_DONE | */
name|B_DELWRI
expr_stmt|;
name|reassignbuf
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bdirtyadd
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	bundirty:  *  *	Clear B_DELWRI for buffer.  *  *	Since the buffer is not on a queue, we do not update the numfreebuffers  *	count.  *	  *	The buffer must be on QUEUE_NONE.  */
end_comment

begin_function
name|void
name|bundirty
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bundirty(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|!=
name|NULL
argument_list|,
operator|(
literal|"No b_bufobj %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
operator|||
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bundirty: buffer %p still on queue %d"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_qindex
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DELWRI
expr_stmt|;
name|reassignbuf
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bdirtysub
argument_list|()
expr_stmt|;
block|}
comment|/* 	 * Since it is now being written, we can clear its deferred write flag. 	 */
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DEFERRED
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bawrite:  *  *	Asynchronous write.  Start output on a buffer, but do not wait for  *	it to complete.  The buffer is released when the output completes.  *  *	bwrite() ( or the VOP routine anyway ) is responsible for handling   *	B_INVAL buffers.  Not us.  */
end_comment

begin_function
name|void
name|bawrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
operator|(
name|void
operator|)
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	babarrierwrite:  *  *	Asynchronous barrier write.  Start output on a buffer, but do not  *	wait for it to complete.  Place a write barrier after this write so  *	that this buffer and all buffers written before it are committed to  *	the disk before any buffers written after this write are committed  *	to the disk.  The buffer is released when the output completes.  */
end_comment

begin_function
name|void
name|babarrierwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_ASYNC
operator||
name|B_BARRIER
expr_stmt|;
operator|(
name|void
operator|)
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bbarrierwrite:  *  *	Synchronous barrier write.  Start output on a buffer and wait for  *	it to complete.  Place a write barrier after this write so that  *	this buffer and all buffers written before it are committed to   *	the disk before any buffers written after this write are committed  *	to the disk.  The buffer is released when the output completes.  */
end_comment

begin_function
name|int
name|bbarrierwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_BARRIER
expr_stmt|;
return|return
operator|(
name|bwrite
argument_list|(
name|bp
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	bwillwrite:  *  *	Called prior to the locking of any vnodes when we are expecting to  *	write.  We do not want to starve the buffer cache with too many  *	dirty buffers so we block here.  By blocking prior to the locking  *	of any vnodes we attempt to avoid the situation where a locked vnode  *	prevents the various system daemons from flushing related buffers.  */
end_comment

begin_function
name|void
name|bwillwrite
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|numdirtybuffers
operator|>=
name|hidirtybuffers
condition|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|bdirtylock
argument_list|)
expr_stmt|;
while|while
condition|(
name|numdirtybuffers
operator|>=
name|hidirtybuffers
condition|)
block|{
name|bdirtywait
operator|=
literal|1
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|bdirtywait
argument_list|,
operator|&
name|bdirtylock
argument_list|,
operator|(
name|PRIBIO
operator|+
literal|4
operator|)
argument_list|,
literal|"flswai"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|bdirtylock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Return true if we have too many dirty buffers.  */
end_comment

begin_function
name|int
name|buf_dirty_count_severe
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
name|numdirtybuffers
operator|>=
name|hidirtybuffers
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__noinline
name|int
name|buf_vm_page_count_severe
parameter_list|(
name|void
parameter_list|)
block|{
name|KFAIL_POINT_CODE
argument_list|(
argument|DEBUG_FP
argument_list|,
argument|buf_pressure
argument_list|,
argument|return
literal|1
argument_list|)
empty_stmt|;
return|return
name|vm_page_count_severe
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/*  *	brelse:  *  *	Release a busy buffer and, if requested, free its resources.  The  *	buffer will be stashed in the appropriate bufqueue[] allowing it  *	to be accessed later as a cache entity or reused for other purposes.  */
end_comment

begin_function
name|void
name|brelse
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|qindex
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"brelse(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTER
operator||
name|B_PAGING
operator|)
operator|)
argument_list|,
operator|(
literal|"brelse: inappropriate B_PAGING or B_CLUSTER bp %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|BUF_LOCKRECURSED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
comment|/* 		 * Do not process, in particular, do not handle the 		 * B_INVAL/B_RELBUF and do not release to free list. 		 */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MANAGED
condition|)
block|{
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|bp
operator|->
name|b_vflags
operator|&
operator|(
name|BV_BKGRDINPROG
operator||
name|BV_BKGRDERR
operator|)
operator|)
operator|==
name|BV_BKGRDERR
condition|)
block|{
name|BO_LOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_vflags
operator|&=
operator|~
name|BV_BKGRDERR
expr_stmt|;
name|BO_UNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
argument_list|)
expr_stmt|;
name|bdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_WRITE
operator|&&
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
operator|&&
name|bp
operator|->
name|b_error
operator|==
name|EIO
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
condition|)
block|{
comment|/* 		 * Failed write, redirty.  Must clear BIO_ERROR to prevent 		 * pages from being scrapped.  If the error is anything 		 * other than an I/O error (EIO), assume that retrying 		 * is futile. 		 */
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|bdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_NOCACHE
operator||
name|B_INVAL
operator|)
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_bufsize
operator|<=
literal|0
operator|)
condition|)
block|{
comment|/* 		 * Either a failed I/O or we were asked to free or not 		 * cache the buffer. 		 */
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
if|if
condition|(
operator|!
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
condition|)
name|buf_deallocate
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|bdirtysub
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_DELWRI
operator||
name|B_CACHE
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
name|allocbuf
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * We must clear B_RELBUF if B_DELWRI is set.  If vfs_vmio_release()  	 * is called with B_DELWRI set, the underlying pages may wind up 	 * getting freed causing a previous write (bdwrite()) to get 'lost' 	 * because pages associated with a B_DELWRI bp are marked clean. 	 *  	 * We still allow the B_INVAL case to call vfs_vmio_release(), even 	 * if B_DELWRI is set. 	 * 	 * If B_DELWRI is not set we may have to set B_RELBUF if we are low 	 * on pages to return pages to the VM page queues. 	 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_RELBUF
expr_stmt|;
elseif|else
if|if
condition|(
name|buf_vm_page_count_severe
argument_list|()
condition|)
block|{
comment|/* 		 * BKGRDINPROG can only be set with the buf and bufobj 		 * locks both held.  We tolerate a race to clear it here. 		 */
if|if
condition|(
operator|!
operator|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
operator|)
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_RELBUF
expr_stmt|;
block|}
comment|/* 	 * VMIO buffer rundown.  It is not very necessary to keep a VMIO buffer 	 * constituted, not even NFS buffers now.  Two flags effect this.  If 	 * B_INVAL, the struct buf is invalidated but the VM object is kept 	 * around ( i.e. so it is trivial to reconstitute the buffer later ). 	 * 	 * If BIO_ERROR or B_NOCACHE is set, pages in the VM object will be 	 * invalidated.  BIO_ERROR cannot be set for a failed write unless the 	 * buffer is also B_INVAL because it hits the re-dirtying code above. 	 * 	 * Normally we can do this whether a buffer is B_DELWRI or not.  If 	 * the buffer is an NFS buffer, it is tracking piecemeal writes or 	 * the commit state and we cannot afford to lose the buffer. If the 	 * buffer has a background write in progress, we need to keep it 	 * around to prevent it from being reconstituted and starting a second 	 * background write. 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_vp
operator|->
name|v_mount
operator|!=
name|NULL
operator|&&
operator|(
name|bp
operator|->
name|b_vp
operator|->
name|v_mount
operator|->
name|mnt_vfc
operator|->
name|vfc_flags
operator|&
name|VFCF_NETWORK
operator|)
operator|!=
literal|0
operator|&&
operator|!
name|vn_isdisk
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|NULL
argument_list|)
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|)
condition|)
block|{
name|int
name|i
decl_stmt|,
name|j
decl_stmt|,
name|resid
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|off_t
name|foff
decl_stmt|;
name|vm_pindex_t
name|poff
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
comment|/* 		 * Get the base offset and length of the buffer.  Note that  		 * in the VMIO case if the buffer block size is not 		 * page-aligned then b_data pointer may not be page-aligned. 		 * But our b_pages[] array *IS* page aligned. 		 * 		 * block sizes less then DEV_BSIZE (usually 512) are not  		 * supported due to the page granularity bits (m->valid, 		 * m->dirty, etc...).  		 * 		 * See man buf(9) for more information 		 */
name|resid
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|int
name|had_bogus
init|=
literal|0
decl_stmt|;
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
comment|/* 			 * If we hit a bogus page, fixup *all* the bogus pages 			 * now. 			 */
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|poff
operator|=
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
expr_stmt|;
name|had_bogus
operator|=
literal|1
expr_stmt|;
name|VM_OBJECT_RLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
for|for
control|(
name|j
operator|=
name|i
init|;
name|j
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|j
operator|++
control|)
block|{
name|vm_page_t
name|mtmp
decl_stmt|;
name|mtmp
operator|=
name|bp
operator|->
name|b_pages
index|[
name|j
index|]
expr_stmt|;
if|if
condition|(
name|mtmp
operator|==
name|bogus_page
condition|)
block|{
name|mtmp
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|poff
operator|+
name|j
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|mtmp
condition|)
block|{
name|panic
argument_list|(
literal|"brelse: page missing\n"
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_pages
index|[
name|j
index|]
operator|=
name|mtmp
expr_stmt|;
block|}
block|}
name|VM_OBJECT_RUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_UNMAPPED
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_NOCACHE
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|&&
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
operator|)
condition|)
block|{
name|int
name|poffset
init|=
name|foff
operator|&
name|PAGE_MASK
decl_stmt|;
name|int
name|presid
init|=
name|resid
operator|>
operator|(
name|PAGE_SIZE
operator|-
name|poffset
operator|)
condition|?
operator|(
name|PAGE_SIZE
operator|-
name|poffset
operator|)
else|:
name|resid
decl_stmt|;
name|KASSERT
argument_list|(
name|presid
operator|>=
literal|0
argument_list|,
operator|(
literal|"brelse: extra page"
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
while|while
condition|(
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
block|{
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
name|vm_page_busy_sleep
argument_list|(
name|m
argument_list|,
literal|"mbncsh"
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pmap_page_wired_mappings
argument_list|(
name|m
argument_list|)
operator|==
literal|0
condition|)
name|vm_page_set_invalid
argument_list|(
name|m
argument_list|,
name|poffset
argument_list|,
name|presid
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
if|if
condition|(
name|had_bogus
condition|)
name|printf
argument_list|(
literal|"avoided corruption bug in bogus_page/brelse code\n"
argument_list|)
expr_stmt|;
block|}
name|resid
operator|-=
name|PAGE_SIZE
operator|-
operator|(
name|foff
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|foff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_RELBUF
operator|)
condition|)
name|vfs_vmio_release
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_RELBUF
operator|)
condition|)
block|{
name|vfs_vmio_release
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_RELBUF
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|!=
literal|0
condition|)
name|allocbuf
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
operator|!=
name|NULL
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If the buffer has junk contents signal it and eventually 	 * clean up B_DELWRI and diassociate the vnode so that gbincore() 	 * doesn't find it. 	 */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
operator|!=
literal|0
operator|||
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_NOCACHE
operator||
name|B_RELBUF
operator|)
operator|)
operator|!=
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|bundirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* buffers with no memory */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_xflags
operator|&=
operator|~
operator|(
name|BX_BKGRDWRITE
operator||
name|BX_ALTDATA
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
condition|)
name|panic
argument_list|(
literal|"losing buffer 1"
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_kvasize
condition|)
name|qindex
operator|=
name|QUEUE_EMPTYKVA
expr_stmt|;
else|else
name|qindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_AGE
expr_stmt|;
comment|/* buffers with junk contents */
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_NOCACHE
operator||
name|B_RELBUF
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
condition|)
block|{
name|bp
operator|->
name|b_xflags
operator|&=
operator|~
operator|(
name|BX_BKGRDWRITE
operator||
name|BX_ALTDATA
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
condition|)
name|panic
argument_list|(
literal|"losing buffer 2"
argument_list|)
expr_stmt|;
name|qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_AGE
expr_stmt|;
comment|/* remaining buffers */
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|qindex
operator|=
name|QUEUE_DIRTY
expr_stmt|;
else|else
name|qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|binsfree
argument_list|(
name|bp
argument_list|,
name|qindex
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ASYNC
operator||
name|B_NOCACHE
operator||
name|B_AGE
operator||
name|B_RELBUF
operator||
name|B_DIRECT
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
operator|&&
operator|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_VNDIRTY
operator|)
condition|)
name|panic
argument_list|(
literal|"brelse: not dirty"
argument_list|)
expr_stmt|;
comment|/* unlock */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Release a buffer back to the appropriate queue but do not try to free  * it.  The buffer is expected to be used again soon.  *  * bqrelse() is used by bdwrite() to requeue a delayed write, and used by  * biodone() to requeue an async I/O on completion.  It is also used when  * known good buffers need to be requeued but we think we may need the data  * again soon.  *  * XXX we should be able to leave the B_RELBUF hint set on completion.  */
end_comment

begin_function
name|void
name|bqrelse
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|qindex
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bqrelse(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTER
operator||
name|B_PAGING
operator|)
operator|)
argument_list|,
operator|(
literal|"bqrelse: inappropriate B_PAGING or B_CLUSTER bp %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|BUF_LOCKRECURSED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
comment|/* do not release to free list */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ASYNC
operator||
name|B_NOCACHE
operator||
name|B_AGE
operator||
name|B_RELBUF
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MANAGED
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
condition|)
name|bremfreef
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|out
goto|;
block|}
comment|/* buffers with stale but valid contents */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|!=
literal|0
operator|||
operator|(
name|bp
operator|->
name|b_vflags
operator|&
operator|(
name|BV_BKGRDINPROG
operator||
name|BV_BKGRDERR
operator|)
operator|)
operator|==
name|BV_BKGRDERR
condition|)
block|{
name|BO_LOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_vflags
operator|&=
operator|~
name|BV_BKGRDERR
expr_stmt|;
name|BO_UNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
argument_list|)
expr_stmt|;
name|qindex
operator|=
name|QUEUE_DIRTY
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
operator|&&
operator|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_VNDIRTY
operator|)
condition|)
name|panic
argument_list|(
literal|"bqrelse: not dirty"
argument_list|)
expr_stmt|;
comment|/* 		 * BKGRDINPROG can only be set with the buf and bufobj 		 * locks both held.  We tolerate a race to clear it here. 		 */
if|if
condition|(
name|buf_vm_page_count_severe
argument_list|()
operator|&&
operator|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 			 * We are too low on memory, we have to try to free 			 * the buffer (most importantly: the wired pages 			 * making up its backing store) *now*. 			 */
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
name|qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
block|}
name|binsfree
argument_list|(
name|bp
argument_list|,
name|qindex
argument_list|)
expr_stmt|;
name|out
label|:
comment|/* unlock */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Give pages used by the bp back to the VM system (where possible) */
end_comment

begin_function
specifier|static
name|void
name|vfs_vmio_release
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|==
literal|0
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
else|else
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
if|if
condition|(
name|obj
operator|!=
name|NULL
condition|)
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|NULL
expr_stmt|;
comment|/* 		 * In order to keep page LRU ordering consistent, put 		 * everything on the inactive queue. 		 */
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
name|PQ_INACTIVE
argument_list|)
expr_stmt|;
comment|/* 		 * Might as well free the page if we can and it has 		 * no valid data.  We also free the page if the 		 * buffer was used for direct I/O 		 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ASYNC
operator|)
operator|==
literal|0
operator|&&
operator|!
name|m
operator|->
name|valid
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|!
name|vm_page_busied
argument_list|(
name|m
argument_list|)
condition|)
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DIRECT
condition|)
name|vm_page_try_to_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|buf_vm_page_count_severe
argument_list|()
condition|)
name|vm_page_try_to_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|obj
operator|!=
name|NULL
condition|)
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
block|{
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
literal|0
expr_stmt|;
block|}
name|bp
operator|->
name|b_npages
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_VMIO
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Check to see if a block at a particular lbn is available for a clustered  * write.  */
end_comment

begin_function
specifier|static
name|int
name|vfs_bio_clcheck
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
name|size
parameter_list|,
name|daddr_t
name|lblkno
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bpa
decl_stmt|;
name|int
name|match
decl_stmt|;
name|match
operator|=
literal|0
expr_stmt|;
comment|/* If the buf isn't in core skip it */
if|if
condition|(
operator|(
name|bpa
operator|=
name|gbincore
argument_list|(
operator|&
name|vp
operator|->
name|v_bufobj
argument_list|,
name|lblkno
argument_list|)
operator|)
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* If the buf is busy we don't want to wait for it */
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bpa
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|NULL
argument_list|)
operator|!=
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* Only cluster with valid clusterable delayed write buffers */
if|if
condition|(
operator|(
name|bpa
operator|->
name|b_flags
operator|&
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator||
name|B_INVAL
operator|)
operator|)
operator|!=
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator|)
condition|)
goto|goto
name|done
goto|;
if|if
condition|(
name|bpa
operator|->
name|b_bufsize
operator|!=
name|size
condition|)
goto|goto
name|done
goto|;
comment|/* 	 * Check to see if it is in the expected place on disk and that the 	 * block has been mapped. 	 */
if|if
condition|(
operator|(
name|bpa
operator|->
name|b_blkno
operator|!=
name|bpa
operator|->
name|b_lblkno
operator|)
operator|&&
operator|(
name|bpa
operator|->
name|b_blkno
operator|==
name|blkno
operator|)
condition|)
name|match
operator|=
literal|1
expr_stmt|;
name|done
label|:
name|BUF_UNLOCK
argument_list|(
name|bpa
argument_list|)
expr_stmt|;
return|return
operator|(
name|match
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_awrite:  *  *	Implement clustered async writes for clearing out B_DELWRI buffers.  *	This is much better then the old way of writing only one buffer at  *	a time.  Note that we may not be presented with the buffers in the   *	correct order, so we search for the cluster in both directions.  */
end_comment

begin_function
name|int
name|vfs_bio_awrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|bufobj
modifier|*
name|bo
decl_stmt|;
name|int
name|i
decl_stmt|;
name|int
name|j
decl_stmt|;
name|daddr_t
name|lblkno
init|=
name|bp
operator|->
name|b_lblkno
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
init|=
name|bp
operator|->
name|b_vp
decl_stmt|;
name|int
name|ncl
decl_stmt|;
name|int
name|nwritten
decl_stmt|;
name|int
name|size
decl_stmt|;
name|int
name|maxcl
decl_stmt|;
name|int
name|gbflags
decl_stmt|;
name|bo
operator|=
operator|&
name|vp
operator|->
name|v_bufobj
expr_stmt|;
name|gbflags
operator|=
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|!=
literal|0
condition|?
name|GB_UNMAPPED
else|:
literal|0
expr_stmt|;
comment|/* 	 * right now we support clustered writing only to regular files.  If 	 * we find a clusterable block we could be in the middle of a cluster 	 * rather then at the beginning. 	 */
if|if
condition|(
operator|(
name|vp
operator|->
name|v_type
operator|==
name|VREG
operator|)
operator|&&
operator|(
name|vp
operator|->
name|v_mount
operator|!=
literal|0
operator|)
operator|&&
comment|/* Only on nodes that have the size info */
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTEROK
operator||
name|B_INVAL
operator|)
operator|)
operator|==
name|B_CLUSTEROK
condition|)
block|{
name|size
operator|=
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
name|maxcl
operator|=
name|MAXPHYS
operator|/
name|size
expr_stmt|;
name|BO_RLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|maxcl
condition|;
name|i
operator|++
control|)
if|if
condition|(
name|vfs_bio_clcheck
argument_list|(
name|vp
argument_list|,
name|size
argument_list|,
name|lblkno
operator|+
name|i
argument_list|,
name|bp
operator|->
name|b_blkno
operator|+
operator|(
operator|(
name|i
operator|*
name|size
operator|)
operator|>>
name|DEV_BSHIFT
operator|)
argument_list|)
operator|==
literal|0
condition|)
break|break;
for|for
control|(
name|j
operator|=
literal|1
init|;
name|i
operator|+
name|j
operator|<=
name|maxcl
operator|&&
name|j
operator|<=
name|lblkno
condition|;
name|j
operator|++
control|)
if|if
condition|(
name|vfs_bio_clcheck
argument_list|(
name|vp
argument_list|,
name|size
argument_list|,
name|lblkno
operator|-
name|j
argument_list|,
name|bp
operator|->
name|b_blkno
operator|-
operator|(
operator|(
name|j
operator|*
name|size
operator|)
operator|>>
name|DEV_BSHIFT
operator|)
argument_list|)
operator|==
literal|0
condition|)
break|break;
name|BO_RUNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
operator|--
name|j
expr_stmt|;
name|ncl
operator|=
name|i
operator|+
name|j
expr_stmt|;
comment|/* 		 * this is a possible cluster write 		 */
if|if
condition|(
name|ncl
operator|!=
literal|1
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|nwritten
operator|=
name|cluster_wbuild
argument_list|(
name|vp
argument_list|,
name|size
argument_list|,
name|lblkno
operator|-
name|j
argument_list|,
name|ncl
argument_list|,
name|gbflags
argument_list|)
expr_stmt|;
return|return
operator|(
name|nwritten
operator|)
return|;
block|}
block|}
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
comment|/* 	 * default (old) behavior, writing out only one block 	 * 	 * XXX returns b_bufsize instead of b_bcount for nwritten? 	 */
name|nwritten
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
operator|(
name|void
operator|)
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|nwritten
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|setbufkva
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|int
name|maxsize
parameter_list|,
name|int
name|gbflags
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_UNMAPPED
operator||
name|B_KVAALLOC
operator|)
operator|)
operator|==
literal|0
operator|&&
name|bp
operator|->
name|b_kvasize
operator|==
literal|0
argument_list|,
operator|(
literal|"call bfreekva(%p)"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|gbflags
operator|&
name|GB_UNMAPPED
operator|)
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_kvabase
operator|=
operator|(
name|caddr_t
operator|)
name|addr
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|gbflags
operator|&
name|GB_KVAALLOC
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|gbflags
operator|&
name|GB_UNMAPPED
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"GB_KVAALLOC without GB_UNMAPPED"
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_kvaalloc
operator|=
operator|(
name|caddr_t
operator|)
name|addr
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_UNMAPPED
operator||
name|B_KVAALLOC
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|unmapped_bufspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_kvasize
operator|=
name|maxsize
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Allocate the buffer KVA and set b_kvasize. Also set b_kvabase if  * needed.  */
end_comment

begin_function
specifier|static
name|int
name|allocbufkva
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|maxsize
parameter_list|,
name|int
name|gbflags
parameter_list|)
block|{
name|vm_offset_t
name|addr
decl_stmt|;
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|addr
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|vmem_alloc
argument_list|(
name|buffer_arena
argument_list|,
name|maxsize
argument_list|,
name|M_BESTFIT
operator||
name|M_NOWAIT
argument_list|,
operator|&
name|addr
argument_list|)
condition|)
block|{
comment|/* 		 * Buffer map is too fragmented.  Request the caller 		 * to defragment the map. 		 */
name|atomic_add_int
argument_list|(
operator|&
name|bufdefragcnt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
name|setbufkva
argument_list|(
name|bp
argument_list|,
name|addr
argument_list|,
name|maxsize
argument_list|,
name|gbflags
argument_list|)
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|bufspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Ask the bufdaemon for help, or act as bufdaemon itself, when a  * locked vnode is supplied.  */
end_comment

begin_function
specifier|static
name|void
name|getnewbuf_bufd_help
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
name|gbflags
parameter_list|,
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|,
name|int
name|defrag
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|char
modifier|*
name|waitmsg
decl_stmt|;
name|int
name|error
decl_stmt|,
name|fl
decl_stmt|,
name|flags
decl_stmt|,
name|norunbuf
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|bqclean
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|defrag
condition|)
block|{
name|flags
operator|=
name|VFS_BIO_NEED_BUFSPACE
expr_stmt|;
name|waitmsg
operator|=
literal|"nbufkv"
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bufspace
operator|>=
name|hibufspace
condition|)
block|{
name|waitmsg
operator|=
literal|"nbufbs"
expr_stmt|;
name|flags
operator|=
name|VFS_BIO_NEED_BUFSPACE
expr_stmt|;
block|}
else|else
block|{
name|waitmsg
operator|=
literal|"newbuf"
expr_stmt|;
name|flags
operator|=
name|VFS_BIO_NEED_ANY
expr_stmt|;
block|}
name|atomic_set_int
argument_list|(
operator|&
name|needsbuffer
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bqclean
argument_list|)
expr_stmt|;
name|bd_speedup
argument_list|()
expr_stmt|;
comment|/* heeeelp */
if|if
condition|(
operator|(
name|gbflags
operator|&
name|GB_NOWAIT_BD
operator|)
operator|!=
literal|0
condition|)
return|return;
name|td
operator|=
name|curthread
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|needsbuffer
operator|&
name|flags
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|vp
operator|!=
name|NULL
operator|&&
name|vp
operator|->
name|v_type
operator|!=
name|VCHR
operator|&&
operator|(
name|td
operator|->
name|td_pflags
operator|&
name|TDP_BUFNEED
operator|)
operator|==
literal|0
condition|)
block|{
name|rw_wunlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
comment|/* 			 * getblk() is called with a vnode locked, and 			 * some majority of the dirty buffers may as 			 * well belong to the vnode.  Flushing the 			 * buffers there would make a progress that 			 * cannot be achieved by the buf_daemon, that 			 * cannot lock the vnode. 			 */
name|norunbuf
operator|=
operator|~
operator|(
name|TDP_BUFNEED
operator||
name|TDP_NORUNNINGBUF
operator|)
operator||
operator|(
name|td
operator|->
name|td_pflags
operator|&
name|TDP_NORUNNINGBUF
operator|)
expr_stmt|;
comment|/* 			 * Play bufdaemon.  The getnewbuf() function 			 * may be called while the thread owns lock 			 * for another dirty buffer for the same 			 * vnode, which makes it impossible to use 			 * VOP_FSYNC() there, due to the buffer lock 			 * recursion. 			 */
name|td
operator|->
name|td_pflags
operator||=
name|TDP_BUFNEED
operator||
name|TDP_NORUNNINGBUF
expr_stmt|;
name|fl
operator|=
name|buf_flush
argument_list|(
name|vp
argument_list|,
name|flushbufqtarget
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_pflags
operator|&=
name|norunbuf
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
if|if
condition|(
name|fl
operator|!=
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|(
name|needsbuffer
operator|&
name|flags
operator|)
operator|==
literal|0
condition|)
break|break;
block|}
name|error
operator|=
name|rw_sleep
argument_list|(
name|__DEVOLATILE
argument_list|(
name|void
operator|*
argument_list|,
operator|&
name|needsbuffer
argument_list|)
argument_list|,
operator|&
name|nblock
argument_list|,
operator|(
name|PRIBIO
operator|+
literal|4
operator|)
operator||
name|slpflag
argument_list|,
name|waitmsg
argument_list|,
name|slptimeo
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
break|break;
block|}
name|rw_wunlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|getnewbuf_reuse_bp
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|qindex
parameter_list|)
block|{
name|CTR6
argument_list|(
name|KTR_BUF
argument_list|,
literal|"getnewbuf(%p) vp %p flags %X kvasize %d bufsize %d "
literal|"queue %d (recycling)"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|,
name|qindex
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|bqclean
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Note: we no longer distinguish between VMIO and non-VMIO 	 * buffers. 	 */
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"delwri buffer %p found in queue %d"
operator|,
name|bp
operator|,
name|qindex
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|qindex
operator|==
name|QUEUE_CLEAN
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_ASYNC
expr_stmt|;
name|vfs_vmio_release
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_vp
operator|!=
name|NULL
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Get the rest of the buffer freed up.  b_kva* is still valid 	 * after this operation. 	 */
if|if
condition|(
name|bp
operator|->
name|b_rcred
operator|!=
name|NOCRED
condition|)
block|{
name|crfree
argument_list|(
name|bp
operator|->
name|b_rcred
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_rcred
operator|=
name|NOCRED
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_wcred
operator|!=
name|NOCRED
condition|)
block|{
name|crfree
argument_list|(
name|bp
operator|->
name|b_wcred
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_wcred
operator|=
name|NOCRED
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
condition|)
name|buf_deallocate
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
condition|)
name|panic
argument_list|(
literal|"losing buffer 3"
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_vp
operator|==
name|NULL
argument_list|,
operator|(
literal|"bp: %p still has vnode %p.  qindex: %d"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_vp
operator|,
name|qindex
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_xflags
operator|&
operator|(
name|BX_VNCLEAN
operator||
name|BX_VNDIRTY
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"bp: %p still on a buffer list. xflags %X"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_xflags
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
name|allocbuf
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
name|B_UNMAPPED
operator||
name|B_KVAALLOC
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_xflags
operator|=
literal|0
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INFREECNT
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"buf %p still counted as free?"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_vflags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_vp
operator|=
name|NULL
expr_stmt|;
name|bp
operator|->
name|b_blkno
operator|=
name|bp
operator|->
name|b_lblkno
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_offset
operator|=
name|NOOFFSET
expr_stmt|;
name|bp
operator|->
name|b_iodone
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_error
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_bcount
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_npages
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_dirtyoff
operator|=
name|bp
operator|->
name|b_dirtyend
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_bufobj
operator|=
name|NULL
expr_stmt|;
name|bp
operator|->
name|b_pin_count
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_fsprivate1
operator|=
name|NULL
expr_stmt|;
name|bp
operator|->
name|b_fsprivate2
operator|=
name|NULL
expr_stmt|;
name|bp
operator|->
name|b_fsprivate3
operator|=
name|NULL
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
expr_stmt|;
block|}
end_function

begin_decl_stmt
specifier|static
name|int
name|flushingbufs
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|struct
name|buf
modifier|*
name|getnewbuf_scan
parameter_list|(
name|int
name|maxsize
parameter_list|,
name|int
name|defrag
parameter_list|,
name|int
name|unmapped
parameter_list|,
name|int
name|metadata
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|,
modifier|*
name|nbp
decl_stmt|;
name|int
name|nqindex
decl_stmt|,
name|qindex
decl_stmt|,
name|pass
decl_stmt|;
name|KASSERT
argument_list|(
operator|!
name|unmapped
operator|||
operator|!
name|defrag
argument_list|,
operator|(
literal|"both unmapped and defrag"
operator|)
argument_list|)
expr_stmt|;
name|pass
operator|=
literal|1
expr_stmt|;
name|restart
label|:
name|atomic_add_int
argument_list|(
operator|&
name|getnewbufrestarts
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * Setup for scan.  If we do not have enough free buffers, 	 * we setup a degenerate case that immediately fails.  Note 	 * that if we are specially marked process, we are allowed to 	 * dip into our reserves. 	 * 	 * The scanning sequence is nominally: EMPTY->EMPTYKVA->CLEAN 	 * for the allocation of the mapped buffer.  For unmapped, the 	 * easiest is to start with EMPTY outright. 	 * 	 * We start with EMPTYKVA.  If the list is empty we backup to EMPTY. 	 * However, there are a number of cases (defragging, reusing, ...) 	 * where we cannot backup. 	 */
name|nbp
operator|=
name|NULL
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bqclean
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|defrag
operator|&&
name|unmapped
condition|)
block|{
name|nqindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTY
index|]
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|nbp
operator|==
name|NULL
condition|)
block|{
name|nqindex
operator|=
name|QUEUE_EMPTYKVA
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTYKVA
index|]
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If no EMPTYKVA buffers and we are either defragging or 	 * reusing, locate a CLEAN buffer to free or reuse.  If 	 * bufspace useage is low skip this step so we can allocate a 	 * new buffer. 	 */
if|if
condition|(
name|nbp
operator|==
name|NULL
operator|&&
operator|(
name|defrag
operator|||
name|bufspace
operator|>=
name|lobufspace
operator|)
condition|)
block|{
name|nqindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If we could not find or were not allowed to reuse a CLEAN 	 * buffer, check to see if it is ok to use an EMPTY buffer. 	 * We can only use an EMPTY buffer if allocating its KVA would 	 * not otherwise run us out of buffer space.  No KVA is needed 	 * for the unmapped allocation. 	 */
if|if
condition|(
name|nbp
operator|==
name|NULL
operator|&&
name|defrag
operator|==
literal|0
operator|&&
operator|(
name|bufspace
operator|+
name|maxsize
operator|<
name|hibufspace
operator|||
name|metadata
operator|)
condition|)
block|{
name|nqindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTY
index|]
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * All available buffers might be clean, retry ignoring the 	 * lobufspace as the last resort. 	 */
if|if
condition|(
name|nbp
operator|==
name|NULL
operator|&&
operator|!
name|TAILQ_EMPTY
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|)
condition|)
block|{
name|nqindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Run scan, possibly freeing data and/or kva mappings on the fly 	 * depending. 	 */
while|while
condition|(
operator|(
name|bp
operator|=
name|nbp
operator|)
operator|!=
name|NULL
condition|)
block|{
name|qindex
operator|=
name|nqindex
expr_stmt|;
comment|/* 		 * Calculate next bp (we can only use it if we do not 		 * block or do other fancy things). 		 */
if|if
condition|(
operator|(
name|nbp
operator|=
name|TAILQ_NEXT
argument_list|(
name|bp
argument_list|,
name|b_freelist
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
switch|switch
condition|(
name|qindex
condition|)
block|{
case|case
name|QUEUE_EMPTY
case|:
name|nqindex
operator|=
name|QUEUE_EMPTYKVA
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTYKVA
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|nbp
operator|!=
name|NULL
condition|)
break|break;
comment|/* FALLTHROUGH */
case|case
name|QUEUE_EMPTYKVA
case|:
name|nqindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|nbp
operator|!=
name|NULL
condition|)
break|break;
comment|/* FALLTHROUGH */
case|case
name|QUEUE_CLEAN
case|:
if|if
condition|(
name|metadata
operator|&&
name|pass
operator|==
literal|1
condition|)
block|{
name|pass
operator|=
literal|2
expr_stmt|;
name|nqindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTY
index|]
argument_list|)
expr_stmt|;
block|}
comment|/* 				 * nbp is NULL.  				 */
break|break;
block|}
block|}
comment|/* 		 * If we are defragging then we need a buffer with  		 * b_kvasize != 0.  XXX this situation should no longer 		 * occur, if defrag is non-zero the buffer's b_kvasize 		 * should also be non-zero at this point.  XXX 		 */
if|if
condition|(
name|defrag
operator|&&
name|bp
operator|->
name|b_kvasize
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"Warning: defrag empty buffer %p\n"
argument_list|,
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Start freeing the bp.  This is somewhat involved.  nbp 		 * remains valid only for QUEUE_EMPTY[KVA] bp's. 		 */
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|NULL
argument_list|)
operator|!=
literal|0
condition|)
continue|continue;
comment|/* 		 * BKGRDINPROG can only be set with the buf and bufobj 		 * locks both held.  We tolerate a race to clear it here. 		 */
if|if
condition|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Requeue the background write buffer with error. 		 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDERR
operator|)
operator|!=
literal|0
condition|)
block|{
name|bremfreel
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bqclean
argument_list|)
expr_stmt|;
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|==
name|qindex
argument_list|,
operator|(
literal|"getnewbuf: inconsistent queue %d bp %p"
operator|,
name|qindex
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|bremfreel
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bqclean
argument_list|)
expr_stmt|;
comment|/* 		 * NOTE:  nbp is now entirely invalid.  We can only restart 		 * the scan from this point on. 		 */
name|getnewbuf_reuse_bp
argument_list|(
name|bp
argument_list|,
name|qindex
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|bqclean
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
comment|/* 		 * If we are defragging then free the buffer. 		 */
if|if
condition|(
name|defrag
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|defrag
operator|=
literal|0
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
comment|/* 		 * Notify any waiters for the buffer lock about 		 * identity change by freeing the buffer. 		 */
if|if
condition|(
name|qindex
operator|==
name|QUEUE_CLEAN
operator|&&
name|BUF_LOCKWAITERS
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
if|if
condition|(
name|metadata
condition|)
break|break;
comment|/* 		 * If we are overcomitted then recover the buffer and its 		 * KVM space.  This occurs in rare situations when multiple 		 * processes are blocked in getnewbuf() or allocbuf(). 		 */
if|if
condition|(
name|bufspace
operator|>=
name|hibufspace
condition|)
name|flushingbufs
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|flushingbufs
operator|&&
name|bp
operator|->
name|b_kvasize
operator|!=
literal|0
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
if|if
condition|(
name|bufspace
operator|<
name|lobufspace
condition|)
name|flushingbufs
operator|=
literal|0
expr_stmt|;
break|break;
block|}
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	getnewbuf:  *  *	Find and initialize a new buffer header, freeing up existing buffers  *	in the bufqueues as necessary.  The new buffer is returned locked.  *  *	Important:  B_INVAL is not set.  If the caller wishes to throw the  *	buffer away, the caller must set B_INVAL prior to calling brelse().  *  *	We block if:  *		We have insufficient buffer headers  *		We have insufficient buffer space  *		buffer_arena is too fragmented ( space reservation fails )  *		If we have to flush dirty buffers ( but we try to avoid this )  */
end_comment

begin_function
specifier|static
name|struct
name|buf
modifier|*
name|getnewbuf
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|,
name|int
name|size
parameter_list|,
name|int
name|maxsize
parameter_list|,
name|int
name|gbflags
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|defrag
decl_stmt|,
name|metadata
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|gbflags
operator|&
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
operator|)
operator|!=
name|GB_KVAALLOC
argument_list|,
operator|(
literal|"GB_KVAALLOC only makes sense with GB_UNMAPPED"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|unmapped_buf_allowed
condition|)
name|gbflags
operator|&=
operator|~
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
expr_stmt|;
name|defrag
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|vp
operator|==
name|NULL
operator|||
operator|(
name|vp
operator|->
name|v_vflag
operator|&
operator|(
name|VV_MD
operator||
name|VV_SYSTEM
operator|)
operator|)
operator|!=
literal|0
operator|||
name|vp
operator|->
name|v_type
operator|==
name|VCHR
condition|)
name|metadata
operator|=
literal|1
expr_stmt|;
else|else
name|metadata
operator|=
literal|0
expr_stmt|;
comment|/* 	 * We can't afford to block since we might be holding a vnode lock, 	 * which may prevent system daemons from running.  We deal with 	 * low-memory situations by proactively returning memory and running 	 * async I/O rather then sync I/O. 	 */
name|atomic_add_int
argument_list|(
operator|&
name|getnewbufcalls
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|getnewbufrestarts
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|restart
label|:
name|bp
operator|=
name|getnewbuf_scan
argument_list|(
name|maxsize
argument_list|,
name|defrag
argument_list|,
operator|(
name|gbflags
operator|&
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
operator|)
operator|==
name|GB_UNMAPPED
argument_list|,
name|metadata
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|!=
name|NULL
condition|)
name|defrag
operator|=
literal|0
expr_stmt|;
comment|/* 	 * If we exhausted our list, sleep as appropriate.  We may have to 	 * wakeup various daemons and write out some dirty buffers. 	 * 	 * Generally we are sleeping due to insufficient buffer space. 	 */
if|if
condition|(
name|bp
operator|==
name|NULL
condition|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|bqclean
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|getnewbuf_bufd_help
argument_list|(
name|vp
argument_list|,
name|gbflags
argument_list|,
name|slpflag
argument_list|,
name|slptimeo
argument_list|,
name|defrag
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|bqclean
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|gbflags
operator|&
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
operator|)
operator|==
name|GB_UNMAPPED
condition|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|bqclean
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_UNMAPPED
expr_stmt|;
name|bp
operator|->
name|b_kvabase
operator|=
name|bp
operator|->
name|b_data
operator|=
name|unmapped_buf
expr_stmt|;
name|bp
operator|->
name|b_kvasize
operator|=
name|maxsize
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|bufspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|unmapped_bufspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|bufreusecnt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_assert
argument_list|(
operator|&
name|bqclean
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
comment|/* 		 * We finally have a valid bp.  We aren't quite out of the 		 * woods, we still have to reserve kva space.  In order 		 * to keep fragmentation sane we only allocate kva in 		 * BKVASIZE chunks. 		 */
name|maxsize
operator|=
operator|(
name|maxsize
operator|+
name|BKVAMASK
operator|)
operator|&
operator|~
name|BKVAMASK
expr_stmt|;
if|if
condition|(
name|maxsize
operator|!=
name|bp
operator|->
name|b_kvasize
operator|||
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_UNMAPPED
operator||
name|B_KVAALLOC
operator|)
operator|)
operator|==
name|B_UNMAPPED
condition|)
block|{
if|if
condition|(
name|allocbufkva
argument_list|(
name|bp
argument_list|,
name|maxsize
argument_list|,
name|gbflags
argument_list|)
condition|)
block|{
name|defrag
operator|=
literal|1
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
name|atomic_add_int
argument_list|(
operator|&
name|bufreusecnt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_KVAALLOC
operator|)
operator|!=
literal|0
operator|&&
operator|(
name|gbflags
operator|&
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 			 * If the reused buffer has KVA allocated, 			 * reassign b_kvaalloc to b_kvabase. 			 */
name|bp
operator|->
name|b_kvabase
operator|=
name|bp
operator|->
name|b_kvaalloc
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_KVAALLOC
expr_stmt|;
name|atomic_subtract_long
argument_list|(
operator|&
name|unmapped_bufspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|bufreusecnt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_UNMAPPED
operator||
name|B_KVAALLOC
operator|)
operator|)
operator|==
literal|0
operator|&&
operator|(
name|gbflags
operator|&
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
operator|)
operator|==
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
condition|)
block|{
comment|/* 			 * The case of reused buffer already have KVA 			 * mapped, but the request is for unmapped 			 * buffer with KVA allocated. 			 */
name|bp
operator|->
name|b_kvaalloc
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
operator|=
name|unmapped_buf
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_UNMAPPED
operator||
name|B_KVAALLOC
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|unmapped_bufspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|bufreusecnt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|gbflags
operator|&
name|GB_UNMAPPED
operator|)
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_saveaddr
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_saveaddr
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_UNMAPPED
expr_stmt|;
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	buf_daemon:  *  *	buffer flushing daemon.  Buffers are normally flushed by the  *	update daemon but if it cannot keep up this process starts to  *	take the load in an attempt to prevent getnewbuf() from blocking.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|kproc_desc
name|buf_kp
init|=
block|{
literal|"bufdaemon"
block|,
name|buf_daemon
block|,
operator|&
name|bufdaemonproc
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSINIT
argument_list|(
name|bufdaemon
argument_list|,
name|SI_SUB_KTHREAD_BUF
argument_list|,
name|SI_ORDER_FIRST
argument_list|,
name|kproc_start
argument_list|,
operator|&
name|buf_kp
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|buf_flush
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
name|target
parameter_list|)
block|{
name|int
name|flushed
decl_stmt|;
name|flushed
operator|=
name|flushbufqueues
argument_list|(
name|vp
argument_list|,
name|target
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|flushed
operator|==
literal|0
condition|)
block|{
comment|/* 		 * Could not find any buffers without rollback 		 * dependencies, so just write the first one 		 * in the hopes of eventually making progress. 		 */
if|if
condition|(
name|vp
operator|!=
name|NULL
operator|&&
name|target
operator|>
literal|2
condition|)
name|target
operator|/=
literal|2
expr_stmt|;
name|flushbufqueues
argument_list|(
name|vp
argument_list|,
name|target
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|flushed
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|buf_daemon
parameter_list|()
block|{
name|int
name|lodirty
decl_stmt|;
comment|/* 	 * This process needs to be suspended prior to shutdown sync. 	 */
name|EVENTHANDLER_REGISTER
argument_list|(
name|shutdown_pre_sync
argument_list|,
name|kproc_shutdown
argument_list|,
name|bufdaemonproc
argument_list|,
name|SHUTDOWN_PRI_LAST
argument_list|)
expr_stmt|;
comment|/* 	 * This process is allowed to take the buffer cache to the limit 	 */
name|curthread
operator|->
name|td_pflags
operator||=
name|TDP_NORUNNINGBUF
operator||
name|TDP_BUFNEED
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|bd_request
operator|=
literal|0
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
name|kproc_suspend_check
argument_list|(
name|bufdaemonproc
argument_list|)
expr_stmt|;
name|lodirty
operator|=
name|lodirtybuffers
expr_stmt|;
if|if
condition|(
name|bd_speedupreq
condition|)
block|{
name|lodirty
operator|=
name|numdirtybuffers
operator|/
literal|2
expr_stmt|;
name|bd_speedupreq
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 		 * Do the flush.  Limit the amount of in-transit I/O we 		 * allow to build up, otherwise we would completely saturate 		 * the I/O system. 		 */
while|while
condition|(
name|numdirtybuffers
operator|>
name|lodirty
condition|)
block|{
if|if
condition|(
name|buf_flush
argument_list|(
name|NULL
argument_list|,
name|numdirtybuffers
operator|-
name|lodirty
argument_list|)
operator|==
literal|0
condition|)
break|break;
name|kern_yield
argument_list|(
name|PRI_USER
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Only clear bd_request if we have reached our low water 		 * mark.  The buf_daemon normally waits 1 second and 		 * then incrementally flushes any dirty buffers that have 		 * built up, within reason. 		 * 		 * If we were unable to hit our low water mark and couldn't 		 * find any flushable buffers, we sleep for a short period 		 * to avoid endless loops on unlockable buffers. 		 */
name|mtx_lock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|numdirtybuffers
operator|<=
name|lodirtybuffers
condition|)
block|{
comment|/* 			 * We reached our low water mark, reset the 			 * request and sleep until we are needed again. 			 * The sleep is just so the suspend code works. 			 */
name|bd_request
operator|=
literal|0
expr_stmt|;
comment|/* 			 * Do an extra wakeup in case dirty threshold 			 * changed via sysctl and the explicit transition 			 * out of shortfall was missed. 			 */
name|bdirtywakeup
argument_list|()
expr_stmt|;
if|if
condition|(
name|runningbufspace
operator|<=
name|lorunningspace
condition|)
name|runningwakeup
argument_list|()
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|bd_request
argument_list|,
operator|&
name|bdlock
argument_list|,
name|PVM
argument_list|,
literal|"psleep"
argument_list|,
name|hz
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * We couldn't find any flushable dirty buffers but 			 * still have too many dirty buffers, we 			 * have to sleep and try again.  (rare) 			 */
name|msleep
argument_list|(
operator|&
name|bd_request
argument_list|,
operator|&
name|bdlock
argument_list|,
name|PVM
argument_list|,
literal|"qsleep"
argument_list|,
name|hz
operator|/
literal|10
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	flushbufqueues:  *  *	Try to flush a buffer in the dirty queue.  We must be careful to  *	free up B_INVAL buffers instead of write them, which NFS is   *	particularly sensitive to.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|flushwithdeps
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|flushwithdeps
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|flushwithdeps
argument_list|,
literal|0
argument_list|,
literal|"Number of buffers flushed with dependecies that require rollbacks"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|flushbufqueues
parameter_list|(
name|struct
name|vnode
modifier|*
name|lvp
parameter_list|,
name|int
name|target
parameter_list|,
name|int
name|flushdeps
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|sentinel
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|struct
name|mount
modifier|*
name|mp
decl_stmt|;
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|hasdeps
decl_stmt|;
name|int
name|flushed
decl_stmt|;
name|int
name|queue
decl_stmt|;
name|int
name|error
decl_stmt|;
name|bool
name|unlock
decl_stmt|;
name|flushed
operator|=
literal|0
expr_stmt|;
name|queue
operator|=
name|QUEUE_DIRTY
expr_stmt|;
name|bp
operator|=
name|NULL
expr_stmt|;
name|sentinel
operator|=
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|buf
argument_list|)
argument_list|,
name|M_TEMP
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
name|sentinel
operator|->
name|b_qindex
operator|=
name|QUEUE_SENTINEL
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bqdirty
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|queue
index|]
argument_list|,
name|sentinel
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bqdirty
argument_list|)
expr_stmt|;
while|while
condition|(
name|flushed
operator|!=
name|target
condition|)
block|{
name|maybe_yield
argument_list|()
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bqdirty
argument_list|)
expr_stmt|;
name|bp
operator|=
name|TAILQ_NEXT
argument_list|(
name|sentinel
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|!=
name|NULL
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|bufqueues
index|[
name|queue
index|]
argument_list|,
name|sentinel
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|bufqueues
index|[
name|queue
index|]
argument_list|,
name|bp
argument_list|,
name|sentinel
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_unlock
argument_list|(
operator|&
name|bqdirty
argument_list|)
expr_stmt|;
break|break;
block|}
comment|/* 		 * Skip sentinels inserted by other invocations of the 		 * flushbufqueues(), taking care to not reorder them. 		 * 		 * Only flush the buffers that belong to the 		 * vnode locked by the curthread. 		 */
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_SENTINEL
operator|||
operator|(
name|lvp
operator|!=
name|NULL
operator|&&
name|bp
operator|->
name|b_vp
operator|!=
name|lvp
operator|)
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|bqdirty
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|error
operator|=
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bqdirty
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
continue|continue;
if|if
condition|(
name|bp
operator|->
name|b_pin_count
operator|>
literal|0
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * BKGRDINPROG can only be set with the buf and bufobj 		 * locks both held.  We tolerate a race to clear it here. 		 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
operator|)
operator|!=
literal|0
operator|||
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
name|bremfreef
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|flushed
operator|++
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|!
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|&&
name|buf_countdeps
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
condition|)
block|{
if|if
condition|(
name|flushdeps
operator|==
literal|0
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|hasdeps
operator|=
literal|1
expr_stmt|;
block|}
else|else
name|hasdeps
operator|=
literal|0
expr_stmt|;
comment|/* 		 * We must hold the lock on a vnode before writing 		 * one of its buffers. Otherwise we may confuse, or 		 * in the case of a snapshot vnode, deadlock the 		 * system. 		 * 		 * The lock order here is the reverse of the normal 		 * of vnode followed by buf lock.  This is ok because 		 * the NOWAIT will prevent deadlock. 		 */
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
if|if
condition|(
name|vn_start_write
argument_list|(
name|vp
argument_list|,
operator|&
name|mp
argument_list|,
name|V_NOWAIT
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|lvp
operator|==
name|NULL
condition|)
block|{
name|unlock
operator|=
name|true
expr_stmt|;
name|error
operator|=
name|vn_lock
argument_list|(
name|vp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT_VOP_LOCKED
argument_list|(
name|vp
argument_list|,
literal|"getbuf"
argument_list|)
expr_stmt|;
name|unlock
operator|=
name|false
expr_stmt|;
name|error
operator|=
name|VOP_ISLOCKED
argument_list|(
name|vp
argument_list|)
operator|==
name|LK_EXCLUSIVE
condition|?
literal|0
else|:
name|vn_lock
argument_list|(
name|vp
argument_list|,
name|LK_TRYUPGRADE
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|error
operator|==
literal|0
condition|)
block|{
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"flushbufqueue(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|curproc
operator|==
name|bufdaemonproc
condition|)
block|{
name|vfs_bio_awrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|notbufdflushes
operator|++
expr_stmt|;
block|}
name|vn_finished_write
argument_list|(
name|mp
argument_list|)
expr_stmt|;
if|if
condition|(
name|unlock
condition|)
name|VOP_UNLOCK
argument_list|(
name|vp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|flushwithdeps
operator|+=
name|hasdeps
expr_stmt|;
name|flushed
operator|++
expr_stmt|;
comment|/* 			 * Sleeping on runningbufspace while holding 			 * vnode lock leads to deadlock. 			 */
if|if
condition|(
name|curproc
operator|==
name|bufdaemonproc
operator|&&
name|runningbufspace
operator|>
name|hirunningspace
condition|)
name|waitrunningbufspace
argument_list|()
expr_stmt|;
continue|continue;
block|}
name|vn_finished_write
argument_list|(
name|mp
argument_list|)
expr_stmt|;
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|mtx_lock
argument_list|(
operator|&
name|bqdirty
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|bufqueues
index|[
name|queue
index|]
argument_list|,
name|sentinel
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bqdirty
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|sentinel
argument_list|,
name|M_TEMP
argument_list|)
expr_stmt|;
return|return
operator|(
name|flushed
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Check to see if a block is currently memory resident.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|incore
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|BO_RLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|bp
operator|=
name|gbincore
argument_list|(
name|bo
argument_list|,
name|blkno
argument_list|)
expr_stmt|;
name|BO_RUNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns true if no I/O is needed to access the  * associated VM object.  This is like incore except  * it also hunts around in the VM system for the data.  */
end_comment

begin_function
specifier|static
name|int
name|inmem
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_offset_t
name|toff
decl_stmt|,
name|tinc
decl_stmt|,
name|size
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_ooffset_t
name|off
decl_stmt|;
name|ASSERT_VOP_LOCKED
argument_list|(
name|vp
argument_list|,
literal|"inmem"
argument_list|)
expr_stmt|;
if|if
condition|(
name|incore
argument_list|(
operator|&
name|vp
operator|->
name|v_bufobj
argument_list|,
name|blkno
argument_list|)
condition|)
return|return
literal|1
return|;
if|if
condition|(
name|vp
operator|->
name|v_mount
operator|==
name|NULL
condition|)
return|return
literal|0
return|;
name|obj
operator|=
name|vp
operator|->
name|v_object
expr_stmt|;
if|if
condition|(
name|obj
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|size
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
name|size
operator|>
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
condition|)
name|size
operator|=
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
name|off
operator|=
operator|(
name|vm_ooffset_t
operator|)
name|blkno
operator|*
operator|(
name|vm_ooffset_t
operator|)
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
name|VM_OBJECT_RLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
for|for
control|(
name|toff
operator|=
literal|0
init|;
name|toff
operator|<
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
condition|;
name|toff
operator|+=
name|tinc
control|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|off
operator|+
name|toff
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|m
condition|)
goto|goto
name|notinmem
goto|;
name|tinc
operator|=
name|size
expr_stmt|;
if|if
condition|(
name|tinc
operator|>
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
operator|)
condition|)
name|tinc
operator|=
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
if|if
condition|(
name|vm_page_is_valid
argument_list|(
name|m
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
argument_list|)
argument_list|,
name|tinc
argument_list|)
operator|==
literal|0
condition|)
goto|goto
name|notinmem
goto|;
block|}
name|VM_OBJECT_RUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
name|notinmem
label|:
name|VM_OBJECT_RUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Set the dirty range for a buffer based on the status of the dirty  * bits in the pages comprising the buffer.  The range is limited  * to the size of the buffer.  *  * Tell the VM system that the pages associated with this buffer  * are clean.  This is used for delayed writes where the data is  * going to go to disk eventually without additional VM intevention.  *  * Note that while we only really need to clean through to b_bcount, we  * just go ahead and clean through to b_bufsize.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_clean_pages_dirty_buf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|vm_ooffset_t
name|foff
decl_stmt|,
name|noff
decl_stmt|,
name|eoff
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
operator|||
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
return|return;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"vfs_clean_pages_dirty_buf: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
name|vfs_drain_busy_pages
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|vfs_setdirty_locked_object
argument_list|(
name|bp
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|noff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
name|eoff
operator|=
name|noff
expr_stmt|;
if|if
condition|(
name|eoff
operator|>
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bufsize
condition|)
name|eoff
operator|=
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|vfs_page_set_validclean
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|m
argument_list|)
expr_stmt|;
comment|/* vm_page_clear_dirty(m, foff& PAGE_MASK, eoff - foff); */
name|foff
operator|=
name|noff
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vfs_setdirty_locked_object
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|int
name|i
decl_stmt|;
name|object
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 	 * We qualify the scan for modified pages on whether the 	 * object has been flushed yet. 	 */
if|if
condition|(
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_MIGHTBEDIRTY
operator|)
operator|!=
literal|0
condition|)
block|{
name|vm_offset_t
name|boffset
decl_stmt|;
name|vm_offset_t
name|eoffset
decl_stmt|;
comment|/* 		 * test the pages to see if they have been modified directly 		 * by users through the VM system. 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
name|vm_page_test_dirty
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|)
expr_stmt|;
comment|/* 		 * Calculate the encompassing dirty range, boffset and eoffset, 		 * (eoffset - boffset) bytes. 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|dirty
condition|)
break|break;
block|}
name|boffset
operator|=
operator|(
name|i
operator|<<
name|PAGE_SHIFT
operator|)
operator|-
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|bp
operator|->
name|b_npages
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
operator|--
name|i
control|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|dirty
condition|)
block|{
break|break;
block|}
block|}
name|eoffset
operator|=
operator|(
operator|(
name|i
operator|+
literal|1
operator|)
operator|<<
name|PAGE_SHIFT
operator|)
operator|-
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
comment|/* 		 * Fit it to the buffer. 		 */
if|if
condition|(
name|eoffset
operator|>
name|bp
operator|->
name|b_bcount
condition|)
name|eoffset
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* 		 * If we have a good dirty range, merge with the existing 		 * dirty range. 		 */
if|if
condition|(
name|boffset
operator|<
name|eoffset
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_dirtyoff
operator|>
name|boffset
condition|)
name|bp
operator|->
name|b_dirtyoff
operator|=
name|boffset
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_dirtyend
operator|<
name|eoffset
condition|)
name|bp
operator|->
name|b_dirtyend
operator|=
name|eoffset
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * Allocate the KVA mapping for an existing buffer. It handles the  * cases of both B_UNMAPPED buffer, and buffer with the preallocated  * KVA which is not mapped (B_KVAALLOC).  */
end_comment

begin_function
specifier|static
name|void
name|bp_unmapped_get_kva
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|int
name|gbflags
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|scratch_bp
decl_stmt|;
name|int
name|bsize
decl_stmt|,
name|maxsize
decl_stmt|,
name|need_mapping
decl_stmt|,
name|need_kva
decl_stmt|;
name|off_t
name|offset
decl_stmt|;
name|need_mapping
operator|=
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|!=
literal|0
operator|&&
operator|(
name|gbflags
operator|&
name|GB_UNMAPPED
operator|)
operator|==
literal|0
expr_stmt|;
name|need_kva
operator|=
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_KVAALLOC
operator||
name|B_UNMAPPED
operator|)
operator|)
operator|==
name|B_UNMAPPED
operator|&&
operator|(
name|gbflags
operator|&
name|GB_KVAALLOC
operator|)
operator|!=
literal|0
expr_stmt|;
if|if
condition|(
operator|!
name|need_mapping
operator|&&
operator|!
name|need_kva
condition|)
return|return;
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|need_mapping
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_KVAALLOC
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * Buffer is not mapped, but the KVA was already 		 * reserved at the time of the instantiation.  Use the 		 * allocated space. 		 */
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_KVAALLOC
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_kvaalloc
operator|!=
literal|0
argument_list|,
operator|(
literal|"kvaalloc == 0"
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_kvabase
operator|=
name|bp
operator|->
name|b_kvaalloc
expr_stmt|;
name|atomic_subtract_long
argument_list|(
operator|&
name|unmapped_bufspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
goto|goto
name|has_addr
goto|;
block|}
comment|/* 	 * Calculate the amount of the address space we would reserve 	 * if the buffer was mapped. 	 */
name|bsize
operator|=
name|vn_isdisk
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|NULL
argument_list|)
condition|?
name|DEV_BSIZE
else|:
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_bsize
expr_stmt|;
name|KASSERT
argument_list|(
name|bsize
operator|!=
literal|0
argument_list|,
operator|(
literal|"bsize == 0, check bo->bo_bsize"
operator|)
argument_list|)
expr_stmt|;
name|offset
operator|=
name|blkno
operator|*
name|bsize
expr_stmt|;
name|maxsize
operator|=
name|size
operator|+
operator|(
name|offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|maxsize
operator|=
name|imax
argument_list|(
name|maxsize
argument_list|,
name|bsize
argument_list|)
expr_stmt|;
name|mapping_loop
label|:
if|if
condition|(
name|allocbufkva
argument_list|(
name|bp
argument_list|,
name|maxsize
argument_list|,
name|gbflags
argument_list|)
condition|)
block|{
comment|/* 		 * Request defragmentation. getnewbuf() returns us the 		 * allocated space by the scratch buffer KVA. 		 */
name|scratch_bp
operator|=
name|getnewbuf
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|size
argument_list|,
name|maxsize
argument_list|,
name|gbflags
operator||
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|scratch_bp
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|gbflags
operator|&
name|GB_NOWAIT_BD
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 				 * XXXKIB: defragmentation cannot 				 * succeed, not sure what else to do. 				 */
name|panic
argument_list|(
literal|"GB_NOWAIT_BD and B_UNMAPPED %p"
argument_list|,
name|bp
argument_list|)
expr_stmt|;
block|}
name|atomic_add_int
argument_list|(
operator|&
name|mappingrestarts
argument_list|,
literal|1
argument_list|)
expr_stmt|;
goto|goto
name|mapping_loop
goto|;
block|}
name|KASSERT
argument_list|(
operator|(
name|scratch_bp
operator|->
name|b_flags
operator|&
name|B_KVAALLOC
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"scratch bp !B_KVAALLOC %p"
operator|,
name|scratch_bp
operator|)
argument_list|)
expr_stmt|;
name|setbufkva
argument_list|(
name|bp
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|scratch_bp
operator|->
name|b_kvaalloc
argument_list|,
name|scratch_bp
operator|->
name|b_kvasize
argument_list|,
name|gbflags
argument_list|)
expr_stmt|;
comment|/* Get rid of the scratch buffer. */
name|scratch_bp
operator|->
name|b_kvasize
operator|=
literal|0
expr_stmt|;
name|scratch_bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|scratch_bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_UNMAPPED
operator||
name|B_KVAALLOC
operator|)
expr_stmt|;
name|brelse
argument_list|(
name|scratch_bp
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|need_mapping
condition|)
return|return;
name|has_addr
label|:
name|bp
operator|->
name|b_saveaddr
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_saveaddr
expr_stmt|;
comment|/* b_offset is handled by bpmap_qenter */
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_UNMAPPED
expr_stmt|;
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bpmap_qenter
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	getblk:  *  *	Get a block given a specified block and offset into a file/device.  *	The buffers B_DONE bit will be cleared on return, making it almost  * 	ready for an I/O initiation.  B_INVAL may or may not be set on   *	return.  The caller should clear B_INVAL prior to initiating a  *	READ.  *  *	For a non-VMIO buffer, B_CACHE is set to the opposite of B_INVAL for  *	an existing buffer.  *  *	For a VMIO buffer, B_CACHE is modified according to the backing VM.  *	If getblk()ing a previously 0-sized invalid buffer, B_CACHE is set  *	and then cleared based on the backing VM.  If the previous buffer is  *	non-0-sized but invalid, B_CACHE will be cleared.  *  *	If getblk() must create a new buffer, the new buffer is returned with  *	both B_INVAL and B_CACHE clear unless it is a VMIO buffer, in which  *	case it is returned with B_INVAL clear and B_CACHE set based on the  *	backing VM.  *  *	getblk() also forces a bwrite() for any B_DELWRI buffer whos  *	B_CACHE bit is clear.  *	  *	What this means, basically, is that the caller should use B_CACHE to  *	determine whether the buffer is fully valid or not and should clear  *	B_INVAL prior to issuing a read.  If the caller intends to validate  *	the buffer by loading its data area with something, the caller needs  *	to clear B_INVAL.  If the caller does this without issuing an I/O,   *	the caller should set B_CACHE ( as an optimization ), else the caller  *	should issue the I/O and biodone() will set B_CACHE if the I/O was  *	a write attempt or if it was a successfull read.  If the caller   *	intends to issue a READ, the caller must clear B_INVAL and BIO_ERROR  *	prior to issuing the READ.  biodone() will *not* clear B_INVAL.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|getblk
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|struct
name|bufobj
modifier|*
name|bo
decl_stmt|;
name|int
name|bsize
decl_stmt|,
name|error
decl_stmt|,
name|maxsize
decl_stmt|,
name|vmio
decl_stmt|;
name|off_t
name|offset
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"getblk(%p, %ld, %d)"
argument_list|,
name|vp
argument_list|,
operator|(
name|long
operator|)
name|blkno
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|flags
operator|&
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
operator|)
operator|!=
name|GB_KVAALLOC
argument_list|,
operator|(
literal|"GB_KVAALLOC only makes sense with GB_UNMAPPED"
operator|)
argument_list|)
expr_stmt|;
name|ASSERT_VOP_LOCKED
argument_list|(
name|vp
argument_list|,
literal|"getblk"
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|>
name|MAXBCACHEBUF
condition|)
name|panic
argument_list|(
literal|"getblk: size(%d)> MAXBCACHEBUF(%d)\n"
argument_list|,
name|size
argument_list|,
name|MAXBCACHEBUF
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|unmapped_buf_allowed
condition|)
name|flags
operator|&=
operator|~
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
expr_stmt|;
name|bo
operator|=
operator|&
name|vp
operator|->
name|v_bufobj
expr_stmt|;
name|loop
label|:
name|BO_RLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|bp
operator|=
name|gbincore
argument_list|(
name|bo
argument_list|,
name|blkno
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|!=
name|NULL
condition|)
block|{
name|int
name|lockflags
decl_stmt|;
comment|/* 		 * Buffer is in-core.  If the buffer is not busy nor managed, 		 * it must be on a queue. 		 */
name|lockflags
operator|=
name|LK_EXCLUSIVE
operator||
name|LK_SLEEPFAIL
operator||
name|LK_INTERLOCK
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|GB_LOCK_NOWAIT
condition|)
name|lockflags
operator||=
name|LK_NOWAIT
expr_stmt|;
name|error
operator|=
name|BUF_TIMELOCK
argument_list|(
name|bp
argument_list|,
name|lockflags
argument_list|,
name|BO_LOCKPTR
argument_list|(
name|bo
argument_list|)
argument_list|,
literal|"getblk"
argument_list|,
name|slpflag
argument_list|,
name|slptimeo
argument_list|)
expr_stmt|;
comment|/* 		 * If we slept and got the lock we have to restart in case 		 * the buffer changed identities. 		 */
if|if
condition|(
name|error
operator|==
name|ENOLCK
condition|)
goto|goto
name|loop
goto|;
comment|/* We timed out or were interrupted. */
elseif|else
if|if
condition|(
name|error
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
comment|/* If recursed, assume caller knows the rules. */
elseif|else
if|if
condition|(
name|BUF_LOCKRECURSED
argument_list|(
name|bp
argument_list|)
condition|)
goto|goto
name|end
goto|;
comment|/* 		 * The buffer is locked.  B_CACHE is cleared if the buffer is  		 * invalid.  Otherwise, for a non-VMIO buffer, B_CACHE is set 		 * and for a VMIO buffer B_CACHE is adjusted according to the 		 * backing VM cache. 		 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_VMIO
operator||
name|B_INVAL
operator|)
operator|)
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MANAGED
condition|)
name|MPASS
argument_list|(
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_NONE
argument_list|)
expr_stmt|;
else|else
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 		 * check for size inconsistencies for non-VMIO case. 		 */
if|if
condition|(
name|bp
operator|->
name|b_bcount
operator|!=
name|size
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
operator|||
operator|(
name|size
operator|>
name|bp
operator|->
name|b_kvasize
operator|)
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
comment|/* 					 * If buffer is pinned and caller does 					 * not want sleep  waiting for it to be 					 * unpinned, bail out 					 * */
if|if
condition|(
name|bp
operator|->
name|b_pin_count
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|flags
operator|&
name|GB_LOCK_NOWAIT
condition|)
block|{
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
else|else
block|{
name|bunpin_wait
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_RELBUF
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
goto|goto
name|loop
goto|;
block|}
block|}
comment|/* 		 * Handle the case of unmapped buffer which should 		 * become mapped, or the buffer for which KVA 		 * reservation is requested. 		 */
name|bp_unmapped_get_kva
argument_list|(
name|bp
argument_list|,
name|blkno
argument_list|,
name|size
argument_list|,
name|flags
argument_list|)
expr_stmt|;
comment|/* 		 * If the size is inconsistant in the VMIO case, we can resize 		 * the buffer.  This might lead to B_CACHE getting set or 		 * cleared.  If the size has not changed, B_CACHE remains 		 * unchanged from its previous state. 		 */
if|if
condition|(
name|bp
operator|->
name|b_bcount
operator|!=
name|size
condition|)
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"getblk: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * A buffer with B_DELWRI set and B_CACHE clear must 		 * be committed before we can return the buffer in 		 * order to prevent the caller from issuing a read 		 * ( due to B_CACHE not being set ) and overwriting 		 * it. 		 * 		 * Most callers, including NFS and FFS, need this to 		 * operate properly either because they assume they 		 * can issue a read if B_CACHE is not set, or because 		 * ( for example ) an uncached B_DELWRI might loop due  		 * to softupdates re-dirtying the buffer.  In the latter 		 * case, B_CACHE is set after the first write completes, 		 * preventing further loops. 		 * NOTE!  b*write() sets B_CACHE.  If we cleared B_CACHE 		 * above while extending the buffer, we cannot allow the 		 * buffer to remain with B_CACHE set after the write 		 * completes or it will represent a corrupt state.  To 		 * deal with this we set B_NOCACHE to scrap the buffer 		 * after the write. 		 * 		 * We might be able to do something fancy, like setting 		 * B_CACHE in bwrite() except if B_DELWRI is already set, 		 * so the below call doesn't set B_CACHE, but that gets real 		 * confusing.  This is much easier. 		 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CACHE
operator||
name|B_DELWRI
operator|)
operator|)
operator|==
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Buffer is not in-core, create new buffer.  The buffer 		 * returned by getnewbuf() is locked.  Note that the returned 		 * buffer is also considered valid (not marked B_INVAL). 		 */
name|BO_RUNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
comment|/* 		 * If the user does not want us to create the buffer, bail out 		 * here. 		 */
if|if
condition|(
name|flags
operator|&
name|GB_NOCREAT
condition|)
return|return
name|NULL
return|;
if|if
condition|(
name|numfreebuffers
operator|==
literal|0
operator|&&
name|TD_IS_IDLETHREAD
argument_list|(
name|curthread
argument_list|)
condition|)
return|return
name|NULL
return|;
name|bsize
operator|=
name|vn_isdisk
argument_list|(
name|vp
argument_list|,
name|NULL
argument_list|)
condition|?
name|DEV_BSIZE
else|:
name|bo
operator|->
name|bo_bsize
expr_stmt|;
name|KASSERT
argument_list|(
name|bsize
operator|!=
literal|0
argument_list|,
operator|(
literal|"bsize == 0, check bo->bo_bsize"
operator|)
argument_list|)
expr_stmt|;
name|offset
operator|=
name|blkno
operator|*
name|bsize
expr_stmt|;
name|vmio
operator|=
name|vp
operator|->
name|v_object
operator|!=
name|NULL
expr_stmt|;
if|if
condition|(
name|vmio
condition|)
block|{
name|maxsize
operator|=
name|size
operator|+
operator|(
name|offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
block|}
else|else
block|{
name|maxsize
operator|=
name|size
expr_stmt|;
comment|/* Do not allow non-VMIO notmapped buffers. */
name|flags
operator|&=
operator|~
name|GB_UNMAPPED
expr_stmt|;
block|}
name|maxsize
operator|=
name|imax
argument_list|(
name|maxsize
argument_list|,
name|bsize
argument_list|)
expr_stmt|;
name|bp
operator|=
name|getnewbuf
argument_list|(
name|vp
argument_list|,
name|slpflag
argument_list|,
name|slptimeo
argument_list|,
name|size
argument_list|,
name|maxsize
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|slpflag
operator|||
name|slptimeo
condition|)
return|return
name|NULL
return|;
goto|goto
name|loop
goto|;
block|}
comment|/* 		 * This code is used to make sure that a buffer is not 		 * created while the getnewbuf routine is blocked. 		 * This can be a problem whether the vnode is locked or not. 		 * If the buffer is created out from under us, we have to 		 * throw away the one we just created. 		 * 		 * Note: this must occur before we associate the buffer 		 * with the vp especially considering limitations in 		 * the splay tree implementation when dealing with duplicate 		 * lblkno's. 		 */
name|BO_LOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
if|if
condition|(
name|gbincore
argument_list|(
name|bo
argument_list|,
name|blkno
argument_list|)
condition|)
block|{
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
comment|/* 		 * Insert the buffer into the hash, so that it can 		 * be found by incore. 		 */
name|bp
operator|->
name|b_blkno
operator|=
name|bp
operator|->
name|b_lblkno
operator|=
name|blkno
expr_stmt|;
name|bp
operator|->
name|b_offset
operator|=
name|offset
expr_stmt|;
name|bgetvp
argument_list|(
name|vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
comment|/* 		 * set B_VMIO bit.  allocbuf() the buffer bigger.  Since the 		 * buffer size starts out as 0, B_CACHE will be set by 		 * allocbuf() for the VMIO case prior to it testing the 		 * backing store for validity. 		 */
if|if
condition|(
name|vmio
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_VMIO
expr_stmt|;
name|KASSERT
argument_list|(
name|vp
operator|->
name|v_object
operator|==
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|,
operator|(
literal|"ARGH! different b_bufobj->bo_object %p %p %p\n"
operator|,
name|bp
operator|,
name|vp
operator|->
name|v_object
operator|,
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_VMIO
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
operator|==
name|NULL
argument_list|,
operator|(
literal|"ARGH! has b_bufobj->bo_object %p %p\n"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
operator|)
argument_list|)
expr_stmt|;
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
block|}
name|CTR4
argument_list|(
name|KTR_BUF
argument_list|,
literal|"getblk(%p, %ld, %d) = %p"
argument_list|,
name|vp
argument_list|,
operator|(
name|long
operator|)
name|blkno
argument_list|,
name|size
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|end
label|:
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|==
name|bo
argument_list|,
operator|(
literal|"bp %p wrong b_bufobj %p should be %p"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_bufobj
operator|,
name|bo
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Get an empty, disassociated buffer of given size.  The buffer is initially  * set to B_INVAL.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|geteblk
parameter_list|(
name|int
name|size
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|maxsize
decl_stmt|;
name|maxsize
operator|=
operator|(
name|size
operator|+
name|BKVAMASK
operator|)
operator|&
operator|~
name|BKVAMASK
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|=
name|getnewbuf
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|size
argument_list|,
name|maxsize
argument_list|,
name|flags
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|flags
operator|&
name|GB_NOWAIT_BD
operator|)
operator|&&
operator|(
name|curthread
operator|->
name|td_pflags
operator|&
name|TDP_BUFNEED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
comment|/* b_dep cleared by getnewbuf() */
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This code constitutes the buffer memory from either anonymous system  * memory (in the case of non-VMIO operations) or from an associated  * VM object (in the case of VMIO operations).  This code is able to  * resize a buffer up or down.  *  * Note that this code is tricky, and has many complications to resolve  * deadlock or inconsistant data situations.  Tread lightly!!!   * There are B_CACHE and B_DELWRI interactions that must be dealt with by   * the caller.  Calling this code willy nilly can result in the loss of data.  *  * allocbuf() only adjusts B_CACHE for VMIO buffers.  getblk() deals with  * B_CACHE for the non-VMIO case.  */
end_comment

begin_function
name|int
name|allocbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|newbsize
decl_stmt|,
name|mbsize
decl_stmt|;
name|int
name|i
decl_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_kvasize
operator|<
name|size
condition|)
name|panic
argument_list|(
literal|"allocbuf: buffer too small"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
condition|)
block|{
name|caddr_t
name|origbuf
decl_stmt|;
name|int
name|origbufsize
decl_stmt|;
comment|/* 		 * Just get anonymous memory from the kernel.  Don't 		 * mess with B_CACHE. 		 */
name|mbsize
operator|=
operator|(
name|size
operator|+
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
name|newbsize
operator|=
name|mbsize
expr_stmt|;
else|else
name|newbsize
operator|=
name|round_page
argument_list|(
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
block|{
comment|/* 			 * malloced buffers are not shrunk 			 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
block|{
if|if
condition|(
name|newbsize
condition|)
block|{
name|bp
operator|->
name|b_bcount
operator|=
name|size
expr_stmt|;
block|}
else|else
block|{
name|free
argument_list|(
name|bp
operator|->
name|b_data
argument_list|,
name|M_BIOBUF
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
block|{
name|atomic_subtract_long
argument_list|(
operator|&
name|bufmallocspace
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
literal|0
expr_stmt|;
block|}
name|bp
operator|->
name|b_saveaddr
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_saveaddr
expr_stmt|;
name|bp
operator|->
name|b_bcount
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_MALLOC
expr_stmt|;
block|}
return|return
literal|1
return|;
block|}
name|vm_hold_free_pages
argument_list|(
name|bp
argument_list|,
name|newbsize
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|newbsize
operator|>
name|bp
operator|->
name|b_bufsize
condition|)
block|{
comment|/* 			 * We only use malloced memory on the first allocation. 			 * and revert to page-allocated memory when the buffer 			 * grows. 			 */
comment|/* 			 * There is a potential smp race here that could lead 			 * to bufmallocspace slightly passing the max.  It 			 * is probably extremely rare and not worth worrying 			 * over. 			 */
if|if
condition|(
operator|(
name|bufmallocspace
operator|<
name|maxbufmallocspace
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
operator|)
operator|&&
operator|(
name|mbsize
operator|<=
name|PAGE_SIZE
operator|/
literal|2
operator|)
condition|)
block|{
name|bp
operator|->
name|b_data
operator|=
name|malloc
argument_list|(
name|mbsize
argument_list|,
name|M_BIOBUF
argument_list|,
name|M_WAITOK
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
name|mbsize
expr_stmt|;
name|bp
operator|->
name|b_bcount
operator|=
name|size
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_MALLOC
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|bufmallocspace
argument_list|,
name|mbsize
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
name|origbuf
operator|=
name|NULL
expr_stmt|;
name|origbufsize
operator|=
literal|0
expr_stmt|;
comment|/* 			 * If the buffer is growing on its other-than-first allocation, 			 * then we revert to the page-allocation scheme. 			 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
block|{
name|origbuf
operator|=
name|bp
operator|->
name|b_data
expr_stmt|;
name|origbufsize
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
block|{
name|atomic_subtract_long
argument_list|(
operator|&
name|bufmallocspace
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
literal|0
expr_stmt|;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_MALLOC
expr_stmt|;
name|newbsize
operator|=
name|round_page
argument_list|(
name|newbsize
argument_list|)
expr_stmt|;
block|}
name|vm_hold_load_pages
argument_list|(
name|bp
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|bp
operator|->
name|b_bufsize
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|newbsize
argument_list|)
expr_stmt|;
if|if
condition|(
name|origbuf
condition|)
block|{
name|bcopy
argument_list|(
name|origbuf
argument_list|,
name|bp
operator|->
name|b_data
argument_list|,
name|origbufsize
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|origbuf
argument_list|,
name|M_BIOBUF
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|int
name|desiredpages
decl_stmt|;
name|newbsize
operator|=
operator|(
name|size
operator|+
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
expr_stmt|;
name|desiredpages
operator|=
operator|(
name|size
operator|==
literal|0
operator|)
condition|?
literal|0
else|:
name|num_pages
argument_list|(
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|+
name|newbsize
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
name|panic
argument_list|(
literal|"allocbuf: VMIO buffer can't be malloced"
argument_list|)
expr_stmt|;
comment|/* 		 * Set B_CACHE initially if buffer is 0 length or will become 		 * 0-length. 		 */
if|if
condition|(
name|size
operator|==
literal|0
operator|||
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
block|{
comment|/* 			 * DEV_BSIZE aligned new buffer size is less then the 			 * DEV_BSIZE aligned existing buffer size.  Figure out 			 * if we have to remove any pages. 			 */
if|if
condition|(
name|desiredpages
operator|<
name|bp
operator|->
name|b_npages
condition|)
block|{
name|vm_page_t
name|m
decl_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|==
literal|0
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|+
operator|(
name|desiredpages
operator|<<
name|PAGE_SHIFT
operator|)
argument_list|,
operator|(
name|bp
operator|->
name|b_npages
operator|-
name|desiredpages
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|desiredpages
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
comment|/* 					 * the page is not freed here -- it 					 * is the responsibility of  					 * vnode_pager_setsize 					 */
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|!=
name|bogus_page
argument_list|,
operator|(
literal|"allocbuf: bogus page found"
operator|)
argument_list|)
expr_stmt|;
while|while
condition|(
name|vm_page_sleep_if_busy
argument_list|(
name|m
argument_list|,
literal|"biodep"
argument_list|)
condition|)
continue|continue;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|NULL
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
name|PQ_INACTIVE
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_npages
operator|=
name|desiredpages
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|size
operator|>
name|bp
operator|->
name|b_bcount
condition|)
block|{
comment|/* 			 * We are growing the buffer, possibly in a  			 * byte-granular fashion. 			 */
name|vm_object_t
name|obj
decl_stmt|;
name|vm_offset_t
name|toff
decl_stmt|;
name|vm_offset_t
name|tinc
decl_stmt|;
comment|/* 			 * Step 1, bring in the VM pages from the object,  			 * allocating them if necessary.  We must clear 			 * B_CACHE if these pages are not valid for the  			 * range covered by the buffer. 			 */
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
while|while
condition|(
name|bp
operator|->
name|b_npages
operator|<
name|desiredpages
condition|)
block|{
name|vm_page_t
name|m
decl_stmt|;
comment|/* 				 * We must allocate system pages since blocking 				 * here could interfere with paging I/O, no 				 * matter which process we are. 				 * 				 * Only exclusive busy can be tested here. 				 * Blocking on shared busy might lead to 				 * deadlocks once allocbuf() is called after 				 * pages are vfs_busy_pages(). 				 */
name|m
operator|=
name|vm_page_grab
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
operator|+
name|bp
operator|->
name|b_npages
argument_list|,
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SYSTEM
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_IGN_SBUSY
operator||
name|VM_ALLOC_COUNT
argument_list|(
name|desiredpages
operator|-
name|bp
operator|->
name|b_npages
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|bp
operator|->
name|b_npages
index|]
operator|=
name|m
expr_stmt|;
operator|++
name|bp
operator|->
name|b_npages
expr_stmt|;
block|}
comment|/* 			 * Step 2.  We've loaded the pages into the buffer, 			 * we have to figure out if we can still have B_CACHE 			 * set.  Note that B_CACHE is set according to the 			 * byte-granular range ( bcount and size ), new the 			 * aligned range ( newbsize ). 			 * 			 * The VM test is against m->valid, which is DEV_BSIZE 			 * aligned.  Needless to say, the validity of the data 			 * needs to also be DEV_BSIZE aligned.  Note that this 			 * fails with NFS if the server or some other client 			 * extends the file's EOF.  If our buffer is resized,  			 * B_CACHE may remain set! XXX 			 */
name|toff
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
name|tinc
operator|=
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|bp
operator|->
name|b_offset
operator|+
name|toff
operator|)
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|&&
name|toff
operator|<
name|size
condition|)
block|{
name|vm_pindex_t
name|pi
decl_stmt|;
if|if
condition|(
name|tinc
operator|>
operator|(
name|size
operator|-
name|toff
operator|)
condition|)
name|tinc
operator|=
name|size
operator|-
name|toff
expr_stmt|;
name|pi
operator|=
operator|(
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|+
name|toff
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
name|vfs_buf_test_cache
argument_list|(
name|bp
argument_list|,
name|bp
operator|->
name|b_offset
argument_list|,
name|toff
argument_list|,
name|tinc
argument_list|,
name|bp
operator|->
name|b_pages
index|[
name|pi
index|]
argument_list|)
expr_stmt|;
name|toff
operator|+=
name|tinc
expr_stmt|;
name|tinc
operator|=
name|PAGE_SIZE
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
comment|/* 			 * Step 3, fixup the KVM pmap. 			 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|==
literal|0
condition|)
name|bpmap_qenter
argument_list|(
name|bp
argument_list|)
expr_stmt|;
else|else
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
name|newbsize
expr_stmt|;
comment|/* actual buffer allocation	*/
name|bp
operator|->
name|b_bcount
operator|=
name|size
expr_stmt|;
comment|/* requested buffer size	*/
return|return
literal|1
return|;
block|}
end_function

begin_decl_stmt
specifier|extern
name|int
name|inflight_transient_maps
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|biodone
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|void
function_decl|(
modifier|*
name|done
function_decl|)
parameter_list|(
name|struct
name|bio
modifier|*
parameter_list|)
function_decl|;
name|vm_offset_t
name|start
decl_stmt|,
name|end
decl_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|bio_flags
operator|&
name|BIO_TRANSIENT_MAPPING
operator|)
operator|!=
literal|0
condition|)
block|{
name|bp
operator|->
name|bio_flags
operator|&=
operator|~
name|BIO_TRANSIENT_MAPPING
expr_stmt|;
name|bp
operator|->
name|bio_flags
operator||=
name|BIO_UNMAPPED
expr_stmt|;
name|start
operator|=
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|bio_data
argument_list|)
expr_stmt|;
name|end
operator|=
name|round_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|bio_data
operator|+
name|bp
operator|->
name|bio_length
argument_list|)
expr_stmt|;
name|bp
operator|->
name|bio_data
operator|=
name|unmapped_buf
expr_stmt|;
name|pmap_qremove
argument_list|(
name|start
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|end
operator|-
name|start
argument_list|)
argument_list|)
expr_stmt|;
name|vmem_free
argument_list|(
name|transient_arena
argument_list|,
name|start
argument_list|,
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|inflight_transient_maps
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
name|done
operator|=
name|bp
operator|->
name|bio_done
expr_stmt|;
if|if
condition|(
name|done
operator|==
name|NULL
condition|)
block|{
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|bio_flags
operator||=
name|BIO_DONE
expr_stmt|;
name|wakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|bio_flags
operator||=
name|BIO_DONE
expr_stmt|;
name|done
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Wait for a BIO to finish.  */
end_comment

begin_function
name|int
name|biowait
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|,
specifier|const
name|char
modifier|*
name|wchan
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|->
name|bio_flags
operator|&
name|BIO_DONE
operator|)
operator|==
literal|0
condition|)
name|msleep
argument_list|(
name|bp
argument_list|,
name|mtxp
argument_list|,
name|PRIBIO
argument_list|,
name|wchan
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|bio_error
operator|!=
literal|0
condition|)
return|return
operator|(
name|bp
operator|->
name|bio_error
operator|)
return|;
if|if
condition|(
operator|!
operator|(
name|bp
operator|->
name|bio_flags
operator|&
name|BIO_ERROR
operator|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
return|return
operator|(
name|EIO
operator|)
return|;
block|}
end_function

begin_function
name|void
name|biofinish
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|,
name|struct
name|devstat
modifier|*
name|stat
parameter_list|,
name|int
name|error
parameter_list|)
block|{
if|if
condition|(
name|error
condition|)
block|{
name|bp
operator|->
name|bio_error
operator|=
name|error
expr_stmt|;
name|bp
operator|->
name|bio_flags
operator||=
name|BIO_ERROR
expr_stmt|;
block|}
if|if
condition|(
name|stat
operator|!=
name|NULL
condition|)
name|devstat_end_transaction_bio
argument_list|(
name|stat
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|biodone
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufwait:  *  *	Wait for buffer I/O completion, returning error status.  The buffer  *	is left locked and B_DONE on return.  B_EINTR is converted into an EINTR  *	error and cleared.  */
end_comment

begin_function
name|int
name|bufwait
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
condition|)
name|bwait
argument_list|(
name|bp
argument_list|,
name|PRIBIO
argument_list|,
literal|"biord"
argument_list|)
expr_stmt|;
else|else
name|bwait
argument_list|(
name|bp
argument_list|,
name|PRIBIO
argument_list|,
literal|"biowr"
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_EINTR
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_EINTR
expr_stmt|;
return|return
operator|(
name|EINTR
operator|)
return|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
condition|)
block|{
return|return
operator|(
name|bp
operator|->
name|b_error
condition|?
name|bp
operator|->
name|b_error
else|:
name|EIO
operator|)
return|;
block|}
else|else
block|{
return|return
operator|(
literal|0
operator|)
return|;
block|}
block|}
end_function

begin_comment
comment|/*   * Call back function from struct bio back up to struct buf.   */
end_comment

begin_function
specifier|static
name|void
name|bufdonebio
parameter_list|(
name|struct
name|bio
modifier|*
name|bip
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|bp
operator|=
name|bip
operator|->
name|bio_caller2
expr_stmt|;
name|bp
operator|->
name|b_resid
operator|=
name|bip
operator|->
name|bio_resid
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|=
name|bip
operator|->
name|bio_flags
expr_stmt|;
name|bp
operator|->
name|b_error
operator|=
name|bip
operator|->
name|bio_error
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_error
condition|)
name|bp
operator|->
name|b_ioflags
operator||=
name|BIO_ERROR
expr_stmt|;
name|bufdone
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|g_destroy_bio
argument_list|(
name|bip
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|dev_strategy
parameter_list|(
name|struct
name|cdev
modifier|*
name|dev
parameter_list|,
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|cdevsw
modifier|*
name|csw
decl_stmt|;
name|int
name|ref
decl_stmt|;
name|KASSERT
argument_list|(
name|dev
operator|->
name|si_refcount
operator|>
literal|0
argument_list|,
operator|(
literal|"dev_strategy on un-referenced struct cdev *(%s) %p"
operator|,
name|devtoname
argument_list|(
name|dev
argument_list|)
operator|,
name|dev
operator|)
argument_list|)
expr_stmt|;
name|csw
operator|=
name|dev_refthread
argument_list|(
name|dev
argument_list|,
operator|&
name|ref
argument_list|)
expr_stmt|;
name|dev_strategy_csw
argument_list|(
name|dev
argument_list|,
name|csw
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|dev_relthread
argument_list|(
name|dev
argument_list|,
name|ref
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|dev_strategy_csw
parameter_list|(
name|struct
name|cdev
modifier|*
name|dev
parameter_list|,
name|struct
name|cdevsw
modifier|*
name|csw
parameter_list|,
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|bio
modifier|*
name|bip
decl_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
operator|||
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_WRITE
argument_list|,
operator|(
literal|"b_iocmd botch"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|(
name|dev
operator|->
name|si_flags
operator|&
name|SI_ETERNAL
operator|)
operator|!=
literal|0
operator|&&
name|csw
operator|!=
name|NULL
operator|)
operator|||
name|dev
operator|->
name|si_threadcount
operator|>
literal|0
argument_list|,
operator|(
literal|"dev_strategy_csw threadcount cdev *(%s) %p"
operator|,
name|devtoname
argument_list|(
name|dev
argument_list|)
operator|,
name|dev
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|csw
operator|==
name|NULL
condition|)
block|{
name|bp
operator|->
name|b_error
operator|=
name|ENXIO
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|=
name|BIO_ERROR
expr_stmt|;
name|bufdone
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
for|for
control|(
init|;
condition|;
control|)
block|{
name|bip
operator|=
name|g_new_bio
argument_list|()
expr_stmt|;
if|if
condition|(
name|bip
operator|!=
name|NULL
condition|)
break|break;
comment|/* Try again later */
name|tsleep
argument_list|(
operator|&
name|bp
argument_list|,
name|PRIBIO
argument_list|,
literal|"dev_strat"
argument_list|,
name|hz
operator|/
literal|10
argument_list|)
expr_stmt|;
block|}
name|bip
operator|->
name|bio_cmd
operator|=
name|bp
operator|->
name|b_iocmd
expr_stmt|;
name|bip
operator|->
name|bio_offset
operator|=
name|bp
operator|->
name|b_iooffset
expr_stmt|;
name|bip
operator|->
name|bio_length
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
name|bip
operator|->
name|bio_bcount
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* XXX: remove */
name|bdata2bio
argument_list|(
name|bp
argument_list|,
name|bip
argument_list|)
expr_stmt|;
name|bip
operator|->
name|bio_done
operator|=
name|bufdonebio
expr_stmt|;
name|bip
operator|->
name|bio_caller2
operator|=
name|bp
expr_stmt|;
name|bip
operator|->
name|bio_dev
operator|=
name|dev
expr_stmt|;
call|(
modifier|*
name|csw
operator|->
name|d_strategy
call|)
argument_list|(
name|bip
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufdone:  *  *	Finish I/O on a buffer, optionally calling a completion function.  *	This is usually called from an interrupt so process blocking is  *	not allowed.  *  *	biodone is also responsible for setting B_CACHE in a B_VMIO bp.  *	In a non-VMIO bp, B_CACHE will be set on the next getblk()   *	assuming B_INVAL is clear.  *  *	For the VMIO case, we set B_CACHE if the op was a read and no  *	read error occured, or if the op was a write.  B_CACHE is never  *	set if the buffer is invalid or otherwise uncacheable.  *  *	biodone does not mess with B_INVAL, allowing the I/O routine or the  *	initiator to leave B_INVAL set to brelse the buffer out of existance  *	in the biodone routine.  */
end_comment

begin_function
name|void
name|bufdone
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|bufobj
modifier|*
name|dropobj
decl_stmt|;
name|void
function_decl|(
modifier|*
name|biodone
function_decl|)
parameter_list|(
name|struct
name|buf
modifier|*
parameter_list|)
function_decl|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bufdone(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|dropobj
operator|=
name|NULL
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DONE
operator|)
argument_list|,
operator|(
literal|"biodone: bp %p already done"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|runningbufwakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_WRITE
condition|)
name|dropobj
operator|=
name|bp
operator|->
name|b_bufobj
expr_stmt|;
comment|/* call optional completion function if requested */
if|if
condition|(
name|bp
operator|->
name|b_iodone
operator|!=
name|NULL
condition|)
block|{
name|biodone
operator|=
name|bp
operator|->
name|b_iodone
expr_stmt|;
name|bp
operator|->
name|b_iodone
operator|=
name|NULL
expr_stmt|;
call|(
modifier|*
name|biodone
call|)
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|dropobj
condition|)
name|bufobj_wdrop
argument_list|(
name|dropobj
argument_list|)
expr_stmt|;
return|return;
block|}
name|bufdone_finish
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|dropobj
condition|)
name|bufobj_wdrop
argument_list|(
name|dropobj
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bufdone_finish
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
condition|)
name|buf_complete
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|vm_ooffset_t
name|foff
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|int
name|bogus
decl_stmt|,
name|i
decl_stmt|,
name|iosize
decl_stmt|;
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|KASSERT
argument_list|(
name|obj
operator|->
name|paging_in_progress
operator|>=
name|bp
operator|->
name|b_npages
argument_list|,
operator|(
literal|"biodone_finish: paging in progress(%d)< b_npages(%d)"
operator|,
name|obj
operator|->
name|paging_in_progress
operator|,
name|bp
operator|->
name|b_npages
operator|)
argument_list|)
expr_stmt|;
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
name|KASSERT
argument_list|(
name|vp
operator|->
name|v_holdcnt
operator|>
literal|0
argument_list|,
operator|(
literal|"biodone_finish: vnode %p has zero hold count"
operator|,
name|vp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|vp
operator|->
name|v_object
operator|!=
name|NULL
argument_list|,
operator|(
literal|"biodone_finish: vnode %p has no vm_object"
operator|,
name|vp
operator|)
argument_list|)
expr_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"biodone_finish: bp %p has no buffer offset"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Set B_CACHE if the op was a normal read and no error 		 * occured.  B_CACHE is set for writes in the b*write() 		 * routines. 		 */
name|iosize
operator|=
name|bp
operator|->
name|b_bcount
operator|-
name|bp
operator|->
name|b_resid
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_NOCACHE
operator|)
operator|)
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
block|}
name|bogus
operator|=
literal|0
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|int
name|bogusflag
init|=
literal|0
decl_stmt|;
name|int
name|resid
decl_stmt|;
name|resid
operator|=
operator|(
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
operator|)
operator|-
name|foff
expr_stmt|;
if|if
condition|(
name|resid
operator|>
name|iosize
condition|)
name|resid
operator|=
name|iosize
expr_stmt|;
comment|/* 			 * cleanup bogus pages, restoring the originals 			 */
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|bogus
operator|=
name|bogusflag
operator|=
literal|1
expr_stmt|;
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|foff
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"biodone: page disappeared!"
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|m
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|OFF_TO_IDX
argument_list|(
name|foff
argument_list|)
operator|==
name|m
operator|->
name|pindex
argument_list|,
operator|(
literal|"biodone_finish: foff(%jd)/pindex(%ju) mismatch"
operator|,
operator|(
name|intmax_t
operator|)
name|foff
operator|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|pindex
operator|)
argument_list|)
expr_stmt|;
comment|/* 			 * In the write case, the valid and clean bits are 			 * already changed correctly ( see bdwrite() ), so we  			 * only need to do this here in the read case. 			 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
operator|)
operator|&&
operator|!
name|bogusflag
operator|&&
name|resid
operator|>
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|dirty
operator|&
name|vm_page_bits
argument_list|(
name|foff
operator|&
name|PAGE_MASK
argument_list|,
name|resid
argument_list|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"bufdone_finish:"
literal|" page %p has unexpected dirty bits"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vfs_page_set_valid
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_sunbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_object_pip_subtract
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|foff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
name|iosize
operator|-=
name|resid
expr_stmt|;
block|}
name|vm_object_pip_wakeupn
argument_list|(
name|obj
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
if|if
condition|(
name|bogus
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|==
literal|0
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * For asynchronous completions, release the buffer now. The brelse 	 * will do a wakeup there if necessary - so no need to do a wakeup 	 * here in the async case. The sync case always needs to do a wakeup. 	 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ASYNC
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_NOCACHE
operator||
name|B_INVAL
operator||
name|B_RELBUF
operator|)
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
condition|)
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
else|else
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
name|bdone
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine is called in lieu of iodone in the case of  * incomplete I/O.  This keeps the busy status for pages  * consistant.  */
end_comment

begin_function
name|void
name|vfs_unbusy_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|runningbufwakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
condition|)
return|return;
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
operator|+
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|m
condition|)
name|panic
argument_list|(
literal|"vfs_unbusy_pages: page missing\n"
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|m
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|==
literal|0
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
else|else
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|vm_object_pip_subtract
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_sunbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_object_pip_wakeupn
argument_list|(
name|obj
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vfs_page_set_valid:  *  *	Set the valid bits in a page based on the supplied offset.   The  *	range is restricted to the buffer's size.  *  *	This routine is typically called after a read completes.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_page_set_valid
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_ooffset_t
name|eoff
decl_stmt|;
comment|/* 	 * Compute the end offset, eoff, such that [off, eoff) does not span a 	 * page boundary and eoff is not greater than the end of the buffer. 	 * The end of the buffer, in this case, is our file EOF, not the 	 * allocation size of the buffer. 	 */
name|eoff
operator|=
operator|(
name|off
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|vm_ooffset_t
operator|)
name|PAGE_MASK
expr_stmt|;
if|if
condition|(
name|eoff
operator|>
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
condition|)
name|eoff
operator|=
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* 	 * Set valid range.  This is typically the entire buffer and thus the 	 * entire page. 	 */
if|if
condition|(
name|eoff
operator|>
name|off
condition|)
name|vm_page_set_valid_range
argument_list|(
name|m
argument_list|,
name|off
operator|&
name|PAGE_MASK
argument_list|,
name|eoff
operator|-
name|off
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vfs_page_set_validclean:  *  *	Set the valid bits and clear the dirty bits in a page based on the  *	supplied offset.   The range is restricted to the buffer's size.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_page_set_validclean
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_ooffset_t
name|soff
decl_stmt|,
name|eoff
decl_stmt|;
comment|/* 	 * Start and end offsets in buffer.  eoff - soff may not cross a 	 * page boundry or cross the end of the buffer.  The end of the 	 * buffer, in this case, is our file EOF, not the allocation size 	 * of the buffer. 	 */
name|soff
operator|=
name|off
expr_stmt|;
name|eoff
operator|=
operator|(
name|off
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
if|if
condition|(
name|eoff
operator|>
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
condition|)
name|eoff
operator|=
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* 	 * Set valid range.  This is typically the entire buffer and thus the 	 * entire page. 	 */
if|if
condition|(
name|eoff
operator|>
name|soff
condition|)
block|{
name|vm_page_set_validclean
argument_list|(
name|m
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
name|soff
operator|&
name|PAGE_MASK
argument_list|)
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
name|eoff
operator|-
name|soff
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Ensure that all buffer pages are not exclusive busied.  If any page is  * exclusive busy, drain it.  */
end_comment

begin_function
name|void
name|vfs_drain_busy_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|,
name|last_busied
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
name|last_busied
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
block|{
for|for
control|(
init|;
name|last_busied
operator|<
name|i
condition|;
name|last_busied
operator|++
control|)
name|vm_page_sbusy
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|last_busied
index|]
argument_list|)
expr_stmt|;
while|while
condition|(
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
block|{
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
name|vm_page_busy_sleep
argument_list|(
name|m
argument_list|,
literal|"vbpage"
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
block|}
block|}
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|last_busied
condition|;
name|i
operator|++
control|)
name|vm_page_sunbusy
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine is called before a device strategy routine.  * It is used to tell the VM system that paging I/O is in  * progress, and treat the pages associated with the buffer  * almost as being exclusive busy.  Also the object paging_in_progress  * flag is handled to make sure that the object doesn't become  * inconsistant.  *  * Since I/O has not been initiated yet, certain buffer flags  * such as BIO_ERROR or B_INVAL may be in an inconsistant state  * and should be ignored.  */
end_comment

begin_function
name|void
name|vfs_busy_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|clear_modify
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|bogus
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|vm_ooffset_t
name|foff
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
condition|)
return|return;
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"vfs_busy_pages: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
name|vfs_drain_busy_pages
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|!=
literal|0
condition|)
name|vfs_setdirty_locked_object
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bogus
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CLUSTER
operator|)
operator|==
literal|0
condition|)
block|{
name|vm_object_pip_add
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_sbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * When readying a buffer for a read ( i.e 		 * clear_modify == 0 ), it is important to do 		 * bogus_page replacement for valid pages in  		 * partially instantiated buffers.  Partially  		 * instantiated buffers can, in turn, occur when 		 * reconstituting a buffer from its VM backing store 		 * base.  We only have to do this if B_CACHE is 		 * clear ( which causes the I/O to occur in the 		 * first place ).  The replacement prevents the read 		 * I/O from overwriting potentially dirty VM-backed 		 * pages.  XXX bogus page replacement is, uh, bogus. 		 * It may not work properly with small-block devices. 		 * We need to find a better way. 		 */
if|if
condition|(
name|clear_modify
condition|)
block|{
name|pmap_remove_write
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vfs_page_set_validclean
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|bogus_page
expr_stmt|;
name|bogus
operator|++
expr_stmt|;
block|}
name|foff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
if|if
condition|(
name|bogus
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|==
literal|0
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_set_valid:  *  *	Set the range within the buffer to valid.  The range is  *	relative to the beginning of the buffer, b_offset.  Note that  *	b_offset itself may be offset from the beginning of the first  *	page.  */
end_comment

begin_function
name|void
name|vfs_bio_set_valid
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|n
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
condition|)
return|return;
comment|/* 	 * Fixup base to be relative to beginning of first page. 	 * Set initial n to be the maximum number of bytes in the 	 * first page that can be validated. 	 */
name|base
operator|+=
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
operator|-
operator|(
name|base
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|base
operator|/
name|PAGE_SIZE
init|;
name|size
operator|>
literal|0
operator|&&
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
operator|++
name|i
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|n
operator|>
name|size
condition|)
name|n
operator|=
name|size
expr_stmt|;
name|vm_page_set_valid_range
argument_list|(
name|m
argument_list|,
name|base
operator|&
name|PAGE_MASK
argument_list|,
name|n
argument_list|)
expr_stmt|;
name|base
operator|+=
name|n
expr_stmt|;
name|size
operator|-=
name|n
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_clrbuf:  *  *	If the specified buffer is a non-VMIO buffer, clear the entire  *	buffer.  If the specified buffer is a VMIO buffer, clear and  *	validate only the previously invalid portions of the buffer.  *	This routine essentially fakes an I/O, so we need to clear  *	BIO_ERROR and B_INVAL.  *  *	Note that while we only theoretically need to clear through b_bcount,  *	we go ahead and clear through b_bufsize.  */
end_comment

begin_function
name|void
name|vfs_bio_clrbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|j
decl_stmt|,
name|mask
decl_stmt|,
name|sa
decl_stmt|,
name|ea
decl_stmt|,
name|slide
decl_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_VMIO
operator||
name|B_MALLOC
operator|)
operator|)
operator|!=
name|B_VMIO
condition|)
block|{
name|clrbuf
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INVAL
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_npages
operator|==
literal|1
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_bufsize
operator|<
name|PAGE_SIZE
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|==
name|bogus_page
condition|)
goto|goto
name|unlock
goto|;
name|mask
operator|=
operator|(
literal|1
operator|<<
operator|(
name|bp
operator|->
name|b_bufsize
operator|/
name|DEV_BSIZE
operator|)
operator|)
operator|-
literal|1
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
name|mask
condition|)
goto|goto
name|unlock
goto|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
argument_list|,
literal|0
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator||=
name|mask
expr_stmt|;
goto|goto
name|unlock
goto|;
block|}
block|}
name|sa
operator|=
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|slide
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
operator|,
name|sa
operator|=
literal|0
control|)
block|{
name|slide
operator|=
name|imin
argument_list|(
name|slide
operator|+
name|PAGE_SIZE
argument_list|,
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
name|ea
operator|=
name|slide
operator|&
name|PAGE_MASK
expr_stmt|;
if|if
condition|(
name|ea
operator|==
literal|0
condition|)
name|ea
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|==
name|bogus_page
condition|)
continue|continue;
name|j
operator|=
name|sa
operator|/
name|DEV_BSIZE
expr_stmt|;
name|mask
operator|=
operator|(
operator|(
literal|1
operator|<<
operator|(
operator|(
name|ea
operator|-
name|sa
operator|)
operator|/
name|DEV_BSIZE
operator|)
operator|)
operator|-
literal|1
operator|)
operator|<<
name|j
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
name|mask
condition|)
continue|continue;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|,
name|sa
argument_list|,
name|ea
operator|-
name|sa
argument_list|)
expr_stmt|;
else|else
block|{
for|for
control|(
init|;
name|sa
operator|<
name|ea
condition|;
name|sa
operator|+=
name|DEV_BSIZE
operator|,
name|j
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
name|j
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|,
name|sa
argument_list|,
name|DEV_BSIZE
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator||=
name|mask
expr_stmt|;
block|}
name|unlock
label|:
name|VM_OBJECT_WUNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vfs_bio_bzero_buf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|,
name|n
decl_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|==
literal|0
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
name|bp
operator|->
name|b_data
operator|+
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
operator|-
operator|(
name|base
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|base
operator|/
name|PAGE_SIZE
init|;
name|size
operator|>
literal|0
operator|&&
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
operator|++
name|i
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|n
operator|>
name|size
condition|)
name|n
operator|=
name|size
expr_stmt|;
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|base
operator|&
name|PAGE_MASK
argument_list|,
name|n
argument_list|)
expr_stmt|;
name|base
operator|+=
name|n
expr_stmt|;
name|size
operator|-=
name|n
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * vm_hold_load_pages and vm_hold_free_pages get pages into  * a buffers address space.  The pages are anonymous and are  * not associated with a file object.  */
end_comment

begin_function
specifier|static
name|void
name|vm_hold_load_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
block|{
name|vm_offset_t
name|pg
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|int
name|index
decl_stmt|;
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|to
operator|=
name|round_page
argument_list|(
name|to
argument_list|)
expr_stmt|;
name|from
operator|=
name|round_page
argument_list|(
name|from
argument_list|)
expr_stmt|;
name|index
operator|=
operator|(
name|from
operator|-
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
for|for
control|(
name|pg
operator|=
name|from
init|;
name|pg
operator|<
name|to
condition|;
name|pg
operator|+=
name|PAGE_SIZE
operator|,
name|index
operator|++
control|)
block|{
name|tryagain
label|:
comment|/* 		 * note: must allocate system pages since blocking here 		 * could interfere with paging I/O, no matter which 		 * process we are. 		 */
name|p
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_SYSTEM
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_COUNT
argument_list|(
operator|(
name|to
operator|-
name|pg
operator|)
operator|>>
name|PAGE_SHIFT
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
operator|==
name|NULL
condition|)
block|{
name|VM_WAIT
expr_stmt|;
goto|goto
name|tryagain
goto|;
block|}
name|pmap_qenter
argument_list|(
name|pg
argument_list|,
operator|&
name|p
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
operator|=
name|p
expr_stmt|;
block|}
name|bp
operator|->
name|b_npages
operator|=
name|index
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Return pages associated with this buf to the vm system */
end_comment

begin_function
specifier|static
name|void
name|vm_hold_free_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|newbsize
parameter_list|)
block|{
name|vm_offset_t
name|from
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|int
name|index
decl_stmt|,
name|newnpages
decl_stmt|;
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|from
operator|=
name|round_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|newbsize
argument_list|)
expr_stmt|;
name|newnpages
operator|=
operator|(
name|from
operator|-
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_npages
operator|>
name|newnpages
condition|)
name|pmap_qremove
argument_list|(
name|from
argument_list|,
name|bp
operator|->
name|b_npages
operator|-
name|newnpages
argument_list|)
expr_stmt|;
for|for
control|(
name|index
operator|=
name|newnpages
init|;
name|index
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|index
operator|++
control|)
block|{
name|p
operator|=
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|vm_page_sbusied
argument_list|(
name|p
argument_list|)
condition|)
name|printf
argument_list|(
literal|"vm_hold_free_pages: blkno: %jd, lblkno: %jd\n"
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_blkno
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_lblkno
argument_list|)
expr_stmt|;
name|p
operator|->
name|wire_count
operator|--
expr_stmt|;
name|vm_page_free
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_npages
operator|=
name|newnpages
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map an IO request into kernel virtual address space.  *  * All requests are (re)mapped into kernel VA space.  * Notice that we use b_bufsize for the size of the buffer  * to be mapped.  b_bcount might be modified by the driver.  *  * Note that even if the caller determines that the address space should  * be valid, a race or a smaller-file mapped into a larger space may  * actually cause vmapbuf() to fail, so all callers of vmapbuf() MUST  * check the return value.  */
end_comment

begin_function
name|int
name|vmapbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|mapbuf
parameter_list|)
block|{
name|caddr_t
name|kva
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
name|int
name|pidx
decl_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|<
literal|0
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
name|prot
operator|=
name|VM_PROT_READ
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
condition|)
name|prot
operator||=
name|VM_PROT_WRITE
expr_stmt|;
comment|/* Less backwards than it looks */
if|if
condition|(
operator|(
name|pidx
operator|=
name|vm_fault_quick_hold_pages
argument_list|(
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_map
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|,
name|prot
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|btoc
argument_list|(
name|MAXPHYS
argument_list|)
argument_list|)
operator|)
operator|<
literal|0
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
name|bp
operator|->
name|b_npages
operator|=
name|pidx
expr_stmt|;
if|if
condition|(
name|mapbuf
operator|||
operator|!
name|unmapped_buf_allowed
condition|)
block|{
name|pmap_qenter
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_saveaddr
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|pidx
argument_list|)
expr_stmt|;
name|kva
operator|=
name|bp
operator|->
name|b_saveaddr
expr_stmt|;
name|bp
operator|->
name|b_saveaddr
operator|=
name|bp
operator|->
name|b_data
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|kva
operator|+
operator|(
operator|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|)
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_UNMAPPED
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_UNMAPPED
expr_stmt|;
name|bp
operator|->
name|b_offset
operator|=
operator|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|)
operator|&
name|PAGE_MASK
expr_stmt|;
name|bp
operator|->
name|b_saveaddr
operator|=
name|bp
operator|->
name|b_data
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|unmapped_buf
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Free the io map PTEs associated with this IO operation.  * We also invalidate the TLB entries and restore the original b_addr.  */
end_comment

begin_function
name|void
name|vunmapbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|npages
decl_stmt|;
name|npages
operator|=
name|bp
operator|->
name|b_npages
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_UNMAPPED
expr_stmt|;
else|else
name|pmap_qremove
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|npages
argument_list|)
expr_stmt|;
name|vm_page_unhold_pages
argument_list|(
name|bp
operator|->
name|b_pages
argument_list|,
name|npages
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_saveaddr
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bdone
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_DONE
expr_stmt|;
name|wakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bwait
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|u_char
name|pri
parameter_list|,
specifier|const
name|char
modifier|*
name|wchan
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DONE
operator|)
operator|==
literal|0
condition|)
name|msleep
argument_list|(
name|bp
argument_list|,
name|mtxp
argument_list|,
name|pri
argument_list|,
name|wchan
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|bufsync
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|,
name|int
name|waitfor
parameter_list|)
block|{
return|return
operator|(
name|VOP_FSYNC
argument_list|(
name|bo
operator|->
name|__bo_vnode
argument_list|,
name|waitfor
argument_list|,
name|curthread
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|bufstrategy
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|,
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
init|=
literal|0
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
name|KASSERT
argument_list|(
name|vp
operator|==
name|bo
operator|->
name|bo_private
argument_list|,
operator|(
literal|"Inconsistent vnode bufstrategy"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|vp
operator|->
name|v_type
operator|!=
name|VCHR
operator|&&
name|vp
operator|->
name|v_type
operator|!=
name|VBLK
argument_list|,
operator|(
literal|"Wrong vnode in bufstrategy(bp=%p, vp=%p)"
operator|,
name|bp
operator|,
name|vp
operator|)
argument_list|)
expr_stmt|;
name|i
operator|=
name|VOP_STRATEGY
argument_list|(
name|vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|i
operator|==
literal|0
argument_list|,
operator|(
literal|"VOP_STRATEGY failed bp=%p vp=%p"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_vp
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bufobj_wrefl
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|bo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"NULL bo in bufobj_wref"
operator|)
argument_list|)
expr_stmt|;
name|ASSERT_BO_WLOCKED
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|bo
operator|->
name|bo_numoutput
operator|++
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bufobj_wref
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|bo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"NULL bo in bufobj_wref"
operator|)
argument_list|)
expr_stmt|;
name|BO_LOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|bo
operator|->
name|bo_numoutput
operator|++
expr_stmt|;
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bufobj_wdrop
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|bo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"NULL bo in bufobj_wdrop"
operator|)
argument_list|)
expr_stmt|;
name|BO_LOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bo
operator|->
name|bo_numoutput
operator|>
literal|0
argument_list|,
operator|(
literal|"bufobj_wdrop non-positive count"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|--
name|bo
operator|->
name|bo_numoutput
operator|==
literal|0
operator|)
operator|&&
operator|(
name|bo
operator|->
name|bo_flag
operator|&
name|BO_WWAIT
operator|)
condition|)
block|{
name|bo
operator|->
name|bo_flag
operator|&=
operator|~
name|BO_WWAIT
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|bo
operator|->
name|bo_numoutput
argument_list|)
expr_stmt|;
block|}
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|bufobj_wwait
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|,
name|int
name|slpflag
parameter_list|,
name|int
name|timeo
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
name|KASSERT
argument_list|(
name|bo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"NULL bo in bufobj_wwait"
operator|)
argument_list|)
expr_stmt|;
name|ASSERT_BO_WLOCKED
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|error
operator|=
literal|0
expr_stmt|;
while|while
condition|(
name|bo
operator|->
name|bo_numoutput
condition|)
block|{
name|bo
operator|->
name|bo_flag
operator||=
name|BO_WWAIT
expr_stmt|;
name|error
operator|=
name|msleep
argument_list|(
operator|&
name|bo
operator|->
name|bo_numoutput
argument_list|,
name|BO_LOCKPTR
argument_list|(
name|bo
argument_list|)
argument_list|,
name|slpflag
operator||
operator|(
name|PRIBIO
operator|+
literal|1
operator|)
argument_list|,
literal|"bo_wwait"
argument_list|,
name|timeo
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
break|break;
block|}
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
name|void
name|bpin
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pin_count
operator|++
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bunpin
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|--
name|bp
operator|->
name|b_pin_count
operator|==
literal|0
condition|)
name|wakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bunpin_wait
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
while|while
condition|(
name|bp
operator|->
name|b_pin_count
operator|>
literal|0
condition|)
name|msleep
argument_list|(
name|bp
argument_list|,
name|mtxp
argument_list|,
name|PRIBIO
argument_list|,
literal|"bwunpin"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Set bio_data or bio_ma for struct bio from the struct buf.  */
end_comment

begin_function
name|void
name|bdata2bio
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|struct
name|bio
modifier|*
name|bip
parameter_list|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_UNMAPPED
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|unmapped_buf_allowed
argument_list|,
operator|(
literal|"unmapped"
operator|)
argument_list|)
expr_stmt|;
name|bip
operator|->
name|bio_ma
operator|=
name|bp
operator|->
name|b_pages
expr_stmt|;
name|bip
operator|->
name|bio_ma_n
operator|=
name|bp
operator|->
name|b_npages
expr_stmt|;
name|bip
operator|->
name|bio_data
operator|=
name|unmapped_buf
expr_stmt|;
name|bip
operator|->
name|bio_ma_offset
operator|=
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|bip
operator|->
name|bio_flags
operator||=
name|BIO_UNMAPPED
expr_stmt|;
name|KASSERT
argument_list|(
name|round_page
argument_list|(
name|bip
operator|->
name|bio_ma_offset
operator|+
name|bip
operator|->
name|bio_length
argument_list|)
operator|/
name|PAGE_SIZE
operator|==
name|bp
operator|->
name|b_npages
argument_list|,
operator|(
literal|"Buffer %p too short: %d %lld %d"
operator|,
name|bp
operator|,
name|bip
operator|->
name|bio_ma_offset
operator|,
operator|(
name|long
name|long
operator|)
name|bip
operator|->
name|bio_length
operator|,
name|bip
operator|->
name|bio_ma_n
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bip
operator|->
name|bio_data
operator|=
name|bp
operator|->
name|b_data
expr_stmt|;
name|bip
operator|->
name|bio_ma
operator|=
name|NULL
expr_stmt|;
block|}
block|}
end_function

begin_include
include|#
directive|include
file|"opt_ddb.h"
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_include
include|#
directive|include
file|<ddb/ddb.h>
end_include

begin_comment
comment|/* DDB command to show buffer data */
end_comment

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|buffer
argument_list|,
argument|db_show_buffer
argument_list|)
end_macro

begin_block
block|{
comment|/* get args */
name|struct
name|buf
modifier|*
name|bp
init|=
operator|(
expr|struct
name|buf
operator|*
operator|)
name|addr
decl_stmt|;
if|if
condition|(
operator|!
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"usage: show buffer<addr>\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|db_printf
argument_list|(
literal|"buf at %p\n"
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"b_flags = 0x%b, b_xflags=0x%b, b_vflags=0x%b\n"
argument_list|,
operator|(
name|u_int
operator|)
name|bp
operator|->
name|b_flags
argument_list|,
name|PRINT_BUF_FLAGS
argument_list|,
operator|(
name|u_int
operator|)
name|bp
operator|->
name|b_xflags
argument_list|,
name|PRINT_BUF_XFLAGS
argument_list|,
operator|(
name|u_int
operator|)
name|bp
operator|->
name|b_vflags
argument_list|,
name|PRINT_BUF_VFLAGS
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"b_error = %d, b_bufsize = %ld, b_bcount = %ld, b_resid = %ld\n"
literal|"b_bufobj = (%p), b_data = %p, b_blkno = %jd, b_lblkno = %jd, "
literal|"b_dep = %p\n"
argument_list|,
name|bp
operator|->
name|b_error
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|,
name|bp
operator|->
name|b_bcount
argument_list|,
name|bp
operator|->
name|b_resid
argument_list|,
name|bp
operator|->
name|b_bufobj
argument_list|,
name|bp
operator|->
name|b_data
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_blkno
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_lblkno
argument_list|,
name|bp
operator|->
name|b_dep
operator|.
name|lh_first
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_npages
condition|)
block|{
name|int
name|i
decl_stmt|;
name|db_printf
argument_list|(
literal|"b_npages = %d, pages(OBJ, IDX, PA): "
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|db_printf
argument_list|(
literal|"(%p, 0x%lx, 0x%lx)"
argument_list|,
operator|(
name|void
operator|*
operator|)
name|m
operator|->
name|object
argument_list|,
operator|(
name|u_long
operator|)
name|m
operator|->
name|pindex
argument_list|,
operator|(
name|u_long
operator|)
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|i
operator|+
literal|1
operator|)
operator|<
name|bp
operator|->
name|b_npages
condition|)
name|db_printf
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|" "
argument_list|)
expr_stmt|;
name|BUF_LOCKPRINTINFO
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_block

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|lockedbufs
argument_list|,
argument|lockedbufs
argument_list|)
end_macro

begin_block
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nbuf
condition|;
name|i
operator|++
control|)
block|{
name|bp
operator|=
operator|&
name|buf
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|BUF_ISLOCKED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|db_show_buffer
argument_list|(
operator|(
name|uintptr_t
operator|)
name|bp
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_block

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|vnodebufs
argument_list|,
argument|db_show_vnodebufs
argument_list|)
end_macro

begin_block
block|{
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
if|if
condition|(
operator|!
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"usage: show vnodebufs<addr>\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|vp
operator|=
operator|(
expr|struct
name|vnode
operator|*
operator|)
name|addr
expr_stmt|;
name|db_printf
argument_list|(
literal|"Clean buffers:\n"
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|bp
argument_list|,
argument|&vp->v_bufobj.bo_clean.bv_hd
argument_list|,
argument|b_bobufs
argument_list|)
block|{
name|db_show_buffer
argument_list|(
operator|(
name|uintptr_t
operator|)
name|bp
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"Dirty buffers:\n"
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|bp
argument_list|,
argument|&vp->v_bufobj.bo_dirty.bv_hd
argument_list|,
argument|b_bobufs
argument_list|)
block|{
name|db_show_buffer
argument_list|(
operator|(
name|uintptr_t
operator|)
name|bp
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
block|}
end_block

begin_macro
name|DB_COMMAND
argument_list|(
argument|countfreebufs
argument_list|,
argument|db_coundfreebufs
argument_list|)
end_macro

begin_block
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|i
decl_stmt|,
name|used
init|=
literal|0
decl_stmt|,
name|nfree
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"usage: countfreebufs\n"
argument_list|)
expr_stmt|;
return|return;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nbuf
condition|;
name|i
operator|++
control|)
block|{
name|bp
operator|=
operator|&
name|buf
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INFREECNT
operator|)
operator|!=
literal|0
condition|)
name|nfree
operator|++
expr_stmt|;
else|else
name|used
operator|++
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"Counted %d free, %d used (%d tot)\n"
argument_list|,
name|nfree
argument_list|,
name|used
argument_list|,
name|nfree
operator|+
name|used
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"numfreebuffers is %d\n"
argument_list|,
name|numfreebuffers
argument_list|)
expr_stmt|;
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* DDB */
end_comment

end_unit

