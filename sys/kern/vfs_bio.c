begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2004 Poul-Henning Kamp  * Copyright (c) 1994,1997 John S. Dyson  * Copyright (c) 2013 The FreeBSD Foundation  * All rights reserved.  *  * Portions of this software were developed by Konstantin Belousov  * under sponsorship from the FreeBSD Foundation.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  */
end_comment

begin_comment
comment|/*  * this file contains a new buffer I/O scheme implementing a coherent  * VM object and buffer cache scheme.  Pains have been taken to make  * sure that the performance degradation associated with schemes such  * as this is not realized.  *  * Author:  John S. Dyson  * Significant help during the development and debugging phases  * had been provided by David Greenman, also of the FreeBSD core team.  *  * see man buf(9) for more info.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/bio.h>
end_include

begin_include
include|#
directive|include
file|<sys/conf.h>
end_include

begin_include
include|#
directive|include
file|<sys/buf.h>
end_include

begin_include
include|#
directive|include
file|<sys/devicestat.h>
end_include

begin_include
include|#
directive|include
file|<sys/eventhandler.h>
end_include

begin_include
include|#
directive|include
file|<sys/fail.h>
end_include

begin_include
include|#
directive|include
file|<sys/limits.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mount.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/kthread.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/racct.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysproto.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmem.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<sys/watchdog.h>
end_include

begin_include
include|#
directive|include
file|<geom/geom.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/swap_pager.h>
end_include

begin_include
include|#
directive|include
file|"opt_compat.h"
end_include

begin_include
include|#
directive|include
file|"opt_swap.h"
end_include

begin_expr_stmt
specifier|static
name|MALLOC_DEFINE
argument_list|(
name|M_BIOBUF
argument_list|,
literal|"biobuf"
argument_list|,
literal|"BIO buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|struct
name|bio_ops
name|bioops
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* I/O operation notification */
end_comment

begin_decl_stmt
name|struct
name|buf_ops
name|buf_ops_bio
init|=
block|{
operator|.
name|bop_name
operator|=
literal|"buf_ops_bio"
block|,
operator|.
name|bop_write
operator|=
name|bufwrite
block|,
operator|.
name|bop_strategy
operator|=
name|bufstrategy
block|,
operator|.
name|bop_sync
operator|=
name|bufsync
block|,
operator|.
name|bop_bdflush
operator|=
name|bufbdflush
block|, }
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|buf
modifier|*
name|buf
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* buffer header pool */
end_comment

begin_decl_stmt
specifier|extern
name|struct
name|buf
modifier|*
name|swbuf
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Swap buffer header pool. */
end_comment

begin_decl_stmt
name|caddr_t
name|unmapped_buf
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Used below and for softdep flushing threads in ufs/ffs/ffs_softdep.c */
end_comment

begin_decl_stmt
name|struct
name|proc
modifier|*
name|bufdaemonproc
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|proc
modifier|*
name|bufspacedaemonproc
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|int
name|inmem
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_hold_free_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|newbsize
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_hold_load_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_page_set_valid
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_page_set_validclean
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_clean_pages_dirty_buf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_setdirty_locked_object
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_vmio_invalidate
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_vmio_truncate
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|npages
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_vmio_extend
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|npages
parameter_list|,
name|int
name|size
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vfs_bio_clcheck
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
name|size
parameter_list|,
name|daddr_t
name|lblkno
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|buf_flush
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|buf_recycle
parameter_list|(
name|bool
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|buf_scan
parameter_list|(
name|bool
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|flushbufqueues
parameter_list|(
name|struct
name|vnode
modifier|*
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|buf_daemon
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|bremfreel
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|bd_wakeup
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sysctl_runningspace
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|bufkva_reclaim
parameter_list|(
name|vmem_t
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|bufkva_free
parameter_list|(
name|struct
name|buf
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|buf_import
parameter_list|(
name|void
modifier|*
parameter_list|,
name|void
modifier|*
modifier|*
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|buf_release
parameter_list|(
name|void
modifier|*
parameter_list|,
name|void
modifier|*
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|maxbcachebuf_adjust
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_if
if|#
directive|if
name|defined
argument_list|(
name|COMPAT_FREEBSD4
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD5
argument_list|)
operator|||
expr|\
name|defined
argument_list|(
name|COMPAT_FREEBSD6
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD7
argument_list|)
end_if

begin_function_decl
specifier|static
name|int
name|sysctl_bufspace
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
name|int
name|vmiodirenable
init|=
name|TRUE
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|vmiodirenable
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vmiodirenable
argument_list|,
literal|0
argument_list|,
literal|"Use the VM system for directory writes"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|long
name|runningbufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|runningbufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|runningbufspace
argument_list|,
literal|0
argument_list|,
literal|"Amount of presently outstanding async buffer io"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|bufspace
decl_stmt|;
end_decl_stmt

begin_if
if|#
directive|if
name|defined
argument_list|(
name|COMPAT_FREEBSD4
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD5
argument_list|)
operator|||
expr|\
name|defined
argument_list|(
name|COMPAT_FREEBSD6
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD7
argument_list|)
end_if

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufspace
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_MPSAFE
operator||
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufspace
argument_list|,
literal|0
argument_list|,
name|sysctl_bufspace
argument_list|,
literal|"L"
argument_list|,
literal|"Virtual memory used for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_else
else|#
directive|else
end_else

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufspace
argument_list|,
literal|0
argument_list|,
literal|"Physical memory used for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|long
name|bufkvaspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufkvaspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufkvaspace
argument_list|,
literal|0
argument_list|,
literal|"Kernel virtual memory used for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|maxbufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|maxbufspace
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|maxbufspace
argument_list|,
literal|0
argument_list|,
literal|"Maximum allowed value of bufspace (including metadata)"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|bufmallocspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufmallocspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufmallocspace
argument_list|,
literal|0
argument_list|,
literal|"Amount of malloced memory for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|maxbufmallocspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|maxmallocbufspace
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|maxbufmallocspace
argument_list|,
literal|0
argument_list|,
literal|"Maximum amount of malloced memory for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|lobufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lobufspace
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|lobufspace
argument_list|,
literal|0
argument_list|,
literal|"Minimum amount of buffers we want to have"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|long
name|hibufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hibufspace
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|hibufspace
argument_list|,
literal|0
argument_list|,
literal|"Maximum allowed value of bufspace (excluding metadata)"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|long
name|bufspacethresh
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufspacethresh
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|bufspacethresh
argument_list|,
literal|0
argument_list|,
literal|"Bufspace consumed before waking the daemon to free some"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|buffreekvacnt
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|buffreekvacnt
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|buffreekvacnt
argument_list|,
literal|0
argument_list|,
literal|"Number of times we have freed the KVA space from some buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|bufdefragcnt
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufdefragcnt
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|bufdefragcnt
argument_list|,
literal|0
argument_list|,
literal|"Number of times we have had to repeat buffer allocation to defragment"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|lorunningspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lorunningspace
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_MPSAFE
operator||
name|CTLFLAG_RW
argument_list|,
operator|&
name|lorunningspace
argument_list|,
literal|0
argument_list|,
name|sysctl_runningspace
argument_list|,
literal|"L"
argument_list|,
literal|"Minimum preferred space used for in-progress I/O"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|hirunningspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hirunningspace
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_MPSAFE
operator||
name|CTLFLAG_RW
argument_list|,
operator|&
name|hirunningspace
argument_list|,
literal|0
argument_list|,
name|sysctl_runningspace
argument_list|,
literal|"L"
argument_list|,
literal|"Maximum amount of space to use for in-progress I/O"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|dirtybufferflushes
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|dirtybufferflushes
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|dirtybufferflushes
argument_list|,
literal|0
argument_list|,
literal|"Number of bdwrite to bawrite conversions to limit dirty buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|bdwriteskip
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bdwriteskip
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|bdwriteskip
argument_list|,
literal|0
argument_list|,
literal|"Number of buffers supplied to bdwrite with snapshot deadlock risk"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|altbufferflushes
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|altbufferflushes
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|altbufferflushes
argument_list|,
literal|0
argument_list|,
literal|"Number of fsync flushes to limit dirty buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|recursiveflushes
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|recursiveflushes
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|recursiveflushes
argument_list|,
literal|0
argument_list|,
literal|"Number of flushes skipped due to being recursive"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|numdirtybuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|numdirtybuffers
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|numdirtybuffers
argument_list|,
literal|0
argument_list|,
literal|"Number of buffers that are dirty (has unwritten changes) at the moment"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|lodirtybuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lodirtybuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|lodirtybuffers
argument_list|,
literal|0
argument_list|,
literal|"How many buffers we want to have free before bufdaemon can sleep"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|hidirtybuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hidirtybuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|hidirtybuffers
argument_list|,
literal|0
argument_list|,
literal|"When the number of dirty buffers is considered severe"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|dirtybufthresh
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|dirtybufthresh
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|dirtybufthresh
argument_list|,
literal|0
argument_list|,
literal|"Number of bdwrite to bawrite conversions to clear dirty buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|numfreebuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|numfreebuffers
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|numfreebuffers
argument_list|,
literal|0
argument_list|,
literal|"Number of free buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|lofreebuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lofreebuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|lofreebuffers
argument_list|,
literal|0
argument_list|,
literal|"Target number of free buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|hifreebuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hifreebuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|hifreebuffers
argument_list|,
literal|0
argument_list|,
literal|"Threshold for clean buffer recycling"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|getnewbufcalls
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|getnewbufcalls
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|getnewbufcalls
argument_list|,
literal|0
argument_list|,
literal|"Number of calls to getnewbuf"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|getnewbufrestarts
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|getnewbufrestarts
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|getnewbufrestarts
argument_list|,
literal|0
argument_list|,
literal|"Number of times getnewbuf has had to restart a buffer acquisition"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|mappingrestarts
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|mappingrestarts
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|mappingrestarts
argument_list|,
literal|0
argument_list|,
literal|"Number of times getblk has had to restart a buffer mapping for "
literal|"unmapped buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|numbufallocfails
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|numbufallocfails
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|numbufallocfails
argument_list|,
literal|0
argument_list|,
literal|"Number of times buffer allocations failed"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|flushbufqtarget
init|=
literal|100
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|flushbufqtarget
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|flushbufqtarget
argument_list|,
literal|0
argument_list|,
literal|"Amount of work to do in flushbufqueues when helping bufdaemon"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|notbufdflushes
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|notbufdflushes
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|notbufdflushes
argument_list|,
literal|0
argument_list|,
literal|"Number of dirty buffer flushes done by the bufdaemon helpers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|barrierwrites
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|barrierwrites
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|barrierwrites
argument_list|,
literal|0
argument_list|,
literal|"Number of barrier writes"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|unmapped_buf_allowed
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|unmapped_buf_allowed
argument_list|,
literal|0
argument_list|,
literal|"Permit the use of the unmapped i/o"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|maxbcachebuf
init|=
name|MAXBCACHEBUF
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|maxbcachebuf
argument_list|,
name|CTLFLAG_RDTUN
argument_list|,
operator|&
name|maxbcachebuf
argument_list|,
literal|0
argument_list|,
literal|"Maximum size of a buffer cache block"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * This lock synchronizes access to bd_request.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mtx_padalign
name|bdlock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * This lock protects the runningbufreq and synchronizes runningbufwakeup and  * waitrunningbufspace().  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mtx_padalign
name|rbreqlock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Lock that protects needsbuffer and the sleeps/wakeups surrounding it.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|rwlock_padalign
name|nblock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Lock that protects bdirtywait.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mtx_padalign
name|bdirtylock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Wakeup point for bufdaemon, as well as indicator of whether it is already  * active.  Set to 1 when the bufdaemon is already "on" the queue, 0 when it  * is idling.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|bd_request
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Request/wakeup point for the bufspace daemon.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|bufspace_request
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Request for the buf daemon to write more buffers than is indicated by  * lodirtybuf.  This may be necessary to push out excess dependencies or  * defragment the address space where a simple count of the number of dirty  * buffers is insufficient to characterize the demand for flushing them.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|bd_speedupreq
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Synchronization (sleep/wakeup) variable for active buffer space requests.  * Set when wait starts, cleared prior to wakeup().  * Used in runningbufwakeup() and waitrunningbufspace().  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|runningbufreq
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*   * Synchronization (sleep/wakeup) variable for buffer requests.  * Can contain the VFS_BIO_NEED flags defined below; setting/clearing is done  * by and/or.  * Used in numdirtywakeup(), bufspace_wakeup(), bwillwrite(),  * getnewbuf(), and getblk().  */
end_comment

begin_decl_stmt
specifier|static
specifier|volatile
name|int
name|needsbuffer
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Synchronization for bwillwrite() waiters.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|bdirtywait
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Definitions for the buffer free lists.  */
end_comment

begin_define
define|#
directive|define
name|QUEUE_NONE
value|0
end_define

begin_comment
comment|/* on no queue */
end_comment

begin_define
define|#
directive|define
name|QUEUE_EMPTY
value|1
end_define

begin_comment
comment|/* empty buffer headers */
end_comment

begin_define
define|#
directive|define
name|QUEUE_DIRTY
value|2
end_define

begin_comment
comment|/* B_DELWRI buffers */
end_comment

begin_define
define|#
directive|define
name|QUEUE_CLEAN
value|3
end_define

begin_comment
comment|/* non-B_DELWRI buffers */
end_comment

begin_define
define|#
directive|define
name|QUEUE_SENTINEL
value|1024
end_define

begin_comment
comment|/* not an queue index, but mark for sentinel */
end_comment

begin_comment
comment|/* Maximum number of clean buffer queues. */
end_comment

begin_define
define|#
directive|define
name|CLEAN_QUEUES
value|16
end_define

begin_comment
comment|/* Configured number of clean queues. */
end_comment

begin_decl_stmt
specifier|static
name|int
name|clean_queues
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Maximum number of buffer queues. */
end_comment

begin_define
define|#
directive|define
name|BUFFER_QUEUES
value|(QUEUE_CLEAN + CLEAN_QUEUES)
end_define

begin_comment
comment|/* Queues for free buffers with various properties */
end_comment

begin_expr_stmt
specifier|static
name|TAILQ_HEAD
argument_list|(
argument|bqueues
argument_list|,
argument|buf
argument_list|)
name|bufqueues
index|[
name|BUFFER_QUEUES
index|]
operator|=
block|{
block|{
literal|0
block|}
block|}
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|INVARIANTS
end_ifdef

begin_decl_stmt
specifier|static
name|int
name|bq_len
index|[
name|BUFFER_QUEUES
index|]
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Lock for each bufqueue  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mtx_padalign
name|bqlocks
index|[
name|BUFFER_QUEUES
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * per-cpu empty buffer cache.  */
end_comment

begin_decl_stmt
name|uma_zone_t
name|buf_zone
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Single global constant for BUF_WMESG, to avoid getting multiple references.  * buf_wmesg is referred from macros.  */
end_comment

begin_decl_stmt
specifier|const
name|char
modifier|*
name|buf_wmesg
init|=
name|BUF_WMESG
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|int
name|sysctl_runningspace
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|long
name|value
decl_stmt|;
name|int
name|error
decl_stmt|;
name|value
operator|=
operator|*
operator|(
name|long
operator|*
operator|)
name|arg1
expr_stmt|;
name|error
operator|=
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
operator|&
name|value
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|error
operator|)
return|;
name|mtx_lock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|arg1
operator|==
operator|&
name|hirunningspace
condition|)
block|{
if|if
condition|(
name|value
operator|<
name|lorunningspace
condition|)
name|error
operator|=
name|EINVAL
expr_stmt|;
else|else
name|hirunningspace
operator|=
name|value
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
name|arg1
operator|==
operator|&
name|lorunningspace
argument_list|,
operator|(
literal|"%s: unknown arg1"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|value
operator|>
name|hirunningspace
condition|)
name|error
operator|=
name|EINVAL
expr_stmt|;
else|else
name|lorunningspace
operator|=
name|value
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_if
if|#
directive|if
name|defined
argument_list|(
name|COMPAT_FREEBSD4
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD5
argument_list|)
operator|||
expr|\
name|defined
argument_list|(
name|COMPAT_FREEBSD6
argument_list|)
operator|||
name|defined
argument_list|(
name|COMPAT_FREEBSD7
argument_list|)
end_if

begin_function
specifier|static
name|int
name|sysctl_bufspace
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|long
name|lvalue
decl_stmt|;
name|int
name|ivalue
decl_stmt|;
if|if
condition|(
sizeof|sizeof
argument_list|(
name|int
argument_list|)
operator|==
sizeof|sizeof
argument_list|(
name|long
argument_list|)
operator|||
name|req
operator|->
name|oldlen
operator|>=
sizeof|sizeof
argument_list|(
name|long
argument_list|)
condition|)
return|return
operator|(
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
name|arg1
argument_list|,
name|arg2
argument_list|,
name|req
argument_list|)
operator|)
return|;
name|lvalue
operator|=
operator|*
operator|(
name|long
operator|*
operator|)
name|arg1
expr_stmt|;
if|if
condition|(
name|lvalue
operator|>
name|INT_MAX
condition|)
comment|/* On overflow, still write out a long to trigger ENOMEM. */
return|return
operator|(
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
operator|&
name|lvalue
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
operator|)
return|;
name|ivalue
operator|=
name|lvalue
expr_stmt|;
return|return
operator|(
name|sysctl_handle_int
argument_list|(
name|oidp
argument_list|,
operator|&
name|ivalue
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|int
name|bqcleanq
parameter_list|(
name|void
parameter_list|)
block|{
specifier|static
name|int
name|nextq
decl_stmt|;
return|return
operator|(
operator|(
name|atomic_fetchadd_int
argument_list|(
operator|&
name|nextq
argument_list|,
literal|1
argument_list|)
operator|%
name|clean_queues
operator|)
operator|+
name|QUEUE_CLEAN
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|bqisclean
parameter_list|(
name|int
name|qindex
parameter_list|)
block|{
return|return
operator|(
name|qindex
operator|>=
name|QUEUE_CLEAN
operator|&&
name|qindex
operator|<
name|QUEUE_CLEAN
operator|+
name|CLEAN_QUEUES
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	bqlock:  *  *	Return the appropriate queue lock based on the index.  */
end_comment

begin_function
specifier|static
specifier|inline
name|struct
name|mtx
modifier|*
name|bqlock
parameter_list|(
name|int
name|qindex
parameter_list|)
block|{
return|return
operator|(
expr|struct
name|mtx
operator|*
operator|)
operator|&
name|bqlocks
index|[
name|qindex
index|]
return|;
block|}
end_function

begin_comment
comment|/*  *	bdirtywakeup:  *  *	Wakeup any bwillwrite() waiters.  */
end_comment

begin_function
specifier|static
name|void
name|bdirtywakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|bdirtylock
argument_list|)
expr_stmt|;
if|if
condition|(
name|bdirtywait
condition|)
block|{
name|bdirtywait
operator|=
literal|0
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|bdirtywait
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|bdirtylock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bdirtysub:  *  *	Decrement the numdirtybuffers count by one and wakeup any  *	threads blocked in bwillwrite().  */
end_comment

begin_function
specifier|static
name|void
name|bdirtysub
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|atomic_fetchadd_int
argument_list|(
operator|&
name|numdirtybuffers
argument_list|,
operator|-
literal|1
argument_list|)
operator|==
operator|(
name|lodirtybuffers
operator|+
name|hidirtybuffers
operator|)
operator|/
literal|2
condition|)
name|bdirtywakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bdirtyadd:  *  *	Increment the numdirtybuffers count by one and wakeup the buf   *	daemon if needed.  */
end_comment

begin_function
specifier|static
name|void
name|bdirtyadd
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * Only do the wakeup once as we cross the boundary.  The 	 * buf daemon will keep running until the condition clears. 	 */
if|if
condition|(
name|atomic_fetchadd_int
argument_list|(
operator|&
name|numdirtybuffers
argument_list|,
literal|1
argument_list|)
operator|==
operator|(
name|lodirtybuffers
operator|+
name|hidirtybuffers
operator|)
operator|/
literal|2
condition|)
name|bd_wakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufspace_wakeup:  *  *	Called when buffer space is potentially available for recovery.  *	getnewbuf() will block on this flag when it is unable to free   *	sufficient buffer space.  Buffer space becomes recoverable when   *	bp's get placed back in the queues.  */
end_comment

begin_function
specifier|static
name|void
name|bufspace_wakeup
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * If someone is waiting for bufspace, wake them up. 	 * 	 * Since needsbuffer is set prior to doing an additional queue 	 * scan it is safe to check for the flag prior to acquiring the 	 * lock.  The thread that is preparing to scan again before 	 * blocking would discover the buf we released. 	 */
if|if
condition|(
name|needsbuffer
condition|)
block|{
name|rw_rlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
if|if
condition|(
name|atomic_cmpset_int
argument_list|(
operator|&
name|needsbuffer
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|)
operator|==
literal|1
condition|)
name|wakeup
argument_list|(
name|__DEVOLATILE
argument_list|(
name|void
operator|*
argument_list|,
operator|&
name|needsbuffer
argument_list|)
argument_list|)
expr_stmt|;
name|rw_runlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	bufspace_daemonwakeup:  *  *	Wakeup the daemon responsible for freeing clean bufs.  */
end_comment

begin_function
specifier|static
name|void
name|bufspace_daemonwakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|rw_rlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
if|if
condition|(
name|bufspace_request
operator|==
literal|0
condition|)
block|{
name|bufspace_request
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|bufspace_request
argument_list|)
expr_stmt|;
block|}
name|rw_runlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufspace_adjust:  *  *	Adjust the reported bufspace for a KVA managed buffer, possibly  * 	waking any waiters.  */
end_comment

begin_function
specifier|static
name|void
name|bufspace_adjust
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|bufsize
parameter_list|)
block|{
name|long
name|space
decl_stmt|;
name|int
name|diff
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"bufspace_adjust: malloc buf %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|diff
operator|=
name|bufsize
operator|-
name|bp
operator|->
name|b_bufsize
expr_stmt|;
if|if
condition|(
name|diff
operator|<
literal|0
condition|)
block|{
name|atomic_subtract_long
argument_list|(
operator|&
name|bufspace
argument_list|,
operator|-
name|diff
argument_list|)
expr_stmt|;
name|bufspace_wakeup
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|space
operator|=
name|atomic_fetchadd_long
argument_list|(
operator|&
name|bufspace
argument_list|,
name|diff
argument_list|)
expr_stmt|;
comment|/* Wake up the daemon on the transition. */
if|if
condition|(
name|space
operator|<
name|bufspacethresh
operator|&&
name|space
operator|+
name|diff
operator|>=
name|bufspacethresh
condition|)
name|bufspace_daemonwakeup
argument_list|()
expr_stmt|;
block|}
name|bp
operator|->
name|b_bufsize
operator|=
name|bufsize
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufspace_reserve:  *  *	Reserve bufspace before calling allocbuf().  metadata has a  *	different space limit than data.  */
end_comment

begin_function
specifier|static
name|int
name|bufspace_reserve
parameter_list|(
name|int
name|size
parameter_list|,
name|bool
name|metadata
parameter_list|)
block|{
name|long
name|limit
decl_stmt|;
name|long
name|space
decl_stmt|;
if|if
condition|(
name|metadata
condition|)
name|limit
operator|=
name|maxbufspace
expr_stmt|;
else|else
name|limit
operator|=
name|hibufspace
expr_stmt|;
do|do
block|{
name|space
operator|=
name|bufspace
expr_stmt|;
if|if
condition|(
name|space
operator|+
name|size
operator|>
name|limit
condition|)
return|return
operator|(
name|ENOSPC
operator|)
return|;
block|}
do|while
condition|(
name|atomic_cmpset_long
argument_list|(
operator|&
name|bufspace
argument_list|,
name|space
argument_list|,
name|space
operator|+
name|size
argument_list|)
operator|==
literal|0
condition|)
do|;
comment|/* Wake up the daemon on the transition. */
if|if
condition|(
name|space
operator|<
name|bufspacethresh
operator|&&
name|space
operator|+
name|size
operator|>=
name|bufspacethresh
condition|)
name|bufspace_daemonwakeup
argument_list|()
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	bufspace_release:  *  *	Release reserved bufspace after bufspace_adjust() has consumed it.  */
end_comment

begin_function
specifier|static
name|void
name|bufspace_release
parameter_list|(
name|int
name|size
parameter_list|)
block|{
name|atomic_subtract_long
argument_list|(
operator|&
name|bufspace
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|bufspace_wakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufspace_wait:  *  *	Wait for bufspace, acting as the buf daemon if a locked vnode is  *	supplied.  needsbuffer must be set in a safe fashion prior to  *	polling for space.  The operation must be re-tried on return.  */
end_comment

begin_function
specifier|static
name|void
name|bufspace_wait
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
name|gbflags
parameter_list|,
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|int
name|error
decl_stmt|,
name|fl
decl_stmt|,
name|norunbuf
decl_stmt|;
if|if
condition|(
operator|(
name|gbflags
operator|&
name|GB_NOWAIT_BD
operator|)
operator|!=
literal|0
condition|)
return|return;
name|td
operator|=
name|curthread
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
while|while
condition|(
name|needsbuffer
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|vp
operator|!=
name|NULL
operator|&&
name|vp
operator|->
name|v_type
operator|!=
name|VCHR
operator|&&
operator|(
name|td
operator|->
name|td_pflags
operator|&
name|TDP_BUFNEED
operator|)
operator|==
literal|0
condition|)
block|{
name|rw_wunlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
comment|/* 			 * getblk() is called with a vnode locked, and 			 * some majority of the dirty buffers may as 			 * well belong to the vnode.  Flushing the 			 * buffers there would make a progress that 			 * cannot be achieved by the buf_daemon, that 			 * cannot lock the vnode. 			 */
name|norunbuf
operator|=
operator|~
operator|(
name|TDP_BUFNEED
operator||
name|TDP_NORUNNINGBUF
operator|)
operator||
operator|(
name|td
operator|->
name|td_pflags
operator|&
name|TDP_NORUNNINGBUF
operator|)
expr_stmt|;
comment|/* 			 * Play bufdaemon.  The getnewbuf() function 			 * may be called while the thread owns lock 			 * for another dirty buffer for the same 			 * vnode, which makes it impossible to use 			 * VOP_FSYNC() there, due to the buffer lock 			 * recursion. 			 */
name|td
operator|->
name|td_pflags
operator||=
name|TDP_BUFNEED
operator||
name|TDP_NORUNNINGBUF
expr_stmt|;
name|fl
operator|=
name|buf_flush
argument_list|(
name|vp
argument_list|,
name|flushbufqtarget
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_pflags
operator|&=
name|norunbuf
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
if|if
condition|(
name|fl
operator|!=
literal|0
condition|)
continue|continue;
if|if
condition|(
name|needsbuffer
operator|==
literal|0
condition|)
break|break;
block|}
name|error
operator|=
name|rw_sleep
argument_list|(
name|__DEVOLATILE
argument_list|(
name|void
operator|*
argument_list|,
operator|&
name|needsbuffer
argument_list|)
argument_list|,
operator|&
name|nblock
argument_list|,
operator|(
name|PRIBIO
operator|+
literal|4
operator|)
operator||
name|slpflag
argument_list|,
literal|"newbuf"
argument_list|,
name|slptimeo
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
break|break;
block|}
name|rw_wunlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufspace_daemon:  *  *	buffer space management daemon.  Tries to maintain some marginal  *	amount of free buffer space so that requesting processes neither  *	block nor work to reclaim buffers.  */
end_comment

begin_function
specifier|static
name|void
name|bufspace_daemon
parameter_list|(
name|void
parameter_list|)
block|{
for|for
control|(
init|;
condition|;
control|)
block|{
name|kproc_suspend_check
argument_list|(
name|bufspacedaemonproc
argument_list|)
expr_stmt|;
comment|/* 		 * Free buffers from the clean queue until we meet our 		 * targets. 		 * 		 * Theory of operation:  The buffer cache is most efficient 		 * when some free buffer headers and space are always 		 * available to getnewbuf().  This daemon attempts to prevent 		 * the excessive blocking and synchronization associated 		 * with shortfall.  It goes through three phases according 		 * demand: 		 * 		 * 1)	The daemon wakes up voluntarily once per-second 		 *	during idle periods when the counters are below 		 *	the wakeup thresholds (bufspacethresh, lofreebuffers). 		 * 		 * 2)	The daemon wakes up as we cross the thresholds 		 *	ahead of any potential blocking.  This may bounce 		 *	slightly according to the rate of consumption and 		 *	release. 		 * 		 * 3)	The daemon and consumers are starved for working 		 *	clean buffers.  This is the 'bufspace' sleep below 		 *	which will inefficiently trade bufs with bqrelse 		 *	until we return to condition 2. 		 */
while|while
condition|(
name|bufspace
operator|>
name|lobufspace
operator|||
name|numfreebuffers
operator|<
name|hifreebuffers
condition|)
block|{
if|if
condition|(
name|buf_recycle
argument_list|(
name|false
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|atomic_set_int
argument_list|(
operator|&
name|needsbuffer
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf_recycle
argument_list|(
name|false
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|rw_wlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
if|if
condition|(
name|needsbuffer
condition|)
name|rw_sleep
argument_list|(
name|__DEVOLATILE
argument_list|(
name|void
operator|*
argument_list|,
operator|&
name|needsbuffer
argument_list|)
argument_list|,
operator|&
name|nblock
argument_list|,
name|PRIBIO
operator||
name|PDROP
argument_list|,
literal|"bufspace"
argument_list|,
name|hz
operator|/
literal|10
argument_list|)
expr_stmt|;
else|else
name|rw_wunlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
block|}
block|}
name|maybe_yield
argument_list|()
expr_stmt|;
block|}
comment|/* 		 * Re-check our limits under the exclusive nblock. 		 */
name|rw_wlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
if|if
condition|(
name|bufspace
operator|<
name|bufspacethresh
operator|&&
name|numfreebuffers
operator|>
name|lofreebuffers
condition|)
block|{
name|bufspace_request
operator|=
literal|0
expr_stmt|;
name|rw_sleep
argument_list|(
operator|&
name|bufspace_request
argument_list|,
operator|&
name|nblock
argument_list|,
name|PRIBIO
operator||
name|PDROP
argument_list|,
literal|"-"
argument_list|,
name|hz
argument_list|)
expr_stmt|;
block|}
else|else
name|rw_wunlock
argument_list|(
operator|&
name|nblock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_decl_stmt
specifier|static
name|struct
name|kproc_desc
name|bufspace_kp
init|=
block|{
literal|"bufspacedaemon"
block|,
name|bufspace_daemon
block|,
operator|&
name|bufspacedaemonproc
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSINIT
argument_list|(
name|bufspacedaemon
argument_list|,
name|SI_SUB_KTHREAD_BUF
argument_list|,
name|SI_ORDER_FIRST
argument_list|,
name|kproc_start
argument_list|,
operator|&
name|bufspace_kp
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *	bufmallocadjust:  *  *	Adjust the reported bufspace for a malloc managed buffer, possibly  *	waking any waiters.  */
end_comment

begin_function
specifier|static
name|void
name|bufmallocadjust
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|bufsize
parameter_list|)
block|{
name|int
name|diff
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"bufmallocadjust: non-malloc buf %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|diff
operator|=
name|bufsize
operator|-
name|bp
operator|->
name|b_bufsize
expr_stmt|;
if|if
condition|(
name|diff
operator|<
literal|0
condition|)
name|atomic_subtract_long
argument_list|(
operator|&
name|bufmallocspace
argument_list|,
operator|-
name|diff
argument_list|)
expr_stmt|;
else|else
name|atomic_add_long
argument_list|(
operator|&
name|bufmallocspace
argument_list|,
name|diff
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
name|bufsize
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	runningwakeup:  *  *	Wake up processes that are waiting on asynchronous writes to fall  *	below lorunningspace.  */
end_comment

begin_function
specifier|static
name|void
name|runningwakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|runningbufreq
condition|)
block|{
name|runningbufreq
operator|=
literal|0
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|runningbufreq
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	runningbufwakeup:  *  *	Decrement the outstanding write count according.  */
end_comment

begin_function
name|void
name|runningbufwakeup
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|long
name|space
decl_stmt|,
name|bspace
decl_stmt|;
name|bspace
operator|=
name|bp
operator|->
name|b_runningbufspace
expr_stmt|;
if|if
condition|(
name|bspace
operator|==
literal|0
condition|)
return|return;
name|space
operator|=
name|atomic_fetchadd_long
argument_list|(
operator|&
name|runningbufspace
argument_list|,
operator|-
name|bspace
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|space
operator|>=
name|bspace
argument_list|,
operator|(
literal|"runningbufspace underflow %ld %ld"
operator|,
name|space
operator|,
name|bspace
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_runningbufspace
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Only acquire the lock and wakeup on the transition from exceeding 	 * the threshold to falling below it. 	 */
if|if
condition|(
name|space
operator|<
name|lorunningspace
condition|)
return|return;
if|if
condition|(
name|space
operator|-
name|bspace
operator|>
name|lorunningspace
condition|)
return|return;
name|runningwakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	waitrunningbufspace()  *  *	runningbufspace is a measure of the amount of I/O currently  *	running.  This routine is used in async-write situations to  *	prevent creating huge backups of pending writes to a device.  *	Only asynchronous writes are governed by this function.  *  *	This does NOT turn an async write into a sync write.  It waits    *	for earlier writes to complete and generally returns before the  *	caller's write has reached the device.  */
end_comment

begin_function
name|void
name|waitrunningbufspace
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
while|while
condition|(
name|runningbufspace
operator|>
name|hirunningspace
condition|)
block|{
name|runningbufreq
operator|=
literal|1
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|runningbufreq
argument_list|,
operator|&
name|rbreqlock
argument_list|,
name|PVM
argument_list|,
literal|"wdrain"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|rbreqlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vfs_buf_test_cache:  *  *	Called when a buffer is extended.  This function clears the B_CACHE  *	bit if the newly extended portion of the buffer does not contain  *	valid data.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|vfs_buf_test_cache
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|foff
parameter_list|,
name|vm_offset_t
name|off
parameter_list|,
name|vm_offset_t
name|size
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
condition|)
block|{
name|int
name|base
init|=
operator|(
name|foff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
decl_stmt|;
if|if
condition|(
name|vm_page_is_valid
argument_list|(
name|m
argument_list|,
name|base
argument_list|,
name|size
argument_list|)
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/* Wake up the buffer daemon if necessary */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|bd_wakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|bd_request
operator|==
literal|0
condition|)
block|{
name|bd_request
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|bd_request
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Adjust the maxbcachbuf tunable.  */
end_comment

begin_function
specifier|static
name|void
name|maxbcachebuf_adjust
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
comment|/* 	 * maxbcachebuf must be a power of 2>= MAXBSIZE. 	 */
name|i
operator|=
literal|2
expr_stmt|;
while|while
condition|(
name|i
operator|*
literal|2
operator|<=
name|maxbcachebuf
condition|)
name|i
operator|*=
literal|2
expr_stmt|;
name|maxbcachebuf
operator|=
name|i
expr_stmt|;
if|if
condition|(
name|maxbcachebuf
operator|<
name|MAXBSIZE
condition|)
name|maxbcachebuf
operator|=
name|MAXBSIZE
expr_stmt|;
if|if
condition|(
name|maxbcachebuf
operator|>
name|MAXPHYS
condition|)
name|maxbcachebuf
operator|=
name|MAXPHYS
expr_stmt|;
if|if
condition|(
name|bootverbose
operator|!=
literal|0
operator|&&
name|maxbcachebuf
operator|!=
name|MAXBCACHEBUF
condition|)
name|printf
argument_list|(
literal|"maxbcachebuf=%d\n"
argument_list|,
name|maxbcachebuf
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * bd_speedup - speedup the buffer cache flushing code  */
end_comment

begin_function
name|void
name|bd_speedup
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|needwake
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
name|needwake
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|bd_speedupreq
operator|==
literal|0
operator|||
name|bd_request
operator|==
literal|0
condition|)
name|needwake
operator|=
literal|1
expr_stmt|;
name|bd_speedupreq
operator|=
literal|1
expr_stmt|;
name|bd_request
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|needwake
condition|)
name|wakeup
argument_list|(
operator|&
name|bd_request
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_ifndef
ifndef|#
directive|ifndef
name|NSWBUF_MIN
end_ifndef

begin_define
define|#
directive|define
name|NSWBUF_MIN
value|16
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|__i386__
end_ifdef

begin_define
define|#
directive|define
name|TRANSIENT_DENOM
value|5
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|TRANSIENT_DENOM
value|10
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Calculating buffer cache scaling values and reserve space for buffer  * headers.  This is called during low level kernel initialization and  * may be called more then once.  We CANNOT write to the memory area  * being reserved at this time.  */
end_comment

begin_function
name|caddr_t
name|kern_vfs_bio_buffer_alloc
parameter_list|(
name|caddr_t
name|v
parameter_list|,
name|long
name|physmem_est
parameter_list|)
block|{
name|int
name|tuned_nbuf
decl_stmt|;
name|long
name|maxbuf
decl_stmt|,
name|maxbuf_sz
decl_stmt|,
name|buf_sz
decl_stmt|,
name|biotmap_sz
decl_stmt|;
comment|/* 	 * physmem_est is in pages.  Convert it to kilobytes (assumes 	 * PAGE_SIZE is>= 1K) 	 */
name|physmem_est
operator|=
name|physmem_est
operator|*
operator|(
name|PAGE_SIZE
operator|/
literal|1024
operator|)
expr_stmt|;
name|maxbcachebuf_adjust
argument_list|()
expr_stmt|;
comment|/* 	 * The nominal buffer size (and minimum KVA allocation) is BKVASIZE. 	 * For the first 64MB of ram nominally allocate sufficient buffers to 	 * cover 1/4 of our ram.  Beyond the first 64MB allocate additional 	 * buffers to cover 1/10 of our ram over 64MB.  When auto-sizing 	 * the buffer cache we limit the eventual kva reservation to 	 * maxbcache bytes. 	 * 	 * factor represents the 1/4 x ram conversion. 	 */
if|if
condition|(
name|nbuf
operator|==
literal|0
condition|)
block|{
name|int
name|factor
init|=
literal|4
operator|*
name|BKVASIZE
operator|/
literal|1024
decl_stmt|;
name|nbuf
operator|=
literal|50
expr_stmt|;
if|if
condition|(
name|physmem_est
operator|>
literal|4096
condition|)
name|nbuf
operator|+=
name|min
argument_list|(
operator|(
name|physmem_est
operator|-
literal|4096
operator|)
operator|/
name|factor
argument_list|,
literal|65536
operator|/
name|factor
argument_list|)
expr_stmt|;
if|if
condition|(
name|physmem_est
operator|>
literal|65536
condition|)
name|nbuf
operator|+=
name|min
argument_list|(
operator|(
name|physmem_est
operator|-
literal|65536
operator|)
operator|*
literal|2
operator|/
operator|(
name|factor
operator|*
literal|5
operator|)
argument_list|,
literal|32
operator|*
literal|1024
operator|*
literal|1024
operator|/
operator|(
name|factor
operator|*
literal|5
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|maxbcache
operator|&&
name|nbuf
operator|>
name|maxbcache
operator|/
name|BKVASIZE
condition|)
name|nbuf
operator|=
name|maxbcache
operator|/
name|BKVASIZE
expr_stmt|;
name|tuned_nbuf
operator|=
literal|1
expr_stmt|;
block|}
else|else
name|tuned_nbuf
operator|=
literal|0
expr_stmt|;
comment|/* XXX Avoid unsigned long overflows later on with maxbufspace. */
name|maxbuf
operator|=
operator|(
name|LONG_MAX
operator|/
literal|3
operator|)
operator|/
name|BKVASIZE
expr_stmt|;
if|if
condition|(
name|nbuf
operator|>
name|maxbuf
condition|)
block|{
if|if
condition|(
operator|!
name|tuned_nbuf
condition|)
name|printf
argument_list|(
literal|"Warning: nbufs lowered from %d to %ld\n"
argument_list|,
name|nbuf
argument_list|,
name|maxbuf
argument_list|)
expr_stmt|;
name|nbuf
operator|=
name|maxbuf
expr_stmt|;
block|}
comment|/* 	 * Ideal allocation size for the transient bio submap is 10% 	 * of the maximal space buffer map.  This roughly corresponds 	 * to the amount of the buffer mapped for typical UFS load. 	 * 	 * Clip the buffer map to reserve space for the transient 	 * BIOs, if its extent is bigger than 90% (80% on i386) of the 	 * maximum buffer map extent on the platform. 	 * 	 * The fall-back to the maxbuf in case of maxbcache unset, 	 * allows to not trim the buffer KVA for the architectures 	 * with ample KVA space. 	 */
if|if
condition|(
name|bio_transient_maxcnt
operator|==
literal|0
operator|&&
name|unmapped_buf_allowed
condition|)
block|{
name|maxbuf_sz
operator|=
name|maxbcache
operator|!=
literal|0
condition|?
name|maxbcache
else|:
name|maxbuf
operator|*
name|BKVASIZE
expr_stmt|;
name|buf_sz
operator|=
operator|(
name|long
operator|)
name|nbuf
operator|*
name|BKVASIZE
expr_stmt|;
if|if
condition|(
name|buf_sz
operator|<
name|maxbuf_sz
operator|/
name|TRANSIENT_DENOM
operator|*
operator|(
name|TRANSIENT_DENOM
operator|-
literal|1
operator|)
condition|)
block|{
comment|/* 			 * There is more KVA than memory.  Do not 			 * adjust buffer map size, and assign the rest 			 * of maxbuf to transient map. 			 */
name|biotmap_sz
operator|=
name|maxbuf_sz
operator|-
name|buf_sz
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * Buffer map spans all KVA we could afford on 			 * this platform.  Give 10% (20% on i386) of 			 * the buffer map to the transient bio map. 			 */
name|biotmap_sz
operator|=
name|buf_sz
operator|/
name|TRANSIENT_DENOM
expr_stmt|;
name|buf_sz
operator|-=
name|biotmap_sz
expr_stmt|;
block|}
if|if
condition|(
name|biotmap_sz
operator|/
name|INT_MAX
operator|>
name|MAXPHYS
condition|)
name|bio_transient_maxcnt
operator|=
name|INT_MAX
expr_stmt|;
else|else
name|bio_transient_maxcnt
operator|=
name|biotmap_sz
operator|/
name|MAXPHYS
expr_stmt|;
comment|/* 		 * Artificially limit to 1024 simultaneous in-flight I/Os 		 * using the transient mapping. 		 */
if|if
condition|(
name|bio_transient_maxcnt
operator|>
literal|1024
condition|)
name|bio_transient_maxcnt
operator|=
literal|1024
expr_stmt|;
if|if
condition|(
name|tuned_nbuf
condition|)
name|nbuf
operator|=
name|buf_sz
operator|/
name|BKVASIZE
expr_stmt|;
block|}
comment|/* 	 * swbufs are used as temporary holders for I/O, such as paging I/O. 	 * We have no less then 16 and no more then 256. 	 */
name|nswbuf
operator|=
name|min
argument_list|(
name|nbuf
operator|/
literal|4
argument_list|,
literal|256
argument_list|)
expr_stmt|;
name|TUNABLE_INT_FETCH
argument_list|(
literal|"kern.nswbuf"
argument_list|,
operator|&
name|nswbuf
argument_list|)
expr_stmt|;
if|if
condition|(
name|nswbuf
operator|<
name|NSWBUF_MIN
condition|)
name|nswbuf
operator|=
name|NSWBUF_MIN
expr_stmt|;
comment|/* 	 * Reserve space for the buffer cache buffers 	 */
name|swbuf
operator|=
operator|(
name|void
operator|*
operator|)
name|v
expr_stmt|;
name|v
operator|=
call|(
name|caddr_t
call|)
argument_list|(
name|swbuf
operator|+
name|nswbuf
argument_list|)
expr_stmt|;
name|buf
operator|=
operator|(
name|void
operator|*
operator|)
name|v
expr_stmt|;
name|v
operator|=
call|(
name|caddr_t
call|)
argument_list|(
name|buf
operator|+
name|nbuf
argument_list|)
expr_stmt|;
return|return
operator|(
name|v
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Initialize the buffer subsystem.  Called before use of any buffers. */
end_comment

begin_function
name|void
name|bufinit
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|i
decl_stmt|;
name|KASSERT
argument_list|(
name|maxbcachebuf
operator|>=
name|MAXBSIZE
argument_list|,
operator|(
literal|"maxbcachebuf (%d) must be>= MAXBSIZE (%d)\n"
operator|,
name|maxbcachebuf
operator|,
name|MAXBSIZE
operator|)
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|bqlocks
index|[
name|QUEUE_DIRTY
index|]
argument_list|,
literal|"bufq dirty lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|bqlocks
index|[
name|QUEUE_EMPTY
index|]
argument_list|,
literal|"bufq empty lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|QUEUE_CLEAN
init|;
name|i
operator|<
name|QUEUE_CLEAN
operator|+
name|CLEAN_QUEUES
condition|;
name|i
operator|++
control|)
name|mtx_init
argument_list|(
operator|&
name|bqlocks
index|[
name|i
index|]
argument_list|,
literal|"bufq clean lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|rbreqlock
argument_list|,
literal|"runningbufspace lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|rw_init
argument_list|(
operator|&
name|nblock
argument_list|,
literal|"needsbuffer lock"
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|bdlock
argument_list|,
literal|"buffer daemon lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|bdirtylock
argument_list|,
literal|"dirty buf lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* next, make a null set of free lists */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|BUFFER_QUEUES
condition|;
name|i
operator|++
control|)
name|TAILQ_INIT
argument_list|(
operator|&
name|bufqueues
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|unmapped_buf
operator|=
operator|(
name|caddr_t
operator|)
name|kva_alloc
argument_list|(
name|MAXPHYS
argument_list|)
expr_stmt|;
comment|/* finally, initialize each buffer header and stick on empty q */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nbuf
condition|;
name|i
operator|++
control|)
block|{
name|bp
operator|=
operator|&
name|buf
index|[
name|i
index|]
expr_stmt|;
name|bzero
argument_list|(
name|bp
argument_list|,
sizeof|sizeof
expr|*
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|=
name|B_INVAL
expr_stmt|;
name|bp
operator|->
name|b_rcred
operator|=
name|NOCRED
expr_stmt|;
name|bp
operator|->
name|b_wcred
operator|=
name|NOCRED
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|bp
operator|->
name|b_xflags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
operator|=
name|unmapped_buf
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
expr_stmt|;
name|BUF_LOCKINIT
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTY
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|INVARIANTS
name|bq_len
index|[
name|QUEUE_EMPTY
index|]
operator|++
expr_stmt|;
endif|#
directive|endif
block|}
comment|/* 	 * maxbufspace is the absolute maximum amount of buffer space we are  	 * allowed to reserve in KVM and in real terms.  The absolute maximum 	 * is nominally used by metadata.  hibufspace is the nominal maximum 	 * used by most other requests.  The differential is required to  	 * ensure that metadata deadlocks don't occur. 	 * 	 * maxbufspace is based on BKVASIZE.  Allocating buffers larger then 	 * this may result in KVM fragmentation which is not handled optimally 	 * by the system. XXX This is less true with vmem.  We could use 	 * PAGE_SIZE. 	 */
name|maxbufspace
operator|=
operator|(
name|long
operator|)
name|nbuf
operator|*
name|BKVASIZE
expr_stmt|;
name|hibufspace
operator|=
name|lmax
argument_list|(
literal|3
operator|*
name|maxbufspace
operator|/
literal|4
argument_list|,
name|maxbufspace
operator|-
name|maxbcachebuf
operator|*
literal|10
argument_list|)
expr_stmt|;
name|lobufspace
operator|=
operator|(
name|hibufspace
operator|/
literal|20
operator|)
operator|*
literal|19
expr_stmt|;
comment|/* 95% */
name|bufspacethresh
operator|=
name|lobufspace
operator|+
operator|(
name|hibufspace
operator|-
name|lobufspace
operator|)
operator|/
literal|2
expr_stmt|;
comment|/* 	 * Note: The 16 MiB upper limit for hirunningspace was chosen 	 * arbitrarily and may need further tuning. It corresponds to 	 * 128 outstanding write IO requests (if IO size is 128 KiB), 	 * which fits with many RAID controllers' tagged queuing limits. 	 * The lower 1 MiB limit is the historical upper limit for 	 * hirunningspace. 	 */
name|hirunningspace
operator|=
name|lmax
argument_list|(
name|lmin
argument_list|(
name|roundup
argument_list|(
name|hibufspace
operator|/
literal|64
argument_list|,
name|maxbcachebuf
argument_list|)
argument_list|,
literal|16
operator|*
literal|1024
operator|*
literal|1024
argument_list|)
argument_list|,
literal|1024
operator|*
literal|1024
argument_list|)
expr_stmt|;
name|lorunningspace
operator|=
name|roundup
argument_list|(
operator|(
name|hirunningspace
operator|*
literal|2
operator|)
operator|/
literal|3
argument_list|,
name|maxbcachebuf
argument_list|)
expr_stmt|;
comment|/* 	 * Limit the amount of malloc memory since it is wired permanently into 	 * the kernel space.  Even though this is accounted for in the buffer 	 * allocation, we don't want the malloced region to grow uncontrolled. 	 * The malloc scheme improves memory utilization significantly on 	 * average (small) directories. 	 */
name|maxbufmallocspace
operator|=
name|hibufspace
operator|/
literal|20
expr_stmt|;
comment|/* 	 * Reduce the chance of a deadlock occurring by limiting the number 	 * of delayed-write dirty buffers we allow to stack up. 	 */
name|hidirtybuffers
operator|=
name|nbuf
operator|/
literal|4
operator|+
literal|20
expr_stmt|;
name|dirtybufthresh
operator|=
name|hidirtybuffers
operator|*
literal|9
operator|/
literal|10
expr_stmt|;
name|numdirtybuffers
operator|=
literal|0
expr_stmt|;
comment|/* 	 * To support extreme low-memory systems, make sure hidirtybuffers 	 * cannot eat up all available buffer space.  This occurs when our 	 * minimum cannot be met.  We try to size hidirtybuffers to 3/4 our 	 * buffer space assuming BKVASIZE'd buffers. 	 */
while|while
condition|(
operator|(
name|long
operator|)
name|hidirtybuffers
operator|*
name|BKVASIZE
operator|>
literal|3
operator|*
name|hibufspace
operator|/
literal|4
condition|)
block|{
name|hidirtybuffers
operator|>>=
literal|1
expr_stmt|;
block|}
name|lodirtybuffers
operator|=
name|hidirtybuffers
operator|/
literal|2
expr_stmt|;
comment|/* 	 * lofreebuffers should be sufficient to avoid stalling waiting on 	 * buf headers under heavy utilization.  The bufs in per-cpu caches 	 * are counted as free but will be unavailable to threads executing 	 * on other cpus. 	 * 	 * hifreebuffers is the free target for the bufspace daemon.  This 	 * should be set appropriately to limit work per-iteration. 	 */
name|lofreebuffers
operator|=
name|MIN
argument_list|(
operator|(
name|nbuf
operator|/
literal|25
operator|)
operator|+
operator|(
literal|20
operator|*
name|mp_ncpus
operator|)
argument_list|,
literal|128
operator|*
name|mp_ncpus
argument_list|)
expr_stmt|;
name|hifreebuffers
operator|=
operator|(
literal|3
operator|*
name|lofreebuffers
operator|)
operator|/
literal|2
expr_stmt|;
name|numfreebuffers
operator|=
name|nbuf
expr_stmt|;
comment|/* Setup the kva and free list allocators. */
name|vmem_set_reclaim
argument_list|(
name|buffer_arena
argument_list|,
name|bufkva_reclaim
argument_list|)
expr_stmt|;
name|buf_zone
operator|=
name|uma_zcache_create
argument_list|(
literal|"buf free cache"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|buf
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|buf_import
argument_list|,
name|buf_release
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * Size the clean queue according to the amount of buffer space. 	 * One queue per-256mb up to the max.  More queues gives better 	 * concurrency but less accurate LRU. 	 */
name|clean_queues
operator|=
name|MIN
argument_list|(
name|howmany
argument_list|(
name|maxbufspace
argument_list|,
literal|256
operator|*
literal|1024
operator|*
literal|1024
argument_list|)
argument_list|,
name|CLEAN_QUEUES
argument_list|)
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|INVARIANTS
end_ifdef

begin_function
specifier|static
specifier|inline
name|void
name|vfs_buf_check_mapped
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_kvabase
operator|!=
name|unmapped_buf
argument_list|,
operator|(
literal|"mapped buf: b_kvabase was not updated %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_data
operator|!=
name|unmapped_buf
argument_list|,
operator|(
literal|"mapped buf: b_data was not updated %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_data
operator|<
name|unmapped_buf
operator|||
name|bp
operator|->
name|b_data
operator|>=
name|unmapped_buf
operator|+
name|MAXPHYS
argument_list|,
operator|(
literal|"b_data + b_offset unmapped %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
specifier|inline
name|void
name|vfs_buf_check_unmapped
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_data
operator|==
name|unmapped_buf
argument_list|,
operator|(
literal|"unmapped buf: corrupted b_data %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_define
define|#
directive|define
name|BUF_CHECK_MAPPED
parameter_list|(
name|bp
parameter_list|)
value|vfs_buf_check_mapped(bp)
end_define

begin_define
define|#
directive|define
name|BUF_CHECK_UNMAPPED
parameter_list|(
name|bp
parameter_list|)
value|vfs_buf_check_unmapped(bp)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|BUF_CHECK_MAPPED
parameter_list|(
name|bp
parameter_list|)
value|do {} while (0)
end_define

begin_define
define|#
directive|define
name|BUF_CHECK_UNMAPPED
parameter_list|(
name|bp
parameter_list|)
value|do {} while (0)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|int
name|isbufbusy
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
if|if
condition|(
operator|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|==
literal|0
operator|&&
name|BUF_ISLOCKED
argument_list|(
name|bp
argument_list|)
operator|)
operator|||
operator|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_DELWRI
operator||
name|B_INVAL
operator|)
operator|)
operator|==
name|B_DELWRI
operator|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Shutdown the system cleanly to prepare for reboot, halt, or power off.  */
end_comment

begin_function
name|void
name|bufshutdown
parameter_list|(
name|int
name|show_busybufs
parameter_list|)
block|{
specifier|static
name|int
name|first_buf_printf
init|=
literal|1
decl_stmt|;
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|iter
decl_stmt|,
name|nbusy
decl_stmt|,
name|pbusy
decl_stmt|;
ifndef|#
directive|ifndef
name|PREEMPTION
name|int
name|subiter
decl_stmt|;
endif|#
directive|endif
comment|/*  	 * Sync filesystems for shutdown 	 */
name|wdog_kern_pat
argument_list|(
name|WD_LASTVAL
argument_list|)
expr_stmt|;
name|sys_sync
argument_list|(
name|curthread
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 	 * With soft updates, some buffers that are 	 * written will be remarked as dirty until other 	 * buffers are written. 	 */
for|for
control|(
name|iter
operator|=
name|pbusy
operator|=
literal|0
init|;
name|iter
operator|<
literal|20
condition|;
name|iter
operator|++
control|)
block|{
name|nbusy
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|bp
operator|=
operator|&
name|buf
index|[
name|nbuf
index|]
init|;
operator|--
name|bp
operator|>=
name|buf
condition|;
control|)
if|if
condition|(
name|isbufbusy
argument_list|(
name|bp
argument_list|)
condition|)
name|nbusy
operator|++
expr_stmt|;
if|if
condition|(
name|nbusy
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|first_buf_printf
condition|)
name|printf
argument_list|(
literal|"All buffers synced."
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|first_buf_printf
condition|)
block|{
name|printf
argument_list|(
literal|"Syncing disks, buffers remaining... "
argument_list|)
expr_stmt|;
name|first_buf_printf
operator|=
literal|0
expr_stmt|;
block|}
name|printf
argument_list|(
literal|"%d "
argument_list|,
name|nbusy
argument_list|)
expr_stmt|;
if|if
condition|(
name|nbusy
operator|<
name|pbusy
condition|)
name|iter
operator|=
literal|0
expr_stmt|;
name|pbusy
operator|=
name|nbusy
expr_stmt|;
name|wdog_kern_pat
argument_list|(
name|WD_LASTVAL
argument_list|)
expr_stmt|;
name|sys_sync
argument_list|(
name|curthread
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|PREEMPTION
comment|/* 		 * Drop Giant and spin for a while to allow 		 * interrupt threads to run. 		 */
name|DROP_GIANT
argument_list|()
expr_stmt|;
name|DELAY
argument_list|(
literal|50000
operator|*
name|iter
argument_list|)
expr_stmt|;
name|PICKUP_GIANT
argument_list|()
expr_stmt|;
else|#
directive|else
comment|/* 		 * Drop Giant and context switch several times to 		 * allow interrupt threads to run. 		 */
name|DROP_GIANT
argument_list|()
expr_stmt|;
for|for
control|(
name|subiter
operator|=
literal|0
init|;
name|subiter
operator|<
literal|50
operator|*
name|iter
condition|;
name|subiter
operator|++
control|)
block|{
name|thread_lock
argument_list|(
name|curthread
argument_list|)
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_VOL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|curthread
argument_list|)
expr_stmt|;
name|DELAY
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
block|}
name|PICKUP_GIANT
argument_list|()
expr_stmt|;
endif|#
directive|endif
block|}
name|printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
comment|/* 	 * Count only busy local buffers to prevent forcing  	 * a fsck if we're just a client of a wedged NFS server 	 */
name|nbusy
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|bp
operator|=
operator|&
name|buf
index|[
name|nbuf
index|]
init|;
operator|--
name|bp
operator|>=
name|buf
condition|;
control|)
block|{
if|if
condition|(
name|isbufbusy
argument_list|(
name|bp
argument_list|)
condition|)
block|{
if|#
directive|if
literal|0
comment|/* XXX: This is bogus.  We should probably have a BO_REMOTE flag instead */
block|if (bp->b_dev == NULL) { 				TAILQ_REMOVE(&mountlist, 				    bp->b_vp->v_mount, mnt_list); 				continue; 			}
endif|#
directive|endif
name|nbusy
operator|++
expr_stmt|;
if|if
condition|(
name|show_busybufs
operator|>
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"%d: buf:%p, vnode:%p, flags:%0x, blkno:%jd, lblkno:%jd, buflock:"
argument_list|,
name|nbusy
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_blkno
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_lblkno
argument_list|)
expr_stmt|;
name|BUF_LOCKPRINTINFO
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|show_busybufs
operator|>
literal|1
condition|)
name|vn_printf
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
literal|"vnode content: "
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|nbusy
condition|)
block|{
comment|/* 		 * Failed to sync all blocks. Indicate this and don't 		 * unmount filesystems (thus forcing an fsck on reboot). 		 */
name|printf
argument_list|(
literal|"Giving up on %d buffers\n"
argument_list|,
name|nbusy
argument_list|)
expr_stmt|;
name|DELAY
argument_list|(
literal|5000000
argument_list|)
expr_stmt|;
comment|/* 5 seconds */
block|}
else|else
block|{
if|if
condition|(
operator|!
name|first_buf_printf
condition|)
name|printf
argument_list|(
literal|"Final sync complete\n"
argument_list|)
expr_stmt|;
comment|/* 		 * Unmount filesystems 		 */
if|if
condition|(
name|panicstr
operator|==
name|NULL
condition|)
name|vfs_unmountall
argument_list|()
expr_stmt|;
block|}
name|swapoff_all
argument_list|()
expr_stmt|;
name|DELAY
argument_list|(
literal|100000
argument_list|)
expr_stmt|;
comment|/* wait for console output to finish */
block|}
end_function

begin_function
specifier|static
name|void
name|bpmap_qenter
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * bp->b_data is relative to bp->b_offset, but 	 * bp->b_offset may be offset into the first page. 	 */
name|bp
operator|->
name|b_data
operator|=
operator|(
name|caddr_t
operator|)
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
call|(
name|caddr_t
call|)
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator||
call|(
name|vm_offset_t
call|)
argument_list|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	binsfree:  *  *	Insert the buffer into the appropriate free list.  */
end_comment

begin_function
specifier|static
name|void
name|binsfree
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|qindex
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|olock
decl_stmt|,
modifier|*
name|nlock
decl_stmt|;
if|if
condition|(
name|qindex
operator|!=
name|QUEUE_EMPTY
condition|)
block|{
name|BUF_ASSERT_XLOCKED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Stick to the same clean queue for the lifetime of the buf to 	 * limit locking below.  Otherwise pick ont sequentially. 	 */
if|if
condition|(
name|qindex
operator|==
name|QUEUE_CLEAN
condition|)
block|{
if|if
condition|(
name|bqisclean
argument_list|(
name|bp
operator|->
name|b_qindex
argument_list|)
condition|)
name|qindex
operator|=
name|bp
operator|->
name|b_qindex
expr_stmt|;
else|else
name|qindex
operator|=
name|bqcleanq
argument_list|()
expr_stmt|;
block|}
comment|/* 	 * Handle delayed bremfree() processing. 	 */
name|nlock
operator|=
name|bqlock
argument_list|(
name|qindex
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
condition|)
block|{
name|olock
operator|=
name|bqlock
argument_list|(
name|bp
operator|->
name|b_qindex
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|olock
argument_list|)
expr_stmt|;
name|bremfreel
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|olock
operator|!=
name|nlock
condition|)
block|{
name|mtx_unlock
argument_list|(
name|olock
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|nlock
argument_list|)
expr_stmt|;
block|}
block|}
else|else
name|mtx_lock
argument_list|(
name|nlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
condition|)
name|panic
argument_list|(
literal|"binsfree: free buffer onto another queue???"
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|qindex
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_AGE
condition|)
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|INVARIANTS
name|bq_len
index|[
name|bp
operator|->
name|b_qindex
index|]
operator|++
expr_stmt|;
endif|#
directive|endif
name|mtx_unlock
argument_list|(
name|nlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * buf_free:  *  *	Free a buffer to the buf zone once it no longer has valid contents.  */
end_comment

begin_function
specifier|static
name|void
name|buf_free
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
condition|)
name|bremfreef
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
condition|)
name|panic
argument_list|(
literal|"losing buffer 1"
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_rcred
operator|!=
name|NOCRED
condition|)
block|{
name|crfree
argument_list|(
name|bp
operator|->
name|b_rcred
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_rcred
operator|=
name|NOCRED
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_wcred
operator|!=
name|NOCRED
condition|)
block|{
name|crfree
argument_list|(
name|bp
operator|->
name|b_wcred
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_wcred
operator|=
name|NOCRED
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
condition|)
name|buf_deallocate
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bufkva_free
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|uma_zfree
argument_list|(
name|buf_zone
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|numfreebuffers
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|bufspace_wakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * buf_import:  *  *	Import bufs into the uma cache from the buf list.  The system still  *	expects a static array of bufs and much of the synchronization  *	around bufs assumes type stable storage.  As a result, UMA is used  *	only as a per-cpu cache of bufs still maintained on a global list.  */
end_comment

begin_function
specifier|static
name|int
name|buf_import
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|void
modifier|*
modifier|*
name|store
parameter_list|,
name|int
name|cnt
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|i
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bqlocks
index|[
name|QUEUE_EMPTY
index|]
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|cnt
condition|;
name|i
operator|++
control|)
block|{
name|bp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTY
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|==
name|NULL
condition|)
break|break;
name|bremfreel
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|store
index|[
name|i
index|]
operator|=
name|bp
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|bqlocks
index|[
name|QUEUE_EMPTY
index|]
argument_list|)
expr_stmt|;
return|return
operator|(
name|i
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * buf_release:  *  *	Release bufs from the uma cache back to the buffer queues.  */
end_comment

begin_function
specifier|static
name|void
name|buf_release
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|void
modifier|*
modifier|*
name|store
parameter_list|,
name|int
name|cnt
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|cnt
condition|;
name|i
operator|++
control|)
name|binsfree
argument_list|(
name|store
index|[
name|i
index|]
argument_list|,
name|QUEUE_EMPTY
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * buf_alloc:  *  *	Allocate an empty buffer header.  */
end_comment

begin_function
specifier|static
name|struct
name|buf
modifier|*
name|buf_alloc
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|bp
operator|=
name|uma_zalloc
argument_list|(
name|buf_zone
argument_list|,
name|M_NOWAIT
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|==
name|NULL
condition|)
block|{
name|bufspace_daemonwakeup
argument_list|()
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|numbufallocfails
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
comment|/* 	 * Wake-up the bufspace daemon on transition. 	 */
if|if
condition|(
name|atomic_fetchadd_int
argument_list|(
operator|&
name|numfreebuffers
argument_list|,
operator|-
literal|1
argument_list|)
operator|==
name|lofreebuffers
condition|)
name|bufspace_daemonwakeup
argument_list|()
expr_stmt|;
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|NULL
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"getnewbuf_empty: Locked buf %p on free queue."
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_vp
operator|==
name|NULL
argument_list|,
operator|(
literal|"bp: %p still has vnode %p."
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_vp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_DELWRI
operator||
name|B_NOREUSE
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"invalid buffer %p flags %#x"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_flags
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_xflags
operator|&
operator|(
name|BX_VNCLEAN
operator||
name|BX_VNDIRTY
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"bp: %p still on a buffer list. xflags %X"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_xflags
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_npages
operator|==
literal|0
argument_list|,
operator|(
literal|"bp: %p still has %d vm pages\n"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_npages
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_kvasize
operator|==
literal|0
argument_list|,
operator|(
literal|"bp: %p still has kva\n"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
argument_list|,
operator|(
literal|"bp: %p still has bufspace\n"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_xflags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_vflags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_vp
operator|=
name|NULL
expr_stmt|;
name|bp
operator|->
name|b_blkno
operator|=
name|bp
operator|->
name|b_lblkno
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_offset
operator|=
name|NOOFFSET
expr_stmt|;
name|bp
operator|->
name|b_iodone
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_error
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_bcount
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_npages
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_dirtyoff
operator|=
name|bp
operator|->
name|b_dirtyend
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_bufobj
operator|=
name|NULL
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
operator|=
name|unmapped_buf
expr_stmt|;
name|bp
operator|->
name|b_fsprivate1
operator|=
name|NULL
expr_stmt|;
name|bp
operator|->
name|b_fsprivate2
operator|=
name|NULL
expr_stmt|;
name|bp
operator|->
name|b_fsprivate3
operator|=
name|NULL
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	buf_qrecycle:  *  *	Free a buffer from the given bufqueue.  kva controls whether the  *	freed buf must own some kva resources.  This is used for  *	defragmenting.  */
end_comment

begin_function
specifier|static
name|int
name|buf_qrecycle
parameter_list|(
name|int
name|qindex
parameter_list|,
name|bool
name|kva
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|,
modifier|*
name|nbp
decl_stmt|;
if|if
condition|(
name|kva
condition|)
name|atomic_add_int
argument_list|(
operator|&
name|bufdefragcnt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|nbp
operator|=
name|NULL
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bqlocks
index|[
name|qindex
index|]
argument_list|)
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|qindex
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * Run scan, possibly freeing data and/or kva mappings on the fly 	 * depending. 	 */
while|while
condition|(
operator|(
name|bp
operator|=
name|nbp
operator|)
operator|!=
name|NULL
condition|)
block|{
comment|/* 		 * Calculate next bp (we can only use it if we do not 		 * release the bqlock). 		 */
name|nbp
operator|=
name|TAILQ_NEXT
argument_list|(
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
comment|/* 		 * If we are defragging then we need a buffer with  		 * some kva to reclaim. 		 */
if|if
condition|(
name|kva
operator|&&
name|bp
operator|->
name|b_kvasize
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|NULL
argument_list|)
operator|!=
literal|0
condition|)
continue|continue;
comment|/* 		 * Skip buffers with background writes in progress. 		 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
operator|)
operator|!=
literal|0
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|==
name|qindex
argument_list|,
operator|(
literal|"getnewbuf: inconsistent queue %d bp %p"
operator|,
name|qindex
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * NOTE:  nbp is now entirely invalid.  We can only restart 		 * the scan from this point on. 		 */
name|bremfreel
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bqlocks
index|[
name|qindex
index|]
argument_list|)
expr_stmt|;
comment|/* 		 * Requeue the background write buffer with error and 		 * restart the scan. 		 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDERR
operator|)
operator|!=
literal|0
condition|)
block|{
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bqlocks
index|[
name|qindex
index|]
argument_list|)
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|qindex
index|]
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|bqlocks
index|[
name|qindex
index|]
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENOBUFS
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	buf_recycle:  *  *	Iterate through all clean queues until we find a buf to recycle or  *	exhaust the search.  */
end_comment

begin_function
specifier|static
name|int
name|buf_recycle
parameter_list|(
name|bool
name|kva
parameter_list|)
block|{
name|int
name|qindex
decl_stmt|,
name|first_qindex
decl_stmt|;
name|qindex
operator|=
name|first_qindex
operator|=
name|bqcleanq
argument_list|()
expr_stmt|;
do|do
block|{
if|if
condition|(
name|buf_qrecycle
argument_list|(
name|qindex
argument_list|,
name|kva
argument_list|)
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|if
condition|(
operator|++
name|qindex
operator|==
name|QUEUE_CLEAN
operator|+
name|clean_queues
condition|)
name|qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
block|}
do|while
condition|(
name|qindex
operator|!=
name|first_qindex
condition|)
do|;
return|return
operator|(
name|ENOBUFS
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	buf_scan:  *  *	Scan the clean queues looking for a buffer to recycle.  needsbuffer  *	is set on failure so that the caller may optionally bufspace_wait()  *	in a race-free fashion.  */
end_comment

begin_function
specifier|static
name|int
name|buf_scan
parameter_list|(
name|bool
name|defrag
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
comment|/* 	 * To avoid heavy synchronization and wakeup races we set 	 * needsbuffer and re-poll before failing.  This ensures that 	 * no frees can be missed between an unsuccessful poll and 	 * going to sleep in a synchronized fashion. 	 */
if|if
condition|(
operator|(
name|error
operator|=
name|buf_recycle
argument_list|(
name|defrag
argument_list|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|atomic_set_int
argument_list|(
operator|&
name|needsbuffer
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|bufspace_daemonwakeup
argument_list|()
expr_stmt|;
name|error
operator|=
name|buf_recycle
argument_list|(
name|defrag
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|error
operator|==
literal|0
condition|)
name|atomic_add_int
argument_list|(
operator|&
name|getnewbufrestarts
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	bremfree:  *  *	Mark the buffer for removal from the appropriate free list.  *	  */
end_comment

begin_function
name|void
name|bremfree
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bremfree(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"bremfree: buffer %p already marked for delayed removal."
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bremfree: buffer %p not on a queue."
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_XLOCKED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_REMFREE
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bremfreef:  *  *	Force an immediate removal from a free list.  Used only in nfs when  *	it abuses the b_freelist pointer.  */
end_comment

begin_function
name|void
name|bremfreef
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|qlock
decl_stmt|;
name|qlock
operator|=
name|bqlock
argument_list|(
name|bp
operator|->
name|b_qindex
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|qlock
argument_list|)
expr_stmt|;
name|bremfreel
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|qlock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bremfreel:  *  *	Removes a buffer from the free list, must be called with the  *	correct qlock held.  */
end_comment

begin_function
specifier|static
name|void
name|bremfreel
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bremfreel(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bremfreel: buffer %p not on a queue."
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_EMPTY
condition|)
block|{
name|BUF_ASSERT_XLOCKED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|mtx_assert
argument_list|(
name|bqlock
argument_list|(
name|bp
operator|->
name|b_qindex
argument_list|)
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|INVARIANTS
name|KASSERT
argument_list|(
name|bq_len
index|[
name|bp
operator|->
name|b_qindex
index|]
operator|>=
literal|1
argument_list|,
operator|(
literal|"queue %d underflow"
operator|,
name|bp
operator|->
name|b_qindex
operator|)
argument_list|)
expr_stmt|;
name|bq_len
index|[
name|bp
operator|->
name|b_qindex
index|]
operator|--
expr_stmt|;
endif|#
directive|endif
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_NONE
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_REMFREE
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufkva_free:  *  *	Free the kva allocation for a buffer.  *  */
end_comment

begin_function
specifier|static
name|void
name|bufkva_free
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|INVARIANTS
if|if
condition|(
name|bp
operator|->
name|b_kvasize
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_kvabase
operator|==
name|unmapped_buf
operator|&&
name|bp
operator|->
name|b_data
operator|==
name|unmapped_buf
argument_list|,
operator|(
literal|"Leaked KVA space on %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|buf_mapped
argument_list|(
name|bp
argument_list|)
condition|)
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
else|else
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|bp
operator|->
name|b_kvasize
operator|==
literal|0
condition|)
return|return;
name|vmem_free
argument_list|(
name|buffer_arena
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_kvabase
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
name|atomic_subtract_long
argument_list|(
operator|&
name|bufkvaspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|buffreekvacnt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
operator|=
name|unmapped_buf
expr_stmt|;
name|bp
operator|->
name|b_kvasize
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufkva_alloc:  *  *	Allocate the buffer KVA and set b_kvasize and b_kvabase.  */
end_comment

begin_function
specifier|static
name|int
name|bufkva_alloc
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|maxsize
parameter_list|,
name|int
name|gbflags
parameter_list|)
block|{
name|vm_offset_t
name|addr
decl_stmt|;
name|int
name|error
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|gbflags
operator|&
name|GB_UNMAPPED
operator|)
operator|==
literal|0
operator|||
operator|(
name|gbflags
operator|&
name|GB_KVAALLOC
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"Invalid gbflags 0x%x in %s"
operator|,
name|gbflags
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|bufkva_free
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|addr
operator|=
literal|0
expr_stmt|;
name|error
operator|=
name|vmem_alloc
argument_list|(
name|buffer_arena
argument_list|,
name|maxsize
argument_list|,
name|M_BESTFIT
operator||
name|M_NOWAIT
argument_list|,
operator|&
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * Buffer map is too fragmented.  Request the caller 		 * to defragment the map. 		 */
return|return
operator|(
name|error
operator|)
return|;
block|}
name|bp
operator|->
name|b_kvabase
operator|=
operator|(
name|caddr_t
operator|)
name|addr
expr_stmt|;
name|bp
operator|->
name|b_kvasize
operator|=
name|maxsize
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|bufkvaspace
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|gbflags
operator|&
name|GB_UNMAPPED
operator|)
operator|!=
literal|0
condition|)
block|{
name|bp
operator|->
name|b_data
operator|=
name|unmapped_buf
expr_stmt|;
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	bufkva_reclaim:  *  *	Reclaim buffer kva by freeing buffers holding kva.  This is a vmem  *	callback that fires to avoid returning failure.  */
end_comment

begin_function
specifier|static
name|void
name|bufkva_reclaim
parameter_list|(
name|vmem_t
modifier|*
name|vmem
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|5
condition|;
name|i
operator|++
control|)
if|if
condition|(
name|buf_scan
argument_list|(
name|true
argument_list|)
operator|!=
literal|0
condition|)
break|break;
return|return;
block|}
end_function

begin_comment
comment|/*  * Attempt to initiate asynchronous I/O on read-ahead blocks.  We must  * clear BIO_ERROR and B_INVAL prior to initiating I/O . If B_CACHE is set,  * the buffer is valid and we do not have to do anything.  */
end_comment

begin_function
name|void
name|breada
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
modifier|*
name|rablkno
parameter_list|,
name|int
modifier|*
name|rabsize
parameter_list|,
name|int
name|cnt
parameter_list|,
name|struct
name|ucred
modifier|*
name|cred
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|rabp
decl_stmt|;
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|cnt
condition|;
name|i
operator|++
operator|,
name|rablkno
operator|++
operator|,
name|rabsize
operator|++
control|)
block|{
if|if
condition|(
name|inmem
argument_list|(
name|vp
argument_list|,
operator|*
name|rablkno
argument_list|)
condition|)
continue|continue;
name|rabp
operator|=
name|getblk
argument_list|(
name|vp
argument_list|,
operator|*
name|rablkno
argument_list|,
operator|*
name|rabsize
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|rabp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|TD_IS_IDLETHREAD
argument_list|(
name|curthread
argument_list|)
condition|)
block|{
ifdef|#
directive|ifdef
name|RACCT
if|if
condition|(
name|racct_enable
condition|)
block|{
name|PROC_LOCK
argument_list|(
name|curproc
argument_list|)
expr_stmt|;
name|racct_add_buf
argument_list|(
name|curproc
argument_list|,
name|rabp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|curproc
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* RACCT */
name|curthread
operator|->
name|td_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
block|}
name|rabp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
name|rabp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INVAL
expr_stmt|;
name|rabp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|rabp
operator|->
name|b_iocmd
operator|=
name|BIO_READ
expr_stmt|;
if|if
condition|(
name|rabp
operator|->
name|b_rcred
operator|==
name|NOCRED
operator|&&
name|cred
operator|!=
name|NOCRED
condition|)
name|rabp
operator|->
name|b_rcred
operator|=
name|crhold
argument_list|(
name|cred
argument_list|)
expr_stmt|;
name|vfs_busy_pages
argument_list|(
name|rabp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|BUF_KERNPROC
argument_list|(
name|rabp
argument_list|)
expr_stmt|;
name|rabp
operator|->
name|b_iooffset
operator|=
name|dbtob
argument_list|(
name|rabp
operator|->
name|b_blkno
argument_list|)
expr_stmt|;
name|bstrategy
argument_list|(
name|rabp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|brelse
argument_list|(
name|rabp
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * Entry point for bread() and breadn() via #defines in sys/buf.h.  *  * Get a buffer with the specified data.  Look in the cache first.  We  * must clear BIO_ERROR and B_INVAL prior to initiating I/O.  If B_CACHE  * is set, the buffer is valid and we do not have to do anything, see  * getblk(). Also starts asynchronous I/O on read-ahead blocks.  *  * Always return a NULL buffer pointer (in bpp) when returning an error.  */
end_comment

begin_function
name|int
name|breadn_flags
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|daddr_t
modifier|*
name|rablkno
parameter_list|,
name|int
modifier|*
name|rabsize
parameter_list|,
name|int
name|cnt
parameter_list|,
name|struct
name|ucred
modifier|*
name|cred
parameter_list|,
name|int
name|flags
parameter_list|,
name|struct
name|buf
modifier|*
modifier|*
name|bpp
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|rv
init|=
literal|0
decl_stmt|,
name|readwait
init|=
literal|0
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"breadn(%p, %jd, %d)"
argument_list|,
name|vp
argument_list|,
name|blkno
argument_list|,
name|size
argument_list|)
expr_stmt|;
comment|/* 	 * Can only return NULL if GB_LOCK_NOWAIT flag is specified. 	 */
operator|*
name|bpp
operator|=
name|bp
operator|=
name|getblk
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|,
name|size
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|==
name|NULL
condition|)
return|return
operator|(
name|EBUSY
operator|)
return|;
comment|/* if not found in cache, do some I/O */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|TD_IS_IDLETHREAD
argument_list|(
name|curthread
argument_list|)
condition|)
block|{
ifdef|#
directive|ifdef
name|RACCT
if|if
condition|(
name|racct_enable
condition|)
block|{
name|PROC_LOCK
argument_list|(
name|curproc
argument_list|)
expr_stmt|;
name|racct_add_buf
argument_list|(
name|curproc
argument_list|,
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|curproc
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* RACCT */
name|curthread
operator|->
name|td_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
block|}
name|bp
operator|->
name|b_iocmd
operator|=
name|BIO_READ
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INVAL
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_rcred
operator|==
name|NOCRED
operator|&&
name|cred
operator|!=
name|NOCRED
condition|)
name|bp
operator|->
name|b_rcred
operator|=
name|crhold
argument_list|(
name|cred
argument_list|)
expr_stmt|;
name|vfs_busy_pages
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_iooffset
operator|=
name|dbtob
argument_list|(
name|bp
operator|->
name|b_blkno
argument_list|)
expr_stmt|;
name|bstrategy
argument_list|(
name|bp
argument_list|)
expr_stmt|;
operator|++
name|readwait
expr_stmt|;
block|}
name|breada
argument_list|(
name|vp
argument_list|,
name|rablkno
argument_list|,
name|rabsize
argument_list|,
name|cnt
argument_list|,
name|cred
argument_list|)
expr_stmt|;
if|if
condition|(
name|readwait
condition|)
block|{
name|rv
operator|=
name|bufwait
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
operator|!=
literal|0
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
operator|*
name|bpp
operator|=
name|NULL
expr_stmt|;
block|}
block|}
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Write, release buffer on completion.  (Done by iodone  * if async).  Do not bother writing anything if the buffer  * is invalid.  *  * Note that we set B_CACHE here, indicating that buffer is  * fully valid and thus cacheable.  This is true even of NFS  * now so we set it generally.  This could be set either here   * or in biodone() since the I/O is synchronous.  We put it  * here.  */
end_comment

begin_function
name|int
name|bufwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|oldflags
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|long
name|space
decl_stmt|;
name|int
name|vp_md
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bufwrite(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_flag
operator|&
name|BO_DEAD
operator|)
operator|!=
literal|0
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
operator||
name|B_RELBUF
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENXIO
operator|)
return|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_BARRIER
condition|)
name|barrierwrites
operator|++
expr_stmt|;
name|oldflags
operator|=
name|bp
operator|->
name|b_flags
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
operator|)
argument_list|,
operator|(
literal|"FFS background buffer should not get here %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
if|if
condition|(
name|vp
condition|)
name|vp_md
operator|=
name|vp
operator|->
name|v_vflag
operator|&
name|VV_MD
expr_stmt|;
else|else
name|vp_md
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Mark the buffer clean.  Increment the bufobj write count 	 * before bundirty() call, to prevent other thread from seeing 	 * empty dirty list and zero counter for writes in progress, 	 * falsely indicating that the bufobj is clean. 	 */
name|bufobj_wref
argument_list|(
name|bp
operator|->
name|b_bufobj
argument_list|)
expr_stmt|;
name|bundirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
name|bp
operator|->
name|b_iocmd
operator|=
name|BIO_WRITE
expr_stmt|;
name|vfs_busy_pages
argument_list|(
name|bp
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * Normal bwrites pipeline writes 	 */
name|bp
operator|->
name|b_runningbufspace
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|space
operator|=
name|atomic_fetchadd_long
argument_list|(
operator|&
name|runningbufspace
argument_list|,
name|bp
operator|->
name|b_runningbufspace
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|TD_IS_IDLETHREAD
argument_list|(
name|curthread
argument_list|)
condition|)
block|{
ifdef|#
directive|ifdef
name|RACCT
if|if
condition|(
name|racct_enable
condition|)
block|{
name|PROC_LOCK
argument_list|(
name|curproc
argument_list|)
expr_stmt|;
name|racct_add_buf
argument_list|(
name|curproc
argument_list|,
name|bp
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|curproc
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* RACCT */
name|curthread
operator|->
name|td_ru
operator|.
name|ru_oublock
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|oldflags
operator|&
name|B_ASYNC
condition|)
name|BUF_KERNPROC
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_iooffset
operator|=
name|dbtob
argument_list|(
name|bp
operator|->
name|b_blkno
argument_list|)
expr_stmt|;
name|buf_track
argument_list|(
name|bp
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|bstrategy
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|oldflags
operator|&
name|B_ASYNC
operator|)
operator|==
literal|0
condition|)
block|{
name|int
name|rtval
init|=
name|bufwait
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|rtval
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|space
operator|>
name|hirunningspace
condition|)
block|{
comment|/* 		 * don't allow the async write to saturate the I/O 		 * system.  We will not deadlock here because 		 * we are blocking waiting for I/O that is already in-progress 		 * to complete. We do not block here if it is the update 		 * or syncer daemon trying to clean up as that can lead 		 * to deadlock. 		 */
if|if
condition|(
operator|(
name|curthread
operator|->
name|td_pflags
operator|&
name|TDP_NORUNNINGBUF
operator|)
operator|==
literal|0
operator|&&
operator|!
name|vp_md
condition|)
name|waitrunningbufspace
argument_list|()
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|void
name|bufbdflush
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|,
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|nbp
decl_stmt|;
if|if
condition|(
name|bo
operator|->
name|bo_dirty
operator|.
name|bv_cnt
operator|>
name|dirtybufthresh
operator|+
literal|10
condition|)
block|{
operator|(
name|void
operator|)
name|VOP_FSYNC
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|MNT_NOWAIT
argument_list|,
name|curthread
argument_list|)
expr_stmt|;
name|altbufferflushes
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bo
operator|->
name|bo_dirty
operator|.
name|bv_cnt
operator|>
name|dirtybufthresh
condition|)
block|{
name|BO_LOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
comment|/* 		 * Try to find a buffer to flush. 		 */
name|TAILQ_FOREACH
argument_list|(
argument|nbp
argument_list|,
argument|&bo->bo_dirty.bv_hd
argument_list|,
argument|b_bobufs
argument_list|)
block|{
if|if
condition|(
operator|(
name|nbp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
operator|)
operator|||
name|BUF_LOCK
argument_list|(
name|nbp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|NULL
argument_list|)
condition|)
continue|continue;
if|if
condition|(
name|bp
operator|==
name|nbp
condition|)
name|panic
argument_list|(
literal|"bdwrite: found ourselves"
argument_list|)
expr_stmt|;
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
comment|/* Don't countdeps with the bo lock held. */
if|if
condition|(
name|buf_countdeps
argument_list|(
name|nbp
argument_list|,
literal|0
argument_list|)
condition|)
block|{
name|BO_LOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|BUF_UNLOCK
argument_list|(
name|nbp
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|nbp
operator|->
name|b_flags
operator|&
name|B_CLUSTEROK
condition|)
block|{
name|vfs_bio_awrite
argument_list|(
name|nbp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bremfree
argument_list|(
name|nbp
argument_list|)
expr_stmt|;
name|bawrite
argument_list|(
name|nbp
argument_list|)
expr_stmt|;
block|}
name|dirtybufferflushes
operator|++
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|nbp
operator|==
name|NULL
condition|)
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Delayed write. (Buffer is marked dirty).  Do not bother writing  * anything if the buffer is marked invalid.  *  * Note that since the buffer must be completely valid, we can safely  * set B_CACHE.  In fact, we have to set B_CACHE here rather then in  * biodone() in order to prevent getblk from writing the buffer  * out synchronously.  */
end_comment

begin_function
name|void
name|bdwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
init|=
name|curthread
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|struct
name|bufobj
modifier|*
name|bo
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bdwrite(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|!=
name|NULL
argument_list|,
operator|(
literal|"No b_bufobj %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_BARRIER
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"Barrier request in delayed write %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * If we have too many dirty buffers, don't create any more. 	 * If we are wildly over our limit, then force a complete 	 * cleanup. Otherwise, just keep the situation from getting 	 * out of control. Note that we have to avoid a recursive 	 * disaster and not try to clean up after our own cleanup! 	 */
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
name|bo
operator|=
name|bp
operator|->
name|b_bufobj
expr_stmt|;
if|if
condition|(
operator|(
name|td
operator|->
name|td_pflags
operator|&
operator|(
name|TDP_COWINPROGRESS
operator||
name|TDP_INBDFLUSH
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|td
operator|->
name|td_pflags
operator||=
name|TDP_INBDFLUSH
expr_stmt|;
name|BO_BDFLUSH
argument_list|(
name|bo
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_pflags
operator|&=
operator|~
name|TDP_INBDFLUSH
expr_stmt|;
block|}
else|else
name|recursiveflushes
operator|++
expr_stmt|;
name|bdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * Set B_CACHE, indicating that the buffer is fully valid.  This is 	 * true even of NFS now. 	 */
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
comment|/* 	 * This bmap keeps the system from needing to do the bmap later, 	 * perhaps when the system is attempting to do a sync.  Since it 	 * is likely that the indirect block -- or whatever other datastructure 	 * that the filesystem needs is still in memory now, it is a good 	 * thing to do this.  Note also, that if the pageout daemon is 	 * requesting a sync -- there might not be enough memory to do 	 * the bmap then...  So, this is important to do. 	 */
if|if
condition|(
name|vp
operator|->
name|v_type
operator|!=
name|VCHR
operator|&&
name|bp
operator|->
name|b_lblkno
operator|==
name|bp
operator|->
name|b_blkno
condition|)
block|{
name|VOP_BMAP
argument_list|(
name|vp
argument_list|,
name|bp
operator|->
name|b_lblkno
argument_list|,
name|NULL
argument_list|,
operator|&
name|bp
operator|->
name|b_blkno
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
name|buf_track
argument_list|(
name|bp
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
comment|/* 	 * Set the *dirty* buffer range based upon the VM system dirty 	 * pages. 	 * 	 * Mark the buffer pages as clean.  We need to do this here to 	 * satisfy the vnode_pager and the pageout daemon, so that it 	 * thinks that the pages have been "cleaned".  Note that since 	 * the pages are in a delayed write buffer -- the VFS layer 	 * "will" see that the pages get written out on the next sync, 	 * or perhaps the cluster will be completed. 	 */
name|vfs_clean_pages_dirty_buf
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * note: we cannot initiate I/O from a bdwrite even if we wanted to, 	 * due to the softdep code. 	 */
block|}
end_function

begin_comment
comment|/*  *	bdirty:  *  *	Turn buffer into delayed write request.  We must clear BIO_READ and  *	B_RELBUF, and we must set B_DELWRI.  We reassign the buffer to   *	itself to properly update it in the dirty/clean lists.  We mark it  *	B_DONE to ensure that any asynchronization of the buffer properly  *	clears B_DONE ( else a panic will occur later ).    *  *	bdirty() is kinda like bdwrite() - we have to clear B_INVAL which  *	might have been set pre-getblk().  Unlike bwrite/bdwrite, bdirty()  *	should only be called if the buffer is known-good.  *  *	Since the buffer is not on a queue, we do not update the numfreebuffers  *	count.  *  *	The buffer must be on QUEUE_NONE.  */
end_comment

begin_function
name|void
name|bdirty
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bdirty(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|!=
name|NULL
argument_list|,
operator|(
literal|"No b_bufobj %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
operator|||
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bdirty: buffer %p still on queue %d"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_qindex
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_RELBUF
operator|)
expr_stmt|;
name|bp
operator|->
name|b_iocmd
operator|=
name|BIO_WRITE
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
comment|/* XXX B_DONE | */
name|B_DELWRI
expr_stmt|;
name|reassignbuf
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bdirtyadd
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	bundirty:  *  *	Clear B_DELWRI for buffer.  *  *	Since the buffer is not on a queue, we do not update the numfreebuffers  *	count.  *	  *	The buffer must be on QUEUE_NONE.  */
end_comment

begin_function
name|void
name|bundirty
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bundirty(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|!=
name|NULL
argument_list|,
operator|(
literal|"No b_bufobj %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
operator|||
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bundirty: buffer %p still on queue %d"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_qindex
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DELWRI
expr_stmt|;
name|reassignbuf
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bdirtysub
argument_list|()
expr_stmt|;
block|}
comment|/* 	 * Since it is now being written, we can clear its deferred write flag. 	 */
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DEFERRED
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bawrite:  *  *	Asynchronous write.  Start output on a buffer, but do not wait for  *	it to complete.  The buffer is released when the output completes.  *  *	bwrite() ( or the VOP routine anyway ) is responsible for handling   *	B_INVAL buffers.  Not us.  */
end_comment

begin_function
name|void
name|bawrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
operator|(
name|void
operator|)
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	babarrierwrite:  *  *	Asynchronous barrier write.  Start output on a buffer, but do not  *	wait for it to complete.  Place a write barrier after this write so  *	that this buffer and all buffers written before it are committed to  *	the disk before any buffers written after this write are committed  *	to the disk.  The buffer is released when the output completes.  */
end_comment

begin_function
name|void
name|babarrierwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_ASYNC
operator||
name|B_BARRIER
expr_stmt|;
operator|(
name|void
operator|)
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bbarrierwrite:  *  *	Synchronous barrier write.  Start output on a buffer and wait for  *	it to complete.  Place a write barrier after this write so that  *	this buffer and all buffers written before it are committed to   *	the disk before any buffers written after this write are committed  *	to the disk.  The buffer is released when the output completes.  */
end_comment

begin_function
name|int
name|bbarrierwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_BARRIER
expr_stmt|;
return|return
operator|(
name|bwrite
argument_list|(
name|bp
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	bwillwrite:  *  *	Called prior to the locking of any vnodes when we are expecting to  *	write.  We do not want to starve the buffer cache with too many  *	dirty buffers so we block here.  By blocking prior to the locking  *	of any vnodes we attempt to avoid the situation where a locked vnode  *	prevents the various system daemons from flushing related buffers.  */
end_comment

begin_function
name|void
name|bwillwrite
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|numdirtybuffers
operator|>=
name|hidirtybuffers
condition|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|bdirtylock
argument_list|)
expr_stmt|;
while|while
condition|(
name|numdirtybuffers
operator|>=
name|hidirtybuffers
condition|)
block|{
name|bdirtywait
operator|=
literal|1
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|bdirtywait
argument_list|,
operator|&
name|bdirtylock
argument_list|,
operator|(
name|PRIBIO
operator|+
literal|4
operator|)
argument_list|,
literal|"flswai"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|bdirtylock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Return true if we have too many dirty buffers.  */
end_comment

begin_function
name|int
name|buf_dirty_count_severe
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
name|numdirtybuffers
operator|>=
name|hidirtybuffers
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	brelse:  *  *	Release a busy buffer and, if requested, free its resources.  The  *	buffer will be stashed in the appropriate bufqueue[] allowing it  *	to be accessed later as a cache entity or reused for other purposes.  */
end_comment

begin_function
name|void
name|brelse
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|qindex
decl_stmt|;
comment|/* 	 * Many functions erroneously call brelse with a NULL bp under rare 	 * error conditions. Simply return when called with a NULL bp. 	 */
if|if
condition|(
name|bp
operator|==
name|NULL
condition|)
return|return;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"brelse(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTER
operator||
name|B_PAGING
operator|)
operator|)
argument_list|,
operator|(
literal|"brelse: inappropriate B_PAGING or B_CLUSTER bp %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|!=
literal|0
operator|||
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_NOREUSE
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"brelse: non-VMIO buffer marked NOREUSE"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|BUF_LOCKRECURSED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
comment|/* 		 * Do not process, in particular, do not handle the 		 * B_INVAL/B_RELBUF and do not release to free list. 		 */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MANAGED
condition|)
block|{
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|bp
operator|->
name|b_vflags
operator|&
operator|(
name|BV_BKGRDINPROG
operator||
name|BV_BKGRDERR
operator|)
operator|)
operator|==
name|BV_BKGRDERR
condition|)
block|{
name|BO_LOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_vflags
operator|&=
operator|~
name|BV_BKGRDERR
expr_stmt|;
name|BO_UNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
argument_list|)
expr_stmt|;
name|bdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_WRITE
operator|&&
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_error
operator|!=
name|ENXIO
operator|||
operator|!
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|)
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
condition|)
block|{
comment|/* 		 * Failed write, redirty.  All errors except ENXIO (which 		 * means the device is gone) are expected to be potentially 		 * transient - underlying media might work if tried again 		 * after EIO, and memory might be available after an ENOMEM. 		 * 		 * Do this also for buffers that failed with ENXIO, but have 		 * non-empty dependencies - the soft updates code might need 		 * to access the buffer to untangle them. 		 * 		 * Must clear BIO_ERROR to prevent pages from being scrapped. 		 */
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|bdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_NOCACHE
operator||
name|B_INVAL
operator|)
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_bufsize
operator|<=
literal|0
operator|)
condition|)
block|{
comment|/* 		 * Either a failed read I/O, or we were asked to free or not 		 * cache the buffer, or we failed to write to a device that's 		 * no longer present. 		 */
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
if|if
condition|(
operator|!
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
condition|)
name|buf_deallocate
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|bdirtysub
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_DELWRI
operator||
name|B_CACHE
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
condition|)
block|{
name|allocbuf
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * We must clear B_RELBUF if B_DELWRI is set.  If vfs_vmio_truncate()  	 * is called with B_DELWRI set, the underlying pages may wind up 	 * getting freed causing a previous write (bdwrite()) to get 'lost' 	 * because pages associated with a B_DELWRI bp are marked clean. 	 *  	 * We still allow the B_INVAL case to call vfs_vmio_truncate(), even 	 * if B_DELWRI is set. 	 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_RELBUF
expr_stmt|;
comment|/* 	 * VMIO buffer rundown.  It is not very necessary to keep a VMIO buffer 	 * constituted, not even NFS buffers now.  Two flags effect this.  If 	 * B_INVAL, the struct buf is invalidated but the VM object is kept 	 * around ( i.e. so it is trivial to reconstitute the buffer later ). 	 * 	 * If BIO_ERROR or B_NOCACHE is set, pages in the VM object will be 	 * invalidated.  BIO_ERROR cannot be set for a failed write unless the 	 * buffer is also B_INVAL because it hits the re-dirtying code above. 	 * 	 * Normally we can do this whether a buffer is B_DELWRI or not.  If 	 * the buffer is an NFS buffer, it is tracking piecemeal writes or 	 * the commit state and we cannot afford to lose the buffer. If the 	 * buffer has a background write in progress, we need to keep it 	 * around to prevent it from being reconstituted and starting a second 	 * background write. 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_NOCACHE
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|&&
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
operator|)
operator|)
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_vp
operator|->
name|v_mount
operator|!=
name|NULL
operator|&&
operator|(
name|bp
operator|->
name|b_vp
operator|->
name|v_mount
operator|->
name|mnt_vfc
operator|->
name|vfc_flags
operator|&
name|VFCF_NETWORK
operator|)
operator|!=
literal|0
operator|&&
operator|!
name|vn_isdisk
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|NULL
argument_list|)
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|)
condition|)
block|{
name|vfs_vmio_invalidate
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|allocbuf
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_RELBUF
operator|)
operator|)
operator|!=
literal|0
operator|||
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_DELWRI
operator||
name|B_NOREUSE
operator|)
operator|)
operator|==
name|B_NOREUSE
condition|)
block|{
name|allocbuf
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_NOREUSE
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
operator|!=
name|NULL
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If the buffer has junk contents signal it and eventually 	 * clean up B_DELWRI and diassociate the vnode so that gbincore() 	 * doesn't find it. 	 */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
operator|!=
literal|0
operator|||
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_NOCACHE
operator||
name|B_RELBUF
operator|)
operator|)
operator|!=
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|bundirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|buf_track
argument_list|(
name|bp
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
comment|/* buffers with no memory */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
block|{
name|buf_free
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* buffers with junk contents */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_NOCACHE
operator||
name|B_RELBUF
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
condition|)
block|{
name|bp
operator|->
name|b_xflags
operator|&=
operator|~
operator|(
name|BX_BKGRDWRITE
operator||
name|BX_ALTDATA
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
condition|)
name|panic
argument_list|(
literal|"losing buffer 2"
argument_list|)
expr_stmt|;
name|qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_AGE
expr_stmt|;
comment|/* remaining buffers */
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|qindex
operator|=
name|QUEUE_DIRTY
expr_stmt|;
else|else
name|qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|binsfree
argument_list|(
name|bp
argument_list|,
name|qindex
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ASYNC
operator||
name|B_NOCACHE
operator||
name|B_AGE
operator||
name|B_RELBUF
operator||
name|B_DIRECT
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
operator|&&
operator|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_VNDIRTY
operator|)
condition|)
name|panic
argument_list|(
literal|"brelse: not dirty"
argument_list|)
expr_stmt|;
comment|/* unlock */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|qindex
operator|==
name|QUEUE_CLEAN
condition|)
name|bufspace_wakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Release a buffer back to the appropriate queue but do not try to free  * it.  The buffer is expected to be used again soon.  *  * bqrelse() is used by bdwrite() to requeue a delayed write, and used by  * biodone() to requeue an async I/O on completion.  It is also used when  * known good buffers need to be requeued but we think we may need the data  * again soon.  *  * XXX we should be able to leave the B_RELBUF hint set on completion.  */
end_comment

begin_function
name|void
name|bqrelse
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|qindex
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bqrelse(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTER
operator||
name|B_PAGING
operator|)
operator|)
argument_list|,
operator|(
literal|"bqrelse: inappropriate B_PAGING or B_CLUSTER bp %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|qindex
operator|=
name|QUEUE_NONE
expr_stmt|;
if|if
condition|(
name|BUF_LOCKRECURSED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
comment|/* do not release to free list */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ASYNC
operator||
name|B_NOCACHE
operator||
name|B_AGE
operator||
name|B_RELBUF
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MANAGED
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_REMFREE
condition|)
name|bremfreef
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|out
goto|;
block|}
comment|/* buffers with stale but valid contents */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|!=
literal|0
operator|||
operator|(
name|bp
operator|->
name|b_vflags
operator|&
operator|(
name|BV_BKGRDINPROG
operator||
name|BV_BKGRDERR
operator|)
operator|)
operator|==
name|BV_BKGRDERR
condition|)
block|{
name|BO_LOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_vflags
operator|&=
operator|~
name|BV_BKGRDERR
expr_stmt|;
name|BO_UNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
argument_list|)
expr_stmt|;
name|qindex
operator|=
name|QUEUE_DIRTY
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
operator|&&
operator|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_VNDIRTY
operator|)
condition|)
name|panic
argument_list|(
literal|"bqrelse: not dirty"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_NOREUSE
operator|)
operator|!=
literal|0
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
name|qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
block|}
name|binsfree
argument_list|(
name|bp
argument_list|,
name|qindex
argument_list|)
expr_stmt|;
name|out
label|:
name|buf_track
argument_list|(
name|bp
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
comment|/* unlock */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|qindex
operator|==
name|QUEUE_CLEAN
condition|)
name|bufspace_wakeup
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Complete I/O to a VMIO backed page.  Validate the pages as appropriate,  * restore bogus pages.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_vmio_iodone
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|vm_ooffset_t
name|foff
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|int
name|i
decl_stmt|,
name|iosize
decl_stmt|,
name|resid
decl_stmt|;
name|bool
name|bogus
decl_stmt|;
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|KASSERT
argument_list|(
name|obj
operator|->
name|paging_in_progress
operator|>=
name|bp
operator|->
name|b_npages
argument_list|,
operator|(
literal|"vfs_vmio_iodone: paging in progress(%d)< b_npages(%d)"
operator|,
name|obj
operator|->
name|paging_in_progress
operator|,
name|bp
operator|->
name|b_npages
operator|)
argument_list|)
expr_stmt|;
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
name|KASSERT
argument_list|(
name|vp
operator|->
name|v_holdcnt
operator|>
literal|0
argument_list|,
operator|(
literal|"vfs_vmio_iodone: vnode %p has zero hold count"
operator|,
name|vp
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|vp
operator|->
name|v_object
operator|!=
name|NULL
argument_list|,
operator|(
literal|"vfs_vmio_iodone: vnode %p has no vm_object"
operator|,
name|vp
operator|)
argument_list|)
expr_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"vfs_vmio_iodone: bp %p has no buffer offset"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|bogus
operator|=
name|false
expr_stmt|;
name|iosize
operator|=
name|bp
operator|->
name|b_bcount
operator|-
name|bp
operator|->
name|b_resid
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|resid
operator|=
operator|(
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
operator|)
operator|-
name|foff
expr_stmt|;
if|if
condition|(
name|resid
operator|>
name|iosize
condition|)
name|resid
operator|=
name|iosize
expr_stmt|;
comment|/* 		 * cleanup bogus pages, restoring the originals 		 */
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|bogus
operator|=
name|true
expr_stmt|;
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|foff
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"biodone: page disappeared!"
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|m
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
operator|)
operator|&&
name|resid
operator|>
literal|0
condition|)
block|{
comment|/* 			 * In the write case, the valid and clean bits are 			 * already changed correctly ( see bdwrite() ), so we  			 * only need to do this here in the read case. 			 */
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|dirty
operator|&
name|vm_page_bits
argument_list|(
name|foff
operator|&
name|PAGE_MASK
argument_list|,
name|resid
argument_list|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vfs_vmio_iodone: page %p "
literal|"has unexpected dirty bits"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vfs_page_set_valid
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|OFF_TO_IDX
argument_list|(
name|foff
argument_list|)
operator|==
name|m
operator|->
name|pindex
argument_list|,
operator|(
literal|"vfs_vmio_iodone: foff(%jd)/pindex(%ju) mismatch"
operator|,
operator|(
name|intmax_t
operator|)
name|foff
operator|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|pindex
operator|)
argument_list|)
expr_stmt|;
name|vm_page_sunbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|foff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
name|iosize
operator|-=
name|resid
expr_stmt|;
block|}
name|vm_object_pip_wakeupn
argument_list|(
name|obj
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
if|if
condition|(
name|bogus
operator|&&
name|buf_mapped
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Unwire a page held by a buf and place it on the appropriate vm queue.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_vmio_unwire
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|bool
name|freed
decl_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
name|PQ_NONE
argument_list|)
condition|)
block|{
comment|/* 		 * Determine if the page should be freed before adding 		 * it to the inactive queue. 		 */
if|if
condition|(
name|m
operator|->
name|valid
operator|==
literal|0
condition|)
block|{
name|freed
operator|=
operator|!
name|vm_page_busied
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|freed
condition|)
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DIRECT
operator|)
operator|!=
literal|0
condition|)
name|freed
operator|=
name|vm_page_try_to_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
else|else
name|freed
operator|=
name|false
expr_stmt|;
if|if
condition|(
operator|!
name|freed
condition|)
block|{
comment|/* 			 * If the page is unlikely to be reused, let the 			 * VM know.  Otherwise, maintain LRU page 			 * ordering and put the page at the tail of the 			 * inactive queue. 			 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_NOREUSE
operator|)
operator|!=
literal|0
condition|)
name|vm_page_deactivate_noreuse
argument_list|(
name|m
argument_list|)
expr_stmt|;
else|else
name|vm_page_deactivate
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Perform page invalidation when a buffer is released.  The fully invalid  * pages will be reclaimed later in vfs_vmio_truncate().  */
end_comment

begin_function
specifier|static
name|void
name|vfs_vmio_invalidate
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|,
name|resid
decl_stmt|,
name|poffset
decl_stmt|,
name|presid
decl_stmt|;
if|if
condition|(
name|buf_mapped
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
else|else
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * Get the base offset and length of the buffer.  Note that  	 * in the VMIO case if the buffer block size is not 	 * page-aligned then b_data pointer may not be page-aligned. 	 * But our b_pages[] array *IS* page aligned. 	 * 	 * block sizes less then DEV_BSIZE (usually 512) are not  	 * supported due to the page granularity bits (m->valid, 	 * m->dirty, etc...).  	 * 	 * See man buf(9) for more information 	 */
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|resid
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|poffset
operator|=
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
name|panic
argument_list|(
literal|"vfs_vmio_invalidate: Unexpected bogus page."
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|NULL
expr_stmt|;
name|presid
operator|=
name|resid
operator|>
operator|(
name|PAGE_SIZE
operator|-
name|poffset
operator|)
condition|?
operator|(
name|PAGE_SIZE
operator|-
name|poffset
operator|)
else|:
name|resid
expr_stmt|;
name|KASSERT
argument_list|(
name|presid
operator|>=
literal|0
argument_list|,
operator|(
literal|"brelse: extra page"
operator|)
argument_list|)
expr_stmt|;
while|while
condition|(
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
block|{
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
name|vm_page_busy_sleep
argument_list|(
name|m
argument_list|,
literal|"mbncsh"
argument_list|,
name|true
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pmap_page_wired_mappings
argument_list|(
name|m
argument_list|)
operator|==
literal|0
condition|)
name|vm_page_set_invalid
argument_list|(
name|m
argument_list|,
name|poffset
argument_list|,
name|presid
argument_list|)
expr_stmt|;
name|vfs_vmio_unwire
argument_list|(
name|bp
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|resid
operator|-=
name|presid
expr_stmt|;
name|poffset
operator|=
literal|0
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_npages
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Page-granular truncation of an existing VMIO buffer.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_vmio_truncate
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|desiredpages
parameter_list|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_npages
operator|==
name|desiredpages
condition|)
return|return;
if|if
condition|(
name|buf_mapped
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|+
operator|(
name|desiredpages
operator|<<
name|PAGE_SHIFT
operator|)
argument_list|,
name|bp
operator|->
name|b_npages
operator|-
name|desiredpages
argument_list|)
expr_stmt|;
block|}
else|else
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
if|if
condition|(
name|obj
operator|!=
name|NULL
condition|)
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|desiredpages
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|!=
name|bogus_page
argument_list|,
operator|(
literal|"allocbuf: bogus page found"
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|NULL
expr_stmt|;
name|vfs_vmio_unwire
argument_list|(
name|bp
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|obj
operator|!=
name|NULL
condition|)
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_npages
operator|=
name|desiredpages
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Byte granular extension of VMIO buffers.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_vmio_extend
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|desiredpages
parameter_list|,
name|int
name|size
parameter_list|)
block|{
comment|/* 	 * We are growing the buffer, possibly in a  	 * byte-granular fashion. 	 */
name|vm_object_t
name|obj
decl_stmt|;
name|vm_offset_t
name|toff
decl_stmt|;
name|vm_offset_t
name|tinc
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
comment|/* 	 * Step 1, bring in the VM pages from the object, allocating 	 * them if necessary.  We must clear B_CACHE if these pages 	 * are not valid for the range covered by the buffer. 	 */
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
while|while
condition|(
name|bp
operator|->
name|b_npages
operator|<
name|desiredpages
condition|)
block|{
comment|/* 		 * We must allocate system pages since blocking 		 * here could interfere with paging I/O, no 		 * matter which process we are. 		 * 		 * Only exclusive busy can be tested here. 		 * Blocking on shared busy might lead to 		 * deadlocks once allocbuf() is called after 		 * pages are vfs_busy_pages(). 		 */
name|m
operator|=
name|vm_page_grab
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
operator|+
name|bp
operator|->
name|b_npages
argument_list|,
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SYSTEM
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_IGN_SBUSY
operator||
name|VM_ALLOC_COUNT
argument_list|(
name|desiredpages
operator|-
name|bp
operator|->
name|b_npages
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|bp
operator|->
name|b_npages
index|]
operator|=
name|m
expr_stmt|;
operator|++
name|bp
operator|->
name|b_npages
expr_stmt|;
block|}
comment|/* 	 * Step 2.  We've loaded the pages into the buffer, 	 * we have to figure out if we can still have B_CACHE 	 * set.  Note that B_CACHE is set according to the 	 * byte-granular range ( bcount and size ), not the 	 * aligned range ( newbsize ). 	 * 	 * The VM test is against m->valid, which is DEV_BSIZE 	 * aligned.  Needless to say, the validity of the data 	 * needs to also be DEV_BSIZE aligned.  Note that this 	 * fails with NFS if the server or some other client 	 * extends the file's EOF.  If our buffer is resized,  	 * B_CACHE may remain set! XXX 	 */
name|toff
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
name|tinc
operator|=
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|bp
operator|->
name|b_offset
operator|+
name|toff
operator|)
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|&&
name|toff
operator|<
name|size
condition|)
block|{
name|vm_pindex_t
name|pi
decl_stmt|;
if|if
condition|(
name|tinc
operator|>
operator|(
name|size
operator|-
name|toff
operator|)
condition|)
name|tinc
operator|=
name|size
operator|-
name|toff
expr_stmt|;
name|pi
operator|=
operator|(
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|+
name|toff
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|pi
index|]
expr_stmt|;
name|vfs_buf_test_cache
argument_list|(
name|bp
argument_list|,
name|bp
operator|->
name|b_offset
argument_list|,
name|toff
argument_list|,
name|tinc
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|toff
operator|+=
name|tinc
expr_stmt|;
name|tinc
operator|=
name|PAGE_SIZE
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
comment|/* 	 * Step 3, fixup the KVA pmap. 	 */
if|if
condition|(
name|buf_mapped
argument_list|(
name|bp
argument_list|)
condition|)
name|bpmap_qenter
argument_list|(
name|bp
argument_list|)
expr_stmt|;
else|else
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Check to see if a block at a particular lbn is available for a clustered  * write.  */
end_comment

begin_function
specifier|static
name|int
name|vfs_bio_clcheck
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
name|size
parameter_list|,
name|daddr_t
name|lblkno
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bpa
decl_stmt|;
name|int
name|match
decl_stmt|;
name|match
operator|=
literal|0
expr_stmt|;
comment|/* If the buf isn't in core skip it */
if|if
condition|(
operator|(
name|bpa
operator|=
name|gbincore
argument_list|(
operator|&
name|vp
operator|->
name|v_bufobj
argument_list|,
name|lblkno
argument_list|)
operator|)
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* If the buf is busy we don't want to wait for it */
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bpa
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|NULL
argument_list|)
operator|!=
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* Only cluster with valid clusterable delayed write buffers */
if|if
condition|(
operator|(
name|bpa
operator|->
name|b_flags
operator|&
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator||
name|B_INVAL
operator|)
operator|)
operator|!=
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator|)
condition|)
goto|goto
name|done
goto|;
if|if
condition|(
name|bpa
operator|->
name|b_bufsize
operator|!=
name|size
condition|)
goto|goto
name|done
goto|;
comment|/* 	 * Check to see if it is in the expected place on disk and that the 	 * block has been mapped. 	 */
if|if
condition|(
operator|(
name|bpa
operator|->
name|b_blkno
operator|!=
name|bpa
operator|->
name|b_lblkno
operator|)
operator|&&
operator|(
name|bpa
operator|->
name|b_blkno
operator|==
name|blkno
operator|)
condition|)
name|match
operator|=
literal|1
expr_stmt|;
name|done
label|:
name|BUF_UNLOCK
argument_list|(
name|bpa
argument_list|)
expr_stmt|;
return|return
operator|(
name|match
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_awrite:  *  *	Implement clustered async writes for clearing out B_DELWRI buffers.  *	This is much better then the old way of writing only one buffer at  *	a time.  Note that we may not be presented with the buffers in the   *	correct order, so we search for the cluster in both directions.  */
end_comment

begin_function
name|int
name|vfs_bio_awrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|bufobj
modifier|*
name|bo
decl_stmt|;
name|int
name|i
decl_stmt|;
name|int
name|j
decl_stmt|;
name|daddr_t
name|lblkno
init|=
name|bp
operator|->
name|b_lblkno
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
init|=
name|bp
operator|->
name|b_vp
decl_stmt|;
name|int
name|ncl
decl_stmt|;
name|int
name|nwritten
decl_stmt|;
name|int
name|size
decl_stmt|;
name|int
name|maxcl
decl_stmt|;
name|int
name|gbflags
decl_stmt|;
name|bo
operator|=
operator|&
name|vp
operator|->
name|v_bufobj
expr_stmt|;
name|gbflags
operator|=
operator|(
name|bp
operator|->
name|b_data
operator|==
name|unmapped_buf
operator|)
condition|?
name|GB_UNMAPPED
else|:
literal|0
expr_stmt|;
comment|/* 	 * right now we support clustered writing only to regular files.  If 	 * we find a clusterable block we could be in the middle of a cluster 	 * rather then at the beginning. 	 */
if|if
condition|(
operator|(
name|vp
operator|->
name|v_type
operator|==
name|VREG
operator|)
operator|&&
operator|(
name|vp
operator|->
name|v_mount
operator|!=
literal|0
operator|)
operator|&&
comment|/* Only on nodes that have the size info */
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTEROK
operator||
name|B_INVAL
operator|)
operator|)
operator|==
name|B_CLUSTEROK
condition|)
block|{
name|size
operator|=
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
name|maxcl
operator|=
name|MAXPHYS
operator|/
name|size
expr_stmt|;
name|BO_RLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|maxcl
condition|;
name|i
operator|++
control|)
if|if
condition|(
name|vfs_bio_clcheck
argument_list|(
name|vp
argument_list|,
name|size
argument_list|,
name|lblkno
operator|+
name|i
argument_list|,
name|bp
operator|->
name|b_blkno
operator|+
operator|(
operator|(
name|i
operator|*
name|size
operator|)
operator|>>
name|DEV_BSHIFT
operator|)
argument_list|)
operator|==
literal|0
condition|)
break|break;
for|for
control|(
name|j
operator|=
literal|1
init|;
name|i
operator|+
name|j
operator|<=
name|maxcl
operator|&&
name|j
operator|<=
name|lblkno
condition|;
name|j
operator|++
control|)
if|if
condition|(
name|vfs_bio_clcheck
argument_list|(
name|vp
argument_list|,
name|size
argument_list|,
name|lblkno
operator|-
name|j
argument_list|,
name|bp
operator|->
name|b_blkno
operator|-
operator|(
operator|(
name|j
operator|*
name|size
operator|)
operator|>>
name|DEV_BSHIFT
operator|)
argument_list|)
operator|==
literal|0
condition|)
break|break;
name|BO_RUNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
operator|--
name|j
expr_stmt|;
name|ncl
operator|=
name|i
operator|+
name|j
expr_stmt|;
comment|/* 		 * this is a possible cluster write 		 */
if|if
condition|(
name|ncl
operator|!=
literal|1
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|nwritten
operator|=
name|cluster_wbuild
argument_list|(
name|vp
argument_list|,
name|size
argument_list|,
name|lblkno
operator|-
name|j
argument_list|,
name|ncl
argument_list|,
name|gbflags
argument_list|)
expr_stmt|;
return|return
operator|(
name|nwritten
operator|)
return|;
block|}
block|}
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
comment|/* 	 * default (old) behavior, writing out only one block 	 * 	 * XXX returns b_bufsize instead of b_bcount for nwritten? 	 */
name|nwritten
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
operator|(
name|void
operator|)
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|nwritten
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	getnewbuf_kva:  *  *	Allocate KVA for an empty buf header according to gbflags.  */
end_comment

begin_function
specifier|static
name|int
name|getnewbuf_kva
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|gbflags
parameter_list|,
name|int
name|maxsize
parameter_list|)
block|{
if|if
condition|(
operator|(
name|gbflags
operator|&
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
operator|)
operator|!=
name|GB_UNMAPPED
condition|)
block|{
comment|/* 		 * In order to keep fragmentation sane we only allocate kva 		 * in BKVASIZE chunks.  XXX with vmem we can do page size. 		 */
name|maxsize
operator|=
operator|(
name|maxsize
operator|+
name|BKVAMASK
operator|)
operator|&
operator|~
name|BKVAMASK
expr_stmt|;
if|if
condition|(
name|maxsize
operator|!=
name|bp
operator|->
name|b_kvasize
operator|&&
name|bufkva_alloc
argument_list|(
name|bp
argument_list|,
name|maxsize
argument_list|,
name|gbflags
argument_list|)
condition|)
return|return
operator|(
name|ENOSPC
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	getnewbuf:  *  *	Find and initialize a new buffer header, freeing up existing buffers  *	in the bufqueues as necessary.  The new buffer is returned locked.  *  *	We block if:  *		We have insufficient buffer headers  *		We have insufficient buffer space  *		buffer_arena is too fragmented ( space reservation fails )  *		If we have to flush dirty buffers ( but we try to avoid this )  *  *	The caller is responsible for releasing the reserved bufspace after  *	allocbuf() is called.  */
end_comment

begin_function
specifier|static
name|struct
name|buf
modifier|*
name|getnewbuf
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|,
name|int
name|maxsize
parameter_list|,
name|int
name|gbflags
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|bool
name|metadata
decl_stmt|,
name|reserved
decl_stmt|;
name|bp
operator|=
name|NULL
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|gbflags
operator|&
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
operator|)
operator|!=
name|GB_KVAALLOC
argument_list|,
operator|(
literal|"GB_KVAALLOC only makes sense with GB_UNMAPPED"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|unmapped_buf_allowed
condition|)
name|gbflags
operator|&=
operator|~
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
expr_stmt|;
if|if
condition|(
name|vp
operator|==
name|NULL
operator|||
operator|(
name|vp
operator|->
name|v_vflag
operator|&
operator|(
name|VV_MD
operator||
name|VV_SYSTEM
operator|)
operator|)
operator|!=
literal|0
operator|||
name|vp
operator|->
name|v_type
operator|==
name|VCHR
condition|)
name|metadata
operator|=
name|true
expr_stmt|;
else|else
name|metadata
operator|=
name|false
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|getnewbufcalls
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|reserved
operator|=
name|false
expr_stmt|;
do|do
block|{
if|if
condition|(
name|reserved
operator|==
name|false
operator|&&
name|bufspace_reserve
argument_list|(
name|maxsize
argument_list|,
name|metadata
argument_list|)
operator|!=
literal|0
condition|)
continue|continue;
name|reserved
operator|=
name|true
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|=
name|buf_alloc
argument_list|()
operator|)
operator|==
name|NULL
condition|)
continue|continue;
if|if
condition|(
name|getnewbuf_kva
argument_list|(
name|bp
argument_list|,
name|gbflags
argument_list|,
name|maxsize
argument_list|)
operator|==
literal|0
condition|)
return|return
operator|(
name|bp
operator|)
return|;
break|break;
block|}
do|while
condition|(
name|buf_scan
argument_list|(
name|false
argument_list|)
operator|==
literal|0
condition|)
do|;
if|if
condition|(
name|reserved
condition|)
name|atomic_subtract_long
argument_list|(
operator|&
name|bufspace
argument_list|,
name|maxsize
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|!=
name|NULL
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|bufspace_wait
argument_list|(
name|vp
argument_list|,
name|gbflags
argument_list|,
name|slpflag
argument_list|,
name|slptimeo
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	buf_daemon:  *  *	buffer flushing daemon.  Buffers are normally flushed by the  *	update daemon but if it cannot keep up this process starts to  *	take the load in an attempt to prevent getnewbuf() from blocking.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|kproc_desc
name|buf_kp
init|=
block|{
literal|"bufdaemon"
block|,
name|buf_daemon
block|,
operator|&
name|bufdaemonproc
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSINIT
argument_list|(
name|bufdaemon
argument_list|,
name|SI_SUB_KTHREAD_BUF
argument_list|,
name|SI_ORDER_FIRST
argument_list|,
name|kproc_start
argument_list|,
operator|&
name|buf_kp
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|buf_flush
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|int
name|target
parameter_list|)
block|{
name|int
name|flushed
decl_stmt|;
name|flushed
operator|=
name|flushbufqueues
argument_list|(
name|vp
argument_list|,
name|target
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|flushed
operator|==
literal|0
condition|)
block|{
comment|/* 		 * Could not find any buffers without rollback 		 * dependencies, so just write the first one 		 * in the hopes of eventually making progress. 		 */
if|if
condition|(
name|vp
operator|!=
name|NULL
operator|&&
name|target
operator|>
literal|2
condition|)
name|target
operator|/=
literal|2
expr_stmt|;
name|flushbufqueues
argument_list|(
name|vp
argument_list|,
name|target
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|flushed
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|buf_daemon
parameter_list|()
block|{
name|int
name|lodirty
decl_stmt|;
comment|/* 	 * This process needs to be suspended prior to shutdown sync. 	 */
name|EVENTHANDLER_REGISTER
argument_list|(
name|shutdown_pre_sync
argument_list|,
name|kproc_shutdown
argument_list|,
name|bufdaemonproc
argument_list|,
name|SHUTDOWN_PRI_LAST
argument_list|)
expr_stmt|;
comment|/* 	 * This process is allowed to take the buffer cache to the limit 	 */
name|curthread
operator|->
name|td_pflags
operator||=
name|TDP_NORUNNINGBUF
operator||
name|TDP_BUFNEED
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|bd_request
operator|=
literal|0
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
name|kproc_suspend_check
argument_list|(
name|bufdaemonproc
argument_list|)
expr_stmt|;
name|lodirty
operator|=
name|lodirtybuffers
expr_stmt|;
if|if
condition|(
name|bd_speedupreq
condition|)
block|{
name|lodirty
operator|=
name|numdirtybuffers
operator|/
literal|2
expr_stmt|;
name|bd_speedupreq
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 		 * Do the flush.  Limit the amount of in-transit I/O we 		 * allow to build up, otherwise we would completely saturate 		 * the I/O system. 		 */
while|while
condition|(
name|numdirtybuffers
operator|>
name|lodirty
condition|)
block|{
if|if
condition|(
name|buf_flush
argument_list|(
name|NULL
argument_list|,
name|numdirtybuffers
operator|-
name|lodirty
argument_list|)
operator|==
literal|0
condition|)
break|break;
name|kern_yield
argument_list|(
name|PRI_USER
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Only clear bd_request if we have reached our low water 		 * mark.  The buf_daemon normally waits 1 second and 		 * then incrementally flushes any dirty buffers that have 		 * built up, within reason. 		 * 		 * If we were unable to hit our low water mark and couldn't 		 * find any flushable buffers, we sleep for a short period 		 * to avoid endless loops on unlockable buffers. 		 */
name|mtx_lock
argument_list|(
operator|&
name|bdlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|numdirtybuffers
operator|<=
name|lodirtybuffers
condition|)
block|{
comment|/* 			 * We reached our low water mark, reset the 			 * request and sleep until we are needed again. 			 * The sleep is just so the suspend code works. 			 */
name|bd_request
operator|=
literal|0
expr_stmt|;
comment|/* 			 * Do an extra wakeup in case dirty threshold 			 * changed via sysctl and the explicit transition 			 * out of shortfall was missed. 			 */
name|bdirtywakeup
argument_list|()
expr_stmt|;
if|if
condition|(
name|runningbufspace
operator|<=
name|lorunningspace
condition|)
name|runningwakeup
argument_list|()
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|bd_request
argument_list|,
operator|&
name|bdlock
argument_list|,
name|PVM
argument_list|,
literal|"psleep"
argument_list|,
name|hz
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * We couldn't find any flushable dirty buffers but 			 * still have too many dirty buffers, we 			 * have to sleep and try again.  (rare) 			 */
name|msleep
argument_list|(
operator|&
name|bd_request
argument_list|,
operator|&
name|bdlock
argument_list|,
name|PVM
argument_list|,
literal|"qsleep"
argument_list|,
name|hz
operator|/
literal|10
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	flushbufqueues:  *  *	Try to flush a buffer in the dirty queue.  We must be careful to  *	free up B_INVAL buffers instead of write them, which NFS is   *	particularly sensitive to.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|flushwithdeps
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|flushwithdeps
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|flushwithdeps
argument_list|,
literal|0
argument_list|,
literal|"Number of buffers flushed with dependecies that require rollbacks"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|flushbufqueues
parameter_list|(
name|struct
name|vnode
modifier|*
name|lvp
parameter_list|,
name|int
name|target
parameter_list|,
name|int
name|flushdeps
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|sentinel
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|struct
name|mount
modifier|*
name|mp
decl_stmt|;
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|hasdeps
decl_stmt|;
name|int
name|flushed
decl_stmt|;
name|int
name|queue
decl_stmt|;
name|int
name|error
decl_stmt|;
name|bool
name|unlock
decl_stmt|;
name|flushed
operator|=
literal|0
expr_stmt|;
name|queue
operator|=
name|QUEUE_DIRTY
expr_stmt|;
name|bp
operator|=
name|NULL
expr_stmt|;
name|sentinel
operator|=
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|buf
argument_list|)
argument_list|,
name|M_TEMP
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
name|sentinel
operator|->
name|b_qindex
operator|=
name|QUEUE_SENTINEL
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bqlocks
index|[
name|queue
index|]
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|queue
index|]
argument_list|,
name|sentinel
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bqlocks
index|[
name|queue
index|]
argument_list|)
expr_stmt|;
while|while
condition|(
name|flushed
operator|!=
name|target
condition|)
block|{
name|maybe_yield
argument_list|()
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|bqlocks
index|[
name|queue
index|]
argument_list|)
expr_stmt|;
name|bp
operator|=
name|TAILQ_NEXT
argument_list|(
name|sentinel
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|!=
name|NULL
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|bufqueues
index|[
name|queue
index|]
argument_list|,
name|sentinel
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|bufqueues
index|[
name|queue
index|]
argument_list|,
name|bp
argument_list|,
name|sentinel
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_unlock
argument_list|(
operator|&
name|bqlocks
index|[
name|queue
index|]
argument_list|)
expr_stmt|;
break|break;
block|}
comment|/* 		 * Skip sentinels inserted by other invocations of the 		 * flushbufqueues(), taking care to not reorder them. 		 * 		 * Only flush the buffers that belong to the 		 * vnode locked by the curthread. 		 */
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_SENTINEL
operator|||
operator|(
name|lvp
operator|!=
name|NULL
operator|&&
name|bp
operator|->
name|b_vp
operator|!=
name|lvp
operator|)
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|bqlocks
index|[
name|queue
index|]
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|error
operator|=
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bqlocks
index|[
name|queue
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
continue|continue;
comment|/* 		 * BKGRDINPROG can only be set with the buf and bufobj 		 * locks both held.  We tolerate a race to clear it here. 		 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_vflags
operator|&
name|BV_BKGRDINPROG
operator|)
operator|!=
literal|0
operator|||
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
name|bremfreef
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|flushed
operator|++
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|!
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|&&
name|buf_countdeps
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
condition|)
block|{
if|if
condition|(
name|flushdeps
operator|==
literal|0
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|hasdeps
operator|=
literal|1
expr_stmt|;
block|}
else|else
name|hasdeps
operator|=
literal|0
expr_stmt|;
comment|/* 		 * We must hold the lock on a vnode before writing 		 * one of its buffers. Otherwise we may confuse, or 		 * in the case of a snapshot vnode, deadlock the 		 * system. 		 * 		 * The lock order here is the reverse of the normal 		 * of vnode followed by buf lock.  This is ok because 		 * the NOWAIT will prevent deadlock. 		 */
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
if|if
condition|(
name|vn_start_write
argument_list|(
name|vp
argument_list|,
operator|&
name|mp
argument_list|,
name|V_NOWAIT
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|lvp
operator|==
name|NULL
condition|)
block|{
name|unlock
operator|=
name|true
expr_stmt|;
name|error
operator|=
name|vn_lock
argument_list|(
name|vp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ASSERT_VOP_LOCKED
argument_list|(
name|vp
argument_list|,
literal|"getbuf"
argument_list|)
expr_stmt|;
name|unlock
operator|=
name|false
expr_stmt|;
name|error
operator|=
name|VOP_ISLOCKED
argument_list|(
name|vp
argument_list|)
operator|==
name|LK_EXCLUSIVE
condition|?
literal|0
else|:
name|vn_lock
argument_list|(
name|vp
argument_list|,
name|LK_TRYUPGRADE
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|error
operator|==
literal|0
condition|)
block|{
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"flushbufqueue(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|curproc
operator|==
name|bufdaemonproc
condition|)
block|{
name|vfs_bio_awrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|notbufdflushes
operator|++
expr_stmt|;
block|}
name|vn_finished_write
argument_list|(
name|mp
argument_list|)
expr_stmt|;
if|if
condition|(
name|unlock
condition|)
name|VOP_UNLOCK
argument_list|(
name|vp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|flushwithdeps
operator|+=
name|hasdeps
expr_stmt|;
name|flushed
operator|++
expr_stmt|;
comment|/* 			 * Sleeping on runningbufspace while holding 			 * vnode lock leads to deadlock. 			 */
if|if
condition|(
name|curproc
operator|==
name|bufdaemonproc
operator|&&
name|runningbufspace
operator|>
name|hirunningspace
condition|)
name|waitrunningbufspace
argument_list|()
expr_stmt|;
continue|continue;
block|}
name|vn_finished_write
argument_list|(
name|mp
argument_list|)
expr_stmt|;
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|mtx_lock
argument_list|(
operator|&
name|bqlocks
index|[
name|queue
index|]
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|bufqueues
index|[
name|queue
index|]
argument_list|,
name|sentinel
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|bqlocks
index|[
name|queue
index|]
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|sentinel
argument_list|,
name|M_TEMP
argument_list|)
expr_stmt|;
return|return
operator|(
name|flushed
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Check to see if a block is currently memory resident.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|incore
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|BO_RLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|bp
operator|=
name|gbincore
argument_list|(
name|bo
argument_list|,
name|blkno
argument_list|)
expr_stmt|;
name|BO_RUNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns true if no I/O is needed to access the  * associated VM object.  This is like incore except  * it also hunts around in the VM system for the data.  */
end_comment

begin_function
specifier|static
name|int
name|inmem
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_offset_t
name|toff
decl_stmt|,
name|tinc
decl_stmt|,
name|size
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_ooffset_t
name|off
decl_stmt|;
name|ASSERT_VOP_LOCKED
argument_list|(
name|vp
argument_list|,
literal|"inmem"
argument_list|)
expr_stmt|;
if|if
condition|(
name|incore
argument_list|(
operator|&
name|vp
operator|->
name|v_bufobj
argument_list|,
name|blkno
argument_list|)
condition|)
return|return
literal|1
return|;
if|if
condition|(
name|vp
operator|->
name|v_mount
operator|==
name|NULL
condition|)
return|return
literal|0
return|;
name|obj
operator|=
name|vp
operator|->
name|v_object
expr_stmt|;
if|if
condition|(
name|obj
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|size
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
name|size
operator|>
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
condition|)
name|size
operator|=
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
name|off
operator|=
operator|(
name|vm_ooffset_t
operator|)
name|blkno
operator|*
operator|(
name|vm_ooffset_t
operator|)
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
name|VM_OBJECT_RLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
for|for
control|(
name|toff
operator|=
literal|0
init|;
name|toff
operator|<
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
condition|;
name|toff
operator|+=
name|tinc
control|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|off
operator|+
name|toff
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|m
condition|)
goto|goto
name|notinmem
goto|;
name|tinc
operator|=
name|size
expr_stmt|;
if|if
condition|(
name|tinc
operator|>
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
operator|)
condition|)
name|tinc
operator|=
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
if|if
condition|(
name|vm_page_is_valid
argument_list|(
name|m
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
argument_list|)
argument_list|,
name|tinc
argument_list|)
operator|==
literal|0
condition|)
goto|goto
name|notinmem
goto|;
block|}
name|VM_OBJECT_RUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
name|notinmem
label|:
name|VM_OBJECT_RUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Set the dirty range for a buffer based on the status of the dirty  * bits in the pages comprising the buffer.  The range is limited  * to the size of the buffer.  *  * Tell the VM system that the pages associated with this buffer  * are clean.  This is used for delayed writes where the data is  * going to go to disk eventually without additional VM intevention.  *  * Note that while we only really need to clean through to b_bcount, we  * just go ahead and clean through to b_bufsize.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_clean_pages_dirty_buf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|vm_ooffset_t
name|foff
decl_stmt|,
name|noff
decl_stmt|,
name|eoff
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
operator|||
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
return|return;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"vfs_clean_pages_dirty_buf: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
name|vfs_drain_busy_pages
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|vfs_setdirty_locked_object
argument_list|(
name|bp
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|noff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
name|eoff
operator|=
name|noff
expr_stmt|;
if|if
condition|(
name|eoff
operator|>
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bufsize
condition|)
name|eoff
operator|=
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|vfs_page_set_validclean
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|m
argument_list|)
expr_stmt|;
comment|/* vm_page_clear_dirty(m, foff& PAGE_MASK, eoff - foff); */
name|foff
operator|=
name|noff
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vfs_setdirty_locked_object
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|int
name|i
decl_stmt|;
name|object
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 	 * We qualify the scan for modified pages on whether the 	 * object has been flushed yet. 	 */
if|if
condition|(
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_MIGHTBEDIRTY
operator|)
operator|!=
literal|0
condition|)
block|{
name|vm_offset_t
name|boffset
decl_stmt|;
name|vm_offset_t
name|eoffset
decl_stmt|;
comment|/* 		 * test the pages to see if they have been modified directly 		 * by users through the VM system. 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
name|vm_page_test_dirty
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|)
expr_stmt|;
comment|/* 		 * Calculate the encompassing dirty range, boffset and eoffset, 		 * (eoffset - boffset) bytes. 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|dirty
condition|)
break|break;
block|}
name|boffset
operator|=
operator|(
name|i
operator|<<
name|PAGE_SHIFT
operator|)
operator|-
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|bp
operator|->
name|b_npages
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
operator|--
name|i
control|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|dirty
condition|)
block|{
break|break;
block|}
block|}
name|eoffset
operator|=
operator|(
operator|(
name|i
operator|+
literal|1
operator|)
operator|<<
name|PAGE_SHIFT
operator|)
operator|-
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
comment|/* 		 * Fit it to the buffer. 		 */
if|if
condition|(
name|eoffset
operator|>
name|bp
operator|->
name|b_bcount
condition|)
name|eoffset
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* 		 * If we have a good dirty range, merge with the existing 		 * dirty range. 		 */
if|if
condition|(
name|boffset
operator|<
name|eoffset
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_dirtyoff
operator|>
name|boffset
condition|)
name|bp
operator|->
name|b_dirtyoff
operator|=
name|boffset
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_dirtyend
operator|<
name|eoffset
condition|)
name|bp
operator|->
name|b_dirtyend
operator|=
name|eoffset
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * Allocate the KVA mapping for an existing buffer.  * If an unmapped buffer is provided but a mapped buffer is requested, take  * also care to properly setup mappings between pages and KVA.  */
end_comment

begin_function
specifier|static
name|void
name|bp_unmapped_get_kva
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|int
name|gbflags
parameter_list|)
block|{
name|int
name|bsize
decl_stmt|,
name|maxsize
decl_stmt|,
name|need_mapping
decl_stmt|,
name|need_kva
decl_stmt|;
name|off_t
name|offset
decl_stmt|;
name|need_mapping
operator|=
name|bp
operator|->
name|b_data
operator|==
name|unmapped_buf
operator|&&
operator|(
name|gbflags
operator|&
name|GB_UNMAPPED
operator|)
operator|==
literal|0
expr_stmt|;
name|need_kva
operator|=
name|bp
operator|->
name|b_kvabase
operator|==
name|unmapped_buf
operator|&&
name|bp
operator|->
name|b_data
operator|==
name|unmapped_buf
operator|&&
operator|(
name|gbflags
operator|&
name|GB_KVAALLOC
operator|)
operator|!=
literal|0
expr_stmt|;
if|if
condition|(
operator|!
name|need_mapping
operator|&&
operator|!
name|need_kva
condition|)
return|return;
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|need_mapping
operator|&&
name|bp
operator|->
name|b_kvabase
operator|!=
name|unmapped_buf
condition|)
block|{
comment|/* 		 * Buffer is not mapped, but the KVA was already 		 * reserved at the time of the instantiation.  Use the 		 * allocated space. 		 */
goto|goto
name|has_addr
goto|;
block|}
comment|/* 	 * Calculate the amount of the address space we would reserve 	 * if the buffer was mapped. 	 */
name|bsize
operator|=
name|vn_isdisk
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|NULL
argument_list|)
condition|?
name|DEV_BSIZE
else|:
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_bsize
expr_stmt|;
name|KASSERT
argument_list|(
name|bsize
operator|!=
literal|0
argument_list|,
operator|(
literal|"bsize == 0, check bo->bo_bsize"
operator|)
argument_list|)
expr_stmt|;
name|offset
operator|=
name|blkno
operator|*
name|bsize
expr_stmt|;
name|maxsize
operator|=
name|size
operator|+
operator|(
name|offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|maxsize
operator|=
name|imax
argument_list|(
name|maxsize
argument_list|,
name|bsize
argument_list|)
expr_stmt|;
while|while
condition|(
name|bufkva_alloc
argument_list|(
name|bp
argument_list|,
name|maxsize
argument_list|,
name|gbflags
argument_list|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|gbflags
operator|&
name|GB_NOWAIT_BD
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * XXXKIB: defragmentation cannot 			 * succeed, not sure what else to do. 			 */
name|panic
argument_list|(
literal|"GB_NOWAIT_BD and GB_UNMAPPED %p"
argument_list|,
name|bp
argument_list|)
expr_stmt|;
block|}
name|atomic_add_int
argument_list|(
operator|&
name|mappingrestarts
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|bufspace_wait
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|gbflags
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|has_addr
label|:
if|if
condition|(
name|need_mapping
condition|)
block|{
comment|/* b_offset is handled by bpmap_qenter. */
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bpmap_qenter
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	getblk:  *  *	Get a block given a specified block and offset into a file/device.  *	The buffers B_DONE bit will be cleared on return, making it almost  * 	ready for an I/O initiation.  B_INVAL may or may not be set on   *	return.  The caller should clear B_INVAL prior to initiating a  *	READ.  *  *	For a non-VMIO buffer, B_CACHE is set to the opposite of B_INVAL for  *	an existing buffer.  *  *	For a VMIO buffer, B_CACHE is modified according to the backing VM.  *	If getblk()ing a previously 0-sized invalid buffer, B_CACHE is set  *	and then cleared based on the backing VM.  If the previous buffer is  *	non-0-sized but invalid, B_CACHE will be cleared.  *  *	If getblk() must create a new buffer, the new buffer is returned with  *	both B_INVAL and B_CACHE clear unless it is a VMIO buffer, in which  *	case it is returned with B_INVAL clear and B_CACHE set based on the  *	backing VM.  *  *	getblk() also forces a bwrite() for any B_DELWRI buffer whos  *	B_CACHE bit is clear.  *	  *	What this means, basically, is that the caller should use B_CACHE to  *	determine whether the buffer is fully valid or not and should clear  *	B_INVAL prior to issuing a read.  If the caller intends to validate  *	the buffer by loading its data area with something, the caller needs  *	to clear B_INVAL.  If the caller does this without issuing an I/O,   *	the caller should set B_CACHE ( as an optimization ), else the caller  *	should issue the I/O and biodone() will set B_CACHE if the I/O was  *	a write attempt or if it was a successful read.  If the caller   *	intends to issue a READ, the caller must clear B_INVAL and BIO_ERROR  *	prior to issuing the READ.  biodone() will *not* clear B_INVAL.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|getblk
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|struct
name|bufobj
modifier|*
name|bo
decl_stmt|;
name|int
name|bsize
decl_stmt|,
name|error
decl_stmt|,
name|maxsize
decl_stmt|,
name|vmio
decl_stmt|;
name|off_t
name|offset
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"getblk(%p, %ld, %d)"
argument_list|,
name|vp
argument_list|,
operator|(
name|long
operator|)
name|blkno
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|flags
operator|&
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
operator|)
operator|!=
name|GB_KVAALLOC
argument_list|,
operator|(
literal|"GB_KVAALLOC only makes sense with GB_UNMAPPED"
operator|)
argument_list|)
expr_stmt|;
name|ASSERT_VOP_LOCKED
argument_list|(
name|vp
argument_list|,
literal|"getblk"
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|>
name|maxbcachebuf
condition|)
name|panic
argument_list|(
literal|"getblk: size(%d)> maxbcachebuf(%d)\n"
argument_list|,
name|size
argument_list|,
name|maxbcachebuf
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|unmapped_buf_allowed
condition|)
name|flags
operator|&=
operator|~
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
expr_stmt|;
name|bo
operator|=
operator|&
name|vp
operator|->
name|v_bufobj
expr_stmt|;
name|loop
label|:
name|BO_RLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|bp
operator|=
name|gbincore
argument_list|(
name|bo
argument_list|,
name|blkno
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|!=
name|NULL
condition|)
block|{
name|int
name|lockflags
decl_stmt|;
comment|/* 		 * Buffer is in-core.  If the buffer is not busy nor managed, 		 * it must be on a queue. 		 */
name|lockflags
operator|=
name|LK_EXCLUSIVE
operator||
name|LK_SLEEPFAIL
operator||
name|LK_INTERLOCK
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|GB_LOCK_NOWAIT
condition|)
name|lockflags
operator||=
name|LK_NOWAIT
expr_stmt|;
name|error
operator|=
name|BUF_TIMELOCK
argument_list|(
name|bp
argument_list|,
name|lockflags
argument_list|,
name|BO_LOCKPTR
argument_list|(
name|bo
argument_list|)
argument_list|,
literal|"getblk"
argument_list|,
name|slpflag
argument_list|,
name|slptimeo
argument_list|)
expr_stmt|;
comment|/* 		 * If we slept and got the lock we have to restart in case 		 * the buffer changed identities. 		 */
if|if
condition|(
name|error
operator|==
name|ENOLCK
condition|)
goto|goto
name|loop
goto|;
comment|/* We timed out or were interrupted. */
elseif|else
if|if
condition|(
name|error
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
comment|/* If recursed, assume caller knows the rules. */
elseif|else
if|if
condition|(
name|BUF_LOCKRECURSED
argument_list|(
name|bp
argument_list|)
condition|)
goto|goto
name|end
goto|;
comment|/* 		 * The buffer is locked.  B_CACHE is cleared if the buffer is  		 * invalid.  Otherwise, for a non-VMIO buffer, B_CACHE is set 		 * and for a VMIO buffer B_CACHE is adjusted according to the 		 * backing VM cache. 		 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_VMIO
operator||
name|B_INVAL
operator|)
operator|)
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MANAGED
condition|)
name|MPASS
argument_list|(
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_NONE
argument_list|)
expr_stmt|;
else|else
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 		 * check for size inconsistencies for non-VMIO case. 		 */
if|if
condition|(
name|bp
operator|->
name|b_bcount
operator|!=
name|size
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
operator|||
operator|(
name|size
operator|>
name|bp
operator|->
name|b_kvasize
operator|)
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_RELBUF
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
goto|goto
name|loop
goto|;
block|}
block|}
comment|/* 		 * Handle the case of unmapped buffer which should 		 * become mapped, or the buffer for which KVA 		 * reservation is requested. 		 */
name|bp_unmapped_get_kva
argument_list|(
name|bp
argument_list|,
name|blkno
argument_list|,
name|size
argument_list|,
name|flags
argument_list|)
expr_stmt|;
comment|/* 		 * If the size is inconsistent in the VMIO case, we can resize 		 * the buffer.  This might lead to B_CACHE getting set or 		 * cleared.  If the size has not changed, B_CACHE remains 		 * unchanged from its previous state. 		 */
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"getblk: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * A buffer with B_DELWRI set and B_CACHE clear must 		 * be committed before we can return the buffer in 		 * order to prevent the caller from issuing a read 		 * ( due to B_CACHE not being set ) and overwriting 		 * it. 		 * 		 * Most callers, including NFS and FFS, need this to 		 * operate properly either because they assume they 		 * can issue a read if B_CACHE is not set, or because 		 * ( for example ) an uncached B_DELWRI might loop due  		 * to softupdates re-dirtying the buffer.  In the latter 		 * case, B_CACHE is set after the first write completes, 		 * preventing further loops. 		 * NOTE!  b*write() sets B_CACHE.  If we cleared B_CACHE 		 * above while extending the buffer, we cannot allow the 		 * buffer to remain with B_CACHE set after the write 		 * completes or it will represent a corrupt state.  To 		 * deal with this we set B_NOCACHE to scrap the buffer 		 * after the write. 		 * 		 * We might be able to do something fancy, like setting 		 * B_CACHE in bwrite() except if B_DELWRI is already set, 		 * so the below call doesn't set B_CACHE, but that gets real 		 * confusing.  This is much easier. 		 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CACHE
operator||
name|B_DELWRI
operator|)
operator|)
operator|==
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|bwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Buffer is not in-core, create new buffer.  The buffer 		 * returned by getnewbuf() is locked.  Note that the returned 		 * buffer is also considered valid (not marked B_INVAL). 		 */
name|BO_RUNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
comment|/* 		 * If the user does not want us to create the buffer, bail out 		 * here. 		 */
if|if
condition|(
name|flags
operator|&
name|GB_NOCREAT
condition|)
return|return
name|NULL
return|;
if|if
condition|(
name|numfreebuffers
operator|==
literal|0
operator|&&
name|TD_IS_IDLETHREAD
argument_list|(
name|curthread
argument_list|)
condition|)
return|return
name|NULL
return|;
name|bsize
operator|=
name|vn_isdisk
argument_list|(
name|vp
argument_list|,
name|NULL
argument_list|)
condition|?
name|DEV_BSIZE
else|:
name|bo
operator|->
name|bo_bsize
expr_stmt|;
name|KASSERT
argument_list|(
name|bsize
operator|!=
literal|0
argument_list|,
operator|(
literal|"bsize == 0, check bo->bo_bsize"
operator|)
argument_list|)
expr_stmt|;
name|offset
operator|=
name|blkno
operator|*
name|bsize
expr_stmt|;
name|vmio
operator|=
name|vp
operator|->
name|v_object
operator|!=
name|NULL
expr_stmt|;
if|if
condition|(
name|vmio
condition|)
block|{
name|maxsize
operator|=
name|size
operator|+
operator|(
name|offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
block|}
else|else
block|{
name|maxsize
operator|=
name|size
expr_stmt|;
comment|/* Do not allow non-VMIO notmapped buffers. */
name|flags
operator|&=
operator|~
operator|(
name|GB_UNMAPPED
operator||
name|GB_KVAALLOC
operator|)
expr_stmt|;
block|}
name|maxsize
operator|=
name|imax
argument_list|(
name|maxsize
argument_list|,
name|bsize
argument_list|)
expr_stmt|;
name|bp
operator|=
name|getnewbuf
argument_list|(
name|vp
argument_list|,
name|slpflag
argument_list|,
name|slptimeo
argument_list|,
name|maxsize
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|slpflag
operator|||
name|slptimeo
condition|)
return|return
name|NULL
return|;
comment|/* 			 * XXX This is here until the sleep path is diagnosed 			 * enough to work under very low memory conditions. 			 * 			 * There's an issue on low memory, 4BSD+non-preempt 			 * systems (eg MIPS routers with 32MB RAM) where buffer 			 * exhaustion occurs without sleeping for buffer 			 * reclaimation.  This just sticks in a loop and 			 * constantly attempts to allocate a buffer, which 			 * hits exhaustion and tries to wakeup bufdaemon. 			 * This never happens because we never yield. 			 * 			 * The real solution is to identify and fix these cases 			 * so we aren't effectively busy-waiting in a loop 			 * until the reclaimation path has cycles to run. 			 */
name|kern_yield
argument_list|(
name|PRI_USER
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
comment|/* 		 * This code is used to make sure that a buffer is not 		 * created while the getnewbuf routine is blocked. 		 * This can be a problem whether the vnode is locked or not. 		 * If the buffer is created out from under us, we have to 		 * throw away the one we just created. 		 * 		 * Note: this must occur before we associate the buffer 		 * with the vp especially considering limitations in 		 * the splay tree implementation when dealing with duplicate 		 * lblkno's. 		 */
name|BO_LOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
if|if
condition|(
name|gbincore
argument_list|(
name|bo
argument_list|,
name|blkno
argument_list|)
condition|)
block|{
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bufspace_release
argument_list|(
name|maxsize
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
comment|/* 		 * Insert the buffer into the hash, so that it can 		 * be found by incore. 		 */
name|bp
operator|->
name|b_blkno
operator|=
name|bp
operator|->
name|b_lblkno
operator|=
name|blkno
expr_stmt|;
name|bp
operator|->
name|b_offset
operator|=
name|offset
expr_stmt|;
name|bgetvp
argument_list|(
name|vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
comment|/* 		 * set B_VMIO bit.  allocbuf() the buffer bigger.  Since the 		 * buffer size starts out as 0, B_CACHE will be set by 		 * allocbuf() for the VMIO case prior to it testing the 		 * backing store for validity. 		 */
if|if
condition|(
name|vmio
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_VMIO
expr_stmt|;
name|KASSERT
argument_list|(
name|vp
operator|->
name|v_object
operator|==
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|,
operator|(
literal|"ARGH! different b_bufobj->bo_object %p %p %p\n"
operator|,
name|bp
operator|,
name|vp
operator|->
name|v_object
operator|,
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_VMIO
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
operator|==
name|NULL
argument_list|,
operator|(
literal|"ARGH! has b_bufobj->bo_object %p %p\n"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
operator|)
argument_list|)
expr_stmt|;
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|bufspace_release
argument_list|(
name|maxsize
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
block|}
name|CTR4
argument_list|(
name|KTR_BUF
argument_list|,
literal|"getblk(%p, %ld, %d) = %p"
argument_list|,
name|vp
argument_list|,
operator|(
name|long
operator|)
name|blkno
argument_list|,
name|size
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|end
label|:
name|buf_track
argument_list|(
name|bp
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|==
name|bo
argument_list|,
operator|(
literal|"bp %p wrong b_bufobj %p should be %p"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_bufobj
operator|,
name|bo
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Get an empty, disassociated buffer of given size.  The buffer is initially  * set to B_INVAL.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|geteblk
parameter_list|(
name|int
name|size
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|maxsize
decl_stmt|;
name|maxsize
operator|=
operator|(
name|size
operator|+
name|BKVAMASK
operator|)
operator|&
operator|~
name|BKVAMASK
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|=
name|getnewbuf
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|maxsize
argument_list|,
name|flags
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|flags
operator|&
name|GB_NOWAIT_BD
operator|)
operator|&&
operator|(
name|curthread
operator|->
name|td_pflags
operator|&
name|TDP_BUFNEED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|bufspace_release
argument_list|(
name|maxsize
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
comment|/* b_dep cleared by getnewbuf() */
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Truncate the backing store for a non-vmio buffer.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_nonvmio_truncate
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|newbsize
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
block|{
comment|/* 		 * malloced buffers are not shrunk 		 */
if|if
condition|(
name|newbsize
operator|==
literal|0
condition|)
block|{
name|bufmallocadjust
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|bp
operator|->
name|b_data
argument_list|,
name|M_BIOBUF
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_MALLOC
expr_stmt|;
block|}
return|return;
block|}
name|vm_hold_free_pages
argument_list|(
name|bp
argument_list|,
name|newbsize
argument_list|)
expr_stmt|;
name|bufspace_adjust
argument_list|(
name|bp
argument_list|,
name|newbsize
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Extend the backing for a non-VMIO buffer.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_nonvmio_extend
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|newbsize
parameter_list|)
block|{
name|caddr_t
name|origbuf
decl_stmt|;
name|int
name|origbufsize
decl_stmt|;
comment|/* 	 * We only use malloced memory on the first allocation. 	 * and revert to page-allocated memory when the buffer 	 * grows. 	 * 	 * There is a potential smp race here that could lead 	 * to bufmallocspace slightly passing the max.  It 	 * is probably extremely rare and not worth worrying 	 * over. 	 */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
operator|&&
name|newbsize
operator|<=
name|PAGE_SIZE
operator|/
literal|2
operator|&&
name|bufmallocspace
operator|<
name|maxbufmallocspace
condition|)
block|{
name|bp
operator|->
name|b_data
operator|=
name|malloc
argument_list|(
name|newbsize
argument_list|,
name|M_BIOBUF
argument_list|,
name|M_WAITOK
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_MALLOC
expr_stmt|;
name|bufmallocadjust
argument_list|(
name|bp
argument_list|,
name|newbsize
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * If the buffer is growing on its other-than-first 	 * allocation then we revert to the page-allocation 	 * scheme. 	 */
name|origbuf
operator|=
name|NULL
expr_stmt|;
name|origbufsize
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
block|{
name|origbuf
operator|=
name|bp
operator|->
name|b_data
expr_stmt|;
name|origbufsize
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|bufmallocadjust
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_MALLOC
expr_stmt|;
name|newbsize
operator|=
name|round_page
argument_list|(
name|newbsize
argument_list|)
expr_stmt|;
block|}
name|vm_hold_load_pages
argument_list|(
name|bp
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|bp
operator|->
name|b_bufsize
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|newbsize
argument_list|)
expr_stmt|;
if|if
condition|(
name|origbuf
operator|!=
name|NULL
condition|)
block|{
name|bcopy
argument_list|(
name|origbuf
argument_list|,
name|bp
operator|->
name|b_data
argument_list|,
name|origbufsize
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|origbuf
argument_list|,
name|M_BIOBUF
argument_list|)
expr_stmt|;
block|}
name|bufspace_adjust
argument_list|(
name|bp
argument_list|,
name|newbsize
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This code constitutes the buffer memory from either anonymous system  * memory (in the case of non-VMIO operations) or from an associated  * VM object (in the case of VMIO operations).  This code is able to  * resize a buffer up or down.  *  * Note that this code is tricky, and has many complications to resolve  * deadlock or inconsistent data situations.  Tread lightly!!!   * There are B_CACHE and B_DELWRI interactions that must be dealt with by   * the caller.  Calling this code willy nilly can result in the loss of data.  *  * allocbuf() only adjusts B_CACHE for VMIO buffers.  getblk() deals with  * B_CACHE for the non-VMIO case.  */
end_comment

begin_function
name|int
name|allocbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|newbsize
decl_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bcount
operator|==
name|size
condition|)
return|return
operator|(
literal|1
operator|)
return|;
if|if
condition|(
name|bp
operator|->
name|b_kvasize
operator|!=
literal|0
operator|&&
name|bp
operator|->
name|b_kvasize
operator|<
name|size
condition|)
name|panic
argument_list|(
literal|"allocbuf: buffer too small"
argument_list|)
expr_stmt|;
name|newbsize
operator|=
name|roundup2
argument_list|(
name|size
argument_list|,
name|DEV_BSIZE
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
operator|)
operator|==
literal|0
condition|)
name|newbsize
operator|=
name|round_page
argument_list|(
name|newbsize
argument_list|)
expr_stmt|;
comment|/* 		 * Just get anonymous memory from the kernel.  Don't 		 * mess with B_CACHE. 		 */
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
name|vfs_nonvmio_truncate
argument_list|(
name|bp
argument_list|,
name|newbsize
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|newbsize
operator|>
name|bp
operator|->
name|b_bufsize
condition|)
name|vfs_nonvmio_extend
argument_list|(
name|bp
argument_list|,
name|newbsize
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|int
name|desiredpages
decl_stmt|;
name|desiredpages
operator|=
operator|(
name|size
operator|==
literal|0
operator|)
condition|?
literal|0
else|:
name|num_pages
argument_list|(
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|+
name|newbsize
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
name|panic
argument_list|(
literal|"allocbuf: VMIO buffer can't be malloced"
argument_list|)
expr_stmt|;
comment|/* 		 * Set B_CACHE initially if buffer is 0 length or will become 		 * 0-length. 		 */
if|if
condition|(
name|size
operator|==
literal|0
operator|||
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
name|vfs_vmio_truncate
argument_list|(
name|bp
argument_list|,
name|desiredpages
argument_list|)
expr_stmt|;
comment|/* XXX This looks as if it should be newbsize> b_bufsize */
elseif|else
if|if
condition|(
name|size
operator|>
name|bp
operator|->
name|b_bcount
condition|)
name|vfs_vmio_extend
argument_list|(
name|bp
argument_list|,
name|desiredpages
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|bufspace_adjust
argument_list|(
name|bp
argument_list|,
name|newbsize
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_bcount
operator|=
name|size
expr_stmt|;
comment|/* requested buffer size. */
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|extern
name|int
name|inflight_transient_maps
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|biodone
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|void
function_decl|(
modifier|*
name|done
function_decl|)
parameter_list|(
name|struct
name|bio
modifier|*
parameter_list|)
function_decl|;
name|vm_offset_t
name|start
decl_stmt|,
name|end
decl_stmt|;
name|biotrack
argument_list|(
name|bp
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|bio_flags
operator|&
name|BIO_TRANSIENT_MAPPING
operator|)
operator|!=
literal|0
condition|)
block|{
name|bp
operator|->
name|bio_flags
operator|&=
operator|~
name|BIO_TRANSIENT_MAPPING
expr_stmt|;
name|bp
operator|->
name|bio_flags
operator||=
name|BIO_UNMAPPED
expr_stmt|;
name|start
operator|=
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|bio_data
argument_list|)
expr_stmt|;
name|end
operator|=
name|round_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|bio_data
operator|+
name|bp
operator|->
name|bio_length
argument_list|)
expr_stmt|;
name|bp
operator|->
name|bio_data
operator|=
name|unmapped_buf
expr_stmt|;
name|pmap_qremove
argument_list|(
name|start
argument_list|,
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
argument_list|)
expr_stmt|;
name|vmem_free
argument_list|(
name|transient_arena
argument_list|,
name|start
argument_list|,
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|inflight_transient_maps
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
name|done
operator|=
name|bp
operator|->
name|bio_done
expr_stmt|;
if|if
condition|(
name|done
operator|==
name|NULL
condition|)
block|{
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|bio_flags
operator||=
name|BIO_DONE
expr_stmt|;
name|wakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
block|}
else|else
name|done
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Wait for a BIO to finish.  */
end_comment

begin_function
name|int
name|biowait
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|,
specifier|const
name|char
modifier|*
name|wchan
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|->
name|bio_flags
operator|&
name|BIO_DONE
operator|)
operator|==
literal|0
condition|)
name|msleep
argument_list|(
name|bp
argument_list|,
name|mtxp
argument_list|,
name|PRIBIO
argument_list|,
name|wchan
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|bio_error
operator|!=
literal|0
condition|)
return|return
operator|(
name|bp
operator|->
name|bio_error
operator|)
return|;
if|if
condition|(
operator|!
operator|(
name|bp
operator|->
name|bio_flags
operator|&
name|BIO_ERROR
operator|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
return|return
operator|(
name|EIO
operator|)
return|;
block|}
end_function

begin_function
name|void
name|biofinish
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|,
name|struct
name|devstat
modifier|*
name|stat
parameter_list|,
name|int
name|error
parameter_list|)
block|{
if|if
condition|(
name|error
condition|)
block|{
name|bp
operator|->
name|bio_error
operator|=
name|error
expr_stmt|;
name|bp
operator|->
name|bio_flags
operator||=
name|BIO_ERROR
expr_stmt|;
block|}
if|if
condition|(
name|stat
operator|!=
name|NULL
condition|)
name|devstat_end_transaction_bio
argument_list|(
name|stat
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|biodone
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_if
if|#
directive|if
name|defined
argument_list|(
name|BUF_TRACKING
argument_list|)
operator|||
name|defined
argument_list|(
name|FULL_BUF_TRACKING
argument_list|)
end_if

begin_function
name|void
name|biotrack_buf
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|,
specifier|const
name|char
modifier|*
name|location
parameter_list|)
block|{
name|buf_track
argument_list|(
name|bp
operator|->
name|bio_track_bp
argument_list|,
name|location
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  *	bufwait:  *  *	Wait for buffer I/O completion, returning error status.  The buffer  *	is left locked and B_DONE on return.  B_EINTR is converted into an EINTR  *	error and cleared.  */
end_comment

begin_function
name|int
name|bufwait
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
condition|)
name|bwait
argument_list|(
name|bp
argument_list|,
name|PRIBIO
argument_list|,
literal|"biord"
argument_list|)
expr_stmt|;
else|else
name|bwait
argument_list|(
name|bp
argument_list|,
name|PRIBIO
argument_list|,
literal|"biowr"
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_EINTR
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_EINTR
expr_stmt|;
return|return
operator|(
name|EINTR
operator|)
return|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
condition|)
block|{
return|return
operator|(
name|bp
operator|->
name|b_error
condition|?
name|bp
operator|->
name|b_error
else|:
name|EIO
operator|)
return|;
block|}
else|else
block|{
return|return
operator|(
literal|0
operator|)
return|;
block|}
block|}
end_function

begin_comment
comment|/*  *	bufdone:  *  *	Finish I/O on a buffer, optionally calling a completion function.  *	This is usually called from an interrupt so process blocking is  *	not allowed.  *  *	biodone is also responsible for setting B_CACHE in a B_VMIO bp.  *	In a non-VMIO bp, B_CACHE will be set on the next getblk()   *	assuming B_INVAL is clear.  *  *	For the VMIO case, we set B_CACHE if the op was a read and no  *	read error occurred, or if the op was a write.  B_CACHE is never  *	set if the buffer is invalid or otherwise uncacheable.  *  *	biodone does not mess with B_INVAL, allowing the I/O routine or the  *	initiator to leave B_INVAL set to brelse the buffer out of existence  *	in the biodone routine.  */
end_comment

begin_function
name|void
name|bufdone
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|bufobj
modifier|*
name|dropobj
decl_stmt|;
name|void
function_decl|(
modifier|*
name|biodone
function_decl|)
parameter_list|(
name|struct
name|buf
modifier|*
parameter_list|)
function_decl|;
name|buf_track
argument_list|(
name|bp
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_BUF
argument_list|,
literal|"bufdone(%p) vp %p flags %X"
argument_list|,
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|)
expr_stmt|;
name|dropobj
operator|=
name|NULL
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DONE
operator|)
argument_list|,
operator|(
literal|"biodone: bp %p already done"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|runningbufwakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_WRITE
condition|)
name|dropobj
operator|=
name|bp
operator|->
name|b_bufobj
expr_stmt|;
comment|/* call optional completion function if requested */
if|if
condition|(
name|bp
operator|->
name|b_iodone
operator|!=
name|NULL
condition|)
block|{
name|biodone
operator|=
name|bp
operator|->
name|b_iodone
expr_stmt|;
name|bp
operator|->
name|b_iodone
operator|=
name|NULL
expr_stmt|;
call|(
modifier|*
name|biodone
call|)
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|dropobj
condition|)
name|bufobj_wdrop
argument_list|(
name|dropobj
argument_list|)
expr_stmt|;
return|return;
block|}
name|bufdone_finish
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|dropobj
condition|)
name|bufobj_wdrop
argument_list|(
name|dropobj
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bufdone_finish
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|BUF_ASSERT_HELD
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
condition|)
name|buf_complete
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
comment|/* 		 * Set B_CACHE if the op was a normal read and no error 		 * occurred.  B_CACHE is set for writes in the b*write() 		 * routines. 		 */
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_NOCACHE
operator|)
operator|)
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
name|vfs_vmio_iodone
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * For asynchronous completions, release the buffer now. The brelse 	 * will do a wakeup there if necessary - so no need to do a wakeup 	 * here in the async case. The sync case always needs to do a wakeup. 	 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ASYNC
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_NOCACHE
operator||
name|B_INVAL
operator||
name|B_RELBUF
operator|)
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
condition|)
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
else|else
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
name|bdone
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine is called in lieu of iodone in the case of  * incomplete I/O.  This keeps the busy status for pages  * consistent.  */
end_comment

begin_function
name|void
name|vfs_unbusy_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|runningbufwakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
condition|)
return|return;
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
operator|+
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|m
condition|)
name|panic
argument_list|(
literal|"vfs_unbusy_pages: page missing\n"
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|m
expr_stmt|;
if|if
condition|(
name|buf_mapped
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
else|else
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|vm_page_sunbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_object_pip_wakeupn
argument_list|(
name|obj
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vfs_page_set_valid:  *  *	Set the valid bits in a page based on the supplied offset.   The  *	range is restricted to the buffer's size.  *  *	This routine is typically called after a read completes.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_page_set_valid
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_ooffset_t
name|eoff
decl_stmt|;
comment|/* 	 * Compute the end offset, eoff, such that [off, eoff) does not span a 	 * page boundary and eoff is not greater than the end of the buffer. 	 * The end of the buffer, in this case, is our file EOF, not the 	 * allocation size of the buffer. 	 */
name|eoff
operator|=
operator|(
name|off
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|vm_ooffset_t
operator|)
name|PAGE_MASK
expr_stmt|;
if|if
condition|(
name|eoff
operator|>
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
condition|)
name|eoff
operator|=
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* 	 * Set valid range.  This is typically the entire buffer and thus the 	 * entire page. 	 */
if|if
condition|(
name|eoff
operator|>
name|off
condition|)
name|vm_page_set_valid_range
argument_list|(
name|m
argument_list|,
name|off
operator|&
name|PAGE_MASK
argument_list|,
name|eoff
operator|-
name|off
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vfs_page_set_validclean:  *  *	Set the valid bits and clear the dirty bits in a page based on the  *	supplied offset.   The range is restricted to the buffer's size.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_page_set_validclean
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_ooffset_t
name|soff
decl_stmt|,
name|eoff
decl_stmt|;
comment|/* 	 * Start and end offsets in buffer.  eoff - soff may not cross a 	 * page boundary or cross the end of the buffer.  The end of the 	 * buffer, in this case, is our file EOF, not the allocation size 	 * of the buffer. 	 */
name|soff
operator|=
name|off
expr_stmt|;
name|eoff
operator|=
operator|(
name|off
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
if|if
condition|(
name|eoff
operator|>
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
condition|)
name|eoff
operator|=
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* 	 * Set valid range.  This is typically the entire buffer and thus the 	 * entire page. 	 */
if|if
condition|(
name|eoff
operator|>
name|soff
condition|)
block|{
name|vm_page_set_validclean
argument_list|(
name|m
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
name|soff
operator|&
name|PAGE_MASK
argument_list|)
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
name|eoff
operator|-
name|soff
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Ensure that all buffer pages are not exclusive busied.  If any page is  * exclusive busy, drain it.  */
end_comment

begin_function
name|void
name|vfs_drain_busy_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|,
name|last_busied
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
name|last_busied
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
block|{
for|for
control|(
init|;
name|last_busied
operator|<
name|i
condition|;
name|last_busied
operator|++
control|)
name|vm_page_sbusy
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|last_busied
index|]
argument_list|)
expr_stmt|;
while|while
condition|(
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
block|{
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
name|vm_page_busy_sleep
argument_list|(
name|m
argument_list|,
literal|"vbpage"
argument_list|,
name|true
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
block|}
block|}
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|last_busied
condition|;
name|i
operator|++
control|)
name|vm_page_sunbusy
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine is called before a device strategy routine.  * It is used to tell the VM system that paging I/O is in  * progress, and treat the pages associated with the buffer  * almost as being exclusive busy.  Also the object paging_in_progress  * flag is handled to make sure that the object doesn't become  * inconsistent.  *  * Since I/O has not been initiated yet, certain buffer flags  * such as BIO_ERROR or B_INVAL may be in an inconsistent state  * and should be ignored.  */
end_comment

begin_function
name|void
name|vfs_busy_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|clear_modify
parameter_list|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_ooffset_t
name|foff
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
name|bool
name|bogus
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
condition|)
return|return;
name|obj
operator|=
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
expr_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"vfs_busy_pages: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
name|vfs_drain_busy_pages
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|!=
literal|0
condition|)
name|vfs_setdirty_locked_object
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bogus
operator|=
name|false
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CLUSTER
operator|)
operator|==
literal|0
condition|)
block|{
name|vm_object_pip_add
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_sbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * When readying a buffer for a read ( i.e 		 * clear_modify == 0 ), it is important to do 		 * bogus_page replacement for valid pages in  		 * partially instantiated buffers.  Partially  		 * instantiated buffers can, in turn, occur when 		 * reconstituting a buffer from its VM backing store 		 * base.  We only have to do this if B_CACHE is 		 * clear ( which causes the I/O to occur in the 		 * first place ).  The replacement prevents the read 		 * I/O from overwriting potentially dirty VM-backed 		 * pages.  XXX bogus page replacement is, uh, bogus. 		 * It may not work properly with small-block devices. 		 * We need to find a better way. 		 */
if|if
condition|(
name|clear_modify
condition|)
block|{
name|pmap_remove_write
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vfs_page_set_validclean
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|bogus_page
expr_stmt|;
name|bogus
operator|=
name|true
expr_stmt|;
block|}
name|foff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
if|if
condition|(
name|bogus
operator|&&
name|buf_mapped
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_set_valid:  *  *	Set the range within the buffer to valid.  The range is  *	relative to the beginning of the buffer, b_offset.  Note that  *	b_offset itself may be offset from the beginning of the first  *	page.  */
end_comment

begin_function
name|void
name|vfs_bio_set_valid
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|n
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
condition|)
return|return;
comment|/* 	 * Fixup base to be relative to beginning of first page. 	 * Set initial n to be the maximum number of bytes in the 	 * first page that can be validated. 	 */
name|base
operator|+=
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
operator|-
operator|(
name|base
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|base
operator|/
name|PAGE_SIZE
init|;
name|size
operator|>
literal|0
operator|&&
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
operator|++
name|i
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|n
operator|>
name|size
condition|)
name|n
operator|=
name|size
expr_stmt|;
name|vm_page_set_valid_range
argument_list|(
name|m
argument_list|,
name|base
operator|&
name|PAGE_MASK
argument_list|,
name|n
argument_list|)
expr_stmt|;
name|base
operator|+=
name|n
expr_stmt|;
name|size
operator|-=
name|n
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_clrbuf:  *  *	If the specified buffer is a non-VMIO buffer, clear the entire  *	buffer.  If the specified buffer is a VMIO buffer, clear and  *	validate only the previously invalid portions of the buffer.  *	This routine essentially fakes an I/O, so we need to clear  *	BIO_ERROR and B_INVAL.  *  *	Note that while we only theoretically need to clear through b_bcount,  *	we go ahead and clear through b_bufsize.  */
end_comment

begin_function
name|void
name|vfs_bio_clrbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|j
decl_stmt|,
name|mask
decl_stmt|,
name|sa
decl_stmt|,
name|ea
decl_stmt|,
name|slide
decl_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_VMIO
operator||
name|B_MALLOC
operator|)
operator|)
operator|!=
name|B_VMIO
condition|)
block|{
name|clrbuf
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INVAL
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_npages
operator|==
literal|1
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_bufsize
operator|<
name|PAGE_SIZE
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|==
name|bogus_page
condition|)
goto|goto
name|unlock
goto|;
name|mask
operator|=
operator|(
literal|1
operator|<<
operator|(
name|bp
operator|->
name|b_bufsize
operator|/
name|DEV_BSIZE
operator|)
operator|)
operator|-
literal|1
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
name|mask
condition|)
goto|goto
name|unlock
goto|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
argument_list|,
literal|0
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator||=
name|mask
expr_stmt|;
goto|goto
name|unlock
goto|;
block|}
block|}
name|sa
operator|=
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|slide
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
operator|,
name|sa
operator|=
literal|0
control|)
block|{
name|slide
operator|=
name|imin
argument_list|(
name|slide
operator|+
name|PAGE_SIZE
argument_list|,
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
name|ea
operator|=
name|slide
operator|&
name|PAGE_MASK
expr_stmt|;
if|if
condition|(
name|ea
operator|==
literal|0
condition|)
name|ea
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|==
name|bogus_page
condition|)
continue|continue;
name|j
operator|=
name|sa
operator|/
name|DEV_BSIZE
expr_stmt|;
name|mask
operator|=
operator|(
operator|(
literal|1
operator|<<
operator|(
operator|(
name|ea
operator|-
name|sa
operator|)
operator|/
name|DEV_BSIZE
operator|)
operator|)
operator|-
literal|1
operator|)
operator|<<
name|j
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
name|mask
condition|)
continue|continue;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|,
name|sa
argument_list|,
name|ea
operator|-
name|sa
argument_list|)
expr_stmt|;
else|else
block|{
for|for
control|(
init|;
name|sa
operator|<
name|ea
condition|;
name|sa
operator|+=
name|DEV_BSIZE
operator|,
name|j
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
name|j
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|,
name|sa
argument_list|,
name|DEV_BSIZE
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator||=
name|mask
expr_stmt|;
block|}
name|unlock
label|:
name|VM_OBJECT_WUNLOCK
argument_list|(
name|bp
operator|->
name|b_bufobj
operator|->
name|bo_object
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vfs_bio_bzero_buf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|,
name|n
decl_stmt|;
if|if
condition|(
name|buf_mapped
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
name|bp
operator|->
name|b_data
operator|+
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|BUF_CHECK_UNMAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
operator|-
operator|(
name|base
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|base
operator|/
name|PAGE_SIZE
init|;
name|size
operator|>
literal|0
operator|&&
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
operator|++
name|i
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|n
operator|>
name|size
condition|)
name|n
operator|=
name|size
expr_stmt|;
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|base
operator|&
name|PAGE_MASK
argument_list|,
name|n
argument_list|)
expr_stmt|;
name|base
operator|+=
name|n
expr_stmt|;
name|size
operator|-=
name|n
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * Update buffer flags based on I/O request parameters, optionally releasing the  * buffer.  If it's VMIO or direct I/O, the buffer pages are released to the VM,  * where they may be placed on a page queue (VMIO) or freed immediately (direct  * I/O).  Otherwise the buffer is released to the cache.  */
end_comment

begin_function
specifier|static
name|void
name|b_io_dismiss
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|ioflag
parameter_list|,
name|bool
name|release
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|ioflag
operator|&
name|IO_NOREUSE
operator|)
operator|==
literal|0
operator|||
operator|(
name|ioflag
operator|&
name|IO_VMIO
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"buf %p non-VMIO noreuse"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|ioflag
operator|&
name|IO_DIRECT
operator|)
operator|!=
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_DIRECT
expr_stmt|;
if|if
condition|(
operator|(
name|ioflag
operator|&
operator|(
name|IO_VMIO
operator||
name|IO_DIRECT
operator|)
operator|)
operator|!=
literal|0
operator|&&
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_RELBUF
expr_stmt|;
if|if
condition|(
operator|(
name|ioflag
operator|&
name|IO_NOREUSE
operator|)
operator|!=
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_NOREUSE
expr_stmt|;
if|if
condition|(
name|release
condition|)
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|release
condition|)
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vfs_bio_brelse
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|ioflag
parameter_list|)
block|{
name|b_io_dismiss
argument_list|(
name|bp
argument_list|,
name|ioflag
argument_list|,
name|true
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vfs_bio_set_flags
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|ioflag
parameter_list|)
block|{
name|b_io_dismiss
argument_list|(
name|bp
argument_list|,
name|ioflag
argument_list|,
name|false
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_hold_load_pages and vm_hold_free_pages get pages into  * a buffers address space.  The pages are anonymous and are  * not associated with a file object.  */
end_comment

begin_function
specifier|static
name|void
name|vm_hold_load_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
block|{
name|vm_offset_t
name|pg
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|int
name|index
decl_stmt|;
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|to
operator|=
name|round_page
argument_list|(
name|to
argument_list|)
expr_stmt|;
name|from
operator|=
name|round_page
argument_list|(
name|from
argument_list|)
expr_stmt|;
name|index
operator|=
operator|(
name|from
operator|-
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
for|for
control|(
name|pg
operator|=
name|from
init|;
name|pg
operator|<
name|to
condition|;
name|pg
operator|+=
name|PAGE_SIZE
operator|,
name|index
operator|++
control|)
block|{
name|tryagain
label|:
comment|/* 		 * note: must allocate system pages since blocking here 		 * could interfere with paging I/O, no matter which 		 * process we are. 		 */
name|p
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_SYSTEM
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_COUNT
argument_list|(
operator|(
name|to
operator|-
name|pg
operator|)
operator|>>
name|PAGE_SHIFT
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
operator|==
name|NULL
condition|)
block|{
name|VM_WAIT
expr_stmt|;
goto|goto
name|tryagain
goto|;
block|}
name|pmap_qenter
argument_list|(
name|pg
argument_list|,
operator|&
name|p
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
operator|=
name|p
expr_stmt|;
block|}
name|bp
operator|->
name|b_npages
operator|=
name|index
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Return pages associated with this buf to the vm system */
end_comment

begin_function
specifier|static
name|void
name|vm_hold_free_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|newbsize
parameter_list|)
block|{
name|vm_offset_t
name|from
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|int
name|index
decl_stmt|,
name|newnpages
decl_stmt|;
name|BUF_CHECK_MAPPED
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|from
operator|=
name|round_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|newbsize
argument_list|)
expr_stmt|;
name|newnpages
operator|=
operator|(
name|from
operator|-
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_npages
operator|>
name|newnpages
condition|)
name|pmap_qremove
argument_list|(
name|from
argument_list|,
name|bp
operator|->
name|b_npages
operator|-
name|newnpages
argument_list|)
expr_stmt|;
for|for
control|(
name|index
operator|=
name|newnpages
init|;
name|index
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|index
operator|++
control|)
block|{
name|p
operator|=
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|vm_page_sbusied
argument_list|(
name|p
argument_list|)
condition|)
name|printf
argument_list|(
literal|"vm_hold_free_pages: blkno: %jd, lblkno: %jd\n"
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_blkno
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_lblkno
argument_list|)
expr_stmt|;
name|p
operator|->
name|wire_count
operator|--
expr_stmt|;
name|vm_page_free
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_npages
operator|=
name|newnpages
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map an IO request into kernel virtual address space.  *  * All requests are (re)mapped into kernel VA space.  * Notice that we use b_bufsize for the size of the buffer  * to be mapped.  b_bcount might be modified by the driver.  *  * Note that even if the caller determines that the address space should  * be valid, a race or a smaller-file mapped into a larger space may  * actually cause vmapbuf() to fail, so all callers of vmapbuf() MUST  * check the return value.  *  * This function only works with pager buffers.  */
end_comment

begin_function
name|int
name|vmapbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|mapbuf
parameter_list|)
block|{
name|vm_prot_t
name|prot
decl_stmt|;
name|int
name|pidx
decl_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|<
literal|0
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
name|prot
operator|=
name|VM_PROT_READ
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
condition|)
name|prot
operator||=
name|VM_PROT_WRITE
expr_stmt|;
comment|/* Less backwards than it looks */
if|if
condition|(
operator|(
name|pidx
operator|=
name|vm_fault_quick_hold_pages
argument_list|(
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_map
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|,
name|prot
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|btoc
argument_list|(
name|MAXPHYS
argument_list|)
argument_list|)
operator|)
operator|<
literal|0
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
name|bp
operator|->
name|b_npages
operator|=
name|pidx
expr_stmt|;
name|bp
operator|->
name|b_offset
operator|=
operator|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|)
operator|&
name|PAGE_MASK
expr_stmt|;
if|if
condition|(
name|mapbuf
operator|||
operator|!
name|unmapped_buf_allowed
condition|)
block|{
name|pmap_qenter
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_kvabase
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|pidx
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
operator|+
name|bp
operator|->
name|b_offset
expr_stmt|;
block|}
else|else
name|bp
operator|->
name|b_data
operator|=
name|unmapped_buf
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Free the io map PTEs associated with this IO operation.  * We also invalidate the TLB entries and restore the original b_addr.  *  * This function only works with pager buffers.  */
end_comment

begin_function
name|void
name|vunmapbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|npages
decl_stmt|;
name|npages
operator|=
name|bp
operator|->
name|b_npages
expr_stmt|;
if|if
condition|(
name|buf_mapped
argument_list|(
name|bp
argument_list|)
condition|)
name|pmap_qremove
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|npages
argument_list|)
expr_stmt|;
name|vm_page_unhold_pages
argument_list|(
name|bp
operator|->
name|b_pages
argument_list|,
name|npages
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|unmapped_buf
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bdone
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_DONE
expr_stmt|;
name|wakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bwait
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|u_char
name|pri
parameter_list|,
specifier|const
name|char
modifier|*
name|wchan
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtxp
decl_stmt|;
name|mtxp
operator|=
name|mtx_pool_find
argument_list|(
name|mtxpool_sleep
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DONE
operator|)
operator|==
literal|0
condition|)
name|msleep
argument_list|(
name|bp
argument_list|,
name|mtxp
argument_list|,
name|pri
argument_list|,
name|wchan
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|mtxp
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|bufsync
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|,
name|int
name|waitfor
parameter_list|)
block|{
return|return
operator|(
name|VOP_FSYNC
argument_list|(
name|bo2vnode
argument_list|(
name|bo
argument_list|)
argument_list|,
name|waitfor
argument_list|,
name|curthread
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|bufstrategy
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|,
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
init|=
literal|0
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
name|KASSERT
argument_list|(
name|vp
operator|==
name|bo
operator|->
name|bo_private
argument_list|,
operator|(
literal|"Inconsistent vnode bufstrategy"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|vp
operator|->
name|v_type
operator|!=
name|VCHR
operator|&&
name|vp
operator|->
name|v_type
operator|!=
name|VBLK
argument_list|,
operator|(
literal|"Wrong vnode in bufstrategy(bp=%p, vp=%p)"
operator|,
name|bp
operator|,
name|vp
operator|)
argument_list|)
expr_stmt|;
name|i
operator|=
name|VOP_STRATEGY
argument_list|(
name|vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|i
operator|==
literal|0
argument_list|,
operator|(
literal|"VOP_STRATEGY failed bp=%p vp=%p"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_vp
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bufobj_wrefl
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|bo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"NULL bo in bufobj_wref"
operator|)
argument_list|)
expr_stmt|;
name|ASSERT_BO_WLOCKED
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|bo
operator|->
name|bo_numoutput
operator|++
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bufobj_wref
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|bo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"NULL bo in bufobj_wref"
operator|)
argument_list|)
expr_stmt|;
name|BO_LOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|bo
operator|->
name|bo_numoutput
operator|++
expr_stmt|;
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bufobj_wdrop
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|bo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"NULL bo in bufobj_wdrop"
operator|)
argument_list|)
expr_stmt|;
name|BO_LOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bo
operator|->
name|bo_numoutput
operator|>
literal|0
argument_list|,
operator|(
literal|"bufobj_wdrop non-positive count"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|--
name|bo
operator|->
name|bo_numoutput
operator|==
literal|0
operator|)
operator|&&
operator|(
name|bo
operator|->
name|bo_flag
operator|&
name|BO_WWAIT
operator|)
condition|)
block|{
name|bo
operator|->
name|bo_flag
operator|&=
operator|~
name|BO_WWAIT
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|bo
operator|->
name|bo_numoutput
argument_list|)
expr_stmt|;
block|}
name|BO_UNLOCK
argument_list|(
name|bo
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|bufobj_wwait
parameter_list|(
name|struct
name|bufobj
modifier|*
name|bo
parameter_list|,
name|int
name|slpflag
parameter_list|,
name|int
name|timeo
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
name|KASSERT
argument_list|(
name|bo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"NULL bo in bufobj_wwait"
operator|)
argument_list|)
expr_stmt|;
name|ASSERT_BO_WLOCKED
argument_list|(
name|bo
argument_list|)
expr_stmt|;
name|error
operator|=
literal|0
expr_stmt|;
while|while
condition|(
name|bo
operator|->
name|bo_numoutput
condition|)
block|{
name|bo
operator|->
name|bo_flag
operator||=
name|BO_WWAIT
expr_stmt|;
name|error
operator|=
name|msleep
argument_list|(
operator|&
name|bo
operator|->
name|bo_numoutput
argument_list|,
name|BO_LOCKPTR
argument_list|(
name|bo
argument_list|)
argument_list|,
name|slpflag
operator||
operator|(
name|PRIBIO
operator|+
literal|1
operator|)
argument_list|,
literal|"bo_wwait"
argument_list|,
name|timeo
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
break|break;
block|}
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Set bio_data or bio_ma for struct bio from the struct buf.  */
end_comment

begin_function
name|void
name|bdata2bio
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|struct
name|bio
modifier|*
name|bip
parameter_list|)
block|{
if|if
condition|(
operator|!
name|buf_mapped
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|KASSERT
argument_list|(
name|unmapped_buf_allowed
argument_list|,
operator|(
literal|"unmapped"
operator|)
argument_list|)
expr_stmt|;
name|bip
operator|->
name|bio_ma
operator|=
name|bp
operator|->
name|b_pages
expr_stmt|;
name|bip
operator|->
name|bio_ma_n
operator|=
name|bp
operator|->
name|b_npages
expr_stmt|;
name|bip
operator|->
name|bio_data
operator|=
name|unmapped_buf
expr_stmt|;
name|bip
operator|->
name|bio_ma_offset
operator|=
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|bip
operator|->
name|bio_flags
operator||=
name|BIO_UNMAPPED
expr_stmt|;
name|KASSERT
argument_list|(
name|round_page
argument_list|(
name|bip
operator|->
name|bio_ma_offset
operator|+
name|bip
operator|->
name|bio_length
argument_list|)
operator|/
name|PAGE_SIZE
operator|==
name|bp
operator|->
name|b_npages
argument_list|,
operator|(
literal|"Buffer %p too short: %d %lld %d"
operator|,
name|bp
operator|,
name|bip
operator|->
name|bio_ma_offset
operator|,
operator|(
name|long
name|long
operator|)
name|bip
operator|->
name|bio_length
operator|,
name|bip
operator|->
name|bio_ma_n
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bip
operator|->
name|bio_data
operator|=
name|bp
operator|->
name|b_data
expr_stmt|;
name|bip
operator|->
name|bio_ma
operator|=
name|NULL
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * The MIPS pmap code currently doesn't handle aliased pages.  * The VIPT caches may not handle page aliasing themselves, leading  * to data corruption.  *  * As such, this code makes a system extremely unhappy if said  * system doesn't support unaliasing the above situation in hardware.  * Some "recent" systems (eg some mips24k/mips74k cores) don't enable  * this feature at build time, so it has to be handled in software.  *  * Once the MIPS pmap/cache code grows to support this function on  * earlier chips, it should be flipped back off.  */
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|__mips__
end_ifdef

begin_decl_stmt
specifier|static
name|int
name|buf_pager_relbuf
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_else
else|#
directive|else
end_else

begin_decl_stmt
specifier|static
name|int
name|buf_pager_relbuf
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|buf_pager_relbuf
argument_list|,
name|CTLFLAG_RWTUN
argument_list|,
operator|&
name|buf_pager_relbuf
argument_list|,
literal|0
argument_list|,
literal|"Make buffer pager release buffers after reading"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * The buffer pager.  It uses buffer reads to validate pages.  *  * In contrast to the generic local pager from vm/vnode_pager.c, this  * pager correctly and easily handles volumes where the underlying  * device block size is greater than the machine page size.  The  * buffer cache transparently extends the requested page run to be  * aligned at the block boundary, and does the necessary bogus page  * replacements in the addends to avoid obliterating already valid  * pages.  *  * The only non-trivial issue is that the exclusive busy state for  * pages, which is assumed by the vm_pager_getpages() interface, is  * incompatible with the VMIO buffer cache's desire to share-busy the  * pages.  This function performs a trivial downgrade of the pages'  * state before reading buffers, and a less trivial upgrade from the  * shared-busy to excl-busy state after the read.  */
end_comment

begin_function
name|int
name|vfs_bio_getpages
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|int
name|count
parameter_list|,
name|int
modifier|*
name|rbehind
parameter_list|,
name|int
modifier|*
name|rahead
parameter_list|,
name|vbg_get_lblkno_t
name|get_lblkno
parameter_list|,
name|vbg_get_blksize_t
name|get_blksize
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|struct
name|mount
modifier|*
name|mp
decl_stmt|;
name|daddr_t
name|lbn
decl_stmt|,
name|lbnp
decl_stmt|;
name|vm_ooffset_t
name|la
decl_stmt|,
name|lb
decl_stmt|,
name|poff
decl_stmt|,
name|poffe
decl_stmt|;
name|long
name|bsize
decl_stmt|;
name|int
name|bo_bs
decl_stmt|,
name|br_flags
decl_stmt|,
name|error
decl_stmt|,
name|i
decl_stmt|,
name|pgsin
decl_stmt|,
name|pgsin_a
decl_stmt|,
name|pgsin_b
decl_stmt|;
name|bool
name|redo
decl_stmt|,
name|lpart
decl_stmt|;
name|object
operator|=
name|vp
operator|->
name|v_object
expr_stmt|;
name|mp
operator|=
name|vp
operator|->
name|v_mount
expr_stmt|;
name|la
operator|=
name|IDX_TO_OFF
argument_list|(
name|ma
index|[
name|count
operator|-
literal|1
index|]
operator|->
name|pindex
argument_list|)
expr_stmt|;
if|if
condition|(
name|la
operator|>=
name|object
operator|->
name|un_pager
operator|.
name|vnp
operator|.
name|vnp_size
condition|)
return|return
operator|(
name|VM_PAGER_BAD
operator|)
return|;
name|lpart
operator|=
name|la
operator|+
name|PAGE_SIZE
operator|>
name|object
operator|->
name|un_pager
operator|.
name|vnp
operator|.
name|vnp_size
expr_stmt|;
name|bo_bs
operator|=
name|get_blksize
argument_list|(
name|vp
argument_list|,
name|get_lblkno
argument_list|(
name|vp
argument_list|,
name|IDX_TO_OFF
argument_list|(
name|ma
index|[
literal|0
index|]
operator|->
name|pindex
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Calculate read-ahead, behind and total pages. 	 */
name|pgsin
operator|=
name|count
expr_stmt|;
name|lb
operator|=
name|IDX_TO_OFF
argument_list|(
name|ma
index|[
literal|0
index|]
operator|->
name|pindex
argument_list|)
expr_stmt|;
name|pgsin_b
operator|=
name|OFF_TO_IDX
argument_list|(
name|lb
operator|-
name|rounddown2
argument_list|(
name|lb
argument_list|,
name|bo_bs
argument_list|)
argument_list|)
expr_stmt|;
name|pgsin
operator|+=
name|pgsin_b
expr_stmt|;
if|if
condition|(
name|rbehind
operator|!=
name|NULL
condition|)
operator|*
name|rbehind
operator|=
name|pgsin_b
expr_stmt|;
name|pgsin_a
operator|=
name|OFF_TO_IDX
argument_list|(
name|roundup2
argument_list|(
name|la
argument_list|,
name|bo_bs
argument_list|)
operator|-
name|la
argument_list|)
expr_stmt|;
if|if
condition|(
name|la
operator|+
name|IDX_TO_OFF
argument_list|(
name|pgsin_a
argument_list|)
operator|>=
name|object
operator|->
name|un_pager
operator|.
name|vnp
operator|.
name|vnp_size
condition|)
name|pgsin_a
operator|=
name|OFF_TO_IDX
argument_list|(
name|roundup2
argument_list|(
name|object
operator|->
name|un_pager
operator|.
name|vnp
operator|.
name|vnp_size
argument_list|,
name|PAGE_SIZE
argument_list|)
operator|-
name|la
argument_list|)
expr_stmt|;
name|pgsin
operator|+=
name|pgsin_a
expr_stmt|;
if|if
condition|(
name|rahead
operator|!=
name|NULL
condition|)
operator|*
name|rahead
operator|=
name|pgsin_a
expr_stmt|;
name|VM_CNT_INC
argument_list|(
name|v_vnodein
argument_list|)
expr_stmt|;
name|VM_CNT_ADD
argument_list|(
name|v_vnodepgsin
argument_list|,
name|pgsin
argument_list|)
expr_stmt|;
name|br_flags
operator|=
operator|(
name|mp
operator|!=
name|NULL
operator|&&
operator|(
name|mp
operator|->
name|mnt_kern_flag
operator|&
name|MNTK_UNMAPPED_BUFS
operator|)
operator|!=
literal|0
operator|)
condition|?
name|GB_UNMAPPED
else|:
literal|0
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|again
label|:
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
name|vm_page_busy_downgrade
argument_list|(
name|ma
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|lbnp
operator|=
operator|-
literal|1
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|ma
index|[
name|i
index|]
expr_stmt|;
comment|/* 		 * Pages are shared busy and the object lock is not 		 * owned, which together allow for the pages' 		 * invalidation.  The racy test for validity avoids 		 * useless creation of the buffer for the most typical 		 * case when invalidation is not used in redo or for 		 * parallel read.  The shared->excl upgrade loop at 		 * the end of the function catches the race in a 		 * reliable way (protected by the object lock). 		 */
if|if
condition|(
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
condition|)
continue|continue;
name|poff
operator|=
name|IDX_TO_OFF
argument_list|(
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
name|poffe
operator|=
name|MIN
argument_list|(
name|poff
operator|+
name|PAGE_SIZE
argument_list|,
name|object
operator|->
name|un_pager
operator|.
name|vnp
operator|.
name|vnp_size
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|poff
operator|<
name|poffe
condition|;
name|poff
operator|+=
name|bsize
control|)
block|{
name|lbn
operator|=
name|get_lblkno
argument_list|(
name|vp
argument_list|,
name|poff
argument_list|)
expr_stmt|;
if|if
condition|(
name|lbn
operator|==
name|lbnp
condition|)
goto|goto
name|next_page
goto|;
name|lbnp
operator|=
name|lbn
expr_stmt|;
name|bsize
operator|=
name|get_blksize
argument_list|(
name|vp
argument_list|,
name|lbn
argument_list|)
expr_stmt|;
name|error
operator|=
name|bread_gb
argument_list|(
name|vp
argument_list|,
name|lbn
argument_list|,
name|bsize
argument_list|,
name|curthread
operator|->
name|td_ucred
argument_list|,
name|br_flags
argument_list|,
operator|&
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
goto|goto
name|end_pages
goto|;
if|if
condition|(
name|LIST_EMPTY
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
condition|)
block|{
comment|/* 				 * Invalidation clears m->valid, but 				 * may leave B_CACHE flag if the 				 * buffer existed at the invalidation 				 * time.  In this case, recycle the 				 * buffer to do real read on next 				 * bread() after redo. 				 * 				 * Otherwise B_RELBUF is not strictly 				 * necessary, enable to reduce buf 				 * cache pressure. 				 */
if|if
condition|(
name|buf_pager_relbuf
operator|||
name|m
operator|->
name|valid
operator|!=
name|VM_PAGE_BITS_ALL
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_RELBUF
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_NOCACHE
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
name|KASSERT
argument_list|(
literal|1
comment|/* racy, enable for debugging */
operator|||
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|||
name|i
operator|==
name|count
operator|-
literal|1
argument_list|,
operator|(
literal|"buf %d %p invalid"
operator|,
name|i
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|==
name|count
operator|-
literal|1
operator|&&
name|lpart
condition|)
block|{
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|!=
literal|0
operator|&&
name|m
operator|->
name|valid
operator|!=
name|VM_PAGE_BITS_ALL
condition|)
name|vm_page_zero_invalid
argument_list|(
name|m
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
name|next_page
label|:
empty_stmt|;
block|}
name|end_pages
label|:
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|redo
operator|=
name|false
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_sunbusy
argument_list|(
name|ma
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|ma
index|[
name|i
index|]
operator|=
name|vm_page_grab
argument_list|(
name|object
argument_list|,
name|ma
index|[
name|i
index|]
operator|->
name|pindex
argument_list|,
name|VM_ALLOC_NORMAL
argument_list|)
expr_stmt|;
comment|/* 		 * Since the pages were only sbusy while neither the 		 * buffer nor the object lock was held by us, or 		 * reallocated while vm_page_grab() slept for busy 		 * relinguish, they could have been invalidated. 		 * Recheck the valid bits and re-read as needed. 		 * 		 * Note that the last page is made fully valid in the 		 * read loop, and partial validity for the page at 		 * index count - 1 could mean that the page was 		 * invalidated or removed, so we must restart for 		 * safety as well. 		 */
if|if
condition|(
name|ma
index|[
name|i
index|]
operator|->
name|valid
operator|!=
name|VM_PAGE_BITS_ALL
condition|)
name|redo
operator|=
name|true
expr_stmt|;
block|}
if|if
condition|(
name|redo
operator|&&
name|error
operator|==
literal|0
condition|)
goto|goto
name|again
goto|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|!=
literal|0
condition|?
name|VM_PAGER_ERROR
else|:
name|VM_PAGER_OK
operator|)
return|;
block|}
end_function

begin_include
include|#
directive|include
file|"opt_ddb.h"
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_include
include|#
directive|include
file|<ddb/ddb.h>
end_include

begin_comment
comment|/* DDB command to show buffer data */
end_comment

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|buffer
argument_list|,
argument|db_show_buffer
argument_list|)
end_macro

begin_block
block|{
comment|/* get args */
name|struct
name|buf
modifier|*
name|bp
init|=
operator|(
expr|struct
name|buf
operator|*
operator|)
name|addr
decl_stmt|;
ifdef|#
directive|ifdef
name|FULL_BUF_TRACKING
name|uint32_t
name|i
decl_stmt|,
name|j
decl_stmt|;
endif|#
directive|endif
if|if
condition|(
operator|!
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"usage: show buffer<addr>\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|db_printf
argument_list|(
literal|"buf at %p\n"
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"b_flags = 0x%b, b_xflags=0x%b, b_vflags=0x%b\n"
argument_list|,
operator|(
name|u_int
operator|)
name|bp
operator|->
name|b_flags
argument_list|,
name|PRINT_BUF_FLAGS
argument_list|,
operator|(
name|u_int
operator|)
name|bp
operator|->
name|b_xflags
argument_list|,
name|PRINT_BUF_XFLAGS
argument_list|,
operator|(
name|u_int
operator|)
name|bp
operator|->
name|b_vflags
argument_list|,
name|PRINT_BUF_VFLAGS
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"b_error = %d, b_bufsize = %ld, b_bcount = %ld, b_resid = %ld\n"
literal|"b_bufobj = (%p), b_data = %p, b_blkno = %jd, b_lblkno = %jd, "
literal|"b_dep = %p\n"
argument_list|,
name|bp
operator|->
name|b_error
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|,
name|bp
operator|->
name|b_bcount
argument_list|,
name|bp
operator|->
name|b_resid
argument_list|,
name|bp
operator|->
name|b_bufobj
argument_list|,
name|bp
operator|->
name|b_data
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_blkno
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_lblkno
argument_list|,
name|bp
operator|->
name|b_dep
operator|.
name|lh_first
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"b_kvabase = %p, b_kvasize = %d\n"
argument_list|,
name|bp
operator|->
name|b_kvabase
argument_list|,
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_npages
condition|)
block|{
name|int
name|i
decl_stmt|;
name|db_printf
argument_list|(
literal|"b_npages = %d, pages(OBJ, IDX, PA): "
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|m
operator|!=
name|NULL
condition|)
name|db_printf
argument_list|(
literal|"(%p, 0x%lx, 0x%lx)"
argument_list|,
name|m
operator|->
name|object
argument_list|,
operator|(
name|u_long
operator|)
name|m
operator|->
name|pindex
argument_list|,
operator|(
name|u_long
operator|)
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
else|else
name|db_printf
argument_list|(
literal|"( ??? )"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|i
operator|+
literal|1
operator|)
operator|<
name|bp
operator|->
name|b_npages
condition|)
name|db_printf
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
if|#
directive|if
name|defined
argument_list|(
name|FULL_BUF_TRACKING
argument_list|)
name|db_printf
argument_list|(
literal|"b_io_tracking: b_io_tcnt = %u\n"
argument_list|,
name|bp
operator|->
name|b_io_tcnt
argument_list|)
expr_stmt|;
name|i
operator|=
name|bp
operator|->
name|b_io_tcnt
operator|%
name|BUF_TRACKING_SIZE
expr_stmt|;
for|for
control|(
name|j
operator|=
literal|1
init|;
name|j
operator|<=
name|BUF_TRACKING_SIZE
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_io_tracking
index|[
name|BUF_TRACKING_ENTRY
argument_list|(
name|i
operator|-
name|j
argument_list|)
index|]
operator|==
name|NULL
condition|)
continue|continue;
name|db_printf
argument_list|(
literal|" %2u: %s\n"
argument_list|,
name|j
argument_list|,
name|bp
operator|->
name|b_io_tracking
index|[
name|BUF_TRACKING_ENTRY
argument_list|(
name|i
operator|-
name|j
argument_list|)
index|]
argument_list|)
expr_stmt|;
block|}
elif|#
directive|elif
name|defined
argument_list|(
name|BUF_TRACKING
argument_list|)
name|db_printf
argument_list|(
literal|"b_io_tracking: %s\n"
argument_list|,
name|bp
operator|->
name|b_io_tracking
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|db_printf
argument_list|(
literal|" "
argument_list|)
expr_stmt|;
name|BUF_LOCKPRINTINFO
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_block

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|lockedbufs
argument_list|,
argument|lockedbufs
argument_list|)
end_macro

begin_block
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nbuf
condition|;
name|i
operator|++
control|)
block|{
name|bp
operator|=
operator|&
name|buf
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|BUF_ISLOCKED
argument_list|(
name|bp
argument_list|)
condition|)
block|{
name|db_show_buffer
argument_list|(
operator|(
name|uintptr_t
operator|)
name|bp
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
if|if
condition|(
name|db_pager_quit
condition|)
break|break;
block|}
block|}
block|}
end_block

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|vnodebufs
argument_list|,
argument|db_show_vnodebufs
argument_list|)
end_macro

begin_block
block|{
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
if|if
condition|(
operator|!
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"usage: show vnodebufs<addr>\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|vp
operator|=
operator|(
expr|struct
name|vnode
operator|*
operator|)
name|addr
expr_stmt|;
name|db_printf
argument_list|(
literal|"Clean buffers:\n"
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|bp
argument_list|,
argument|&vp->v_bufobj.bo_clean.bv_hd
argument_list|,
argument|b_bobufs
argument_list|)
block|{
name|db_show_buffer
argument_list|(
operator|(
name|uintptr_t
operator|)
name|bp
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"Dirty buffers:\n"
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|bp
argument_list|,
argument|&vp->v_bufobj.bo_dirty.bv_hd
argument_list|,
argument|b_bobufs
argument_list|)
block|{
name|db_show_buffer
argument_list|(
operator|(
name|uintptr_t
operator|)
name|bp
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
block|}
end_block

begin_macro
name|DB_COMMAND
argument_list|(
argument|countfreebufs
argument_list|,
argument|db_coundfreebufs
argument_list|)
end_macro

begin_block
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|i
decl_stmt|,
name|used
init|=
literal|0
decl_stmt|,
name|nfree
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"usage: countfreebufs\n"
argument_list|)
expr_stmt|;
return|return;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nbuf
condition|;
name|i
operator|++
control|)
block|{
name|bp
operator|=
operator|&
name|buf
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_EMPTY
condition|)
name|nfree
operator|++
expr_stmt|;
else|else
name|used
operator|++
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"Counted %d free, %d used (%d tot)\n"
argument_list|,
name|nfree
argument_list|,
name|used
argument_list|,
name|nfree
operator|+
name|used
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"numfreebuffers is %d\n"
argument_list|,
name|numfreebuffers
argument_list|)
expr_stmt|;
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* DDB */
end_comment

end_unit

