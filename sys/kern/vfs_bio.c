begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * Copyright (c) 1994,1997 John S. Dyson  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice immediately at the beginning of the file, without modification,  *    this list of conditions, and the following disclaimer.  * 2. Absolutely no warranty of function or purpose is made by the author  *		John S. Dyson.  *  * $FreeBSD$  */
end_comment

begin_comment
comment|/*  * this file contains a new buffer I/O scheme implementing a coherent  * VM object and buffer cache scheme.  Pains have been taken to make  * sure that the performance degradation associated with schemes such  * as this is not realized.  *  * Author:  John S. Dyson  * Significant help during the development and debugging phases  * had been provided by David Greenman, also of the FreeBSD core team.  *  * see man buf(9) for more info.  */
end_comment

begin_define
define|#
directive|define
name|VMIO
end_define

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/kthread.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_prot.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<sys/buf.h>
end_include

begin_include
include|#
directive|include
file|<sys/mount.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/conf.h>
end_include

begin_expr_stmt
specifier|static
name|MALLOC_DEFINE
argument_list|(
name|M_BIOBUF
argument_list|,
literal|"BIO buffer"
argument_list|,
literal|"BIO buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|struct
name|bio_ops
name|bioops
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* I/O operation notification */
end_comment

begin_decl_stmt
name|struct
name|buf
modifier|*
name|buf
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* buffer header pool */
end_comment

begin_decl_stmt
name|struct
name|swqueue
name|bswlist
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|void
name|vm_hold_free_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_hold_load_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_page_set_valid
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|int
name|pageno
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_clean_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_setdirty
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_vmio_release
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|flushbufqueues
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
specifier|static
name|int
name|bd_request
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|void
name|buf_daemon
name|__P
argument_list|(
operator|(
name|void
operator|)
argument_list|)
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * bogus page -- for I/O to/from partially complete buffers  * this is a temporary solution to the problem, but it is not  * really that bad.  it would be better to split the buffer  * for input in the case of buffers partially already in memory,  * but the code is intricate enough already.  */
end_comment

begin_decl_stmt
name|vm_page_t
name|bogus_page
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|runningbufspace
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|vmiodirenable
init|=
name|FALSE
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|vm_offset_t
name|bogus_offset
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|bufspace
decl_stmt|,
name|maxbufspace
decl_stmt|,
name|vmiospace
decl_stmt|,
name|bufmallocspace
decl_stmt|,
name|maxbufmallocspace
decl_stmt|,
name|hibufspace
decl_stmt|;
end_decl_stmt

begin_if
if|#
directive|if
literal|0
end_if

begin_endif
unit|static int maxvmiobufspace;
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|int
name|maxbdrun
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|needsbuffer
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|numdirtybuffers
decl_stmt|,
name|lodirtybuffers
decl_stmt|,
name|hidirtybuffers
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|numfreebuffers
decl_stmt|,
name|lofreebuffers
decl_stmt|,
name|hifreebuffers
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|getnewbufcalls
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|getnewbufrestarts
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|kvafreespace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|numdirtybuffers
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|numdirtybuffers
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lodirtybuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|lodirtybuffers
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hidirtybuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|hidirtybuffers
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|numfreebuffers
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|numfreebuffers
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lofreebuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|lofreebuffers
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hifreebuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|hifreebuffers
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|runningbufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|runningbufspace
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|maxbufspace
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|maxbufspace
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hibufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|hibufspace
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufspace
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|maxbdrun
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|maxbdrun
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_if
if|#
directive|if
literal|0
end_if

begin_endif
unit|SYSCTL_INT(_vfs, OID_AUTO, maxvmiobufspace, CTLFLAG_RW,&maxvmiobufspace, 0, "");
endif|#
directive|endif
end_endif

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|vmiospace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|vmiospace
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|maxmallocbufspace
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|maxbufmallocspace
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufmallocspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufmallocspace
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|kvafreespace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|kvafreespace
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|getnewbufcalls
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|getnewbufcalls
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|getnewbufrestarts
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|getnewbufrestarts
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|vmiodirenable
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vmiodirenable
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|bufhashmask
decl_stmt|;
end_decl_stmt

begin_expr_stmt
specifier|static
name|LIST_HEAD
argument_list|(
name|bufhashhdr
argument_list|,
name|buf
argument_list|)
operator|*
name|bufhashtbl
operator|,
name|invalhash
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|struct
name|bqueues
name|bufqueues
index|[
name|BUFFER_QUEUES
index|]
init|=
block|{
block|{
literal|0
block|}
block|}
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|char
modifier|*
name|buf_wmesg
init|=
name|BUF_WMESG
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|int
name|vm_swap_size
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|BUF_MAXUSE
value|24
end_define

begin_define
define|#
directive|define
name|VFS_BIO_NEED_ANY
value|0x01
end_define

begin_comment
comment|/* any freeable buffer */
end_comment

begin_define
define|#
directive|define
name|VFS_BIO_NEED_DIRTYFLUSH
value|0x02
end_define

begin_comment
comment|/* waiting for dirty buffer flush */
end_comment

begin_define
define|#
directive|define
name|VFS_BIO_NEED_FREE
value|0x04
end_define

begin_comment
comment|/* wait for free bufs, hi hysteresis */
end_comment

begin_define
define|#
directive|define
name|VFS_BIO_NEED_BUFSPACE
value|0x08
end_define

begin_comment
comment|/* wait for buf space, lo hysteresis */
end_comment

begin_define
define|#
directive|define
name|VFS_BIO_NEED_KVASPACE
value|0x10
end_define

begin_comment
comment|/* wait for buffer_map space, emerg  */
end_comment

begin_comment
comment|/*  * Buffer hash table code.  Note that the logical block scans linearly, which  * gives us some L1 cache locality.  */
end_comment

begin_expr_stmt
specifier|static
name|__inline
expr|struct
name|bufhashhdr
operator|*
name|bufhash
argument_list|(
argument|struct vnode *vnp
argument_list|,
argument|daddr_t bn
argument_list|)
block|{
return|return
operator|(
operator|&
name|bufhashtbl
index|[
operator|(
operator|(
call|(
name|uintptr_t
call|)
argument_list|(
name|vnp
argument_list|)
operator|>>
literal|7
operator|)
operator|+
operator|(
name|int
operator|)
name|bn
operator|)
operator|&
name|bufhashmask
index|]
operator|)
return|;
block|}
end_expr_stmt

begin_comment
comment|/*  *	kvaspacewakeup:  *  *	Called when kva space is potential available for recovery or when  *	kva space is recovered in the buffer_map.  This function wakes up  *	anyone waiting for buffer_map kva space.  Even though the buffer_map  *	is larger then maxbufspace, this situation will typically occur   *	when the buffer_map gets fragmented.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|kvaspacewakeup
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * If someone is waiting for KVA space, wake them up.  Even 	 * though we haven't freed the kva space yet, the waiting 	 * process will be able to now. 	 */
if|if
condition|(
name|needsbuffer
operator|&
name|VFS_BIO_NEED_KVASPACE
condition|)
block|{
name|needsbuffer
operator|&=
operator|~
name|VFS_BIO_NEED_KVASPACE
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|needsbuffer
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	numdirtywakeup:  *  *	If someone is blocked due to there being too many dirty buffers,  *	and numdirtybuffers is now reasonable, wake them up.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|numdirtywakeup
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|numdirtybuffers
operator|<
name|hidirtybuffers
condition|)
block|{
if|if
condition|(
name|needsbuffer
operator|&
name|VFS_BIO_NEED_DIRTYFLUSH
condition|)
block|{
name|needsbuffer
operator|&=
operator|~
name|VFS_BIO_NEED_DIRTYFLUSH
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|needsbuffer
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	bufspacewakeup:  *  *	Called when buffer space is potentially available for recovery or when  *	buffer space is recovered.  getnewbuf() will block on this flag when  *	it is unable to free sufficient buffer space.  Buffer space becomes  *	recoverable when bp's get placed back in the queues.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|bufspacewakeup
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * If someone is waiting for BUF space, wake them up.  Even 	 * though we haven't freed the kva space yet, the waiting 	 * process will be able to now. 	 */
if|if
condition|(
name|needsbuffer
operator|&
name|VFS_BIO_NEED_BUFSPACE
condition|)
block|{
name|needsbuffer
operator|&=
operator|~
name|VFS_BIO_NEED_BUFSPACE
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|needsbuffer
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	bufcountwakeup:  *  *	Called when a buffer has been added to one of the free queues to  *	account for the buffer and to wakeup anyone waiting for free buffers.  *	This typically occurs when large amounts of metadata are being handled  *	by the buffer cache ( else buffer space runs out first, usually ).  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|bufcountwakeup
parameter_list|(
name|void
parameter_list|)
block|{
operator|++
name|numfreebuffers
expr_stmt|;
if|if
condition|(
name|needsbuffer
condition|)
block|{
name|needsbuffer
operator|&=
operator|~
name|VFS_BIO_NEED_ANY
expr_stmt|;
if|if
condition|(
name|numfreebuffers
operator|>=
name|hifreebuffers
condition|)
name|needsbuffer
operator|&=
operator|~
name|VFS_BIO_NEED_FREE
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|needsbuffer
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vfs_buf_test_cache:  *  *	Called when a buffer is extended.  This function clears the B_CACHE  *	bit if the newly extended portion of the buffer does not contain  *	valid data.  */
end_comment

begin_function
specifier|static
name|__inline__
name|void
name|vfs_buf_test_cache
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|foff
parameter_list|,
name|vm_offset_t
name|off
parameter_list|,
name|vm_offset_t
name|size
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
condition|)
block|{
name|int
name|base
init|=
operator|(
name|foff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
decl_stmt|;
if|if
condition|(
name|vm_page_is_valid
argument_list|(
name|m
argument_list|,
name|base
argument_list|,
name|size
argument_list|)
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|__inline__
name|void
name|bd_wakeup
parameter_list|(
name|int
name|dirtybuflevel
parameter_list|)
block|{
if|if
condition|(
name|numdirtybuffers
operator|>=
name|dirtybuflevel
operator|&&
name|bd_request
operator|==
literal|0
condition|)
block|{
name|bd_request
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|bd_request
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Initialize buffer headers and related structures.   */
end_comment

begin_function
name|caddr_t
name|bufhashinit
parameter_list|(
name|caddr_t
name|vaddr
parameter_list|)
block|{
comment|/* first, make a null hash table */
for|for
control|(
name|bufhashmask
operator|=
literal|8
init|;
name|bufhashmask
operator|<
name|nbuf
operator|/
literal|4
condition|;
name|bufhashmask
operator|<<=
literal|1
control|)
empty_stmt|;
name|bufhashtbl
operator|=
operator|(
name|void
operator|*
operator|)
name|vaddr
expr_stmt|;
name|vaddr
operator|=
name|vaddr
operator|+
sizeof|sizeof
argument_list|(
operator|*
name|bufhashtbl
argument_list|)
operator|*
name|bufhashmask
expr_stmt|;
operator|--
name|bufhashmask
expr_stmt|;
return|return
operator|(
name|vaddr
operator|)
return|;
block|}
end_function

begin_function
name|void
name|bufinit
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|i
decl_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|bswlist
argument_list|)
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|invalhash
argument_list|)
expr_stmt|;
name|simple_lock_init
argument_list|(
operator|&
name|buftimelock
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|bufhashmask
condition|;
name|i
operator|++
control|)
name|LIST_INIT
argument_list|(
operator|&
name|bufhashtbl
index|[
name|i
index|]
argument_list|)
expr_stmt|;
comment|/* next, make a null set of free lists */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|BUFFER_QUEUES
condition|;
name|i
operator|++
control|)
name|TAILQ_INIT
argument_list|(
operator|&
name|bufqueues
index|[
name|i
index|]
argument_list|)
expr_stmt|;
comment|/* finally, initialize each buffer header and stick on empty q */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nbuf
condition|;
name|i
operator|++
control|)
block|{
name|bp
operator|=
operator|&
name|buf
index|[
name|i
index|]
expr_stmt|;
name|bzero
argument_list|(
name|bp
argument_list|,
sizeof|sizeof
expr|*
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|=
name|B_INVAL
expr_stmt|;
comment|/* we're just an empty header */
name|bp
operator|->
name|b_dev
operator|=
name|NODEV
expr_stmt|;
name|bp
operator|->
name|b_rcred
operator|=
name|NOCRED
expr_stmt|;
name|bp
operator|->
name|b_wcred
operator|=
name|NOCRED
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|bp
operator|->
name|b_xflags
operator|=
literal|0
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
expr_stmt|;
name|BUF_LOCKINIT
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTY
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|invalhash
argument_list|,
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * maxbufspace is currently calculated to support all filesystem  	 * blocks to be 8K.  If you happen to use a 16K filesystem, the size 	 * of the buffer cache is still the same as it would be for 8K  	 * filesystems.  This keeps the size of the buffer cache "in check"  	 * for big block filesystems. 	 * 	 * maxbufspace is calculated as around 50% of the KVA available in 	 * the buffer_map ( DFLTSIZE vs BKVASIZE ), I presume to reduce the  	 * effect of fragmentation. 	 */
name|maxbufspace
operator|=
operator|(
name|nbuf
operator|+
literal|8
operator|)
operator|*
name|DFLTBSIZE
expr_stmt|;
if|if
condition|(
operator|(
name|hibufspace
operator|=
name|maxbufspace
operator|-
name|MAXBSIZE
operator|*
literal|5
operator|)
operator|<=
name|MAXBSIZE
condition|)
name|hibufspace
operator|=
literal|3
operator|*
name|maxbufspace
operator|/
literal|4
expr_stmt|;
if|#
directive|if
literal|0
comment|/*  * reserve 1/3 of the buffers for metadata (VDIR) which might not be VMIO'ed  */
block|maxvmiobufspace = 2 * hibufspace / 3;
endif|#
directive|endif
comment|/*  * Limit the amount of malloc memory since it is wired permanently into  * the kernel space.  Even though this is accounted for in the buffer  * allocation, we don't want the malloced region to grow uncontrolled.  * The malloc scheme improves memory utilization significantly on average  * (small) directories.  */
name|maxbufmallocspace
operator|=
name|hibufspace
operator|/
literal|20
expr_stmt|;
comment|/*  * Reduce the chance of a deadlock occuring by limiting the number  * of delayed-write dirty buffers we allow to stack up.  */
name|lodirtybuffers
operator|=
name|nbuf
operator|/
literal|7
operator|+
literal|10
expr_stmt|;
name|hidirtybuffers
operator|=
name|nbuf
operator|/
literal|4
operator|+
literal|20
expr_stmt|;
name|numdirtybuffers
operator|=
literal|0
expr_stmt|;
comment|/*  * Try to keep the number of free buffers in the specified range,  * and give the syncer access to an emergency reserve.  */
name|lofreebuffers
operator|=
name|nbuf
operator|/
literal|18
operator|+
literal|5
expr_stmt|;
name|hifreebuffers
operator|=
literal|2
operator|*
name|lofreebuffers
expr_stmt|;
name|numfreebuffers
operator|=
name|nbuf
expr_stmt|;
comment|/*  * Maximum number of async ops initiated per buf_daemon loop.  This is  * somewhat of a hack at the moment, we really need to limit ourselves  * based on the number of bytes of I/O in-transit that were initiated  * from buf_daemon.  */
if|if
condition|(
operator|(
name|maxbdrun
operator|=
name|nswbuf
operator|/
literal|4
operator|)
operator|<
literal|4
condition|)
name|maxbdrun
operator|=
literal|4
expr_stmt|;
name|kvafreespace
operator|=
literal|0
expr_stmt|;
name|bogus_offset
operator|=
name|kmem_alloc_pageable
argument_list|(
name|kernel_map
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|bogus_page
operator|=
name|vm_page_alloc
argument_list|(
name|kernel_object
argument_list|,
operator|(
operator|(
name|bogus_offset
operator|-
name|VM_MIN_KERNEL_ADDRESS
operator|)
operator|>>
name|PAGE_SHIFT
operator|)
argument_list|,
name|VM_ALLOC_NORMAL
argument_list|)
expr_stmt|;
name|cnt
operator|.
name|v_wire_count
operator|++
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Free the kva allocation for a buffer  * Must be called only at splbio or higher,  *  as this is the only locking for buffer_map.  */
end_comment

begin_function
specifier|static
name|void
name|bfreekva
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_kvasize
condition|)
block|{
name|vm_map_delete
argument_list|(
name|buffer_map
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_kvabase
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_kvabase
operator|+
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_kvasize
operator|=
literal|0
expr_stmt|;
name|kvaspacewakeup
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	bremfree:  *  *	Remove the buffer from the appropriate free list.  */
end_comment

begin_function
name|void
name|bremfree
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|s
init|=
name|splbio
argument_list|()
decl_stmt|;
name|int
name|old_qindex
init|=
name|bp
operator|->
name|b_qindex
decl_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_EMPTYKVA
condition|)
block|{
name|kvafreespace
operator|-=
name|bp
operator|->
name|b_kvasize
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|==
literal|1
argument_list|,
operator|(
literal|"bremfree: bp %p not locked"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_NONE
expr_stmt|;
name|runningbufspace
operator|+=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
block|}
else|else
block|{
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|<=
literal|1
condition|)
name|panic
argument_list|(
literal|"bremfree: removing a buffer not on a queue"
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
comment|/* 	 * Fixup numfreebuffers count.  If the buffer is invalid or not 	 * delayed-write, and it was on the EMPTY, LRU, or AGE queues, 	 * the buffer was free and we must decrement numfreebuffers. 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
condition|)
block|{
switch|switch
condition|(
name|old_qindex
condition|)
block|{
case|case
name|QUEUE_DIRTY
case|:
case|case
name|QUEUE_CLEAN
case|:
case|case
name|QUEUE_EMPTY
case|:
case|case
name|QUEUE_EMPTYKVA
case|:
operator|--
name|numfreebuffers
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Get a buffer with the specified data.  Look in the cache first.  We  * must clear B_ERROR and B_INVAL prior to initiating I/O.  If B_CACHE  * is set, the buffer is valid and we do not have to do anything ( see  * getblk() ).  */
end_comment

begin_function
name|int
name|bread
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|struct
name|ucred
modifier|*
name|cred
parameter_list|,
name|struct
name|buf
modifier|*
modifier|*
name|bpp
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|bp
operator|=
name|getblk
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|,
name|size
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
operator|*
name|bpp
operator|=
name|bp
expr_stmt|;
comment|/* if not found in cache, do some I/O */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|curproc
operator|!=
name|NULL
condition|)
name|curproc
operator|->
name|p_stats
operator|->
name|p_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ASYNC
operator|)
argument_list|,
operator|(
literal|"bread: illegal async bp %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_READ
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ERROR
operator||
name|B_INVAL
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_rcred
operator|==
name|NOCRED
condition|)
block|{
if|if
condition|(
name|cred
operator|!=
name|NOCRED
condition|)
name|crhold
argument_list|(
name|cred
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_rcred
operator|=
name|cred
expr_stmt|;
block|}
name|vfs_busy_pages
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|VOP_STRATEGY
argument_list|(
name|vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|biowait
argument_list|(
name|bp
argument_list|)
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Operates like bread, but also starts asynchronous I/O on  * read-ahead blocks.  We must clear B_ERROR and B_INVAL prior  * to initiating I/O . If B_CACHE is set, the buffer is valid   * and we do not have to do anything.  */
end_comment

begin_function
name|int
name|breadn
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|daddr_t
modifier|*
name|rablkno
parameter_list|,
name|int
modifier|*
name|rabsize
parameter_list|,
name|int
name|cnt
parameter_list|,
name|struct
name|ucred
modifier|*
name|cred
parameter_list|,
name|struct
name|buf
modifier|*
modifier|*
name|bpp
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|,
modifier|*
name|rabp
decl_stmt|;
name|int
name|i
decl_stmt|;
name|int
name|rv
init|=
literal|0
decl_stmt|,
name|readwait
init|=
literal|0
decl_stmt|;
operator|*
name|bpp
operator|=
name|bp
operator|=
name|getblk
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|,
name|size
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* if not found in cache, do some I/O */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|curproc
operator|!=
name|NULL
condition|)
name|curproc
operator|->
name|p_stats
operator|->
name|p_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_READ
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ERROR
operator||
name|B_INVAL
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_rcred
operator|==
name|NOCRED
condition|)
block|{
if|if
condition|(
name|cred
operator|!=
name|NOCRED
condition|)
name|crhold
argument_list|(
name|cred
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_rcred
operator|=
name|cred
expr_stmt|;
block|}
name|vfs_busy_pages
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|VOP_STRATEGY
argument_list|(
name|vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
operator|++
name|readwait
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|cnt
condition|;
name|i
operator|++
operator|,
name|rablkno
operator|++
operator|,
name|rabsize
operator|++
control|)
block|{
if|if
condition|(
name|inmem
argument_list|(
name|vp
argument_list|,
operator|*
name|rablkno
argument_list|)
condition|)
continue|continue;
name|rabp
operator|=
name|getblk
argument_list|(
name|vp
argument_list|,
operator|*
name|rablkno
argument_list|,
operator|*
name|rabsize
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|rabp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|curproc
operator|!=
name|NULL
condition|)
name|curproc
operator|->
name|p_stats
operator|->
name|p_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
name|rabp
operator|->
name|b_flags
operator||=
name|B_READ
operator||
name|B_ASYNC
expr_stmt|;
name|rabp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ERROR
operator||
name|B_INVAL
operator|)
expr_stmt|;
if|if
condition|(
name|rabp
operator|->
name|b_rcred
operator|==
name|NOCRED
condition|)
block|{
if|if
condition|(
name|cred
operator|!=
name|NOCRED
condition|)
name|crhold
argument_list|(
name|cred
argument_list|)
expr_stmt|;
name|rabp
operator|->
name|b_rcred
operator|=
name|cred
expr_stmt|;
block|}
name|vfs_busy_pages
argument_list|(
name|rabp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|BUF_KERNPROC
argument_list|(
name|rabp
argument_list|)
expr_stmt|;
name|VOP_STRATEGY
argument_list|(
name|vp
argument_list|,
name|rabp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|brelse
argument_list|(
name|rabp
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|readwait
condition|)
block|{
name|rv
operator|=
name|biowait
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Write, release buffer on completion.  (Done by iodone  * if async).  Do not bother writing anything if the buffer  * is invalid.  *  * Note that we set B_CACHE here, indicating that buffer is  * fully valid and thus cacheable.  This is true even of NFS  * now so we set it generally.  This could be set either here   * or in biodone() since the I/O is synchronous.  We put it  * here.  */
end_comment

begin_function
name|int
name|bwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|oldflags
decl_stmt|,
name|s
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|struct
name|mount
modifier|*
name|mp
decl_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|oldflags
operator|=
name|bp
operator|->
name|b_flags
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"bwrite: buffer is not busy???"
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
name|bundirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_READ
operator||
name|B_DONE
operator||
name|B_ERROR
operator|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_WRITEINPROG
operator||
name|B_CACHE
expr_stmt|;
name|bp
operator|->
name|b_vp
operator|->
name|v_numoutput
operator|++
expr_stmt|;
name|vfs_busy_pages
argument_list|(
name|bp
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|curproc
operator|!=
name|NULL
condition|)
name|curproc
operator|->
name|p_stats
operator|->
name|p_ru
operator|.
name|ru_oublock
operator|++
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldflags
operator|&
name|B_ASYNC
condition|)
name|BUF_KERNPROC
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|VOP_STRATEGY
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * Collect statistics on synchronous and asynchronous writes. 	 * Writes to block devices are charged to their associated 	 * filesystem (if any). 	 */
if|if
condition|(
operator|(
name|vp
operator|=
name|bp
operator|->
name|b_vp
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|vp
operator|->
name|v_type
operator|==
name|VBLK
condition|)
name|mp
operator|=
name|vp
operator|->
name|v_specmountpoint
expr_stmt|;
else|else
name|mp
operator|=
name|vp
operator|->
name|v_mount
expr_stmt|;
if|if
condition|(
name|mp
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|oldflags
operator|&
name|B_ASYNC
operator|)
operator|==
literal|0
condition|)
name|mp
operator|->
name|mnt_stat
operator|.
name|f_syncwrites
operator|++
expr_stmt|;
else|else
name|mp
operator|->
name|mnt_stat
operator|.
name|f_asyncwrites
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|(
name|oldflags
operator|&
name|B_ASYNC
operator|)
operator|==
literal|0
condition|)
block|{
name|int
name|rtval
init|=
name|biowait
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|rtval
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Delayed write. (Buffer is marked dirty).  Do not bother writing  * anything if the buffer is marked invalid.  *  * Note that since the buffer must be completely valid, we can safely  * set B_CACHE.  In fact, we have to set B_CACHE here rather then in  * biodone() in order to prevent getblk from writing the buffer  * out synchronously.  */
end_comment

begin_function
name|void
name|bdwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
if|#
directive|if
literal|0
block|struct vnode *vp;
endif|#
directive|endif
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"bdwrite: buffer is not busy"
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
name|bdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * Set B_CACHE, indicating that the buffer is fully valid.  This is 	 * true even of NFS now. 	 */
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
comment|/* 	 * This bmap keeps the system from needing to do the bmap later, 	 * perhaps when the system is attempting to do a sync.  Since it 	 * is likely that the indirect block -- or whatever other datastructure 	 * that the filesystem needs is still in memory now, it is a good 	 * thing to do this.  Note also, that if the pageout daemon is 	 * requesting a sync -- there might not be enough memory to do 	 * the bmap then...  So, this is important to do. 	 */
if|if
condition|(
name|bp
operator|->
name|b_lblkno
operator|==
name|bp
operator|->
name|b_blkno
condition|)
block|{
name|VOP_BMAP
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_lblkno
argument_list|,
name|NULL
argument_list|,
operator|&
name|bp
operator|->
name|b_blkno
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Set the *dirty* buffer range based upon the VM system dirty pages. 	 */
name|vfs_setdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * We need to do this here to satisfy the vnode_pager and the 	 * pageout daemon, so that it thinks that the pages have been 	 * "cleaned".  Note that since the pages are in a delayed write 	 * buffer -- the VFS layer "will" see that the pages get written 	 * out on the next sync, or perhaps the cluster will be completed. 	 */
name|vfs_clean_pages
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * Wakeup the buffer flushing daemon if we have saturated the 	 * buffer cache. 	 */
name|bd_wakeup
argument_list|(
name|hidirtybuffers
argument_list|)
expr_stmt|;
comment|/* 	 * note: we cannot initiate I/O from a bdwrite even if we wanted to, 	 * due to the softdep code. 	 */
if|#
directive|if
literal|0
comment|/* 	 * XXX The soft dependency code is not prepared to 	 * have I/O done when a bdwrite is requested. For 	 * now we just let the write be delayed if it is 	 * requested by the soft dependency code. 	 */
block|if ((vp = bp->b_vp)&& 	    ((vp->v_type == VBLK&& vp->v_specmountpoint&& 		  (vp->v_specmountpoint->mnt_flag& MNT_SOFTDEP)) || 		 (vp->v_mount&& (vp->v_mount->mnt_flag& MNT_SOFTDEP)))) 		return;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  *	bdirty:  *  *	Turn buffer into delayed write request.  We must clear B_READ and  *	B_RELBUF, and we must set B_DELWRI.  We reassign the buffer to   *	itself to properly update it in the dirty/clean lists.  We mark it  *	B_DONE to ensure that any asynchronization of the buffer properly  *	clears B_DONE ( else a panic will occur later ).    *  *	bdirty() is kinda like bdwrite() - we have to clear B_INVAL which  *	might have been set pre-getblk().  Unlike bwrite/bdwrite, bdirty()  *	should only be called if the buffer is known-good.  *  *	Since the buffer is not on a queue, we do not update the numfreebuffers  *	count.  *  *	Must be called at splbio().  *	The buffer must be on QUEUE_NONE.  */
end_comment

begin_function
name|void
name|bdirty
parameter_list|(
name|bp
parameter_list|)
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
block|{
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bdirty: buffer %p still on queue %d"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_qindex
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_READ
operator||
name|B_RELBUF
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_DONE
operator||
name|B_DELWRI
expr_stmt|;
name|reassignbuf
argument_list|(
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|)
expr_stmt|;
operator|++
name|numdirtybuffers
expr_stmt|;
name|bd_wakeup
argument_list|(
name|hidirtybuffers
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	bundirty:  *  *	Clear B_DELWRI for buffer.  *  *	Since the buffer is not on a queue, we do not update the numfreebuffers  *	count.  *	  *	Must be called at splbio().  *	The buffer must be on QUEUE_NONE.  */
end_comment

begin_function
name|void
name|bundirty
parameter_list|(
name|bp
parameter_list|)
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
block|{
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bundirty: buffer %p still on queue %d"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_qindex
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DELWRI
expr_stmt|;
name|reassignbuf
argument_list|(
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|)
expr_stmt|;
operator|--
name|numdirtybuffers
expr_stmt|;
name|numdirtywakeup
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	bawrite:  *  *	Asynchronous write.  Start output on a buffer, but do not wait for  *	it to complete.  The buffer is released when the output completes.  *  *	bwrite() ( or the VOP routine anyway ) is responsible for handling   *	B_INVAL buffers.  Not us.  */
end_comment

begin_function
name|void
name|bawrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
operator|(
name|void
operator|)
name|VOP_BWRITE
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bowrite:  *  *	Ordered write.  Start output on a buffer, and flag it so that the   *	device will write it in the order it was queued.  The buffer is   *	released when the output completes.  bwrite() ( or the VOP routine  *	anyway ) is responsible for handling B_INVAL buffers.  */
end_comment

begin_function
name|int
name|bowrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_ORDERED
operator||
name|B_ASYNC
expr_stmt|;
return|return
operator|(
name|VOP_BWRITE
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	bwillwrite:  *  *	Called prior to the locking of any vnodes when we are expecting to  *	write.  We do not want to starve the buffer cache with too many  *	dirty buffers so we block here.  By blocking prior to the locking  *	of any vnodes we attempt to avoid the situation where a locked vnode  *	prevents the various system daemons from flushing related buffers.  */
end_comment

begin_function
name|void
name|bwillwrite
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|twenty
init|=
operator|(
name|hidirtybuffers
operator|-
name|lodirtybuffers
operator|)
operator|/
literal|5
decl_stmt|;
if|if
condition|(
name|numdirtybuffers
operator|>
name|hidirtybuffers
operator|+
name|twenty
condition|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
while|while
condition|(
name|numdirtybuffers
operator|>
name|hidirtybuffers
condition|)
block|{
name|bd_wakeup
argument_list|(
name|hidirtybuffers
argument_list|)
expr_stmt|;
name|needsbuffer
operator||=
name|VFS_BIO_NEED_DIRTYFLUSH
expr_stmt|;
name|tsleep
argument_list|(
operator|&
name|needsbuffer
argument_list|,
operator|(
name|PRIBIO
operator|+
literal|4
operator|)
argument_list|,
literal|"flswai"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	brelse:  *  *	Release a busy buffer and, if requested, free its resources.  The  *	buffer will be stashed in the appropriate bufqueue[] allowing it  *	to be accessed later as a cache entity or reused for other purposes.  */
end_comment

begin_function
name|void
name|brelse
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTER
operator||
name|B_PAGING
operator|)
operator|)
argument_list|,
operator|(
literal|"brelse: inappropriate B_PAGING or B_CLUSTER bp %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|#
directive|if
literal|0
block|if (bp->b_flags& B_CLUSTER) { 		relpbuf(bp, NULL); 		return; 	}
endif|#
directive|endif
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_LOCKED
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_ERROR
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_READ
operator||
name|B_ERROR
operator||
name|B_INVAL
operator|)
operator|)
operator|==
name|B_ERROR
condition|)
block|{
comment|/* 		 * Failed write, redirty.  Must clear B_ERROR to prevent 		 * pages from being scrapped.  If B_INVAL is set then 		 * this case is not run and the next case is run to  		 * destroy the buffer.  B_INVAL can occur if the buffer 		 * is outside the range supported by the underlying device. 		 */
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_ERROR
expr_stmt|;
name|bdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_NOCACHE
operator||
name|B_INVAL
operator||
name|B_ERROR
operator||
name|B_FREEBUF
operator|)
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_bufsize
operator|<=
literal|0
operator|)
condition|)
block|{
comment|/* 		 * Either a failed I/O or we were asked to free or not 		 * cache the buffer. 		 */
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
if|if
condition|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|!=
name|NULL
operator|&&
name|bioops
operator|.
name|io_deallocate
condition|)
call|(
modifier|*
name|bioops
operator|.
name|io_deallocate
call|)
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
operator|--
name|numdirtybuffers
expr_stmt|;
name|numdirtywakeup
argument_list|()
expr_stmt|;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_DELWRI
operator||
name|B_CACHE
operator||
name|B_FREEBUF
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
name|allocbuf
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * We must clear B_RELBUF if B_DELWRI is set.  If vfs_vmio_release()  	 * is called with B_DELWRI set, the underlying pages may wind up 	 * getting freed causing a previous write (bdwrite()) to get 'lost' 	 * because pages associated with a B_DELWRI bp are marked clean. 	 *  	 * We still allow the B_INVAL case to call vfs_vmio_release(), even 	 * if B_DELWRI is set. 	 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_RELBUF
expr_stmt|;
comment|/* 	 * VMIO buffer rundown.  It is not very necessary to keep a VMIO buffer 	 * constituted, not even NFS buffers now.  Two flags effect this.  If 	 * B_INVAL, the struct buf is invalidated but the VM object is kept 	 * around ( i.e. so it is trivial to reconstitute the buffer later ). 	 * 	 * If B_ERROR or B_NOCACHE is set, pages in the VM object will be 	 * invalidated.  B_ERROR cannot be set for a failed write unless the 	 * buffer is also B_INVAL because it hits the re-dirtying code above. 	 * 	 * Normally we can do this whether a buffer is B_DELWRI or not.  If 	 * the buffer is an NFS buffer, it is tracking piecemeal writes or 	 * the commit state and we cannot afford to lose the buffer. 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_vp
operator|->
name|v_tag
operator|==
name|VT_NFS
operator|&&
name|bp
operator|->
name|b_vp
operator|->
name|v_type
operator|!=
name|VBLK
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|)
condition|)
block|{
name|int
name|i
decl_stmt|,
name|j
decl_stmt|,
name|resid
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|off_t
name|foff
decl_stmt|;
name|vm_pindex_t
name|poff
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
comment|/* 		 * Get the base offset and length of the buffer.  Note that  		 * for block sizes that are less then PAGE_SIZE, the b_data 		 * base of the buffer does not represent exactly b_offset and 		 * neither b_offset nor b_size are necessarily page aligned. 		 * Instead, the starting position of b_offset is: 		 * 		 * 	b_data + (b_offset& PAGE_MASK) 		 * 		 * block sizes less then DEV_BSIZE (usually 512) are not  		 * supported due to the page granularity bits (m->valid, 		 * m->dirty, etc...).  		 * 		 * See man buf(9) for more information 		 */
name|resid
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|obj
operator|=
operator|(
name|vm_object_t
operator|)
name|vp
operator|->
name|v_object
expr_stmt|;
name|poff
operator|=
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
expr_stmt|;
for|for
control|(
name|j
operator|=
name|i
init|;
name|j
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|j
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|j
index|]
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|poff
operator|+
name|j
argument_list|)
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
operator|!
name|m
condition|)
block|{
name|panic
argument_list|(
literal|"brelse: page missing\n"
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|bp
operator|->
name|b_pages
index|[
name|j
index|]
operator|=
name|m
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_NOCACHE
operator||
name|B_ERROR
operator|)
condition|)
block|{
name|int
name|poffset
init|=
name|foff
operator|&
name|PAGE_MASK
decl_stmt|;
name|int
name|presid
init|=
name|resid
operator|>
operator|(
name|PAGE_SIZE
operator|-
name|poffset
operator|)
condition|?
operator|(
name|PAGE_SIZE
operator|-
name|poffset
operator|)
else|:
name|resid
decl_stmt|;
name|KASSERT
argument_list|(
name|presid
operator|>=
literal|0
argument_list|,
operator|(
literal|"brelse: extra page"
operator|)
argument_list|)
expr_stmt|;
name|vm_page_set_invalid
argument_list|(
name|m
argument_list|,
name|poffset
argument_list|,
name|presid
argument_list|)
expr_stmt|;
block|}
name|resid
operator|-=
name|PAGE_SIZE
operator|-
operator|(
name|foff
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|foff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
name|PAGE_MASK
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_RELBUF
operator|)
condition|)
name|vfs_vmio_release
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_RELBUF
operator|)
condition|)
name|vfs_vmio_release
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
condition|)
name|panic
argument_list|(
literal|"brelse: free buffer onto another queue???"
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|>
literal|1
condition|)
block|{
comment|/* Temporary panic to verify exclusive locking */
comment|/* This panic goes away when we allow shared refs */
name|panic
argument_list|(
literal|"brelse: multiple refs"
argument_list|)
expr_stmt|;
comment|/* do not release to free list */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* enqueue */
comment|/* buffers with no memory */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_kvasize
condition|)
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_EMPTYKVA
expr_stmt|;
else|else
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|LIST_REMOVE
argument_list|(
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|invalhash
argument_list|,
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_dev
operator|=
name|NODEV
expr_stmt|;
name|kvafreespace
operator|+=
name|bp
operator|->
name|b_kvasize
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_kvasize
condition|)
name|kvaspacewakeup
argument_list|()
expr_stmt|;
comment|/* buffers with junk contents */
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_ERROR
operator||
name|B_INVAL
operator||
name|B_NOCACHE
operator||
name|B_RELBUF
operator|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|LIST_REMOVE
argument_list|(
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|invalhash
argument_list|,
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_dev
operator|=
name|NODEV
expr_stmt|;
comment|/* buffers that are locked */
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_LOCKED
condition|)
block|{
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_LOCKED
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_LOCKED
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
comment|/* remaining buffers */
block|}
else|else
block|{
switch|switch
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_DELWRI
operator||
name|B_AGE
operator|)
condition|)
block|{
case|case
name|B_DELWRI
operator||
name|B_AGE
case|:
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_DIRTY
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_DIRTY
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
break|break;
case|case
name|B_DELWRI
case|:
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_DIRTY
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_DIRTY
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
break|break;
case|case
name|B_AGE
case|:
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
break|break;
default|default:
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
comment|/* 	 * If B_INVAL, clear B_DELWRI.  We've already placed the buffer 	 * on the correct queue. 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_DELWRI
operator|)
operator|)
operator|==
operator|(
name|B_INVAL
operator||
name|B_DELWRI
operator|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DELWRI
expr_stmt|;
operator|--
name|numdirtybuffers
expr_stmt|;
name|numdirtywakeup
argument_list|()
expr_stmt|;
block|}
name|runningbufspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
comment|/* 	 * Fixup numfreebuffers count.  The bp is on an appropriate queue 	 * unless locked.  We then bump numfreebuffers if it is not B_DELWRI. 	 * We've already handled the B_INVAL case ( B_DELWRI will be clear 	 * if B_INVAL is set ). 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_LOCKED
operator|)
operator|==
literal|0
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
condition|)
name|bufcountwakeup
argument_list|()
expr_stmt|;
comment|/* 	 * Something we can maybe free. 	 */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
comment|/* unlock */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ORDERED
operator||
name|B_ASYNC
operator||
name|B_NOCACHE
operator||
name|B_AGE
operator||
name|B_RELBUF
operator|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Release a buffer back to the appropriate queue but do not try to free  * it.  *  * bqrelse() is used by bdwrite() to requeue a delayed write, and used by  * biodone() to requeue an async I/O on completion.  It is also used when  * known good buffers need to be requeued but we think we may need the data  * again soon.  */
end_comment

begin_function
name|void
name|bqrelse
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTER
operator||
name|B_PAGING
operator|)
operator|)
argument_list|,
operator|(
literal|"bqrelse: inappropriate B_PAGING or B_CLUSTER bp %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
condition|)
name|panic
argument_list|(
literal|"bqrelse: free buffer onto another queue???"
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|>
literal|1
condition|)
block|{
comment|/* do not release to free list */
name|panic
argument_list|(
literal|"bqrelse: multiple refs"
argument_list|)
expr_stmt|;
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_LOCKED
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_ERROR
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_LOCKED
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_LOCKED
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
comment|/* buffers with stale but valid contents */
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_DIRTY
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_DIRTY
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
block|}
name|runningbufspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_LOCKED
operator|)
operator|==
literal|0
operator|&&
operator|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|||
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|)
condition|)
block|{
name|bufcountwakeup
argument_list|()
expr_stmt|;
block|}
comment|/* 	 * Something we can maybe wakeup 	 */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
comment|/* unlock */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ORDERED
operator||
name|B_ASYNC
operator||
name|B_NOCACHE
operator||
name|B_AGE
operator||
name|B_RELBUF
operator|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vfs_vmio_release
parameter_list|(
name|bp
parameter_list|)
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
block|{
name|int
name|i
decl_stmt|,
name|s
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|NULL
expr_stmt|;
comment|/* 		 * In order to keep page LRU ordering consistent, put 		 * everything on the inactive queue. 		 */
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 		 * We don't mess with busy pages, it is 		 * the responsibility of the process that 		 * busied the pages to deal with them. 		 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_BUSY
operator|)
operator|||
operator|(
name|m
operator|->
name|busy
operator|!=
literal|0
operator|)
condition|)
continue|continue;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
comment|/* 			 * Might as well free the page if we can and it has 			 * no valid data. 			 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ASYNC
operator|)
operator|==
literal|0
operator|&&
operator|!
name|m
operator|->
name|valid
operator|&&
name|m
operator|->
name|hold_count
operator|==
literal|0
condition|)
block|{
name|vm_page_busy
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_protect
argument_list|(
name|m
argument_list|,
name|VM_PROT_NONE
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|bufspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|vmiospace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|runningbufspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_npages
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_VMIO
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Check to see if a block is currently memory resident.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|gbincore
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|struct
name|bufhashhdr
modifier|*
name|bh
decl_stmt|;
name|bh
operator|=
name|bufhash
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
expr_stmt|;
name|bp
operator|=
name|bh
operator|->
name|lh_first
expr_stmt|;
comment|/* Search hash chain */
while|while
condition|(
name|bp
operator|!=
name|NULL
condition|)
block|{
comment|/* hit */
if|if
condition|(
name|bp
operator|->
name|b_vp
operator|==
name|vp
operator|&&
name|bp
operator|->
name|b_lblkno
operator|==
name|blkno
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|==
literal|0
condition|)
block|{
break|break;
block|}
name|bp
operator|=
name|bp
operator|->
name|b_hash
operator|.
name|le_next
expr_stmt|;
block|}
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_awrite:  *  *	Implement clustered async writes for clearing out B_DELWRI buffers.  *	This is much better then the old way of writing only one buffer at  *	a time.  Note that we may not be presented with the buffers in the   *	correct order, so we search for the cluster in both directions.  */
end_comment

begin_function
name|int
name|vfs_bio_awrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|int
name|j
decl_stmt|;
name|daddr_t
name|lblkno
init|=
name|bp
operator|->
name|b_lblkno
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
init|=
name|bp
operator|->
name|b_vp
decl_stmt|;
name|int
name|s
decl_stmt|;
name|int
name|ncl
decl_stmt|;
name|struct
name|buf
modifier|*
name|bpa
decl_stmt|;
name|int
name|nwritten
decl_stmt|;
name|int
name|size
decl_stmt|;
name|int
name|maxcl
decl_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
comment|/* 	 * right now we support clustered writing only to regular files.  If 	 * we find a clusterable block we could be in the middle of a cluster 	 * rather then at the beginning. 	 */
if|if
condition|(
operator|(
name|vp
operator|->
name|v_type
operator|==
name|VREG
operator|)
operator|&&
operator|(
name|vp
operator|->
name|v_mount
operator|!=
literal|0
operator|)
operator|&&
comment|/* Only on nodes that have the size info */
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTEROK
operator||
name|B_INVAL
operator|)
operator|)
operator|==
name|B_CLUSTEROK
condition|)
block|{
name|size
operator|=
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
name|maxcl
operator|=
name|MAXPHYS
operator|/
name|size
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|maxcl
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|bpa
operator|=
name|gbincore
argument_list|(
name|vp
argument_list|,
name|lblkno
operator|+
name|i
argument_list|)
operator|)
operator|&&
name|BUF_REFCNT
argument_list|(
name|bpa
argument_list|)
operator|==
literal|0
operator|&&
operator|(
operator|(
name|bpa
operator|->
name|b_flags
operator|&
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator||
name|B_INVAL
operator|)
operator|)
operator|==
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator|)
operator|)
operator|&&
operator|(
name|bpa
operator|->
name|b_bufsize
operator|==
name|size
operator|)
condition|)
block|{
if|if
condition|(
operator|(
name|bpa
operator|->
name|b_blkno
operator|==
name|bpa
operator|->
name|b_lblkno
operator|)
operator|||
operator|(
name|bpa
operator|->
name|b_blkno
operator|!=
name|bp
operator|->
name|b_blkno
operator|+
operator|(
operator|(
name|i
operator|*
name|size
operator|)
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
condition|)
break|break;
block|}
else|else
block|{
break|break;
block|}
block|}
for|for
control|(
name|j
operator|=
literal|1
init|;
name|i
operator|+
name|j
operator|<=
name|maxcl
operator|&&
name|j
operator|<=
name|lblkno
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|bpa
operator|=
name|gbincore
argument_list|(
name|vp
argument_list|,
name|lblkno
operator|-
name|j
argument_list|)
operator|)
operator|&&
name|BUF_REFCNT
argument_list|(
name|bpa
argument_list|)
operator|==
literal|0
operator|&&
operator|(
operator|(
name|bpa
operator|->
name|b_flags
operator|&
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator||
name|B_INVAL
operator|)
operator|)
operator|==
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator|)
operator|)
operator|&&
operator|(
name|bpa
operator|->
name|b_bufsize
operator|==
name|size
operator|)
condition|)
block|{
if|if
condition|(
operator|(
name|bpa
operator|->
name|b_blkno
operator|==
name|bpa
operator|->
name|b_lblkno
operator|)
operator|||
operator|(
name|bpa
operator|->
name|b_blkno
operator|!=
name|bp
operator|->
name|b_blkno
operator|-
operator|(
operator|(
name|j
operator|*
name|size
operator|)
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
condition|)
break|break;
block|}
else|else
block|{
break|break;
block|}
block|}
operator|--
name|j
expr_stmt|;
name|ncl
operator|=
name|i
operator|+
name|j
expr_stmt|;
comment|/* 		 * this is a possible cluster write 		 */
if|if
condition|(
name|ncl
operator|!=
literal|1
condition|)
block|{
name|nwritten
operator|=
name|cluster_wbuild
argument_list|(
name|vp
argument_list|,
name|size
argument_list|,
name|lblkno
operator|-
name|j
argument_list|,
name|ncl
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
name|nwritten
return|;
block|}
block|}
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
argument_list|)
expr_stmt|;
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
comment|/* 	 * default (old) behavior, writing out only one block 	 * 	 * XXX returns b_bufsize instead of b_bcount for nwritten? 	 */
name|nwritten
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
operator|(
name|void
operator|)
name|VOP_BWRITE
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
return|return
name|nwritten
return|;
block|}
end_function

begin_comment
comment|/*  *	getnewbuf:  *  *	Find and initialize a new buffer header, freeing up existing buffers   *	in the bufqueues as necessary.  The new buffer is returned locked.  *  *	Important:  B_INVAL is not set.  If the caller wishes to throw the  *	buffer away, the caller must set B_INVAL prior to calling brelse().  *  *	We block if:  *		We have insufficient buffer headers  *		We have insufficient buffer space  *		buffer_map is too fragmented ( space reservation fails )  *		If we have to flush dirty buffers ( but we try to avoid this )  *  *	To avoid VFS layer recursion we do not flush dirty buffers ourselves.  *	Instead we ask the buf daemon to do it for us.  We attempt to  *	avoid piecemeal wakeups of the pageout daemon.  */
end_comment

begin_function
specifier|static
name|struct
name|buf
modifier|*
name|getnewbuf
parameter_list|(
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|,
name|int
name|size
parameter_list|,
name|int
name|maxsize
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|struct
name|buf
modifier|*
name|nbp
decl_stmt|;
name|struct
name|buf
modifier|*
name|dbp
decl_stmt|;
name|int
name|outofspace
decl_stmt|;
name|int
name|nqindex
decl_stmt|;
name|int
name|defrag
init|=
literal|0
decl_stmt|;
operator|++
name|getnewbufcalls
expr_stmt|;
operator|--
name|getnewbufrestarts
expr_stmt|;
name|restart
label|:
operator|++
name|getnewbufrestarts
expr_stmt|;
comment|/* 	 * Calculate whether we are out of buffer space.  This state is 	 * recalculated on every restart.  If we are out of space, we 	 * have to turn off defragmentation.  Setting defrag to -1 when 	 * outofspace is positive means "defrag while freeing buffers". 	 * The looping conditional will be muffed up if defrag is left 	 * positive when outofspace is positive. 	 */
name|dbp
operator|=
name|NULL
expr_stmt|;
name|outofspace
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|bufspace
operator|>=
name|hibufspace
condition|)
block|{
if|if
condition|(
operator|(
name|curproc
operator|&&
operator|(
name|curproc
operator|->
name|p_flag
operator|&
name|P_BUFEXHAUST
operator|)
operator|==
literal|0
operator|)
operator|||
name|bufspace
operator|>=
name|maxbufspace
condition|)
block|{
name|outofspace
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|defrag
operator|>
literal|0
condition|)
name|defrag
operator|=
operator|-
literal|1
expr_stmt|;
block|}
block|}
comment|/* 	 * defrag state is semi-persistant.  1 means we are flagged for 	 * defragging.  -1 means we actually defragged something. 	 */
comment|/* nop */
comment|/* 	 * Setup for scan.  If we do not have enough free buffers, 	 * we setup a degenerate case that immediately fails.  Note 	 * that if we are specially marked process, we are allowed to 	 * dip into our reserves. 	 * 	 * Normally we want to find an EMPTYKVA buffer.  That is, a 	 * buffer with kva already allocated.  If there are no EMPTYKVA 	 * buffers we back up to the truely EMPTY buffers.  When defragging 	 * we do not bother backing up since we have to locate buffers with 	 * kva to defrag.  If we are out of space we skip both EMPTY and 	 * EMPTYKVA and dig right into the CLEAN queue. 	 * 	 * In this manner we avoid scanning unnecessary buffers.  It is very 	 * important for us to do this because the buffer cache is almost 	 * constantly out of space or in need of defragmentation. 	 */
if|if
condition|(
name|curproc
operator|&&
operator|(
name|curproc
operator|->
name|p_flag
operator|&
name|P_BUFEXHAUST
operator|)
operator|==
literal|0
operator|&&
name|numfreebuffers
operator|<
name|lofreebuffers
condition|)
block|{
name|nqindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|nbp
operator|=
name|NULL
expr_stmt|;
block|}
else|else
block|{
name|nqindex
operator|=
name|QUEUE_EMPTYKVA
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTYKVA
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|nbp
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|defrag
operator|<=
literal|0
condition|)
block|{
name|nqindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTY
index|]
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|outofspace
operator|||
name|nbp
operator|==
name|NULL
condition|)
block|{
name|nqindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * Run scan, possibly freeing data and/or kva mappings on the fly 	 * depending. 	 */
while|while
condition|(
operator|(
name|bp
operator|=
name|nbp
operator|)
operator|!=
name|NULL
condition|)
block|{
name|int
name|qindex
init|=
name|nqindex
decl_stmt|;
comment|/* 		 * Calculate next bp ( we can only use it if we do not block 		 * or do other fancy things ). 		 */
if|if
condition|(
operator|(
name|nbp
operator|=
name|TAILQ_NEXT
argument_list|(
name|bp
argument_list|,
name|b_freelist
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
switch|switch
condition|(
name|qindex
condition|)
block|{
case|case
name|QUEUE_EMPTY
case|:
name|nqindex
operator|=
name|QUEUE_EMPTYKVA
expr_stmt|;
if|if
condition|(
operator|(
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTYKVA
index|]
argument_list|)
operator|)
condition|)
break|break;
comment|/* fall through */
case|case
name|QUEUE_EMPTYKVA
case|:
name|nqindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
if|if
condition|(
operator|(
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|)
operator|)
condition|)
break|break;
comment|/* fall through */
case|case
name|QUEUE_CLEAN
case|:
comment|/* 				 * nbp is NULL.  				 */
break|break;
block|}
block|}
comment|/* 		 * Sanity Checks 		 */
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|==
name|qindex
argument_list|,
operator|(
literal|"getnewbuf: inconsistant queue %d bp %p"
operator|,
name|qindex
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Note: we no longer distinguish between VMIO and non-VMIO 		 * buffers. 		 */
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"delwri buffer %p found in queue %d"
operator|,
name|bp
operator|,
name|qindex
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * If we are defragging and the buffer isn't useful for fixing 		 * that problem we continue.  If we are out of space and the 		 * buffer isn't useful for fixing that problem we continue. 		 */
if|if
condition|(
name|defrag
operator|>
literal|0
operator|&&
name|bp
operator|->
name|b_kvasize
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|outofspace
operator|>
literal|0
operator|&&
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
continue|continue;
comment|/* 		 * Start freeing the bp.  This is somewhat involved.  nbp 		 * remains valid only for QUEUE_EMPTY[KVA] bp's. 		 */
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"getnewbuf: locked buf"
argument_list|)
expr_stmt|;
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|qindex
operator|==
name|QUEUE_CLEAN
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_ASYNC
expr_stmt|;
name|vfs_vmio_release
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * NOTE:  nbp is now entirely invalid.  We can only restart 		 * the scan from this point on. 		 * 		 * Get the rest of the buffer freed up.  b_kva* is still 		 * valid after this operation. 		 */
if|if
condition|(
name|bp
operator|->
name|b_rcred
operator|!=
name|NOCRED
condition|)
block|{
name|crfree
argument_list|(
name|bp
operator|->
name|b_rcred
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_rcred
operator|=
name|NOCRED
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_wcred
operator|!=
name|NOCRED
condition|)
block|{
name|crfree
argument_list|(
name|bp
operator|->
name|b_wcred
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_wcred
operator|=
name|NOCRED
expr_stmt|;
block|}
if|if
condition|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|!=
name|NULL
operator|&&
name|bioops
operator|.
name|io_deallocate
condition|)
call|(
modifier|*
name|bioops
operator|.
name|io_deallocate
call|)
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|LIST_REMOVE
argument_list|(
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|invalhash
argument_list|,
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
name|allocbuf
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_dev
operator|=
name|NODEV
expr_stmt|;
name|bp
operator|->
name|b_vp
operator|=
name|NULL
expr_stmt|;
name|bp
operator|->
name|b_blkno
operator|=
name|bp
operator|->
name|b_lblkno
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_offset
operator|=
name|NOOFFSET
expr_stmt|;
name|bp
operator|->
name|b_iodone
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_error
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_bcount
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_npages
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_dirtyoff
operator|=
name|bp
operator|->
name|b_dirtyend
operator|=
literal|0
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
expr_stmt|;
comment|/* 		 * Ok, now that we have a free buffer, if we are defragging 		 * we have to recover the kvaspace.  If we are out of space 		 * we have to free the buffer (which we just did), but we 		 * do not have to recover kva space unless we hit a defrag 		 * hicup.  Being able to avoid freeing the kva space leads 		 * to a significant reduction in overhead. 		 */
if|if
condition|(
name|defrag
operator|>
literal|0
condition|)
block|{
name|defrag
operator|=
operator|-
literal|1
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
if|if
condition|(
name|outofspace
operator|>
literal|0
condition|)
block|{
name|outofspace
operator|=
operator|-
literal|1
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
if|if
condition|(
name|defrag
operator|<
literal|0
condition|)
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
comment|/* 		 * We are done 		 */
break|break;
block|}
comment|/* 	 * If we exhausted our list, sleep as appropriate.  We may have to 	 * wakeup various daemons and write out some dirty buffers. 	 * 	 * Generally we are sleeping due to insufficient buffer space. 	 */
if|if
condition|(
name|bp
operator|==
name|NULL
condition|)
block|{
name|int
name|flags
decl_stmt|;
name|char
modifier|*
name|waitmsg
decl_stmt|;
name|dosleep
label|:
if|if
condition|(
name|defrag
operator|>
literal|0
condition|)
block|{
name|flags
operator|=
name|VFS_BIO_NEED_KVASPACE
expr_stmt|;
name|waitmsg
operator|=
literal|"nbufkv"
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|outofspace
operator|>
literal|0
condition|)
block|{
name|waitmsg
operator|=
literal|"nbufbs"
expr_stmt|;
name|flags
operator|=
name|VFS_BIO_NEED_BUFSPACE
expr_stmt|;
block|}
else|else
block|{
name|waitmsg
operator|=
literal|"newbuf"
expr_stmt|;
name|flags
operator|=
name|VFS_BIO_NEED_ANY
expr_stmt|;
block|}
comment|/* XXX */
operator|(
name|void
operator|)
name|speedup_syncer
argument_list|()
expr_stmt|;
name|needsbuffer
operator||=
name|flags
expr_stmt|;
while|while
condition|(
name|needsbuffer
operator|&
name|flags
condition|)
block|{
if|if
condition|(
name|tsleep
argument_list|(
operator|&
name|needsbuffer
argument_list|,
operator|(
name|PRIBIO
operator|+
literal|4
operator|)
operator||
name|slpflag
argument_list|,
name|waitmsg
argument_list|,
name|slptimeo
argument_list|)
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
block|}
block|}
else|else
block|{
comment|/* 		 * We finally have a valid bp.  We aren't quite out of the 		 * woods, we still have to reserve kva space. 		 */
name|vm_offset_t
name|addr
init|=
literal|0
decl_stmt|;
name|maxsize
operator|=
operator|(
name|maxsize
operator|+
name|PAGE_MASK
operator|)
operator|&
operator|~
name|PAGE_MASK
expr_stmt|;
if|if
condition|(
name|maxsize
operator|!=
name|bp
operator|->
name|b_kvasize
condition|)
block|{
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_map_findspace
argument_list|(
name|buffer_map
argument_list|,
name|vm_map_min
argument_list|(
name|buffer_map
argument_list|)
argument_list|,
name|maxsize
argument_list|,
operator|&
name|addr
argument_list|)
condition|)
block|{
comment|/* 				 * Uh oh.  Buffer map is to fragmented.  Try 				 * to defragment. 				 */
if|if
condition|(
name|defrag
operator|<=
literal|0
condition|)
block|{
name|defrag
operator|=
literal|1
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
comment|/* 				 * Uh oh.  We couldn't seem to defragment 				 */
name|bp
operator|=
name|NULL
expr_stmt|;
goto|goto
name|dosleep
goto|;
block|}
block|}
if|if
condition|(
name|addr
condition|)
block|{
name|vm_map_insert
argument_list|(
name|buffer_map
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
name|addr
argument_list|,
name|addr
operator|+
name|maxsize
argument_list|,
name|VM_PROT_ALL
argument_list|,
name|VM_PROT_ALL
argument_list|,
name|MAP_NOFAULT
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_kvabase
operator|=
operator|(
name|caddr_t
operator|)
name|addr
expr_stmt|;
name|bp
operator|->
name|b_kvasize
operator|=
name|maxsize
expr_stmt|;
block|}
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
block|}
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	waitfreebuffers:  *  *	Wait for sufficient free buffers.  Only called from normal processes.  */
end_comment

begin_function
specifier|static
name|void
name|waitfreebuffers
parameter_list|(
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|)
block|{
while|while
condition|(
name|numfreebuffers
operator|<
name|hifreebuffers
condition|)
block|{
if|if
condition|(
name|numfreebuffers
operator|>=
name|hifreebuffers
condition|)
break|break;
name|needsbuffer
operator||=
name|VFS_BIO_NEED_FREE
expr_stmt|;
if|if
condition|(
name|tsleep
argument_list|(
operator|&
name|needsbuffer
argument_list|,
operator|(
name|PRIBIO
operator|+
literal|4
operator|)
operator||
name|slpflag
argument_list|,
literal|"biofre"
argument_list|,
name|slptimeo
argument_list|)
condition|)
break|break;
block|}
block|}
end_function

begin_comment
comment|/*  *	buf_daemon:  *  *	buffer flushing daemon.  Buffers are normally flushed by the  *	update daemon but if it cannot keep up this process starts to  *	take the load in an attempt to prevent getnewbuf() from blocking.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|proc
modifier|*
name|bufdaemonproc
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|bd_interval
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|bd_flushto
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|kproc_desc
name|buf_kp
init|=
block|{
literal|"bufdaemon"
block|,
name|buf_daemon
block|,
operator|&
name|bufdaemonproc
block|}
decl_stmt|;
end_decl_stmt

begin_macro
name|SYSINIT
argument_list|(
argument|bufdaemon
argument_list|,
argument|SI_SUB_KTHREAD_BUF
argument_list|,
argument|SI_ORDER_FIRST
argument_list|,
argument|kproc_start
argument_list|,
argument|&buf_kp
argument_list|)
end_macro

begin_function
specifier|static
name|void
name|buf_daemon
parameter_list|()
block|{
name|int
name|s
decl_stmt|;
comment|/* 	 * This process is allowed to take the buffer cache to the limit 	 */
name|curproc
operator|->
name|p_flag
operator||=
name|P_BUFEXHAUST
expr_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
name|bd_interval
operator|=
literal|5
operator|*
name|hz
expr_stmt|;
comment|/* dynamically adjusted */
name|bd_flushto
operator|=
name|hidirtybuffers
expr_stmt|;
comment|/* dynamically adjusted */
while|while
condition|(
name|TRUE
condition|)
block|{
name|bd_request
operator|=
literal|0
expr_stmt|;
comment|/* 		 * Do the flush.  Limit the number of buffers we flush in one 		 * go.  The failure condition occurs when processes are writing 		 * buffers faster then we can dispose of them.  In this case 		 * we may be flushing so often that the previous set of flushes 		 * have not had time to complete, causing us to run out of 		 * physical buffers and block. 		 */
block|{
name|int
name|runcount
init|=
name|maxbdrun
decl_stmt|;
while|while
condition|(
name|numdirtybuffers
operator|>
name|bd_flushto
operator|&&
name|runcount
condition|)
block|{
operator|--
name|runcount
expr_stmt|;
if|if
condition|(
name|flushbufqueues
argument_list|()
operator|==
literal|0
condition|)
break|break;
block|}
block|}
comment|/* 		 * If nobody is requesting anything we sleep 		 */
if|if
condition|(
name|bd_request
operator|==
literal|0
condition|)
name|tsleep
argument_list|(
operator|&
name|bd_request
argument_list|,
name|PVM
argument_list|,
literal|"psleep"
argument_list|,
name|bd_interval
argument_list|)
expr_stmt|;
comment|/* 		 * We calculate how much to add or subtract from bd_flushto 		 * and bd_interval based on how far off we are from the  		 * optimal number of dirty buffers, which is 20% below the 		 * hidirtybuffers mark.  We cannot use hidirtybuffers straight 		 * because being right on the mark will cause getnewbuf() 		 * to oscillate our wakeup. 		 * 		 * The larger the error in either direction, the more we adjust 		 * bd_flushto and bd_interval.  The time interval is adjusted 		 * by 2 seconds per whole-buffer-range of error.  This is an 		 * exponential convergence algorithm, with large errors 		 * producing large changes and small errors producing small 		 * changes. 		 */
block|{
name|int
name|brange
init|=
name|hidirtybuffers
operator|-
name|lodirtybuffers
decl_stmt|;
name|int
name|middb
init|=
name|hidirtybuffers
operator|-
name|brange
operator|/
literal|5
decl_stmt|;
name|int
name|deltabuf
init|=
name|middb
operator|-
name|numdirtybuffers
decl_stmt|;
name|bd_flushto
operator|+=
name|deltabuf
operator|/
literal|20
expr_stmt|;
name|bd_interval
operator|+=
name|deltabuf
operator|*
operator|(
literal|2
operator|*
name|hz
operator|)
operator|/
operator|(
name|brange
operator|*
literal|1
operator|)
expr_stmt|;
block|}
if|if
condition|(
name|bd_flushto
operator|<
name|lodirtybuffers
condition|)
name|bd_flushto
operator|=
name|lodirtybuffers
expr_stmt|;
if|if
condition|(
name|bd_flushto
operator|>
name|hidirtybuffers
condition|)
name|bd_flushto
operator|=
name|hidirtybuffers
expr_stmt|;
if|if
condition|(
name|bd_interval
operator|<
name|hz
operator|/
literal|10
condition|)
name|bd_interval
operator|=
name|hz
operator|/
literal|10
expr_stmt|;
if|if
condition|(
name|bd_interval
operator|>
literal|5
operator|*
name|hz
condition|)
name|bd_interval
operator|=
literal|5
operator|*
name|hz
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	flushbufqueues:  *  *	Try to flush a buffer in the dirty queue.  We must be careful to  *	free up B_INVAL buffers instead of write them, which NFS is   *	particularly sensitive to.  */
end_comment

begin_function
specifier|static
name|int
name|flushbufqueues
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|r
init|=
literal|0
decl_stmt|;
name|bp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_DIRTY
index|]
argument_list|)
expr_stmt|;
while|while
condition|(
name|bp
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
argument_list|,
operator|(
literal|"unexpected clean buffer %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"flushbufqueues: locked buf"
argument_list|)
expr_stmt|;
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
operator|++
name|r
expr_stmt|;
break|break;
block|}
name|vfs_bio_awrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
operator|++
name|r
expr_stmt|;
break|break;
block|}
name|bp
operator|=
name|TAILQ_NEXT
argument_list|(
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|r
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Check to see if a block is currently memory resident.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|incore
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|s
init|=
name|splbio
argument_list|()
decl_stmt|;
name|bp
operator|=
name|gbincore
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns true if no I/O is needed to access the  * associated VM object.  This is like incore except  * it also hunts around in the VM system for the data.  */
end_comment

begin_function
name|int
name|inmem
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_offset_t
name|toff
decl_stmt|,
name|tinc
decl_stmt|,
name|size
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_ooffset_t
name|off
decl_stmt|;
if|if
condition|(
name|incore
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
condition|)
return|return
literal|1
return|;
if|if
condition|(
name|vp
operator|->
name|v_mount
operator|==
name|NULL
condition|)
return|return
literal|0
return|;
if|if
condition|(
operator|(
name|vp
operator|->
name|v_object
operator|==
name|NULL
operator|)
operator|||
operator|(
name|vp
operator|->
name|v_flag
operator|&
name|VOBJBUF
operator|)
operator|==
literal|0
condition|)
return|return
literal|0
return|;
name|obj
operator|=
name|vp
operator|->
name|v_object
expr_stmt|;
name|size
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
name|size
operator|>
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
condition|)
name|size
operator|=
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
name|off
operator|=
operator|(
name|vm_ooffset_t
operator|)
name|blkno
operator|*
operator|(
name|vm_ooffset_t
operator|)
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
for|for
control|(
name|toff
operator|=
literal|0
init|;
name|toff
operator|<
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
condition|;
name|toff
operator|+=
name|tinc
control|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|off
operator|+
name|toff
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|m
condition|)
return|return
literal|0
return|;
name|tinc
operator|=
name|size
expr_stmt|;
if|if
condition|(
name|tinc
operator|>
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
operator|)
condition|)
name|tinc
operator|=
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
if|if
condition|(
name|vm_page_is_valid
argument_list|(
name|m
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
argument_list|)
argument_list|,
name|tinc
argument_list|)
operator|==
literal|0
condition|)
return|return
literal|0
return|;
block|}
return|return
literal|1
return|;
block|}
end_function

begin_comment
comment|/*  *	vfs_setdirty:  *  *	Sets the dirty range for a buffer based on the status of the dirty  *	bits in the pages comprising the buffer.  *  *	The range is limited to the size of the buffer.  *  *	This routine is primarily used by NFS, but is generalized for the  *	B_VMIO case.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_setdirty
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
comment|/* 	 * Degenerate case - empty buffer 	 */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
return|return;
comment|/* 	 * We qualify the scan for modified pages on whether the 	 * object has been flushed yet.  The OBJ_WRITEABLE flag 	 * is not cleared simply by protecting pages off. 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
condition|)
return|return;
name|object
operator|=
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|object
expr_stmt|;
if|if
condition|(
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_WRITEABLE
operator|)
operator|&&
operator|!
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_MIGHTBEDIRTY
operator|)
condition|)
name|printf
argument_list|(
literal|"Warning: object %p writeable but not mightbedirty\n"
argument_list|,
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_WRITEABLE
operator|)
operator|&&
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_MIGHTBEDIRTY
operator|)
condition|)
name|printf
argument_list|(
literal|"Warning: object %p mightbedirty but not writeable\n"
argument_list|,
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|flags
operator|&
operator|(
name|OBJ_MIGHTBEDIRTY
operator||
name|OBJ_CLEANING
operator|)
condition|)
block|{
name|vm_offset_t
name|boffset
decl_stmt|;
name|vm_offset_t
name|eoffset
decl_stmt|;
comment|/* 		 * test the pages to see if they have been modified directly 		 * by users through the VM system. 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_flag_clear
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|vm_page_test_dirty
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Calculate the encompassing dirty range, boffset and eoffset, 		 * (eoffset - boffset) bytes. 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|dirty
condition|)
break|break;
block|}
name|boffset
operator|=
operator|(
name|i
operator|<<
name|PAGE_SHIFT
operator|)
operator|-
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|bp
operator|->
name|b_npages
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
operator|--
name|i
control|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|dirty
condition|)
block|{
break|break;
block|}
block|}
name|eoffset
operator|=
operator|(
operator|(
name|i
operator|+
literal|1
operator|)
operator|<<
name|PAGE_SHIFT
operator|)
operator|-
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
comment|/* 		 * Fit it to the buffer. 		 */
if|if
condition|(
name|eoffset
operator|>
name|bp
operator|->
name|b_bcount
condition|)
name|eoffset
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* 		 * If we have a good dirty range, merge with the existing 		 * dirty range. 		 */
if|if
condition|(
name|boffset
operator|<
name|eoffset
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_dirtyoff
operator|>
name|boffset
condition|)
name|bp
operator|->
name|b_dirtyoff
operator|=
name|boffset
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_dirtyend
operator|<
name|eoffset
condition|)
name|bp
operator|->
name|b_dirtyend
operator|=
name|eoffset
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	getblk:  *  *	Get a block given a specified block and offset into a file/device.  *	The buffers B_DONE bit will be cleared on return, making it almost  * 	ready for an I/O initiation.  B_INVAL may or may not be set on   *	return.  The caller should clear B_INVAL prior to initiating a  *	READ.  *  *	For a non-VMIO buffer, B_CACHE is set to the opposite of B_INVAL for  *	an existing buffer.  *  *	For a VMIO buffer, B_CACHE is modified according to the backing VM.  *	If getblk()ing a previously 0-sized invalid buffer, B_CACHE is set  *	and then cleared based on the backing VM.  If the previous buffer is  *	non-0-sized but invalid, B_CACHE will be cleared.  *  *	If getblk() must create a new buffer, the new buffer is returned with  *	both B_INVAL and B_CACHE clear unless it is a VMIO buffer, in which  *	case it is returned with B_INVAL clear and B_CACHE set based on the  *	backing VM.  *  *	getblk() also forces a VOP_BWRITE() for any B_DELWRI buffer whos  *	B_CACHE bit is clear.  *	  *	What this means, basically, is that the caller should use B_CACHE to  *	determine whether the buffer is fully valid or not and should clear  *	B_INVAL prior to issuing a read.  If the caller intends to validate  *	the buffer by loading its data area with something, the caller needs  *	to clear B_INVAL.  If the caller does this without issuing an I/O,   *	the caller should set B_CACHE ( as an optimization ), else the caller  *	should issue the I/O and biodone() will set B_CACHE if the I/O was  *	a write attempt or if it was a successfull read.  If the caller   *	intends to issue a READ, the caller must clear B_INVAL and B_ERROR  *	prior to issuing the READ.  biodone() will *not* clear B_INVAL.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|getblk
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|s
decl_stmt|;
name|struct
name|bufhashhdr
modifier|*
name|bh
decl_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
name|size
operator|>
name|MAXBSIZE
condition|)
name|panic
argument_list|(
literal|"getblk: size(%d)> MAXBSIZE(%d)\n"
argument_list|,
name|size
argument_list|,
name|MAXBSIZE
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
name|loop
label|:
comment|/* 	 * Block if we are low on buffers.   Certain processes are allowed 	 * to completely exhaust the buffer cache.          *          * If this check ever becomes a bottleneck it may be better to          * move it into the else, when gbincore() fails.  At the moment          * it isn't a problem.          */
if|if
condition|(
operator|!
name|curproc
operator|||
operator|(
name|curproc
operator|->
name|p_flag
operator|&
name|P_BUFEXHAUST
operator|)
condition|)
block|{
if|if
condition|(
name|numfreebuffers
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|curproc
condition|)
return|return
name|NULL
return|;
name|needsbuffer
operator||=
name|VFS_BIO_NEED_ANY
expr_stmt|;
name|tsleep
argument_list|(
operator|&
name|needsbuffer
argument_list|,
operator|(
name|PRIBIO
operator|+
literal|4
operator|)
operator||
name|slpflag
argument_list|,
literal|"newbuf"
argument_list|,
name|slptimeo
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|numfreebuffers
operator|<
name|lofreebuffers
condition|)
block|{
name|waitfreebuffers
argument_list|(
name|slpflag
argument_list|,
name|slptimeo
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|bp
operator|=
name|gbincore
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
operator|)
condition|)
block|{
comment|/* 		 * Buffer is in-core.  If the buffer is not busy, it must 		 * be on a queue. 		 */
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|)
condition|)
block|{
if|if
condition|(
name|BUF_TIMELOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_SLEEPFAIL
argument_list|,
literal|"getblk"
argument_list|,
name|slpflag
argument_list|,
name|slptimeo
argument_list|)
operator|==
name|ENOLCK
condition|)
goto|goto
name|loop
goto|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
operator|(
expr|struct
name|buf
operator|*
operator|)
name|NULL
return|;
block|}
comment|/* 		 * The buffer is locked.  B_CACHE is cleared if the buffer is  		 * invalid.  Ohterwise, for a non-VMIO buffer, B_CACHE is set 		 * and for a VMIO buffer B_CACHE is adjusted according to the 		 * backing VM cache. 		 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_VMIO
operator||
name|B_INVAL
operator|)
operator|)
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 		 * check for size inconsistancies for non-VMIO case. 		 */
if|if
condition|(
name|bp
operator|->
name|b_bcount
operator|!=
name|size
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
operator|||
operator|(
name|size
operator|>
name|bp
operator|->
name|b_kvasize
operator|)
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|VOP_BWRITE
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|&&
operator|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|==
name|NULL
operator|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_RELBUF
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|VOP_BWRITE
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
goto|goto
name|loop
goto|;
block|}
block|}
comment|/* 		 * If the size is inconsistant in the VMIO case, we can resize 		 * the buffer.  This might lead to B_CACHE getting set or 		 * cleared.  If the size has not changed, B_CACHE remains 		 * unchanged from its previous state. 		 */
if|if
condition|(
name|bp
operator|->
name|b_bcount
operator|!=
name|size
condition|)
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"getblk: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * A buffer with B_DELWRI set and B_CACHE clear must 		 * be committed before we can return the buffer in 		 * order to prevent the caller from issuing a read 		 * ( due to B_CACHE not being set ) and overwriting 		 * it. 		 * 		 * Most callers, including NFS and FFS, need this to 		 * operate properly either because they assume they 		 * can issue a read if B_CACHE is not set, or because 		 * ( for example ) an uncached B_DELWRI might loop due  		 * to softupdates re-dirtying the buffer.  In the latter 		 * case, B_CACHE is set after the first write completes, 		 * preventing further loops. 		 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CACHE
operator||
name|B_DELWRI
operator|)
operator|)
operator|==
name|B_DELWRI
condition|)
block|{
name|VOP_BWRITE
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Buffer is not in-core, create new buffer.  The buffer 		 * returned by getnewbuf() is locked.  Note that the returned 		 * buffer is also considered valid (not marked B_INVAL). 		 */
name|int
name|bsize
decl_stmt|,
name|maxsize
decl_stmt|,
name|vmio
decl_stmt|;
name|off_t
name|offset
decl_stmt|;
if|if
condition|(
name|vp
operator|->
name|v_type
operator|==
name|VBLK
condition|)
name|bsize
operator|=
name|DEV_BSIZE
expr_stmt|;
elseif|else
if|if
condition|(
name|vp
operator|->
name|v_mountedhere
condition|)
name|bsize
operator|=
name|vp
operator|->
name|v_mountedhere
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
elseif|else
if|if
condition|(
name|vp
operator|->
name|v_mount
condition|)
name|bsize
operator|=
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
else|else
name|bsize
operator|=
name|size
expr_stmt|;
name|offset
operator|=
operator|(
name|off_t
operator|)
name|blkno
operator|*
name|bsize
expr_stmt|;
name|vmio
operator|=
operator|(
name|vp
operator|->
name|v_object
operator|!=
literal|0
operator|)
operator|&&
operator|(
name|vp
operator|->
name|v_flag
operator|&
name|VOBJBUF
operator|)
expr_stmt|;
name|maxsize
operator|=
name|vmio
condition|?
name|size
operator|+
operator|(
name|offset
operator|&
name|PAGE_MASK
operator|)
else|:
name|size
expr_stmt|;
name|maxsize
operator|=
name|imax
argument_list|(
name|maxsize
argument_list|,
name|bsize
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|=
name|getnewbuf
argument_list|(
name|slpflag
argument_list|,
name|slptimeo
argument_list|,
name|size
argument_list|,
name|maxsize
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|slpflag
operator|||
name|slptimeo
condition|)
block|{
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
name|NULL
return|;
block|}
goto|goto
name|loop
goto|;
block|}
comment|/* 		 * This code is used to make sure that a buffer is not 		 * created while the getnewbuf routine is blocked. 		 * This can be a problem whether the vnode is locked or not. 		 * If the buffer is created out from under us, we have to 		 * throw away the one we just created.  There is now window 		 * race because we are safely running at splbio() from the 		 * point of the duplicate buffer creation through to here, 		 * and we've locked the buffer. 		 */
if|if
condition|(
name|gbincore
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
comment|/* 		 * Insert the buffer into the hash, so that it can 		 * be found by incore. 		 */
name|bp
operator|->
name|b_blkno
operator|=
name|bp
operator|->
name|b_lblkno
operator|=
name|blkno
expr_stmt|;
name|bp
operator|->
name|b_offset
operator|=
name|offset
expr_stmt|;
name|bgetvp
argument_list|(
name|vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|LIST_REMOVE
argument_list|(
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
name|bh
operator|=
name|bufhash
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
name|bh
argument_list|,
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
comment|/* 		 * set B_VMIO bit.  allocbuf() the buffer bigger.  Since the 		 * buffer size starts out as 0, B_CACHE will be set by 		 * allocbuf() for the VMIO case prior to it testing the 		 * backing store for validity. 		 */
if|if
condition|(
name|vmio
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_VMIO
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|VFS_BIO_DEBUG
argument_list|)
if|if
condition|(
name|vp
operator|->
name|v_type
operator|!=
name|VREG
operator|&&
name|vp
operator|->
name|v_type
operator|!=
name|VBLK
condition|)
name|printf
argument_list|(
literal|"getblk: vmioing file type %d???\n"
argument_list|,
name|vp
operator|->
name|v_type
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
else|else
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_VMIO
expr_stmt|;
block|}
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
block|}
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Get an empty, disassociated buffer of given size.  The buffer is initially  * set to B_INVAL.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|geteblk
parameter_list|(
name|int
name|size
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|=
name|getnewbuf
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
name|size
argument_list|,
name|MAXBSIZE
argument_list|)
operator|)
operator|==
literal|0
condition|)
empty_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
comment|/* b_dep cleared by getnewbuf() */
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This code constitutes the buffer memory from either anonymous system  * memory (in the case of non-VMIO operations) or from an associated  * VM object (in the case of VMIO operations).  This code is able to  * resize a buffer up or down.  *  * Note that this code is tricky, and has many complications to resolve  * deadlock or inconsistant data situations.  Tread lightly!!!   * There are B_CACHE and B_DELWRI interactions that must be dealt with by   * the caller.  Calling this code willy nilly can result in the loss of data.  *  * allocbuf() only adjusts B_CACHE for VMIO buffers.  getblk() deals with  * B_CACHE for the non-VMIO case.  */
end_comment

begin_function
name|int
name|allocbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|newbsize
decl_stmt|,
name|mbsize
decl_stmt|;
name|int
name|i
decl_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"allocbuf: buffer not busy"
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_kvasize
operator|<
name|size
condition|)
name|panic
argument_list|(
literal|"allocbuf: buffer too small"
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
condition|)
block|{
name|caddr_t
name|origbuf
decl_stmt|;
name|int
name|origbufsize
decl_stmt|;
comment|/* 		 * Just get anonymous memory from the kernel.  Don't 		 * mess with B_CACHE. 		 */
name|mbsize
operator|=
operator|(
name|size
operator|+
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_B_MALLOC
argument_list|)
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
name|newbsize
operator|=
name|mbsize
expr_stmt|;
else|else
endif|#
directive|endif
name|newbsize
operator|=
name|round_page
argument_list|(
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
block|{
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_B_MALLOC
argument_list|)
comment|/* 			 * malloced buffers are not shrunk 			 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
block|{
if|if
condition|(
name|newbsize
condition|)
block|{
name|bp
operator|->
name|b_bcount
operator|=
name|size
expr_stmt|;
block|}
else|else
block|{
name|free
argument_list|(
name|bp
operator|->
name|b_data
argument_list|,
name|M_BIOBUF
argument_list|)
expr_stmt|;
name|bufspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|bufmallocspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|runningbufspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_bcount
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_MALLOC
expr_stmt|;
block|}
return|return
literal|1
return|;
block|}
endif|#
directive|endif
name|vm_hold_free_pages
argument_list|(
name|bp
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|newbsize
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|newbsize
operator|>
name|bp
operator|->
name|b_bufsize
condition|)
block|{
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_B_MALLOC
argument_list|)
comment|/* 			 * We only use malloced memory on the first allocation. 			 * and revert to page-allocated memory when the buffer 			 * grows. 			 */
if|if
condition|(
operator|(
name|bufmallocspace
operator|<
name|maxbufmallocspace
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
operator|)
operator|&&
operator|(
name|mbsize
operator|<=
name|PAGE_SIZE
operator|/
literal|2
operator|)
condition|)
block|{
name|bp
operator|->
name|b_data
operator|=
name|malloc
argument_list|(
name|mbsize
argument_list|,
name|M_BIOBUF
argument_list|,
name|M_WAITOK
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
name|mbsize
expr_stmt|;
name|bp
operator|->
name|b_bcount
operator|=
name|size
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_MALLOC
expr_stmt|;
name|bufspace
operator|+=
name|mbsize
expr_stmt|;
name|bufmallocspace
operator|+=
name|mbsize
expr_stmt|;
name|runningbufspace
operator|+=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
return|return
literal|1
return|;
block|}
endif|#
directive|endif
name|origbuf
operator|=
name|NULL
expr_stmt|;
name|origbufsize
operator|=
literal|0
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_B_MALLOC
argument_list|)
comment|/* 			 * If the buffer is growing on its other-than-first allocation, 			 * then we revert to the page-allocation scheme. 			 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
block|{
name|origbuf
operator|=
name|bp
operator|->
name|b_data
expr_stmt|;
name|origbufsize
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|bufspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|bufmallocspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|runningbufspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_MALLOC
expr_stmt|;
name|newbsize
operator|=
name|round_page
argument_list|(
name|newbsize
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|vm_hold_load_pages
argument_list|(
name|bp
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|bp
operator|->
name|b_bufsize
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|newbsize
argument_list|)
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_B_MALLOC
argument_list|)
if|if
condition|(
name|origbuf
condition|)
block|{
name|bcopy
argument_list|(
name|origbuf
argument_list|,
name|bp
operator|->
name|b_data
argument_list|,
name|origbufsize
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|origbuf
argument_list|,
name|M_BIOBUF
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
block|}
else|else
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|desiredpages
decl_stmt|;
name|newbsize
operator|=
operator|(
name|size
operator|+
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
expr_stmt|;
name|desiredpages
operator|=
operator|(
name|size
operator|==
literal|0
operator|)
condition|?
literal|0
else|:
name|num_pages
argument_list|(
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|+
name|newbsize
argument_list|)
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_B_MALLOC
argument_list|)
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
name|panic
argument_list|(
literal|"allocbuf: VMIO buffer can't be malloced"
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 		 * Set B_CACHE initially if buffer is 0 length or will become 		 * 0-length. 		 */
if|if
condition|(
name|size
operator|==
literal|0
operator|||
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
block|{
comment|/* 			 * DEV_BSIZE aligned new buffer size is less then the 			 * DEV_BSIZE aligned existing buffer size.  Figure out 			 * if we have to remove any pages. 			 */
if|if
condition|(
name|desiredpages
operator|<
name|bp
operator|->
name|b_npages
condition|)
block|{
for|for
control|(
name|i
operator|=
name|desiredpages
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
comment|/* 					 * the page is not freed here -- it 					 * is the responsibility of  					 * vnode_pager_setsize 					 */
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|!=
name|bogus_page
argument_list|,
operator|(
literal|"allocbuf: bogus page found"
operator|)
argument_list|)
expr_stmt|;
while|while
condition|(
name|vm_page_sleep_busy
argument_list|(
name|m
argument_list|,
name|TRUE
argument_list|,
literal|"biodep"
argument_list|)
condition|)
empty_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|NULL
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|pmap_qremove
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|+
operator|(
name|desiredpages
operator|<<
name|PAGE_SHIFT
operator|)
argument_list|,
operator|(
name|bp
operator|->
name|b_npages
operator|-
name|desiredpages
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_npages
operator|=
name|desiredpages
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|size
operator|>
name|bp
operator|->
name|b_bcount
condition|)
block|{
comment|/* 			 * We are growing the buffer, possibly in a  			 * byte-granular fashion. 			 */
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|vm_offset_t
name|toff
decl_stmt|;
name|vm_offset_t
name|tinc
decl_stmt|;
comment|/* 			 * Step 1, bring in the VM pages from the object,  			 * allocating them if necessary.  We must clear 			 * B_CACHE if these pages are not valid for the  			 * range covered by the buffer. 			 */
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
name|obj
operator|=
name|vp
operator|->
name|v_object
expr_stmt|;
while|while
condition|(
name|bp
operator|->
name|b_npages
operator|<
name|desiredpages
condition|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_pindex_t
name|pi
decl_stmt|;
name|pi
operator|=
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
operator|+
name|bp
operator|->
name|b_npages
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|pi
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|obj
argument_list|,
name|pi
argument_list|,
name|VM_ALLOC_NORMAL
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|VM_WAIT
expr_stmt|;
name|vm_pageout_deficit
operator|+=
name|desiredpages
operator|-
name|bp
operator|->
name|b_npages
expr_stmt|;
block|}
else|else
block|{
name|vm_page_wire
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|bp
operator|->
name|b_npages
index|]
operator|=
name|m
expr_stmt|;
operator|++
name|bp
operator|->
name|b_npages
expr_stmt|;
block|}
continue|continue;
block|}
comment|/* 				 * We found a page.  If we have to sleep on it, 				 * retry because it might have gotten freed out 				 * from under us. 				 * 				 * We can only test PG_BUSY here.  Blocking on 				 * m->busy might lead to a deadlock: 				 * 				 *  vm_fault->getpages->cluster_read->allocbuf 				 * 				 */
if|if
condition|(
name|vm_page_sleep_busy
argument_list|(
name|m
argument_list|,
name|FALSE
argument_list|,
literal|"pgtblk"
argument_list|)
condition|)
continue|continue;
comment|/* 				 * We have a good page.  Should we wakeup the 				 * page daemon? 				 */
if|if
condition|(
operator|(
name|curproc
operator|!=
name|pageproc
operator|)
operator|&&
operator|(
operator|(
name|m
operator|->
name|queue
operator|-
name|m
operator|->
name|pc
operator|)
operator|==
name|PQ_CACHE
operator|)
operator|&&
operator|(
operator|(
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|)
operator|<
operator|(
name|cnt
operator|.
name|v_free_min
operator|+
name|cnt
operator|.
name|v_cache_min
operator|)
operator|)
condition|)
block|{
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
block|}
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|vm_page_wire
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|bp
operator|->
name|b_npages
index|]
operator|=
name|m
expr_stmt|;
operator|++
name|bp
operator|->
name|b_npages
expr_stmt|;
block|}
comment|/* 			 * Step 2.  We've loaded the pages into the buffer, 			 * we have to figure out if we can still have B_CACHE 			 * set.  Note that B_CACHE is set according to the 			 * byte-granular range ( bcount and size ), new the 			 * aligned range ( newbsize ). 			 * 			 * The VM test is against m->valid, which is DEV_BSIZE 			 * aligned.  Needless to say, the validity of the data 			 * needs to also be DEV_BSIZE aligned.  Note that this 			 * fails with NFS if the server or some other client 			 * extends the file's EOF.  If our buffer is resized,  			 * B_CACHE may remain set! XXX 			 */
name|toff
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
name|tinc
operator|=
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|bp
operator|->
name|b_offset
operator|+
name|toff
operator|)
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|&&
name|toff
operator|<
name|size
condition|)
block|{
name|vm_pindex_t
name|pi
decl_stmt|;
if|if
condition|(
name|tinc
operator|>
operator|(
name|size
operator|-
name|toff
operator|)
condition|)
name|tinc
operator|=
name|size
operator|-
name|toff
expr_stmt|;
name|pi
operator|=
operator|(
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|+
name|toff
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
name|vfs_buf_test_cache
argument_list|(
name|bp
argument_list|,
name|bp
operator|->
name|b_offset
argument_list|,
name|toff
argument_list|,
name|tinc
argument_list|,
name|bp
operator|->
name|b_pages
index|[
name|pi
index|]
argument_list|)
expr_stmt|;
name|toff
operator|+=
name|tinc
expr_stmt|;
name|tinc
operator|=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* 			 * Step 3, fixup the KVM pmap.  Remember that 			 * bp->b_data is relative to bp->b_offset, but  			 * bp->b_offset may be offset into the first page. 			 */
name|bp
operator|->
name|b_data
operator|=
operator|(
name|caddr_t
operator|)
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
call|(
name|caddr_t
call|)
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator||
call|(
name|vm_offset_t
call|)
argument_list|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
name|vmiospace
operator|+=
operator|(
name|newbsize
operator|-
name|bp
operator|->
name|b_bufsize
operator|)
expr_stmt|;
name|bufspace
operator|+=
operator|(
name|newbsize
operator|-
name|bp
operator|->
name|b_bufsize
operator|)
expr_stmt|;
name|runningbufspace
operator|+=
operator|(
name|newbsize
operator|-
name|bp
operator|->
name|b_bufsize
operator|)
expr_stmt|;
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
name|newbsize
expr_stmt|;
comment|/* actual buffer allocation	*/
name|bp
operator|->
name|b_bcount
operator|=
name|size
expr_stmt|;
comment|/* requested buffer size	*/
return|return
literal|1
return|;
block|}
end_function

begin_comment
comment|/*  *	biowait:  *  *	Wait for buffer I/O completion, returning error status.  The buffer  *	is left locked and B_DONE on return.  B_EINTR is converted into a EINTR  *	error and cleared.  */
end_comment

begin_function
name|int
name|biowait
parameter_list|(
specifier|register
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DONE
operator|)
operator|==
literal|0
condition|)
block|{
if|#
directive|if
name|defined
argument_list|(
name|NO_SCHEDULE_MODS
argument_list|)
name|tsleep
argument_list|(
name|bp
argument_list|,
name|PRIBIO
argument_list|,
literal|"biowait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
else|#
directive|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_READ
condition|)
name|tsleep
argument_list|(
name|bp
argument_list|,
name|PRIBIO
argument_list|,
literal|"biord"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
else|else
name|tsleep
argument_list|(
name|bp
argument_list|,
name|PRIBIO
argument_list|,
literal|"biowr"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_EINTR
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_EINTR
expr_stmt|;
return|return
operator|(
name|EINTR
operator|)
return|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ERROR
condition|)
block|{
return|return
operator|(
name|bp
operator|->
name|b_error
condition|?
name|bp
operator|->
name|b_error
else|:
name|EIO
operator|)
return|;
block|}
else|else
block|{
return|return
operator|(
literal|0
operator|)
return|;
block|}
block|}
end_function

begin_comment
comment|/*  *	biodone:  *  *	Finish I/O on a buffer, optionally calling a completion function.  *	This is usually called from an interrupt so process blocking is  *	not allowed.  *  *	biodone is also responsible for setting B_CACHE in a B_VMIO bp.  *	In a non-VMIO bp, B_CACHE will be set on the next getblk()   *	assuming B_INVAL is clear.  *  *	For the VMIO case, we set B_CACHE if the op was a read and no  *	read error occured, or if the op was a write.  B_CACHE is never  *	set if the buffer is invalid or otherwise uncacheable.  *  *	biodone does not mess with B_INVAL, allowing the I/O routine or the  *	initiator to leave B_INVAL set to brelse the buffer out of existance  *	in the biodone routine.  */
end_comment

begin_function
name|void
name|biodone
parameter_list|(
specifier|register
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
name|KASSERT
argument_list|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|>
literal|0
argument_list|,
operator|(
literal|"biodone: bp %p not busy %d"
operator|,
name|bp
operator|,
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DONE
operator|)
argument_list|,
operator|(
literal|"biodone: bp %p already done"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_DONE
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_FREEBUF
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_READ
operator|)
operator|==
literal|0
condition|)
block|{
name|vwakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* call optional completion function if requested */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CALL
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CALL
expr_stmt|;
call|(
modifier|*
name|bp
operator|->
name|b_iodone
call|)
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|!=
name|NULL
operator|&&
name|bioops
operator|.
name|io_complete
condition|)
call|(
modifier|*
name|bioops
operator|.
name|io_complete
call|)
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|int
name|i
decl_stmt|,
name|resid
decl_stmt|;
name|vm_ooffset_t
name|foff
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|int
name|iosize
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
init|=
name|bp
operator|->
name|b_vp
decl_stmt|;
name|obj
operator|=
name|vp
operator|->
name|v_object
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|VFS_BIO_DEBUG
argument_list|)
if|if
condition|(
name|vp
operator|->
name|v_usecount
operator|==
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"biodone: zero vnode ref count"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|vp
operator|->
name|v_object
operator|==
name|NULL
condition|)
block|{
name|panic
argument_list|(
literal|"biodone: missing VM object"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|vp
operator|->
name|v_flag
operator|&
name|VOBJBUF
operator|)
operator|==
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"biodone: vnode is not setup for merged cache"
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"biodone: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
operator|!
name|obj
condition|)
block|{
name|panic
argument_list|(
literal|"biodone: no object"
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
if|#
directive|if
name|defined
argument_list|(
name|VFS_BIO_DEBUG
argument_list|)
if|if
condition|(
name|obj
operator|->
name|paging_in_progress
operator|<
name|bp
operator|->
name|b_npages
condition|)
block|{
name|printf
argument_list|(
literal|"biodone: paging in progress(%d)< bp->b_npages(%d)\n"
argument_list|,
name|obj
operator|->
name|paging_in_progress
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* 		 * Set B_CACHE if the op was a normal read and no error 		 * occured.  B_CACHE is set for writes in the b*write() 		 * routines. 		 */
name|iosize
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_READ
operator||
name|B_FREEBUF
operator||
name|B_INVAL
operator||
name|B_NOCACHE
operator||
name|B_ERROR
operator|)
operator|)
operator|==
name|B_READ
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|int
name|bogusflag
init|=
literal|0
decl_stmt|;
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|bogusflag
operator|=
literal|1
expr_stmt|;
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|foff
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|m
condition|)
block|{
if|#
directive|if
name|defined
argument_list|(
name|VFS_BIO_DEBUG
argument_list|)
name|printf
argument_list|(
literal|"biodone: page disappeared\n"
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|vm_object_pip_subtract
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
continue|continue;
block|}
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|m
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
if|#
directive|if
name|defined
argument_list|(
name|VFS_BIO_DEBUG
argument_list|)
if|if
condition|(
name|OFF_TO_IDX
argument_list|(
name|foff
argument_list|)
operator|!=
name|m
operator|->
name|pindex
condition|)
block|{
name|printf
argument_list|(
literal|"biodone: foff(%lu)/m->pindex(%d) mismatch\n"
argument_list|,
operator|(
name|unsigned
name|long
operator|)
name|foff
argument_list|,
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|resid
operator|=
name|IDX_TO_OFF
argument_list|(
name|m
operator|->
name|pindex
operator|+
literal|1
argument_list|)
operator|-
name|foff
expr_stmt|;
if|if
condition|(
name|resid
operator|>
name|iosize
condition|)
name|resid
operator|=
name|iosize
expr_stmt|;
comment|/* 			 * In the write case, the valid and clean bits are 			 * already changed correctly ( see bdwrite() ), so we  			 * only need to do this here in the read case. 			 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_READ
operator|)
operator|&&
operator|!
name|bogusflag
operator|&&
name|resid
operator|>
literal|0
condition|)
block|{
name|vfs_page_set_valid
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|i
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
comment|/* 			 * when debugging new filesystems or buffer I/O methods, this 			 * is the most common error that pops up.  if you see this, you 			 * have not set the page busy flag correctly!!! 			 */
if|if
condition|(
name|m
operator|->
name|busy
operator|==
literal|0
condition|)
block|{
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
name|printf
argument_list|(
literal|"biodone: page busy< 0, "
literal|"pindex: %d, foff: 0x(%x,%x), "
literal|"resid: %d, index: %d\n"
argument_list|,
operator|(
name|int
operator|)
name|m
operator|->
name|pindex
argument_list|,
call|(
name|int
call|)
argument_list|(
name|foff
operator|>>
literal|32
argument_list|)
argument_list|,
operator|(
name|int
operator|)
name|foff
operator|&
literal|0xffffffff
argument_list|,
name|resid
argument_list|,
name|i
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|vp
operator|->
name|v_type
operator|!=
name|VBLK
condition|)
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
name|printf
argument_list|(
literal|" iosize: %ld, lblkno: %d, flags: 0x%lx, npages: %d\n"
argument_list|,
name|bp
operator|->
name|b_vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
argument_list|,
operator|(
name|int
operator|)
name|bp
operator|->
name|b_lblkno
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
else|else
name|printf
argument_list|(
literal|" VDEV, lblkno: %d, flags: 0x%lx, npages: %d\n"
argument_list|,
operator|(
name|int
operator|)
name|bp
operator|->
name|b_lblkno
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|" valid: 0x%x, dirty: 0x%x, wired: %d\n"
argument_list|,
name|m
operator|->
name|valid
argument_list|,
name|m
operator|->
name|dirty
argument_list|,
name|m
operator|->
name|wire_count
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|panic
argument_list|(
literal|"biodone: page busy< 0\n"
argument_list|)
expr_stmt|;
block|}
name|vm_page_io_finish
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_object_pip_subtract
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|foff
operator|+=
name|resid
expr_stmt|;
name|iosize
operator|-=
name|resid
expr_stmt|;
block|}
if|if
condition|(
name|obj
condition|)
name|vm_object_pip_wakeupn
argument_list|(
name|obj
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * For asynchronous completions, release the buffer now. The brelse 	 * will do a wakeup there if necessary - so no need to do a wakeup 	 * here in the async case. The sync case always needs to do a wakeup. 	 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ASYNC
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_NOCACHE
operator||
name|B_INVAL
operator||
name|B_ERROR
operator||
name|B_RELBUF
operator|)
operator|)
operator|!=
literal|0
condition|)
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
else|else
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|wakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine is called in lieu of iodone in the case of  * incomplete I/O.  This keeps the busy status for pages  * consistant.  */
end_comment

begin_function
name|void
name|vfs_unbusy_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|struct
name|vnode
modifier|*
name|vp
init|=
name|bp
operator|->
name|b_vp
decl_stmt|;
name|vm_object_t
name|obj
init|=
name|vp
operator|->
name|v_object
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
init|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
operator|+
name|i
argument_list|)
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
operator|!
name|m
condition|)
block|{
name|panic
argument_list|(
literal|"vfs_unbusy_pages: page missing\n"
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|m
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
name|vm_object_pip_subtract
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|vm_page_io_finish
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_object_pip_wakeupn
argument_list|(
name|obj
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * vfs_page_set_valid:  *  *	Set the valid bits in a page based on the supplied offset.   The  *	range is restricted to the buffer's size.  *  *	This routine is typically called after a read completes.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_page_set_valid
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|int
name|pageno
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_ooffset_t
name|soff
decl_stmt|,
name|eoff
decl_stmt|;
comment|/* 	 * Start and end offsets in buffer.  eoff - soff may not cross a 	 * page boundry or cross the end of the buffer.  The end of the 	 * buffer, in this case, is our file EOF, not the allocation size 	 * of the buffer. 	 */
name|soff
operator|=
name|off
expr_stmt|;
name|eoff
operator|=
operator|(
name|off
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
name|PAGE_MASK
expr_stmt|;
if|if
condition|(
name|eoff
operator|>
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
condition|)
name|eoff
operator|=
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* 	 * Set valid range.  This is typically the entire buffer and thus the 	 * entire page. 	 */
if|if
condition|(
name|eoff
operator|>
name|soff
condition|)
block|{
name|vm_page_set_validclean
argument_list|(
name|m
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
name|soff
operator|&
name|PAGE_MASK
argument_list|)
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
name|eoff
operator|-
name|soff
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * This routine is called before a device strategy routine.  * It is used to tell the VM system that paging I/O is in  * progress, and treat the pages associated with the buffer  * almost as being PG_BUSY.  Also the object paging_in_progress  * flag is handled to make sure that the object doesn't become  * inconsistant.  *  * Since I/O has not been initiated yet, certain buffer flags  * such as B_ERROR or B_INVAL may be in an inconsistant state  * and should be ignored.  */
end_comment

begin_function
name|void
name|vfs_busy_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|clear_modify
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|bogus
decl_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|struct
name|vnode
modifier|*
name|vp
init|=
name|bp
operator|->
name|b_vp
decl_stmt|;
name|vm_object_t
name|obj
init|=
name|vp
operator|->
name|v_object
decl_stmt|;
name|vm_ooffset_t
name|foff
decl_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"vfs_busy_pages: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
name|vfs_setdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|retry
label|:
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
init|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|vm_page_sleep_busy
argument_list|(
name|m
argument_list|,
name|FALSE
argument_list|,
literal|"vbpage"
argument_list|)
condition|)
goto|goto
name|retry
goto|;
block|}
name|bogus
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
init|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
decl_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CLUSTER
operator|)
operator|==
literal|0
condition|)
block|{
name|vm_object_pip_add
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_io_start
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
comment|/* 			 * When readying a buffer for a read ( i.e 			 * clear_modify == 0 ), it is important to do 			 * bogus_page replacement for valid pages in  			 * partially instantiated buffers.  Partially  			 * instantiated buffers can, in turn, occur when 			 * reconstituting a buffer from its VM backing store 			 * base.  We only have to do this if B_CACHE is 			 * clear ( which causes the I/O to occur in the 			 * first place ).  The replacement prevents the read 			 * I/O from overwriting potentially dirty VM-backed 			 * pages.  XXX bogus page replacement is, uh, bogus. 			 * It may not work properly with small-block devices. 			 * We need to find a better way. 			 */
name|vm_page_protect
argument_list|(
name|m
argument_list|,
name|VM_PROT_NONE
argument_list|)
expr_stmt|;
if|if
condition|(
name|clear_modify
condition|)
name|vfs_page_set_valid
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|i
argument_list|,
name|m
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|bogus_page
expr_stmt|;
name|bogus
operator|++
expr_stmt|;
block|}
name|foff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
name|PAGE_MASK
expr_stmt|;
block|}
if|if
condition|(
name|bogus
condition|)
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Tell the VM system that the pages associated with this buffer  * are clean.  This is used for delayed writes where the data is  * going to go to disk eventually without additional VM intevention.  *  * Note that while we only really need to clean through to b_bcount, we  * just go ahead and clean through to b_bufsize.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_clean_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|vm_ooffset_t
name|foff
decl_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"vfs_clean_pages: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
init|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
decl_stmt|;
name|vm_ooffset_t
name|noff
init|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
name|PAGE_MASK
decl_stmt|;
name|vm_ooffset_t
name|eoff
init|=
name|noff
decl_stmt|;
if|if
condition|(
name|eoff
operator|>
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bufsize
condition|)
name|eoff
operator|=
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|vfs_page_set_valid
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|i
argument_list|,
name|m
argument_list|)
expr_stmt|;
comment|/* vm_page_clear_dirty(m, foff& PAGE_MASK, eoff - foff); */
name|foff
operator|=
name|noff
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_set_validclean:  *  *	Set the range within the buffer to valid and clean.  The range is   *	relative to the beginning of the buffer, b_offset.  Note that b_offset  *	itself may be offset from the beginning of the first page.  */
end_comment

begin_function
name|void
name|vfs_bio_set_validclean
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|int
name|i
decl_stmt|;
name|int
name|n
decl_stmt|;
comment|/* 		 * Fixup base to be relative to beginning of first page. 		 * Set initial n to be the maximum number of bytes in the 		 * first page that can be validated. 		 */
name|base
operator|+=
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
operator|-
operator|(
name|base
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|base
operator|/
name|PAGE_SIZE
init|;
name|size
operator|>
literal|0
operator|&&
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
operator|++
name|i
control|)
block|{
name|vm_page_t
name|m
init|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|n
operator|>
name|size
condition|)
name|n
operator|=
name|size
expr_stmt|;
name|vm_page_set_validclean
argument_list|(
name|m
argument_list|,
name|base
operator|&
name|PAGE_MASK
argument_list|,
name|n
argument_list|)
expr_stmt|;
name|base
operator|+=
name|n
expr_stmt|;
name|size
operator|-=
name|n
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_clrbuf:  *  *	clear a buffer.  This routine essentially fakes an I/O, so we need  *	to clear B_ERROR and B_INVAL.  *  *	Note that while we only theoretically need to clear through b_bcount,  *	we go ahead and clear through b_bufsize.  */
end_comment

begin_function
name|void
name|vfs_bio_clrbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|mask
init|=
literal|0
decl_stmt|;
name|caddr_t
name|sa
decl_stmt|,
name|ea
decl_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_VMIO
operator||
name|B_MALLOC
operator|)
operator|)
operator|==
name|B_VMIO
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_INVAL
operator||
name|B_ERROR
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_npages
operator|==
literal|1
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_bufsize
operator|<
name|PAGE_SIZE
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
condition|)
block|{
name|mask
operator|=
operator|(
literal|1
operator|<<
operator|(
name|bp
operator|->
name|b_bufsize
operator|/
name|DEV_BSIZE
operator|)
operator|)
operator|-
literal|1
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
operator|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|!=
name|mask
operator|)
condition|)
block|{
name|bzero
argument_list|(
name|bp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator||=
name|mask
expr_stmt|;
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
return|return;
block|}
name|ea
operator|=
name|sa
operator|=
name|bp
operator|->
name|b_data
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
operator|,
name|sa
operator|=
name|ea
control|)
block|{
name|int
name|j
init|=
operator|(
operator|(
name|vm_offset_t
operator|)
name|sa
operator|&
name|PAGE_MASK
operator|)
operator|/
name|DEV_BSIZE
decl_stmt|;
name|ea
operator|=
operator|(
name|caddr_t
operator|)
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|sa
operator|+
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|ea
operator|=
operator|(
name|caddr_t
operator|)
operator|(
name|vm_offset_t
operator|)
name|ulmin
argument_list|(
operator|(
name|u_long
operator|)
operator|(
name|vm_offset_t
operator|)
name|ea
argument_list|,
operator|(
name|u_long
operator|)
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
name|mask
operator|=
operator|(
operator|(
literal|1
operator|<<
operator|(
operator|(
name|ea
operator|-
name|sa
operator|)
operator|/
name|DEV_BSIZE
operator|)
operator|)
operator|-
literal|1
operator|)
operator|<<
name|j
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
name|mask
condition|)
continue|continue;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
block|{
name|bzero
argument_list|(
name|sa
argument_list|,
name|ea
operator|-
name|sa
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
init|;
name|sa
operator|<
name|ea
condition|;
name|sa
operator|+=
name|DEV_BSIZE
operator|,
name|j
operator|++
control|)
block|{
if|if
condition|(
operator|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
name|j
operator|)
operator|)
operator|==
literal|0
condition|)
name|bzero
argument_list|(
name|sa
argument_list|,
name|DEV_BSIZE
argument_list|)
expr_stmt|;
block|}
block|}
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator||=
name|mask
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
name|clrbuf
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * vm_hold_load_pages and vm_hold_unload pages get pages into  * a buffers address space.  The pages are anonymous and are  * not associated with a file object.  */
end_comment

begin_function
name|void
name|vm_hold_load_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
block|{
name|vm_offset_t
name|pg
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|int
name|index
decl_stmt|;
name|to
operator|=
name|round_page
argument_list|(
name|to
argument_list|)
expr_stmt|;
name|from
operator|=
name|round_page
argument_list|(
name|from
argument_list|)
expr_stmt|;
name|index
operator|=
operator|(
name|from
operator|-
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
for|for
control|(
name|pg
operator|=
name|from
init|;
name|pg
operator|<
name|to
condition|;
name|pg
operator|+=
name|PAGE_SIZE
operator|,
name|index
operator|++
control|)
block|{
name|tryagain
label|:
name|p
operator|=
name|vm_page_alloc
argument_list|(
name|kernel_object
argument_list|,
operator|(
operator|(
name|pg
operator|-
name|VM_MIN_KERNEL_ADDRESS
operator|)
operator|>>
name|PAGE_SHIFT
operator|)
argument_list|,
name|VM_ALLOC_NORMAL
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|p
condition|)
block|{
name|vm_pageout_deficit
operator|+=
operator|(
name|to
operator|-
name|from
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
name|VM_WAIT
expr_stmt|;
goto|goto
name|tryagain
goto|;
block|}
name|vm_page_wire
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|p
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|p
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|pmap_kenter
argument_list|(
name|pg
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
operator|=
name|p
expr_stmt|;
name|vm_page_wakeup
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_npages
operator|=
name|index
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_hold_free_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
block|{
name|vm_offset_t
name|pg
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|int
name|index
decl_stmt|,
name|newnpages
decl_stmt|;
name|from
operator|=
name|round_page
argument_list|(
name|from
argument_list|)
expr_stmt|;
name|to
operator|=
name|round_page
argument_list|(
name|to
argument_list|)
expr_stmt|;
name|newnpages
operator|=
name|index
operator|=
operator|(
name|from
operator|-
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
for|for
control|(
name|pg
operator|=
name|from
init|;
name|pg
operator|<
name|to
condition|;
name|pg
operator|+=
name|PAGE_SIZE
operator|,
name|index
operator|++
control|)
block|{
name|p
operator|=
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
expr_stmt|;
if|if
condition|(
name|p
operator|&&
operator|(
name|index
operator|<
name|bp
operator|->
name|b_npages
operator|)
condition|)
block|{
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAX_PERF
argument_list|)
if|if
condition|(
name|p
operator|->
name|busy
condition|)
block|{
name|printf
argument_list|(
literal|"vm_hold_free_pages: blkno: %d, lblkno: %d\n"
argument_list|,
name|bp
operator|->
name|b_blkno
argument_list|,
name|bp
operator|->
name|b_lblkno
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
operator|=
name|NULL
expr_stmt|;
name|pmap_kremove
argument_list|(
name|pg
argument_list|)
expr_stmt|;
name|vm_page_busy
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|p
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
block|}
name|bp
operator|->
name|b_npages
operator|=
name|newnpages
expr_stmt|;
block|}
end_function

begin_include
include|#
directive|include
file|"opt_ddb.h"
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_include
include|#
directive|include
file|<ddb/ddb.h>
end_include

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|buffer
argument_list|,
argument|db_show_buffer
argument_list|)
end_macro

begin_block
block|{
comment|/* get args */
name|struct
name|buf
modifier|*
name|bp
init|=
operator|(
expr|struct
name|buf
operator|*
operator|)
name|addr
decl_stmt|;
if|if
condition|(
operator|!
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"usage: show buffer<addr>\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|db_printf
argument_list|(
literal|"b_flags = 0x%b\n"
argument_list|,
operator|(
name|u_int
operator|)
name|bp
operator|->
name|b_flags
argument_list|,
name|PRINT_BUF_FLAGS
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"b_error = %d, b_bufsize = %ld, b_bcount = %ld, "
literal|"b_resid = %ld\nb_dev = (%d,%d), b_data = %p, "
literal|"b_blkno = %d, b_pblkno = %d\n"
argument_list|,
name|bp
operator|->
name|b_error
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|,
name|bp
operator|->
name|b_bcount
argument_list|,
name|bp
operator|->
name|b_resid
argument_list|,
name|major
argument_list|(
name|bp
operator|->
name|b_dev
argument_list|)
argument_list|,
name|minor
argument_list|(
name|bp
operator|->
name|b_dev
argument_list|)
argument_list|,
name|bp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_blkno
argument_list|,
name|bp
operator|->
name|b_pblkno
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_npages
condition|)
block|{
name|int
name|i
decl_stmt|;
name|db_printf
argument_list|(
literal|"b_npages = %d, pages(OBJ, IDX, PA): "
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|db_printf
argument_list|(
literal|"(%p, 0x%lx, 0x%lx)"
argument_list|,
operator|(
name|void
operator|*
operator|)
name|m
operator|->
name|object
argument_list|,
operator|(
name|u_long
operator|)
name|m
operator|->
name|pindex
argument_list|,
operator|(
name|u_long
operator|)
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|i
operator|+
literal|1
operator|)
operator|<
name|bp
operator|->
name|b_npages
condition|)
name|db_printf
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* DDB */
end_comment

end_unit

