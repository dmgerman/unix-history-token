begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * Copyright (c) 1994,1997 John S. Dyson  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice immediately at the beginning of the file, without modification,  *    this list of conditions, and the following disclaimer.  * 2. Absolutely no warranty of function or purpose is made by the author  *		John S. Dyson.  *  * $FreeBSD$  */
end_comment

begin_comment
comment|/*  * this file contains a new buffer I/O scheme implementing a coherent  * VM object and buffer cache scheme.  Pains have been taken to make  * sure that the performance degradation associated with schemes such  * as this is not realized.  *  * Author:  John S. Dyson  * Significant help during the development and debugging phases  * had been provided by David Greenman, also of the FreeBSD core team.  *  * see man buf(9) for more info.  */
end_comment

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/stdint.h>
end_include

begin_include
include|#
directive|include
file|<sys/bio.h>
end_include

begin_include
include|#
directive|include
file|<sys/buf.h>
end_include

begin_include
include|#
directive|include
file|<sys/devicestat.h>
end_include

begin_include
include|#
directive|include
file|<sys/eventhandler.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mount.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/kthread.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_expr_stmt
specifier|static
name|MALLOC_DEFINE
argument_list|(
name|M_BIOBUF
argument_list|,
literal|"BIO buffer"
argument_list|,
literal|"BIO buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|struct
name|bio_ops
name|bioops
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* I/O operation notification */
end_comment

begin_decl_stmt
name|struct
name|buf_ops
name|buf_ops_bio
init|=
block|{
literal|"buf_ops_bio"
block|,
name|bwrite
block|}
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * XXX buf is global because kern_shutdown.c and ffs_checkoverlap has  * carnal knowledge of buffers.  This knowledge should be moved to vfs_bio.c.  */
end_comment

begin_decl_stmt
name|struct
name|buf
modifier|*
name|buf
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* buffer header pool */
end_comment

begin_decl_stmt
name|struct
name|mtx
name|buftimelock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Interlock on setting prio and timo */
end_comment

begin_function_decl
specifier|static
name|void
name|vm_hold_free_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_hold_load_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_page_set_valid
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|int
name|pageno
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_clean_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_setdirty
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_vmio_release
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vfs_backgroundwritedone
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|flushbufqueues
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|buf_daemon
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
name|int
name|vmiodirenable
init|=
name|TRUE
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|vmiodirenable
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vmiodirenable
argument_list|,
literal|0
argument_list|,
literal|"Use the VM system for directory writes"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|runningbufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|runningbufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|runningbufspace
argument_list|,
literal|0
argument_list|,
literal|"Amount of presently outstanding async buffer io"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|bufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufspace
argument_list|,
literal|0
argument_list|,
literal|"KVA memory used for bufs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|maxbufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|maxbufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|maxbufspace
argument_list|,
literal|0
argument_list|,
literal|"Maximum allowed value of bufspace (including buf_daemon)"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|bufmallocspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufmallocspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|bufmallocspace
argument_list|,
literal|0
argument_list|,
literal|"Amount of malloced memory for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|maxbufmallocspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|maxmallocbufspace
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|maxbufmallocspace
argument_list|,
literal|0
argument_list|,
literal|"Maximum amount of malloced memory for buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|lobufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lobufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|lobufspace
argument_list|,
literal|0
argument_list|,
literal|"Minimum amount of buffers we want to have"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|hibufspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hibufspace
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|hibufspace
argument_list|,
literal|0
argument_list|,
literal|"Maximum allowed value of bufspace (excluding buf_daemon)"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|bufreusecnt
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufreusecnt
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|bufreusecnt
argument_list|,
literal|0
argument_list|,
literal|"Number of times we have reused a buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|buffreekvacnt
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|buffreekvacnt
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|buffreekvacnt
argument_list|,
literal|0
argument_list|,
literal|"Number of times we have freed the KVA space from some buffer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|bufdefragcnt
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|bufdefragcnt
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|bufdefragcnt
argument_list|,
literal|0
argument_list|,
literal|"Number of times we have had to repeat buffer allocation to defragment"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|lorunningspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lorunningspace
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|lorunningspace
argument_list|,
literal|0
argument_list|,
literal|"Minimum preferred space used for in-progress I/O"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|hirunningspace
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hirunningspace
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|hirunningspace
argument_list|,
literal|0
argument_list|,
literal|"Maximum amount of space to use for in-progress I/O"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|numdirtybuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|numdirtybuffers
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|numdirtybuffers
argument_list|,
literal|0
argument_list|,
literal|"Number of buffers that are dirty (has unwritten changes) at the moment"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|lodirtybuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lodirtybuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|lodirtybuffers
argument_list|,
literal|0
argument_list|,
literal|"How many buffers we want to have free before bufdaemon can sleep"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|hidirtybuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hidirtybuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|hidirtybuffers
argument_list|,
literal|0
argument_list|,
literal|"When the number of dirty buffers is considered severe"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|numfreebuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|numfreebuffers
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|numfreebuffers
argument_list|,
literal|0
argument_list|,
literal|"Number of free buffers"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|lofreebuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|lofreebuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|lofreebuffers
argument_list|,
literal|0
argument_list|,
literal|"XXX Unused"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|hifreebuffers
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|hifreebuffers
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|hifreebuffers
argument_list|,
literal|0
argument_list|,
literal|"XXX Complicatedly unused"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|getnewbufcalls
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|getnewbufcalls
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|getnewbufcalls
argument_list|,
literal|0
argument_list|,
literal|"Number of calls to getnewbuf"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|getnewbufrestarts
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|getnewbufrestarts
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|getnewbufrestarts
argument_list|,
literal|0
argument_list|,
literal|"Number of times getnewbuf has had to restart a buffer aquisition"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|dobkgrdwrite
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_debug
argument_list|,
name|OID_AUTO
argument_list|,
name|dobkgrdwrite
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|dobkgrdwrite
argument_list|,
literal|0
argument_list|,
literal|"Do background writes (honoring the BX_BKGRDWRITE flag)?"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Wakeup point for bufdaemon, as well as indicator of whether it is already  * active.  Set to 1 when the bufdaemon is already "on" the queue, 0 when it  * is idling.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|bd_request
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * bogus page -- for I/O to/from partially complete buffers  * this is a temporary solution to the problem, but it is not  * really that bad.  it would be better to split the buffer  * for input in the case of buffers partially already in memory,  * but the code is intricate enough already.  */
end_comment

begin_decl_stmt
name|vm_page_t
name|bogus_page
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Synchronization (sleep/wakeup) variable for active buffer space requests.  * Set when wait starts, cleared prior to wakeup().  * Used in runningbufwakeup() and waitrunningbufspace().  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|runningbufreq
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*   * Synchronization (sleep/wakeup) variable for buffer requests.  * Can contain the VFS_BIO_NEED flags defined below; setting/clearing is done  * by and/or.  * Used in numdirtywakeup(), bufspacewakeup(), bufcountwakeup(), bwillwrite(),  * getnewbuf(), and getblk().  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|needsbuffer
decl_stmt|;
end_decl_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|USE_BUFHASH
end_ifdef

begin_comment
comment|/*  * Mask for index into the buffer hash table, which needs to be power of 2 in  * size.  Set in kern_vfs_bio_buffer_alloc.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|bufhashmask
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Hash table for all buffers, with a linked list hanging from each table  * entry.  Set in kern_vfs_bio_buffer_alloc, initialized in buf_init.  */
end_comment

begin_expr_stmt
specifier|static
name|LIST_HEAD
argument_list|(
name|bufhashhdr
argument_list|,
name|buf
argument_list|)
operator|*
name|bufhashtbl
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Somewhere to store buffers when they are not in another list, to always  * have them in a list (and thus being able to use the same set of operations  * on them.)  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|bufhashhdr
name|invalhash
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Definitions for the buffer free lists.  */
end_comment

begin_define
define|#
directive|define
name|BUFFER_QUEUES
value|6
end_define

begin_comment
comment|/* number of free buffer queues */
end_comment

begin_define
define|#
directive|define
name|QUEUE_NONE
value|0
end_define

begin_comment
comment|/* on no queue */
end_comment

begin_define
define|#
directive|define
name|QUEUE_LOCKED
value|1
end_define

begin_comment
comment|/* locked buffers */
end_comment

begin_define
define|#
directive|define
name|QUEUE_CLEAN
value|2
end_define

begin_comment
comment|/* non-B_DELWRI buffers */
end_comment

begin_define
define|#
directive|define
name|QUEUE_DIRTY
value|3
end_define

begin_comment
comment|/* B_DELWRI buffers */
end_comment

begin_define
define|#
directive|define
name|QUEUE_EMPTYKVA
value|4
end_define

begin_comment
comment|/* empty buffer headers w/KVA assignment */
end_comment

begin_define
define|#
directive|define
name|QUEUE_EMPTY
value|5
end_define

begin_comment
comment|/* empty buffer headers */
end_comment

begin_comment
comment|/* Queues for free buffers with various properties */
end_comment

begin_expr_stmt
specifier|static
name|TAILQ_HEAD
argument_list|(
argument|bqueues
argument_list|,
argument|buf
argument_list|)
name|bufqueues
index|[
name|BUFFER_QUEUES
index|]
operator|=
block|{
block|{
literal|0
block|}
block|}
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Single global constant for BUF_WMESG, to avoid getting multiple references.  * buf_wmesg is referred from macros.  */
end_comment

begin_decl_stmt
specifier|const
name|char
modifier|*
name|buf_wmesg
init|=
name|BUF_WMESG
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|VFS_BIO_NEED_ANY
value|0x01
end_define

begin_comment
comment|/* any freeable buffer */
end_comment

begin_define
define|#
directive|define
name|VFS_BIO_NEED_DIRTYFLUSH
value|0x02
end_define

begin_comment
comment|/* waiting for dirty buffer flush */
end_comment

begin_define
define|#
directive|define
name|VFS_BIO_NEED_FREE
value|0x04
end_define

begin_comment
comment|/* wait for free bufs, hi hysteresis */
end_comment

begin_define
define|#
directive|define
name|VFS_BIO_NEED_BUFSPACE
value|0x08
end_define

begin_comment
comment|/* wait for buf space, lo hysteresis */
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|USE_BUFHASH
end_ifdef

begin_comment
comment|/*  * Buffer hash table code.  Note that the logical block scans linearly, which  * gives us some L1 cache locality.  */
end_comment

begin_expr_stmt
specifier|static
name|__inline
expr|struct
name|bufhashhdr
operator|*
name|bufhash
argument_list|(
argument|struct vnode *vnp
argument_list|,
argument|daddr_t bn
argument_list|)
block|{
return|return
operator|(
operator|&
name|bufhashtbl
index|[
operator|(
operator|(
call|(
name|uintptr_t
call|)
argument_list|(
name|vnp
argument_list|)
operator|>>
literal|7
operator|)
operator|+
operator|(
name|int
operator|)
name|bn
operator|)
operator|&
name|bufhashmask
index|]
operator|)
return|;
block|}
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  *	numdirtywakeup:  *  *	If someone is blocked due to there being too many dirty buffers,  *	and numdirtybuffers is now reasonable, wake them up.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|numdirtywakeup
parameter_list|(
name|int
name|level
parameter_list|)
block|{
if|if
condition|(
name|numdirtybuffers
operator|<=
name|level
condition|)
block|{
if|if
condition|(
name|needsbuffer
operator|&
name|VFS_BIO_NEED_DIRTYFLUSH
condition|)
block|{
name|needsbuffer
operator|&=
operator|~
name|VFS_BIO_NEED_DIRTYFLUSH
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|needsbuffer
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	bufspacewakeup:  *  *	Called when buffer space is potentially available for recovery.  *	getnewbuf() will block on this flag when it is unable to free   *	sufficient buffer space.  Buffer space becomes recoverable when   *	bp's get placed back in the queues.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|bufspacewakeup
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * If someone is waiting for BUF space, wake them up.  Even 	 * though we haven't freed the kva space yet, the waiting 	 * process will be able to now. 	 */
if|if
condition|(
name|needsbuffer
operator|&
name|VFS_BIO_NEED_BUFSPACE
condition|)
block|{
name|needsbuffer
operator|&=
operator|~
name|VFS_BIO_NEED_BUFSPACE
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|needsbuffer
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * runningbufwakeup() - in-progress I/O accounting.  *  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|runningbufwakeup
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_runningbufspace
condition|)
block|{
name|runningbufspace
operator|-=
name|bp
operator|->
name|b_runningbufspace
expr_stmt|;
name|bp
operator|->
name|b_runningbufspace
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|runningbufreq
operator|&&
name|runningbufspace
operator|<=
name|lorunningspace
condition|)
block|{
name|runningbufreq
operator|=
literal|0
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|runningbufreq
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	bufcountwakeup:  *  *	Called when a buffer has been added to one of the free queues to  *	account for the buffer and to wakeup anyone waiting for free buffers.  *	This typically occurs when large amounts of metadata are being handled  *	by the buffer cache ( else buffer space runs out first, usually ).  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|bufcountwakeup
parameter_list|(
name|void
parameter_list|)
block|{
operator|++
name|numfreebuffers
expr_stmt|;
if|if
condition|(
name|needsbuffer
condition|)
block|{
name|needsbuffer
operator|&=
operator|~
name|VFS_BIO_NEED_ANY
expr_stmt|;
if|if
condition|(
name|numfreebuffers
operator|>=
name|hifreebuffers
condition|)
name|needsbuffer
operator|&=
operator|~
name|VFS_BIO_NEED_FREE
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|needsbuffer
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	waitrunningbufspace()  *  *	runningbufspace is a measure of the amount of I/O currently  *	running.  This routine is used in async-write situations to  *	prevent creating huge backups of pending writes to a device.  *	Only asynchronous writes are governed by this function.  *  *	Reads will adjust runningbufspace, but will not block based on it.  *	The read load has a side effect of reducing the allowed write load.  *  *	This does NOT turn an async write into a sync write.  It waits    *	for earlier writes to complete and generally returns before the  *	caller's write has reached the device.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|waitrunningbufspace
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * XXX race against wakeup interrupt, currently 	 * protected by Giant.  FIXME! 	 */
while|while
condition|(
name|runningbufspace
operator|>
name|hirunningspace
condition|)
block|{
operator|++
name|runningbufreq
expr_stmt|;
name|tsleep
argument_list|(
operator|&
name|runningbufreq
argument_list|,
name|PVM
argument_list|,
literal|"wdrain"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vfs_buf_test_cache:  *  *	Called when a buffer is extended.  This function clears the B_CACHE  *	bit if the newly extended portion of the buffer does not contain  *	valid data.  */
end_comment

begin_function
specifier|static
name|__inline__
name|void
name|vfs_buf_test_cache
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|foff
parameter_list|,
name|vm_offset_t
name|off
parameter_list|,
name|vm_offset_t
name|size
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|GIANT_REQUIRED
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
condition|)
block|{
name|int
name|base
init|=
operator|(
name|foff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
decl_stmt|;
if|if
condition|(
name|vm_page_is_valid
argument_list|(
name|m
argument_list|,
name|base
argument_list|,
name|size
argument_list|)
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/* Wake up the buffer deamon if necessary */
end_comment

begin_function
specifier|static
name|__inline__
name|void
name|bd_wakeup
parameter_list|(
name|int
name|dirtybuflevel
parameter_list|)
block|{
if|if
condition|(
name|bd_request
operator|==
literal|0
operator|&&
name|numdirtybuffers
operator|>=
name|dirtybuflevel
condition|)
block|{
name|bd_request
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|bd_request
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * bd_speedup - speedup the buffer cache flushing code  */
end_comment

begin_function
specifier|static
name|__inline__
name|void
name|bd_speedup
parameter_list|(
name|void
parameter_list|)
block|{
name|bd_wakeup
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Calculating buffer cache scaling values and reserve space for buffer  * headers.  This is called during low level kernel initialization and  * may be called more then once.  We CANNOT write to the memory area  * being reserved at this time.  */
end_comment

begin_function
name|caddr_t
name|kern_vfs_bio_buffer_alloc
parameter_list|(
name|caddr_t
name|v
parameter_list|,
name|long
name|physmem_est
parameter_list|)
block|{
comment|/* 	 * physmem_est is in pages.  Convert it to kilobytes (assumes 	 * PAGE_SIZE is>= 1K) 	 */
name|physmem_est
operator|=
name|physmem_est
operator|*
operator|(
name|PAGE_SIZE
operator|/
literal|1024
operator|)
expr_stmt|;
comment|/* 	 * The nominal buffer size (and minimum KVA allocation) is BKVASIZE. 	 * For the first 64MB of ram nominally allocate sufficient buffers to 	 * cover 1/4 of our ram.  Beyond the first 64MB allocate additional 	 * buffers to cover 1/20 of our ram over 64MB.  When auto-sizing 	 * the buffer cache we limit the eventual kva reservation to 	 * maxbcache bytes. 	 * 	 * factor represents the 1/4 x ram conversion. 	 */
if|if
condition|(
name|nbuf
operator|==
literal|0
condition|)
block|{
name|int
name|factor
init|=
literal|4
operator|*
name|BKVASIZE
operator|/
literal|1024
decl_stmt|;
name|nbuf
operator|=
literal|50
expr_stmt|;
if|if
condition|(
name|physmem_est
operator|>
literal|4096
condition|)
name|nbuf
operator|+=
name|min
argument_list|(
operator|(
name|physmem_est
operator|-
literal|4096
operator|)
operator|/
name|factor
argument_list|,
literal|65536
operator|/
name|factor
argument_list|)
expr_stmt|;
if|if
condition|(
name|physmem_est
operator|>
literal|65536
condition|)
name|nbuf
operator|+=
operator|(
name|physmem_est
operator|-
literal|65536
operator|)
operator|*
literal|2
operator|/
operator|(
name|factor
operator|*
literal|5
operator|)
expr_stmt|;
if|if
condition|(
name|maxbcache
operator|&&
name|nbuf
operator|>
name|maxbcache
operator|/
name|BKVASIZE
condition|)
name|nbuf
operator|=
name|maxbcache
operator|/
name|BKVASIZE
expr_stmt|;
block|}
if|#
directive|if
literal|0
comment|/* 	 * Do not allow the buffer_map to be more then 1/2 the size of the 	 * kernel_map. 	 */
block|if (nbuf> (kernel_map->max_offset - kernel_map->min_offset) /  	    (BKVASIZE * 2)) { 		nbuf = (kernel_map->max_offset - kernel_map->min_offset) /  		    (BKVASIZE * 2); 		printf("Warning: nbufs capped at %d\n", nbuf); 	}
endif|#
directive|endif
comment|/* 	 * swbufs are used as temporary holders for I/O, such as paging I/O. 	 * We have no less then 16 and no more then 256. 	 */
name|nswbuf
operator|=
name|max
argument_list|(
name|min
argument_list|(
name|nbuf
operator|/
literal|4
argument_list|,
literal|256
argument_list|)
argument_list|,
literal|16
argument_list|)
expr_stmt|;
comment|/* 	 * Reserve space for the buffer cache buffers 	 */
name|swbuf
operator|=
operator|(
name|void
operator|*
operator|)
name|v
expr_stmt|;
name|v
operator|=
call|(
name|caddr_t
call|)
argument_list|(
name|swbuf
operator|+
name|nswbuf
argument_list|)
expr_stmt|;
name|buf
operator|=
operator|(
name|void
operator|*
operator|)
name|v
expr_stmt|;
name|v
operator|=
call|(
name|caddr_t
call|)
argument_list|(
name|buf
operator|+
name|nbuf
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|USE_BUFHASH
comment|/* 	 * Calculate the hash table size and reserve space 	 */
for|for
control|(
name|bufhashmask
operator|=
literal|8
init|;
name|bufhashmask
operator|<
name|nbuf
operator|/
literal|4
condition|;
name|bufhashmask
operator|<<=
literal|1
control|)
empty_stmt|;
name|bufhashtbl
operator|=
operator|(
name|void
operator|*
operator|)
name|v
expr_stmt|;
name|v
operator|=
call|(
name|caddr_t
call|)
argument_list|(
name|bufhashtbl
operator|+
name|bufhashmask
argument_list|)
expr_stmt|;
operator|--
name|bufhashmask
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
name|v
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Initialize the buffer subsystem.  Called before use of any buffers. */
end_comment

begin_function
name|void
name|bufinit
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|vm_offset_t
name|bogus_offset
decl_stmt|;
name|int
name|i
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
ifdef|#
directive|ifdef
name|USE_BUFHASH
name|LIST_INIT
argument_list|(
operator|&
name|invalhash
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|mtx_init
argument_list|(
operator|&
name|buftimelock
argument_list|,
literal|"buftime lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|USE_BUFHASH
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|bufhashmask
condition|;
name|i
operator|++
control|)
name|LIST_INIT
argument_list|(
operator|&
name|bufhashtbl
index|[
name|i
index|]
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* next, make a null set of free lists */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|BUFFER_QUEUES
condition|;
name|i
operator|++
control|)
name|TAILQ_INIT
argument_list|(
operator|&
name|bufqueues
index|[
name|i
index|]
argument_list|)
expr_stmt|;
comment|/* finally, initialize each buffer header and stick on empty q */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nbuf
condition|;
name|i
operator|++
control|)
block|{
name|bp
operator|=
operator|&
name|buf
index|[
name|i
index|]
expr_stmt|;
name|bzero
argument_list|(
name|bp
argument_list|,
sizeof|sizeof
expr|*
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|=
name|B_INVAL
expr_stmt|;
comment|/* we're just an empty header */
name|bp
operator|->
name|b_dev
operator|=
name|NODEV
expr_stmt|;
name|bp
operator|->
name|b_rcred
operator|=
name|NOCRED
expr_stmt|;
name|bp
operator|->
name|b_wcred
operator|=
name|NOCRED
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|bp
operator|->
name|b_xflags
operator|=
literal|0
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
expr_stmt|;
name|BUF_LOCKINIT
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTY
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|USE_BUFHASH
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|invalhash
argument_list|,
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
comment|/* 	 * maxbufspace is the absolute maximum amount of buffer space we are  	 * allowed to reserve in KVM and in real terms.  The absolute maximum 	 * is nominally used by buf_daemon.  hibufspace is the nominal maximum 	 * used by most other processes.  The differential is required to  	 * ensure that buf_daemon is able to run when other processes might  	 * be blocked waiting for buffer space. 	 * 	 * maxbufspace is based on BKVASIZE.  Allocating buffers larger then 	 * this may result in KVM fragmentation which is not handled optimally 	 * by the system. 	 */
name|maxbufspace
operator|=
name|nbuf
operator|*
name|BKVASIZE
expr_stmt|;
name|hibufspace
operator|=
name|imax
argument_list|(
literal|3
operator|*
name|maxbufspace
operator|/
literal|4
argument_list|,
name|maxbufspace
operator|-
name|MAXBSIZE
operator|*
literal|10
argument_list|)
expr_stmt|;
name|lobufspace
operator|=
name|hibufspace
operator|-
name|MAXBSIZE
expr_stmt|;
name|lorunningspace
operator|=
literal|512
operator|*
literal|1024
expr_stmt|;
name|hirunningspace
operator|=
literal|1024
operator|*
literal|1024
expr_stmt|;
comment|/*  * Limit the amount of malloc memory since it is wired permanently into  * the kernel space.  Even though this is accounted for in the buffer  * allocation, we don't want the malloced region to grow uncontrolled.  * The malloc scheme improves memory utilization significantly on average  * (small) directories.  */
name|maxbufmallocspace
operator|=
name|hibufspace
operator|/
literal|20
expr_stmt|;
comment|/*  * Reduce the chance of a deadlock occuring by limiting the number  * of delayed-write dirty buffers we allow to stack up.  */
name|hidirtybuffers
operator|=
name|nbuf
operator|/
literal|4
operator|+
literal|20
expr_stmt|;
name|numdirtybuffers
operator|=
literal|0
expr_stmt|;
comment|/*  * To support extreme low-memory systems, make sure hidirtybuffers cannot  * eat up all available buffer space.  This occurs when our minimum cannot  * be met.  We try to size hidirtybuffers to 3/4 our buffer space assuming  * BKVASIZE'd (8K) buffers.  */
while|while
condition|(
name|hidirtybuffers
operator|*
name|BKVASIZE
operator|>
literal|3
operator|*
name|hibufspace
operator|/
literal|4
condition|)
block|{
name|hidirtybuffers
operator|>>=
literal|1
expr_stmt|;
block|}
name|lodirtybuffers
operator|=
name|hidirtybuffers
operator|/
literal|2
expr_stmt|;
comment|/*  * Try to keep the number of free buffers in the specified range,  * and give special processes (e.g. like buf_daemon) access to an   * emergency reserve.  */
name|lofreebuffers
operator|=
name|nbuf
operator|/
literal|18
operator|+
literal|5
expr_stmt|;
name|hifreebuffers
operator|=
literal|2
operator|*
name|lofreebuffers
expr_stmt|;
name|numfreebuffers
operator|=
name|nbuf
expr_stmt|;
comment|/*  * Maximum number of async ops initiated per buf_daemon loop.  This is  * somewhat of a hack at the moment, we really need to limit ourselves  * based on the number of bytes of I/O in-transit that were initiated  * from buf_daemon.  */
name|bogus_offset
operator|=
name|kmem_alloc_pageable
argument_list|(
name|kernel_map
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|vm_object_lock
argument_list|(
name|kernel_object
argument_list|)
expr_stmt|;
name|bogus_page
operator|=
name|vm_page_alloc
argument_list|(
name|kernel_object
argument_list|,
operator|(
operator|(
name|bogus_offset
operator|-
name|VM_MIN_KERNEL_ADDRESS
operator|)
operator|>>
name|PAGE_SHIFT
operator|)
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_WIRED
argument_list|)
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|kernel_object
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * bfreekva() - free the kva allocation for a buffer.  *  *	Must be called at splbio() or higher as this is the only locking for  *	buffer_map.  *  *	Since this call frees up buffer space, we call bufspacewakeup().  */
end_comment

begin_function
specifier|static
name|void
name|bfreekva
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|GIANT_REQUIRED
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_kvasize
condition|)
block|{
operator|++
name|buffreekvacnt
expr_stmt|;
name|bufspace
operator|-=
name|bp
operator|->
name|b_kvasize
expr_stmt|;
name|vm_map_delete
argument_list|(
name|buffer_map
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_kvabase
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_kvabase
operator|+
name|bp
operator|->
name|b_kvasize
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_kvasize
operator|=
literal|0
expr_stmt|;
name|bufspacewakeup
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	bremfree:  *  *	Remove the buffer from the appropriate free list.  */
end_comment

begin_function
name|void
name|bremfree
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|s
init|=
name|splbio
argument_list|()
decl_stmt|;
name|int
name|old_qindex
init|=
name|bp
operator|->
name|b_qindex
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
condition|)
block|{
name|KASSERT
argument_list|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|==
literal|1
argument_list|,
operator|(
literal|"bremfree: bp %p not locked"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_NONE
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|<=
literal|1
condition|)
name|panic
argument_list|(
literal|"bremfree: removing a buffer not on a queue"
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Fixup numfreebuffers count.  If the buffer is invalid or not 	 * delayed-write, and it was on the EMPTY, LRU, or AGE queues, 	 * the buffer was free and we must decrement numfreebuffers. 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
condition|)
block|{
switch|switch
condition|(
name|old_qindex
condition|)
block|{
case|case
name|QUEUE_DIRTY
case|:
case|case
name|QUEUE_CLEAN
case|:
case|case
name|QUEUE_EMPTY
case|:
case|case
name|QUEUE_EMPTYKVA
case|:
operator|--
name|numfreebuffers
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Get a buffer with the specified data.  Look in the cache first.  We  * must clear BIO_ERROR and B_INVAL prior to initiating I/O.  If B_CACHE  * is set, the buffer is valid and we do not have to do anything ( see  * getblk() ).  This is really just a special case of breadn().  */
end_comment

begin_function
name|int
name|bread
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|struct
name|ucred
modifier|*
name|cred
parameter_list|,
name|struct
name|buf
modifier|*
modifier|*
name|bpp
parameter_list|)
block|{
return|return
operator|(
name|breadn
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|,
name|size
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|cred
argument_list|,
name|bpp
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Operates like bread, but also starts asynchronous I/O on  * read-ahead blocks.  We must clear BIO_ERROR and B_INVAL prior  * to initiating I/O . If B_CACHE is set, the buffer is valid   * and we do not have to do anything.  */
end_comment

begin_function
name|int
name|breadn
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|daddr_t
modifier|*
name|rablkno
parameter_list|,
name|int
modifier|*
name|rabsize
parameter_list|,
name|int
name|cnt
parameter_list|,
name|struct
name|ucred
modifier|*
name|cred
parameter_list|,
name|struct
name|buf
modifier|*
modifier|*
name|bpp
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|,
modifier|*
name|rabp
decl_stmt|;
name|int
name|i
decl_stmt|;
name|int
name|rv
init|=
literal|0
decl_stmt|,
name|readwait
init|=
literal|0
decl_stmt|;
operator|*
name|bpp
operator|=
name|bp
operator|=
name|getblk
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|,
name|size
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* if not found in cache, do some I/O */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|curthread
operator|!=
name|PCPU_GET
argument_list|(
name|idlethread
argument_list|)
condition|)
name|curthread
operator|->
name|td_proc
operator|->
name|p_stats
operator|->
name|p_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
name|bp
operator|->
name|b_iocmd
operator|=
name|BIO_READ
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INVAL
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_rcred
operator|==
name|NOCRED
operator|&&
name|cred
operator|!=
name|NOCRED
condition|)
name|bp
operator|->
name|b_rcred
operator|=
name|crhold
argument_list|(
name|cred
argument_list|)
expr_stmt|;
name|vfs_busy_pages
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|vp
operator|->
name|v_type
operator|==
name|VCHR
condition|)
name|VOP_SPECSTRATEGY
argument_list|(
name|vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
else|else
name|VOP_STRATEGY
argument_list|(
name|vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
operator|++
name|readwait
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|cnt
condition|;
name|i
operator|++
operator|,
name|rablkno
operator|++
operator|,
name|rabsize
operator|++
control|)
block|{
if|if
condition|(
name|inmem
argument_list|(
name|vp
argument_list|,
operator|*
name|rablkno
argument_list|)
condition|)
continue|continue;
name|rabp
operator|=
name|getblk
argument_list|(
name|vp
argument_list|,
operator|*
name|rablkno
argument_list|,
operator|*
name|rabsize
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|rabp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|curthread
operator|!=
name|PCPU_GET
argument_list|(
name|idlethread
argument_list|)
condition|)
name|curthread
operator|->
name|td_proc
operator|->
name|p_stats
operator|->
name|p_ru
operator|.
name|ru_inblock
operator|++
expr_stmt|;
name|rabp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
name|rabp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INVAL
expr_stmt|;
name|rabp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|rabp
operator|->
name|b_iocmd
operator|=
name|BIO_READ
expr_stmt|;
if|if
condition|(
name|rabp
operator|->
name|b_rcred
operator|==
name|NOCRED
operator|&&
name|cred
operator|!=
name|NOCRED
condition|)
name|rabp
operator|->
name|b_rcred
operator|=
name|crhold
argument_list|(
name|cred
argument_list|)
expr_stmt|;
name|vfs_busy_pages
argument_list|(
name|rabp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|BUF_KERNPROC
argument_list|(
name|rabp
argument_list|)
expr_stmt|;
if|if
condition|(
name|vp
operator|->
name|v_type
operator|==
name|VCHR
condition|)
name|VOP_SPECSTRATEGY
argument_list|(
name|vp
argument_list|,
name|rabp
argument_list|)
expr_stmt|;
else|else
name|VOP_STRATEGY
argument_list|(
name|vp
argument_list|,
name|rabp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|brelse
argument_list|(
name|rabp
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|readwait
condition|)
block|{
name|rv
operator|=
name|bufwait
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Write, release buffer on completion.  (Done by iodone  * if async).  Do not bother writing anything if the buffer  * is invalid.  *  * Note that we set B_CACHE here, indicating that buffer is  * fully valid and thus cacheable.  This is true even of NFS  * now so we set it generally.  This could be set either here   * or in biodone() since the I/O is synchronous.  We put it  * here.  */
end_comment

begin_function
name|int
name|bwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|oldflags
decl_stmt|,
name|s
decl_stmt|;
name|struct
name|buf
modifier|*
name|newbp
decl_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|oldflags
operator|=
name|bp
operator|->
name|b_flags
expr_stmt|;
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"bwrite: buffer is not busy???"
argument_list|)
expr_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
comment|/* 	 * If a background write is already in progress, delay 	 * writing this block if it is asynchronous. Otherwise 	 * wait for the background write to complete. 	 */
if|if
condition|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDINPROG
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ASYNC
condition|)
block|{
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|bdwrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|bp
operator|->
name|b_xflags
operator||=
name|BX_BKGRDWAIT
expr_stmt|;
name|tsleep
argument_list|(
operator|&
name|bp
operator|->
name|b_xflags
argument_list|,
name|PRIBIO
argument_list|,
literal|"bwrbg"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDINPROG
condition|)
name|panic
argument_list|(
literal|"bwrite: still writing"
argument_list|)
expr_stmt|;
block|}
comment|/* Mark the buffer clean */
name|bundirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * If this buffer is marked for background writing and we 	 * do not have to wait for it, make a copy and write the 	 * copy so as to leave this buffer ready for further use. 	 * 	 * This optimization eats a lot of memory.  If we have a page 	 * or buffer shortfall we can't do it. 	 */
if|if
condition|(
name|dobkgrdwrite
operator|&&
operator|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDWRITE
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ASYNC
operator|)
operator|&&
operator|!
name|vm_page_count_severe
argument_list|()
operator|&&
operator|!
name|buf_dirty_count_severe
argument_list|()
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_iodone
operator|!=
name|NULL
condition|)
block|{
name|printf
argument_list|(
literal|"bp->b_iodone = %p\n"
argument_list|,
name|bp
operator|->
name|b_iodone
argument_list|)
expr_stmt|;
name|panic
argument_list|(
literal|"bwrite: need chained iodone"
argument_list|)
expr_stmt|;
block|}
comment|/* get a new block */
name|newbp
operator|=
name|geteblk
argument_list|(
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
comment|/* 		 * set it to be identical to the old block.  We have to 		 * set b_lblkno and BKGRDMARKER before calling bgetvp() 		 * to avoid confusing the splay tree and gbincore(). 		 */
name|memcpy
argument_list|(
name|newbp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
name|newbp
operator|->
name|b_lblkno
operator|=
name|bp
operator|->
name|b_lblkno
expr_stmt|;
name|newbp
operator|->
name|b_xflags
operator||=
name|BX_BKGRDMARKER
expr_stmt|;
name|bgetvp
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|newbp
argument_list|)
expr_stmt|;
name|newbp
operator|->
name|b_blkno
operator|=
name|bp
operator|->
name|b_blkno
expr_stmt|;
name|newbp
operator|->
name|b_offset
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|newbp
operator|->
name|b_iodone
operator|=
name|vfs_backgroundwritedone
expr_stmt|;
name|newbp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
name|newbp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INVAL
expr_stmt|;
comment|/* move over the dependencies */
if|if
condition|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|!=
name|NULL
condition|)
name|buf_movedeps
argument_list|(
name|bp
argument_list|,
name|newbp
argument_list|)
expr_stmt|;
comment|/* 		 * Initiate write on the copy, release the original to 		 * the B_LOCKED queue so that it cannot go away until 		 * the background write completes. If not locked it could go 		 * away and then be reconstituted while it was being written. 		 * If the reconstituted buffer were written, we could end up 		 * with two background copies being written at the same time. 		 */
name|bp
operator|->
name|b_xflags
operator||=
name|BX_BKGRDINPROG
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_LOCKED
expr_stmt|;
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|=
name|newbp
expr_stmt|;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_WRITEINPROG
operator||
name|B_CACHE
expr_stmt|;
name|bp
operator|->
name|b_iocmd
operator|=
name|BIO_WRITE
expr_stmt|;
name|VI_LOCK
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_vp
operator|->
name|v_numoutput
operator|++
expr_stmt|;
name|VI_UNLOCK
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|)
expr_stmt|;
name|vfs_busy_pages
argument_list|(
name|bp
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * Normal bwrites pipeline writes 	 */
name|bp
operator|->
name|b_runningbufspace
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|runningbufspace
operator|+=
name|bp
operator|->
name|b_runningbufspace
expr_stmt|;
if|if
condition|(
name|curthread
operator|!=
name|PCPU_GET
argument_list|(
name|idlethread
argument_list|)
condition|)
name|curthread
operator|->
name|td_proc
operator|->
name|p_stats
operator|->
name|p_ru
operator|.
name|ru_oublock
operator|++
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldflags
operator|&
name|B_ASYNC
condition|)
name|BUF_KERNPROC
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
operator|->
name|v_type
operator|==
name|VCHR
condition|)
name|VOP_SPECSTRATEGY
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
else|else
name|VOP_STRATEGY
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|oldflags
operator|&
name|B_ASYNC
operator|)
operator|==
literal|0
condition|)
block|{
name|int
name|rtval
init|=
name|bufwait
argument_list|(
name|bp
argument_list|)
decl_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
name|rtval
operator|)
return|;
block|}
elseif|else
if|if
condition|(
operator|(
name|oldflags
operator|&
name|B_NOWDRAIN
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 		 * don't allow the async write to saturate the I/O 		 * system.  Deadlocks can occur only if a device strategy 		 * routine (like in MD) turns around and issues another 		 * high-level write, in which case B_NOWDRAIN is expected 		 * to be set.  Otherwise we will not deadlock here because 		 * we are blocking waiting for I/O that is already in-progress 		 * to complete. 		 */
name|waitrunningbufspace
argument_list|()
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Complete a background write started from bwrite.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_backgroundwritedone
parameter_list|(
name|bp
parameter_list|)
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
block|{
name|struct
name|buf
modifier|*
name|origbp
decl_stmt|;
comment|/* 	 * Find the original buffer that we are writing. 	 */
name|VI_LOCK
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|origbp
operator|=
name|gbincore
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_lblkno
argument_list|)
operator|)
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"backgroundwritedone: lost buffer"
argument_list|)
expr_stmt|;
name|VI_UNLOCK
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|)
expr_stmt|;
comment|/* 	 * Process dependencies then return any unfinished ones. 	 */
if|if
condition|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|!=
name|NULL
condition|)
name|buf_complete
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|!=
name|NULL
condition|)
name|buf_movedeps
argument_list|(
name|bp
argument_list|,
name|origbp
argument_list|)
expr_stmt|;
comment|/* 	 * Clear the BX_BKGRDINPROG flag in the original buffer 	 * and awaken it if it is waiting for the write to complete. 	 * If BX_BKGRDINPROG is not set in the original buffer it must 	 * have been released and re-instantiated - which is not legal. 	 */
name|KASSERT
argument_list|(
operator|(
name|origbp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDINPROG
operator|)
argument_list|,
operator|(
literal|"backgroundwritedone: lost buffer2"
operator|)
argument_list|)
expr_stmt|;
name|origbp
operator|->
name|b_xflags
operator|&=
operator|~
name|BX_BKGRDINPROG
expr_stmt|;
if|if
condition|(
name|origbp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDWAIT
condition|)
block|{
name|origbp
operator|->
name|b_xflags
operator|&=
operator|~
name|BX_BKGRDWAIT
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|origbp
operator|->
name|b_xflags
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Clear the B_LOCKED flag and remove it from the locked 	 * queue if it currently resides there. 	 */
name|origbp
operator|->
name|b_flags
operator|&=
operator|~
name|B_LOCKED
expr_stmt|;
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|origbp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|)
operator|==
literal|0
condition|)
block|{
name|bremfree
argument_list|(
name|origbp
argument_list|)
expr_stmt|;
name|bqrelse
argument_list|(
name|origbp
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * This buffer is marked B_NOCACHE, so when it is released 	 * by biodone, it will be tossed. We mark it with BIO_READ 	 * to avoid biodone doing a second vwakeup. 	 */
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|bp
operator|->
name|b_iocmd
operator|=
name|BIO_READ
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_CACHE
operator||
name|B_DONE
operator|)
expr_stmt|;
name|bp
operator|->
name|b_iodone
operator|=
literal|0
expr_stmt|;
name|bufdone
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Delayed write. (Buffer is marked dirty).  Do not bother writing  * anything if the buffer is marked invalid.  *  * Note that since the buffer must be completely valid, we can safely  * set B_CACHE.  In fact, we have to set B_CACHE here rather then in  * biodone() in order to prevent getblk from writing the buffer  * out synchronously.  */
end_comment

begin_function
name|void
name|bdwrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|GIANT_REQUIRED
expr_stmt|;
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"bdwrite: buffer is not busy"
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
name|bdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * Set B_CACHE, indicating that the buffer is fully valid.  This is 	 * true even of NFS now. 	 */
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
comment|/* 	 * This bmap keeps the system from needing to do the bmap later, 	 * perhaps when the system is attempting to do a sync.  Since it 	 * is likely that the indirect block -- or whatever other datastructure 	 * that the filesystem needs is still in memory now, it is a good 	 * thing to do this.  Note also, that if the pageout daemon is 	 * requesting a sync -- there might not be enough memory to do 	 * the bmap then...  So, this is important to do. 	 */
if|if
condition|(
name|bp
operator|->
name|b_vp
operator|->
name|v_type
operator|!=
name|VCHR
operator|&&
name|bp
operator|->
name|b_lblkno
operator|==
name|bp
operator|->
name|b_blkno
condition|)
block|{
name|VOP_BMAP
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|bp
operator|->
name|b_lblkno
argument_list|,
name|NULL
argument_list|,
operator|&
name|bp
operator|->
name|b_blkno
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Set the *dirty* buffer range based upon the VM system dirty pages. 	 */
name|vfs_setdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * We need to do this here to satisfy the vnode_pager and the 	 * pageout daemon, so that it thinks that the pages have been 	 * "cleaned".  Note that since the pages are in a delayed write 	 * buffer -- the VFS layer "will" see that the pages get written 	 * out on the next sync, or perhaps the cluster will be completed. 	 */
name|vfs_clean_pages
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 	 * Wakeup the buffer flushing daemon if we have a lot of dirty 	 * buffers (midpoint between our recovery point and our stall 	 * point). 	 */
name|bd_wakeup
argument_list|(
operator|(
name|lodirtybuffers
operator|+
name|hidirtybuffers
operator|)
operator|/
literal|2
argument_list|)
expr_stmt|;
comment|/* 	 * note: we cannot initiate I/O from a bdwrite even if we wanted to, 	 * due to the softdep code. 	 */
block|}
end_function

begin_comment
comment|/*  *	bdirty:  *  *	Turn buffer into delayed write request.  We must clear BIO_READ and  *	B_RELBUF, and we must set B_DELWRI.  We reassign the buffer to   *	itself to properly update it in the dirty/clean lists.  We mark it  *	B_DONE to ensure that any asynchronization of the buffer properly  *	clears B_DONE ( else a panic will occur later ).    *  *	bdirty() is kinda like bdwrite() - we have to clear B_INVAL which  *	might have been set pre-getblk().  Unlike bwrite/bdwrite, bdirty()  *	should only be called if the buffer is known-good.  *  *	Since the buffer is not on a queue, we do not update the numfreebuffers  *	count.  *  *	Must be called at splbio().  *	The buffer must be on QUEUE_NONE.  */
end_comment

begin_function
name|void
name|bdirty
parameter_list|(
name|bp
parameter_list|)
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
block|{
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bdirty: buffer %p still on queue %d"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_qindex
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_RELBUF
operator|)
expr_stmt|;
name|bp
operator|->
name|b_iocmd
operator|=
name|BIO_WRITE
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_DONE
operator||
name|B_DELWRI
expr_stmt|;
name|reassignbuf
argument_list|(
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|)
expr_stmt|;
operator|++
name|numdirtybuffers
expr_stmt|;
name|bd_wakeup
argument_list|(
operator|(
name|lodirtybuffers
operator|+
name|hidirtybuffers
operator|)
operator|/
literal|2
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	bundirty:  *  *	Clear B_DELWRI for buffer.  *  *	Since the buffer is not on a queue, we do not update the numfreebuffers  *	count.  *	  *	Must be called at splbio().  *	The buffer must be on QUEUE_NONE.  */
end_comment

begin_function
name|void
name|bundirty
parameter_list|(
name|bp
parameter_list|)
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
block|{
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|==
name|QUEUE_NONE
argument_list|,
operator|(
literal|"bundirty: buffer %p still on queue %d"
operator|,
name|bp
operator|,
name|bp
operator|->
name|b_qindex
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DELWRI
expr_stmt|;
name|reassignbuf
argument_list|(
name|bp
argument_list|,
name|bp
operator|->
name|b_vp
argument_list|)
expr_stmt|;
operator|--
name|numdirtybuffers
expr_stmt|;
name|numdirtywakeup
argument_list|(
name|lodirtybuffers
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Since it is now being written, we can clear its deferred write flag. 	 */
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DEFERRED
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bawrite:  *  *	Asynchronous write.  Start output on a buffer, but do not wait for  *	it to complete.  The buffer is released when the output completes.  *  *	bwrite() ( or the VOP routine anyway ) is responsible for handling   *	B_INVAL buffers.  Not us.  */
end_comment

begin_function
name|void
name|bawrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
operator|(
name|void
operator|)
name|BUF_WRITE
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bwillwrite:  *  *	Called prior to the locking of any vnodes when we are expecting to  *	write.  We do not want to starve the buffer cache with too many  *	dirty buffers so we block here.  By blocking prior to the locking  *	of any vnodes we attempt to avoid the situation where a locked vnode  *	prevents the various system daemons from flushing related buffers.  */
end_comment

begin_function
name|void
name|bwillwrite
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|numdirtybuffers
operator|>=
name|hidirtybuffers
condition|)
block|{
name|int
name|s
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|Giant
argument_list|)
expr_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
while|while
condition|(
name|numdirtybuffers
operator|>=
name|hidirtybuffers
condition|)
block|{
name|bd_wakeup
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|needsbuffer
operator||=
name|VFS_BIO_NEED_DIRTYFLUSH
expr_stmt|;
name|tsleep
argument_list|(
operator|&
name|needsbuffer
argument_list|,
operator|(
name|PRIBIO
operator|+
literal|4
operator|)
argument_list|,
literal|"flswai"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|Giant
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Return true if we have too many dirty buffers.  */
end_comment

begin_function
name|int
name|buf_dirty_count_severe
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
name|numdirtybuffers
operator|>=
name|hidirtybuffers
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	brelse:  *  *	Release a busy buffer and, if requested, free its resources.  The  *	buffer will be stashed in the appropriate bufqueue[] allowing it  *	to be accessed later as a cache entity or reused for other purposes.  */
end_comment

begin_function
name|void
name|brelse
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTER
operator||
name|B_PAGING
operator|)
operator|)
argument_list|,
operator|(
literal|"brelse: inappropriate B_PAGING or B_CLUSTER bp %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_LOCKED
condition|)
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_WRITE
operator|&&
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
condition|)
block|{
comment|/* 		 * Failed write, redirty.  Must clear BIO_ERROR to prevent 		 * pages from being scrapped.  If B_INVAL is set then 		 * this case is not run and the next case is run to  		 * destroy the buffer.  B_INVAL can occur if the buffer 		 * is outside the range supported by the underlying device. 		 */
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|bdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_NOCACHE
operator||
name|B_INVAL
operator|)
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
operator|||
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_DELETE
operator|||
operator|(
name|bp
operator|->
name|b_bufsize
operator|<=
literal|0
operator|)
condition|)
block|{
comment|/* 		 * Either a failed I/O or we were asked to free or not 		 * cache the buffer. 		 */
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
if|if
condition|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|!=
name|NULL
condition|)
name|buf_deallocate
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
operator|--
name|numdirtybuffers
expr_stmt|;
name|numdirtywakeup
argument_list|(
name|lodirtybuffers
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_DELWRI
operator||
name|B_CACHE
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
name|allocbuf
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * We must clear B_RELBUF if B_DELWRI is set.  If vfs_vmio_release()  	 * is called with B_DELWRI set, the underlying pages may wind up 	 * getting freed causing a previous write (bdwrite()) to get 'lost' 	 * because pages associated with a B_DELWRI bp are marked clean. 	 *  	 * We still allow the B_INVAL case to call vfs_vmio_release(), even 	 * if B_DELWRI is set. 	 * 	 * If B_DELWRI is not set we may have to set B_RELBUF if we are low 	 * on pages to return pages to the VM page queues. 	 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_RELBUF
expr_stmt|;
elseif|else
if|if
condition|(
name|vm_page_count_severe
argument_list|()
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDINPROG
operator|)
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_RELBUF
expr_stmt|;
comment|/* 	 * VMIO buffer rundown.  It is not very necessary to keep a VMIO buffer 	 * constituted, not even NFS buffers now.  Two flags effect this.  If 	 * B_INVAL, the struct buf is invalidated but the VM object is kept 	 * around ( i.e. so it is trivial to reconstitute the buffer later ). 	 * 	 * If BIO_ERROR or B_NOCACHE is set, pages in the VM object will be 	 * invalidated.  BIO_ERROR cannot be set for a failed write unless the 	 * buffer is also B_INVAL because it hits the re-dirtying code above. 	 * 	 * Normally we can do this whether a buffer is B_DELWRI or not.  If 	 * the buffer is an NFS buffer, it is tracking piecemeal writes or 	 * the commit state and we cannot afford to lose the buffer. If the 	 * buffer has a background write in progress, we need to keep it 	 * around to prevent it from being reconstituted and starting a second 	 * background write. 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_vp
operator|->
name|v_mount
operator|!=
name|NULL
operator|&&
operator|(
name|bp
operator|->
name|b_vp
operator|->
name|v_mount
operator|->
name|mnt_vfc
operator|->
name|vfc_flags
operator|&
name|VFCF_NETWORK
operator|)
operator|!=
literal|0
operator|&&
operator|!
name|vn_isdisk
argument_list|(
name|bp
operator|->
name|b_vp
argument_list|,
name|NULL
argument_list|)
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|)
condition|)
block|{
name|int
name|i
decl_stmt|,
name|j
decl_stmt|,
name|resid
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|off_t
name|foff
decl_stmt|;
name|vm_pindex_t
name|poff
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
name|obj
operator|=
name|bp
operator|->
name|b_object
expr_stmt|;
comment|/* 		 * Get the base offset and length of the buffer.  Note that  		 * in the VMIO case if the buffer block size is not 		 * page-aligned then b_data pointer may not be page-aligned. 		 * But our b_pages[] array *IS* page aligned. 		 * 		 * block sizes less then DEV_BSIZE (usually 512) are not  		 * supported due to the page granularity bits (m->valid, 		 * m->dirty, etc...).  		 * 		 * See man buf(9) for more information 		 */
name|resid
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|int
name|had_bogus
init|=
literal|0
decl_stmt|;
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
comment|/* 			 * If we hit a bogus page, fixup *all* the bogus pages 			 * now. 			 */
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|poff
operator|=
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
expr_stmt|;
name|had_bogus
operator|=
literal|1
expr_stmt|;
for|for
control|(
name|j
operator|=
name|i
init|;
name|j
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|j
operator|++
control|)
block|{
name|vm_page_t
name|mtmp
decl_stmt|;
name|mtmp
operator|=
name|bp
operator|->
name|b_pages
index|[
name|j
index|]
expr_stmt|;
if|if
condition|(
name|mtmp
operator|==
name|bogus_page
condition|)
block|{
name|mtmp
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|poff
operator|+
name|j
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|mtmp
condition|)
block|{
name|panic
argument_list|(
literal|"brelse: page missing\n"
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_pages
index|[
name|j
index|]
operator|=
name|mtmp
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_NOCACHE
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
condition|)
block|{
name|int
name|poffset
init|=
name|foff
operator|&
name|PAGE_MASK
decl_stmt|;
name|int
name|presid
init|=
name|resid
operator|>
operator|(
name|PAGE_SIZE
operator|-
name|poffset
operator|)
condition|?
operator|(
name|PAGE_SIZE
operator|-
name|poffset
operator|)
else|:
name|resid
decl_stmt|;
name|KASSERT
argument_list|(
name|presid
operator|>=
literal|0
argument_list|,
operator|(
literal|"brelse: extra page"
operator|)
argument_list|)
expr_stmt|;
name|vm_page_set_invalid
argument_list|(
name|m
argument_list|,
name|poffset
argument_list|,
name|presid
argument_list|)
expr_stmt|;
if|if
condition|(
name|had_bogus
condition|)
name|printf
argument_list|(
literal|"avoided corruption bug in bogus_page/brelse code\n"
argument_list|)
expr_stmt|;
block|}
name|resid
operator|-=
name|PAGE_SIZE
operator|-
operator|(
name|foff
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|foff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_RELBUF
operator|)
condition|)
name|vfs_vmio_release
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_RELBUF
operator|)
condition|)
block|{
name|vfs_vmio_release
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
condition|)
name|panic
argument_list|(
literal|"brelse: free buffer onto another queue???"
argument_list|)
expr_stmt|;
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|>
literal|1
condition|)
block|{
comment|/* do not release to free list */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* enqueue */
comment|/* buffers with no memory */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|bp
operator|->
name|b_xflags
operator|&=
operator|~
operator|(
name|BX_BKGRDWRITE
operator||
name|BX_ALTDATA
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDINPROG
condition|)
name|panic
argument_list|(
literal|"losing buffer 1"
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_kvasize
condition|)
block|{
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_EMPTYKVA
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
block|}
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|USE_BUFHASH
name|LIST_REMOVE
argument_list|(
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|invalhash
argument_list|,
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|bp
operator|->
name|b_dev
operator|=
name|NODEV
expr_stmt|;
comment|/* buffers with junk contents */
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_NOCACHE
operator||
name|B_RELBUF
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|bp
operator|->
name|b_xflags
operator|&=
operator|~
operator|(
name|BX_BKGRDWRITE
operator||
name|BX_ALTDATA
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDINPROG
condition|)
name|panic
argument_list|(
literal|"losing buffer 2"
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|USE_BUFHASH
name|LIST_REMOVE
argument_list|(
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|invalhash
argument_list|,
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|bp
operator|->
name|b_dev
operator|=
name|NODEV
expr_stmt|;
comment|/* buffers that are locked */
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_LOCKED
condition|)
block|{
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_LOCKED
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_LOCKED
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
comment|/* remaining buffers */
block|}
else|else
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_DIRTY
expr_stmt|;
else|else
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_AGE
condition|)
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|bp
operator|->
name|b_qindex
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If B_INVAL and B_DELWRI is set, clear B_DELWRI.  We have already 	 * placed the buffer on the correct queue.  We must also disassociate 	 * the device and vnode for a B_INVAL buffer so gbincore() doesn't 	 * find it. 	 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
name|bundirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Fixup numfreebuffers count.  The bp is on an appropriate queue 	 * unless locked.  We then bump numfreebuffers if it is not B_DELWRI. 	 * We've already handled the B_INVAL case ( B_DELWRI will be clear 	 * if B_INVAL is set ). 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_LOCKED
operator|)
operator|==
literal|0
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
condition|)
name|bufcountwakeup
argument_list|()
expr_stmt|;
comment|/* 	 * Something we can maybe free or reuse 	 */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|||
name|bp
operator|->
name|b_kvasize
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
comment|/* unlock */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ASYNC
operator||
name|B_NOCACHE
operator||
name|B_AGE
operator||
name|B_RELBUF
operator||
name|B_DIRECT
operator||
name|B_NOWDRAIN
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
operator|&&
operator|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_VNDIRTY
operator|)
condition|)
name|panic
argument_list|(
literal|"brelse: not dirty"
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Release a buffer back to the appropriate queue but do not try to free  * it.  The buffer is expected to be used again soon.  *  * bqrelse() is used by bdwrite() to requeue a delayed write, and used by  * biodone() to requeue an async I/O on completion.  It is also used when  * known good buffers need to be requeued but we think we may need the data  * again soon.  *  * XXX we should be able to leave the B_RELBUF hint set on completion.  */
end_comment

begin_function
name|void
name|bqrelse
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTER
operator||
name|B_PAGING
operator|)
operator|)
argument_list|,
operator|(
literal|"bqrelse: inappropriate B_PAGING or B_CLUSTER bp %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_qindex
operator|!=
name|QUEUE_NONE
condition|)
name|panic
argument_list|(
literal|"bqrelse: free buffer onto another queue???"
argument_list|)
expr_stmt|;
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|>
literal|1
condition|)
block|{
comment|/* do not release to free list */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_LOCKED
condition|)
block|{
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_LOCKED
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_LOCKED
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
comment|/* buffers with stale but valid contents */
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_DIRTY
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_DIRTY
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|vm_page_count_severe
argument_list|()
condition|)
block|{
comment|/* 		 * We are too low on memory, we have to try to free the 		 * buffer (most importantly: the wired pages making up its 		 * backing store) *now*. 		 */
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return;
block|}
else|else
block|{
name|bp
operator|->
name|b_qindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|,
name|bp
argument_list|,
name|b_freelist
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_LOCKED
operator|)
operator|==
literal|0
operator|&&
operator|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|||
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|)
condition|)
block|{
name|bufcountwakeup
argument_list|()
expr_stmt|;
block|}
comment|/* 	 * Something we can maybe free or reuse. 	 */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
comment|/* unlock */
name|BUF_UNLOCK
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
operator|(
name|B_ASYNC
operator||
name|B_NOCACHE
operator||
name|B_AGE
operator||
name|B_RELBUF
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
operator|&&
operator|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_VNDIRTY
operator|)
condition|)
name|panic
argument_list|(
literal|"bqrelse: not dirty"
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Give pages used by the bp back to the VM system (where possible) */
end_comment

begin_function
specifier|static
name|void
name|vfs_vmio_release
parameter_list|(
name|bp
parameter_list|)
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
block|{
name|int
name|i
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|NULL
expr_stmt|;
comment|/* 		 * In order to keep page LRU ordering consistent, put 		 * everything on the inactive queue. 		 */
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 		 * We don't mess with busy pages, it is 		 * the responsibility of the process that 		 * busied the pages to deal with them. 		 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_BUSY
operator|)
operator|||
operator|(
name|m
operator|->
name|busy
operator|!=
literal|0
operator|)
condition|)
continue|continue;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
comment|/* 			 * Might as well free the page if we can and it has 			 * no valid data.  We also free the page if the 			 * buffer was used for direct I/O 			 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ASYNC
operator|)
operator|==
literal|0
operator|&&
operator|!
name|m
operator|->
name|valid
operator|&&
name|m
operator|->
name|hold_count
operator|==
literal|0
condition|)
block|{
name|vm_page_busy
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DIRECT
condition|)
block|{
name|vm_page_try_to_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|vm_page_count_severe
argument_list|()
condition|)
block|{
name|vm_page_try_to_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|pmap_qremove
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
block|{
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
literal|0
expr_stmt|;
block|}
name|bp
operator|->
name|b_npages
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_VMIO
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|USE_BUFHASH
end_ifdef

begin_comment
comment|/*  * XXX MOVED TO VFS_SUBR.C  *  * Check to see if a block is currently memory resident.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|gbincore
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|struct
name|bufhashhdr
modifier|*
name|bh
decl_stmt|;
name|bh
operator|=
name|bufhash
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
expr_stmt|;
comment|/* Search hash chain */
name|LIST_FOREACH
argument_list|(
argument|bp
argument_list|,
argument|bh
argument_list|,
argument|b_hash
argument_list|)
block|{
comment|/* hit */
if|if
condition|(
name|bp
operator|->
name|b_vp
operator|==
name|vp
operator|&&
name|bp
operator|->
name|b_lblkno
operator|==
name|blkno
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
operator|)
operator|==
literal|0
condition|)
block|{
break|break;
block|}
block|}
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  *	vfs_bio_awrite:  *  *	Implement clustered async writes for clearing out B_DELWRI buffers.  *	This is much better then the old way of writing only one buffer at  *	a time.  Note that we may not be presented with the buffers in the   *	correct order, so we search for the cluster in both directions.  */
end_comment

begin_function
name|int
name|vfs_bio_awrite
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|int
name|j
decl_stmt|;
name|daddr_t
name|lblkno
init|=
name|bp
operator|->
name|b_lblkno
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
init|=
name|bp
operator|->
name|b_vp
decl_stmt|;
name|int
name|s
decl_stmt|;
name|int
name|ncl
decl_stmt|;
name|struct
name|buf
modifier|*
name|bpa
decl_stmt|;
name|int
name|nwritten
decl_stmt|;
name|int
name|size
decl_stmt|;
name|int
name|maxcl
decl_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
comment|/* 	 * right now we support clustered writing only to regular files.  If 	 * we find a clusterable block we could be in the middle of a cluster 	 * rather then at the beginning. 	 */
if|if
condition|(
operator|(
name|vp
operator|->
name|v_type
operator|==
name|VREG
operator|)
operator|&&
operator|(
name|vp
operator|->
name|v_mount
operator|!=
literal|0
operator|)
operator|&&
comment|/* Only on nodes that have the size info */
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CLUSTEROK
operator||
name|B_INVAL
operator|)
operator|)
operator|==
name|B_CLUSTEROK
condition|)
block|{
name|size
operator|=
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
name|maxcl
operator|=
name|MAXPHYS
operator|/
name|size
expr_stmt|;
name|VI_LOCK
argument_list|(
name|vp
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|maxcl
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|bpa
operator|=
name|gbincore
argument_list|(
name|vp
argument_list|,
name|lblkno
operator|+
name|i
argument_list|)
operator|)
operator|&&
name|BUF_REFCNT
argument_list|(
name|bpa
argument_list|)
operator|==
literal|0
operator|&&
operator|(
operator|(
name|bpa
operator|->
name|b_flags
operator|&
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator||
name|B_INVAL
operator|)
operator|)
operator|==
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator|)
operator|)
operator|&&
operator|(
name|bpa
operator|->
name|b_bufsize
operator|==
name|size
operator|)
condition|)
block|{
if|if
condition|(
operator|(
name|bpa
operator|->
name|b_blkno
operator|==
name|bpa
operator|->
name|b_lblkno
operator|)
operator|||
operator|(
name|bpa
operator|->
name|b_blkno
operator|!=
name|bp
operator|->
name|b_blkno
operator|+
operator|(
operator|(
name|i
operator|*
name|size
operator|)
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
condition|)
break|break;
block|}
else|else
block|{
break|break;
block|}
block|}
for|for
control|(
name|j
operator|=
literal|1
init|;
name|i
operator|+
name|j
operator|<=
name|maxcl
operator|&&
name|j
operator|<=
name|lblkno
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|bpa
operator|=
name|gbincore
argument_list|(
name|vp
argument_list|,
name|lblkno
operator|-
name|j
argument_list|)
operator|)
operator|&&
name|BUF_REFCNT
argument_list|(
name|bpa
argument_list|)
operator|==
literal|0
operator|&&
operator|(
operator|(
name|bpa
operator|->
name|b_flags
operator|&
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator||
name|B_INVAL
operator|)
operator|)
operator|==
operator|(
name|B_DELWRI
operator||
name|B_CLUSTEROK
operator|)
operator|)
operator|&&
operator|(
name|bpa
operator|->
name|b_bufsize
operator|==
name|size
operator|)
condition|)
block|{
if|if
condition|(
operator|(
name|bpa
operator|->
name|b_blkno
operator|==
name|bpa
operator|->
name|b_lblkno
operator|)
operator|||
operator|(
name|bpa
operator|->
name|b_blkno
operator|!=
name|bp
operator|->
name|b_blkno
operator|-
operator|(
operator|(
name|j
operator|*
name|size
operator|)
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
condition|)
break|break;
block|}
else|else
block|{
break|break;
block|}
block|}
name|VI_UNLOCK
argument_list|(
name|vp
argument_list|)
expr_stmt|;
operator|--
name|j
expr_stmt|;
name|ncl
operator|=
name|i
operator|+
name|j
expr_stmt|;
comment|/* 		 * this is a possible cluster write 		 */
if|if
condition|(
name|ncl
operator|!=
literal|1
condition|)
block|{
name|nwritten
operator|=
name|cluster_wbuild
argument_list|(
name|vp
argument_list|,
name|size
argument_list|,
name|lblkno
operator|-
name|j
argument_list|,
name|ncl
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
name|nwritten
return|;
block|}
block|}
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
argument_list|)
expr_stmt|;
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_ASYNC
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
comment|/* 	 * default (old) behavior, writing out only one block 	 * 	 * XXX returns b_bufsize instead of b_bcount for nwritten? 	 */
name|nwritten
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
operator|(
name|void
operator|)
name|BUF_WRITE
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
name|nwritten
return|;
block|}
end_function

begin_comment
comment|/*  *	getnewbuf:  *  *	Find and initialize a new buffer header, freeing up existing buffers   *	in the bufqueues as necessary.  The new buffer is returned locked.  *  *	Important:  B_INVAL is not set.  If the caller wishes to throw the  *	buffer away, the caller must set B_INVAL prior to calling brelse().  *  *	We block if:  *		We have insufficient buffer headers  *		We have insufficient buffer space  *		buffer_map is too fragmented ( space reservation fails )  *		If we have to flush dirty buffers ( but we try to avoid this )  *  *	To avoid VFS layer recursion we do not flush dirty buffers ourselves.  *	Instead we ask the buf daemon to do it for us.  We attempt to  *	avoid piecemeal wakeups of the pageout daemon.  */
end_comment

begin_function
specifier|static
name|struct
name|buf
modifier|*
name|getnewbuf
parameter_list|(
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|,
name|int
name|size
parameter_list|,
name|int
name|maxsize
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|struct
name|buf
modifier|*
name|nbp
decl_stmt|;
name|int
name|defrag
init|=
literal|0
decl_stmt|;
name|int
name|nqindex
decl_stmt|;
specifier|static
name|int
name|flushingbufs
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
comment|/* 	 * We can't afford to block since we might be holding a vnode lock, 	 * which may prevent system daemons from running.  We deal with 	 * low-memory situations by proactively returning memory and running 	 * async I/O rather then sync I/O. 	 */
operator|++
name|getnewbufcalls
expr_stmt|;
operator|--
name|getnewbufrestarts
expr_stmt|;
name|restart
label|:
operator|++
name|getnewbufrestarts
expr_stmt|;
comment|/* 	 * Setup for scan.  If we do not have enough free buffers, 	 * we setup a degenerate case that immediately fails.  Note 	 * that if we are specially marked process, we are allowed to 	 * dip into our reserves. 	 * 	 * The scanning sequence is nominally:  EMPTY->EMPTYKVA->CLEAN 	 * 	 * We start with EMPTYKVA.  If the list is empty we backup to EMPTY. 	 * However, there are a number of cases (defragging, reusing, ...) 	 * where we cannot backup. 	 */
name|nqindex
operator|=
name|QUEUE_EMPTYKVA
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTYKVA
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|nbp
operator|==
name|NULL
condition|)
block|{
comment|/* 		 * If no EMPTYKVA buffers and we are either 		 * defragging or reusing, locate a CLEAN buffer 		 * to free or reuse.  If bufspace useage is low 		 * skip this step so we can allocate a new buffer. 		 */
if|if
condition|(
name|defrag
operator|||
name|bufspace
operator|>=
name|lobufspace
condition|)
block|{
name|nqindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * If we could not find or were not allowed to reuse a 		 * CLEAN buffer, check to see if it is ok to use an EMPTY 		 * buffer.  We can only use an EMPTY buffer if allocating 		 * its KVA would not otherwise run us out of buffer space. 		 */
if|if
condition|(
name|nbp
operator|==
name|NULL
operator|&&
name|defrag
operator|==
literal|0
operator|&&
name|bufspace
operator|+
name|maxsize
operator|<
name|hibufspace
condition|)
block|{
name|nqindex
operator|=
name|QUEUE_EMPTY
expr_stmt|;
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTY
index|]
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * Run scan, possibly freeing data and/or kva mappings on the fly 	 * depending. 	 */
while|while
condition|(
operator|(
name|bp
operator|=
name|nbp
operator|)
operator|!=
name|NULL
condition|)
block|{
name|int
name|qindex
init|=
name|nqindex
decl_stmt|;
comment|/* 		 * Calculate next bp ( we can only use it if we do not block 		 * or do other fancy things ). 		 */
if|if
condition|(
operator|(
name|nbp
operator|=
name|TAILQ_NEXT
argument_list|(
name|bp
argument_list|,
name|b_freelist
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
switch|switch
condition|(
name|qindex
condition|)
block|{
case|case
name|QUEUE_EMPTY
case|:
name|nqindex
operator|=
name|QUEUE_EMPTYKVA
expr_stmt|;
if|if
condition|(
operator|(
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_EMPTYKVA
index|]
argument_list|)
operator|)
condition|)
break|break;
comment|/* FALLTHROUGH */
case|case
name|QUEUE_EMPTYKVA
case|:
name|nqindex
operator|=
name|QUEUE_CLEAN
expr_stmt|;
if|if
condition|(
operator|(
name|nbp
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|bufqueues
index|[
name|QUEUE_CLEAN
index|]
argument_list|)
operator|)
condition|)
break|break;
comment|/* FALLTHROUGH */
case|case
name|QUEUE_CLEAN
case|:
comment|/* 				 * nbp is NULL.  				 */
break|break;
block|}
block|}
comment|/* 		 * Sanity Checks 		 */
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_qindex
operator|==
name|qindex
argument_list|,
operator|(
literal|"getnewbuf: inconsistant queue %d bp %p"
operator|,
name|qindex
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Note: we no longer distinguish between VMIO and non-VMIO 		 * buffers. 		 */
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"delwri buffer %p found in queue %d"
operator|,
name|bp
operator|,
name|qindex
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * If we are defragging then we need a buffer with  		 * b_kvasize != 0.  XXX this situation should no longer 		 * occur, if defrag is non-zero the buffer's b_kvasize 		 * should also be non-zero at this point.  XXX 		 */
if|if
condition|(
name|defrag
operator|&&
name|bp
operator|->
name|b_kvasize
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"Warning: defrag empty buffer %p\n"
argument_list|,
name|bp
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Start freeing the bp.  This is somewhat involved.  nbp 		 * remains valid only for QUEUE_EMPTY[KVA] bp's. 		 */
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"getnewbuf: locked buf"
argument_list|)
expr_stmt|;
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|qindex
operator|==
name|QUEUE_CLEAN
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_ASYNC
expr_stmt|;
name|vfs_vmio_release
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_vp
condition|)
name|brelvp
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * NOTE:  nbp is now entirely invalid.  We can only restart 		 * the scan from this point on. 		 * 		 * Get the rest of the buffer freed up.  b_kva* is still 		 * valid after this operation. 		 */
if|if
condition|(
name|bp
operator|->
name|b_rcred
operator|!=
name|NOCRED
condition|)
block|{
name|crfree
argument_list|(
name|bp
operator|->
name|b_rcred
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_rcred
operator|=
name|NOCRED
expr_stmt|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_wcred
operator|!=
name|NOCRED
condition|)
block|{
name|crfree
argument_list|(
name|bp
operator|->
name|b_wcred
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_wcred
operator|=
name|NOCRED
expr_stmt|;
block|}
if|if
condition|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|!=
name|NULL
condition|)
name|buf_deallocate
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDINPROG
condition|)
name|panic
argument_list|(
literal|"losing buffer 3"
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|USE_BUFHASH
name|LIST_REMOVE
argument_list|(
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|invalhash
argument_list|,
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
name|allocbuf
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_xflags
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_dev
operator|=
name|NODEV
expr_stmt|;
name|bp
operator|->
name|b_vp
operator|=
name|NULL
expr_stmt|;
name|bp
operator|->
name|b_blkno
operator|=
name|bp
operator|->
name|b_lblkno
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_offset
operator|=
name|NOOFFSET
expr_stmt|;
name|bp
operator|->
name|b_iodone
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_error
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_bcount
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_npages
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_dirtyoff
operator|=
name|bp
operator|->
name|b_dirtyend
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_magic
operator|=
name|B_MAGIC_BIO
expr_stmt|;
name|bp
operator|->
name|b_op
operator|=
operator|&
name|buf_ops_bio
expr_stmt|;
name|bp
operator|->
name|b_object
operator|=
name|NULL
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
expr_stmt|;
comment|/* 		 * If we are defragging then free the buffer. 		 */
if|if
condition|(
name|defrag
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|defrag
operator|=
literal|0
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
comment|/* 		 * If we are overcomitted then recover the buffer and its 		 * KVM space.  This occurs in rare situations when multiple 		 * processes are blocked in getnewbuf() or allocbuf(). 		 */
if|if
condition|(
name|bufspace
operator|>=
name|hibufspace
condition|)
name|flushingbufs
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|flushingbufs
operator|&&
name|bp
operator|->
name|b_kvasize
operator|!=
literal|0
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
if|if
condition|(
name|bufspace
operator|<
name|lobufspace
condition|)
name|flushingbufs
operator|=
literal|0
expr_stmt|;
break|break;
block|}
comment|/* 	 * If we exhausted our list, sleep as appropriate.  We may have to 	 * wakeup various daemons and write out some dirty buffers. 	 * 	 * Generally we are sleeping due to insufficient buffer space. 	 */
if|if
condition|(
name|bp
operator|==
name|NULL
condition|)
block|{
name|int
name|flags
decl_stmt|;
name|char
modifier|*
name|waitmsg
decl_stmt|;
if|if
condition|(
name|defrag
condition|)
block|{
name|flags
operator|=
name|VFS_BIO_NEED_BUFSPACE
expr_stmt|;
name|waitmsg
operator|=
literal|"nbufkv"
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bufspace
operator|>=
name|hibufspace
condition|)
block|{
name|waitmsg
operator|=
literal|"nbufbs"
expr_stmt|;
name|flags
operator|=
name|VFS_BIO_NEED_BUFSPACE
expr_stmt|;
block|}
else|else
block|{
name|waitmsg
operator|=
literal|"newbuf"
expr_stmt|;
name|flags
operator|=
name|VFS_BIO_NEED_ANY
expr_stmt|;
block|}
name|bd_speedup
argument_list|()
expr_stmt|;
comment|/* heeeelp */
name|needsbuffer
operator||=
name|flags
expr_stmt|;
while|while
condition|(
name|needsbuffer
operator|&
name|flags
condition|)
block|{
if|if
condition|(
name|tsleep
argument_list|(
operator|&
name|needsbuffer
argument_list|,
operator|(
name|PRIBIO
operator|+
literal|4
operator|)
operator||
name|slpflag
argument_list|,
name|waitmsg
argument_list|,
name|slptimeo
argument_list|)
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
block|}
block|}
else|else
block|{
comment|/* 		 * We finally have a valid bp.  We aren't quite out of the 		 * woods, we still have to reserve kva space.  In order 		 * to keep fragmentation sane we only allocate kva in 		 * BKVASIZE chunks. 		 */
name|maxsize
operator|=
operator|(
name|maxsize
operator|+
name|BKVAMASK
operator|)
operator|&
operator|~
name|BKVAMASK
expr_stmt|;
if|if
condition|(
name|maxsize
operator|!=
name|bp
operator|->
name|b_kvasize
condition|)
block|{
name|vm_offset_t
name|addr
init|=
literal|0
decl_stmt|;
name|bfreekva
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_map_findspace
argument_list|(
name|buffer_map
argument_list|,
name|vm_map_min
argument_list|(
name|buffer_map
argument_list|)
argument_list|,
name|maxsize
argument_list|,
operator|&
name|addr
argument_list|)
condition|)
block|{
comment|/* 				 * Uh oh.  Buffer map is to fragmented.  We 				 * must defragment the map. 				 */
operator|++
name|bufdefragcnt
expr_stmt|;
name|defrag
operator|=
literal|1
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
if|if
condition|(
name|addr
condition|)
block|{
name|vm_map_insert
argument_list|(
name|buffer_map
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
name|addr
argument_list|,
name|addr
operator|+
name|maxsize
argument_list|,
name|VM_PROT_ALL
argument_list|,
name|VM_PROT_ALL
argument_list|,
name|MAP_NOFAULT
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_kvabase
operator|=
operator|(
name|caddr_t
operator|)
name|addr
expr_stmt|;
name|bp
operator|->
name|b_kvasize
operator|=
name|maxsize
expr_stmt|;
name|bufspace
operator|+=
name|bp
operator|->
name|b_kvasize
expr_stmt|;
operator|++
name|bufreusecnt
expr_stmt|;
block|}
block|}
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
block|}
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	buf_daemon:  *  *	buffer flushing daemon.  Buffers are normally flushed by the  *	update daemon but if it cannot keep up this process starts to  *	take the load in an attempt to prevent getnewbuf() from blocking.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|proc
modifier|*
name|bufdaemonproc
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|kproc_desc
name|buf_kp
init|=
block|{
literal|"bufdaemon"
block|,
name|buf_daemon
block|,
operator|&
name|bufdaemonproc
block|}
decl_stmt|;
end_decl_stmt

begin_macro
name|SYSINIT
argument_list|(
argument|bufdaemon
argument_list|,
argument|SI_SUB_KTHREAD_BUF
argument_list|,
argument|SI_ORDER_FIRST
argument_list|,
argument|kproc_start
argument_list|,
argument|&buf_kp
argument_list|)
end_macro

begin_function
specifier|static
name|void
name|buf_daemon
parameter_list|()
block|{
name|int
name|s
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|Giant
argument_list|)
expr_stmt|;
comment|/* 	 * This process needs to be suspended prior to shutdown sync. 	 */
name|EVENTHANDLER_REGISTER
argument_list|(
name|shutdown_pre_sync
argument_list|,
name|kproc_shutdown
argument_list|,
name|bufdaemonproc
argument_list|,
name|SHUTDOWN_PRI_LAST
argument_list|)
expr_stmt|;
comment|/* 	 * This process is allowed to take the buffer cache to the limit 	 */
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|kthread_suspend_check
argument_list|(
name|bufdaemonproc
argument_list|)
expr_stmt|;
name|bd_request
operator|=
literal|0
expr_stmt|;
comment|/* 		 * Do the flush.  Limit the amount of in-transit I/O we 		 * allow to build up, otherwise we would completely saturate 		 * the I/O system.  Wakeup any waiting processes before we 		 * normally would so they can run in parallel with our drain. 		 */
while|while
condition|(
name|numdirtybuffers
operator|>
name|lodirtybuffers
condition|)
block|{
if|if
condition|(
name|flushbufqueues
argument_list|()
operator|==
literal|0
condition|)
break|break;
name|waitrunningbufspace
argument_list|()
expr_stmt|;
name|numdirtywakeup
argument_list|(
operator|(
name|lodirtybuffers
operator|+
name|hidirtybuffers
operator|)
operator|/
literal|2
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Only clear bd_request if we have reached our low water 		 * mark.  The buf_daemon normally waits 1 second and 		 * then incrementally flushes any dirty buffers that have 		 * built up, within reason. 		 * 		 * If we were unable to hit our low water mark and couldn't 		 * find any flushable buffers, we sleep half a second. 		 * Otherwise we loop immediately. 		 */
if|if
condition|(
name|numdirtybuffers
operator|<=
name|lodirtybuffers
condition|)
block|{
comment|/* 			 * We reached our low water mark, reset the 			 * request and sleep until we are needed again. 			 * The sleep is just so the suspend code works. 			 */
name|bd_request
operator|=
literal|0
expr_stmt|;
name|tsleep
argument_list|(
operator|&
name|bd_request
argument_list|,
name|PVM
argument_list|,
literal|"psleep"
argument_list|,
name|hz
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * We couldn't find any flushable dirty buffers but 			 * still have too many dirty buffers, we 			 * have to sleep and try again.  (rare) 			 */
name|tsleep
argument_list|(
operator|&
name|bd_request
argument_list|,
name|PVM
argument_list|,
literal|"qsleep"
argument_list|,
name|hz
operator|/
literal|10
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	flushbufqueues:  *  *	Try to flush a buffer in the dirty queue.  We must be careful to  *	free up B_INVAL buffers instead of write them, which NFS is   *	particularly sensitive to.  */
end_comment

begin_decl_stmt
name|int
name|flushwithdeps
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vfs
argument_list|,
name|OID_AUTO
argument_list|,
name|flushwithdeps
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|flushwithdeps
argument_list|,
literal|0
argument_list|,
literal|"Number of buffers flushed with dependecies that require rollbacks"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|flushbufqueues
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
init|=
name|curthread
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|bp
argument_list|,
argument|&bufqueues[QUEUE_DIRTY]
argument_list|,
argument|b_freelist
argument_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
argument_list|,
operator|(
literal|"unexpected clean buffer %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDINPROG
operator|)
operator|!=
literal|0
condition|)
continue|continue;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"flushbufqueues: locked buf"
argument_list|)
expr_stmt|;
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
if|if
condition|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|!=
name|NULL
operator|&&
name|buf_countdeps
argument_list|(
name|bp
argument_list|,
literal|0
argument_list|)
condition|)
continue|continue;
comment|/* 		 * We must hold the lock on a vnode before writing 		 * one of its buffers. Otherwise we may confuse, or 		 * in the case of a snapshot vnode, deadlock the 		 * system. 		 */
if|if
condition|(
operator|(
name|vp
operator|=
name|bp
operator|->
name|b_vp
operator|)
operator|==
name|NULL
operator|||
name|vn_lock
argument_list|(
name|vp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|td
argument_list|)
operator|==
literal|0
condition|)
block|{
name|vfs_bio_awrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|vp
operator|!=
name|NULL
condition|)
name|VOP_UNLOCK
argument_list|(
name|vp
argument_list|,
literal|0
argument_list|,
name|td
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
block|}
comment|/* 	 * Could not find any buffers without rollback dependencies, 	 * so just write the first one in the hopes of eventually 	 * making progress. 	 */
name|TAILQ_FOREACH
argument_list|(
argument|bp
argument_list|,
argument|&bufqueues[QUEUE_DIRTY]
argument_list|,
argument|b_freelist
argument_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
operator|)
argument_list|,
operator|(
literal|"unexpected clean buffer %p"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_xflags
operator|&
name|BX_BKGRDINPROG
operator|)
operator|!=
literal|0
condition|)
continue|continue;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
block|{
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"flushbufqueues: locked buf"
argument_list|)
expr_stmt|;
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
comment|/* 		 * We must hold the lock on a vnode before writing 		 * one of its buffers. Otherwise we may confuse, or 		 * in the case of a snapshot vnode, deadlock the 		 * system. 		 */
if|if
condition|(
operator|(
name|vp
operator|=
name|bp
operator|->
name|b_vp
operator|)
operator|==
name|NULL
operator|||
name|vn_lock
argument_list|(
name|vp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|,
name|td
argument_list|)
operator|==
literal|0
condition|)
block|{
name|vfs_bio_awrite
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|vp
operator|!=
name|NULL
condition|)
name|VOP_UNLOCK
argument_list|(
name|vp
argument_list|,
literal|0
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|flushwithdeps
operator|+=
literal|1
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Check to see if a block is currently memory resident.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|incore
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|s
init|=
name|splbio
argument_list|()
decl_stmt|;
name|VI_LOCK
argument_list|(
name|vp
argument_list|)
expr_stmt|;
name|bp
operator|=
name|gbincore
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
expr_stmt|;
name|VI_UNLOCK
argument_list|(
name|vp
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns true if no I/O is needed to access the  * associated VM object.  This is like incore except  * it also hunts around in the VM system for the data.  */
end_comment

begin_function
name|int
name|inmem
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_offset_t
name|toff
decl_stmt|,
name|tinc
decl_stmt|,
name|size
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_ooffset_t
name|off
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
name|ASSERT_VOP_LOCKED
argument_list|(
name|vp
argument_list|,
literal|"inmem"
argument_list|)
expr_stmt|;
if|if
condition|(
name|incore
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
condition|)
return|return
literal|1
return|;
if|if
condition|(
name|vp
operator|->
name|v_mount
operator|==
name|NULL
condition|)
return|return
literal|0
return|;
if|if
condition|(
name|VOP_GETVOBJECT
argument_list|(
name|vp
argument_list|,
operator|&
name|obj
argument_list|)
operator|!=
literal|0
operator|||
operator|(
name|vp
operator|->
name|v_vflag
operator|&
name|VV_OBJBUF
operator|)
operator|==
literal|0
condition|)
return|return
literal|0
return|;
name|size
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
name|size
operator|>
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
condition|)
name|size
operator|=
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
name|off
operator|=
operator|(
name|vm_ooffset_t
operator|)
name|blkno
operator|*
operator|(
name|vm_ooffset_t
operator|)
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
for|for
control|(
name|toff
operator|=
literal|0
init|;
name|toff
operator|<
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
condition|;
name|toff
operator|+=
name|tinc
control|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|off
operator|+
name|toff
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|m
condition|)
goto|goto
name|notinmem
goto|;
name|tinc
operator|=
name|size
expr_stmt|;
if|if
condition|(
name|tinc
operator|>
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
operator|)
condition|)
name|tinc
operator|=
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
if|if
condition|(
name|vm_page_is_valid
argument_list|(
name|m
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
operator|(
name|toff
operator|+
name|off
operator|)
operator|&
name|PAGE_MASK
argument_list|)
argument_list|,
name|tinc
argument_list|)
operator|==
literal|0
condition|)
goto|goto
name|notinmem
goto|;
block|}
return|return
literal|1
return|;
name|notinmem
label|:
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vfs_setdirty:  *  *	Sets the dirty range for a buffer based on the status of the dirty  *	bits in the pages comprising the buffer.  *  *	The range is limited to the size of the buffer.  *  *	This routine is primarily used by NFS, but is generalized for the  *	B_VMIO case.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_setdirty
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
comment|/* 	 * Degenerate case - empty buffer 	 */
if|if
condition|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
return|return;
comment|/* 	 * We qualify the scan for modified pages on whether the 	 * object has been flushed yet.  The OBJ_WRITEABLE flag 	 * is not cleared simply by protecting pages off. 	 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
condition|)
return|return;
name|object
operator|=
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|object
expr_stmt|;
if|if
condition|(
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_WRITEABLE
operator|)
operator|&&
operator|!
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_MIGHTBEDIRTY
operator|)
condition|)
name|printf
argument_list|(
literal|"Warning: object %p writeable but not mightbedirty\n"
argument_list|,
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_WRITEABLE
operator|)
operator|&&
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_MIGHTBEDIRTY
operator|)
condition|)
name|printf
argument_list|(
literal|"Warning: object %p mightbedirty but not writeable\n"
argument_list|,
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|flags
operator|&
operator|(
name|OBJ_MIGHTBEDIRTY
operator||
name|OBJ_CLEANING
operator|)
condition|)
block|{
name|vm_offset_t
name|boffset
decl_stmt|;
name|vm_offset_t
name|eoffset
decl_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
comment|/* 		 * test the pages to see if they have been modified directly 		 * by users through the VM system. 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_flag_clear
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|vm_page_test_dirty
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Calculate the encompassing dirty range, boffset and eoffset, 		 * (eoffset - boffset) bytes. 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|dirty
condition|)
break|break;
block|}
name|boffset
operator|=
operator|(
name|i
operator|<<
name|PAGE_SHIFT
operator|)
operator|-
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|bp
operator|->
name|b_npages
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
operator|--
name|i
control|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|dirty
condition|)
block|{
break|break;
block|}
block|}
name|eoffset
operator|=
operator|(
operator|(
name|i
operator|+
literal|1
operator|)
operator|<<
name|PAGE_SHIFT
operator|)
operator|-
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
comment|/* 		 * Fit it to the buffer. 		 */
if|if
condition|(
name|eoffset
operator|>
name|bp
operator|->
name|b_bcount
condition|)
name|eoffset
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* 		 * If we have a good dirty range, merge with the existing 		 * dirty range. 		 */
if|if
condition|(
name|boffset
operator|<
name|eoffset
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_dirtyoff
operator|>
name|boffset
condition|)
name|bp
operator|->
name|b_dirtyoff
operator|=
name|boffset
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_dirtyend
operator|<
name|eoffset
condition|)
name|bp
operator|->
name|b_dirtyend
operator|=
name|eoffset
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	getblk:  *  *	Get a block given a specified block and offset into a file/device.  *	The buffers B_DONE bit will be cleared on return, making it almost  * 	ready for an I/O initiation.  B_INVAL may or may not be set on   *	return.  The caller should clear B_INVAL prior to initiating a  *	READ.  *  *	For a non-VMIO buffer, B_CACHE is set to the opposite of B_INVAL for  *	an existing buffer.  *  *	For a VMIO buffer, B_CACHE is modified according to the backing VM.  *	If getblk()ing a previously 0-sized invalid buffer, B_CACHE is set  *	and then cleared based on the backing VM.  If the previous buffer is  *	non-0-sized but invalid, B_CACHE will be cleared.  *  *	If getblk() must create a new buffer, the new buffer is returned with  *	both B_INVAL and B_CACHE clear unless it is a VMIO buffer, in which  *	case it is returned with B_INVAL clear and B_CACHE set based on the  *	backing VM.  *  *	getblk() also forces a BUF_WRITE() for any B_DELWRI buffer whos  *	B_CACHE bit is clear.  *	  *	What this means, basically, is that the caller should use B_CACHE to  *	determine whether the buffer is fully valid or not and should clear  *	B_INVAL prior to issuing a read.  If the caller intends to validate  *	the buffer by loading its data area with something, the caller needs  *	to clear B_INVAL.  If the caller does this without issuing an I/O,   *	the caller should set B_CACHE ( as an optimization ), else the caller  *	should issue the I/O and biodone() will set B_CACHE if the I/O was  *	a write attempt or if it was a successfull read.  If the caller   *	intends to issue a READ, the caller must clear B_INVAL and BIO_ERROR  *	prior to issuing the READ.  biodone() will *not* clear B_INVAL.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|getblk
parameter_list|(
name|struct
name|vnode
modifier|*
name|vp
parameter_list|,
name|daddr_t
name|blkno
parameter_list|,
name|int
name|size
parameter_list|,
name|int
name|slpflag
parameter_list|,
name|int
name|slptimeo
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|s
decl_stmt|;
ifdef|#
directive|ifdef
name|USE_BUFHASH
name|struct
name|bufhashhdr
modifier|*
name|bh
decl_stmt|;
endif|#
directive|endif
name|ASSERT_VOP_LOCKED
argument_list|(
name|vp
argument_list|,
literal|"getblk"
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|>
name|MAXBSIZE
condition|)
name|panic
argument_list|(
literal|"getblk: size(%d)> MAXBSIZE(%d)\n"
argument_list|,
name|size
argument_list|,
name|MAXBSIZE
argument_list|)
expr_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
name|loop
label|:
comment|/* 	 * Block if we are low on buffers.   Certain processes are allowed 	 * to completely exhaust the buffer cache.          *          * If this check ever becomes a bottleneck it may be better to          * move it into the else, when gbincore() fails.  At the moment          * it isn't a problem. 	 * 	 * XXX remove if 0 sections (clean this up after its proven)          */
if|if
condition|(
name|numfreebuffers
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|curthread
operator|==
name|PCPU_GET
argument_list|(
name|idlethread
argument_list|)
condition|)
return|return
name|NULL
return|;
name|needsbuffer
operator||=
name|VFS_BIO_NEED_ANY
expr_stmt|;
block|}
name|VI_LOCK
argument_list|(
name|vp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|=
name|gbincore
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
operator|)
condition|)
block|{
name|VI_UNLOCK
argument_list|(
name|vp
argument_list|)
expr_stmt|;
comment|/* 		 * Buffer is in-core.  If the buffer is not busy, it must 		 * be on a queue. 		 */
if|if
condition|(
name|BUF_LOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_NOWAIT
argument_list|)
condition|)
block|{
if|if
condition|(
name|BUF_TIMELOCK
argument_list|(
name|bp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_SLEEPFAIL
argument_list|,
literal|"getblk"
argument_list|,
name|slpflag
argument_list|,
name|slptimeo
argument_list|)
operator|==
name|ENOLCK
condition|)
goto|goto
name|loop
goto|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
operator|(
expr|struct
name|buf
operator|*
operator|)
name|NULL
return|;
block|}
comment|/* 		 * The buffer is locked.  B_CACHE is cleared if the buffer is  		 * invalid.  Otherwise, for a non-VMIO buffer, B_CACHE is set 		 * and for a VMIO buffer B_CACHE is adjusted according to the 		 * backing VM cache. 		 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_INVAL
condition|)
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_VMIO
operator||
name|B_INVAL
operator|)
operator|)
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
name|bremfree
argument_list|(
name|bp
argument_list|)
expr_stmt|;
comment|/* 		 * check for size inconsistancies for non-VMIO case. 		 */
if|if
condition|(
name|bp
operator|->
name|b_bcount
operator|!=
name|size
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
operator|||
operator|(
name|size
operator|>
name|bp
operator|->
name|b_kvasize
operator|)
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|BUF_WRITE
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|&&
operator|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|==
name|NULL
operator|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_RELBUF
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|BUF_WRITE
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
goto|goto
name|loop
goto|;
block|}
block|}
comment|/* 		 * If the size is inconsistant in the VMIO case, we can resize 		 * the buffer.  This might lead to B_CACHE getting set or 		 * cleared.  If the size has not changed, B_CACHE remains 		 * unchanged from its previous state. 		 */
if|if
condition|(
name|bp
operator|->
name|b_bcount
operator|!=
name|size
condition|)
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"getblk: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * A buffer with B_DELWRI set and B_CACHE clear must 		 * be committed before we can return the buffer in 		 * order to prevent the caller from issuing a read 		 * ( due to B_CACHE not being set ) and overwriting 		 * it. 		 * 		 * Most callers, including NFS and FFS, need this to 		 * operate properly either because they assume they 		 * can issue a read if B_CACHE is not set, or because 		 * ( for example ) an uncached B_DELWRI might loop due  		 * to softupdates re-dirtying the buffer.  In the latter 		 * case, B_CACHE is set after the first write completes, 		 * preventing further loops. 		 * NOTE!  b*write() sets B_CACHE.  If we cleared B_CACHE 		 * above while extending the buffer, we cannot allow the 		 * buffer to remain with B_CACHE set after the write 		 * completes or it will represent a corrupt state.  To 		 * deal with this we set B_NOCACHE to scrap the buffer 		 * after the write. 		 * 		 * We might be able to do something fancy, like setting 		 * B_CACHE in bwrite() except if B_DELWRI is already set, 		 * so the below call doesn't set B_CACHE, but that gets real 		 * confusing.  This is much easier. 		 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_CACHE
operator||
name|B_DELWRI
operator|)
operator|)
operator|==
name|B_DELWRI
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_NOCACHE
expr_stmt|;
name|BUF_WRITE
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
block|}
else|else
block|{
name|int
name|bsize
decl_stmt|,
name|maxsize
decl_stmt|,
name|vmio
decl_stmt|;
name|off_t
name|offset
decl_stmt|;
comment|/* 		 * Buffer is not in-core, create new buffer.  The buffer 		 * returned by getnewbuf() is locked.  Note that the returned 		 * buffer is also considered valid (not marked B_INVAL). 		 */
name|VI_UNLOCK
argument_list|(
name|vp
argument_list|)
expr_stmt|;
if|if
condition|(
name|vn_isdisk
argument_list|(
name|vp
argument_list|,
name|NULL
argument_list|)
condition|)
name|bsize
operator|=
name|DEV_BSIZE
expr_stmt|;
elseif|else
if|if
condition|(
name|vp
operator|->
name|v_mountedhere
condition|)
name|bsize
operator|=
name|vp
operator|->
name|v_mountedhere
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
elseif|else
if|if
condition|(
name|vp
operator|->
name|v_mount
condition|)
name|bsize
operator|=
name|vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
expr_stmt|;
else|else
name|bsize
operator|=
name|size
expr_stmt|;
name|offset
operator|=
name|blkno
operator|*
name|bsize
expr_stmt|;
name|vmio
operator|=
operator|(
name|VOP_GETVOBJECT
argument_list|(
name|vp
argument_list|,
name|NULL
argument_list|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|vp
operator|->
name|v_vflag
operator|&
name|VV_OBJBUF
operator|)
expr_stmt|;
name|maxsize
operator|=
name|vmio
condition|?
name|size
operator|+
operator|(
name|offset
operator|&
name|PAGE_MASK
operator|)
else|:
name|size
expr_stmt|;
name|maxsize
operator|=
name|imax
argument_list|(
name|maxsize
argument_list|,
name|bsize
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|=
name|getnewbuf
argument_list|(
name|slpflag
argument_list|,
name|slptimeo
argument_list|,
name|size
argument_list|,
name|maxsize
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|slpflag
operator|||
name|slptimeo
condition|)
block|{
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
name|NULL
return|;
block|}
goto|goto
name|loop
goto|;
block|}
comment|/* 		 * This code is used to make sure that a buffer is not 		 * created while the getnewbuf routine is blocked. 		 * This can be a problem whether the vnode is locked or not. 		 * If the buffer is created out from under us, we have to 		 * throw away the one we just created.  There is now window 		 * race because we are safely running at splbio() from the 		 * point of the duplicate buffer creation through to here, 		 * and we've locked the buffer. 		 * 		 * Note: this must occur before we associate the buffer 		 * with the vp especially considering limitations in 		 * the splay tree implementation when dealing with duplicate 		 * lblkno's. 		 */
name|VI_LOCK
argument_list|(
name|vp
argument_list|)
expr_stmt|;
if|if
condition|(
name|gbincore
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
condition|)
block|{
name|VI_UNLOCK
argument_list|(
name|vp
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
name|VI_UNLOCK
argument_list|(
name|vp
argument_list|)
expr_stmt|;
comment|/* 		 * Insert the buffer into the hash, so that it can 		 * be found by incore. 		 */
name|bp
operator|->
name|b_blkno
operator|=
name|bp
operator|->
name|b_lblkno
operator|=
name|blkno
expr_stmt|;
name|bp
operator|->
name|b_offset
operator|=
name|offset
expr_stmt|;
name|bgetvp
argument_list|(
name|vp
argument_list|,
name|bp
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|USE_BUFHASH
name|LIST_REMOVE
argument_list|(
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
name|bh
operator|=
name|bufhash
argument_list|(
name|vp
argument_list|,
name|blkno
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
name|bh
argument_list|,
name|bp
argument_list|,
name|b_hash
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 		 * set B_VMIO bit.  allocbuf() the buffer bigger.  Since the 		 * buffer size starts out as 0, B_CACHE will be set by 		 * allocbuf() for the VMIO case prior to it testing the 		 * backing store for validity. 		 */
if|if
condition|(
name|vmio
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_VMIO
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|VFS_BIO_DEBUG
argument_list|)
if|if
condition|(
name|vp
operator|->
name|v_type
operator|!=
name|VREG
condition|)
name|printf
argument_list|(
literal|"getblk: vmioing file type %d???\n"
argument_list|,
name|vp
operator|->
name|v_type
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|VOP_GETVOBJECT
argument_list|(
name|vp
argument_list|,
operator|&
name|bp
operator|->
name|b_object
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_VMIO
expr_stmt|;
name|bp
operator|->
name|b_object
operator|=
name|NULL
expr_stmt|;
block|}
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_DONE
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|==
literal|1
argument_list|,
operator|(
literal|"getblk: bp %p not locked"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Get an empty, disassociated buffer of given size.  The buffer is initially  * set to B_INVAL.  */
end_comment

begin_function
name|struct
name|buf
modifier|*
name|geteblk
parameter_list|(
name|int
name|size
parameter_list|)
block|{
name|struct
name|buf
modifier|*
name|bp
decl_stmt|;
name|int
name|s
decl_stmt|;
name|int
name|maxsize
decl_stmt|;
name|maxsize
operator|=
operator|(
name|size
operator|+
name|BKVAMASK
operator|)
operator|&
operator|~
name|BKVAMASK
expr_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|=
name|getnewbuf
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
name|size
argument_list|,
name|maxsize
argument_list|)
operator|)
operator|==
literal|0
condition|)
continue|continue;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|allocbuf
argument_list|(
name|bp
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_INVAL
expr_stmt|;
comment|/* b_dep cleared by getnewbuf() */
name|KASSERT
argument_list|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|==
literal|1
argument_list|,
operator|(
literal|"geteblk: bp %p not locked"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|bp
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This code constitutes the buffer memory from either anonymous system  * memory (in the case of non-VMIO operations) or from an associated  * VM object (in the case of VMIO operations).  This code is able to  * resize a buffer up or down.  *  * Note that this code is tricky, and has many complications to resolve  * deadlock or inconsistant data situations.  Tread lightly!!!   * There are B_CACHE and B_DELWRI interactions that must be dealt with by   * the caller.  Calling this code willy nilly can result in the loss of data.  *  * allocbuf() only adjusts B_CACHE for VMIO buffers.  getblk() deals with  * B_CACHE for the non-VMIO case.  */
end_comment

begin_function
name|int
name|allocbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|newbsize
decl_stmt|,
name|mbsize
decl_stmt|;
name|int
name|i
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
if|if
condition|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"allocbuf: buffer not busy"
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_kvasize
operator|<
name|size
condition|)
name|panic
argument_list|(
literal|"allocbuf: buffer too small"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
operator|)
operator|==
literal|0
condition|)
block|{
name|caddr_t
name|origbuf
decl_stmt|;
name|int
name|origbufsize
decl_stmt|;
comment|/* 		 * Just get anonymous memory from the kernel.  Don't 		 * mess with B_CACHE. 		 */
name|mbsize
operator|=
operator|(
name|size
operator|+
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
name|newbsize
operator|=
name|mbsize
expr_stmt|;
else|else
name|newbsize
operator|=
name|round_page
argument_list|(
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
block|{
comment|/* 			 * malloced buffers are not shrunk 			 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
block|{
if|if
condition|(
name|newbsize
condition|)
block|{
name|bp
operator|->
name|b_bcount
operator|=
name|size
expr_stmt|;
block|}
else|else
block|{
name|free
argument_list|(
name|bp
operator|->
name|b_data
argument_list|,
name|M_BIOBUF
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
block|{
name|bufmallocspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
literal|0
expr_stmt|;
block|}
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
name|bp
operator|->
name|b_bcount
operator|=
literal|0
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_MALLOC
expr_stmt|;
block|}
return|return
literal|1
return|;
block|}
name|vm_hold_free_pages
argument_list|(
name|bp
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|newbsize
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|newbsize
operator|>
name|bp
operator|->
name|b_bufsize
condition|)
block|{
comment|/* 			 * We only use malloced memory on the first allocation. 			 * and revert to page-allocated memory when the buffer 			 * grows. 			 */
if|if
condition|(
operator|(
name|bufmallocspace
operator|<
name|maxbufmallocspace
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
operator|)
operator|&&
operator|(
name|mbsize
operator|<=
name|PAGE_SIZE
operator|/
literal|2
operator|)
condition|)
block|{
name|bp
operator|->
name|b_data
operator|=
name|malloc
argument_list|(
name|mbsize
argument_list|,
name|M_BIOBUF
argument_list|,
name|M_WAITOK
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
name|mbsize
expr_stmt|;
name|bp
operator|->
name|b_bcount
operator|=
name|size
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_MALLOC
expr_stmt|;
name|bufmallocspace
operator|+=
name|mbsize
expr_stmt|;
return|return
literal|1
return|;
block|}
name|origbuf
operator|=
name|NULL
expr_stmt|;
name|origbufsize
operator|=
literal|0
expr_stmt|;
comment|/* 			 * If the buffer is growing on its other-than-first allocation, 			 * then we revert to the page-allocation scheme. 			 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
block|{
name|origbuf
operator|=
name|bp
operator|->
name|b_data
expr_stmt|;
name|origbufsize
operator|=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
name|bp
operator|->
name|b_kvabase
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_bufsize
condition|)
block|{
name|bufmallocspace
operator|-=
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
literal|0
expr_stmt|;
block|}
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_MALLOC
expr_stmt|;
name|newbsize
operator|=
name|round_page
argument_list|(
name|newbsize
argument_list|)
expr_stmt|;
block|}
name|vm_hold_load_pages
argument_list|(
name|bp
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|bp
operator|->
name|b_bufsize
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|newbsize
argument_list|)
expr_stmt|;
if|if
condition|(
name|origbuf
condition|)
block|{
name|bcopy
argument_list|(
name|origbuf
argument_list|,
name|bp
operator|->
name|b_data
argument_list|,
name|origbufsize
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|origbuf
argument_list|,
name|M_BIOBUF
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|int
name|desiredpages
decl_stmt|;
name|newbsize
operator|=
operator|(
name|size
operator|+
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
expr_stmt|;
name|desiredpages
operator|=
operator|(
name|size
operator|==
literal|0
operator|)
condition|?
literal|0
else|:
name|num_pages
argument_list|(
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|+
name|newbsize
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_MALLOC
condition|)
name|panic
argument_list|(
literal|"allocbuf: VMIO buffer can't be malloced"
argument_list|)
expr_stmt|;
comment|/* 		 * Set B_CACHE initially if buffer is 0 length or will become 		 * 0-length. 		 */
if|if
condition|(
name|size
operator|==
literal|0
operator|||
name|bp
operator|->
name|b_bufsize
operator|==
literal|0
condition|)
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
block|{
comment|/* 			 * DEV_BSIZE aligned new buffer size is less then the 			 * DEV_BSIZE aligned existing buffer size.  Figure out 			 * if we have to remove any pages. 			 */
if|if
condition|(
name|desiredpages
operator|<
name|bp
operator|->
name|b_npages
condition|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
name|desiredpages
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
comment|/* 					 * the page is not freed here -- it 					 * is the responsibility of  					 * vnode_pager_setsize 					 */
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|!=
name|bogus_page
argument_list|,
operator|(
literal|"allocbuf: bogus page found"
operator|)
argument_list|)
expr_stmt|;
while|while
condition|(
name|vm_page_sleep_if_busy
argument_list|(
name|m
argument_list|,
name|TRUE
argument_list|,
literal|"biodep"
argument_list|)
condition|)
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|NULL
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|pmap_qremove
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|+
operator|(
name|desiredpages
operator|<<
name|PAGE_SHIFT
operator|)
argument_list|,
operator|(
name|bp
operator|->
name|b_npages
operator|-
name|desiredpages
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_npages
operator|=
name|desiredpages
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|size
operator|>
name|bp
operator|->
name|b_bcount
condition|)
block|{
comment|/* 			 * We are growing the buffer, possibly in a  			 * byte-granular fashion. 			 */
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|vm_offset_t
name|toff
decl_stmt|;
name|vm_offset_t
name|tinc
decl_stmt|;
comment|/* 			 * Step 1, bring in the VM pages from the object,  			 * allocating them if necessary.  We must clear 			 * B_CACHE if these pages are not valid for the  			 * range covered by the buffer. 			 */
name|vp
operator|=
name|bp
operator|->
name|b_vp
expr_stmt|;
name|obj
operator|=
name|bp
operator|->
name|b_object
expr_stmt|;
while|while
condition|(
name|bp
operator|->
name|b_npages
operator|<
name|desiredpages
condition|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_pindex_t
name|pi
decl_stmt|;
name|pi
operator|=
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
operator|+
name|bp
operator|->
name|b_npages
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|pi
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
comment|/* 					 * note: must allocate system pages 					 * since blocking here could intefere 					 * with paging I/O, no matter which 					 * process we are. 					 */
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|obj
argument_list|,
name|pi
argument_list|,
name|VM_ALLOC_SYSTEM
operator||
name|VM_ALLOC_WIRED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|VM_WAIT
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
name|desiredpages
operator|-
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_CACHE
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|bp
operator|->
name|b_npages
index|]
operator|=
name|m
expr_stmt|;
operator|++
name|bp
operator|->
name|b_npages
expr_stmt|;
block|}
continue|continue;
block|}
comment|/* 				 * We found a page.  If we have to sleep on it, 				 * retry because it might have gotten freed out 				 * from under us. 				 * 				 * We can only test PG_BUSY here.  Blocking on 				 * m->busy might lead to a deadlock: 				 * 				 *  vm_fault->getpages->cluster_read->allocbuf 				 * 				 */
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
if|if
condition|(
name|vm_page_sleep_if_busy
argument_list|(
name|m
argument_list|,
name|FALSE
argument_list|,
literal|"pgtblk"
argument_list|)
condition|)
continue|continue;
comment|/* 				 * We have a good page.  Should we wakeup the 				 * page daemon? 				 */
if|if
condition|(
operator|(
name|curproc
operator|!=
name|pageproc
operator|)
operator|&&
operator|(
operator|(
name|m
operator|->
name|queue
operator|-
name|m
operator|->
name|pc
operator|)
operator|==
name|PQ_CACHE
operator|)
operator|&&
operator|(
operator|(
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|)
operator|<
operator|(
name|cnt
operator|.
name|v_free_min
operator|+
name|cnt
operator|.
name|v_cache_min
operator|)
operator|)
condition|)
block|{
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
block|}
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|vm_page_wire
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|bp
operator|->
name|b_npages
index|]
operator|=
name|m
expr_stmt|;
operator|++
name|bp
operator|->
name|b_npages
expr_stmt|;
block|}
comment|/* 			 * Step 2.  We've loaded the pages into the buffer, 			 * we have to figure out if we can still have B_CACHE 			 * set.  Note that B_CACHE is set according to the 			 * byte-granular range ( bcount and size ), new the 			 * aligned range ( newbsize ). 			 * 			 * The VM test is against m->valid, which is DEV_BSIZE 			 * aligned.  Needless to say, the validity of the data 			 * needs to also be DEV_BSIZE aligned.  Note that this 			 * fails with NFS if the server or some other client 			 * extends the file's EOF.  If our buffer is resized,  			 * B_CACHE may remain set! XXX 			 */
name|toff
operator|=
name|bp
operator|->
name|b_bcount
expr_stmt|;
name|tinc
operator|=
name|PAGE_SIZE
operator|-
operator|(
operator|(
name|bp
operator|->
name|b_offset
operator|+
name|toff
operator|)
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|&&
name|toff
operator|<
name|size
condition|)
block|{
name|vm_pindex_t
name|pi
decl_stmt|;
if|if
condition|(
name|tinc
operator|>
operator|(
name|size
operator|-
name|toff
operator|)
condition|)
name|tinc
operator|=
name|size
operator|-
name|toff
expr_stmt|;
name|pi
operator|=
operator|(
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|+
name|toff
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
name|vfs_buf_test_cache
argument_list|(
name|bp
argument_list|,
name|bp
operator|->
name|b_offset
argument_list|,
name|toff
argument_list|,
name|tinc
argument_list|,
name|bp
operator|->
name|b_pages
index|[
name|pi
index|]
argument_list|)
expr_stmt|;
name|toff
operator|+=
name|tinc
expr_stmt|;
name|tinc
operator|=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* 			 * Step 3, fixup the KVM pmap.  Remember that 			 * bp->b_data is relative to bp->b_offset, but  			 * bp->b_offset may be offset into the first page. 			 */
name|bp
operator|->
name|b_data
operator|=
operator|(
name|caddr_t
operator|)
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_data
operator|=
call|(
name|caddr_t
call|)
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator||
call|(
name|vm_offset_t
call|)
argument_list|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|newbsize
operator|<
name|bp
operator|->
name|b_bufsize
condition|)
name|bufspacewakeup
argument_list|()
expr_stmt|;
name|bp
operator|->
name|b_bufsize
operator|=
name|newbsize
expr_stmt|;
comment|/* actual buffer allocation	*/
name|bp
operator|->
name|b_bcount
operator|=
name|size
expr_stmt|;
comment|/* requested buffer size	*/
return|return
literal|1
return|;
block|}
end_function

begin_function
name|void
name|biodone
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|)
block|{
name|bp
operator|->
name|bio_flags
operator||=
name|BIO_DONE
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|bio_done
operator|!=
name|NULL
condition|)
name|bp
operator|->
name|bio_done
argument_list|(
name|bp
argument_list|)
expr_stmt|;
else|else
name|wakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Wait for a BIO to finish.  *  * XXX: resort to a timeout for now.  The optimal locking (if any) for this  * case is not yet clear.  */
end_comment

begin_function
name|int
name|biowait
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|,
specifier|const
name|char
modifier|*
name|wchan
parameter_list|)
block|{
while|while
condition|(
operator|(
name|bp
operator|->
name|bio_flags
operator|&
name|BIO_DONE
operator|)
operator|==
literal|0
condition|)
name|msleep
argument_list|(
name|bp
argument_list|,
name|NULL
argument_list|,
name|PRIBIO
argument_list|,
name|wchan
argument_list|,
name|hz
operator|/
literal|10
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|bio_error
operator|!=
literal|0
condition|)
return|return
operator|(
name|bp
operator|->
name|bio_error
operator|)
return|;
if|if
condition|(
operator|!
operator|(
name|bp
operator|->
name|bio_flags
operator|&
name|BIO_ERROR
operator|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
return|return
operator|(
name|EIO
operator|)
return|;
block|}
end_function

begin_function
name|void
name|biofinish
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|,
name|struct
name|devstat
modifier|*
name|stat
parameter_list|,
name|int
name|error
parameter_list|)
block|{
if|if
condition|(
name|error
condition|)
block|{
name|bp
operator|->
name|bio_error
operator|=
name|error
expr_stmt|;
name|bp
operator|->
name|bio_flags
operator||=
name|BIO_ERROR
expr_stmt|;
block|}
if|if
condition|(
name|stat
operator|!=
name|NULL
condition|)
name|devstat_end_transaction_bio
argument_list|(
name|stat
argument_list|,
name|bp
argument_list|)
expr_stmt|;
name|biodone
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bioq_init
parameter_list|(
name|struct
name|bio_queue_head
modifier|*
name|head
parameter_list|)
block|{
name|TAILQ_INIT
argument_list|(
operator|&
name|head
operator|->
name|queue
argument_list|)
expr_stmt|;
name|head
operator|->
name|last_pblkno
operator|=
literal|0
expr_stmt|;
name|head
operator|->
name|insert_point
operator|=
name|NULL
expr_stmt|;
name|head
operator|->
name|switch_point
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_function
name|void
name|bioq_remove
parameter_list|(
name|struct
name|bio_queue_head
modifier|*
name|head
parameter_list|,
name|struct
name|bio
modifier|*
name|bp
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|==
name|head
operator|->
name|switch_point
condition|)
name|head
operator|->
name|switch_point
operator|=
name|TAILQ_NEXT
argument_list|(
name|bp
argument_list|,
name|bio_queue
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|==
name|head
operator|->
name|insert_point
condition|)
block|{
name|head
operator|->
name|insert_point
operator|=
name|TAILQ_PREV
argument_list|(
name|bp
argument_list|,
name|bio_queue
argument_list|,
name|bio_queue
argument_list|)
expr_stmt|;
if|if
condition|(
name|head
operator|->
name|insert_point
operator|==
name|NULL
condition|)
name|head
operator|->
name|last_pblkno
operator|=
literal|0
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|bp
operator|==
name|TAILQ_FIRST
argument_list|(
operator|&
name|head
operator|->
name|queue
argument_list|)
condition|)
name|head
operator|->
name|last_pblkno
operator|=
name|bp
operator|->
name|bio_pblkno
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|head
operator|->
name|queue
argument_list|,
name|bp
argument_list|,
name|bio_queue
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_FIRST
argument_list|(
operator|&
name|head
operator|->
name|queue
argument_list|)
operator|==
name|head
operator|->
name|switch_point
condition|)
name|head
operator|->
name|switch_point
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufwait:  *  *	Wait for buffer I/O completion, returning error status.  The buffer  *	is left locked and B_DONE on return.  B_EINTR is converted into an EINTR  *	error and cleared.  */
end_comment

begin_function
name|int
name|bufwait
parameter_list|(
specifier|register
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
while|while
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DONE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
condition|)
name|tsleep
argument_list|(
name|bp
argument_list|,
name|PRIBIO
argument_list|,
literal|"biord"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
else|else
name|tsleep
argument_list|(
name|bp
argument_list|,
name|PRIBIO
argument_list|,
literal|"biowr"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_EINTR
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_EINTR
expr_stmt|;
return|return
operator|(
name|EINTR
operator|)
return|;
block|}
if|if
condition|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
condition|)
block|{
return|return
operator|(
name|bp
operator|->
name|b_error
condition|?
name|bp
operator|->
name|b_error
else|:
name|EIO
operator|)
return|;
block|}
else|else
block|{
return|return
operator|(
literal|0
operator|)
return|;
block|}
block|}
end_function

begin_comment
comment|/*   * Call back function from struct bio back up to struct buf.   * The corresponding initialization lives in sys/conf.h:DEV_STRATEGY().   */
end_comment

begin_function
name|void
name|bufdonebio
parameter_list|(
name|struct
name|bio
modifier|*
name|bp
parameter_list|)
block|{
name|bufdone
argument_list|(
name|bp
operator|->
name|bio_caller2
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	bufdone:  *  *	Finish I/O on a buffer, optionally calling a completion function.  *	This is usually called from an interrupt so process blocking is  *	not allowed.  *  *	biodone is also responsible for setting B_CACHE in a B_VMIO bp.  *	In a non-VMIO bp, B_CACHE will be set on the next getblk()   *	assuming B_INVAL is clear.  *  *	For the VMIO case, we set B_CACHE if the op was a read and no  *	read error occured, or if the op was a write.  B_CACHE is never  *	set if the buffer is invalid or otherwise uncacheable.  *  *	biodone does not mess with B_INVAL, allowing the I/O routine or the  *	initiator to leave B_INVAL set to brelse the buffer out of existance  *	in the biodone routine.  */
end_comment

begin_function
name|void
name|bufdone
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|void
function_decl|(
modifier|*
name|biodone
function_decl|)
parameter_list|(
name|struct
name|buf
modifier|*
parameter_list|)
function_decl|;
name|GIANT_REQUIRED
expr_stmt|;
name|s
operator|=
name|splbio
argument_list|()
expr_stmt|;
name|KASSERT
argument_list|(
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|>
literal|0
argument_list|,
operator|(
literal|"biodone: bp %p not busy %d"
operator|,
name|bp
operator|,
name|BUF_REFCNT
argument_list|(
name|bp
argument_list|)
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_DONE
operator|)
argument_list|,
operator|(
literal|"biodone: bp %p already done"
operator|,
name|bp
operator|)
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_flags
operator||=
name|B_DONE
expr_stmt|;
name|runningbufwakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_DELETE
condition|)
block|{
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_WRITE
condition|)
block|{
name|vwakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
comment|/* call optional completion function if requested */
if|if
condition|(
name|bp
operator|->
name|b_iodone
operator|!=
name|NULL
condition|)
block|{
name|biodone
operator|=
name|bp
operator|->
name|b_iodone
expr_stmt|;
name|bp
operator|->
name|b_iodone
operator|=
name|NULL
expr_stmt|;
call|(
modifier|*
name|biodone
call|)
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|LIST_FIRST
argument_list|(
operator|&
name|bp
operator|->
name|b_dep
argument_list|)
operator|!=
name|NULL
condition|)
name|buf_complete
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|int
name|i
decl_stmt|;
name|vm_ooffset_t
name|foff
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|;
name|int
name|iosize
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
init|=
name|bp
operator|->
name|b_vp
decl_stmt|;
name|obj
operator|=
name|bp
operator|->
name|b_object
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|VFS_BIO_DEBUG
argument_list|)
name|mp_fixme
argument_list|(
literal|"usecount and vflag accessed without locks."
argument_list|)
expr_stmt|;
if|if
condition|(
name|vp
operator|->
name|v_usecount
operator|==
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"biodone: zero vnode ref count"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|vp
operator|->
name|v_vflag
operator|&
name|VV_OBJBUF
operator|)
operator|==
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"biodone: vnode is not setup for merged cache"
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"biodone: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|VFS_BIO_DEBUG
argument_list|)
if|if
condition|(
name|obj
operator|->
name|paging_in_progress
operator|<
name|bp
operator|->
name|b_npages
condition|)
block|{
name|printf
argument_list|(
literal|"biodone: paging in progress(%d)< bp->b_npages(%d)\n"
argument_list|,
name|obj
operator|->
name|paging_in_progress
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* 		 * Set B_CACHE if the op was a normal read and no error 		 * occured.  B_CACHE is set for writes in the b*write() 		 * routines. 		 */
name|iosize
operator|=
name|bp
operator|->
name|b_bcount
operator|-
name|bp
operator|->
name|b_resid
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_INVAL
operator||
name|B_NOCACHE
operator|)
operator|)
operator|&&
operator|!
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
condition|)
block|{
name|bp
operator|->
name|b_flags
operator||=
name|B_CACHE
expr_stmt|;
block|}
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|int
name|bogusflag
init|=
literal|0
decl_stmt|;
name|int
name|resid
decl_stmt|;
name|resid
operator|=
operator|(
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
operator|)
operator|-
name|foff
expr_stmt|;
if|if
condition|(
name|resid
operator|>
name|iosize
condition|)
name|resid
operator|=
name|iosize
expr_stmt|;
comment|/* 			 * cleanup bogus pages, restoring the originals 			 */
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|bogusflag
operator|=
literal|1
expr_stmt|;
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|foff
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"biodone: page disappeared!"
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|m
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
if|#
directive|if
name|defined
argument_list|(
name|VFS_BIO_DEBUG
argument_list|)
if|if
condition|(
name|OFF_TO_IDX
argument_list|(
name|foff
argument_list|)
operator|!=
name|m
operator|->
name|pindex
condition|)
block|{
name|printf
argument_list|(
literal|"biodone: foff(%jd)/m->pindex(%ju) mismatch\n"
argument_list|,
operator|(
name|intmax_t
operator|)
name|foff
argument_list|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* 			 * In the write case, the valid and clean bits are 			 * already changed correctly ( see bdwrite() ), so we  			 * only need to do this here in the read case. 			 */
if|if
condition|(
operator|(
name|bp
operator|->
name|b_iocmd
operator|==
name|BIO_READ
operator|)
operator|&&
operator|!
name|bogusflag
operator|&&
name|resid
operator|>
literal|0
condition|)
block|{
name|vfs_page_set_valid
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|i
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
comment|/* 			 * when debugging new filesystems or buffer I/O methods, this 			 * is the most common error that pops up.  if you see this, you 			 * have not set the page busy flag correctly!!! 			 */
if|if
condition|(
name|m
operator|->
name|busy
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"biodone: page busy< 0, "
literal|"pindex: %d, foff: 0x(%x,%x), "
literal|"resid: %d, index: %d\n"
argument_list|,
operator|(
name|int
operator|)
name|m
operator|->
name|pindex
argument_list|,
call|(
name|int
call|)
argument_list|(
name|foff
operator|>>
literal|32
argument_list|)
argument_list|,
operator|(
name|int
operator|)
name|foff
operator|&
literal|0xffffffff
argument_list|,
name|resid
argument_list|,
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vn_isdisk
argument_list|(
name|vp
argument_list|,
name|NULL
argument_list|)
condition|)
name|printf
argument_list|(
literal|" iosize: %ld, lblkno: %jd, flags: 0x%lx, npages: %d\n"
argument_list|,
name|bp
operator|->
name|b_vp
operator|->
name|v_mount
operator|->
name|mnt_stat
operator|.
name|f_iosize
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_lblkno
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
else|else
name|printf
argument_list|(
literal|" VDEV, lblkno: %jd, flags: 0x%lx, npages: %d\n"
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_lblkno
argument_list|,
name|bp
operator|->
name|b_flags
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|" valid: 0x%x, dirty: 0x%x, wired: %d\n"
argument_list|,
name|m
operator|->
name|valid
argument_list|,
name|m
operator|->
name|dirty
argument_list|,
name|m
operator|->
name|wire_count
argument_list|)
expr_stmt|;
name|panic
argument_list|(
literal|"biodone: page busy< 0\n"
argument_list|)
expr_stmt|;
block|}
name|vm_page_io_finish
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_object_pip_subtract
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|foff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
name|iosize
operator|-=
name|resid
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
if|if
condition|(
name|obj
condition|)
name|vm_object_pip_wakeupn
argument_list|(
name|obj
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * For asynchronous completions, release the buffer now. The brelse 	 * will do a wakeup there if necessary - so no need to do a wakeup 	 * here in the async case. The sync case always needs to do a wakeup. 	 */
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_ASYNC
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_NOCACHE
operator||
name|B_INVAL
operator||
name|B_RELBUF
operator|)
operator|)
operator|||
operator|(
name|bp
operator|->
name|b_ioflags
operator|&
name|BIO_ERROR
operator|)
condition|)
name|brelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
else|else
name|bqrelse
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|wakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine is called in lieu of iodone in the case of  * incomplete I/O.  This keeps the busy status for pages  * consistant.  */
end_comment

begin_function
name|void
name|vfs_unbusy_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
name|runningbufwakeup
argument_list|(
name|bp
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|obj
operator|=
name|bp
operator|->
name|b_object
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
init|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|m
operator|==
name|bogus_page
condition|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|obj
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|bp
operator|->
name|b_offset
argument_list|)
operator|+
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|m
condition|)
block|{
name|panic
argument_list|(
literal|"vfs_unbusy_pages: page missing\n"
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|m
expr_stmt|;
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
name|vm_object_pip_subtract
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|vm_page_io_finish
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|vm_object_pip_wakeupn
argument_list|(
name|obj
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * vfs_page_set_valid:  *  *	Set the valid bits in a page based on the supplied offset.   The  *	range is restricted to the buffer's size.  *  *	This routine is typically called after a read completes.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_page_set_valid
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_ooffset_t
name|off
parameter_list|,
name|int
name|pageno
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_ooffset_t
name|soff
decl_stmt|,
name|eoff
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Start and end offsets in buffer.  eoff - soff may not cross a 	 * page boundry or cross the end of the buffer.  The end of the 	 * buffer, in this case, is our file EOF, not the allocation size 	 * of the buffer. 	 */
name|soff
operator|=
name|off
expr_stmt|;
name|eoff
operator|=
operator|(
name|off
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
if|if
condition|(
name|eoff
operator|>
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
condition|)
name|eoff
operator|=
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bcount
expr_stmt|;
comment|/* 	 * Set valid range.  This is typically the entire buffer and thus the 	 * entire page. 	 */
if|if
condition|(
name|eoff
operator|>
name|soff
condition|)
block|{
name|vm_page_set_validclean
argument_list|(
name|m
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
name|soff
operator|&
name|PAGE_MASK
argument_list|)
argument_list|,
call|(
name|vm_offset_t
call|)
argument_list|(
name|eoff
operator|-
name|soff
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * This routine is called before a device strategy routine.  * It is used to tell the VM system that paging I/O is in  * progress, and treat the pages associated with the buffer  * almost as being PG_BUSY.  Also the object paging_in_progress  * flag is handled to make sure that the object doesn't become  * inconsistant.  *  * Since I/O has not been initiated yet, certain buffer flags  * such as BIO_ERROR or B_INVAL may be in an inconsistant state  * and should be ignored.  */
end_comment

begin_function
name|void
name|vfs_busy_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|clear_modify
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|bogus
decl_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_ooffset_t
name|foff
decl_stmt|;
name|obj
operator|=
name|bp
operator|->
name|b_object
expr_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"vfs_busy_pages: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
name|vfs_setdirty
argument_list|(
name|bp
argument_list|)
expr_stmt|;
name|retry
label|:
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
init|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|vm_page_sleep_if_busy
argument_list|(
name|m
argument_list|,
name|FALSE
argument_list|,
literal|"vbpage"
argument_list|)
condition|)
goto|goto
name|retry
goto|;
block|}
name|bogus
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
init|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
decl_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CLUSTER
operator|)
operator|==
literal|0
condition|)
block|{
name|vm_object_pip_add
argument_list|(
name|obj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_io_start
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
comment|/* 			 * When readying a buffer for a read ( i.e 			 * clear_modify == 0 ), it is important to do 			 * bogus_page replacement for valid pages in  			 * partially instantiated buffers.  Partially  			 * instantiated buffers can, in turn, occur when 			 * reconstituting a buffer from its VM backing store 			 * base.  We only have to do this if B_CACHE is 			 * clear ( which causes the I/O to occur in the 			 * first place ).  The replacement prevents the read 			 * I/O from overwriting potentially dirty VM-backed 			 * pages.  XXX bogus page replacement is, uh, bogus. 			 * It may not work properly with small-block devices. 			 * We need to find a better way. 			 */
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|clear_modify
condition|)
name|vfs_page_set_valid
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|i
argument_list|,
name|m
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|&&
operator|(
name|bp
operator|->
name|b_flags
operator|&
name|B_CACHE
operator|)
operator|==
literal|0
condition|)
block|{
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|=
name|bogus_page
expr_stmt|;
name|bogus
operator|++
expr_stmt|;
block|}
name|foff
operator|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
if|if
condition|(
name|bogus
condition|)
name|pmap_qenter
argument_list|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
argument_list|,
name|bp
operator|->
name|b_pages
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Tell the VM system that the pages associated with this buffer  * are clean.  This is used for delayed writes where the data is  * going to go to disk eventually without additional VM intevention.  *  * Note that while we only really need to clean through to b_bcount, we  * just go ahead and clean through to b_bufsize.  */
end_comment

begin_function
specifier|static
name|void
name|vfs_clean_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|vm_ooffset_t
name|foff
decl_stmt|;
name|foff
operator|=
name|bp
operator|->
name|b_offset
expr_stmt|;
name|KASSERT
argument_list|(
name|bp
operator|->
name|b_offset
operator|!=
name|NOOFFSET
argument_list|,
operator|(
literal|"vfs_clean_pages: no buffer offset"
operator|)
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
init|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
decl_stmt|;
name|vm_ooffset_t
name|noff
init|=
operator|(
name|foff
operator|+
name|PAGE_SIZE
operator|)
operator|&
operator|~
operator|(
name|off_t
operator|)
name|PAGE_MASK
decl_stmt|;
name|vm_ooffset_t
name|eoff
init|=
name|noff
decl_stmt|;
if|if
condition|(
name|eoff
operator|>
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bufsize
condition|)
name|eoff
operator|=
name|bp
operator|->
name|b_offset
operator|+
name|bp
operator|->
name|b_bufsize
expr_stmt|;
name|vfs_page_set_valid
argument_list|(
name|bp
argument_list|,
name|foff
argument_list|,
name|i
argument_list|,
name|m
argument_list|)
expr_stmt|;
comment|/* vm_page_clear_dirty(m, foff& PAGE_MASK, eoff - foff); */
name|foff
operator|=
name|noff
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_set_validclean:  *  *	Set the range within the buffer to valid and clean.  The range is   *	relative to the beginning of the buffer, b_offset.  Note that b_offset  *	itself may be offset from the beginning of the first page.  *  */
end_comment

begin_function
name|void
name|vfs_bio_set_validclean
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
if|if
condition|(
name|bp
operator|->
name|b_flags
operator|&
name|B_VMIO
condition|)
block|{
name|int
name|i
decl_stmt|;
name|int
name|n
decl_stmt|;
comment|/* 		 * Fixup base to be relative to beginning of first page. 		 * Set initial n to be the maximum number of bytes in the 		 * first page that can be validated. 		 */
name|base
operator|+=
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
operator|-
operator|(
name|base
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
name|base
operator|/
name|PAGE_SIZE
init|;
name|size
operator|>
literal|0
operator|&&
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
operator|++
name|i
control|)
block|{
name|vm_page_t
name|m
init|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|n
operator|>
name|size
condition|)
name|n
operator|=
name|size
expr_stmt|;
name|vm_page_set_validclean
argument_list|(
name|m
argument_list|,
name|base
operator|&
name|PAGE_MASK
argument_list|,
name|n
argument_list|)
expr_stmt|;
name|base
operator|+=
name|n
expr_stmt|;
name|size
operator|-=
name|n
expr_stmt|;
name|n
operator|=
name|PAGE_SIZE
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vfs_bio_clrbuf:  *  *	clear a buffer.  This routine essentially fakes an I/O, so we need  *	to clear BIO_ERROR and B_INVAL.  *  *	Note that while we only theoretically need to clear through b_bcount,  *	we go ahead and clear through b_bufsize.  */
end_comment

begin_function
name|void
name|vfs_bio_clrbuf
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|mask
init|=
literal|0
decl_stmt|;
name|caddr_t
name|sa
decl_stmt|,
name|ea
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_flags
operator|&
operator|(
name|B_VMIO
operator||
name|B_MALLOC
operator|)
operator|)
operator|==
name|B_VMIO
condition|)
block|{
name|bp
operator|->
name|b_flags
operator|&=
operator|~
name|B_INVAL
expr_stmt|;
name|bp
operator|->
name|b_ioflags
operator|&=
operator|~
name|BIO_ERROR
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_npages
operator|==
literal|1
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_bufsize
operator|<
name|PAGE_SIZE
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_offset
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
condition|)
block|{
name|mask
operator|=
operator|(
literal|1
operator|<<
operator|(
name|bp
operator|->
name|b_bufsize
operator|/
name|DEV_BSIZE
operator|)
operator|)
operator|-
literal|1
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
name|mask
condition|)
block|{
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
operator|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
operator|(
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
literal|0
operator|)
condition|)
block|{
name|bzero
argument_list|(
name|bp
operator|->
name|b_data
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
literal|0
index|]
operator|->
name|valid
operator||=
name|mask
expr_stmt|;
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
return|return;
block|}
block|}
name|ea
operator|=
name|sa
operator|=
name|bp
operator|->
name|b_data
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
operator|,
name|sa
operator|=
name|ea
control|)
block|{
name|int
name|j
init|=
operator|(
operator|(
name|vm_offset_t
operator|)
name|sa
operator|&
name|PAGE_MASK
operator|)
operator|/
name|DEV_BSIZE
decl_stmt|;
name|ea
operator|=
operator|(
name|caddr_t
operator|)
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|sa
operator|+
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|ea
operator|=
operator|(
name|caddr_t
operator|)
operator|(
name|vm_offset_t
operator|)
name|ulmin
argument_list|(
operator|(
name|u_long
operator|)
operator|(
name|vm_offset_t
operator|)
name|ea
argument_list|,
operator|(
name|u_long
operator|)
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
operator|+
name|bp
operator|->
name|b_bufsize
argument_list|)
expr_stmt|;
name|mask
operator|=
operator|(
operator|(
literal|1
operator|<<
operator|(
operator|(
name|ea
operator|-
name|sa
operator|)
operator|/
name|DEV_BSIZE
operator|)
operator|)
operator|-
literal|1
operator|)
operator|<<
name|j
expr_stmt|;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
name|mask
condition|)
continue|continue;
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
name|mask
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
block|{
name|bzero
argument_list|(
name|sa
argument_list|,
name|ea
operator|-
name|sa
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
init|;
name|sa
operator|<
name|ea
condition|;
name|sa
operator|+=
name|DEV_BSIZE
operator|,
name|j
operator|++
control|)
block|{
if|if
condition|(
operator|(
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
name|j
operator|)
operator|)
operator|==
literal|0
condition|)
name|bzero
argument_list|(
name|sa
argument_list|,
name|DEV_BSIZE
argument_list|)
expr_stmt|;
block|}
block|}
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
operator|->
name|valid
operator||=
name|mask
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
name|bp
operator|->
name|b_resid
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
name|clrbuf
argument_list|(
name|bp
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * vm_hold_load_pages and vm_hold_free_pages get pages into  * a buffers address space.  The pages are anonymous and are  * not associated with a file object.  */
end_comment

begin_function
specifier|static
name|void
name|vm_hold_load_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
block|{
name|vm_offset_t
name|pg
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|int
name|index
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
name|to
operator|=
name|round_page
argument_list|(
name|to
argument_list|)
expr_stmt|;
name|from
operator|=
name|round_page
argument_list|(
name|from
argument_list|)
expr_stmt|;
name|index
operator|=
operator|(
name|from
operator|-
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
for|for
control|(
name|pg
operator|=
name|from
init|;
name|pg
operator|<
name|to
condition|;
name|pg
operator|+=
name|PAGE_SIZE
operator|,
name|index
operator|++
control|)
block|{
name|tryagain
label|:
comment|/* 		 * note: must allocate system pages since blocking here 		 * could intefere with paging I/O, no matter which 		 * process we are. 		 */
name|vm_object_lock
argument_list|(
name|kernel_object
argument_list|)
expr_stmt|;
name|p
operator|=
name|vm_page_alloc
argument_list|(
name|kernel_object
argument_list|,
operator|(
operator|(
name|pg
operator|-
name|VM_MIN_KERNEL_ADDRESS
operator|)
operator|>>
name|PAGE_SHIFT
operator|)
argument_list|,
name|VM_ALLOC_SYSTEM
operator||
name|VM_ALLOC_WIRED
argument_list|)
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|kernel_object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|p
condition|)
block|{
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
operator|(
name|to
operator|-
name|from
operator|)
operator|>>
name|PAGE_SHIFT
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
goto|goto
name|tryagain
goto|;
block|}
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|p
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|pmap_qenter
argument_list|(
name|pg
argument_list|,
operator|&
name|p
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
operator|=
name|p
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_wakeup
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
name|bp
operator|->
name|b_npages
operator|=
name|index
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Return pages associated with this buf to the vm system */
end_comment

begin_function
specifier|static
name|void
name|vm_hold_free_pages
parameter_list|(
name|struct
name|buf
modifier|*
name|bp
parameter_list|,
name|vm_offset_t
name|from
parameter_list|,
name|vm_offset_t
name|to
parameter_list|)
block|{
name|vm_offset_t
name|pg
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|int
name|index
decl_stmt|,
name|newnpages
decl_stmt|;
name|GIANT_REQUIRED
expr_stmt|;
name|from
operator|=
name|round_page
argument_list|(
name|from
argument_list|)
expr_stmt|;
name|to
operator|=
name|round_page
argument_list|(
name|to
argument_list|)
expr_stmt|;
name|newnpages
operator|=
name|index
operator|=
operator|(
name|from
operator|-
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|bp
operator|->
name|b_data
argument_list|)
operator|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
for|for
control|(
name|pg
operator|=
name|from
init|;
name|pg
operator|<
name|to
condition|;
name|pg
operator|+=
name|PAGE_SIZE
operator|,
name|index
operator|++
control|)
block|{
name|p
operator|=
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
expr_stmt|;
if|if
condition|(
name|p
operator|&&
operator|(
name|index
operator|<
name|bp
operator|->
name|b_npages
operator|)
condition|)
block|{
if|if
condition|(
name|p
operator|->
name|busy
condition|)
block|{
name|printf
argument_list|(
literal|"vm_hold_free_pages: blkno: %jd, lblkno: %jd\n"
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_blkno
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_lblkno
argument_list|)
expr_stmt|;
block|}
name|bp
operator|->
name|b_pages
index|[
name|index
index|]
operator|=
name|NULL
expr_stmt|;
name|pmap_qremove
argument_list|(
name|pg
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_busy
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|p
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
block|}
name|bp
operator|->
name|b_npages
operator|=
name|newnpages
expr_stmt|;
block|}
end_function

begin_include
include|#
directive|include
file|"opt_ddb.h"
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_include
include|#
directive|include
file|<ddb/ddb.h>
end_include

begin_comment
comment|/* DDB command to show buffer data */
end_comment

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|buffer
argument_list|,
argument|db_show_buffer
argument_list|)
end_macro

begin_block
block|{
comment|/* get args */
name|struct
name|buf
modifier|*
name|bp
init|=
operator|(
expr|struct
name|buf
operator|*
operator|)
name|addr
decl_stmt|;
if|if
condition|(
operator|!
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"usage: show buffer<addr>\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|db_printf
argument_list|(
literal|"b_flags = 0x%b\n"
argument_list|,
operator|(
name|u_int
operator|)
name|bp
operator|->
name|b_flags
argument_list|,
name|PRINT_BUF_FLAGS
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"b_error = %d, b_bufsize = %ld, b_bcount = %ld, b_resid = %ld\n"
literal|"b_dev = (%d,%d), b_data = %p, b_blkno = %jd, b_pblkno = %jd\n"
argument_list|,
name|bp
operator|->
name|b_error
argument_list|,
name|bp
operator|->
name|b_bufsize
argument_list|,
name|bp
operator|->
name|b_bcount
argument_list|,
name|bp
operator|->
name|b_resid
argument_list|,
name|major
argument_list|(
name|bp
operator|->
name|b_dev
argument_list|)
argument_list|,
name|minor
argument_list|(
name|bp
operator|->
name|b_dev
argument_list|)
argument_list|,
name|bp
operator|->
name|b_data
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_blkno
argument_list|,
operator|(
name|intmax_t
operator|)
name|bp
operator|->
name|b_pblkno
argument_list|)
expr_stmt|;
if|if
condition|(
name|bp
operator|->
name|b_npages
condition|)
block|{
name|int
name|i
decl_stmt|;
name|db_printf
argument_list|(
literal|"b_npages = %d, pages(OBJ, IDX, PA): "
argument_list|,
name|bp
operator|->
name|b_npages
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|bp
operator|->
name|b_npages
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|bp
operator|->
name|b_pages
index|[
name|i
index|]
expr_stmt|;
name|db_printf
argument_list|(
literal|"(%p, 0x%lx, 0x%lx)"
argument_list|,
operator|(
name|void
operator|*
operator|)
name|m
operator|->
name|object
argument_list|,
operator|(
name|u_long
operator|)
name|m
operator|->
name|pindex
argument_list|,
operator|(
name|u_long
operator|)
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|i
operator|+
literal|1
operator|)
operator|<
name|bp
operator|->
name|b_npages
condition|)
name|db_printf
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* DDB */
end_comment

end_unit

