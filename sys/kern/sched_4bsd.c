begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1982, 1986, 1990, 1991, 1993  *	The Regents of the University of California.  All rights reserved.  * (c) UNIX System Laboratories, Inc.  * All or some portions of this file are derived from material licensed  * to the University of California by American Telephone and Telegraph  * Co. or Unix System Laboratories, Inc. and are reproduced herein with  * the permission of UNIX System Laboratories, Inc.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_hwpmc_hooks.h"
end_include

begin_define
define|#
directive|define
name|kse
value|td_sched
end_define

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/kthread.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/turnstile.h>
end_include

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
end_ifdef

begin_include
include|#
directive|include
file|<sys/pmckern.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * INVERSE_ESTCPU_WEIGHT is only suitable for statclock() frequencies in  * the range 100-256 Hz (approximately).  */
end_comment

begin_define
define|#
directive|define
name|ESTCPULIM
parameter_list|(
name|e
parameter_list|)
define|\
value|min((e), INVERSE_ESTCPU_WEIGHT * (NICE_WEIGHT * (PRIO_MAX - PRIO_MIN) - \     RQ_PPQ) + INVERSE_ESTCPU_WEIGHT - 1)
end_define

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_define
define|#
directive|define
name|INVERSE_ESTCPU_WEIGHT
value|(8 * smp_cpus)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|INVERSE_ESTCPU_WEIGHT
value|8
end_define

begin_comment
comment|/* 1 / (priorities per estcpu level). */
end_comment

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|NICE_WEIGHT
value|1
end_define

begin_comment
comment|/* Priorities per nice level. */
end_comment

begin_comment
comment|/*  * The schedulable entity that can be given a context to run.  * A process may have several of these. Probably one per processor  * but posibly a few more. In this universe they are grouped  * with a KSEG that contains the priority and niceness  * for the group.  */
end_comment

begin_struct
struct|struct
name|kse
block|{
name|TAILQ_ENTRY
argument_list|(
argument|kse
argument_list|)
name|ke_procq
expr_stmt|;
comment|/* (j/z) Run queue. */
name|struct
name|thread
modifier|*
name|ke_thread
decl_stmt|;
comment|/* (*) Active associated thread. */
name|fixpt_t
name|ke_pctcpu
decl_stmt|;
comment|/* (j) %cpu during p_swtime. */
name|char
name|ke_rqindex
decl_stmt|;
comment|/* (j) Run queue index. */
enum|enum
block|{
name|KES_THREAD
init|=
literal|0x0
block|,
comment|/* slaved to thread state */
name|KES_ONRUNQ
block|}
name|ke_state
enum|;
comment|/* (j) KSE status. */
name|int
name|ke_cpticks
decl_stmt|;
comment|/* (j) Ticks of cpu time. */
name|struct
name|runq
modifier|*
name|ke_runq
decl_stmt|;
comment|/* runq the kse is currently on */
block|}
struct|;
end_struct

begin_define
define|#
directive|define
name|ke_proc
value|ke_thread->td_proc
end_define

begin_define
define|#
directive|define
name|ke_ksegrp
value|ke_thread->td_ksegrp
end_define

begin_define
define|#
directive|define
name|td_kse
value|td_sched
end_define

begin_comment
comment|/* flags kept in td_flags */
end_comment

begin_define
define|#
directive|define
name|TDF_DIDRUN
value|TDF_SCHED0
end_define

begin_comment
comment|/* KSE actually ran. */
end_comment

begin_define
define|#
directive|define
name|TDF_EXIT
value|TDF_SCHED1
end_define

begin_comment
comment|/* KSE is being killed. */
end_comment

begin_define
define|#
directive|define
name|TDF_BOUND
value|TDF_SCHED2
end_define

begin_define
define|#
directive|define
name|ke_flags
value|ke_thread->td_flags
end_define

begin_define
define|#
directive|define
name|KEF_DIDRUN
value|TDF_DIDRUN
end_define

begin_comment
comment|/* KSE actually ran. */
end_comment

begin_define
define|#
directive|define
name|KEF_EXIT
value|TDF_EXIT
end_define

begin_comment
comment|/* KSE is being killed. */
end_comment

begin_define
define|#
directive|define
name|KEF_BOUND
value|TDF_BOUND
end_define

begin_comment
comment|/* stuck to one CPU */
end_comment

begin_define
define|#
directive|define
name|SKE_RUNQ_PCPU
parameter_list|(
name|ke
parameter_list|)
define|\
value|((ke)->ke_runq != 0&& (ke)->ke_runq !=&runq)
end_define

begin_struct
struct|struct
name|kg_sched
block|{
name|struct
name|thread
modifier|*
name|skg_last_assigned
decl_stmt|;
comment|/* (j) Last thread assigned to */
comment|/* the system scheduler. */
name|int
name|skg_avail_opennings
decl_stmt|;
comment|/* (j) Num KSEs requested in group. */
name|int
name|skg_concurrency
decl_stmt|;
comment|/* (j) Num KSEs requested in group. */
block|}
struct|;
end_struct

begin_define
define|#
directive|define
name|kg_last_assigned
value|kg_sched->skg_last_assigned
end_define

begin_define
define|#
directive|define
name|kg_avail_opennings
value|kg_sched->skg_avail_opennings
end_define

begin_define
define|#
directive|define
name|kg_concurrency
value|kg_sched->skg_concurrency
end_define

begin_define
define|#
directive|define
name|SLOT_RELEASE
parameter_list|(
name|kg
parameter_list|)
define|\
value|do {									\ 	kg->kg_avail_opennings++; 					\ 	CTR3(KTR_RUNQ, "kg %p(%d) Slot released (->%d)",		\ 	kg,								\ 	kg->kg_concurrency,						\ 	 kg->kg_avail_opennings);					\
comment|/*	KASSERT((kg->kg_avail_opennings<= kg->kg_concurrency),		\ 	    ("slots out of whack"));*/
value|\ } while (0)
end_define

begin_define
define|#
directive|define
name|SLOT_USE
parameter_list|(
name|kg
parameter_list|)
define|\
value|do {									\ 	kg->kg_avail_opennings--; 					\ 	CTR3(KTR_RUNQ, "kg %p(%d) Slot used (->%d)",			\ 	kg,								\ 	kg->kg_concurrency,						\ 	 kg->kg_avail_opennings);					\
comment|/*	KASSERT((kg->kg_avail_opennings>= 0),				\ 	    ("slots out of whack"));*/
value|\ } while (0)
end_define

begin_comment
comment|/*  * KSE_CAN_MIGRATE macro returns true if the kse can migrate between  * cpus.  */
end_comment

begin_define
define|#
directive|define
name|KSE_CAN_MIGRATE
parameter_list|(
name|ke
parameter_list|)
define|\
value|((ke)->ke_thread->td_pinned == 0&& ((ke)->ke_flags& KEF_BOUND) == 0)
end_define

begin_decl_stmt
specifier|static
name|struct
name|kse
name|kse0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|kg_sched
name|kg_sched0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|sched_tdcnt
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Total runnable threads in the system. */
end_comment

begin_decl_stmt
specifier|static
name|int
name|sched_quantum
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Roundrobin scheduling quantum in ticks. */
end_comment

begin_define
define|#
directive|define
name|SCHED_QUANTUM
value|(hz / 10)
end_define

begin_comment
comment|/* Default sched quantum */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|callout
name|roundrobin_callout
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|void
name|slot_fill
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|kse
modifier|*
name|sched_choose
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/* XXX Should be thread * */
end_comment

begin_function_decl
specifier|static
name|void
name|setup_runqs
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|roundrobin
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|schedcpu
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|schedcpu_thread
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|maybe_resched
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|updatepri
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|resetpriority
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|resetpriority_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
function_decl|;
end_function_decl

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function_decl
specifier|static
name|int
name|forward_wakeup
parameter_list|(
name|int
name|cpunum
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|struct
name|kproc_desc
name|sched_kp
init|=
block|{
literal|"schedcpu"
block|,
name|schedcpu_thread
block|,
name|NULL
block|}
decl_stmt|;
end_decl_stmt

begin_macro
name|SYSINIT
argument_list|(
argument|schedcpu
argument_list|,
argument|SI_SUB_RUN_SCHEDULER
argument_list|,
argument|SI_ORDER_FIRST
argument_list|,
argument|kproc_start
argument_list|,
argument|&sched_kp
argument_list|)
end_macro

begin_macro
name|SYSINIT
argument_list|(
argument|sched_setup
argument_list|,
argument|SI_SUB_RUN_QUEUE
argument_list|,
argument|SI_ORDER_FIRST
argument_list|,
argument|sched_setup
argument_list|,
argument|NULL
argument_list|)
end_macro

begin_comment
comment|/*  * Global run queue.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|runq
name|runq
decl_stmt|;
end_decl_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * Per-CPU run queues  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|runq
name|runq_pcpu
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|void
name|setup_runqs
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
operator|++
name|i
control|)
name|runq_init
argument_list|(
operator|&
name|runq_pcpu
index|[
name|i
index|]
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|runq_init
argument_list|(
operator|&
name|runq
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|sysctl_kern_quantum
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|int
name|error
decl_stmt|,
name|new_val
decl_stmt|;
name|new_val
operator|=
name|sched_quantum
operator|*
name|tick
expr_stmt|;
name|error
operator|=
name|sysctl_handle_int
argument_list|(
name|oidp
argument_list|,
operator|&
name|new_val
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|error
operator|)
return|;
if|if
condition|(
name|new_val
operator|<
name|tick
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|sched_quantum
operator|=
name|new_val
operator|/
name|tick
expr_stmt|;
name|hogticks
operator|=
literal|2
operator|*
name|sched_quantum
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_expr_stmt
name|SYSCTL_NODE
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|sched
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|"Scheduler"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_STRING
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|name
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|"4BSD"
argument_list|,
literal|0
argument_list|,
literal|"Scheduler name"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|quantum
argument_list|,
name|CTLTYPE_INT
operator||
name|CTLFLAG_RW
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
name|sched_quantum
argument_list|,
name|sysctl_kern_quantum
argument_list|,
literal|"I"
argument_list|,
literal|"Roundrobin scheduling quantum in microseconds"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/* Enable forwarding of wakeups to all other cpus */
end_comment

begin_expr_stmt
name|SYSCTL_NODE
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|ipiwakeup
argument_list|,
name|CTLFLAG_RD
argument_list|,
name|NULL
argument_list|,
literal|"Kernel SMP"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeup_enabled
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|enabled
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|forward_wakeup_enabled
argument_list|,
literal|0
argument_list|,
literal|"Forwarding of wakeup to idle CPUs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeups_requested
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|requested
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|forward_wakeups_requested
argument_list|,
literal|0
argument_list|,
literal|"Requests for Forwarding of wakeup to idle CPUs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeups_delivered
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|delivered
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|forward_wakeups_delivered
argument_list|,
literal|0
argument_list|,
literal|"Completed Forwarding of wakeup to idle CPUs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeup_use_mask
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|usemask
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|forward_wakeup_use_mask
argument_list|,
literal|0
argument_list|,
literal|"Use the mask of idle cpus"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeup_use_loop
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|useloop
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|forward_wakeup_use_loop
argument_list|,
literal|0
argument_list|,
literal|"Use a loop to find idle cpus"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeup_use_single
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|onecpu
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|forward_wakeup_use_single
argument_list|,
literal|0
argument_list|,
literal|"Only signal one idle cpu"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeup_use_htt
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|htt2
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|forward_wakeup_use_htt
argument_list|,
literal|0
argument_list|,
literal|"account for htt"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|int
name|sched_followon
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|followon
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|sched_followon
argument_list|,
literal|0
argument_list|,
literal|"allow threads to share a quantum"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|sched_pfollowons
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|pfollowons
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|sched_pfollowons
argument_list|,
literal|0
argument_list|,
literal|"number of followons done to a different ksegrp"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|sched_kgfollowons
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|kgfollowons
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|sched_kgfollowons
argument_list|,
literal|0
argument_list|,
literal|"number of followons done in a ksegrp"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|__inline
name|void
name|sched_load_add
parameter_list|(
name|void
parameter_list|)
block|{
name|sched_tdcnt
operator|++
expr_stmt|;
name|CTR1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"global load: %d"
argument_list|,
name|sched_tdcnt
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|sched_load_rem
parameter_list|(
name|void
parameter_list|)
block|{
name|sched_tdcnt
operator|--
expr_stmt|;
name|CTR1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"global load: %d"
argument_list|,
name|sched_tdcnt
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Arrange to reschedule if necessary, taking the priorities and  * schedulers into account.  */
end_comment

begin_function
specifier|static
name|void
name|maybe_resched
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<
name|curthread
operator|->
name|td_priority
condition|)
name|curthread
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Force switch among equal priority processes every 100ms.  * We don't actually need to force a context switch of the current process.  * The act of firing the event triggers a context switch to softclock() and  * then switching back out again which is equivalent to a preemption, thus  * no further work is needed on the local CPU.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|roundrobin
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|forward_roundrobin
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|callout_reset
argument_list|(
operator|&
name|roundrobin_callout
argument_list|,
name|sched_quantum
argument_list|,
name|roundrobin
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Constants for digital decay and forget:  *	90% of (kg_estcpu) usage in 5 * loadav time  *	95% of (ke_pctcpu) usage in 60 seconds (load insensitive)  *          Note that, as ps(1) mentions, this can let percentages  *          total over 100% (I've seen 137.9% for 3 processes).  *  * Note that schedclock() updates kg_estcpu and p_cpticks asynchronously.  *  * We wish to decay away 90% of kg_estcpu in (5 * loadavg) seconds.  * That is, the system wants to compute a value of decay such  * that the following for loop:  * 	for (i = 0; i< (5 * loadavg); i++)  * 		kg_estcpu *= decay;  * will compute  * 	kg_estcpu *= 0.1;  * for all values of loadavg:  *  * Mathematically this loop can be expressed by saying:  * 	decay ** (5 * loadavg) ~= .1  *  * The system computes decay as:  * 	decay = (2 * loadavg) / (2 * loadavg + 1)  *  * We wish to prove that the system's computation of decay  * will always fulfill the equation:  * 	decay ** (5 * loadavg) ~= .1  *  * If we compute b as:  * 	b = 2 * loadavg  * then  * 	decay = b / (b + 1)  *  * We now need to prove two things:  *	1) Given factor ** (5 * loadavg) ~= .1, prove factor == b/(b+1)  *	2) Given b/(b+1) ** power ~= .1, prove power == (5 * loadavg)  *  * Facts:  *         For x close to zero, exp(x) =~ 1 + x, since  *              exp(x) = 0! + x**1/1! + x**2/2! + ... .  *              therefore exp(-1/b) =~ 1 - (1/b) = (b-1)/b.  *         For x close to zero, ln(1+x) =~ x, since  *              ln(1+x) = x - x**2/2 + x**3/3 - ...     -1< x< 1  *              therefore ln(b/(b+1)) = ln(1 - 1/(b+1)) =~ -1/(b+1).  *         ln(.1) =~ -2.30  *  * Proof of (1):  *    Solve (factor)**(power) =~ .1 given power (5*loadav):  *	solving for factor,  *      ln(factor) =~ (-2.30/5*loadav), or  *      factor =~ exp(-1/((5/2.30)*loadav)) =~ exp(-1/(2*loadav)) =  *          exp(-1/b) =~ (b-1)/b =~ b/(b+1).                    QED  *  * Proof of (2):  *    Solve (factor)**(power) =~ .1 given factor == (b/(b+1)):  *	solving for power,  *      power*ln(b/(b+1)) =~ -2.30, or  *      power =~ 2.3 * (b + 1) = 4.6*loadav + 2.3 =~ 5*loadav.  QED  *  * Actual power values for the implemented algorithm are as follows:  *      loadav: 1       2       3       4  *      power:  5.68    10.32   14.94   19.55  */
end_comment

begin_comment
comment|/* calculations for digital decay to forget 90% of usage in 5*loadav sec */
end_comment

begin_define
define|#
directive|define
name|loadfactor
parameter_list|(
name|loadav
parameter_list|)
value|(2 * (loadav))
end_define

begin_define
define|#
directive|define
name|decay_cpu
parameter_list|(
name|loadfac
parameter_list|,
name|cpu
parameter_list|)
value|(((loadfac) * (cpu)) / ((loadfac) + FSCALE))
end_define

begin_comment
comment|/* decay 95% of `ke_pctcpu' in 60 seconds; see CCPU_SHIFT before changing */
end_comment

begin_decl_stmt
specifier|static
name|fixpt_t
name|ccpu
init|=
literal|0.95122942450071400909
operator|*
name|FSCALE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* exp(-1/20) */
end_comment

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|ccpu
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ccpu
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * If `ccpu' is not equal to `exp(-1/20)' and you still want to use the  * faster/more-accurate formula, you'll have to estimate CCPU_SHIFT below  * and possibly adjust FSHIFT in "param.h" so that (FSHIFT>= CCPU_SHIFT).  *  * To estimate CCPU_SHIFT for exp(-1/20), the following formula was used:  *	1 - exp(-1/20) ~= 0.0487 ~= 0.0488 == 1 (fixed pt, *11* bits).  *  * If you don't want to bother with the faster/more-accurate formula, you  * can set CCPU_SHIFT to (FSHIFT + 1) which will use a slower/less-accurate  * (more general) method of calculating the %age of CPU used by a process.  */
end_comment

begin_define
define|#
directive|define
name|CCPU_SHIFT
value|11
end_define

begin_comment
comment|/*  * Recompute process priorities, every hz ticks.  * MP-safe, called without the Giant mutex.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|schedcpu
parameter_list|(
name|void
parameter_list|)
block|{
specifier|register
name|fixpt_t
name|loadfac
init|=
name|loadfactor
argument_list|(
name|averunnable
operator|.
name|ldavg
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|int
name|awake
decl_stmt|,
name|realstathz
decl_stmt|;
name|realstathz
operator|=
name|stathz
condition|?
name|stathz
else|:
name|hz
expr_stmt|;
name|sx_slock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
name|FOREACH_PROC_IN_SYSTEM
argument_list|(
argument|p
argument_list|)
block|{
comment|/* 		 * Prevent state changes and protect run queue. 		 */
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
comment|/* 		 * Increment time in/out of memory.  We ignore overflow; with 		 * 16-bit int's (remember them?) overflow takes 45 days. 		 */
name|p
operator|->
name|p_swtime
operator|++
expr_stmt|;
name|FOREACH_KSEGRP_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|kg
argument_list|)
block|{
name|awake
operator|=
literal|0
expr_stmt|;
name|FOREACH_THREAD_IN_GROUP
argument_list|(
argument|kg
argument_list|,
argument|td
argument_list|)
block|{
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
comment|/* 				 * Increment sleep time (if sleeping).  We 				 * ignore overflow, as above. 				 */
comment|/* 				 * The kse slptimes are not touched in wakeup 				 * because the thread may not HAVE a KSE. 				 */
if|if
condition|(
name|ke
operator|->
name|ke_state
operator|==
name|KES_ONRUNQ
condition|)
block|{
name|awake
operator|=
literal|1
expr_stmt|;
name|ke
operator|->
name|ke_flags
operator|&=
operator|~
name|KEF_DIDRUN
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|ke
operator|->
name|ke_state
operator|==
name|KES_THREAD
operator|)
operator|&&
operator|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
operator|)
condition|)
block|{
name|awake
operator|=
literal|1
expr_stmt|;
comment|/* Do not clear KEF_DIDRUN */
block|}
elseif|else
if|if
condition|(
name|ke
operator|->
name|ke_flags
operator|&
name|KEF_DIDRUN
condition|)
block|{
name|awake
operator|=
literal|1
expr_stmt|;
name|ke
operator|->
name|ke_flags
operator|&=
operator|~
name|KEF_DIDRUN
expr_stmt|;
block|}
comment|/* 				 * ke_pctcpu is only for ps and ttyinfo(). 				 * Do it per kse, and add them up at the end? 				 * XXXKSE 				 */
name|ke
operator|->
name|ke_pctcpu
operator|=
operator|(
name|ke
operator|->
name|ke_pctcpu
operator|*
name|ccpu
operator|)
operator|>>
name|FSHIFT
expr_stmt|;
comment|/* 				 * If the kse has been idle the entire second, 				 * stop recalculating its priority until 				 * it wakes up. 				 */
if|if
condition|(
name|ke
operator|->
name|ke_cpticks
operator|==
literal|0
condition|)
continue|continue;
if|#
directive|if
operator|(
name|FSHIFT
operator|>=
name|CCPU_SHIFT
operator|)
name|ke
operator|->
name|ke_pctcpu
operator|+=
operator|(
name|realstathz
operator|==
literal|100
operator|)
condition|?
operator|(
operator|(
name|fixpt_t
operator|)
name|ke
operator|->
name|ke_cpticks
operator|)
operator|<<
operator|(
name|FSHIFT
operator|-
name|CCPU_SHIFT
operator|)
else|:
literal|100
operator|*
operator|(
operator|(
operator|(
name|fixpt_t
operator|)
name|ke
operator|->
name|ke_cpticks
operator|)
operator|<<
operator|(
name|FSHIFT
operator|-
name|CCPU_SHIFT
operator|)
operator|)
operator|/
name|realstathz
expr_stmt|;
else|#
directive|else
name|ke
operator|->
name|ke_pctcpu
operator|+=
operator|(
operator|(
name|FSCALE
operator|-
name|ccpu
operator|)
operator|*
operator|(
name|ke
operator|->
name|ke_cpticks
operator|*
name|FSCALE
operator|/
name|realstathz
operator|)
operator|)
operator|>>
name|FSHIFT
expr_stmt|;
endif|#
directive|endif
name|ke
operator|->
name|ke_cpticks
operator|=
literal|0
expr_stmt|;
block|}
comment|/* end of kse loop */
comment|/*  			 * If there are ANY running threads in this KSEGRP, 			 * then don't count it as sleeping. 			 */
if|if
condition|(
name|awake
condition|)
block|{
if|if
condition|(
name|kg
operator|->
name|kg_slptime
operator|>
literal|1
condition|)
block|{
comment|/* 					 * In an ideal world, this should not 					 * happen, because whoever woke us 					 * up from the long sleep should have 					 * unwound the slptime and reset our 					 * priority before we run at the stale 					 * priority.  Should KASSERT at some 					 * point when all the cases are fixed. 					 */
name|updatepri
argument_list|(
name|kg
argument_list|)
expr_stmt|;
block|}
name|kg
operator|->
name|kg_slptime
operator|=
literal|0
expr_stmt|;
block|}
else|else
name|kg
operator|->
name|kg_slptime
operator|++
expr_stmt|;
if|if
condition|(
name|kg
operator|->
name|kg_slptime
operator|>
literal|1
condition|)
continue|continue;
name|kg
operator|->
name|kg_estcpu
operator|=
name|decay_cpu
argument_list|(
name|loadfac
argument_list|,
name|kg
operator|->
name|kg_estcpu
argument_list|)
expr_stmt|;
name|resetpriority
argument_list|(
name|kg
argument_list|)
expr_stmt|;
name|FOREACH_THREAD_IN_GROUP
argument_list|(
argument|kg
argument_list|,
argument|td
argument_list|)
block|{
name|resetpriority_thread
argument_list|(
name|td
argument_list|,
name|kg
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* end of ksegrp loop */
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
comment|/* end of process loop */
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Main loop for a kthread that executes schedcpu once a second.  */
end_comment

begin_function
specifier|static
name|void
name|schedcpu_thread
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|nowake
decl_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|schedcpu
argument_list|()
expr_stmt|;
name|tsleep
argument_list|(
operator|&
name|nowake
argument_list|,
literal|0
argument_list|,
literal|"-"
argument_list|,
name|hz
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Recalculate the priority of a process after it has slept for a while.  * For all load averages>= 1 and max kg_estcpu of 255, sleeping for at  * least six times the loadfactor will decay kg_estcpu to zero.  */
end_comment

begin_function
specifier|static
name|void
name|updatepri
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
block|{
specifier|register
name|fixpt_t
name|loadfac
decl_stmt|;
specifier|register
name|unsigned
name|int
name|newcpu
decl_stmt|;
name|loadfac
operator|=
name|loadfactor
argument_list|(
name|averunnable
operator|.
name|ldavg
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|kg
operator|->
name|kg_slptime
operator|>
literal|5
operator|*
name|loadfac
condition|)
name|kg
operator|->
name|kg_estcpu
operator|=
literal|0
expr_stmt|;
else|else
block|{
name|newcpu
operator|=
name|kg
operator|->
name|kg_estcpu
expr_stmt|;
name|kg
operator|->
name|kg_slptime
operator|--
expr_stmt|;
comment|/* was incremented in schedcpu() */
while|while
condition|(
name|newcpu
operator|&&
operator|--
name|kg
operator|->
name|kg_slptime
condition|)
name|newcpu
operator|=
name|decay_cpu
argument_list|(
name|loadfac
argument_list|,
name|newcpu
argument_list|)
expr_stmt|;
name|kg
operator|->
name|kg_estcpu
operator|=
name|newcpu
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Compute the priority of a process when running in user mode.  * Arrange to reschedule if the resulting priority is better  * than that of the current process.  */
end_comment

begin_function
specifier|static
name|void
name|resetpriority
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
block|{
specifier|register
name|unsigned
name|int
name|newpriority
decl_stmt|;
if|if
condition|(
name|kg
operator|->
name|kg_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
block|{
name|newpriority
operator|=
name|PUSER
operator|+
name|kg
operator|->
name|kg_estcpu
operator|/
name|INVERSE_ESTCPU_WEIGHT
operator|+
name|NICE_WEIGHT
operator|*
operator|(
name|kg
operator|->
name|kg_proc
operator|->
name|p_nice
operator|-
name|PRIO_MIN
operator|)
expr_stmt|;
name|newpriority
operator|=
name|min
argument_list|(
name|max
argument_list|(
name|newpriority
argument_list|,
name|PRI_MIN_TIMESHARE
argument_list|)
argument_list|,
name|PRI_MAX_TIMESHARE
argument_list|)
expr_stmt|;
name|kg
operator|->
name|kg_user_pri
operator|=
name|newpriority
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Update the thread's priority when the associated ksegroup's user  * priority changes.  */
end_comment

begin_function
specifier|static
name|void
name|resetpriority_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
block|{
comment|/* Only change threads with a time sharing user priority. */
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<
name|PRI_MIN_TIMESHARE
operator|||
name|td
operator|->
name|td_priority
operator|>
name|PRI_MAX_TIMESHARE
condition|)
return|return;
comment|/* XXX the whole needresched thing is broken, but not silly. */
name|maybe_resched
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_prio
argument_list|(
name|td
argument_list|,
name|kg
operator|->
name|kg_user_pri
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|setup_runqs
argument_list|()
expr_stmt|;
if|if
condition|(
name|sched_quantum
operator|==
literal|0
condition|)
name|sched_quantum
operator|=
name|SCHED_QUANTUM
expr_stmt|;
name|hogticks
operator|=
literal|2
operator|*
name|sched_quantum
expr_stmt|;
name|callout_init
argument_list|(
operator|&
name|roundrobin_callout
argument_list|,
name|CALLOUT_MPSAFE
argument_list|)
expr_stmt|;
comment|/* Kick off timeout driven events by calling first time. */
name|roundrobin
argument_list|(
name|NULL
argument_list|)
expr_stmt|;
comment|/* Account for thread0. */
name|sched_load_add
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/* External interfaces start here */
end_comment

begin_comment
comment|/*  * Very early in the boot some setup of scheduler-specific  * parts of proc0 and of some scheduler resources needs to be done.  * Called from:  *  proc0_init()  */
end_comment

begin_function
name|void
name|schedinit
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * Set up the scheduler specific parts of proc0. 	 */
name|proc0
operator|.
name|p_sched
operator|=
name|NULL
expr_stmt|;
comment|/* XXX */
name|ksegrp0
operator|.
name|kg_sched
operator|=
operator|&
name|kg_sched0
expr_stmt|;
name|thread0
operator|.
name|td_sched
operator|=
operator|&
name|kse0
expr_stmt|;
name|kse0
operator|.
name|ke_thread
operator|=
operator|&
name|thread0
expr_stmt|;
name|kse0
operator|.
name|ke_state
operator|=
name|KES_THREAD
expr_stmt|;
name|kg_sched0
operator|.
name|skg_concurrency
operator|=
literal|1
expr_stmt|;
name|kg_sched0
operator|.
name|skg_avail_opennings
operator|=
literal|0
expr_stmt|;
comment|/* we are already running */
block|}
end_function

begin_function
name|int
name|sched_runnable
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
return|return
name|runq_check
argument_list|(
operator|&
name|runq
argument_list|)
operator|+
name|runq_check
argument_list|(
operator|&
name|runq_pcpu
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
argument_list|)
return|;
else|#
directive|else
return|return
name|runq_check
argument_list|(
operator|&
name|runq
argument_list|)
return|;
endif|#
directive|endif
block|}
end_function

begin_function
name|int
name|sched_rr_interval
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|sched_quantum
operator|==
literal|0
condition|)
name|sched_quantum
operator|=
name|SCHED_QUANTUM
expr_stmt|;
return|return
operator|(
name|sched_quantum
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * We adjust the priority of the current process.  The priority of  * a process gets worse as it accumulates CPU time.  The cpu usage  * estimator (kg_estcpu) is increased here.  resetpriority() will  * compute a different priority each time kg_estcpu increases by  * INVERSE_ESTCPU_WEIGHT  * (until MAXPRI is reached).  The cpu usage estimator ramps up  * quite quickly when the process is running (linearly), and decays  * away exponentially, at a rate which is proportionally slower when  * the system is busy.  The basic principle is that the system will  * 90% forget that the process used a lot of CPU time in 5 * loadav  * seconds.  This causes the system to favor processes which haven't  * run much recently, and to round-robin among other processes.  */
end_comment

begin_function
name|void
name|sched_clock
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|kg
operator|=
name|td
operator|->
name|td_ksegrp
expr_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|ke
operator|->
name|ke_cpticks
operator|++
expr_stmt|;
name|kg
operator|->
name|kg_estcpu
operator|=
name|ESTCPULIM
argument_list|(
name|kg
operator|->
name|kg_estcpu
operator|+
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|kg
operator|->
name|kg_estcpu
operator|%
name|INVERSE_ESTCPU_WEIGHT
operator|)
operator|==
literal|0
condition|)
block|{
name|resetpriority
argument_list|(
name|kg
argument_list|)
expr_stmt|;
name|resetpriority_thread
argument_list|(
name|td
argument_list|,
name|kg
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * charge childs scheduling cpu usage to parent.  *  * XXXKSE assume only one thread& kse& ksegrp keep estcpu in each ksegrp.  * Charge it to the ksegrp that did the wait since process estcpu is sum of  * all ksegrps, this is strictly as expected.  Assume that the child process  * aggregated all the estcpu into the 'built-in' ksegrp.  */
end_comment

begin_function
name|void
name|sched_exit
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|sched_exit_ksegrp
argument_list|(
name|FIRST_KSEGRP_IN_PROC
argument_list|(
name|p
argument_list|)
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|sched_exit_thread
argument_list|(
name|FIRST_THREAD_IN_PROC
argument_list|(
name|p
argument_list|)
argument_list|,
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_exit_ksegrp
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|,
name|struct
name|thread
modifier|*
name|childtd
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|kg
operator|->
name|kg_estcpu
operator|=
name|ESTCPULIM
argument_list|(
name|kg
operator|->
name|kg_estcpu
operator|+
name|childtd
operator|->
name|td_ksegrp
operator|->
name|kg_estcpu
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_exit_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_exit_thread: %p(%s) prio %d"
argument_list|,
name|child
argument_list|,
name|child
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|child
operator|->
name|td_priority
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|child
operator|->
name|td_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_rem
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_fork
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|childtd
parameter_list|)
block|{
name|sched_fork_ksegrp
argument_list|(
name|td
argument_list|,
name|childtd
operator|->
name|td_ksegrp
argument_list|)
expr_stmt|;
name|sched_fork_thread
argument_list|(
name|td
argument_list|,
name|childtd
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_fork_ksegrp
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|ksegrp
modifier|*
name|child
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|child
operator|->
name|kg_estcpu
operator|=
name|td
operator|->
name|td_ksegrp
operator|->
name|kg_estcpu
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_fork_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|childtd
parameter_list|)
block|{
name|sched_newthread
argument_list|(
name|childtd
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_nice
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|int
name|nice
parameter_list|)
block|{
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|p
operator|->
name|p_nice
operator|=
name|nice
expr_stmt|;
name|FOREACH_KSEGRP_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|kg
argument_list|)
block|{
name|resetpriority
argument_list|(
name|kg
argument_list|)
expr_stmt|;
name|FOREACH_THREAD_IN_GROUP
argument_list|(
argument|kg
argument_list|,
argument|td
argument_list|)
block|{
name|resetpriority_thread
argument_list|(
name|td
argument_list|,
name|kg
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
name|void
name|sched_class
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|,
name|int
name|class
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|kg
operator|->
name|kg_pri_class
operator|=
name|class
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Adjust the priority of a thread.  * This may include moving the thread within the KSEGRP,  * changing the assignment of a kse to the thread,  * and moving a KSE in the system run queue.  */
end_comment

begin_function
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|CTR6
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_prio: %p(%s) prio %d newprio %d by %p(%s)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|prio
argument_list|,
name|curthread
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|==
name|prio
condition|)
return|return;
if|if
condition|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|adjustrunqueue
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|td
operator|->
name|td_priority
operator|=
name|prio
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Update a thread's priority when it is lent another thread's  * priority.  */
end_comment

begin_function
name|void
name|sched_lend_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|td
operator|->
name|td_flags
operator||=
name|TDF_BORROWING
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Restore a thread's priority when priority propagation is  * over.  The prio argument is the minimum priority the thread  * needs to have to satisfy other possible priority lending  * requests.  If the thread's regulary priority is less  * important than prio the thread will keep a priority boost  * of prio.  */
end_comment

begin_function
name|void
name|sched_unlend_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|base_pri
decl_stmt|;
if|if
condition|(
name|td
operator|->
name|td_base_pri
operator|>=
name|PRI_MIN_TIMESHARE
operator|&&
name|td
operator|->
name|td_base_pri
operator|<=
name|PRI_MAX_TIMESHARE
condition|)
name|base_pri
operator|=
name|td
operator|->
name|td_ksegrp
operator|->
name|kg_user_pri
expr_stmt|;
else|else
name|base_pri
operator|=
name|td
operator|->
name|td_base_pri
expr_stmt|;
if|if
condition|(
name|prio
operator|>=
name|base_pri
condition|)
block|{
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_BORROWING
expr_stmt|;
name|sched_prio
argument_list|(
name|td
argument_list|,
name|base_pri
argument_list|)
expr_stmt|;
block|}
else|else
name|sched_lend_prio
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
comment|/* First, update the base priority. */
name|td
operator|->
name|td_base_pri
operator|=
name|prio
expr_stmt|;
comment|/* 	 * If the thread is borrowing another thread's priority, don't ever 	 * lower the priority. 	 */
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
operator|&&
name|td
operator|->
name|td_priority
operator|<
name|prio
condition|)
return|return;
comment|/* Change the real priority. */
name|oldprio
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
comment|/* 	 * If the thread is on a turnstile, then let the turnstile update 	 * its state. 	 */
if|if
condition|(
name|TD_ON_LOCK
argument_list|(
name|td
argument_list|)
operator|&&
name|oldprio
operator|!=
name|prio
condition|)
name|turnstile_adjust
argument_list|(
name|td
argument_list|,
name|oldprio
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_sleep
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_ksegrp
operator|->
name|kg_slptime
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function_decl
specifier|static
name|void
name|remrunqueue
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
function_decl|;
end_function_decl

begin_function
name|void
name|sched_switch
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|newtd
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|p
operator|=
name|td
operator|->
name|td_proc
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|p
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_rem
argument_list|()
expr_stmt|;
comment|/*  	 * We are volunteering to switch out so we get to nominate 	 * a successor for the rest of our quantum 	 * First try another thread in our ksegrp, and then look for  	 * other ksegrps in our process. 	 */
if|if
condition|(
name|sched_followon
operator|&&
operator|(
name|p
operator|->
name|p_flag
operator|&
name|P_HADTHREADS
operator|)
operator|&&
operator|(
name|flags
operator|&
name|SW_VOL
operator|)
operator|&&
name|newtd
operator|==
name|NULL
condition|)
block|{
comment|/* lets schedule another thread from this process */
name|kg
operator|=
name|td
operator|->
name|td_ksegrp
expr_stmt|;
if|if
condition|(
operator|(
name|newtd
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|kg
operator|->
name|kg_runq
argument_list|)
operator|)
condition|)
block|{
name|remrunqueue
argument_list|(
name|newtd
argument_list|)
expr_stmt|;
name|sched_kgfollowons
operator|++
expr_stmt|;
block|}
else|else
block|{
name|FOREACH_KSEGRP_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|kg
argument_list|)
block|{
if|if
condition|(
operator|(
name|newtd
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|kg
operator|->
name|kg_runq
argument_list|)
operator|)
condition|)
block|{
name|sched_pfollowons
operator|++
expr_stmt|;
name|remrunqueue
argument_list|(
name|newtd
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
block|}
block|}
if|if
condition|(
name|newtd
condition|)
name|newtd
operator|->
name|td_flags
operator||=
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_NEEDRESCHED
operator|)
expr_stmt|;
name|td
operator|->
name|td_lastcpu
operator|=
name|td
operator|->
name|td_oncpu
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_NEEDRESCHED
expr_stmt|;
name|td
operator|->
name|td_owepreempt
operator|=
literal|0
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|NOCPU
expr_stmt|;
comment|/* 	 * At the last moment, if this thread is still marked RUNNING, 	 * then put it back on the run queue as it has not been suspended 	 * or stopped or any thing else similar.  We never put the idle 	 * threads on the run queue, however. 	 */
if|if
condition|(
name|td
operator|==
name|PCPU_GET
argument_list|(
name|idlethread
argument_list|)
condition|)
name|TD_SET_CAN_RUN
argument_list|(
name|td
argument_list|)
expr_stmt|;
else|else
block|{
name|SLOT_RELEASE
argument_list|(
name|td
operator|->
name|td_ksegrp
argument_list|)
expr_stmt|;
if|if
condition|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
condition|)
block|{
comment|/* Put us back on the run queue (kse and all). */
name|setrunqueue
argument_list|(
name|td
argument_list|,
operator|(
name|flags
operator|&
name|SW_PREEMPT
operator|)
condition|?
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
operator||
name|SRQ_PREEMPTED
else|:
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|p
operator|->
name|p_flag
operator|&
name|P_HADTHREADS
condition|)
block|{
comment|/* 			 * We will not be on the run queue. So we must be 			 * sleeping or similar. As it's available, 			 * someone else can use the KSE if they need it. 			 * It's NOT available if we are about to need it 			 */
if|if
condition|(
name|newtd
operator|==
name|NULL
operator|||
name|newtd
operator|->
name|td_ksegrp
operator|!=
name|td
operator|->
name|td_ksegrp
condition|)
name|slot_fill
argument_list|(
name|td
operator|->
name|td_ksegrp
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|newtd
condition|)
block|{
comment|/*  		 * The thread we are about to run needs to be counted 		 * as if it had been added to the run queue and selected. 		 * It came from: 		 * * A preemption 		 * * An upcall  		 * * A followon 		 */
name|KASSERT
argument_list|(
operator|(
name|newtd
operator|->
name|td_inhibitors
operator|==
literal|0
operator|)
argument_list|,
operator|(
literal|"trying to run inhibitted thread"
operator|)
argument_list|)
expr_stmt|;
name|SLOT_USE
argument_list|(
name|newtd
operator|->
name|td_ksegrp
argument_list|)
expr_stmt|;
name|newtd
operator|->
name|td_kse
operator|->
name|ke_flags
operator||=
name|KEF_DIDRUN
expr_stmt|;
name|TD_SET_RUNNING
argument_list|(
name|newtd
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|newtd
operator|->
name|td_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_add
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|newtd
operator|=
name|choosethread
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|td
operator|!=
name|newtd
condition|)
block|{
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
if|if
condition|(
name|PMC_PROC_IS_USING_PMCS
argument_list|(
name|td
operator|->
name|td_proc
argument_list|)
condition|)
name|PMC_SWITCH_CONTEXT
argument_list|(
name|td
argument_list|,
name|PMC_FN_CSW_OUT
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|cpu_switch
argument_list|(
name|td
argument_list|,
name|newtd
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
if|if
condition|(
name|PMC_PROC_IS_USING_PMCS
argument_list|(
name|td
operator|->
name|td_proc
argument_list|)
condition|)
name|PMC_SWITCH_CONTEXT
argument_list|(
name|td
argument_list|,
name|PMC_FN_CSW_IN
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
name|sched_lock
operator|.
name|mtx_lock
operator|=
operator|(
name|uintptr_t
operator|)
name|td
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_wakeup
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|kg
operator|=
name|td
operator|->
name|td_ksegrp
expr_stmt|;
if|if
condition|(
name|kg
operator|->
name|kg_slptime
operator|>
literal|1
condition|)
block|{
name|updatepri
argument_list|(
name|kg
argument_list|)
expr_stmt|;
name|resetpriority
argument_list|(
name|kg
argument_list|)
expr_stmt|;
block|}
name|kg
operator|->
name|kg_slptime
operator|=
literal|0
expr_stmt|;
name|setrunqueue
argument_list|(
name|td
argument_list|,
name|SRQ_BORING
argument_list|)
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/* enable HTT_2 if you have a 2-way HTT cpu.*/
end_comment

begin_function
specifier|static
name|int
name|forward_wakeup
parameter_list|(
name|int
name|cpunum
parameter_list|)
block|{
name|cpumask_t
name|map
decl_stmt|,
name|me
decl_stmt|,
name|dontuse
decl_stmt|;
name|cpumask_t
name|map2
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|cpumask_t
name|id
decl_stmt|,
name|map3
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|CTR0
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"forward_wakeup()"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|!
name|forward_wakeup_enabled
operator|)
operator|||
operator|(
name|forward_wakeup_use_mask
operator|==
literal|0
operator|&&
name|forward_wakeup_use_loop
operator|==
literal|0
operator|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|if
condition|(
operator|!
name|smp_started
operator|||
name|cold
operator|||
name|panicstr
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|forward_wakeups_requested
operator|++
expr_stmt|;
comment|/*  * check the idle mask we received against what we calculated before  * in the old version.  */
name|me
operator|=
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
expr_stmt|;
comment|/*  	 * don't bother if we should be doing it ourself.. 	 */
if|if
condition|(
operator|(
name|me
operator|&
name|idle_cpus_mask
operator|)
operator|&&
operator|(
name|cpunum
operator|==
name|NOCPU
operator|||
name|me
operator|==
operator|(
literal|1
operator|<<
name|cpunum
operator|)
operator|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|dontuse
operator|=
name|me
operator||
name|stopped_cpus
operator||
name|hlt_cpus_mask
expr_stmt|;
name|map3
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|forward_wakeup_use_loop
condition|)
block|{
name|SLIST_FOREACH
argument_list|(
argument|pc
argument_list|,
argument|&cpuhead
argument_list|,
argument|pc_allcpu
argument_list|)
block|{
name|id
operator|=
name|pc
operator|->
name|pc_cpumask
expr_stmt|;
if|if
condition|(
operator|(
name|id
operator|&
name|dontuse
operator|)
operator|==
literal|0
operator|&&
name|pc
operator|->
name|pc_curthread
operator|==
name|pc
operator|->
name|pc_idlethread
condition|)
block|{
name|map3
operator||=
name|id
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|forward_wakeup_use_mask
condition|)
block|{
name|map
operator|=
literal|0
expr_stmt|;
name|map
operator|=
name|idle_cpus_mask
operator|&
operator|~
name|dontuse
expr_stmt|;
comment|/* If they are both on, compare and use loop if different */
if|if
condition|(
name|forward_wakeup_use_loop
condition|)
block|{
if|if
condition|(
name|map
operator|!=
name|map3
condition|)
block|{
name|printf
argument_list|(
literal|"map (%02X) != map3 (%02X)\n"
argument_list|,
name|map
argument_list|,
name|map3
argument_list|)
expr_stmt|;
name|map
operator|=
name|map3
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|map
operator|=
name|map3
expr_stmt|;
block|}
comment|/* If we only allow a specific CPU, then mask off all the others */
if|if
condition|(
name|cpunum
operator|!=
name|NOCPU
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|cpunum
operator|<=
name|mp_maxcpus
operator|)
argument_list|,
operator|(
literal|"forward_wakeup: bad cpunum."
operator|)
argument_list|)
expr_stmt|;
name|map
operator|&=
operator|(
literal|1
operator|<<
name|cpunum
operator|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Try choose an idle die. */
if|if
condition|(
name|forward_wakeup_use_htt
condition|)
block|{
name|map2
operator|=
operator|(
name|map
operator|&
operator|(
name|map
operator|>>
literal|1
operator|)
operator|)
operator|&
literal|0x5555
expr_stmt|;
if|if
condition|(
name|map2
condition|)
block|{
name|map
operator|=
name|map2
expr_stmt|;
block|}
block|}
comment|/* set only one bit */
if|if
condition|(
name|forward_wakeup_use_single
condition|)
block|{
name|map
operator|=
name|map
operator|&
operator|(
operator|(
operator|~
name|map
operator|)
operator|+
literal|1
operator|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|map
condition|)
block|{
name|forward_wakeups_delivered
operator|++
expr_stmt|;
name|ipi_selected
argument_list|(
name|map
argument_list|,
name|IPI_AST
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
if|if
condition|(
name|cpunum
operator|==
name|NOCPU
condition|)
name|printf
argument_list|(
literal|"forward_wakeup: Idle processor not found\n"
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function_decl
specifier|static
name|void
name|kick_other_cpu
parameter_list|(
name|int
name|pri
parameter_list|,
name|int
name|cpuid
parameter_list|)
function_decl|;
end_function_decl

begin_function
specifier|static
name|void
name|kick_other_cpu
parameter_list|(
name|int
name|pri
parameter_list|,
name|int
name|cpuid
parameter_list|)
block|{
name|struct
name|pcpu
modifier|*
name|pcpu
init|=
name|pcpu_find
argument_list|(
name|cpuid
argument_list|)
decl_stmt|;
name|int
name|cpri
init|=
name|pcpu
operator|->
name|pc_curthread
operator|->
name|td_priority
decl_stmt|;
if|if
condition|(
name|idle_cpus_mask
operator|&
name|pcpu
operator|->
name|pc_cpumask
condition|)
block|{
name|forward_wakeups_delivered
operator|++
expr_stmt|;
name|ipi_selected
argument_list|(
name|pcpu
operator|->
name|pc_cpumask
argument_list|,
name|IPI_AST
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|pri
operator|>=
name|cpri
condition|)
return|return;
if|#
directive|if
name|defined
argument_list|(
name|IPI_PREEMPTION
argument_list|)
operator|&&
name|defined
argument_list|(
name|PREEMPTION
argument_list|)
if|#
directive|if
operator|!
name|defined
argument_list|(
name|FULL_PREEMPTION
argument_list|)
if|if
condition|(
name|pri
operator|<=
name|PRI_MAX_ITHD
condition|)
endif|#
directive|endif
comment|/* ! FULL_PREEMPTION */
block|{
name|ipi_selected
argument_list|(
name|pcpu
operator|->
name|pc_cpumask
argument_list|,
name|IPI_PREEMPT
argument_list|)
expr_stmt|;
return|return;
block|}
endif|#
directive|endif
comment|/* defined(IPI_PREEMPTION)&& defined(PREEMPTION) */
name|pcpu
operator|->
name|pc_curthread
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
name|ipi_selected
argument_list|(
name|pcpu
operator|->
name|pc_cpumask
argument_list|,
name|IPI_AST
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* SMP */
end_comment

begin_function
name|void
name|sched_add
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
ifdef|#
directive|ifdef
name|SMP
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|int
name|forwarded
init|=
literal|0
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|int
name|single_cpu
init|=
literal|0
decl_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|ke
operator|->
name|ke_state
operator|!=
name|KES_ONRUNQ
argument_list|,
operator|(
literal|"sched_add: kse %p (%s) already in run queue"
operator|,
name|ke
operator|,
name|ke
operator|->
name|ke_proc
operator|->
name|p_comm
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|ke
operator|->
name|ke_proc
operator|->
name|p_sflag
operator|&
name|PS_INMEM
argument_list|,
operator|(
literal|"sched_add: process swapped out"
operator|)
argument_list|)
expr_stmt|;
name|CTR5
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_add: %p(%s) prio %d by %p(%s)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|curthread
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pinned
operator|!=
literal|0
condition|)
block|{
name|cpu
operator|=
name|td
operator|->
name|td_lastcpu
expr_stmt|;
name|ke
operator|->
name|ke_runq
operator|=
operator|&
name|runq_pcpu
index|[
name|cpu
index|]
expr_stmt|;
name|single_cpu
operator|=
literal|1
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"sched_add: Put kse:%p(td:%p) on cpu%d runq"
argument_list|,
name|ke
argument_list|,
name|td
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|ke
operator|)
operator|->
name|ke_flags
operator|&
name|KEF_BOUND
condition|)
block|{
comment|/* Find CPU from bound runq */
name|KASSERT
argument_list|(
name|SKE_RUNQ_PCPU
argument_list|(
name|ke
argument_list|)
argument_list|,
operator|(
literal|"sched_add: bound kse not on cpu runq"
operator|)
argument_list|)
expr_stmt|;
name|cpu
operator|=
name|ke
operator|->
name|ke_runq
operator|-
operator|&
name|runq_pcpu
index|[
literal|0
index|]
expr_stmt|;
name|single_cpu
operator|=
literal|1
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"sched_add: Put kse:%p(td:%p) on cpu%d runq"
argument_list|,
name|ke
argument_list|,
name|td
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|CTR2
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"sched_add: adding kse:%p (td:%p) to gbl runq"
argument_list|,
name|ke
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|cpu
operator|=
name|NOCPU
expr_stmt|;
name|ke
operator|->
name|ke_runq
operator|=
operator|&
name|runq
expr_stmt|;
block|}
if|if
condition|(
name|single_cpu
operator|&&
operator|(
name|cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
operator|)
condition|)
block|{
name|kick_other_cpu
argument_list|(
name|td
operator|->
name|td_priority
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|single_cpu
condition|)
block|{
name|cpumask_t
name|me
init|=
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
decl_stmt|;
name|int
name|idle
init|=
name|idle_cpus_mask
operator|&
name|me
decl_stmt|;
if|if
condition|(
operator|!
name|idle
operator|&&
operator|(
operator|(
name|flags
operator|&
name|SRQ_INTR
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|idle_cpus_mask
operator|&
operator|~
operator|(
name|hlt_cpus_mask
operator||
name|me
operator|)
operator|)
condition|)
name|forwarded
operator|=
name|forward_wakeup
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|forwarded
condition|)
block|{
if|if
condition|(
operator|(
name|flags
operator|&
name|SRQ_YIELDING
operator|)
operator|==
literal|0
operator|&&
name|maybe_preempt
argument_list|(
name|td
argument_list|)
condition|)
return|return;
else|else
name|maybe_resched
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|(
name|td
operator|->
name|td_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_add
argument_list|()
expr_stmt|;
name|SLOT_USE
argument_list|(
name|td
operator|->
name|td_ksegrp
argument_list|)
expr_stmt|;
name|runq_add
argument_list|(
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_state
operator|=
name|KES_ONRUNQ
expr_stmt|;
block|}
end_function

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* SMP */
end_comment

begin_block
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|ke
operator|->
name|ke_state
operator|!=
name|KES_ONRUNQ
argument_list|,
operator|(
literal|"sched_add: kse %p (%s) already in run queue"
operator|,
name|ke
operator|,
name|ke
operator|->
name|ke_proc
operator|->
name|p_comm
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|ke
operator|->
name|ke_proc
operator|->
name|p_sflag
operator|&
name|PS_INMEM
argument_list|,
operator|(
literal|"sched_add: process swapped out"
operator|)
argument_list|)
expr_stmt|;
name|CTR5
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_add: %p(%s) prio %d by %p(%s)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|curthread
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"sched_add: adding kse:%p (td:%p) to runq"
argument_list|,
name|ke
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_runq
operator|=
operator|&
name|runq
expr_stmt|;
comment|/*  	 * If we are yielding (on the way out anyhow)  	 * or the thread being saved is US, 	 * then don't try be smart about preemption 	 * or kicking off another CPU 	 * as it won't help and may hinder. 	 * In the YIEDLING case, we are about to run whoever is  	 * being put in the queue anyhow, and in the  	 * OURSELF case, we are puting ourself on the run queue 	 * which also only happens when we are about to yield. 	 */
if|if
condition|(
operator|(
name|flags
operator|&
name|SRQ_YIELDING
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|maybe_preempt
argument_list|(
name|td
argument_list|)
condition|)
return|return;
block|}
if|if
condition|(
operator|(
name|td
operator|->
name|td_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_add
argument_list|()
expr_stmt|;
name|SLOT_USE
argument_list|(
name|td
operator|->
name|td_ksegrp
argument_list|)
expr_stmt|;
name|runq_add
argument_list|(
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_state
operator|=
name|KES_ONRUNQ
expr_stmt|;
name|maybe_resched
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* SMP */
end_comment

begin_function
name|void
name|sched_rem
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|KASSERT
argument_list|(
name|ke
operator|->
name|ke_proc
operator|->
name|p_sflag
operator|&
name|PS_INMEM
argument_list|,
operator|(
literal|"sched_rem: process swapped out"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|ke
operator|->
name|ke_state
operator|==
name|KES_ONRUNQ
operator|)
argument_list|,
operator|(
literal|"sched_rem: KSE not on run queue"
operator|)
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|CTR5
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_rem: %p(%s) prio %d by %p(%s)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|curthread
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|td
operator|->
name|td_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_rem
argument_list|()
expr_stmt|;
name|SLOT_RELEASE
argument_list|(
name|td
operator|->
name|td_ksegrp
argument_list|)
expr_stmt|;
name|runq_remove
argument_list|(
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_state
operator|=
name|KES_THREAD
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Select threads to run.  * Notice that the running threads still consume a slot.  */
end_comment

begin_function
name|struct
name|kse
modifier|*
name|sched_choose
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|struct
name|runq
modifier|*
name|rq
decl_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|struct
name|kse
modifier|*
name|kecpu
decl_stmt|;
name|rq
operator|=
operator|&
name|runq
expr_stmt|;
name|ke
operator|=
name|runq_choose
argument_list|(
operator|&
name|runq
argument_list|)
expr_stmt|;
name|kecpu
operator|=
name|runq_choose
argument_list|(
operator|&
name|runq_pcpu
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|ke
operator|==
name|NULL
operator|||
operator|(
name|kecpu
operator|!=
name|NULL
operator|&&
name|kecpu
operator|->
name|ke_thread
operator|->
name|td_priority
operator|<
name|ke
operator|->
name|ke_thread
operator|->
name|td_priority
operator|)
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"choosing kse %p from pcpu runq %d"
argument_list|,
name|kecpu
argument_list|,
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|)
expr_stmt|;
name|ke
operator|=
name|kecpu
expr_stmt|;
name|rq
operator|=
operator|&
name|runq_pcpu
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
expr_stmt|;
block|}
else|else
block|{
name|CTR1
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"choosing kse %p from main runq"
argument_list|,
name|ke
argument_list|)
expr_stmt|;
block|}
else|#
directive|else
name|rq
operator|=
operator|&
name|runq
expr_stmt|;
name|ke
operator|=
name|runq_choose
argument_list|(
operator|&
name|runq
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|ke
operator|!=
name|NULL
condition|)
block|{
name|runq_remove
argument_list|(
name|rq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_state
operator|=
name|KES_THREAD
expr_stmt|;
name|KASSERT
argument_list|(
name|ke
operator|->
name|ke_proc
operator|->
name|p_sflag
operator|&
name|PS_INMEM
argument_list|,
operator|(
literal|"sched_choose: process swapped out"
operator|)
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|ke
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_userret
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
comment|/* 	 * XXX we cheat slightly on the locking here to avoid locking in 	 * the usual case.  Setting td_priority here is essentially an 	 * incomplete workaround for not setting it properly elsewhere. 	 * Now that some interrupt handlers are threads, not setting it 	 * properly elsewhere can clobber it in the window between setting 	 * it here and returning to user mode, so don't waste time setting 	 * it perfectly here. 	 */
name|KASSERT
argument_list|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"thread with borrowed priority returning to userland"
operator|)
argument_list|)
expr_stmt|;
name|kg
operator|=
name|td
operator|->
name|td_ksegrp
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|!=
name|kg
operator|->
name|kg_user_pri
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_priority
operator|=
name|kg
operator|->
name|kg_user_pri
expr_stmt|;
name|td
operator|->
name|td_base_pri
operator|=
name|kg
operator|->
name|kg_user_pri
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|sched_bind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
argument_list|,
operator|(
literal|"sched_bind: cannot bind non-running thread"
operator|)
argument_list|)
expr_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|ke
operator|->
name|ke_flags
operator||=
name|KEF_BOUND
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|ke
operator|->
name|ke_runq
operator|=
operator|&
name|runq_pcpu
index|[
name|cpu
index|]
expr_stmt|;
if|if
condition|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
operator|==
name|cpu
condition|)
return|return;
name|ke
operator|->
name|ke_state
operator|=
name|KES_THREAD
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_VOL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|sched_unbind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_kse
operator|->
name|ke_flags
operator|&=
operator|~
name|KEF_BOUND
expr_stmt|;
block|}
end_function

begin_function
name|int
name|sched_is_bound
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
name|td
operator|->
name|td_kse
operator|->
name|ke_flags
operator|&
name|KEF_BOUND
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_load
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
name|sched_tdcnt
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_sizeof_ksegrp
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|ksegrp
argument_list|)
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|kg_sched
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_sizeof_proc
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|proc
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_sizeof_thread
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|thread
argument_list|)
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|kse
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|fixpt_t
name|sched_pctcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
return|return
operator|(
name|ke
operator|->
name|ke_pctcpu
operator|)
return|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|KERN_SWITCH_INCLUDE
value|1
end_define

begin_include
include|#
directive|include
file|"kern/kern_switch.c"
end_include

end_unit

