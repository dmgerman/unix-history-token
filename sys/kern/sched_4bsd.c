begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1982, 1986, 1990, 1991, 1993  *	The Regents of the University of California.  All rights reserved.  * (c) UNIX System Laboratories, Inc.  * All or some portions of this file are derived from material licensed  * to the University of California by American Telephone and Telegraph  * Co. or Unix System Laboratories, Inc. and are reproduced herein with  * the permission of UNIX System Laboratories, Inc.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_hwpmc_hooks.h"
end_include

begin_include
include|#
directive|include
file|"opt_sched.h"
end_include

begin_include
include|#
directive|include
file|"opt_kdtrace.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/cpuset.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/kthread.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/turnstile.h>
end_include

begin_include
include|#
directive|include
file|<sys/umtx.h>
end_include

begin_include
include|#
directive|include
file|<machine/pcb.h>
end_include

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
end_ifdef

begin_include
include|#
directive|include
file|<sys/pmckern.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|KDTRACE_HOOKS
end_ifdef

begin_include
include|#
directive|include
file|<sys/dtrace_bsd.h>
end_include

begin_decl_stmt
name|int
name|dtrace_vtime_active
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|dtrace_vtime_switch_func_t
name|dtrace_vtime_switch_func
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * INVERSE_ESTCPU_WEIGHT is only suitable for statclock() frequencies in  * the range 100-256 Hz (approximately).  */
end_comment

begin_define
define|#
directive|define
name|ESTCPULIM
parameter_list|(
name|e
parameter_list|)
define|\
value|min((e), INVERSE_ESTCPU_WEIGHT * (NICE_WEIGHT * (PRIO_MAX - PRIO_MIN) - \     RQ_PPQ) + INVERSE_ESTCPU_WEIGHT - 1)
end_define

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_define
define|#
directive|define
name|INVERSE_ESTCPU_WEIGHT
value|(8 * smp_cpus)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|INVERSE_ESTCPU_WEIGHT
value|8
end_define

begin_comment
comment|/* 1 / (priorities per estcpu level). */
end_comment

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|NICE_WEIGHT
value|1
end_define

begin_comment
comment|/* Priorities per nice level. */
end_comment

begin_define
define|#
directive|define
name|TS_NAME_LEN
value|(MAXCOMLEN + sizeof(" td ") + sizeof(__XSTRING(UINT_MAX)))
end_define

begin_comment
comment|/*  * The schedulable entity that runs a context.  * This is  an extension to the thread structure and is tailored to  * the requirements of this scheduler  */
end_comment

begin_struct
struct|struct
name|td_sched
block|{
name|fixpt_t
name|ts_pctcpu
decl_stmt|;
comment|/* (j) %cpu during p_swtime. */
name|int
name|ts_cpticks
decl_stmt|;
comment|/* (j) Ticks of cpu time. */
name|int
name|ts_slptime
decl_stmt|;
comment|/* (j) Seconds !RUNNING. */
name|int
name|ts_flags
decl_stmt|;
name|struct
name|runq
modifier|*
name|ts_runq
decl_stmt|;
comment|/* runq the thread is currently on */
ifdef|#
directive|ifdef
name|KTR
name|char
name|ts_name
index|[
name|TS_NAME_LEN
index|]
decl_stmt|;
endif|#
directive|endif
block|}
struct|;
end_struct

begin_comment
comment|/* flags kept in td_flags */
end_comment

begin_define
define|#
directive|define
name|TDF_DIDRUN
value|TDF_SCHED0
end_define

begin_comment
comment|/* thread actually ran. */
end_comment

begin_define
define|#
directive|define
name|TDF_BOUND
value|TDF_SCHED1
end_define

begin_comment
comment|/* Bound to one CPU. */
end_comment

begin_comment
comment|/* flags kept in ts_flags */
end_comment

begin_define
define|#
directive|define
name|TSF_AFFINITY
value|0x0001
end_define

begin_comment
comment|/* Has a non-"full" CPU set. */
end_comment

begin_define
define|#
directive|define
name|SKE_RUNQ_PCPU
parameter_list|(
name|ts
parameter_list|)
define|\
value|((ts)->ts_runq != 0&& (ts)->ts_runq !=&runq)
end_define

begin_define
define|#
directive|define
name|THREAD_CAN_SCHED
parameter_list|(
name|td
parameter_list|,
name|cpu
parameter_list|)
define|\
value|CPU_ISSET((cpu),&(td)->td_cpuset->cs_mask)
end_define

begin_decl_stmt
specifier|static
name|struct
name|td_sched
name|td_sched0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mtx
name|sched_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|sched_tdcnt
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Total runnable threads in the system. */
end_comment

begin_decl_stmt
specifier|static
name|int
name|sched_quantum
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Roundrobin scheduling quantum in ticks. */
end_comment

begin_define
define|#
directive|define
name|SCHED_QUANTUM
value|(hz / 10)
end_define

begin_comment
comment|/* Default sched quantum */
end_comment

begin_function_decl
specifier|static
name|void
name|setup_runqs
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|schedcpu
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|schedcpu_thread
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|maybe_resched
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|updatepri
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|resetpriority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|resetpriority_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
function_decl|;
end_function_decl

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function_decl
specifier|static
name|int
name|sched_pickcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|forward_wakeup
parameter_list|(
name|int
name|cpunum
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|kick_other_cpu
parameter_list|(
name|int
name|pri
parameter_list|,
name|int
name|cpuid
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|struct
name|kproc_desc
name|sched_kp
init|=
block|{
literal|"schedcpu"
block|,
name|schedcpu_thread
block|,
name|NULL
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSINIT
argument_list|(
name|schedcpu
argument_list|,
name|SI_SUB_RUN_SCHEDULER
argument_list|,
name|SI_ORDER_FIRST
argument_list|,
name|kproc_start
argument_list|,
operator|&
name|sched_kp
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSINIT
argument_list|(
name|sched_setup
argument_list|,
name|SI_SUB_RUN_QUEUE
argument_list|,
name|SI_ORDER_FIRST
argument_list|,
name|sched_setup
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Global run queue.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|runq
name|runq
decl_stmt|;
end_decl_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * Per-CPU run queues  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|runq
name|runq_pcpu
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|long
name|runq_length
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|void
name|setup_runqs
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
operator|++
name|i
control|)
name|runq_init
argument_list|(
operator|&
name|runq_pcpu
index|[
name|i
index|]
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|runq_init
argument_list|(
operator|&
name|runq
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|sysctl_kern_quantum
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|int
name|error
decl_stmt|,
name|new_val
decl_stmt|;
name|new_val
operator|=
name|sched_quantum
operator|*
name|tick
expr_stmt|;
name|error
operator|=
name|sysctl_handle_int
argument_list|(
name|oidp
argument_list|,
operator|&
name|new_val
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|error
operator|)
return|;
if|if
condition|(
name|new_val
operator|<
name|tick
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|sched_quantum
operator|=
name|new_val
operator|/
name|tick
expr_stmt|;
name|hogticks
operator|=
literal|2
operator|*
name|sched_quantum
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_expr_stmt
name|SYSCTL_NODE
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|sched
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|"Scheduler"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_STRING
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|name
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|"4BSD"
argument_list|,
literal|0
argument_list|,
literal|"Scheduler name"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|quantum
argument_list|,
name|CTLTYPE_INT
operator||
name|CTLFLAG_RW
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
name|sched_quantum
argument_list|,
name|sysctl_kern_quantum
argument_list|,
literal|"I"
argument_list|,
literal|"Roundrobin scheduling quantum in microseconds"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/* Enable forwarding of wakeups to all other cpus */
end_comment

begin_expr_stmt
name|SYSCTL_NODE
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|ipiwakeup
argument_list|,
name|CTLFLAG_RD
argument_list|,
name|NULL
argument_list|,
literal|"Kernel SMP"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|runq_fuzz
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|runq_fuzz
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|runq_fuzz
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeup_enabled
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|enabled
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|forward_wakeup_enabled
argument_list|,
literal|0
argument_list|,
literal|"Forwarding of wakeup to idle CPUs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeups_requested
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|requested
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|forward_wakeups_requested
argument_list|,
literal|0
argument_list|,
literal|"Requests for Forwarding of wakeup to idle CPUs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeups_delivered
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|delivered
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|forward_wakeups_delivered
argument_list|,
literal|0
argument_list|,
literal|"Completed Forwarding of wakeup to idle CPUs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeup_use_mask
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|usemask
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|forward_wakeup_use_mask
argument_list|,
literal|0
argument_list|,
literal|"Use the mask of idle cpus"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeup_use_loop
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|useloop
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|forward_wakeup_use_loop
argument_list|,
literal|0
argument_list|,
literal|"Use a loop to find idle cpus"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeup_use_single
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|onecpu
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|forward_wakeup_use_single
argument_list|,
literal|0
argument_list|,
literal|"Only signal one idle cpu"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|forward_wakeup_use_htt
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched_ipiwakeup
argument_list|,
name|OID_AUTO
argument_list|,
name|htt2
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|forward_wakeup_use_htt
argument_list|,
literal|0
argument_list|,
literal|"account for htt"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_if
if|#
directive|if
literal|0
end_if

begin_endif
unit|static int sched_followon = 0; SYSCTL_INT(_kern_sched, OID_AUTO, followon, CTLFLAG_RW,&sched_followon, 0, 	   "allow threads to share a quantum");
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|__inline
name|void
name|sched_load_add
parameter_list|(
name|void
parameter_list|)
block|{
name|sched_tdcnt
operator|++
expr_stmt|;
name|KTR_COUNTER0
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"load"
argument_list|,
literal|"global load"
argument_list|,
name|sched_tdcnt
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|sched_load_rem
parameter_list|(
name|void
parameter_list|)
block|{
name|sched_tdcnt
operator|--
expr_stmt|;
name|KTR_COUNTER0
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"load"
argument_list|,
literal|"global load"
argument_list|,
name|sched_tdcnt
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Arrange to reschedule if necessary, taking the priorities and  * schedulers into account.  */
end_comment

begin_function
specifier|static
name|void
name|maybe_resched
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<
name|curthread
operator|->
name|td_priority
condition|)
name|curthread
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This function is called when a thread is about to be put on run queue  * because it has been made runnable or its priority has been adjusted.  It  * determines if the new thread should be immediately preempted to.  If so,  * it switches to it and eventually returns true.  If not, it returns false  * so that the caller may place the thread on an appropriate run queue.  */
end_comment

begin_function
name|int
name|maybe_preempt
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|PREEMPTION
name|struct
name|thread
modifier|*
name|ctd
decl_stmt|;
name|int
name|cpri
decl_stmt|,
name|pri
decl_stmt|;
comment|/* 	 * The new thread should not preempt the current thread if any of the 	 * following conditions are true: 	 * 	 *  - The kernel is in the throes of crashing (panicstr). 	 *  - The current thread has a higher (numerically lower) or 	 *    equivalent priority.  Note that this prevents curthread from 	 *    trying to preempt to itself. 	 *  - It is too early in the boot for context switches (cold is set). 	 *  - The current thread has an inhibitor set or is in the process of 	 *    exiting.  In this case, the current thread is about to switch 	 *    out anyways, so there's no point in preempting.  If we did, 	 *    the current thread would not be properly resumed as well, so 	 *    just avoid that whole landmine. 	 *  - If the new thread's priority is not a realtime priority and 	 *    the current thread's priority is not an idle priority and 	 *    FULL_PREEMPTION is disabled. 	 * 	 * If all of these conditions are false, but the current thread is in 	 * a nested critical section, then we have to defer the preemption 	 * until we exit the critical section.  Otherwise, switch immediately 	 * to the new thread. 	 */
name|ctd
operator|=
name|curthread
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|td
operator|->
name|td_inhibitors
operator|==
literal|0
operator|)
argument_list|,
operator|(
literal|"maybe_preempt: trying to run inhibited thread"
operator|)
argument_list|)
expr_stmt|;
name|pri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|cpri
operator|=
name|ctd
operator|->
name|td_priority
expr_stmt|;
if|if
condition|(
name|panicstr
operator|!=
name|NULL
operator|||
name|pri
operator|>=
name|cpri
operator|||
name|cold
comment|/* || dumping */
operator|||
name|TD_IS_INHIBITED
argument_list|(
name|ctd
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
ifndef|#
directive|ifndef
name|FULL_PREEMPTION
if|if
condition|(
name|pri
operator|>
name|PRI_MAX_ITHD
operator|&&
name|cpri
operator|<
name|PRI_MIN_IDLE
condition|)
return|return
operator|(
literal|0
operator|)
return|;
endif|#
directive|endif
if|if
condition|(
name|ctd
operator|->
name|td_critnest
operator|>
literal|1
condition|)
block|{
name|CTR1
argument_list|(
name|KTR_PROC
argument_list|,
literal|"maybe_preempt: in critical section %d"
argument_list|,
name|ctd
operator|->
name|td_critnest
argument_list|)
expr_stmt|;
name|ctd
operator|->
name|td_owepreempt
operator|=
literal|1
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
comment|/* 	 * Thread is runnable but not yet put on system run queue. 	 */
name|MPASS
argument_list|(
name|ctd
operator|->
name|td_lock
operator|==
name|td
operator|->
name|td_lock
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
argument_list|)
expr_stmt|;
name|TD_SET_RUNNING
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PROC
argument_list|,
literal|"preempting to thread %p (pid %d, %s)\n"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_pid
argument_list|,
name|td
operator|->
name|td_name
argument_list|)
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_INVOL
operator||
name|SW_PREEMPT
operator||
name|SWT_PREEMPT
argument_list|,
name|td
argument_list|)
expr_stmt|;
comment|/* 	 * td's lock pointer may have changed.  We have to return with it 	 * locked. 	 */
name|spinlock_enter
argument_list|()
expr_stmt|;
name|thread_unlock
argument_list|(
name|ctd
argument_list|)
expr_stmt|;
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|spinlock_exit
argument_list|()
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
else|#
directive|else
return|return
operator|(
literal|0
operator|)
return|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  * Constants for digital decay and forget:  *	90% of (td_estcpu) usage in 5 * loadav time  *	95% of (ts_pctcpu) usage in 60 seconds (load insensitive)  *          Note that, as ps(1) mentions, this can let percentages  *          total over 100% (I've seen 137.9% for 3 processes).  *  * Note that schedclock() updates td_estcpu and p_cpticks asynchronously.  *  * We wish to decay away 90% of td_estcpu in (5 * loadavg) seconds.  * That is, the system wants to compute a value of decay such  * that the following for loop:  * 	for (i = 0; i< (5 * loadavg); i++)  * 		td_estcpu *= decay;  * will compute  * 	td_estcpu *= 0.1;  * for all values of loadavg:  *  * Mathematically this loop can be expressed by saying:  * 	decay ** (5 * loadavg) ~= .1  *  * The system computes decay as:  * 	decay = (2 * loadavg) / (2 * loadavg + 1)  *  * We wish to prove that the system's computation of decay  * will always fulfill the equation:  * 	decay ** (5 * loadavg) ~= .1  *  * If we compute b as:  * 	b = 2 * loadavg  * then  * 	decay = b / (b + 1)  *  * We now need to prove two things:  *	1) Given factor ** (5 * loadavg) ~= .1, prove factor == b/(b+1)  *	2) Given b/(b+1) ** power ~= .1, prove power == (5 * loadavg)  *  * Facts:  *         For x close to zero, exp(x) =~ 1 + x, since  *              exp(x) = 0! + x**1/1! + x**2/2! + ... .  *              therefore exp(-1/b) =~ 1 - (1/b) = (b-1)/b.  *         For x close to zero, ln(1+x) =~ x, since  *              ln(1+x) = x - x**2/2 + x**3/3 - ...     -1< x< 1  *              therefore ln(b/(b+1)) = ln(1 - 1/(b+1)) =~ -1/(b+1).  *         ln(.1) =~ -2.30  *  * Proof of (1):  *    Solve (factor)**(power) =~ .1 given power (5*loadav):  *	solving for factor,  *      ln(factor) =~ (-2.30/5*loadav), or  *      factor =~ exp(-1/((5/2.30)*loadav)) =~ exp(-1/(2*loadav)) =  *          exp(-1/b) =~ (b-1)/b =~ b/(b+1).                    QED  *  * Proof of (2):  *    Solve (factor)**(power) =~ .1 given factor == (b/(b+1)):  *	solving for power,  *      power*ln(b/(b+1)) =~ -2.30, or  *      power =~ 2.3 * (b + 1) = 4.6*loadav + 2.3 =~ 5*loadav.  QED  *  * Actual power values for the implemented algorithm are as follows:  *      loadav: 1       2       3       4  *      power:  5.68    10.32   14.94   19.55  */
end_comment

begin_comment
comment|/* calculations for digital decay to forget 90% of usage in 5*loadav sec */
end_comment

begin_define
define|#
directive|define
name|loadfactor
parameter_list|(
name|loadav
parameter_list|)
value|(2 * (loadav))
end_define

begin_define
define|#
directive|define
name|decay_cpu
parameter_list|(
name|loadfac
parameter_list|,
name|cpu
parameter_list|)
value|(((loadfac) * (cpu)) / ((loadfac) + FSCALE))
end_define

begin_comment
comment|/* decay 95% of `ts_pctcpu' in 60 seconds; see CCPU_SHIFT before changing */
end_comment

begin_decl_stmt
specifier|static
name|fixpt_t
name|ccpu
init|=
literal|0.95122942450071400909
operator|*
name|FSCALE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* exp(-1/20) */
end_comment

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|ccpu
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ccpu
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * If `ccpu' is not equal to `exp(-1/20)' and you still want to use the  * faster/more-accurate formula, you'll have to estimate CCPU_SHIFT below  * and possibly adjust FSHIFT in "param.h" so that (FSHIFT>= CCPU_SHIFT).  *  * To estimate CCPU_SHIFT for exp(-1/20), the following formula was used:  *	1 - exp(-1/20) ~= 0.0487 ~= 0.0488 == 1 (fixed pt, *11* bits).  *  * If you don't want to bother with the faster/more-accurate formula, you  * can set CCPU_SHIFT to (FSHIFT + 1) which will use a slower/less-accurate  * (more general) method of calculating the %age of CPU used by a process.  */
end_comment

begin_define
define|#
directive|define
name|CCPU_SHIFT
value|11
end_define

begin_comment
comment|/*  * Recompute process priorities, every hz ticks.  * MP-safe, called without the Giant mutex.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|schedcpu
parameter_list|(
name|void
parameter_list|)
block|{
specifier|register
name|fixpt_t
name|loadfac
init|=
name|loadfactor
argument_list|(
name|averunnable
operator|.
name|ldavg
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|awake
decl_stmt|,
name|realstathz
decl_stmt|;
name|realstathz
operator|=
name|stathz
condition|?
name|stathz
else|:
name|hz
expr_stmt|;
name|sx_slock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
name|FOREACH_PROC_IN_SYSTEM
argument_list|(
argument|p
argument_list|)
block|{
name|PROC_LOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
name|awake
operator|=
literal|0
expr_stmt|;
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
comment|/* 			 * Increment sleep time (if sleeping).  We 			 * ignore overflow, as above. 			 */
comment|/* 			 * The td_sched slptimes are not touched in wakeup 			 * because the thread may not HAVE everything in 			 * memory? XXX I think this is out of date. 			 */
if|if
condition|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|awake
operator|=
literal|1
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_DIDRUN
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|awake
operator|=
literal|1
expr_stmt|;
comment|/* Do not clear TDF_DIDRUN */
block|}
elseif|else
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_DIDRUN
condition|)
block|{
name|awake
operator|=
literal|1
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_DIDRUN
expr_stmt|;
block|}
comment|/* 			 * ts_pctcpu is only for ps and ttyinfo(). 			 */
name|ts
operator|->
name|ts_pctcpu
operator|=
operator|(
name|ts
operator|->
name|ts_pctcpu
operator|*
name|ccpu
operator|)
operator|>>
name|FSHIFT
expr_stmt|;
comment|/* 			 * If the td_sched has been idle the entire second, 			 * stop recalculating its priority until 			 * it wakes up. 			 */
if|if
condition|(
name|ts
operator|->
name|ts_cpticks
operator|!=
literal|0
condition|)
block|{
if|#
directive|if
operator|(
name|FSHIFT
operator|>=
name|CCPU_SHIFT
operator|)
name|ts
operator|->
name|ts_pctcpu
operator|+=
operator|(
name|realstathz
operator|==
literal|100
operator|)
condition|?
operator|(
operator|(
name|fixpt_t
operator|)
name|ts
operator|->
name|ts_cpticks
operator|)
operator|<<
operator|(
name|FSHIFT
operator|-
name|CCPU_SHIFT
operator|)
else|:
literal|100
operator|*
operator|(
operator|(
operator|(
name|fixpt_t
operator|)
name|ts
operator|->
name|ts_cpticks
operator|)
operator|<<
operator|(
name|FSHIFT
operator|-
name|CCPU_SHIFT
operator|)
operator|)
operator|/
name|realstathz
expr_stmt|;
else|#
directive|else
name|ts
operator|->
name|ts_pctcpu
operator|+=
operator|(
operator|(
name|FSCALE
operator|-
name|ccpu
operator|)
operator|*
operator|(
name|ts
operator|->
name|ts_cpticks
operator|*
name|FSCALE
operator|/
name|realstathz
operator|)
operator|)
operator|>>
name|FSHIFT
expr_stmt|;
endif|#
directive|endif
name|ts
operator|->
name|ts_cpticks
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 			 * If there are ANY running threads in this process, 			 * then don't count it as sleeping. 			 * XXX: this is broken. 			 */
if|if
condition|(
name|awake
condition|)
block|{
if|if
condition|(
name|ts
operator|->
name|ts_slptime
operator|>
literal|1
condition|)
block|{
comment|/* 					 * In an ideal world, this should not 					 * happen, because whoever woke us 					 * up from the long sleep should have 					 * unwound the slptime and reset our 					 * priority before we run at the stale 					 * priority.  Should KASSERT at some 					 * point when all the cases are fixed. 					 */
name|updatepri
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
name|ts
operator|->
name|ts_slptime
operator|=
literal|0
expr_stmt|;
block|}
else|else
name|ts
operator|->
name|ts_slptime
operator|++
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_slptime
operator|>
literal|1
condition|)
block|{
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|td
operator|->
name|td_estcpu
operator|=
name|decay_cpu
argument_list|(
name|loadfac
argument_list|,
name|td
operator|->
name|td_estcpu
argument_list|)
expr_stmt|;
name|resetpriority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|resetpriority_thread
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Main loop for a kthread that executes schedcpu once a second.  */
end_comment

begin_function
specifier|static
name|void
name|schedcpu_thread
parameter_list|(
name|void
parameter_list|)
block|{
for|for
control|(
init|;
condition|;
control|)
block|{
name|schedcpu
argument_list|()
expr_stmt|;
name|pause
argument_list|(
literal|"-"
argument_list|,
name|hz
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Recalculate the priority of a process after it has slept for a while.  * For all load averages>= 1 and max td_estcpu of 255, sleeping for at  * least six times the loadfactor will decay td_estcpu to zero.  */
end_comment

begin_function
specifier|static
name|void
name|updatepri
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|fixpt_t
name|loadfac
decl_stmt|;
name|unsigned
name|int
name|newcpu
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|loadfac
operator|=
name|loadfactor
argument_list|(
name|averunnable
operator|.
name|ldavg
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_slptime
operator|>
literal|5
operator|*
name|loadfac
condition|)
name|td
operator|->
name|td_estcpu
operator|=
literal|0
expr_stmt|;
else|else
block|{
name|newcpu
operator|=
name|td
operator|->
name|td_estcpu
expr_stmt|;
name|ts
operator|->
name|ts_slptime
operator|--
expr_stmt|;
comment|/* was incremented in schedcpu() */
while|while
condition|(
name|newcpu
operator|&&
operator|--
name|ts
operator|->
name|ts_slptime
condition|)
name|newcpu
operator|=
name|decay_cpu
argument_list|(
name|loadfac
argument_list|,
name|newcpu
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_estcpu
operator|=
name|newcpu
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Compute the priority of a process when running in user mode.  * Arrange to reschedule if the resulting priority is better  * than that of the current process.  */
end_comment

begin_function
specifier|static
name|void
name|resetpriority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
specifier|register
name|unsigned
name|int
name|newpriority
decl_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
block|{
name|newpriority
operator|=
name|PUSER
operator|+
name|td
operator|->
name|td_estcpu
operator|/
name|INVERSE_ESTCPU_WEIGHT
operator|+
name|NICE_WEIGHT
operator|*
operator|(
name|td
operator|->
name|td_proc
operator|->
name|p_nice
operator|-
name|PRIO_MIN
operator|)
expr_stmt|;
name|newpriority
operator|=
name|min
argument_list|(
name|max
argument_list|(
name|newpriority
argument_list|,
name|PRI_MIN_TIMESHARE
argument_list|)
argument_list|,
name|PRI_MAX_TIMESHARE
argument_list|)
expr_stmt|;
name|sched_user_prio
argument_list|(
name|td
argument_list|,
name|newpriority
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Update the thread's priority when the associated process's user  * priority changes.  */
end_comment

begin_function
specifier|static
name|void
name|resetpriority_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
comment|/* Only change threads with a time sharing user priority. */
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<
name|PRI_MIN_TIMESHARE
operator|||
name|td
operator|->
name|td_priority
operator|>
name|PRI_MAX_TIMESHARE
condition|)
return|return;
comment|/* XXX the whole needresched thing is broken, but not silly. */
name|maybe_resched
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_prio
argument_list|(
name|td
argument_list|,
name|td
operator|->
name|td_user_pri
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|setup_runqs
argument_list|()
expr_stmt|;
if|if
condition|(
name|sched_quantum
operator|==
literal|0
condition|)
name|sched_quantum
operator|=
name|SCHED_QUANTUM
expr_stmt|;
name|hogticks
operator|=
literal|2
operator|*
name|sched_quantum
expr_stmt|;
comment|/* Account for thread0. */
name|sched_load_add
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/* External interfaces start here */
end_comment

begin_comment
comment|/*  * Very early in the boot some setup of scheduler-specific  * parts of proc0 and of some scheduler resources needs to be done.  * Called from:  *  proc0_init()  */
end_comment

begin_function
name|void
name|schedinit
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * Set up the scheduler specific parts of proc0. 	 */
name|proc0
operator|.
name|p_sched
operator|=
name|NULL
expr_stmt|;
comment|/* XXX */
name|thread0
operator|.
name|td_sched
operator|=
operator|&
name|td_sched0
expr_stmt|;
name|thread0
operator|.
name|td_lock
operator|=
operator|&
name|sched_lock
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|sched_lock
argument_list|,
literal|"sched lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_SPIN
operator||
name|MTX_RECURSE
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|sched_runnable
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
return|return
name|runq_check
argument_list|(
operator|&
name|runq
argument_list|)
operator|+
name|runq_check
argument_list|(
operator|&
name|runq_pcpu
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
argument_list|)
return|;
else|#
directive|else
return|return
name|runq_check
argument_list|(
operator|&
name|runq
argument_list|)
return|;
endif|#
directive|endif
block|}
end_function

begin_function
name|int
name|sched_rr_interval
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|sched_quantum
operator|==
literal|0
condition|)
name|sched_quantum
operator|=
name|SCHED_QUANTUM
expr_stmt|;
return|return
operator|(
name|sched_quantum
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * We adjust the priority of the current process.  The priority of  * a process gets worse as it accumulates CPU time.  The cpu usage  * estimator (td_estcpu) is increased here.  resetpriority() will  * compute a different priority each time td_estcpu increases by  * INVERSE_ESTCPU_WEIGHT  * (until MAXPRI is reached).  The cpu usage estimator ramps up  * quite quickly when the process is running (linearly), and decays  * away exponentially, at a rate which is proportionally slower when  * the system is busy.  The basic principle is that the system will  * 90% forget that the process used a lot of CPU time in 5 * loadav  * seconds.  This causes the system to favor processes which haven't  * run much recently, and to round-robin among other processes.  */
end_comment

begin_function
name|void
name|sched_clock
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|ts
operator|->
name|ts_cpticks
operator|++
expr_stmt|;
name|td
operator|->
name|td_estcpu
operator|=
name|ESTCPULIM
argument_list|(
name|td
operator|->
name|td_estcpu
operator|+
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|td
operator|->
name|td_estcpu
operator|%
name|INVERSE_ESTCPU_WEIGHT
operator|)
operator|==
literal|0
condition|)
block|{
name|resetpriority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|resetpriority_thread
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Force a context switch if the current thread has used up a full 	 * quantum (default quantum is 100ms). 	 */
if|if
condition|(
operator|!
name|TD_IS_IDLETHREAD
argument_list|(
name|td
argument_list|)
operator|&&
name|ticks
operator|-
name|PCPU_GET
argument_list|(
name|switchticks
argument_list|)
operator|>=
name|sched_quantum
condition|)
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Charge child's scheduling CPU usage to parent.  */
end_comment

begin_function
name|void
name|sched_exit
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|KTR_STATE1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|,
literal|"proc exit"
argument_list|,
literal|"prio:td"
argument_list|,
name|td
operator|->
name|td_priority
argument_list|)
expr_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|sched_exit_thread
argument_list|(
name|FIRST_THREAD_IN_PROC
argument_list|(
name|p
argument_list|)
argument_list|,
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_exit_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|KTR_STATE1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|child
argument_list|)
argument_list|,
literal|"exit"
argument_list|,
literal|"prio:td"
argument_list|,
name|child
operator|->
name|td_priority
argument_list|)
expr_stmt|;
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_estcpu
operator|=
name|ESTCPULIM
argument_list|(
name|td
operator|->
name|td_estcpu
operator|+
name|child
operator|->
name|td_estcpu
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|thread_lock
argument_list|(
name|child
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|child
operator|->
name|td_flags
operator|&
name|TDF_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_rem
argument_list|()
expr_stmt|;
name|thread_unlock
argument_list|(
name|child
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_fork
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|childtd
parameter_list|)
block|{
name|sched_fork_thread
argument_list|(
name|td
argument_list|,
name|childtd
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_fork_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|childtd
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|childtd
operator|->
name|td_estcpu
operator|=
name|td
operator|->
name|td_estcpu
expr_stmt|;
name|childtd
operator|->
name|td_lock
operator|=
operator|&
name|sched_lock
expr_stmt|;
name|childtd
operator|->
name|td_cpuset
operator|=
name|cpuset_ref
argument_list|(
name|td
operator|->
name|td_cpuset
argument_list|)
expr_stmt|;
name|ts
operator|=
name|childtd
operator|->
name|td_sched
expr_stmt|;
name|bzero
argument_list|(
name|ts
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|ts
argument_list|)
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator||=
operator|(
name|td
operator|->
name|td_sched
operator|->
name|ts_flags
operator|&
name|TSF_AFFINITY
operator|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_nice
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|int
name|nice
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|p
operator|->
name|p_nice
operator|=
name|nice
expr_stmt|;
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|resetpriority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|resetpriority_thread
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|sched_class
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|class
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_pri_class
operator|=
name|class
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Adjust the priority of a thread.  */
end_comment

begin_function
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|KTR_POINT3
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|,
literal|"priority change"
argument_list|,
literal|"prio:%d"
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
literal|"new prio:%d"
argument_list|,
name|prio
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|curthread
operator|&&
name|prio
operator|>
name|td
operator|->
name|td_priority
condition|)
block|{
name|KTR_POINT3
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|,
literal|"lend prio"
argument_list|,
literal|"prio:%d"
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
literal|"new prio:%d"
argument_list|,
name|prio
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|==
name|prio
condition|)
return|return;
name|td
operator|->
name|td_priority
operator|=
name|prio
expr_stmt|;
if|if
condition|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
operator|&&
name|td
operator|->
name|td_rqindex
operator|!=
operator|(
name|prio
operator|/
name|RQ_PPQ
operator|)
condition|)
block|{
name|sched_rem
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_add
argument_list|(
name|td
argument_list|,
name|SRQ_BORING
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Update a thread's priority when it is lent another thread's  * priority.  */
end_comment

begin_function
name|void
name|sched_lend_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|td
operator|->
name|td_flags
operator||=
name|TDF_BORROWING
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Restore a thread's priority when priority propagation is  * over.  The prio argument is the minimum priority the thread  * needs to have to satisfy other possible priority lending  * requests.  If the thread's regulary priority is less  * important than prio the thread will keep a priority boost  * of prio.  */
end_comment

begin_function
name|void
name|sched_unlend_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|base_pri
decl_stmt|;
if|if
condition|(
name|td
operator|->
name|td_base_pri
operator|>=
name|PRI_MIN_TIMESHARE
operator|&&
name|td
operator|->
name|td_base_pri
operator|<=
name|PRI_MAX_TIMESHARE
condition|)
name|base_pri
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
else|else
name|base_pri
operator|=
name|td
operator|->
name|td_base_pri
expr_stmt|;
if|if
condition|(
name|prio
operator|>=
name|base_pri
condition|)
block|{
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_BORROWING
expr_stmt|;
name|sched_prio
argument_list|(
name|td
argument_list|,
name|base_pri
argument_list|)
expr_stmt|;
block|}
else|else
name|sched_lend_prio
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
comment|/* First, update the base priority. */
name|td
operator|->
name|td_base_pri
operator|=
name|prio
expr_stmt|;
comment|/* 	 * If the thread is borrowing another thread's priority, don't ever 	 * lower the priority. 	 */
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
operator|&&
name|td
operator|->
name|td_priority
operator|<
name|prio
condition|)
return|return;
comment|/* Change the real priority. */
name|oldprio
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
comment|/* 	 * If the thread is on a turnstile, then let the turnstile update 	 * its state. 	 */
if|if
condition|(
name|TD_ON_LOCK
argument_list|(
name|td
argument_list|)
operator|&&
name|oldprio
operator|!=
name|prio
condition|)
name|turnstile_adjust
argument_list|(
name|td
argument_list|,
name|oldprio
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_base_user_pri
operator|=
name|prio
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_UBORROWING
operator|&&
name|td
operator|->
name|td_user_pri
operator|<=
name|prio
condition|)
return|return;
name|oldprio
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|td
operator|->
name|td_user_pri
operator|=
name|prio
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_lend_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_UBORROWING
expr_stmt|;
name|oldprio
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|td
operator|->
name|td_user_pri
operator|=
name|prio
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_unlend_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|base_pri
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|base_pri
operator|=
name|td
operator|->
name|td_base_user_pri
expr_stmt|;
if|if
condition|(
name|prio
operator|>=
name|base_pri
condition|)
block|{
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_UBORROWING
expr_stmt|;
name|sched_user_prio
argument_list|(
name|td
argument_list|,
name|base_pri
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sched_lend_user_prio
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|sched_sleep
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|pri
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_slptick
operator|=
name|ticks
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_slptime
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|pri
condition|)
name|sched_prio
argument_list|(
name|td
argument_list|,
name|pri
argument_list|)
expr_stmt|;
if|if
condition|(
name|TD_IS_SUSPENDED
argument_list|(
name|td
argument_list|)
operator|||
name|pri
operator|>=
name|PSOCK
condition|)
name|td
operator|->
name|td_flags
operator||=
name|TDF_CANSWAP
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_switch
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|newtd
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|tmtx
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
name|tmtx
operator|=
name|NULL
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|p
operator|=
name|td
operator|->
name|td_proc
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/*  	 * Switch to the sched lock to fix things up and pick 	 * a new thread. 	 * Block the td_lock in order to avoid breaking the critical path. 	 */
if|if
condition|(
name|td
operator|->
name|td_lock
operator|!=
operator|&
name|sched_lock
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|tmtx
operator|=
name|thread_lock_block
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_rem
argument_list|()
expr_stmt|;
if|if
condition|(
name|newtd
condition|)
name|newtd
operator|->
name|td_flags
operator||=
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_NEEDRESCHED
operator|)
expr_stmt|;
name|td
operator|->
name|td_lastcpu
operator|=
name|td
operator|->
name|td_oncpu
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_NEEDRESCHED
expr_stmt|;
name|td
operator|->
name|td_owepreempt
operator|=
literal|0
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|NOCPU
expr_stmt|;
comment|/* 	 * At the last moment, if this thread is still marked RUNNING, 	 * then put it back on the run queue as it has not been suspended 	 * or stopped or any thing else similar.  We never put the idle 	 * threads on the run queue, however. 	 */
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_IDLETD
condition|)
block|{
name|TD_SET_CAN_RUN
argument_list|(
name|td
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|idle_cpus_mask
operator|&=
operator|~
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
else|else
block|{
if|if
condition|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
condition|)
block|{
comment|/* Put us back on the run queue. */
name|sched_add
argument_list|(
name|td
argument_list|,
operator|(
name|flags
operator|&
name|SW_PREEMPT
operator|)
condition|?
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
operator||
name|SRQ_PREEMPTED
else|:
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|newtd
condition|)
block|{
comment|/* 		 * The thread we are about to run needs to be counted 		 * as if it had been added to the run queue and selected. 		 * It came from: 		 * * A preemption 		 * * An upcall 		 * * A followon 		 */
name|KASSERT
argument_list|(
operator|(
name|newtd
operator|->
name|td_inhibitors
operator|==
literal|0
operator|)
argument_list|,
operator|(
literal|"trying to run inhibited thread"
operator|)
argument_list|)
expr_stmt|;
name|newtd
operator|->
name|td_flags
operator||=
name|TDF_DIDRUN
expr_stmt|;
name|TD_SET_RUNNING
argument_list|(
name|newtd
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|newtd
operator|->
name|td_flags
operator|&
name|TDF_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_add
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|newtd
operator|=
name|choosethread
argument_list|()
expr_stmt|;
block|}
name|MPASS
argument_list|(
name|newtd
operator|->
name|td_lock
operator|==
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|newtd
condition|)
block|{
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
if|if
condition|(
name|PMC_PROC_IS_USING_PMCS
argument_list|(
name|td
operator|->
name|td_proc
argument_list|)
condition|)
name|PMC_SWITCH_CONTEXT
argument_list|(
name|td
argument_list|,
name|PMC_FN_CSW_OUT
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* I feel sleepy */
name|lock_profile_release_lock
argument_list|(
operator|&
name|sched_lock
operator|.
name|lock_object
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|KDTRACE_HOOKS
comment|/* 		 * If DTrace has set the active vtime enum to anything 		 * other than INACTIVE (0), then it should have set the 		 * function to call. 		 */
if|if
condition|(
name|dtrace_vtime_active
condition|)
call|(
modifier|*
name|dtrace_vtime_switch_func
call|)
argument_list|(
name|newtd
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|cpu_switch
argument_list|(
name|td
argument_list|,
name|newtd
argument_list|,
name|tmtx
operator|!=
name|NULL
condition|?
name|tmtx
else|:
name|td
operator|->
name|td_lock
argument_list|)
expr_stmt|;
name|lock_profile_obtain_lock_success
argument_list|(
operator|&
name|sched_lock
operator|.
name|lock_object
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|__FILE__
argument_list|,
name|__LINE__
argument_list|)
expr_stmt|;
comment|/* 		 * Where am I?  What year is it? 		 * We are in the same thread that went to sleep above, 		 * but any amount of time may have passed. All our context 		 * will still be available as will local variables. 		 * PCPU values however may have changed as we may have 		 * changed CPU so don't trust cached values of them. 		 * New threads will go to fork_exit() instead of here 		 * so if you change things here you may need to change 		 * things there too. 		 * 		 * If the thread above was exiting it will never wake 		 * up again here, so either it has saved everything it 		 * needed to, or the thread_wait() or wait() will 		 * need to reap it. 		 */
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
if|if
condition|(
name|PMC_PROC_IS_USING_PMCS
argument_list|(
name|td
operator|->
name|td_proc
argument_list|)
condition|)
name|PMC_SWITCH_CONTEXT
argument_list|(
name|td
argument_list|,
name|PMC_FN_CSW_IN
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_IDLETD
condition|)
name|idle_cpus_mask
operator||=
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|sched_lock
operator|.
name|mtx_lock
operator|=
operator|(
name|uintptr_t
operator|)
name|td
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_wakeup
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_CANSWAP
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_slptime
operator|>
literal|1
condition|)
block|{
name|updatepri
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|resetpriority
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
name|td
operator|->
name|td_slptick
operator|=
literal|0
expr_stmt|;
name|ts
operator|->
name|ts_slptime
operator|=
literal|0
expr_stmt|;
name|sched_add
argument_list|(
name|td
argument_list|,
name|SRQ_BORING
argument_list|)
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function
specifier|static
name|int
name|forward_wakeup
parameter_list|(
name|int
name|cpunum
parameter_list|)
block|{
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|cpumask_t
name|dontuse
decl_stmt|,
name|id
decl_stmt|,
name|map
decl_stmt|,
name|map2
decl_stmt|,
name|map3
decl_stmt|,
name|me
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|CTR0
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"forward_wakeup()"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|!
name|forward_wakeup_enabled
operator|)
operator|||
operator|(
name|forward_wakeup_use_mask
operator|==
literal|0
operator|&&
name|forward_wakeup_use_loop
operator|==
literal|0
operator|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|if
condition|(
operator|!
name|smp_started
operator|||
name|cold
operator|||
name|panicstr
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|forward_wakeups_requested
operator|++
expr_stmt|;
comment|/* 	 * Check the idle mask we received against what we calculated 	 * before in the old version. 	 */
name|me
operator|=
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
expr_stmt|;
comment|/* Don't bother if we should be doing it ourself. */
if|if
condition|(
operator|(
name|me
operator|&
name|idle_cpus_mask
operator|)
operator|&&
operator|(
name|cpunum
operator|==
name|NOCPU
operator|||
name|me
operator|==
operator|(
literal|1
operator|<<
name|cpunum
operator|)
operator|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|dontuse
operator|=
name|me
operator||
name|stopped_cpus
operator||
name|hlt_cpus_mask
expr_stmt|;
name|map3
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|forward_wakeup_use_loop
condition|)
block|{
name|SLIST_FOREACH
argument_list|(
argument|pc
argument_list|,
argument|&cpuhead
argument_list|,
argument|pc_allcpu
argument_list|)
block|{
name|id
operator|=
name|pc
operator|->
name|pc_cpumask
expr_stmt|;
if|if
condition|(
operator|(
name|id
operator|&
name|dontuse
operator|)
operator|==
literal|0
operator|&&
name|pc
operator|->
name|pc_curthread
operator|==
name|pc
operator|->
name|pc_idlethread
condition|)
block|{
name|map3
operator||=
name|id
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|forward_wakeup_use_mask
condition|)
block|{
name|map
operator|=
literal|0
expr_stmt|;
name|map
operator|=
name|idle_cpus_mask
operator|&
operator|~
name|dontuse
expr_stmt|;
comment|/* If they are both on, compare and use loop if different. */
if|if
condition|(
name|forward_wakeup_use_loop
condition|)
block|{
if|if
condition|(
name|map
operator|!=
name|map3
condition|)
block|{
name|printf
argument_list|(
literal|"map (%02X) != map3 (%02X)\n"
argument_list|,
name|map
argument_list|,
name|map3
argument_list|)
expr_stmt|;
name|map
operator|=
name|map3
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|map
operator|=
name|map3
expr_stmt|;
block|}
comment|/* If we only allow a specific CPU, then mask off all the others. */
if|if
condition|(
name|cpunum
operator|!=
name|NOCPU
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|cpunum
operator|<=
name|mp_maxcpus
operator|)
argument_list|,
operator|(
literal|"forward_wakeup: bad cpunum."
operator|)
argument_list|)
expr_stmt|;
name|map
operator|&=
operator|(
literal|1
operator|<<
name|cpunum
operator|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Try choose an idle die. */
if|if
condition|(
name|forward_wakeup_use_htt
condition|)
block|{
name|map2
operator|=
operator|(
name|map
operator|&
operator|(
name|map
operator|>>
literal|1
operator|)
operator|)
operator|&
literal|0x5555
expr_stmt|;
if|if
condition|(
name|map2
condition|)
block|{
name|map
operator|=
name|map2
expr_stmt|;
block|}
block|}
comment|/* Set only one bit. */
if|if
condition|(
name|forward_wakeup_use_single
condition|)
block|{
name|map
operator|=
name|map
operator|&
operator|(
operator|(
operator|~
name|map
operator|)
operator|+
literal|1
operator|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|map
condition|)
block|{
name|forward_wakeups_delivered
operator|++
expr_stmt|;
name|ipi_selected
argument_list|(
name|map
argument_list|,
name|IPI_AST
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
if|if
condition|(
name|cpunum
operator|==
name|NOCPU
condition|)
name|printf
argument_list|(
literal|"forward_wakeup: Idle processor not found\n"
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|kick_other_cpu
parameter_list|(
name|int
name|pri
parameter_list|,
name|int
name|cpuid
parameter_list|)
block|{
name|struct
name|pcpu
modifier|*
name|pcpu
decl_stmt|;
name|int
name|cpri
decl_stmt|;
name|pcpu
operator|=
name|pcpu_find
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
if|if
condition|(
name|idle_cpus_mask
operator|&
name|pcpu
operator|->
name|pc_cpumask
condition|)
block|{
name|forward_wakeups_delivered
operator|++
expr_stmt|;
name|ipi_selected
argument_list|(
name|pcpu
operator|->
name|pc_cpumask
argument_list|,
name|IPI_AST
argument_list|)
expr_stmt|;
return|return;
block|}
name|cpri
operator|=
name|pcpu
operator|->
name|pc_curthread
operator|->
name|td_priority
expr_stmt|;
if|if
condition|(
name|pri
operator|>=
name|cpri
condition|)
return|return;
if|#
directive|if
name|defined
argument_list|(
name|IPI_PREEMPTION
argument_list|)
operator|&&
name|defined
argument_list|(
name|PREEMPTION
argument_list|)
if|#
directive|if
operator|!
name|defined
argument_list|(
name|FULL_PREEMPTION
argument_list|)
if|if
condition|(
name|pri
operator|<=
name|PRI_MAX_ITHD
condition|)
endif|#
directive|endif
comment|/* ! FULL_PREEMPTION */
block|{
name|ipi_selected
argument_list|(
name|pcpu
operator|->
name|pc_cpumask
argument_list|,
name|IPI_PREEMPT
argument_list|)
expr_stmt|;
return|return;
block|}
endif|#
directive|endif
comment|/* defined(IPI_PREEMPTION)&& defined(PREEMPTION) */
name|pcpu
operator|->
name|pc_curthread
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
name|ipi_selected
argument_list|(
name|pcpu
operator|->
name|pc_cpumask
argument_list|,
name|IPI_AST
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* SMP */
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function
specifier|static
name|int
name|sched_pickcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|int
name|best
decl_stmt|,
name|cpu
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|td
operator|->
name|td_lastcpu
argument_list|)
condition|)
name|best
operator|=
name|td
operator|->
name|td_lastcpu
expr_stmt|;
else|else
name|best
operator|=
name|NOCPU
expr_stmt|;
for|for
control|(
name|cpu
operator|=
literal|0
init|;
name|cpu
operator|<=
name|mp_maxid
condition|;
name|cpu
operator|++
control|)
block|{
if|if
condition|(
name|CPU_ABSENT
argument_list|(
name|cpu
argument_list|)
condition|)
continue|continue;
if|if
condition|(
operator|!
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|cpu
argument_list|)
condition|)
continue|continue;
if|if
condition|(
name|best
operator|==
name|NOCPU
condition|)
name|best
operator|=
name|cpu
expr_stmt|;
elseif|else
if|if
condition|(
name|runq_length
index|[
name|cpu
index|]
operator|<
name|runq_length
index|[
name|best
index|]
condition|)
name|best
operator|=
name|cpu
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|best
operator|!=
name|NOCPU
argument_list|,
operator|(
literal|"no valid CPUs"
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|best
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
name|void
name|sched_add
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
ifdef|#
directive|ifdef
name|SMP
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|forwarded
init|=
literal|0
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|int
name|single_cpu
init|=
literal|0
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|td
operator|->
name|td_inhibitors
operator|==
literal|0
operator|)
argument_list|,
operator|(
literal|"sched_add: trying to run inhibited thread"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|TD_CAN_RUN
argument_list|(
name|td
argument_list|)
operator|||
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
operator|)
argument_list|,
operator|(
literal|"sched_add: bad thread state"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_INMEM
argument_list|,
operator|(
literal|"sched_add: thread swapped out"
operator|)
argument_list|)
expr_stmt|;
name|KTR_STATE2
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|,
literal|"runq add"
argument_list|,
literal|"prio:%d"
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|)
expr_stmt|;
name|KTR_POINT1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|,
literal|"wokeup"
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Now that the thread is moving to the run-queue, set the lock 	 * to the scheduler's lock. 	 */
if|if
condition|(
name|td
operator|->
name|td_lock
operator|!=
operator|&
name|sched_lock
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|thread_lock_set
argument_list|(
name|td
argument_list|,
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
name|TD_SET_RUNQ
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pinned
operator|!=
literal|0
condition|)
block|{
name|cpu
operator|=
name|td
operator|->
name|td_lastcpu
expr_stmt|;
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|runq_pcpu
index|[
name|cpu
index|]
expr_stmt|;
name|single_cpu
operator|=
literal|1
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"sched_add: Put td_sched:%p(td:%p) on cpu%d runq"
argument_list|,
name|ts
argument_list|,
name|td
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BOUND
condition|)
block|{
comment|/* Find CPU from bound runq. */
name|KASSERT
argument_list|(
name|SKE_RUNQ_PCPU
argument_list|(
name|ts
argument_list|)
argument_list|,
operator|(
literal|"sched_add: bound td_sched not on cpu runq"
operator|)
argument_list|)
expr_stmt|;
name|cpu
operator|=
name|ts
operator|->
name|ts_runq
operator|-
operator|&
name|runq_pcpu
index|[
literal|0
index|]
expr_stmt|;
name|single_cpu
operator|=
literal|1
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"sched_add: Put td_sched:%p(td:%p) on cpu%d runq"
argument_list|,
name|ts
argument_list|,
name|td
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_AFFINITY
condition|)
block|{
comment|/* Find a valid CPU for our cpuset */
name|cpu
operator|=
name|sched_pickcpu
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|runq_pcpu
index|[
name|cpu
index|]
expr_stmt|;
name|single_cpu
operator|=
literal|1
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"sched_add: Put td_sched:%p(td:%p) on cpu%d runq"
argument_list|,
name|ts
argument_list|,
name|td
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|CTR2
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"sched_add: adding td_sched:%p (td:%p) to gbl runq"
argument_list|,
name|ts
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|cpu
operator|=
name|NOCPU
expr_stmt|;
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|runq
expr_stmt|;
block|}
if|if
condition|(
name|single_cpu
operator|&&
operator|(
name|cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
operator|)
condition|)
block|{
name|kick_other_cpu
argument_list|(
name|td
operator|->
name|td_priority
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|single_cpu
condition|)
block|{
name|cpumask_t
name|me
init|=
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
decl_stmt|;
name|cpumask_t
name|idle
init|=
name|idle_cpus_mask
operator|&
name|me
decl_stmt|;
if|if
condition|(
operator|!
name|idle
operator|&&
operator|(
operator|(
name|flags
operator|&
name|SRQ_INTR
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|idle_cpus_mask
operator|&
operator|~
operator|(
name|hlt_cpus_mask
operator||
name|me
operator|)
operator|)
condition|)
name|forwarded
operator|=
name|forward_wakeup
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|forwarded
condition|)
block|{
if|if
condition|(
operator|(
name|flags
operator|&
name|SRQ_YIELDING
operator|)
operator|==
literal|0
operator|&&
name|maybe_preempt
argument_list|(
name|td
argument_list|)
condition|)
return|return;
else|else
name|maybe_resched
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_add
argument_list|()
expr_stmt|;
name|runq_add
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
operator|!=
name|NOCPU
condition|)
name|runq_length
index|[
name|cpu
index|]
operator|++
expr_stmt|;
block|}
end_function

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* SMP */
end_comment

begin_block
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|td
operator|->
name|td_inhibitors
operator|==
literal|0
operator|)
argument_list|,
operator|(
literal|"sched_add: trying to run inhibited thread"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|TD_CAN_RUN
argument_list|(
name|td
argument_list|)
operator|||
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
operator|)
argument_list|,
operator|(
literal|"sched_add: bad thread state"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_INMEM
argument_list|,
operator|(
literal|"sched_add: thread swapped out"
operator|)
argument_list|)
expr_stmt|;
name|KTR_STATE2
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|,
literal|"runq add"
argument_list|,
literal|"prio:%d"
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|)
expr_stmt|;
name|KTR_POINT1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|,
literal|"wokeup"
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Now that the thread is moving to the run-queue, set the lock 	 * to the scheduler's lock. 	 */
if|if
condition|(
name|td
operator|->
name|td_lock
operator|!=
operator|&
name|sched_lock
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|thread_lock_set
argument_list|(
name|td
argument_list|,
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
name|TD_SET_RUNQ
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"sched_add: adding td_sched:%p (td:%p) to runq"
argument_list|,
name|ts
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|runq
expr_stmt|;
comment|/* 	 * If we are yielding (on the way out anyhow) or the thread 	 * being saved is US, then don't try be smart about preemption 	 * or kicking off another CPU as it won't help and may hinder. 	 * In the YIEDLING case, we are about to run whoever is being 	 * put in the queue anyhow, and in the OURSELF case, we are 	 * puting ourself on the run queue which also only happens 	 * when we are about to yield. 	 */
if|if
condition|(
operator|(
name|flags
operator|&
name|SRQ_YIELDING
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|maybe_preempt
argument_list|(
name|td
argument_list|)
condition|)
return|return;
block|}
if|if
condition|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_add
argument_list|()
expr_stmt|;
name|runq_add
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|maybe_resched
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* SMP */
end_comment

begin_function
name|void
name|sched_rem
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_INMEM
argument_list|,
operator|(
literal|"sched_rem: thread swapped out"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
argument_list|,
operator|(
literal|"sched_rem: thread not on run queue"
operator|)
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KTR_STATE2
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|,
literal|"runq rem"
argument_list|,
literal|"prio:%d"
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|sched_load_rem
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|ts
operator|->
name|ts_runq
operator|!=
operator|&
name|runq
condition|)
name|runq_length
index|[
name|ts
operator|->
name|ts_runq
operator|-
name|runq_pcpu
index|]
operator|--
expr_stmt|;
endif|#
directive|endif
name|runq_remove
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|TD_SET_CAN_RUN
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Select threads to run.  Note that running threads still consume a  * slot.  */
end_comment

begin_function
name|struct
name|thread
modifier|*
name|sched_choose
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|runq
modifier|*
name|rq
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|struct
name|thread
modifier|*
name|tdcpu
decl_stmt|;
name|rq
operator|=
operator|&
name|runq
expr_stmt|;
name|td
operator|=
name|runq_choose_fuzz
argument_list|(
operator|&
name|runq
argument_list|,
name|runq_fuzz
argument_list|)
expr_stmt|;
name|tdcpu
operator|=
name|runq_choose
argument_list|(
operator|&
name|runq_pcpu
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|==
name|NULL
operator|||
operator|(
name|tdcpu
operator|!=
name|NULL
operator|&&
name|tdcpu
operator|->
name|td_priority
operator|<
name|td
operator|->
name|td_priority
operator|)
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"choosing td %p from pcpu runq %d"
argument_list|,
name|tdcpu
argument_list|,
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|)
expr_stmt|;
name|td
operator|=
name|tdcpu
expr_stmt|;
name|rq
operator|=
operator|&
name|runq_pcpu
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
expr_stmt|;
block|}
else|else
block|{
name|CTR1
argument_list|(
name|KTR_RUNQ
argument_list|,
literal|"choosing td_sched %p from main runq"
argument_list|,
name|td
argument_list|)
expr_stmt|;
block|}
else|#
directive|else
name|rq
operator|=
operator|&
name|runq
expr_stmt|;
name|td
operator|=
name|runq_choose
argument_list|(
operator|&
name|runq
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|td
condition|)
block|{
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|td
operator|==
name|tdcpu
condition|)
name|runq_length
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
operator|--
expr_stmt|;
endif|#
directive|endif
name|runq_remove
argument_list|(
name|rq
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_DIDRUN
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_INMEM
argument_list|,
operator|(
literal|"sched_choose: thread swapped out"
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|td
operator|)
return|;
block|}
return|return
operator|(
name|PCPU_GET
argument_list|(
name|idlethread
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_preempt
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_critnest
operator|>
literal|1
condition|)
name|td
operator|->
name|td_owepreempt
operator|=
literal|1
expr_stmt|;
else|else
name|mi_switch
argument_list|(
name|SW_INVOL
operator||
name|SW_PREEMPT
operator||
name|SWT_PREEMPT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_userret
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
comment|/* 	 * XXX we cheat slightly on the locking here to avoid locking in 	 * the usual case.  Setting td_priority here is essentially an 	 * incomplete workaround for not setting it properly elsewhere. 	 * Now that some interrupt handlers are threads, not setting it 	 * properly elsewhere can clobber it in the window between setting 	 * it here and returning to user mode, so don't waste time setting 	 * it perfectly here. 	 */
name|KASSERT
argument_list|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"thread with borrowed priority returning to userland"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|!=
name|td
operator|->
name|td_user_pri
condition|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_priority
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|td
operator|->
name|td_base_pri
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|sched_bind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
argument_list|,
operator|(
literal|"sched_bind: cannot bind non-running thread"
operator|)
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_BOUND
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|runq_pcpu
index|[
name|cpu
index|]
expr_stmt|;
if|if
condition|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
operator|==
name|cpu
condition|)
return|return;
name|mi_switch
argument_list|(
name|SW_VOL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|sched_unbind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_BOUND
expr_stmt|;
block|}
end_function

begin_function
name|int
name|sched_is_bound
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BOUND
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_relinquish
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_VOL
operator||
name|SWT_RELINQUISH
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|sched_load
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
name|sched_tdcnt
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_sizeof_proc
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|proc
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_sizeof_thread
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|thread
argument_list|)
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|td_sched
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|fixpt_t
name|sched_pctcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
return|return
operator|(
name|ts
operator|->
name|ts_pctcpu
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_tick
parameter_list|(
name|void
parameter_list|)
block|{ }
end_function

begin_comment
comment|/*  * The actual idle process.  */
end_comment

begin_function
name|void
name|sched_idletd
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
for|for
control|(
init|;
condition|;
control|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|Giant
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
while|while
condition|(
name|sched_runnable
argument_list|()
operator|==
literal|0
condition|)
name|cpu_idle
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_VOL
operator||
name|SWT_IDLE
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * A CPU is entering for the first time or a thread is exiting.  */
end_comment

begin_function
name|void
name|sched_throw
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
comment|/* 	 * Correct spinlock nesting.  The idle thread context that we are 	 * borrowing was created so that it would start out with a single 	 * spin lock (sched_lock) held in fork_trampoline().  Since we've 	 * explicitly acquired locks in this function, the nesting count 	 * is now 2 rather than 1.  Since we are nested, calling 	 * spinlock_exit() will simply adjust the counts without allowing 	 * spin lock using code to interrupt us. 	 */
if|if
condition|(
name|td
operator|==
name|NULL
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|spinlock_exit
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|lock_profile_release_lock
argument_list|(
operator|&
name|sched_lock
operator|.
name|lock_object
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|curthread
operator|->
name|td_md
operator|.
name|md_spinlock_count
operator|==
literal|1
argument_list|,
operator|(
literal|"invalid count"
operator|)
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|switchtime
argument_list|,
name|cpu_ticks
argument_list|()
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|switchticks
argument_list|,
name|ticks
argument_list|)
expr_stmt|;
name|cpu_throw
argument_list|(
name|td
argument_list|,
name|choosethread
argument_list|()
argument_list|)
expr_stmt|;
comment|/* doesn't return */
block|}
end_function

begin_function
name|void
name|sched_fork_exit
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
comment|/* 	 * Finish setting up thread glue so that it begins execution in a 	 * non-nested critical section with sched_lock held but not recursed. 	 */
name|td
operator|->
name|td_oncpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|sched_lock
operator|.
name|mtx_lock
operator|=
operator|(
name|uintptr_t
operator|)
name|td
expr_stmt|;
name|lock_profile_obtain_lock_success
argument_list|(
operator|&
name|sched_lock
operator|.
name|lock_object
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|__FILE__
argument_list|,
name|__LINE__
argument_list|)
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
operator||
name|MA_NOTRECURSED
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|char
modifier|*
name|sched_tdname
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|KTR
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_name
index|[
literal|0
index|]
operator|==
literal|'\0'
condition|)
name|snprintf
argument_list|(
name|ts
operator|->
name|ts_name
argument_list|,
sizeof|sizeof
argument_list|(
name|ts
operator|->
name|ts_name
argument_list|)
argument_list|,
literal|"%s tid %d"
argument_list|,
name|td
operator|->
name|td_name
argument_list|,
name|td
operator|->
name|td_tid
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|->
name|ts_name
operator|)
return|;
else|#
directive|else
return|return
operator|(
name|td
operator|->
name|td_name
operator|)
return|;
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|sched_affinity
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Set the TSF_AFFINITY flag if there is at least one CPU this 	 * thread can't run on. 	 */
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_AFFINITY
expr_stmt|;
for|for
control|(
name|cpu
operator|=
literal|0
init|;
name|cpu
operator|<=
name|mp_maxid
condition|;
name|cpu
operator|++
control|)
block|{
if|if
condition|(
name|CPU_ABSENT
argument_list|(
name|cpu
argument_list|)
condition|)
continue|continue;
if|if
condition|(
operator|!
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|cpu
argument_list|)
condition|)
block|{
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_AFFINITY
expr_stmt|;
break|break;
block|}
block|}
comment|/* 	 * If this thread can run on all CPUs, nothing else to do. 	 */
if|if
condition|(
operator|!
operator|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_AFFINITY
operator|)
condition|)
return|return;
comment|/* Pinned threads and bound threads should be left alone. */
if|if
condition|(
name|td
operator|->
name|td_pinned
operator|!=
literal|0
operator|||
name|td
operator|->
name|td_flags
operator|&
name|TDF_BOUND
condition|)
return|return;
switch|switch
condition|(
name|td
operator|->
name|td_state
condition|)
block|{
case|case
name|TDS_RUNQ
case|:
comment|/* 		 * If we are on a per-CPU runqueue that is in the set, 		 * then nothing needs to be done. 		 */
if|if
condition|(
name|ts
operator|->
name|ts_runq
operator|!=
operator|&
name|runq
operator|&&
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|ts
operator|->
name|ts_runq
operator|-
name|runq_pcpu
argument_list|)
condition|)
return|return;
comment|/* Put this thread on a valid per-CPU runqueue. */
name|sched_rem
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_add
argument_list|(
name|td
argument_list|,
name|SRQ_BORING
argument_list|)
expr_stmt|;
break|break;
case|case
name|TDS_RUNNING
case|:
comment|/* 		 * See if our current CPU is in the set.  If not, force a 		 * context switch. 		 */
if|if
condition|(
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|td
operator|->
name|td_oncpu
argument_list|)
condition|)
return|return;
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|curthread
condition|)
name|ipi_selected
argument_list|(
literal|1
operator|<<
name|cpu
argument_list|,
name|IPI_AST
argument_list|)
expr_stmt|;
break|break;
default|default:
break|break;
block|}
endif|#
directive|endif
block|}
end_function

end_unit

