begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2002-2007, Jeffrey Roberson<jeff@freebsd.org>  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice unmodified, this list of conditions, and the following  *    disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,  * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT  * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,  * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY  * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF  * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  */
end_comment

begin_comment
comment|/*  * This file implements the ULE scheduler.  ULE supports independent CPU  * run queues and fine grain locking.  It has superior interactive  * performance under load even on uni-processor systems.  *  * etymology:  *   ULE is the last three letters in schedule.  It owes its name to a  * generic user created for a scheduling system by Paul Mikesell at  * Isilon Systems and a general lack of creativity on the part of the author.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_hwpmc_hooks.h"
end_include

begin_include
include|#
directive|include
file|"opt_sched.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kdb.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/limits.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/resource.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/sdt.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysproto.h>
end_include

begin_include
include|#
directive|include
file|<sys/turnstile.h>
end_include

begin_include
include|#
directive|include
file|<sys/umtx.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/cpuset.h>
end_include

begin_include
include|#
directive|include
file|<sys/sbuf.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
end_ifdef

begin_include
include|#
directive|include
file|<sys/pmckern.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|KDTRACE_HOOKS
end_ifdef

begin_include
include|#
directive|include
file|<sys/dtrace_bsd.h>
end_include

begin_decl_stmt
name|int
name|dtrace_vtime_active
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|dtrace_vtime_switch_func_t
name|dtrace_vtime_switch_func
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_define
define|#
directive|define
name|KTR_ULE
value|0
end_define

begin_define
define|#
directive|define
name|TS_NAME_LEN
value|(MAXCOMLEN + sizeof(" td ") + sizeof(__XSTRING(UINT_MAX)))
end_define

begin_define
define|#
directive|define
name|TDQ_NAME_LEN
value|(sizeof("sched lock ") + sizeof(__XSTRING(MAXCPU)))
end_define

begin_define
define|#
directive|define
name|TDQ_LOADNAME_LEN
value|(sizeof("CPU ") + sizeof(__XSTRING(MAXCPU)) - 1 + sizeof(" load"))
end_define

begin_comment
comment|/*  * Thread scheduler specific section.  All fields are protected  * by the thread lock.  */
end_comment

begin_struct
struct|struct
name|td_sched
block|{
name|struct
name|runq
modifier|*
name|ts_runq
decl_stmt|;
comment|/* Run-queue we're queued on. */
name|short
name|ts_flags
decl_stmt|;
comment|/* TSF_* flags. */
name|u_char
name|ts_cpu
decl_stmt|;
comment|/* CPU that we have affinity for. */
name|int
name|ts_rltick
decl_stmt|;
comment|/* Real last tick, for affinity. */
name|int
name|ts_slice
decl_stmt|;
comment|/* Ticks of slice remaining. */
name|u_int
name|ts_slptime
decl_stmt|;
comment|/* Number of ticks we vol. slept */
name|u_int
name|ts_runtime
decl_stmt|;
comment|/* Number of ticks we were running */
name|int
name|ts_ltick
decl_stmt|;
comment|/* Last tick that we were running on */
name|int
name|ts_ftick
decl_stmt|;
comment|/* First tick that we were running on */
name|int
name|ts_ticks
decl_stmt|;
comment|/* Tick count */
ifdef|#
directive|ifdef
name|KTR
name|char
name|ts_name
index|[
name|TS_NAME_LEN
index|]
decl_stmt|;
endif|#
directive|endif
block|}
struct|;
end_struct

begin_comment
comment|/* flags kept in ts_flags */
end_comment

begin_define
define|#
directive|define
name|TSF_BOUND
value|0x0001
end_define

begin_comment
comment|/* Thread can not migrate. */
end_comment

begin_define
define|#
directive|define
name|TSF_XFERABLE
value|0x0002
end_define

begin_comment
comment|/* Thread was added as transferable. */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|td_sched
name|td_sched0
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|THREAD_CAN_MIGRATE
parameter_list|(
name|td
parameter_list|)
value|((td)->td_pinned == 0)
end_define

begin_define
define|#
directive|define
name|THREAD_CAN_SCHED
parameter_list|(
name|td
parameter_list|,
name|cpu
parameter_list|)
define|\
value|CPU_ISSET((cpu),&(td)->td_cpuset->cs_mask)
end_define

begin_comment
comment|/*  * Priority ranges used for interactive and non-interactive timeshare  * threads.  The timeshare priorities are split up into four ranges.  * The first range handles interactive threads.  The last three ranges  * (NHALF, x, and NHALF) handle non-interactive threads with the outer  * ranges supporting nice values.  */
end_comment

begin_define
define|#
directive|define
name|PRI_TIMESHARE_RANGE
value|(PRI_MAX_TIMESHARE - PRI_MIN_TIMESHARE + 1)
end_define

begin_define
define|#
directive|define
name|PRI_INTERACT_RANGE
value|((PRI_TIMESHARE_RANGE - SCHED_PRI_NRESV) / 2)
end_define

begin_define
define|#
directive|define
name|PRI_BATCH_RANGE
value|(PRI_TIMESHARE_RANGE - PRI_INTERACT_RANGE)
end_define

begin_define
define|#
directive|define
name|PRI_MIN_INTERACT
value|PRI_MIN_TIMESHARE
end_define

begin_define
define|#
directive|define
name|PRI_MAX_INTERACT
value|(PRI_MIN_TIMESHARE + PRI_INTERACT_RANGE - 1)
end_define

begin_define
define|#
directive|define
name|PRI_MIN_BATCH
value|(PRI_MIN_TIMESHARE + PRI_INTERACT_RANGE)
end_define

begin_define
define|#
directive|define
name|PRI_MAX_BATCH
value|PRI_MAX_TIMESHARE
end_define

begin_comment
comment|/*  * Cpu percentage computation macros and defines.  *  * SCHED_TICK_SECS:	Number of seconds to average the cpu usage across.  * SCHED_TICK_TARG:	Number of hz ticks to average the cpu usage across.  * SCHED_TICK_MAX:	Maximum number of ticks before scaling back.  * SCHED_TICK_SHIFT:	Shift factor to avoid rounding away results.  * SCHED_TICK_HZ:	Compute the number of hz ticks for a given ticks count.  * SCHED_TICK_TOTAL:	Gives the amount of time we've been recording ticks.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_TICK_SECS
value|10
end_define

begin_define
define|#
directive|define
name|SCHED_TICK_TARG
value|(hz * SCHED_TICK_SECS)
end_define

begin_define
define|#
directive|define
name|SCHED_TICK_MAX
value|(SCHED_TICK_TARG + hz)
end_define

begin_define
define|#
directive|define
name|SCHED_TICK_SHIFT
value|10
end_define

begin_define
define|#
directive|define
name|SCHED_TICK_HZ
parameter_list|(
name|ts
parameter_list|)
value|((ts)->ts_ticks>> SCHED_TICK_SHIFT)
end_define

begin_define
define|#
directive|define
name|SCHED_TICK_TOTAL
parameter_list|(
name|ts
parameter_list|)
value|(max((ts)->ts_ltick - (ts)->ts_ftick, hz))
end_define

begin_comment
comment|/*  * These macros determine priorities for non-interactive threads.  They are  * assigned a priority based on their recent cpu utilization as expressed  * by the ratio of ticks to the tick total.  NHALF priorities at the start  * and end of the MIN to MAX timeshare range are only reachable with negative  * or positive nice respectively.  *  * PRI_RANGE:	Priority range for utilization dependent priorities.  * PRI_NRESV:	Number of nice values.  * PRI_TICKS:	Compute a priority in PRI_RANGE from the ticks count and total.  * PRI_NICE:	Determines the part of the priority inherited from nice.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_PRI_NRESV
value|(PRIO_MAX - PRIO_MIN)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_NHALF
value|(SCHED_PRI_NRESV / 2)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_MIN
value|(PRI_MIN_BATCH + SCHED_PRI_NHALF)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_MAX
value|(PRI_MAX_BATCH - SCHED_PRI_NHALF)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_RANGE
value|(SCHED_PRI_MAX - SCHED_PRI_MIN + 1)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_TICKS
parameter_list|(
name|ts
parameter_list|)
define|\
value|(SCHED_TICK_HZ((ts)) /						\     (roundup(SCHED_TICK_TOTAL((ts)), SCHED_PRI_RANGE) / SCHED_PRI_RANGE))
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_NICE
parameter_list|(
name|nice
parameter_list|)
value|(nice)
end_define

begin_comment
comment|/*  * These determine the interactivity of a process.  Interactivity differs from  * cpu utilization in that it expresses the voluntary time slept vs time ran  * while cpu utilization includes all time not running.  This more accurately  * models the intent of the thread.  *  * SLP_RUN_MAX:	Maximum amount of sleep time + run time we'll accumulate  *		before throttling back.  * SLP_RUN_FORK:	Maximum slp+run time to inherit at fork time.  * INTERACT_MAX:	Maximum interactivity value.  Smaller is better.  * INTERACT_THRESH:	Threshold for placement on the current runq.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_SLP_RUN_MAX
value|((hz * 5)<< SCHED_TICK_SHIFT)
end_define

begin_define
define|#
directive|define
name|SCHED_SLP_RUN_FORK
value|((hz / 2)<< SCHED_TICK_SHIFT)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_MAX
value|(100)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_HALF
value|(SCHED_INTERACT_MAX / 2)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_THRESH
value|(30)
end_define

begin_comment
comment|/*  * These parameters determine the slice behavior for batch work.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_SLICE_DEFAULT_DIVISOR
value|10
end_define

begin_comment
comment|/* ~94 ms, 12 stathz ticks. */
end_comment

begin_define
define|#
directive|define
name|SCHED_SLICE_MIN_DIVISOR
value|6
end_define

begin_comment
comment|/* DEFAULT/MIN = ~16 ms. */
end_comment

begin_comment
comment|/* Flags kept in td_flags. */
end_comment

begin_define
define|#
directive|define
name|TDF_SLICEEND
value|TDF_SCHED2
end_define

begin_comment
comment|/* Thread time slice is over. */
end_comment

begin_comment
comment|/*  * tickincr:		Converts a stathz tick into a hz domain scaled by  *			the shift factor.  Without the shift the error rate  *			due to rounding would be unacceptably high.  * realstathz:		stathz is sometimes 0 and run off of hz.  * sched_slice:		Runtime of each thread before rescheduling.  * preempt_thresh:	Priority threshold for preemption and remote IPIs.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|sched_interact
init|=
name|SCHED_INTERACT_THRESH
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|tickincr
init|=
literal|8
operator|<<
name|SCHED_TICK_SHIFT
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|realstathz
init|=
literal|127
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* reset during boot. */
end_comment

begin_decl_stmt
specifier|static
name|int
name|sched_slice
init|=
literal|10
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* reset during boot. */
end_comment

begin_decl_stmt
specifier|static
name|int
name|sched_slice_min
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* reset during boot. */
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|PREEMPTION
end_ifdef

begin_ifdef
ifdef|#
directive|ifdef
name|FULL_PREEMPTION
end_ifdef

begin_decl_stmt
specifier|static
name|int
name|preempt_thresh
init|=
name|PRI_MAX_IDLE
decl_stmt|;
end_decl_stmt

begin_else
else|#
directive|else
end_else

begin_decl_stmt
specifier|static
name|int
name|preempt_thresh
init|=
name|PRI_MIN_KERN
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_else
else|#
directive|else
end_else

begin_decl_stmt
specifier|static
name|int
name|preempt_thresh
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|int
name|static_boost
init|=
name|PRI_MIN_BATCH
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|sched_idlespins
init|=
literal|10000
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|sched_idlespinthresh
init|=
operator|-
literal|1
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * tdq - per processor runqs and statistics.  All fields are protected by the  * tdq_lock.  The load and lowpri may be accessed without to avoid excess  * locking in sched_pickcpu();  */
end_comment

begin_struct
struct|struct
name|tdq
block|{
comment|/*  	 * Ordered to improve efficiency of cpu_search() and switch(). 	 * tdq_lock is padded to avoid false sharing with tdq_load and 	 * tdq_cpu_idle. 	 */
name|struct
name|mtx_padalign
name|tdq_lock
decl_stmt|;
comment|/* run queue lock. */
name|struct
name|cpu_group
modifier|*
name|tdq_cg
decl_stmt|;
comment|/* Pointer to cpu topology. */
specifier|volatile
name|int
name|tdq_load
decl_stmt|;
comment|/* Aggregate load. */
specifier|volatile
name|int
name|tdq_cpu_idle
decl_stmt|;
comment|/* cpu_idle() is active. */
name|int
name|tdq_sysload
decl_stmt|;
comment|/* For loadavg, !ITHD load. */
name|int
name|tdq_transferable
decl_stmt|;
comment|/* Transferable thread count. */
name|short
name|tdq_switchcnt
decl_stmt|;
comment|/* Switches this tick. */
name|short
name|tdq_oldswitchcnt
decl_stmt|;
comment|/* Switches last tick. */
name|u_char
name|tdq_lowpri
decl_stmt|;
comment|/* Lowest priority thread. */
name|u_char
name|tdq_ipipending
decl_stmt|;
comment|/* IPI pending. */
name|u_char
name|tdq_idx
decl_stmt|;
comment|/* Current insert index. */
name|u_char
name|tdq_ridx
decl_stmt|;
comment|/* Current removal index. */
name|struct
name|runq
name|tdq_realtime
decl_stmt|;
comment|/* real-time run queue. */
name|struct
name|runq
name|tdq_timeshare
decl_stmt|;
comment|/* timeshare run queue. */
name|struct
name|runq
name|tdq_idle
decl_stmt|;
comment|/* Queue of IDLE threads. */
name|char
name|tdq_name
index|[
name|TDQ_NAME_LEN
index|]
decl_stmt|;
ifdef|#
directive|ifdef
name|KTR
name|char
name|tdq_loadname
index|[
name|TDQ_LOADNAME_LEN
index|]
decl_stmt|;
endif|#
directive|endif
block|}
name|__aligned
argument_list|(
literal|64
argument_list|)
struct|;
end_struct

begin_comment
comment|/* Idle thread states and config. */
end_comment

begin_define
define|#
directive|define
name|TDQ_RUNNING
value|1
end_define

begin_define
define|#
directive|define
name|TDQ_IDLE
value|2
end_define

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_decl_stmt
name|struct
name|cpu_group
modifier|*
name|cpu_top
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* CPU topology */
end_comment

begin_define
define|#
directive|define
name|SCHED_AFFINITY_DEFAULT
value|(max(1, hz / 1000))
end_define

begin_define
define|#
directive|define
name|SCHED_AFFINITY
parameter_list|(
name|ts
parameter_list|,
name|t
parameter_list|)
value|((ts)->ts_rltick> ticks - ((t) * affinity))
end_define

begin_comment
comment|/*  * Run-time tunables.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|rebalance
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|balance_interval
init|=
literal|128
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Default set in sched_initticks(). */
end_comment

begin_decl_stmt
specifier|static
name|int
name|affinity
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|steal_idle
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|steal_thresh
init|=
literal|2
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * One thread queue per processor.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|tdq
name|tdq_cpu
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|tdq
modifier|*
name|balance_tdq
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|balance_ticks
decl_stmt|;
end_decl_stmt

begin_expr_stmt
specifier|static
name|DPCPU_DEFINE
argument_list|(
name|uint32_t
argument_list|,
name|randomval
argument_list|)
expr_stmt|;
end_expr_stmt

begin_define
define|#
directive|define
name|TDQ_SELF
parameter_list|()
value|(&tdq_cpu[PCPU_GET(cpuid)])
end_define

begin_define
define|#
directive|define
name|TDQ_CPU
parameter_list|(
name|x
parameter_list|)
value|(&tdq_cpu[(x)])
end_define

begin_define
define|#
directive|define
name|TDQ_ID
parameter_list|(
name|x
parameter_list|)
value|((int)((x) - tdq_cpu))
end_define

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* !SMP */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|tdq
name|tdq_cpu
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|TDQ_ID
parameter_list|(
name|x
parameter_list|)
value|(0)
end_define

begin_define
define|#
directive|define
name|TDQ_SELF
parameter_list|()
value|(&tdq_cpu)
end_define

begin_define
define|#
directive|define
name|TDQ_CPU
parameter_list|(
name|x
parameter_list|)
value|(&tdq_cpu)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|TDQ_LOCK_ASSERT
parameter_list|(
name|t
parameter_list|,
name|type
parameter_list|)
value|mtx_assert(TDQ_LOCKPTR((t)), (type))
end_define

begin_define
define|#
directive|define
name|TDQ_LOCK
parameter_list|(
name|t
parameter_list|)
value|mtx_lock_spin(TDQ_LOCKPTR((t)))
end_define

begin_define
define|#
directive|define
name|TDQ_LOCK_FLAGS
parameter_list|(
name|t
parameter_list|,
name|f
parameter_list|)
value|mtx_lock_spin_flags(TDQ_LOCKPTR((t)), (f))
end_define

begin_define
define|#
directive|define
name|TDQ_UNLOCK
parameter_list|(
name|t
parameter_list|)
value|mtx_unlock_spin(TDQ_LOCKPTR((t)))
end_define

begin_define
define|#
directive|define
name|TDQ_LOCKPTR
parameter_list|(
name|t
parameter_list|)
value|((struct mtx *)(&(t)->tdq_lock))
end_define

begin_function_decl
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_thread_priority
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|,
name|u_char
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sched_interact_score
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_interact_update
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_interact_fork
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_pctcpu_update
parameter_list|(
name|struct
name|td_sched
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/* Operations on per processor queues */
end_comment

begin_function_decl
specifier|static
name|struct
name|thread
modifier|*
name|tdq_choose
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_setup
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_load_add
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_load_rem
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|tdq_runq_add
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|tdq_runq_rem
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
specifier|inline
name|int
name|sched_shouldpreempt
parameter_list|(
name|int
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|tdq_print
parameter_list|(
name|int
name|cpu
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|runq_print
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_add
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function_decl
specifier|static
name|int
name|tdq_move
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|tdq_idled
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_notify
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|thread
modifier|*
name|tdq_steal
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|thread
modifier|*
name|runq_steal
parameter_list|(
name|struct
name|runq
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sched_pickcpu
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sched_balance_pair
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
specifier|inline
name|struct
name|tdq
modifier|*
name|sched_setcpu
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
specifier|inline
name|void
name|thread_unblock_switch
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|,
name|struct
name|mtx
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|mtx
modifier|*
name|sched_switch_migrate
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sysctl_kern_sched_topology_spec
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sysctl_kern_sched_topology_spec_internal
parameter_list|(
name|struct
name|sbuf
modifier|*
name|sb
parameter_list|,
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|int
name|indent
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_function_decl
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_expr_stmt
name|SYSINIT
argument_list|(
name|sched_setup
argument_list|,
name|SI_SUB_RUN_QUEUE
argument_list|,
name|SI_ORDER_FIRST
argument_list|,
name|sched_setup
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function_decl
specifier|static
name|void
name|sched_initticks
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_expr_stmt
name|SYSINIT
argument_list|(
name|sched_initticks
argument_list|,
name|SI_SUB_CLOCKS
argument_list|,
name|SI_ORDER_THIRD
argument_list|,
name|sched_initticks
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SDT_PROVIDER_DEFINE
argument_list|(
name|sched
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SDT_PROBE_DEFINE3
argument_list|(
name|sched
argument_list|, , ,
name|change__pri
argument_list|,
literal|"struct thread *"
argument_list|,
literal|"struct proc *"
argument_list|,
literal|"uint8_t"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SDT_PROBE_DEFINE3
argument_list|(
name|sched
argument_list|, , ,
name|dequeue
argument_list|,
literal|"struct thread *"
argument_list|,
literal|"struct proc *"
argument_list|,
literal|"void *"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SDT_PROBE_DEFINE4
argument_list|(
name|sched
argument_list|, , ,
name|enqueue
argument_list|,
literal|"struct thread *"
argument_list|,
literal|"struct proc *"
argument_list|,
literal|"void *"
argument_list|,
literal|"int"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SDT_PROBE_DEFINE4
argument_list|(
name|sched
argument_list|, , ,
name|lend__pri
argument_list|,
literal|"struct thread *"
argument_list|,
literal|"struct proc *"
argument_list|,
literal|"uint8_t"
argument_list|,
literal|"struct thread *"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SDT_PROBE_DEFINE2
argument_list|(
name|sched
argument_list|, , ,
name|load__change
argument_list|,
literal|"int"
argument_list|,
literal|"int"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SDT_PROBE_DEFINE2
argument_list|(
name|sched
argument_list|, , ,
name|off__cpu
argument_list|,
literal|"struct thread *"
argument_list|,
literal|"struct proc *"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SDT_PROBE_DEFINE
argument_list|(
name|sched
argument_list|, , ,
name|on__cpu
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SDT_PROBE_DEFINE
argument_list|(
name|sched
argument_list|, , ,
name|remain__cpu
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SDT_PROBE_DEFINE2
argument_list|(
name|sched
argument_list|, , ,
name|surrender
argument_list|,
literal|"struct thread *"
argument_list|,
literal|"struct proc *"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Print the threads waiting on a run-queue.  */
end_comment

begin_function
specifier|static
name|void
name|runq_print
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|)
block|{
name|struct
name|rqhead
modifier|*
name|rqh
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|int
name|j
decl_stmt|;
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|RQB_LEN
condition|;
name|i
operator|++
control|)
block|{
name|printf
argument_list|(
literal|"\t\trunq bits %d 0x%zx\n"
argument_list|,
name|i
argument_list|,
name|rq
operator|->
name|rq_status
operator|.
name|rqb_bits
index|[
name|i
index|]
argument_list|)
expr_stmt|;
for|for
control|(
name|j
operator|=
literal|0
init|;
name|j
operator|<
name|RQB_BPW
condition|;
name|j
operator|++
control|)
if|if
condition|(
name|rq
operator|->
name|rq_status
operator|.
name|rqb_bits
index|[
name|i
index|]
operator|&
operator|(
literal|1ul
operator|<<
name|j
operator|)
condition|)
block|{
name|pri
operator|=
name|j
operator|+
operator|(
name|i
operator|<<
name|RQB_L2BPW
operator|)
expr_stmt|;
name|rqh
operator|=
operator|&
name|rq
operator|->
name|rq_queues
index|[
name|pri
index|]
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|td
argument_list|,
argument|rqh
argument_list|,
argument|td_runq
argument_list|)
block|{
name|printf
argument_list|(
literal|"\t\t\ttd %p(%s) priority %d rqindex %d pri %d\n"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_name
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|td
operator|->
name|td_rqindex
argument_list|,
name|pri
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * Print the status of a per-cpu thread queue.  Should be a ddb show cmd.  */
end_comment

begin_function
name|void
name|tdq_print
parameter_list|(
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"tdq %d:\n"
argument_list|,
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tlock            %p\n"
argument_list|,
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tLock name:      %s\n"
argument_list|,
name|tdq
operator|->
name|tdq_name
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tload:           %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tswitch cnt:     %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_switchcnt
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\told switch cnt: %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_oldswitchcnt
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\ttimeshare idx:  %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_idx
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\ttimeshare ridx: %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_ridx
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tload transferable: %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_transferable
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tlowest priority:   %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_lowpri
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\trealtime runq:\n"
argument_list|)
expr_stmt|;
name|runq_print
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_realtime
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\ttimeshare runq:\n"
argument_list|)
expr_stmt|;
name|runq_print
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tidle runq:\n"
argument_list|)
expr_stmt|;
name|runq_print
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
specifier|inline
name|int
name|sched_shouldpreempt
parameter_list|(
name|int
name|pri
parameter_list|,
name|int
name|cpri
parameter_list|,
name|int
name|remote
parameter_list|)
block|{
comment|/* 	 * If the new priority is not better than the current priority there is 	 * nothing to do. 	 */
if|if
condition|(
name|pri
operator|>=
name|cpri
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* 	 * Always preempt idle. 	 */
if|if
condition|(
name|cpri
operator|>=
name|PRI_MIN_IDLE
condition|)
return|return
operator|(
literal|1
operator|)
return|;
comment|/* 	 * If preemption is disabled don't preempt others. 	 */
if|if
condition|(
name|preempt_thresh
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* 	 * Preempt if we exceed the threshold. 	 */
if|if
condition|(
name|pri
operator|<=
name|preempt_thresh
condition|)
return|return
operator|(
literal|1
operator|)
return|;
comment|/* 	 * If we're interactive or better and there is non-interactive 	 * or worse running preempt only remote processors. 	 */
if|if
condition|(
name|remote
operator|&&
name|pri
operator|<=
name|PRI_MAX_INTERACT
operator|&&
name|cpri
operator|>
name|PRI_MAX_INTERACT
condition|)
return|return
operator|(
literal|1
operator|)
return|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Add a thread to the actual run-queue.  Keeps transferable counts up to  * date with what is actually on the run-queue.  Selects the correct  * queue position for timeshare threads.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|tdq_runq_add
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|u_char
name|pri
decl_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|TD_SET_RUNQ
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|tdq
operator|->
name|tdq_transferable
operator|++
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_XFERABLE
expr_stmt|;
block|}
if|if
condition|(
name|pri
operator|<
name|PRI_MIN_BATCH
condition|)
block|{
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|tdq
operator|->
name|tdq_realtime
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pri
operator|<=
name|PRI_MAX_BATCH
condition|)
block|{
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|tdq
operator|->
name|tdq_timeshare
expr_stmt|;
name|KASSERT
argument_list|(
name|pri
operator|<=
name|PRI_MAX_BATCH
operator|&&
name|pri
operator|>=
name|PRI_MIN_BATCH
argument_list|,
operator|(
literal|"Invalid priority %d on timeshare runq"
operator|,
name|pri
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * This queue contains only priorities between MIN and MAX 		 * realtime.  Use the whole queue to represent these values. 		 */
if|if
condition|(
operator|(
name|flags
operator|&
operator|(
name|SRQ_BORROWING
operator||
name|SRQ_PREEMPTED
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|pri
operator|=
name|RQ_NQS
operator|*
operator|(
name|pri
operator|-
name|PRI_MIN_BATCH
operator|)
operator|/
name|PRI_BATCH_RANGE
expr_stmt|;
name|pri
operator|=
operator|(
name|pri
operator|+
name|tdq
operator|->
name|tdq_idx
operator|)
operator|%
name|RQ_NQS
expr_stmt|;
comment|/* 			 * This effectively shortens the queue by one so we 			 * can have a one slot difference between idx and 			 * ridx while we wait for threads to drain. 			 */
if|if
condition|(
name|tdq
operator|->
name|tdq_ridx
operator|!=
name|tdq
operator|->
name|tdq_idx
operator|&&
name|pri
operator|==
name|tdq
operator|->
name|tdq_ridx
condition|)
name|pri
operator|=
call|(
name|unsigned
name|char
call|)
argument_list|(
name|pri
operator|-
literal|1
argument_list|)
operator|%
name|RQ_NQS
expr_stmt|;
block|}
else|else
name|pri
operator|=
name|tdq
operator|->
name|tdq_ridx
expr_stmt|;
name|runq_add_pri
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|td
argument_list|,
name|pri
argument_list|,
name|flags
argument_list|)
expr_stmt|;
return|return;
block|}
else|else
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|tdq
operator|->
name|tdq_idle
expr_stmt|;
name|runq_add
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*   * Remove a thread from a run-queue.  This typically happens when a thread  * is selected to run.  Running threads are not on the queue and the  * transferable count does not reflect them.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|tdq_runq_rem
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|ts
operator|->
name|ts_runq
operator|!=
name|NULL
argument_list|,
operator|(
literal|"tdq_runq_remove: thread %p null ts_runq"
operator|,
name|td
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_XFERABLE
condition|)
block|{
name|tdq
operator|->
name|tdq_transferable
operator|--
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_XFERABLE
expr_stmt|;
block|}
if|if
condition|(
name|ts
operator|->
name|ts_runq
operator|==
operator|&
name|tdq
operator|->
name|tdq_timeshare
condition|)
block|{
if|if
condition|(
name|tdq
operator|->
name|tdq_idx
operator|!=
name|tdq
operator|->
name|tdq_ridx
condition|)
name|runq_remove_idx
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|td
argument_list|,
operator|&
name|tdq
operator|->
name|tdq_ridx
argument_list|)
expr_stmt|;
else|else
name|runq_remove_idx
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|td
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
else|else
name|runq_remove
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Load is maintained for all threads RUNNING and ON_RUNQ.  Add the load  * for this thread to the referenced thread queue.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_load_add
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_load
operator|++
expr_stmt|;
if|if
condition|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|tdq
operator|->
name|tdq_sysload
operator|++
expr_stmt|;
name|KTR_COUNTER0
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"load"
argument_list|,
name|tdq
operator|->
name|tdq_loadname
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
name|SDT_PROBE2
argument_list|(
name|sched
argument_list|, , ,
name|load__change
argument_list|,
operator|(
name|int
operator|)
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove the load from a thread that is transitioning to a sleep state or  * exiting.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_load_rem
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|tdq
operator|->
name|tdq_load
operator|!=
literal|0
argument_list|,
operator|(
literal|"tdq_load_rem: Removing with 0 load on queue %d"
operator|,
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
operator|)
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_load
operator|--
expr_stmt|;
if|if
condition|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_NOLOAD
operator|)
operator|==
literal|0
condition|)
name|tdq
operator|->
name|tdq_sysload
operator|--
expr_stmt|;
name|KTR_COUNTER0
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"load"
argument_list|,
name|tdq
operator|->
name|tdq_loadname
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
name|SDT_PROBE2
argument_list|(
name|sched
argument_list|, , ,
name|load__change
argument_list|,
operator|(
name|int
operator|)
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Bound timeshare latency by decreasing slice size as load increases.  We  * consider the maximum latency as the sum of the threads waiting to run  * aside from curthread and target no more than sched_slice latency but  * no less than sched_slice_min runtime.  */
end_comment

begin_function
specifier|static
specifier|inline
name|int
name|tdq_slice
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
name|int
name|load
decl_stmt|;
comment|/* 	 * It is safe to use sys_load here because this is called from 	 * contexts where timeshare threads are running and so there 	 * cannot be higher priority load in the system. 	 */
name|load
operator|=
name|tdq
operator|->
name|tdq_sysload
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|load
operator|>=
name|SCHED_SLICE_MIN_DIVISOR
condition|)
return|return
operator|(
name|sched_slice_min
operator|)
return|;
if|if
condition|(
name|load
operator|<=
literal|1
condition|)
return|return
operator|(
name|sched_slice
operator|)
return|;
return|return
operator|(
name|sched_slice
operator|/
name|load
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Set lowpri to its exact value by searching the run-queue and  * evaluating curthread.  curthread may be passed as an optimization.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_setlowpri
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|ctd
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|ctd
operator|==
name|NULL
condition|)
name|ctd
operator|=
name|pcpu_find
argument_list|(
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|)
operator|->
name|pc_curthread
expr_stmt|;
name|td
operator|=
name|tdq_choose
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|==
name|NULL
operator|||
name|td
operator|->
name|td_priority
operator|>
name|ctd
operator|->
name|td_priority
condition|)
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|ctd
operator|->
name|td_priority
expr_stmt|;
else|else
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_struct
struct|struct
name|cpu_search
block|{
name|cpuset_t
name|cs_mask
decl_stmt|;
name|u_int
name|cs_prefer
decl_stmt|;
name|int
name|cs_pri
decl_stmt|;
comment|/* Min priority for low. */
name|int
name|cs_limit
decl_stmt|;
comment|/* Max load for low, min load for high. */
name|int
name|cs_cpu
decl_stmt|;
name|int
name|cs_load
decl_stmt|;
block|}
struct|;
end_struct

begin_define
define|#
directive|define
name|CPU_SEARCH_LOWEST
value|0x1
end_define

begin_define
define|#
directive|define
name|CPU_SEARCH_HIGHEST
value|0x2
end_define

begin_define
define|#
directive|define
name|CPU_SEARCH_BOTH
value|(CPU_SEARCH_LOWEST|CPU_SEARCH_HIGHEST)
end_define

begin_define
define|#
directive|define
name|CPUSET_FOREACH
parameter_list|(
name|cpu
parameter_list|,
name|mask
parameter_list|)
define|\
value|for ((cpu) = 0; (cpu)<= mp_maxid; (cpu)++)		\ 		if (CPU_ISSET(cpu,&mask))
end_define

begin_function_decl
specifier|static
name|__always_inline
name|int
name|cpu_search
parameter_list|(
specifier|const
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|low
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|high
parameter_list|,
specifier|const
name|int
name|match
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|int
name|__noinline
name|cpu_search_lowest
parameter_list|(
specifier|const
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|low
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|int
name|__noinline
name|cpu_search_highest
parameter_list|(
specifier|const
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|high
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|int
name|__noinline
name|cpu_search_both
parameter_list|(
specifier|const
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|low
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|high
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Search the tree of cpu_groups for the lowest or highest loaded cpu  * according to the match argument.  This routine actually compares the  * load on all paths through the tree and finds the least loaded cpu on  * the least loaded path, which may differ from the least loaded cpu in  * the system.  This balances work among caches and busses.  *  * This inline is instantiated in three forms below using constants for the  * match argument.  It is reduced to the minimum set for each case.  It is  * also recursive to the depth of the tree.  */
end_comment

begin_function
specifier|static
name|__always_inline
name|int
name|cpu_search
parameter_list|(
specifier|const
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|low
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|high
parameter_list|,
specifier|const
name|int
name|match
parameter_list|)
block|{
name|struct
name|cpu_search
name|lgroup
decl_stmt|;
name|struct
name|cpu_search
name|hgroup
decl_stmt|;
name|cpuset_t
name|cpumask
decl_stmt|;
name|struct
name|cpu_group
modifier|*
name|child
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|cpu
decl_stmt|,
name|i
decl_stmt|,
name|hload
decl_stmt|,
name|lload
decl_stmt|,
name|load
decl_stmt|,
name|total
decl_stmt|,
name|rnd
decl_stmt|,
modifier|*
name|rndptr
decl_stmt|;
name|total
operator|=
literal|0
expr_stmt|;
name|cpumask
operator|=
name|cg
operator|->
name|cg_mask
expr_stmt|;
if|if
condition|(
name|match
operator|&
name|CPU_SEARCH_LOWEST
condition|)
block|{
name|lload
operator|=
name|INT_MAX
expr_stmt|;
name|lgroup
operator|=
operator|*
name|low
expr_stmt|;
block|}
if|if
condition|(
name|match
operator|&
name|CPU_SEARCH_HIGHEST
condition|)
block|{
name|hload
operator|=
name|INT_MIN
expr_stmt|;
name|hgroup
operator|=
operator|*
name|high
expr_stmt|;
block|}
comment|/* Iterate through the child CPU groups and then remaining CPUs. */
for|for
control|(
name|i
operator|=
name|cg
operator|->
name|cg_children
operator|,
name|cpu
operator|=
name|mp_maxid
init|;
condition|;
control|)
block|{
if|if
condition|(
name|i
operator|==
literal|0
condition|)
block|{
ifdef|#
directive|ifdef
name|HAVE_INLINE_FFSL
name|cpu
operator|=
name|CPU_FFS
argument_list|(
operator|&
name|cpumask
argument_list|)
operator|-
literal|1
expr_stmt|;
else|#
directive|else
while|while
condition|(
name|cpu
operator|>=
literal|0
operator|&&
operator|!
name|CPU_ISSET
argument_list|(
name|cpu
argument_list|,
operator|&
name|cpumask
argument_list|)
condition|)
name|cpu
operator|--
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|cpu
operator|<
literal|0
condition|)
break|break;
name|child
operator|=
name|NULL
expr_stmt|;
block|}
else|else
name|child
operator|=
operator|&
name|cg
operator|->
name|cg_child
index|[
name|i
operator|-
literal|1
index|]
expr_stmt|;
if|if
condition|(
name|match
operator|&
name|CPU_SEARCH_LOWEST
condition|)
name|lgroup
operator|.
name|cs_cpu
operator|=
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|match
operator|&
name|CPU_SEARCH_HIGHEST
condition|)
name|hgroup
operator|.
name|cs_cpu
operator|=
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|child
condition|)
block|{
comment|/* Handle child CPU group. */
name|CPU_NAND
argument_list|(
operator|&
name|cpumask
argument_list|,
operator|&
name|child
operator|->
name|cg_mask
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|match
condition|)
block|{
case|case
name|CPU_SEARCH_LOWEST
case|:
name|load
operator|=
name|cpu_search_lowest
argument_list|(
name|child
argument_list|,
operator|&
name|lgroup
argument_list|)
expr_stmt|;
break|break;
case|case
name|CPU_SEARCH_HIGHEST
case|:
name|load
operator|=
name|cpu_search_highest
argument_list|(
name|child
argument_list|,
operator|&
name|hgroup
argument_list|)
expr_stmt|;
break|break;
case|case
name|CPU_SEARCH_BOTH
case|:
name|load
operator|=
name|cpu_search_both
argument_list|(
name|child
argument_list|,
operator|&
name|lgroup
argument_list|,
operator|&
name|hgroup
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
else|else
block|{
comment|/* Handle child CPU. */
name|CPU_CLR
argument_list|(
name|cpu
argument_list|,
operator|&
name|cpumask
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|load
operator|=
name|tdq
operator|->
name|tdq_load
operator|*
literal|256
expr_stmt|;
name|rndptr
operator|=
name|DPCPU_PTR
argument_list|(
name|randomval
argument_list|)
expr_stmt|;
name|rnd
operator|=
operator|(
operator|*
name|rndptr
operator|=
operator|*
name|rndptr
operator|*
literal|69069
operator|+
literal|5
operator|)
operator|>>
literal|26
expr_stmt|;
if|if
condition|(
name|match
operator|&
name|CPU_SEARCH_LOWEST
condition|)
block|{
if|if
condition|(
name|cpu
operator|==
name|low
operator|->
name|cs_prefer
condition|)
name|load
operator|-=
literal|64
expr_stmt|;
comment|/* If that CPU is allowed and get data. */
if|if
condition|(
name|tdq
operator|->
name|tdq_lowpri
operator|>
name|lgroup
operator|.
name|cs_pri
operator|&&
name|tdq
operator|->
name|tdq_load
operator|<=
name|lgroup
operator|.
name|cs_limit
operator|&&
name|CPU_ISSET
argument_list|(
name|cpu
argument_list|,
operator|&
name|lgroup
operator|.
name|cs_mask
argument_list|)
condition|)
block|{
name|lgroup
operator|.
name|cs_cpu
operator|=
name|cpu
expr_stmt|;
name|lgroup
operator|.
name|cs_load
operator|=
name|load
operator|-
name|rnd
expr_stmt|;
block|}
block|}
if|if
condition|(
name|match
operator|&
name|CPU_SEARCH_HIGHEST
condition|)
if|if
condition|(
name|tdq
operator|->
name|tdq_load
operator|>=
name|hgroup
operator|.
name|cs_limit
operator|&&
name|tdq
operator|->
name|tdq_transferable
operator|&&
name|CPU_ISSET
argument_list|(
name|cpu
argument_list|,
operator|&
name|hgroup
operator|.
name|cs_mask
argument_list|)
condition|)
block|{
name|hgroup
operator|.
name|cs_cpu
operator|=
name|cpu
expr_stmt|;
name|hgroup
operator|.
name|cs_load
operator|=
name|load
operator|-
name|rnd
expr_stmt|;
block|}
block|}
name|total
operator|+=
name|load
expr_stmt|;
comment|/* We have info about child item. Compare it. */
if|if
condition|(
name|match
operator|&
name|CPU_SEARCH_LOWEST
condition|)
block|{
if|if
condition|(
name|lgroup
operator|.
name|cs_cpu
operator|>=
literal|0
operator|&&
operator|(
name|load
operator|<
name|lload
operator|||
operator|(
name|load
operator|==
name|lload
operator|&&
name|lgroup
operator|.
name|cs_load
operator|<
name|low
operator|->
name|cs_load
operator|)
operator|)
condition|)
block|{
name|lload
operator|=
name|load
expr_stmt|;
name|low
operator|->
name|cs_cpu
operator|=
name|lgroup
operator|.
name|cs_cpu
expr_stmt|;
name|low
operator|->
name|cs_load
operator|=
name|lgroup
operator|.
name|cs_load
expr_stmt|;
block|}
block|}
if|if
condition|(
name|match
operator|&
name|CPU_SEARCH_HIGHEST
condition|)
if|if
condition|(
name|hgroup
operator|.
name|cs_cpu
operator|>=
literal|0
operator|&&
operator|(
name|load
operator|>
name|hload
operator|||
operator|(
name|load
operator|==
name|hload
operator|&&
name|hgroup
operator|.
name|cs_load
operator|>
name|high
operator|->
name|cs_load
operator|)
operator|)
condition|)
block|{
name|hload
operator|=
name|load
expr_stmt|;
name|high
operator|->
name|cs_cpu
operator|=
name|hgroup
operator|.
name|cs_cpu
expr_stmt|;
name|high
operator|->
name|cs_load
operator|=
name|hgroup
operator|.
name|cs_load
expr_stmt|;
block|}
if|if
condition|(
name|child
condition|)
block|{
name|i
operator|--
expr_stmt|;
if|if
condition|(
name|i
operator|==
literal|0
operator|&&
name|CPU_EMPTY
argument_list|(
operator|&
name|cpumask
argument_list|)
condition|)
break|break;
block|}
ifndef|#
directive|ifndef
name|HAVE_INLINE_FFSL
else|else
name|cpu
operator|--
expr_stmt|;
endif|#
directive|endif
block|}
return|return
operator|(
name|total
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * cpu_search instantiations must pass constants to maintain the inline  * optimization.  */
end_comment

begin_function
name|int
name|cpu_search_lowest
parameter_list|(
specifier|const
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|low
parameter_list|)
block|{
return|return
name|cpu_search
argument_list|(
name|cg
argument_list|,
name|low
argument_list|,
name|NULL
argument_list|,
name|CPU_SEARCH_LOWEST
argument_list|)
return|;
block|}
end_function

begin_function
name|int
name|cpu_search_highest
parameter_list|(
specifier|const
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|high
parameter_list|)
block|{
return|return
name|cpu_search
argument_list|(
name|cg
argument_list|,
name|NULL
argument_list|,
name|high
argument_list|,
name|CPU_SEARCH_HIGHEST
argument_list|)
return|;
block|}
end_function

begin_function
name|int
name|cpu_search_both
parameter_list|(
specifier|const
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|low
parameter_list|,
name|struct
name|cpu_search
modifier|*
name|high
parameter_list|)
block|{
return|return
name|cpu_search
argument_list|(
name|cg
argument_list|,
name|low
argument_list|,
name|high
argument_list|,
name|CPU_SEARCH_BOTH
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/*  * Find the cpu with the least load via the least loaded path that has a  * lowpri greater than pri  pri.  A pri of -1 indicates any priority is  * acceptable.  */
end_comment

begin_function
specifier|static
specifier|inline
name|int
name|sched_lowest
parameter_list|(
specifier|const
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|cpuset_t
name|mask
parameter_list|,
name|int
name|pri
parameter_list|,
name|int
name|maxload
parameter_list|,
name|int
name|prefer
parameter_list|)
block|{
name|struct
name|cpu_search
name|low
decl_stmt|;
name|low
operator|.
name|cs_cpu
operator|=
operator|-
literal|1
expr_stmt|;
name|low
operator|.
name|cs_prefer
operator|=
name|prefer
expr_stmt|;
name|low
operator|.
name|cs_mask
operator|=
name|mask
expr_stmt|;
name|low
operator|.
name|cs_pri
operator|=
name|pri
expr_stmt|;
name|low
operator|.
name|cs_limit
operator|=
name|maxload
expr_stmt|;
name|cpu_search_lowest
argument_list|(
name|cg
argument_list|,
operator|&
name|low
argument_list|)
expr_stmt|;
return|return
name|low
operator|.
name|cs_cpu
return|;
block|}
end_function

begin_comment
comment|/*  * Find the cpu with the highest load via the highest loaded path.  */
end_comment

begin_function
specifier|static
specifier|inline
name|int
name|sched_highest
parameter_list|(
specifier|const
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|cpuset_t
name|mask
parameter_list|,
name|int
name|minload
parameter_list|)
block|{
name|struct
name|cpu_search
name|high
decl_stmt|;
name|high
operator|.
name|cs_cpu
operator|=
operator|-
literal|1
expr_stmt|;
name|high
operator|.
name|cs_mask
operator|=
name|mask
expr_stmt|;
name|high
operator|.
name|cs_limit
operator|=
name|minload
expr_stmt|;
name|cpu_search_highest
argument_list|(
name|cg
argument_list|,
operator|&
name|high
argument_list|)
expr_stmt|;
return|return
name|high
operator|.
name|cs_cpu
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_balance_group
parameter_list|(
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|)
block|{
name|cpuset_t
name|hmask
decl_stmt|,
name|lmask
decl_stmt|;
name|int
name|high
decl_stmt|,
name|low
decl_stmt|,
name|anylow
decl_stmt|;
name|CPU_FILL
argument_list|(
operator|&
name|hmask
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|high
operator|=
name|sched_highest
argument_list|(
name|cg
argument_list|,
name|hmask
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* Stop if there is no more CPU with transferrable threads. */
if|if
condition|(
name|high
operator|==
operator|-
literal|1
condition|)
break|break;
name|CPU_CLR
argument_list|(
name|high
argument_list|,
operator|&
name|hmask
argument_list|)
expr_stmt|;
name|CPU_COPY
argument_list|(
operator|&
name|hmask
argument_list|,
operator|&
name|lmask
argument_list|)
expr_stmt|;
comment|/* Stop if there is no more CPU left for low. */
if|if
condition|(
name|CPU_EMPTY
argument_list|(
operator|&
name|lmask
argument_list|)
condition|)
break|break;
name|anylow
operator|=
literal|1
expr_stmt|;
name|nextlow
label|:
name|low
operator|=
name|sched_lowest
argument_list|(
name|cg
argument_list|,
name|lmask
argument_list|,
operator|-
literal|1
argument_list|,
name|TDQ_CPU
argument_list|(
name|high
argument_list|)
operator|->
name|tdq_load
operator|-
literal|1
argument_list|,
name|high
argument_list|)
expr_stmt|;
comment|/* Stop if we looked well and found no less loaded CPU. */
if|if
condition|(
name|anylow
operator|&&
name|low
operator|==
operator|-
literal|1
condition|)
break|break;
comment|/* Go to next high if we found no less loaded CPU. */
if|if
condition|(
name|low
operator|==
operator|-
literal|1
condition|)
continue|continue;
comment|/* Transfer thread from high to low. */
if|if
condition|(
name|sched_balance_pair
argument_list|(
name|TDQ_CPU
argument_list|(
name|high
argument_list|)
argument_list|,
name|TDQ_CPU
argument_list|(
name|low
argument_list|)
argument_list|)
condition|)
block|{
comment|/* CPU that got thread can no longer be a donor. */
name|CPU_CLR
argument_list|(
name|low
argument_list|,
operator|&
name|hmask
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * If failed, then there is no threads on high 			 * that can run on this low. Drop low from low 			 * mask and look for different one. 			 */
name|CPU_CLR
argument_list|(
name|low
argument_list|,
operator|&
name|lmask
argument_list|)
expr_stmt|;
name|anylow
operator|=
literal|0
expr_stmt|;
goto|goto
name|nextlow
goto|;
block|}
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|sched_balance
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
comment|/* 	 * Select a random time between .5 * balance_interval and 	 * 1.5 * balance_interval. 	 */
name|balance_ticks
operator|=
name|max
argument_list|(
name|balance_interval
operator|/
literal|2
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|balance_ticks
operator|+=
name|random
argument_list|()
operator|%
name|balance_interval
expr_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
operator|||
name|rebalance
operator|==
literal|0
condition|)
return|return;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|sched_balance_group
argument_list|(
name|cpu_top
argument_list|)
expr_stmt|;
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Lock two thread queues using their address to maintain lock order.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_lock_pair
parameter_list|(
name|struct
name|tdq
modifier|*
name|one
parameter_list|,
name|struct
name|tdq
modifier|*
name|two
parameter_list|)
block|{
if|if
condition|(
name|one
operator|<
name|two
condition|)
block|{
name|TDQ_LOCK
argument_list|(
name|one
argument_list|)
expr_stmt|;
name|TDQ_LOCK_FLAGS
argument_list|(
name|two
argument_list|,
name|MTX_DUPOK
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|TDQ_LOCK
argument_list|(
name|two
argument_list|)
expr_stmt|;
name|TDQ_LOCK_FLAGS
argument_list|(
name|one
argument_list|,
name|MTX_DUPOK
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Unlock two thread queues.  Order is not important here.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_unlock_pair
parameter_list|(
name|struct
name|tdq
modifier|*
name|one
parameter_list|,
name|struct
name|tdq
modifier|*
name|two
parameter_list|)
block|{
name|TDQ_UNLOCK
argument_list|(
name|one
argument_list|)
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|two
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Transfer load between two imbalanced thread queues.  */
end_comment

begin_function
specifier|static
name|int
name|sched_balance_pair
parameter_list|(
name|struct
name|tdq
modifier|*
name|high
parameter_list|,
name|struct
name|tdq
modifier|*
name|low
parameter_list|)
block|{
name|int
name|moved
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|tdq_lock_pair
argument_list|(
name|high
argument_list|,
name|low
argument_list|)
expr_stmt|;
name|moved
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Determine what the imbalance is and then adjust that to how many 	 * threads we actually have to give up (transferable). 	 */
if|if
condition|(
name|high
operator|->
name|tdq_transferable
operator|!=
literal|0
operator|&&
name|high
operator|->
name|tdq_load
operator|>
name|low
operator|->
name|tdq_load
operator|&&
operator|(
name|moved
operator|=
name|tdq_move
argument_list|(
name|high
argument_list|,
name|low
argument_list|)
operator|)
operator|>
literal|0
condition|)
block|{
comment|/* 		 * In case the target isn't the current cpu IPI it to force a 		 * reschedule with the new workload. 		 */
name|cpu
operator|=
name|TDQ_ID
argument_list|(
name|low
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
name|ipi_cpu
argument_list|(
name|cpu
argument_list|,
name|IPI_PREEMPT
argument_list|)
expr_stmt|;
block|}
name|tdq_unlock_pair
argument_list|(
name|high
argument_list|,
name|low
argument_list|)
expr_stmt|;
return|return
operator|(
name|moved
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Move a thread from one thread queue to another.  */
end_comment

begin_function
specifier|static
name|int
name|tdq_move
parameter_list|(
name|struct
name|tdq
modifier|*
name|from
parameter_list|,
name|struct
name|tdq
modifier|*
name|to
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|from
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|to
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|from
expr_stmt|;
name|cpu
operator|=
name|TDQ_ID
argument_list|(
name|to
argument_list|)
expr_stmt|;
name|td
operator|=
name|tdq_steal
argument_list|(
name|tdq
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
comment|/* 	 * Although the run queue is locked the thread may be blocked.  Lock 	 * it to clear this and acquire the run-queue lock. 	 */
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
comment|/* Drop recursive lock on from acquired via thread_lock(). */
name|TDQ_UNLOCK
argument_list|(
name|from
argument_list|)
expr_stmt|;
name|sched_rem
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_cpu
operator|=
name|cpu
expr_stmt|;
name|td
operator|->
name|td_lock
operator|=
name|TDQ_LOCKPTR
argument_list|(
name|to
argument_list|)
expr_stmt|;
name|tdq_add
argument_list|(
name|to
argument_list|,
name|td
argument_list|,
name|SRQ_YIELDING
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This tdq has idled.  Try to steal a thread from another cpu and switch  * to it.  */
end_comment

begin_function
specifier|static
name|int
name|tdq_idled
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
name|struct
name|cpu_group
modifier|*
name|cg
decl_stmt|;
name|struct
name|tdq
modifier|*
name|steal
decl_stmt|;
name|cpuset_t
name|mask
decl_stmt|;
name|int
name|thresh
decl_stmt|;
name|int
name|cpu
decl_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
operator|||
name|steal_idle
operator|==
literal|0
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|CPU_FILL
argument_list|(
operator|&
name|mask
argument_list|)
expr_stmt|;
name|CPU_CLR
argument_list|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|,
operator|&
name|mask
argument_list|)
expr_stmt|;
comment|/* We don't want to be preempted while we're iterating. */
name|spinlock_enter
argument_list|()
expr_stmt|;
for|for
control|(
name|cg
operator|=
name|tdq
operator|->
name|tdq_cg
init|;
name|cg
operator|!=
name|NULL
condition|;
control|)
block|{
if|if
condition|(
operator|(
name|cg
operator|->
name|cg_flags
operator|&
name|CG_FLAG_THREAD
operator|)
operator|==
literal|0
condition|)
name|thresh
operator|=
name|steal_thresh
expr_stmt|;
else|else
name|thresh
operator|=
literal|1
expr_stmt|;
name|cpu
operator|=
name|sched_highest
argument_list|(
name|cg
argument_list|,
name|mask
argument_list|,
name|thresh
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
operator|==
operator|-
literal|1
condition|)
block|{
name|cg
operator|=
name|cg
operator|->
name|cg_parent
expr_stmt|;
continue|continue;
block|}
name|steal
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|CPU_CLR
argument_list|(
name|cpu
argument_list|,
operator|&
name|mask
argument_list|)
expr_stmt|;
name|tdq_lock_pair
argument_list|(
name|tdq
argument_list|,
name|steal
argument_list|)
expr_stmt|;
if|if
condition|(
name|steal
operator|->
name|tdq_load
operator|<
name|thresh
operator|||
name|steal
operator|->
name|tdq_transferable
operator|==
literal|0
condition|)
block|{
name|tdq_unlock_pair
argument_list|(
name|tdq
argument_list|,
name|steal
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * If a thread was added while interrupts were disabled don't 		 * steal one here.  If we fail to acquire one due to affinity 		 * restrictions loop again with this cpu removed from the 		 * set. 		 */
if|if
condition|(
name|tdq
operator|->
name|tdq_load
operator|==
literal|0
operator|&&
name|tdq_move
argument_list|(
name|steal
argument_list|,
name|tdq
argument_list|)
operator|==
literal|0
condition|)
block|{
name|tdq_unlock_pair
argument_list|(
name|tdq
argument_list|,
name|steal
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|spinlock_exit
argument_list|()
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|steal
argument_list|)
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_VOL
operator||
name|SWT_IDLE
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|curthread
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|spinlock_exit
argument_list|()
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Notify a remote cpu of new work.  Sends an IPI if criteria are met.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_notify
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|ctd
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|int
name|cpu
decl_stmt|;
if|if
condition|(
name|tdq
operator|->
name|tdq_ipipending
condition|)
return|return;
name|cpu
operator|=
name|td
operator|->
name|td_sched
operator|->
name|ts_cpu
expr_stmt|;
name|pri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|ctd
operator|=
name|pcpu_find
argument_list|(
name|cpu
argument_list|)
operator|->
name|pc_curthread
expr_stmt|;
if|if
condition|(
operator|!
name|sched_shouldpreempt
argument_list|(
name|pri
argument_list|,
name|ctd
operator|->
name|td_priority
argument_list|,
literal|1
argument_list|)
condition|)
return|return;
comment|/* 	 * Make sure that our caller's earlier update to tdq_load is 	 * globally visible before we read tdq_cpu_idle.  Idle thread 	 * accesses both of them without locks, and the order is important. 	 */
name|mb
argument_list|()
expr_stmt|;
if|if
condition|(
name|TD_IS_IDLETHREAD
argument_list|(
name|ctd
argument_list|)
condition|)
block|{
comment|/* 		 * If the MD code has an idle wakeup routine try that before 		 * falling back to IPI. 		 */
if|if
condition|(
operator|!
name|tdq
operator|->
name|tdq_cpu_idle
operator|||
name|cpu_idle_wakeup
argument_list|(
name|cpu
argument_list|)
condition|)
return|return;
block|}
name|tdq
operator|->
name|tdq_ipipending
operator|=
literal|1
expr_stmt|;
name|ipi_cpu
argument_list|(
name|cpu
argument_list|,
name|IPI_PREEMPT
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Steals load from a timeshare queue.  Honors the rotating queue head  * index.  */
end_comment

begin_function
specifier|static
name|struct
name|thread
modifier|*
name|runq_steal_from
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|,
name|int
name|cpu
parameter_list|,
name|u_char
name|start
parameter_list|)
block|{
name|struct
name|rqbits
modifier|*
name|rqb
decl_stmt|;
name|struct
name|rqhead
modifier|*
name|rqh
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|,
modifier|*
name|first
decl_stmt|;
name|int
name|bit
decl_stmt|;
name|int
name|i
decl_stmt|;
name|rqb
operator|=
operator|&
name|rq
operator|->
name|rq_status
expr_stmt|;
name|bit
operator|=
name|start
operator|&
operator|(
name|RQB_BPW
operator|-
literal|1
operator|)
expr_stmt|;
name|first
operator|=
name|NULL
expr_stmt|;
name|again
label|:
for|for
control|(
name|i
operator|=
name|RQB_WORD
argument_list|(
name|start
argument_list|)
init|;
name|i
operator|<
name|RQB_LEN
condition|;
name|bit
operator|=
literal|0
operator|,
name|i
operator|++
control|)
block|{
if|if
condition|(
name|rqb
operator|->
name|rqb_bits
index|[
name|i
index|]
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|bit
operator|==
literal|0
condition|)
name|bit
operator|=
name|RQB_FFS
argument_list|(
name|rqb
operator|->
name|rqb_bits
index|[
name|i
index|]
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|bit
operator|<
name|RQB_BPW
condition|;
name|bit
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|rqb
operator|->
name|rqb_bits
index|[
name|i
index|]
operator|&
operator|(
literal|1ul
operator|<<
name|bit
operator|)
operator|)
operator|==
literal|0
condition|)
continue|continue;
name|rqh
operator|=
operator|&
name|rq
operator|->
name|rq_queues
index|[
name|bit
operator|+
operator|(
name|i
operator|<<
name|RQB_L2BPW
operator|)
index|]
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|td
argument_list|,
argument|rqh
argument_list|,
argument|td_runq
argument_list|)
block|{
if|if
condition|(
name|first
operator|&&
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
operator|&&
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|cpu
argument_list|)
condition|)
return|return
operator|(
name|td
operator|)
return|;
name|first
operator|=
name|td
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|start
operator|!=
literal|0
condition|)
block|{
name|start
operator|=
literal|0
expr_stmt|;
goto|goto
name|again
goto|;
block|}
if|if
condition|(
name|first
operator|&&
name|THREAD_CAN_MIGRATE
argument_list|(
name|first
argument_list|)
operator|&&
name|THREAD_CAN_SCHED
argument_list|(
name|first
argument_list|,
name|cpu
argument_list|)
condition|)
return|return
operator|(
name|first
operator|)
return|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Steals load from a standard linear queue.  */
end_comment

begin_function
specifier|static
name|struct
name|thread
modifier|*
name|runq_steal
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|rqhead
modifier|*
name|rqh
decl_stmt|;
name|struct
name|rqbits
modifier|*
name|rqb
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|int
name|word
decl_stmt|;
name|int
name|bit
decl_stmt|;
name|rqb
operator|=
operator|&
name|rq
operator|->
name|rq_status
expr_stmt|;
for|for
control|(
name|word
operator|=
literal|0
init|;
name|word
operator|<
name|RQB_LEN
condition|;
name|word
operator|++
control|)
block|{
if|if
condition|(
name|rqb
operator|->
name|rqb_bits
index|[
name|word
index|]
operator|==
literal|0
condition|)
continue|continue;
for|for
control|(
name|bit
operator|=
literal|0
init|;
name|bit
operator|<
name|RQB_BPW
condition|;
name|bit
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|rqb
operator|->
name|rqb_bits
index|[
name|word
index|]
operator|&
operator|(
literal|1ul
operator|<<
name|bit
operator|)
operator|)
operator|==
literal|0
condition|)
continue|continue;
name|rqh
operator|=
operator|&
name|rq
operator|->
name|rq_queues
index|[
name|bit
operator|+
operator|(
name|word
operator|<<
name|RQB_L2BPW
operator|)
index|]
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|td
argument_list|,
argument|rqh
argument_list|,
argument|td_runq
argument_list|)
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
operator|&&
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|cpu
argument_list|)
condition|)
return|return
operator|(
name|td
operator|)
return|;
block|}
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Attempt to steal a thread in priority order from a thread queue.  */
end_comment

begin_function
specifier|static
name|struct
name|thread
modifier|*
name|tdq_steal
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|td
operator|=
name|runq_steal
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_realtime
argument_list|,
name|cpu
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
return|return
operator|(
name|td
operator|)
return|;
if|if
condition|(
operator|(
name|td
operator|=
name|runq_steal_from
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
argument_list|,
name|cpu
argument_list|,
name|tdq
operator|->
name|tdq_ridx
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
return|return
operator|(
name|td
operator|)
return|;
return|return
operator|(
name|runq_steal
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|,
name|cpu
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Sets the thread lock and ts_cpu to match the requested cpu.  Unlocks the  * current lock and returns with the assigned queue locked.  */
end_comment

begin_function
specifier|static
specifier|inline
name|struct
name|tdq
modifier|*
name|sched_setcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|cpu
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_cpu
operator|=
name|cpu
expr_stmt|;
comment|/* 	 * If the lock matches just return the queue. 	 */
if|if
condition|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
condition|)
return|return
operator|(
name|tdq
operator|)
return|;
ifdef|#
directive|ifdef
name|notyet
comment|/* 	 * If the thread isn't running its lockptr is a 	 * turnstile or a sleepqueue.  We can just lock_set without 	 * blocking. 	 */
if|if
condition|(
name|TD_CAN_RUN
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|thread_lock_set
argument_list|(
name|td
argument_list|,
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|tdq
operator|)
return|;
block|}
endif|#
directive|endif
comment|/* 	 * The hard case, migration, we need to block the thread first to 	 * prevent order reversals with other cpus locks. 	 */
name|spinlock_enter
argument_list|()
expr_stmt|;
name|thread_lock_block
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|thread_lock_unblock
argument_list|(
name|td
argument_list|,
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|spinlock_exit
argument_list|()
expr_stmt|;
return|return
operator|(
name|tdq
operator|)
return|;
block|}
end_function

begin_expr_stmt
name|SCHED_STAT_DEFINE
argument_list|(
name|pickcpu_intrbind
argument_list|,
literal|"Soft interrupt binding"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SCHED_STAT_DEFINE
argument_list|(
name|pickcpu_idle_affinity
argument_list|,
literal|"Picked idle cpu based on affinity"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SCHED_STAT_DEFINE
argument_list|(
name|pickcpu_affinity
argument_list|,
literal|"Picked cpu based on affinity"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SCHED_STAT_DEFINE
argument_list|(
name|pickcpu_lowest
argument_list|,
literal|"Selected lowest load"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SCHED_STAT_DEFINE
argument_list|(
name|pickcpu_local
argument_list|,
literal|"Migrated to current cpu"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SCHED_STAT_DEFINE
argument_list|(
name|pickcpu_migration
argument_list|,
literal|"Selection may have caused migration"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|sched_pickcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|cpu_group
modifier|*
name|cg
decl_stmt|,
modifier|*
name|ccg
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|cpuset_t
name|mask
decl_stmt|;
name|int
name|cpu
decl_stmt|,
name|pri
decl_stmt|,
name|self
decl_stmt|;
name|self
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
condition|)
return|return
operator|(
name|self
operator|)
return|;
comment|/* 	 * Don't migrate a running thread from sched_switch(). 	 */
if|if
condition|(
operator|(
name|flags
operator|&
name|SRQ_OURSELF
operator|)
operator|||
operator|!
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
condition|)
return|return
operator|(
name|ts
operator|->
name|ts_cpu
operator|)
return|;
comment|/* 	 * Prefer to run interrupt threads on the processors that generate 	 * the interrupt. 	 */
name|pri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<=
name|PRI_MAX_ITHD
operator|&&
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|self
argument_list|)
operator|&&
name|curthread
operator|->
name|td_intr_nesting_level
operator|&&
name|ts
operator|->
name|ts_cpu
operator|!=
name|self
condition|)
block|{
name|SCHED_STAT_INC
argument_list|(
name|pickcpu_intrbind
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_cpu
operator|=
name|self
expr_stmt|;
if|if
condition|(
name|TDQ_CPU
argument_list|(
name|self
argument_list|)
operator|->
name|tdq_lowpri
operator|>
name|pri
condition|)
block|{
name|SCHED_STAT_INC
argument_list|(
name|pickcpu_affinity
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|->
name|ts_cpu
operator|)
return|;
block|}
block|}
comment|/* 	 * If the thread can run on the last cpu and the affinity has not 	 * expired or it is idle run it there. 	 */
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
name|cg
operator|=
name|tdq
operator|->
name|tdq_cg
expr_stmt|;
if|if
condition|(
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|)
operator|&&
name|tdq
operator|->
name|tdq_lowpri
operator|>=
name|PRI_MIN_IDLE
operator|&&
name|SCHED_AFFINITY
argument_list|(
name|ts
argument_list|,
name|CG_SHARE_L2
argument_list|)
condition|)
block|{
if|if
condition|(
name|cg
operator|->
name|cg_flags
operator|&
name|CG_FLAG_THREAD
condition|)
block|{
name|CPUSET_FOREACH
argument_list|(
argument|cpu
argument_list|,
argument|cg->cg_mask
argument_list|)
block|{
if|if
condition|(
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
operator|->
name|tdq_lowpri
operator|<
name|PRI_MIN_IDLE
condition|)
break|break;
block|}
block|}
else|else
name|cpu
operator|=
name|INT_MAX
expr_stmt|;
if|if
condition|(
name|cpu
operator|>
name|mp_maxid
condition|)
block|{
name|SCHED_STAT_INC
argument_list|(
name|pickcpu_idle_affinity
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|->
name|ts_cpu
operator|)
return|;
block|}
block|}
comment|/* 	 * Search for the last level cache CPU group in the tree. 	 * Skip caches with expired affinity time and SMT groups. 	 * Affinity to higher level caches will be handled less aggressively. 	 */
for|for
control|(
name|ccg
operator|=
name|NULL
init|;
name|cg
operator|!=
name|NULL
condition|;
name|cg
operator|=
name|cg
operator|->
name|cg_parent
control|)
block|{
if|if
condition|(
name|cg
operator|->
name|cg_flags
operator|&
name|CG_FLAG_THREAD
condition|)
continue|continue;
if|if
condition|(
operator|!
name|SCHED_AFFINITY
argument_list|(
name|ts
argument_list|,
name|cg
operator|->
name|cg_level
argument_list|)
condition|)
continue|continue;
name|ccg
operator|=
name|cg
expr_stmt|;
block|}
if|if
condition|(
name|ccg
operator|!=
name|NULL
condition|)
name|cg
operator|=
name|ccg
expr_stmt|;
name|cpu
operator|=
operator|-
literal|1
expr_stmt|;
comment|/* Search the group for the less loaded idle CPU we can run now. */
name|mask
operator|=
name|td
operator|->
name|td_cpuset
operator|->
name|cs_mask
expr_stmt|;
if|if
condition|(
name|cg
operator|!=
name|NULL
operator|&&
name|cg
operator|!=
name|cpu_top
operator|&&
name|CPU_CMP
argument_list|(
operator|&
name|cg
operator|->
name|cg_mask
argument_list|,
operator|&
name|cpu_top
operator|->
name|cg_mask
argument_list|)
operator|!=
literal|0
condition|)
name|cpu
operator|=
name|sched_lowest
argument_list|(
name|cg
argument_list|,
name|mask
argument_list|,
name|max
argument_list|(
name|pri
argument_list|,
name|PRI_MAX_TIMESHARE
argument_list|)
argument_list|,
name|INT_MAX
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
comment|/* Search globally for the less loaded CPU we can run now. */
if|if
condition|(
name|cpu
operator|==
operator|-
literal|1
condition|)
name|cpu
operator|=
name|sched_lowest
argument_list|(
name|cpu_top
argument_list|,
name|mask
argument_list|,
name|pri
argument_list|,
name|INT_MAX
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
comment|/* Search globally for the less loaded CPU. */
if|if
condition|(
name|cpu
operator|==
operator|-
literal|1
condition|)
name|cpu
operator|=
name|sched_lowest
argument_list|(
name|cpu_top
argument_list|,
name|mask
argument_list|,
operator|-
literal|1
argument_list|,
name|INT_MAX
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|cpu
operator|!=
operator|-
literal|1
argument_list|,
operator|(
literal|"sched_pickcpu: Failed to find a cpu."
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Compare the lowest loaded cpu to current cpu. 	 */
if|if
condition|(
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|self
argument_list|)
operator|&&
name|TDQ_CPU
argument_list|(
name|self
argument_list|)
operator|->
name|tdq_lowpri
operator|>
name|pri
operator|&&
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
operator|->
name|tdq_lowpri
operator|<
name|PRI_MIN_IDLE
operator|&&
name|TDQ_CPU
argument_list|(
name|self
argument_list|)
operator|->
name|tdq_load
operator|<=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
operator|->
name|tdq_load
operator|+
literal|1
condition|)
block|{
name|SCHED_STAT_INC
argument_list|(
name|pickcpu_local
argument_list|)
expr_stmt|;
name|cpu
operator|=
name|self
expr_stmt|;
block|}
else|else
name|SCHED_STAT_INC
argument_list|(
name|pickcpu_lowest
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
operator|!=
name|ts
operator|->
name|ts_cpu
condition|)
name|SCHED_STAT_INC
argument_list|(
name|pickcpu_migration
argument_list|)
expr_stmt|;
return|return
operator|(
name|cpu
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Pick the highest priority task we have and return it.  */
end_comment

begin_function
specifier|static
name|struct
name|thread
modifier|*
name|tdq_choose
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|=
name|runq_choose
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_realtime
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|NULL
condition|)
return|return
operator|(
name|td
operator|)
return|;
name|td
operator|=
name|runq_choose_from
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
argument_list|,
name|tdq
operator|->
name|tdq_ridx
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
name|td
operator|->
name|td_priority
operator|>=
name|PRI_MIN_BATCH
argument_list|,
operator|(
literal|"tdq_choose: Invalid priority on timeshare queue %d"
operator|,
name|td
operator|->
name|td_priority
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|td
operator|)
return|;
block|}
name|td
operator|=
name|runq_choose
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
name|td
operator|->
name|td_priority
operator|>=
name|PRI_MIN_IDLE
argument_list|,
operator|(
literal|"tdq_choose: Invalid priority on idle queue %d"
operator|,
name|td
operator|->
name|td_priority
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|td
operator|)
return|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Initialize a thread queue.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_setup
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
if|if
condition|(
name|bootverbose
condition|)
name|printf
argument_list|(
literal|"ULE: setup cpu %d\n"
argument_list|,
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|runq_init
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_realtime
argument_list|)
expr_stmt|;
name|runq_init
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
argument_list|)
expr_stmt|;
name|runq_init
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|)
expr_stmt|;
name|snprintf
argument_list|(
name|tdq
operator|->
name|tdq_name
argument_list|,
sizeof|sizeof
argument_list|(
name|tdq
operator|->
name|tdq_name
argument_list|)
argument_list|,
literal|"sched lock %d"
argument_list|,
operator|(
name|int
operator|)
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_lock
argument_list|,
name|tdq
operator|->
name|tdq_name
argument_list|,
literal|"sched lock"
argument_list|,
name|MTX_SPIN
operator||
name|MTX_RECURSE
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|KTR
name|snprintf
argument_list|(
name|tdq
operator|->
name|tdq_loadname
argument_list|,
sizeof|sizeof
argument_list|(
name|tdq
operator|->
name|tdq_loadname
argument_list|)
argument_list|,
literal|"CPU %d load"
argument_list|,
operator|(
name|int
operator|)
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function
specifier|static
name|void
name|sched_setup_smp
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|i
decl_stmt|;
name|cpu_top
operator|=
name|smp_topo
argument_list|()
expr_stmt|;
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
block|{
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|tdq_setup
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_cg
operator|=
name|smp_topo_find
argument_list|(
name|cpu_top
argument_list|,
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
name|tdq
operator|->
name|tdq_cg
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"Can't find cpu group for %d\n"
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
name|balance_tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|sched_balance
argument_list|()
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Setup the thread queues and initialize the topology based on MD  * information.  */
end_comment

begin_function
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|sched_setup_smp
argument_list|()
expr_stmt|;
else|#
directive|else
name|tdq_setup
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* Add thread0's load since it's running. */
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|thread0
operator|.
name|td_lock
operator|=
name|TDQ_LOCKPTR
argument_list|(
name|TDQ_SELF
argument_list|()
argument_list|)
expr_stmt|;
name|tdq_load_add
argument_list|(
name|tdq
argument_list|,
operator|&
name|thread0
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|thread0
operator|.
name|td_priority
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine determines time constants after stathz and hz are setup.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|sched_initticks
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|int
name|incr
decl_stmt|;
name|realstathz
operator|=
name|stathz
condition|?
name|stathz
else|:
name|hz
expr_stmt|;
name|sched_slice
operator|=
name|realstathz
operator|/
name|SCHED_SLICE_DEFAULT_DIVISOR
expr_stmt|;
name|sched_slice_min
operator|=
name|sched_slice
operator|/
name|SCHED_SLICE_MIN_DIVISOR
expr_stmt|;
name|hogticks
operator|=
name|imax
argument_list|(
literal|1
argument_list|,
operator|(
literal|2
operator|*
name|hz
operator|*
name|sched_slice
operator|+
name|realstathz
operator|/
literal|2
operator|)
operator|/
name|realstathz
argument_list|)
expr_stmt|;
comment|/* 	 * tickincr is shifted out by 10 to avoid rounding errors due to 	 * hz not being evenly divisible by stathz on all platforms. 	 */
name|incr
operator|=
operator|(
name|hz
operator|<<
name|SCHED_TICK_SHIFT
operator|)
operator|/
name|realstathz
expr_stmt|;
comment|/* 	 * This does not work for values of stathz that are more than 	 * 1<< SCHED_TICK_SHIFT * hz.  In practice this does not happen. 	 */
if|if
condition|(
name|incr
operator|==
literal|0
condition|)
name|incr
operator|=
literal|1
expr_stmt|;
name|tickincr
operator|=
name|incr
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * Set the default balance interval now that we know 	 * what realstathz is. 	 */
name|balance_interval
operator|=
name|realstathz
expr_stmt|;
name|affinity
operator|=
name|SCHED_AFFINITY_DEFAULT
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|sched_idlespinthresh
operator|<
literal|0
condition|)
name|sched_idlespinthresh
operator|=
literal|2
operator|*
name|max
argument_list|(
literal|10000
argument_list|,
literal|6
operator|*
name|hz
argument_list|)
operator|/
name|realstathz
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This is the core of the interactivity algorithm.  Determines a score based  * on past behavior.  It is the ratio of sleep time to run time scaled to  * a [0, 100] integer.  This is the voluntary sleep time of a process, which  * differs from the cpu usage because it does not account for time spent  * waiting on a run-queue.  Would be prettier if we had floating point.  */
end_comment

begin_function
specifier|static
name|int
name|sched_interact_score
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|div
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
comment|/* 	 * The score is only needed if this is likely to be an interactive 	 * task.  Don't go through the expense of computing it if there's 	 * no chance. 	 */
if|if
condition|(
name|sched_interact
operator|<=
name|SCHED_INTERACT_HALF
operator|&&
name|ts
operator|->
name|ts_runtime
operator|>=
name|ts
operator|->
name|ts_slptime
condition|)
return|return
operator|(
name|SCHED_INTERACT_HALF
operator|)
return|;
if|if
condition|(
name|ts
operator|->
name|ts_runtime
operator|>
name|ts
operator|->
name|ts_slptime
condition|)
block|{
name|div
operator|=
name|max
argument_list|(
literal|1
argument_list|,
name|ts
operator|->
name|ts_runtime
operator|/
name|SCHED_INTERACT_HALF
argument_list|)
expr_stmt|;
return|return
operator|(
name|SCHED_INTERACT_HALF
operator|+
operator|(
name|SCHED_INTERACT_HALF
operator|-
operator|(
name|ts
operator|->
name|ts_slptime
operator|/
name|div
operator|)
operator|)
operator|)
return|;
block|}
if|if
condition|(
name|ts
operator|->
name|ts_slptime
operator|>
name|ts
operator|->
name|ts_runtime
condition|)
block|{
name|div
operator|=
name|max
argument_list|(
literal|1
argument_list|,
name|ts
operator|->
name|ts_slptime
operator|/
name|SCHED_INTERACT_HALF
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|->
name|ts_runtime
operator|/
name|div
operator|)
return|;
block|}
comment|/* runtime == slptime */
if|if
condition|(
name|ts
operator|->
name|ts_runtime
condition|)
return|return
operator|(
name|SCHED_INTERACT_HALF
operator|)
return|;
comment|/* 	 * This can happen if slptime and runtime are 0. 	 */
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Scale the scheduling priority according to the "interactivity" of this  * process.  */
end_comment

begin_function
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|int
name|score
decl_stmt|;
name|int
name|pri
decl_stmt|;
if|if
condition|(
name|PRI_BASE
argument_list|(
name|td
operator|->
name|td_pri_class
argument_list|)
operator|!=
name|PRI_TIMESHARE
condition|)
return|return;
comment|/* 	 * If the score is interactive we place the thread in the realtime 	 * queue with a priority that is less than kernel and interrupt 	 * priorities.  These threads are not subject to nice restrictions. 	 * 	 * Scores greater than this are placed on the normal timeshare queue 	 * where the priority is partially decided by the most recent cpu 	 * utilization and the rest is decided by nice value. 	 * 	 * The nice value of the process has a linear effect on the calculated 	 * score.  Negative nice values make it easier for a thread to be 	 * considered interactive. 	 */
name|score
operator|=
name|imax
argument_list|(
literal|0
argument_list|,
name|sched_interact_score
argument_list|(
name|td
argument_list|)
operator|+
name|td
operator|->
name|td_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
if|if
condition|(
name|score
operator|<
name|sched_interact
condition|)
block|{
name|pri
operator|=
name|PRI_MIN_INTERACT
expr_stmt|;
name|pri
operator|+=
operator|(
operator|(
name|PRI_MAX_INTERACT
operator|-
name|PRI_MIN_INTERACT
operator|+
literal|1
operator|)
operator|/
name|sched_interact
operator|)
operator|*
name|score
expr_stmt|;
name|KASSERT
argument_list|(
name|pri
operator|>=
name|PRI_MIN_INTERACT
operator|&&
name|pri
operator|<=
name|PRI_MAX_INTERACT
argument_list|,
operator|(
literal|"sched_priority: invalid interactive priority %d score %d"
operator|,
name|pri
operator|,
name|score
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pri
operator|=
name|SCHED_PRI_MIN
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_sched
operator|->
name|ts_ticks
condition|)
name|pri
operator|+=
name|min
argument_list|(
name|SCHED_PRI_TICKS
argument_list|(
name|td
operator|->
name|td_sched
argument_list|)
argument_list|,
name|SCHED_PRI_RANGE
operator|-
literal|1
argument_list|)
expr_stmt|;
name|pri
operator|+=
name|SCHED_PRI_NICE
argument_list|(
name|td
operator|->
name|td_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pri
operator|>=
name|PRI_MIN_BATCH
operator|&&
name|pri
operator|<=
name|PRI_MAX_BATCH
argument_list|,
operator|(
literal|"sched_priority: invalid priority %d: nice %d, "
literal|"ticks %d ftick %d ltick %d tick pri %d"
operator|,
name|pri
operator|,
name|td
operator|->
name|td_proc
operator|->
name|p_nice
operator|,
name|td
operator|->
name|td_sched
operator|->
name|ts_ticks
operator|,
name|td
operator|->
name|td_sched
operator|->
name|ts_ftick
operator|,
name|td
operator|->
name|td_sched
operator|->
name|ts_ltick
operator|,
name|SCHED_PRI_TICKS
argument_list|(
name|td
operator|->
name|td_sched
argument_list|)
operator|)
argument_list|)
expr_stmt|;
block|}
name|sched_user_prio
argument_list|(
name|td
argument_list|,
name|pri
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_comment
comment|/*  * This routine enforces a maximum limit on the amount of scheduling history  * kept.  It is called after either the slptime or runtime is adjusted.  This  * function is ugly due to integer math.  */
end_comment

begin_function
specifier|static
name|void
name|sched_interact_update
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|u_int
name|sum
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|sum
operator|=
name|ts
operator|->
name|ts_runtime
operator|+
name|ts
operator|->
name|ts_slptime
expr_stmt|;
if|if
condition|(
name|sum
operator|<
name|SCHED_SLP_RUN_MAX
condition|)
return|return;
comment|/* 	 * This only happens from two places: 	 * 1) We have added an unusual amount of run time from fork_exit. 	 * 2) We have added an unusual amount of sleep time from sched_sleep(). 	 */
if|if
condition|(
name|sum
operator|>
name|SCHED_SLP_RUN_MAX
operator|*
literal|2
condition|)
block|{
if|if
condition|(
name|ts
operator|->
name|ts_runtime
operator|>
name|ts
operator|->
name|ts_slptime
condition|)
block|{
name|ts
operator|->
name|ts_runtime
operator|=
name|SCHED_SLP_RUN_MAX
expr_stmt|;
name|ts
operator|->
name|ts_slptime
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|ts
operator|->
name|ts_slptime
operator|=
name|SCHED_SLP_RUN_MAX
expr_stmt|;
name|ts
operator|->
name|ts_runtime
operator|=
literal|1
expr_stmt|;
block|}
return|return;
block|}
comment|/* 	 * If we have exceeded by more than 1/5th then the algorithm below 	 * will not bring us back into range.  Dividing by two here forces 	 * us into the range of [4/5 * SCHED_INTERACT_MAX, SCHED_INTERACT_MAX] 	 */
if|if
condition|(
name|sum
operator|>
operator|(
name|SCHED_SLP_RUN_MAX
operator|/
literal|5
operator|)
operator|*
literal|6
condition|)
block|{
name|ts
operator|->
name|ts_runtime
operator|/=
literal|2
expr_stmt|;
name|ts
operator|->
name|ts_slptime
operator|/=
literal|2
expr_stmt|;
return|return;
block|}
name|ts
operator|->
name|ts_runtime
operator|=
operator|(
name|ts
operator|->
name|ts_runtime
operator|/
literal|5
operator|)
operator|*
literal|4
expr_stmt|;
name|ts
operator|->
name|ts_slptime
operator|=
operator|(
name|ts
operator|->
name|ts_slptime
operator|/
literal|5
operator|)
operator|*
literal|4
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Scale back the interactivity history when a child thread is created.  The  * history is inherited from the parent but the thread may behave totally  * differently.  For example, a shell spawning a compiler process.  We want  * to learn that the compiler is behaving badly very quickly.  */
end_comment

begin_function
specifier|static
name|void
name|sched_interact_fork
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|int
name|ratio
decl_stmt|;
name|int
name|sum
decl_stmt|;
name|sum
operator|=
name|td
operator|->
name|td_sched
operator|->
name|ts_runtime
operator|+
name|td
operator|->
name|td_sched
operator|->
name|ts_slptime
expr_stmt|;
if|if
condition|(
name|sum
operator|>
name|SCHED_SLP_RUN_FORK
condition|)
block|{
name|ratio
operator|=
name|sum
operator|/
name|SCHED_SLP_RUN_FORK
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_runtime
operator|/=
name|ratio
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_slptime
operator|/=
name|ratio
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Called from proc0_init() to setup the scheduler fields.  */
end_comment

begin_function
name|void
name|schedinit
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * Set up the scheduler specific parts of proc0. 	 */
name|proc0
operator|.
name|p_sched
operator|=
name|NULL
expr_stmt|;
comment|/* XXX */
name|thread0
operator|.
name|td_sched
operator|=
operator|&
name|td_sched0
expr_stmt|;
name|td_sched0
operator|.
name|ts_ltick
operator|=
name|ticks
expr_stmt|;
name|td_sched0
operator|.
name|ts_ftick
operator|=
name|ticks
expr_stmt|;
name|td_sched0
operator|.
name|ts_slice
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This is only somewhat accurate since given many processes of the same  * priority they will switch when their slices run out, which will be  * at most sched_slice stathz ticks.  */
end_comment

begin_function
name|int
name|sched_rr_interval
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* Convert sched_slice from stathz to hz. */
return|return
operator|(
name|imax
argument_list|(
literal|1
argument_list|,
operator|(
name|sched_slice
operator|*
name|hz
operator|+
name|realstathz
operator|/
literal|2
operator|)
operator|/
name|realstathz
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Update the percent cpu tracking information when it is requested or  * the total history exceeds the maximum.  We keep a sliding history of  * tick counts that slowly decays.  This is less precise than the 4BSD  * mechanism since it happens with less regular and frequent events.  */
end_comment

begin_function
specifier|static
name|void
name|sched_pctcpu_update
parameter_list|(
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|,
name|int
name|run
parameter_list|)
block|{
name|int
name|t
init|=
name|ticks
decl_stmt|;
if|if
condition|(
name|t
operator|-
name|ts
operator|->
name|ts_ltick
operator|>=
name|SCHED_TICK_TARG
condition|)
block|{
name|ts
operator|->
name|ts_ticks
operator|=
literal|0
expr_stmt|;
name|ts
operator|->
name|ts_ftick
operator|=
name|t
operator|-
name|SCHED_TICK_TARG
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|t
operator|-
name|ts
operator|->
name|ts_ftick
operator|>=
name|SCHED_TICK_MAX
condition|)
block|{
name|ts
operator|->
name|ts_ticks
operator|=
operator|(
name|ts
operator|->
name|ts_ticks
operator|/
operator|(
name|ts
operator|->
name|ts_ltick
operator|-
name|ts
operator|->
name|ts_ftick
operator|)
operator|)
operator|*
operator|(
name|ts
operator|->
name|ts_ltick
operator|-
operator|(
name|t
operator|-
name|SCHED_TICK_TARG
operator|)
operator|)
expr_stmt|;
name|ts
operator|->
name|ts_ftick
operator|=
name|t
operator|-
name|SCHED_TICK_TARG
expr_stmt|;
block|}
if|if
condition|(
name|run
condition|)
name|ts
operator|->
name|ts_ticks
operator|+=
operator|(
name|t
operator|-
name|ts
operator|->
name|ts_ltick
operator|)
operator|<<
name|SCHED_TICK_SHIFT
expr_stmt|;
name|ts
operator|->
name|ts_ltick
operator|=
name|t
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Adjust the priority of a thread.  Move it to the appropriate run-queue  * if necessary.  This is the back-end for several priority related  * functions.  */
end_comment

begin_function
specifier|static
name|void
name|sched_thread_priority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|oldpri
decl_stmt|;
name|KTR_POINT3
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|,
literal|"prio"
argument_list|,
literal|"prio:%d"
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
literal|"new prio:%d"
argument_list|,
name|prio
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|)
expr_stmt|;
name|SDT_PROBE3
argument_list|(
name|sched
argument_list|, , ,
name|change__pri
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
argument_list|,
name|prio
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|curthread
operator|&&
name|prio
operator|<
name|td
operator|->
name|td_priority
condition|)
block|{
name|KTR_POINT3
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|,
literal|"lend prio"
argument_list|,
literal|"prio:%d"
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
literal|"new prio:%d"
argument_list|,
name|prio
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|)
expr_stmt|;
name|SDT_PROBE4
argument_list|(
name|sched
argument_list|, , ,
name|lend__pri
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
argument_list|,
name|prio
argument_list|,
name|curthread
argument_list|)
expr_stmt|;
block|}
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|==
name|prio
condition|)
return|return;
comment|/* 	 * If the priority has been elevated due to priority 	 * propagation, we may have to move ourselves to a new 	 * queue.  This could be optimized to not re-add in some 	 * cases. 	 */
if|if
condition|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
operator|&&
name|prio
operator|<
name|td
operator|->
name|td_priority
condition|)
block|{
name|sched_rem
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_priority
operator|=
name|prio
expr_stmt|;
name|sched_add
argument_list|(
name|td
argument_list|,
name|SRQ_BORROWING
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * If the thread is currently running we may have to adjust the lowpri 	 * information so other cpus are aware of our current priority. 	 */
if|if
condition|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
name|oldpri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|td
operator|->
name|td_priority
operator|=
name|prio
expr_stmt|;
if|if
condition|(
name|prio
operator|<
name|tdq
operator|->
name|tdq_lowpri
condition|)
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|prio
expr_stmt|;
elseif|else
if|if
condition|(
name|tdq
operator|->
name|tdq_lowpri
operator|==
name|oldpri
condition|)
name|tdq_setlowpri
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|)
expr_stmt|;
return|return;
block|}
name|td
operator|->
name|td_priority
operator|=
name|prio
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Update a thread's priority when it is lent another thread's  * priority.  */
end_comment

begin_function
name|void
name|sched_lend_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|td
operator|->
name|td_flags
operator||=
name|TDF_BORROWING
expr_stmt|;
name|sched_thread_priority
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Restore a thread's priority when priority propagation is  * over.  The prio argument is the minimum priority the thread  * needs to have to satisfy other possible priority lending  * requests.  If the thread's regular priority is less  * important than prio, the thread will keep a priority boost  * of prio.  */
end_comment

begin_function
name|void
name|sched_unlend_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|base_pri
decl_stmt|;
if|if
condition|(
name|td
operator|->
name|td_base_pri
operator|>=
name|PRI_MIN_TIMESHARE
operator|&&
name|td
operator|->
name|td_base_pri
operator|<=
name|PRI_MAX_TIMESHARE
condition|)
name|base_pri
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
else|else
name|base_pri
operator|=
name|td
operator|->
name|td_base_pri
expr_stmt|;
if|if
condition|(
name|prio
operator|>=
name|base_pri
condition|)
block|{
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_BORROWING
expr_stmt|;
name|sched_thread_priority
argument_list|(
name|td
argument_list|,
name|base_pri
argument_list|)
expr_stmt|;
block|}
else|else
name|sched_lend_prio
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Standard entry for setting the priority to an absolute value.  */
end_comment

begin_function
name|void
name|sched_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
comment|/* First, update the base priority. */
name|td
operator|->
name|td_base_pri
operator|=
name|prio
expr_stmt|;
comment|/* 	 * If the thread is borrowing another thread's priority, don't 	 * ever lower the priority. 	 */
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
operator|&&
name|td
operator|->
name|td_priority
operator|<
name|prio
condition|)
return|return;
comment|/* Change the real priority. */
name|oldprio
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|sched_thread_priority
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
comment|/* 	 * If the thread is on a turnstile, then let the turnstile update 	 * its state. 	 */
if|if
condition|(
name|TD_ON_LOCK
argument_list|(
name|td
argument_list|)
operator|&&
name|oldprio
operator|!=
name|prio
condition|)
name|turnstile_adjust
argument_list|(
name|td
argument_list|,
name|oldprio
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Set the base user priority, does not effect current running priority.  */
end_comment

begin_function
name|void
name|sched_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|td
operator|->
name|td_base_user_pri
operator|=
name|prio
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_lend_user_pri
operator|<=
name|prio
condition|)
return|return;
name|td
operator|->
name|td_user_pri
operator|=
name|prio
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_lend_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_lend_user_pri
operator|=
name|prio
expr_stmt|;
name|td
operator|->
name|td_user_pri
operator|=
name|min
argument_list|(
name|prio
argument_list|,
name|td
operator|->
name|td_base_user_pri
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|>
name|td
operator|->
name|td_user_pri
condition|)
name|sched_prio
argument_list|(
name|td
argument_list|,
name|td
operator|->
name|td_user_pri
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|td
operator|->
name|td_priority
operator|!=
name|td
operator|->
name|td_user_pri
condition|)
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Handle migration from sched_switch().  This happens only for  * cpu binding.  */
end_comment

begin_function
specifier|static
name|struct
name|mtx
modifier|*
name|sched_switch_migrate
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdn
decl_stmt|;
name|tdn
operator|=
name|TDQ_CPU
argument_list|(
name|td
operator|->
name|td_sched
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|)
expr_stmt|;
comment|/* 	 * Do the lock dance required to avoid LOR.  We grab an extra 	 * spinlock nesting to prevent preemption while we're 	 * not holding either run-queue lock. 	 */
name|spinlock_enter
argument_list|()
expr_stmt|;
name|thread_lock_block
argument_list|(
name|td
argument_list|)
expr_stmt|;
comment|/* This releases the lock on tdq. */
comment|/* 	 * Acquire both run-queue locks before placing the thread on the new 	 * run-queue to avoid deadlocks created by placing a thread with a 	 * blocked lock on the run-queue of a remote processor.  The deadlock 	 * occurs when a third processor attempts to lock the two queues in 	 * question while the target processor is spinning with its own 	 * run-queue lock held while waiting for the blocked lock to clear. 	 */
name|tdq_lock_pair
argument_list|(
name|tdn
argument_list|,
name|tdq
argument_list|)
expr_stmt|;
name|tdq_add
argument_list|(
name|tdn
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|tdq_notify
argument_list|(
name|tdn
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|tdn
argument_list|)
expr_stmt|;
name|spinlock_exit
argument_list|()
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
name|TDQ_LOCKPTR
argument_list|(
name|tdn
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Variadic version of thread_lock_unblock() that does not assume td_lock  * is blocked.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|thread_unblock_switch
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|mtx
modifier|*
name|mtx
parameter_list|)
block|{
name|atomic_store_rel_ptr
argument_list|(
operator|(
specifier|volatile
name|uintptr_t
operator|*
operator|)
operator|&
name|td
operator|->
name|td_lock
argument_list|,
operator|(
name|uintptr_t
operator|)
name|mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Switch threads.  This function has to handle threads coming in while  * blocked for some reason, running, or idle.  It also must deal with  * migrating a thread from one queue to another as running threads may  * be assigned elsewhere via binding.  */
end_comment

begin_function
name|void
name|sched_switch
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|newtd
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|mtx
modifier|*
name|mtx
decl_stmt|;
name|int
name|srqflag
decl_stmt|;
name|int
name|cpuid
decl_stmt|,
name|preempted
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|newtd
operator|==
name|NULL
argument_list|,
operator|(
literal|"sched_switch: Unsupported newtd argument"
operator|)
argument_list|)
expr_stmt|;
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|mtx
operator|=
name|td
operator|->
name|td_lock
expr_stmt|;
name|sched_pctcpu_update
argument_list|(
name|ts
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_rltick
operator|=
name|ticks
expr_stmt|;
name|td
operator|->
name|td_lastcpu
operator|=
name|td
operator|->
name|td_oncpu
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|NOCPU
expr_stmt|;
name|preempted
operator|=
operator|!
operator|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_SLICEEND
operator|)
operator|||
operator|(
name|flags
operator|&
name|SWT_RELINQUISH
operator|)
operator|)
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
operator|(
name|TDF_NEEDRESCHED
operator||
name|TDF_SLICEEND
operator|)
expr_stmt|;
name|td
operator|->
name|td_owepreempt
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|!
name|TD_IS_IDLETHREAD
argument_list|(
name|td
argument_list|)
condition|)
name|tdq
operator|->
name|tdq_switchcnt
operator|++
expr_stmt|;
comment|/* 	 * The lock pointer in an idle thread should never change.  Reset it 	 * to CAN_RUN as well. 	 */
if|if
condition|(
name|TD_IS_IDLETHREAD
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|TD_SET_CAN_RUN
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|srqflag
operator|=
name|preempted
condition|?
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
operator||
name|SRQ_PREEMPTED
else|:
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
operator|&&
operator|!
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|)
condition|)
name|ts
operator|->
name|ts_cpu
operator|=
name|sched_pickcpu
argument_list|(
name|td
argument_list|,
literal|0
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|ts
operator|->
name|ts_cpu
operator|==
name|cpuid
condition|)
name|tdq_runq_add
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|,
name|srqflag
argument_list|)
expr_stmt|;
else|else
block|{
name|KASSERT
argument_list|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
operator|||
operator|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_BOUND
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"Thread %p shouldn't migrate"
operator|,
name|td
operator|)
argument_list|)
expr_stmt|;
name|mtx
operator|=
name|sched_switch_migrate
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|,
name|srqflag
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|/* This thread must be going to sleep. */
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|mtx
operator|=
name|thread_lock_block
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * We enter here with the thread blocked and assigned to the 	 * appropriate cpu run-queue or sleep-queue and with the current 	 * thread-queue locked. 	 */
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
operator||
name|MA_NOTRECURSED
argument_list|)
expr_stmt|;
name|newtd
operator|=
name|choosethread
argument_list|()
expr_stmt|;
comment|/* 	 * Call the MD code to switch contexts if necessary. 	 */
if|if
condition|(
name|td
operator|!=
name|newtd
condition|)
block|{
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
if|if
condition|(
name|PMC_PROC_IS_USING_PMCS
argument_list|(
name|td
operator|->
name|td_proc
argument_list|)
condition|)
name|PMC_SWITCH_CONTEXT
argument_list|(
name|td
argument_list|,
name|PMC_FN_CSW_OUT
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|SDT_PROBE2
argument_list|(
name|sched
argument_list|, , ,
name|off__cpu
argument_list|,
name|newtd
argument_list|,
name|newtd
operator|->
name|td_proc
argument_list|)
expr_stmt|;
name|lock_profile_release_lock
argument_list|(
operator|&
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
operator|->
name|lock_object
argument_list|)
expr_stmt|;
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
operator|->
name|mtx_lock
operator|=
operator|(
name|uintptr_t
operator|)
name|newtd
expr_stmt|;
name|sched_pctcpu_update
argument_list|(
name|newtd
operator|->
name|td_sched
argument_list|,
literal|0
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|KDTRACE_HOOKS
comment|/* 		 * If DTrace has set the active vtime enum to anything 		 * other than INACTIVE (0), then it should have set the 		 * function to call. 		 */
if|if
condition|(
name|dtrace_vtime_active
condition|)
call|(
modifier|*
name|dtrace_vtime_switch_func
call|)
argument_list|(
name|newtd
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|cpu_switch
argument_list|(
name|td
argument_list|,
name|newtd
argument_list|,
name|mtx
argument_list|)
expr_stmt|;
comment|/* 		 * We may return from cpu_switch on a different cpu.  However, 		 * we always return with td_lock pointing to the current cpu's 		 * run queue lock. 		 */
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|lock_profile_obtain_lock_success
argument_list|(
operator|&
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
operator|->
name|lock_object
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|__FILE__
argument_list|,
name|__LINE__
argument_list|)
expr_stmt|;
name|SDT_PROBE0
argument_list|(
name|sched
argument_list|, , ,
name|on__cpu
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
if|if
condition|(
name|PMC_PROC_IS_USING_PMCS
argument_list|(
name|td
operator|->
name|td_proc
argument_list|)
condition|)
name|PMC_SWITCH_CONTEXT
argument_list|(
name|td
argument_list|,
name|PMC_FN_CSW_IN
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
else|else
block|{
name|thread_unblock_switch
argument_list|(
name|td
argument_list|,
name|mtx
argument_list|)
expr_stmt|;
name|SDT_PROBE0
argument_list|(
name|sched
argument_list|, , ,
name|remain__cpu
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Assert that all went well and return. 	 */
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
operator||
name|MA_NOTRECURSED
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|cpuid
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Adjust thread priorities as a result of a nice request.  */
end_comment

begin_function
name|void
name|sched_nice
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|int
name|nice
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|p
operator|->
name|p_nice
operator|=
name|nice
expr_stmt|;
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_prio
argument_list|(
name|td
argument_list|,
name|td
operator|->
name|td_base_user_pri
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Record the sleep time for the interactivity scorer.  */
end_comment

begin_function
name|void
name|sched_sleep
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|prio
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_slptick
operator|=
name|ticks
expr_stmt|;
if|if
condition|(
name|TD_IS_SUSPENDED
argument_list|(
name|td
argument_list|)
operator|||
name|prio
operator|>=
name|PSOCK
condition|)
name|td
operator|->
name|td_flags
operator||=
name|TDF_CANSWAP
expr_stmt|;
if|if
condition|(
name|PRI_BASE
argument_list|(
name|td
operator|->
name|td_pri_class
argument_list|)
operator|!=
name|PRI_TIMESHARE
condition|)
return|return;
if|if
condition|(
name|static_boost
operator|==
literal|1
operator|&&
name|prio
condition|)
name|sched_prio
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|static_boost
operator|&&
name|td
operator|->
name|td_priority
operator|>
name|static_boost
condition|)
name|sched_prio
argument_list|(
name|td
argument_list|,
name|static_boost
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Schedule a thread to resume execution and record how long it voluntarily  * slept.  We also update the pctcpu, interactivity, and priority.  */
end_comment

begin_function
name|void
name|sched_wakeup
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|slptick
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_CANSWAP
expr_stmt|;
comment|/* 	 * If we slept for more than a tick update our interactivity and 	 * priority. 	 */
name|slptick
operator|=
name|td
operator|->
name|td_slptick
expr_stmt|;
name|td
operator|->
name|td_slptick
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|slptick
operator|&&
name|slptick
operator|!=
name|ticks
condition|)
block|{
name|ts
operator|->
name|ts_slptime
operator|+=
operator|(
name|ticks
operator|-
name|slptick
operator|)
operator|<<
name|SCHED_TICK_SHIFT
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_pctcpu_update
argument_list|(
name|ts
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Reset the slice value since we slept and advanced the round-robin. 	 */
name|ts
operator|->
name|ts_slice
operator|=
literal|0
expr_stmt|;
name|sched_add
argument_list|(
name|td
argument_list|,
name|SRQ_BORING
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Penalize the parent for creating a new child and initialize the child's  * priority.  */
end_comment

begin_function
name|void
name|sched_fork
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|sched_pctcpu_update
argument_list|(
name|td
operator|->
name|td_sched
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|sched_fork_thread
argument_list|(
name|td
argument_list|,
name|child
argument_list|)
expr_stmt|;
comment|/* 	 * Penalize the parent and child for forking. 	 */
name|sched_interact_fork
argument_list|(
name|child
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|child
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_runtime
operator|+=
name|tickincr
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Fork a new thread, may be within the same process.  */
end_comment

begin_function
name|void
name|sched_fork_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts2
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize child. 	 */
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|ts2
operator|=
name|child
operator|->
name|td_sched
expr_stmt|;
name|child
operator|->
name|td_lock
operator|=
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|child
operator|->
name|td_cpuset
operator|=
name|cpuset_ref
argument_list|(
name|td
operator|->
name|td_cpuset
argument_list|)
expr_stmt|;
name|ts2
operator|->
name|ts_cpu
operator|=
name|ts
operator|->
name|ts_cpu
expr_stmt|;
name|ts2
operator|->
name|ts_flags
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Grab our parents cpu estimation information. 	 */
name|ts2
operator|->
name|ts_ticks
operator|=
name|ts
operator|->
name|ts_ticks
expr_stmt|;
name|ts2
operator|->
name|ts_ltick
operator|=
name|ts
operator|->
name|ts_ltick
expr_stmt|;
name|ts2
operator|->
name|ts_ftick
operator|=
name|ts
operator|->
name|ts_ftick
expr_stmt|;
comment|/* 	 * Do not inherit any borrowed priority from the parent. 	 */
name|child
operator|->
name|td_priority
operator|=
name|child
operator|->
name|td_base_pri
expr_stmt|;
comment|/* 	 * And update interactivity score. 	 */
name|ts2
operator|->
name|ts_slptime
operator|=
name|ts
operator|->
name|ts_slptime
expr_stmt|;
name|ts2
operator|->
name|ts_runtime
operator|=
name|ts
operator|->
name|ts_runtime
expr_stmt|;
comment|/* Attempt to quickly learn interactivity. */
name|ts2
operator|->
name|ts_slice
operator|=
name|tdq_slice
argument_list|(
name|tdq
argument_list|)
operator|-
name|sched_slice_min
expr_stmt|;
ifdef|#
directive|ifdef
name|KTR
name|bzero
argument_list|(
name|ts2
operator|->
name|ts_name
argument_list|,
sizeof|sizeof
argument_list|(
name|ts2
operator|->
name|ts_name
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  * Adjust the priority class of a thread.  */
end_comment

begin_function
name|void
name|sched_class
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|class
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|==
name|class
condition|)
return|return;
name|td
operator|->
name|td_pri_class
operator|=
name|class
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return some of the child's priority and interactivity to the parent.  */
end_comment

begin_function
name|void
name|sched_exit
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|KTR_STATE1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|child
argument_list|)
argument_list|,
literal|"proc exit"
argument_list|,
literal|"prio:%d"
argument_list|,
name|child
operator|->
name|td_priority
argument_list|)
expr_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|=
name|FIRST_THREAD_IN_PROC
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|sched_exit_thread
argument_list|(
name|td
argument_list|,
name|child
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Penalize another thread for the time spent on this one.  This helps to  * worsen the priority and interactivity of processes which schedule batch  * jobs such as make.  This has little effect on the make process itself but  * causes new processes spawned by it to receive worse scores immediately.  */
end_comment

begin_function
name|void
name|sched_exit_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|KTR_STATE1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|child
argument_list|)
argument_list|,
literal|"thread exit"
argument_list|,
literal|"prio:%d"
argument_list|,
name|child
operator|->
name|td_priority
argument_list|)
expr_stmt|;
comment|/* 	 * Give the child's runtime to the parent without returning the 	 * sleep time as a penalty to the parent.  This causes shells that 	 * launch expensive things to mark their children as expensive. 	 */
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_runtime
operator|+=
name|child
operator|->
name|td_sched
operator|->
name|ts_runtime
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_preempt
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|SDT_PROBE2
argument_list|(
name|sched
argument_list|, , ,
name|surrender
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
argument_list|)
expr_stmt|;
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_ipipending
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|>
name|tdq
operator|->
name|tdq_lowpri
condition|)
block|{
name|int
name|flags
decl_stmt|;
name|flags
operator|=
name|SW_INVOL
operator||
name|SW_PREEMPT
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_critnest
operator|>
literal|1
condition|)
name|td
operator|->
name|td_owepreempt
operator|=
literal|1
expr_stmt|;
elseif|else
if|if
condition|(
name|TD_IS_IDLETHREAD
argument_list|(
name|td
argument_list|)
condition|)
name|mi_switch
argument_list|(
name|flags
operator||
name|SWT_REMOTEWAKEIDLE
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
else|else
name|mi_switch
argument_list|(
name|flags
operator||
name|SWT_REMOTEPREEMPT
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Fix priorities on return to user-space.  Priorities may be elevated due  * to static priorities in msleep() or similar.  */
end_comment

begin_function
name|void
name|sched_userret
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
comment|/* 	 * XXX we cheat slightly on the locking here to avoid locking in   	 * the usual case.  Setting td_priority here is essentially an 	 * incomplete workaround for not setting it properly elsewhere. 	 * Now that some interrupt handlers are threads, not setting it 	 * properly elsewhere can clobber it in the window between setting 	 * it here and returning to user mode, so don't waste time setting 	 * it perfectly here. 	 */
name|KASSERT
argument_list|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"thread with borrowed priority returning to userland"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|!=
name|td
operator|->
name|td_user_pri
condition|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_priority
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|td
operator|->
name|td_base_pri
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|tdq_setlowpri
argument_list|(
name|TDQ_SELF
argument_list|()
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Handle a stathz tick.  This is really only relevant for timeshare  * threads.  */
end_comment

begin_function
name|void
name|sched_clock
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * We run the long term load balancer infrequently on the first cpu. 	 */
if|if
condition|(
name|balance_tdq
operator|==
name|tdq
condition|)
block|{
if|if
condition|(
name|balance_ticks
operator|&&
operator|--
name|balance_ticks
operator|==
literal|0
condition|)
name|sched_balance
argument_list|()
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* 	 * Save the old switch count so we have a record of the last ticks 	 * activity.   Initialize the new switch count based on our load. 	 * If there is some activity seed it to reflect that. 	 */
name|tdq
operator|->
name|tdq_oldswitchcnt
operator|=
name|tdq
operator|->
name|tdq_switchcnt
expr_stmt|;
name|tdq
operator|->
name|tdq_switchcnt
operator|=
name|tdq
operator|->
name|tdq_load
expr_stmt|;
comment|/* 	 * Advance the insert index once for each tick to ensure that all 	 * threads get a chance to run. 	 */
if|if
condition|(
name|tdq
operator|->
name|tdq_idx
operator|==
name|tdq
operator|->
name|tdq_ridx
condition|)
block|{
name|tdq
operator|->
name|tdq_idx
operator|=
operator|(
name|tdq
operator|->
name|tdq_idx
operator|+
literal|1
operator|)
operator|%
name|RQ_NQS
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
operator|.
name|rq_queues
index|[
name|tdq
operator|->
name|tdq_ridx
index|]
argument_list|)
condition|)
name|tdq
operator|->
name|tdq_ridx
operator|=
name|tdq
operator|->
name|tdq_idx
expr_stmt|;
block|}
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|sched_pctcpu_update
argument_list|(
name|ts
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|&
name|PRI_FIFO_BIT
condition|)
return|return;
if|if
condition|(
name|PRI_BASE
argument_list|(
name|td
operator|->
name|td_pri_class
argument_list|)
operator|==
name|PRI_TIMESHARE
condition|)
block|{
comment|/* 		 * We used a tick; charge it to the thread so 		 * that we can compute our interactivity. 		 */
name|td
operator|->
name|td_sched
operator|->
name|ts_runtime
operator|+=
name|tickincr
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Force a context switch if the current thread has used up a full 	 * time slice (default is 100ms). 	 */
if|if
condition|(
operator|!
name|TD_IS_IDLETHREAD
argument_list|(
name|td
argument_list|)
operator|&&
operator|++
name|ts
operator|->
name|ts_slice
operator|>=
name|tdq_slice
argument_list|(
name|tdq
argument_list|)
condition|)
block|{
name|ts
operator|->
name|ts_slice
operator|=
literal|0
expr_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
operator||
name|TDF_SLICEEND
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Called once per hz tick.  */
end_comment

begin_function
name|void
name|sched_tick
parameter_list|(
name|int
name|cnt
parameter_list|)
block|{  }
end_function

begin_comment
comment|/*  * Return whether the current CPU has runnable tasks.  Used for in-kernel  * cooperative idle threads.  */
end_comment

begin_function
name|int
name|sched_runnable
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|load
decl_stmt|;
name|load
operator|=
literal|1
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|curthread
operator|->
name|td_flags
operator|&
name|TDF_IDLETD
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|tdq
operator|->
name|tdq_load
operator|>
literal|0
condition|)
goto|goto
name|out
goto|;
block|}
elseif|else
if|if
condition|(
name|tdq
operator|->
name|tdq_load
operator|-
literal|1
operator|>
literal|0
condition|)
goto|goto
name|out
goto|;
name|load
operator|=
literal|0
expr_stmt|;
name|out
label|:
return|return
operator|(
name|load
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Choose the highest priority thread to run.  The thread is removed from  * the run-queue while running however the load remains.  For SMP we set  * the tdq in the global idle bitmask if it idles here.  */
end_comment

begin_function
name|struct
name|thread
modifier|*
name|sched_choose
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|=
name|tdq_choose
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
condition|)
block|{
name|tdq_runq_rem
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
return|return
operator|(
name|td
operator|)
return|;
block|}
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|PRI_MAX_IDLE
expr_stmt|;
return|return
operator|(
name|PCPU_GET
argument_list|(
name|idlethread
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Set owepreempt if necessary.  Preemption never happens directly in ULE,  * we always request it once we exit a critical section.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|sched_setpreempt
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|ctd
decl_stmt|;
name|int
name|cpri
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|curthread
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ctd
operator|=
name|curthread
expr_stmt|;
name|pri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|cpri
operator|=
name|ctd
operator|->
name|td_priority
expr_stmt|;
if|if
condition|(
name|pri
operator|<
name|cpri
condition|)
name|ctd
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
if|if
condition|(
name|panicstr
operator|!=
name|NULL
operator|||
name|pri
operator|>=
name|cpri
operator|||
name|cold
operator|||
name|TD_IS_INHIBITED
argument_list|(
name|ctd
argument_list|)
condition|)
return|return;
if|if
condition|(
operator|!
name|sched_shouldpreempt
argument_list|(
name|pri
argument_list|,
name|cpri
argument_list|,
literal|0
argument_list|)
condition|)
return|return;
name|ctd
operator|->
name|td_owepreempt
operator|=
literal|1
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Add a thread to a thread queue.  Select the appropriate runq and add the  * thread to it.  This is the internal function called when the tdq is  * predetermined.  */
end_comment

begin_function
name|void
name|tdq_add
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|td
operator|->
name|td_inhibitors
operator|==
literal|0
operator|)
argument_list|,
operator|(
literal|"sched_add: trying to run inhibited thread"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|TD_CAN_RUN
argument_list|(
name|td
argument_list|)
operator|||
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
operator|)
argument_list|,
operator|(
literal|"sched_add: bad thread state"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_INMEM
argument_list|,
operator|(
literal|"sched_add: thread swapped out"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<
name|tdq
operator|->
name|tdq_lowpri
condition|)
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|tdq_runq_add
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|tdq_load_add
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Select the target thread queue and add a thread to it.  Request  * preemption or IPI a remote processor if required.  */
end_comment

begin_function
name|void
name|sched_add
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|int
name|cpu
decl_stmt|;
endif|#
directive|endif
name|KTR_STATE2
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|,
literal|"runq add"
argument_list|,
literal|"prio:%d"
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|)
expr_stmt|;
name|KTR_POINT1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|curthread
argument_list|)
argument_list|,
literal|"wokeup"
argument_list|,
name|KTR_ATTR_LINKED
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|)
expr_stmt|;
name|SDT_PROBE4
argument_list|(
name|sched
argument_list|, , ,
name|enqueue
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
argument_list|,
name|NULL
argument_list|,
name|flags
operator|&
name|SRQ_PREEMPTED
argument_list|)
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Recalculate the priority before we select the target cpu or 	 * run-queue. 	 */
if|if
condition|(
name|PRI_BASE
argument_list|(
name|td
operator|->
name|td_pri_class
argument_list|)
operator|==
name|PRI_TIMESHARE
condition|)
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * Pick the destination cpu and if it isn't ours transfer to the 	 * target cpu. 	 */
name|cpu
operator|=
name|sched_pickcpu
argument_list|(
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|sched_setcpu
argument_list|(
name|td
argument_list|,
name|cpu
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|tdq_add
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
block|{
name|tdq_notify
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|)
expr_stmt|;
return|return;
block|}
else|#
directive|else
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
comment|/* 	 * Now that the thread is moving to the run-queue, set the lock 	 * to the scheduler's lock. 	 */
name|thread_lock_set
argument_list|(
name|td
argument_list|,
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|tdq_add
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
operator|!
operator|(
name|flags
operator|&
name|SRQ_YIELDING
operator|)
condition|)
name|sched_setpreempt
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove a thread from a run-queue without running it.  This is used  * when we're stealing a thread from a remote queue.  Otherwise all threads  * exit by calling sched_exit_thread() and sched_throw() themselves.  */
end_comment

begin_function
name|void
name|sched_rem
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|KTR_STATE1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"thread"
argument_list|,
name|sched_tdname
argument_list|(
name|td
argument_list|)
argument_list|,
literal|"runq rem"
argument_list|,
literal|"prio:%d"
argument_list|,
name|td
operator|->
name|td_priority
argument_list|)
expr_stmt|;
name|SDT_PROBE3
argument_list|(
name|sched
argument_list|, , ,
name|dequeue
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|td
operator|->
name|td_sched
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
argument_list|,
operator|(
literal|"sched_rem: thread not on run queue"
operator|)
argument_list|)
expr_stmt|;
name|tdq_runq_rem
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|TD_SET_CAN_RUN
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|==
name|tdq
operator|->
name|tdq_lowpri
condition|)
name|tdq_setlowpri
argument_list|(
name|tdq
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Fetch cpu utilization information.  Updates on demand.  */
end_comment

begin_function
name|fixpt_t
name|sched_pctcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|fixpt_t
name|pctcpu
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|pctcpu
operator|=
literal|0
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|ts
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|sched_pctcpu_update
argument_list|(
name|ts
argument_list|,
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_ticks
condition|)
block|{
name|int
name|rtick
decl_stmt|;
comment|/* How many rtick per second ? */
name|rtick
operator|=
name|min
argument_list|(
name|SCHED_TICK_HZ
argument_list|(
name|ts
argument_list|)
operator|/
name|SCHED_TICK_SECS
argument_list|,
name|hz
argument_list|)
expr_stmt|;
name|pctcpu
operator|=
operator|(
name|FSCALE
operator|*
operator|(
operator|(
name|FSCALE
operator|*
name|rtick
operator|)
operator|/
name|hz
operator|)
operator|)
operator|>>
name|FSHIFT
expr_stmt|;
block|}
return|return
operator|(
name|pctcpu
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Enforce affinity settings for a thread.  Called after adjustments to  * cpumask.  */
end_comment

begin_function
name|void
name|sched_affinity
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|)
condition|)
return|return;
if|if
condition|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|sched_rem
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_add
argument_list|(
name|td
argument_list|,
name|SRQ_BORING
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|!
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
condition|)
return|return;
comment|/* 	 * Force a switch before returning to userspace.  If the 	 * target thread is not running locally send an ipi to force 	 * the issue. 	 */
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|curthread
condition|)
name|ipi_cpu
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|,
name|IPI_PREEMPT
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  * Bind a thread to a target cpu.  */
end_comment

begin_function
name|void
name|sched_bind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
operator||
name|MA_NOTRECURSED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|==
name|curthread
argument_list|,
operator|(
literal|"sched_bind: can only bind curthread"
operator|)
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_BOUND
condition|)
name|sched_unbind
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
argument_list|,
operator|(
literal|"%p must be migratable"
operator|,
name|td
operator|)
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_BOUND
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
operator|==
name|cpu
condition|)
return|return;
name|ts
operator|->
name|ts_cpu
operator|=
name|cpu
expr_stmt|;
comment|/* When we return from mi_switch we'll be on the correct cpu. */
name|mi_switch
argument_list|(
name|SW_VOL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Release a bound thread.  */
end_comment

begin_function
name|void
name|sched_unbind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|==
name|curthread
argument_list|,
operator|(
literal|"sched_unbind: can only bind curthread"
operator|)
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
operator|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_BOUND
operator|)
operator|==
literal|0
condition|)
return|return;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_BOUND
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|int
name|sched_is_bound
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
name|td
operator|->
name|td_sched
operator|->
name|ts_flags
operator|&
name|TSF_BOUND
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Basic yield call.  */
end_comment

begin_function
name|void
name|sched_relinquish
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_VOL
operator||
name|SWT_RELINQUISH
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return the total system load.  */
end_comment

begin_function
name|int
name|sched_load
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|int
name|total
decl_stmt|;
name|int
name|i
decl_stmt|;
name|total
operator|=
literal|0
expr_stmt|;
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
name|total
operator|+=
name|TDQ_CPU
argument_list|(
name|i
argument_list|)
operator|->
name|tdq_sysload
expr_stmt|;
return|return
operator|(
name|total
operator|)
return|;
else|#
directive|else
return|return
operator|(
name|TDQ_SELF
argument_list|()
operator|->
name|tdq_sysload
operator|)
return|;
endif|#
directive|endif
block|}
end_function

begin_function
name|int
name|sched_sizeof_proc
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|proc
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_sizeof_thread
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|thread
argument_list|)
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|td_sched
argument_list|)
operator|)
return|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_define
define|#
directive|define
name|TDQ_IDLESPIN
parameter_list|(
name|tdq
parameter_list|)
define|\
value|((tdq)->tdq_cg != NULL&& ((tdq)->tdq_cg->cg_flags& CG_FLAG_THREAD) == 0)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|TDQ_IDLESPIN
parameter_list|(
name|tdq
parameter_list|)
value|1
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * The actual idle process.  */
end_comment

begin_function
name|void
name|sched_idletd
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|oldswitchcnt
decl_stmt|,
name|switchcnt
decl_stmt|;
name|int
name|i
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|Giant
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
name|td
operator|=
name|curthread
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|THREAD_NO_SLEEPING
argument_list|()
expr_stmt|;
name|oldswitchcnt
operator|=
operator|-
literal|1
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
if|if
condition|(
name|tdq
operator|->
name|tdq_load
condition|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_VOL
operator||
name|SWT_IDLE
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
name|switchcnt
operator|=
name|tdq
operator|->
name|tdq_switchcnt
operator|+
name|tdq
operator|->
name|tdq_oldswitchcnt
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|switchcnt
operator|!=
name|oldswitchcnt
condition|)
block|{
name|oldswitchcnt
operator|=
name|switchcnt
expr_stmt|;
if|if
condition|(
name|tdq_idled
argument_list|(
name|tdq
argument_list|)
operator|==
literal|0
condition|)
continue|continue;
block|}
name|switchcnt
operator|=
name|tdq
operator|->
name|tdq_switchcnt
operator|+
name|tdq
operator|->
name|tdq_oldswitchcnt
expr_stmt|;
else|#
directive|else
name|oldswitchcnt
operator|=
name|switchcnt
expr_stmt|;
endif|#
directive|endif
comment|/* 		 * If we're switching very frequently, spin while checking 		 * for load rather than entering a low power state that  		 * may require an IPI.  However, don't do any busy 		 * loops while on SMT machines as this simply steals 		 * cycles from cores doing useful work. 		 */
if|if
condition|(
name|TDQ_IDLESPIN
argument_list|(
name|tdq
argument_list|)
operator|&&
name|switchcnt
operator|>
name|sched_idlespinthresh
condition|)
block|{
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|sched_idlespins
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|tdq
operator|->
name|tdq_load
condition|)
break|break;
name|cpu_spinwait
argument_list|()
expr_stmt|;
block|}
block|}
comment|/* If there was context switch during spin, restart it. */
name|switchcnt
operator|=
name|tdq
operator|->
name|tdq_switchcnt
operator|+
name|tdq
operator|->
name|tdq_oldswitchcnt
expr_stmt|;
if|if
condition|(
name|tdq
operator|->
name|tdq_load
operator|!=
literal|0
operator|||
name|switchcnt
operator|!=
name|oldswitchcnt
condition|)
continue|continue;
comment|/* Run main MD idle handler. */
name|tdq
operator|->
name|tdq_cpu_idle
operator|=
literal|1
expr_stmt|;
comment|/* 		 * Make sure that tdq_cpu_idle update is globally visible 		 * before cpu_idle() read tdq_load.  The order is important 		 * to avoid race with tdq_notify. 		 */
name|mb
argument_list|()
expr_stmt|;
name|cpu_idle
argument_list|(
name|switchcnt
operator|*
literal|4
operator|>
name|sched_idlespinthresh
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_cpu_idle
operator|=
literal|0
expr_stmt|;
comment|/* 		 * Account thread-less hardware interrupts and 		 * other wakeup reasons equal to context switches. 		 */
name|switchcnt
operator|=
name|tdq
operator|->
name|tdq_switchcnt
operator|+
name|tdq
operator|->
name|tdq_oldswitchcnt
expr_stmt|;
if|if
condition|(
name|switchcnt
operator|!=
name|oldswitchcnt
condition|)
continue|continue;
name|tdq
operator|->
name|tdq_switchcnt
operator|++
expr_stmt|;
name|oldswitchcnt
operator|++
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * A CPU is entering for the first time or a thread is exiting.  */
end_comment

begin_function
name|void
name|sched_throw
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|newtd
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
if|if
condition|(
name|td
operator|==
name|NULL
condition|)
block|{
comment|/* Correct spinlock nesting and acquire the correct lock. */
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|spinlock_exit
argument_list|()
expr_stmt|;
name|PCPU_SET
argument_list|(
name|switchtime
argument_list|,
name|cpu_ticks
argument_list|()
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|switchticks
argument_list|,
name|ticks
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|lock_profile_release_lock
argument_list|(
operator|&
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
operator|->
name|lock_object
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|curthread
operator|->
name|td_md
operator|.
name|md_spinlock_count
operator|==
literal|1
argument_list|,
operator|(
literal|"invalid count"
operator|)
argument_list|)
expr_stmt|;
name|newtd
operator|=
name|choosethread
argument_list|()
expr_stmt|;
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
operator|->
name|mtx_lock
operator|=
operator|(
name|uintptr_t
operator|)
name|newtd
expr_stmt|;
name|cpu_throw
argument_list|(
name|td
argument_list|,
name|newtd
argument_list|)
expr_stmt|;
comment|/* doesn't return */
block|}
end_function

begin_comment
comment|/*  * This is called from fork_exit().  Just acquire the correct locks and  * let fork do the rest of the work.  */
end_comment

begin_function
name|void
name|sched_fork_exit
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|cpuid
decl_stmt|;
comment|/* 	 * Finish setting up thread glue so that it begins execution in a 	 * non-nested critical section with the scheduler lock held. 	 */
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
if|if
condition|(
name|TD_IS_IDLETHREAD
argument_list|(
name|td
argument_list|)
condition|)
name|td
operator|->
name|td_lock
operator|=
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|cpuid
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
operator||
name|MA_NOTRECURSED
argument_list|)
expr_stmt|;
name|lock_profile_obtain_lock_success
argument_list|(
operator|&
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
operator|->
name|lock_object
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|__FILE__
argument_list|,
name|__LINE__
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Create on first use to catch odd startup conditons.  */
end_comment

begin_function
name|char
modifier|*
name|sched_tdname
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|KTR
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_name
index|[
literal|0
index|]
operator|==
literal|'\0'
condition|)
name|snprintf
argument_list|(
name|ts
operator|->
name|ts_name
argument_list|,
sizeof|sizeof
argument_list|(
name|ts
operator|->
name|ts_name
argument_list|)
argument_list|,
literal|"%s tid %d"
argument_list|,
name|td
operator|->
name|td_name
argument_list|,
name|td
operator|->
name|td_tid
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|->
name|ts_name
operator|)
return|;
else|#
directive|else
return|return
operator|(
name|td
operator|->
name|td_name
operator|)
return|;
endif|#
directive|endif
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|KTR
end_ifdef

begin_function
name|void
name|sched_clear_tdname
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|ts
operator|->
name|ts_name
index|[
literal|0
index|]
operator|=
literal|'\0'
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * Build the CPU topology dump string. Is recursively called to collect  * the topology tree.  */
end_comment

begin_function
specifier|static
name|int
name|sysctl_kern_sched_topology_spec_internal
parameter_list|(
name|struct
name|sbuf
modifier|*
name|sb
parameter_list|,
name|struct
name|cpu_group
modifier|*
name|cg
parameter_list|,
name|int
name|indent
parameter_list|)
block|{
name|char
name|cpusetbuf
index|[
name|CPUSETBUFSIZ
index|]
decl_stmt|;
name|int
name|i
decl_stmt|,
name|first
decl_stmt|;
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"%*s<group level=\"%d\" cache-level=\"%d\">\n"
argument_list|,
name|indent
argument_list|,
literal|""
argument_list|,
literal|1
operator|+
name|indent
operator|/
literal|2
argument_list|,
name|cg
operator|->
name|cg_level
argument_list|)
expr_stmt|;
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"%*s<cpu count=\"%d\" mask=\"%s\">"
argument_list|,
name|indent
argument_list|,
literal|""
argument_list|,
name|cg
operator|->
name|cg_count
argument_list|,
name|cpusetobj_strprint
argument_list|(
name|cpusetbuf
argument_list|,
operator|&
name|cg
operator|->
name|cg_mask
argument_list|)
argument_list|)
expr_stmt|;
name|first
operator|=
name|TRUE
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|CPU_ISSET
argument_list|(
name|i
argument_list|,
operator|&
name|cg
operator|->
name|cg_mask
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|first
condition|)
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|", "
argument_list|)
expr_stmt|;
else|else
name|first
operator|=
name|FALSE
expr_stmt|;
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"%d"
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
block|}
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"</cpu>\n"
argument_list|)
expr_stmt|;
if|if
condition|(
name|cg
operator|->
name|cg_flags
operator|!=
literal|0
condition|)
block|{
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"%*s<flags>"
argument_list|,
name|indent
argument_list|,
literal|""
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|cg
operator|->
name|cg_flags
operator|&
name|CG_FLAG_HTT
operator|)
operator|!=
literal|0
condition|)
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"<flag name=\"HTT\">HTT group</flag>"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|cg
operator|->
name|cg_flags
operator|&
name|CG_FLAG_THREAD
operator|)
operator|!=
literal|0
condition|)
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"<flag name=\"THREAD\">THREAD group</flag>"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|cg
operator|->
name|cg_flags
operator|&
name|CG_FLAG_SMT
operator|)
operator|!=
literal|0
condition|)
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"<flag name=\"SMT\">SMT group</flag>"
argument_list|)
expr_stmt|;
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"</flags>\n"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cg
operator|->
name|cg_children
operator|>
literal|0
condition|)
block|{
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"%*s<children>\n"
argument_list|,
name|indent
argument_list|,
literal|""
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|cg
operator|->
name|cg_children
condition|;
name|i
operator|++
control|)
name|sysctl_kern_sched_topology_spec_internal
argument_list|(
name|sb
argument_list|,
operator|&
name|cg
operator|->
name|cg_child
index|[
name|i
index|]
argument_list|,
name|indent
operator|+
literal|2
argument_list|)
expr_stmt|;
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"%*s</children>\n"
argument_list|,
name|indent
argument_list|,
literal|""
argument_list|)
expr_stmt|;
block|}
name|sbuf_printf
argument_list|(
name|sb
argument_list|,
literal|"%*s</group>\n"
argument_list|,
name|indent
argument_list|,
literal|""
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Sysctl handler for retrieving topology dump. It's a wrapper for  * the recursive sysctl_kern_smp_topology_spec_internal().  */
end_comment

begin_function
specifier|static
name|int
name|sysctl_kern_sched_topology_spec
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|struct
name|sbuf
modifier|*
name|topo
decl_stmt|;
name|int
name|err
decl_stmt|;
name|KASSERT
argument_list|(
name|cpu_top
operator|!=
name|NULL
argument_list|,
operator|(
literal|"cpu_top isn't initialized"
operator|)
argument_list|)
expr_stmt|;
name|topo
operator|=
name|sbuf_new
argument_list|(
name|NULL
argument_list|,
name|NULL
argument_list|,
literal|500
argument_list|,
name|SBUF_AUTOEXTEND
argument_list|)
expr_stmt|;
if|if
condition|(
name|topo
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
name|sbuf_printf
argument_list|(
name|topo
argument_list|,
literal|"<groups>\n"
argument_list|)
expr_stmt|;
name|err
operator|=
name|sysctl_kern_sched_topology_spec_internal
argument_list|(
name|topo
argument_list|,
name|cpu_top
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|sbuf_printf
argument_list|(
name|topo
argument_list|,
literal|"</groups>\n"
argument_list|)
expr_stmt|;
if|if
condition|(
name|err
operator|==
literal|0
condition|)
block|{
name|sbuf_finish
argument_list|(
name|topo
argument_list|)
expr_stmt|;
name|err
operator|=
name|SYSCTL_OUT
argument_list|(
name|req
argument_list|,
name|sbuf_data
argument_list|(
name|topo
argument_list|)
argument_list|,
name|sbuf_len
argument_list|(
name|topo
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|sbuf_delete
argument_list|(
name|topo
argument_list|)
expr_stmt|;
return|return
operator|(
name|err
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|int
name|sysctl_kern_quantum
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|int
name|error
decl_stmt|,
name|new_val
decl_stmt|,
name|period
decl_stmt|;
name|period
operator|=
literal|1000000
operator|/
name|realstathz
expr_stmt|;
name|new_val
operator|=
name|period
operator|*
name|sched_slice
expr_stmt|;
name|error
operator|=
name|sysctl_handle_int
argument_list|(
name|oidp
argument_list|,
operator|&
name|new_val
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
operator|||
name|req
operator|->
name|newptr
operator|==
name|NULL
condition|)
return|return
operator|(
name|error
operator|)
return|;
if|if
condition|(
name|new_val
operator|<=
literal|0
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|sched_slice
operator|=
name|imax
argument_list|(
literal|1
argument_list|,
operator|(
name|new_val
operator|+
name|period
operator|/
literal|2
operator|)
operator|/
name|period
argument_list|)
expr_stmt|;
name|sched_slice_min
operator|=
name|sched_slice
operator|/
name|SCHED_SLICE_MIN_DIVISOR
expr_stmt|;
name|hogticks
operator|=
name|imax
argument_list|(
literal|1
argument_list|,
operator|(
literal|2
operator|*
name|hz
operator|*
name|sched_slice
operator|+
name|realstathz
operator|/
literal|2
operator|)
operator|/
name|realstathz
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_expr_stmt
name|SYSCTL_NODE
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|sched
argument_list|,
name|CTLFLAG_RW
argument_list|,
literal|0
argument_list|,
literal|"Scheduler"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_STRING
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|name
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|"ULE"
argument_list|,
literal|0
argument_list|,
literal|"Scheduler name"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|quantum
argument_list|,
name|CTLTYPE_INT
operator||
name|CTLFLAG_RW
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
name|sysctl_kern_quantum
argument_list|,
literal|"I"
argument_list|,
literal|"Quantum for timeshare threads in microseconds"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|slice
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|sched_slice
argument_list|,
literal|0
argument_list|,
literal|"Quantum for timeshare threads in stathz ticks"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|interact
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|sched_interact
argument_list|,
literal|0
argument_list|,
literal|"Interactivity score threshold"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|preempt_thresh
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|preempt_thresh
argument_list|,
literal|0
argument_list|,
literal|"Maximal (lowest) priority for preemption"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|static_boost
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|static_boost
argument_list|,
literal|0
argument_list|,
literal|"Assign static kernel priorities to sleeping threads"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|idlespins
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|sched_idlespins
argument_list|,
literal|0
argument_list|,
literal|"Number of times idle thread will spin waiting for new work"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|idlespinthresh
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|sched_idlespinthresh
argument_list|,
literal|0
argument_list|,
literal|"Threshold before we will permit idle thread spinning"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|affinity
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|affinity
argument_list|,
literal|0
argument_list|,
literal|"Number of hz ticks to keep thread affinity for"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|balance
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|rebalance
argument_list|,
literal|0
argument_list|,
literal|"Enables the long-term load balancer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|balance_interval
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|balance_interval
argument_list|,
literal|0
argument_list|,
literal|"Average period in stathz ticks to run the long-term balancer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|steal_idle
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|steal_idle
argument_list|,
literal|0
argument_list|,
literal|"Attempts to steal work from other cores before idling"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|steal_thresh
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|steal_thresh
argument_list|,
literal|0
argument_list|,
literal|"Minimum load on remote CPU before we'll steal"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|topology_spec
argument_list|,
name|CTLTYPE_STRING
operator||
name|CTLFLAG_RD
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
name|sysctl_kern_sched_topology_spec
argument_list|,
literal|"A"
argument_list|,
literal|"XML dump of detected CPU topology"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* ps compat.  All cpu percentages from ULE are weighted. */
end_comment

begin_decl_stmt
specifier|static
name|int
name|ccpu
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|ccpu
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ccpu
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

end_unit

