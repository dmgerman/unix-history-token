begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2002-2006, Jeffrey Roberson<jeff@freebsd.org>  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice unmodified, this list of conditions, and the following  *    disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,  * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT  * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,  * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY  * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF  * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_hwpmc_hooks.h"
end_include

begin_include
include|#
directive|include
file|"opt_sched.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kdb.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/resource.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysproto.h>
end_include

begin_include
include|#
directive|include
file|<sys/turnstile.h>
end_include

begin_include
include|#
directive|include
file|<sys/umtx.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|KTRACE
end_ifdef

begin_include
include|#
directive|include
file|<sys/uio.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktrace.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
end_ifdef

begin_include
include|#
directive|include
file|<sys/pmckern.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_comment
comment|/* decay 95% of `p_pctcpu' in 60 seconds; see CCPU_SHIFT before changing */
end_comment

begin_comment
comment|/* XXX This is bogus compatability crap for ps */
end_comment

begin_decl_stmt
specifier|static
name|fixpt_t
name|ccpu
init|=
literal|0.95122942450071400909
operator|*
name|FSCALE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* exp(-1/20) */
end_comment

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|ccpu
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ccpu
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function_decl
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_macro
name|SYSINIT
argument_list|(
argument|sched_setup
argument_list|,
argument|SI_SUB_RUN_QUEUE
argument_list|,
argument|SI_ORDER_FIRST
argument_list|,
argument|sched_setup
argument_list|,
argument|NULL
argument_list|)
end_macro

begin_function_decl
specifier|static
name|void
name|sched_initticks
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_macro
name|SYSINIT
argument_list|(
argument|sched_initticks
argument_list|,
argument|SI_SUB_CLOCKS
argument_list|,
argument|SI_ORDER_THIRD
argument_list|,
argument|sched_initticks
argument_list|,
argument|NULL
argument_list|)
end_macro

begin_expr_stmt
specifier|static
name|SYSCTL_NODE
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|sched
argument_list|,
name|CTLFLAG_RW
argument_list|,
literal|0
argument_list|,
literal|"Scheduler"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_STRING
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|name
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|"ule"
argument_list|,
literal|0
argument_list|,
literal|"Scheduler name"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|slice_min
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|slice_min
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|slice_min
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|slice_max
init|=
literal|10
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|slice_max
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|slice_max
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|realstathz
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|tickincr
init|=
literal|1
operator|<<
literal|10
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Thread scheduler specific section.  */
end_comment

begin_struct
struct|struct
name|td_sched
block|{
name|TAILQ_ENTRY
argument_list|(
argument|td_sched
argument_list|)
name|ts_procq
expr_stmt|;
comment|/* (j/z) Run queue. */
name|int
name|ts_flags
decl_stmt|;
comment|/* (j) TSF_* flags. */
name|struct
name|thread
modifier|*
name|ts_thread
decl_stmt|;
comment|/* (*) Active associated thread. */
name|fixpt_t
name|ts_pctcpu
decl_stmt|;
comment|/* (j) %cpu during p_swtime. */
name|u_char
name|ts_rqindex
decl_stmt|;
comment|/* (j) Run queue index. */
enum|enum
block|{
name|TSS_THREAD
init|=
literal|0x0
block|,
comment|/* slaved to thread state */
name|TSS_ONRUNQ
block|}
name|ts_state
enum|;
comment|/* (j) thread sched specific status. */
name|int
name|ts_slptime
decl_stmt|;
name|int
name|ts_slice
decl_stmt|;
name|struct
name|runq
modifier|*
name|ts_runq
decl_stmt|;
name|u_char
name|ts_cpu
decl_stmt|;
comment|/* CPU that we have affinity for. */
comment|/* The following variables are only used for pctcpu calculation */
name|int
name|ts_ltick
decl_stmt|;
comment|/* Last tick that we were running on */
name|int
name|ts_ftick
decl_stmt|;
comment|/* First tick that we were running on */
name|int
name|ts_ticks
decl_stmt|;
comment|/* Tick count */
comment|/* originally from kg_sched */
name|int
name|skg_slptime
decl_stmt|;
comment|/* Number of ticks we vol. slept */
name|int
name|skg_runtime
decl_stmt|;
comment|/* Number of ticks we were running */
block|}
struct|;
end_struct

begin_define
define|#
directive|define
name|ts_assign
value|ts_procq.tqe_next
end_define

begin_comment
comment|/* flags kept in ts_flags */
end_comment

begin_define
define|#
directive|define
name|TSF_ASSIGNED
value|0x0001
end_define

begin_comment
comment|/* Thread is being migrated. */
end_comment

begin_define
define|#
directive|define
name|TSF_BOUND
value|0x0002
end_define

begin_comment
comment|/* Thread can not migrate. */
end_comment

begin_define
define|#
directive|define
name|TSF_XFERABLE
value|0x0004
end_define

begin_comment
comment|/* Thread was added as transferable. */
end_comment

begin_define
define|#
directive|define
name|TSF_HOLD
value|0x0008
end_define

begin_comment
comment|/* Thread is temporarily bound. */
end_comment

begin_define
define|#
directive|define
name|TSF_REMOVED
value|0x0010
end_define

begin_comment
comment|/* Thread was removed while ASSIGNED */
end_comment

begin_define
define|#
directive|define
name|TSF_INTERNAL
value|0x0020
end_define

begin_comment
comment|/* Thread added due to migration. */
end_comment

begin_define
define|#
directive|define
name|TSF_PREEMPTED
value|0x0040
end_define

begin_comment
comment|/* Thread was preempted */
end_comment

begin_define
define|#
directive|define
name|TSF_DIDRUN
value|0x2000
end_define

begin_comment
comment|/* Thread actually ran. */
end_comment

begin_define
define|#
directive|define
name|TSF_EXIT
value|0x4000
end_define

begin_comment
comment|/* Thread is being killed. */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|td_sched
name|td_sched0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * The priority is primarily determined by the interactivity score.  Thus, we  * give lower(better) priorities to threads that use less CPU.  The nice  * value is then directly added to this to allow nice to have some effect  * on latency.  *  * PRI_RANGE:	Total priority range for timeshare threads.  * PRI_NRESV:	Number of nice values.  * PRI_BASE:	The start of the dynamic range.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_PRI_RANGE
value|(PRI_MAX_TIMESHARE - PRI_MIN_TIMESHARE + 1)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_NRESV
value|((PRIO_MAX - PRIO_MIN) + 1)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_NHALF
value|(SCHED_PRI_NRESV / 2)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_BASE
value|(PRI_MIN_TIMESHARE)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_INTERACT
parameter_list|(
name|score
parameter_list|)
define|\
value|((score) * SCHED_PRI_RANGE / SCHED_INTERACT_MAX)
end_define

begin_comment
comment|/*  * These determine the interactivity of a process.  *  * SLP_RUN_MAX:	Maximum amount of sleep time + run time we'll accumulate  *		before throttling back.  * SLP_RUN_FORK:	Maximum slp+run time to inherit at fork time.  * INTERACT_MAX:	Maximum interactivity value.  Smaller is better.  * INTERACT_THRESH:	Threshhold for placement on the current runq.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_SLP_RUN_MAX
value|((hz * 5)<< 10)
end_define

begin_define
define|#
directive|define
name|SCHED_SLP_RUN_FORK
value|((hz / 2)<< 10)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_MAX
value|(100)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_HALF
value|(SCHED_INTERACT_MAX / 2)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_THRESH
value|(30)
end_define

begin_comment
comment|/*  * These parameters and macros determine the size of the time slice that is  * granted to each thread.  *  * SLICE_MIN:	Minimum time slice granted, in units of ticks.  * SLICE_MAX:	Maximum time slice granted.  * SLICE_RANGE:	Range of available time slices scaled by hz.  * SLICE_SCALE:	The number slices granted per val in the range of [0, max].  * SLICE_NICE:  Determine the amount of slice granted to a scaled nice.  * SLICE_NTHRESH:	The nice cutoff point for slice assignment.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_SLICE_MIN
value|(slice_min)
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_MAX
value|(slice_max)
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_INTERACTIVE
value|(slice_max)
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_NTHRESH
value|(SCHED_PRI_NHALF - 1)
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_RANGE
value|(SCHED_SLICE_MAX - SCHED_SLICE_MIN + 1)
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_SCALE
parameter_list|(
name|val
parameter_list|,
name|max
parameter_list|)
value|(((val) * SCHED_SLICE_RANGE) / (max))
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_NICE
parameter_list|(
name|nice
parameter_list|)
define|\
value|(SCHED_SLICE_MAX - SCHED_SLICE_SCALE((nice), SCHED_SLICE_NTHRESH))
end_define

begin_comment
comment|/*  * This macro determines whether or not the thread belongs on the current or  * next run queue.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_INTERACTIVE
parameter_list|(
name|td
parameter_list|)
define|\
value|(sched_interact_score(td)< SCHED_INTERACT_THRESH)
end_define

begin_define
define|#
directive|define
name|SCHED_CURR
parameter_list|(
name|td
parameter_list|,
name|ts
parameter_list|)
define|\
value|((ts->ts_thread->td_flags& TDF_BORROWING) ||			\      (ts->ts_flags& TSF_PREEMPTED) || SCHED_INTERACTIVE(td))
end_define

begin_comment
comment|/*  * Cpu percentage computation macros and defines.  *  * SCHED_CPU_TIME:	Number of seconds to average the cpu usage across.  * SCHED_CPU_TICKS:	Number of hz ticks to average the cpu usage across.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_CPU_TIME
value|10
end_define

begin_define
define|#
directive|define
name|SCHED_CPU_TICKS
value|(hz * SCHED_CPU_TIME)
end_define

begin_comment
comment|/*  * tdq - per processor runqs and statistics.  */
end_comment

begin_struct
struct|struct
name|tdq
block|{
name|struct
name|runq
name|tdq_idle
decl_stmt|;
comment|/* Queue of IDLE threads. */
name|struct
name|runq
name|tdq_timeshare
index|[
literal|2
index|]
decl_stmt|;
comment|/* Run queues for !IDLE. */
name|struct
name|runq
modifier|*
name|tdq_next
decl_stmt|;
comment|/* Next timeshare queue. */
name|struct
name|runq
modifier|*
name|tdq_curr
decl_stmt|;
comment|/* Current queue. */
name|int
name|tdq_load_timeshare
decl_stmt|;
comment|/* Load for timeshare. */
name|int
name|tdq_load
decl_stmt|;
comment|/* Aggregate load. */
name|short
name|tdq_nice
index|[
name|SCHED_PRI_NRESV
index|]
decl_stmt|;
comment|/* threadss in each nice bin. */
name|short
name|tdq_nicemin
decl_stmt|;
comment|/* Least nice. */
ifdef|#
directive|ifdef
name|SMP
name|int
name|tdq_transferable
decl_stmt|;
name|LIST_ENTRY
argument_list|(
argument|tdq
argument_list|)
name|tdq_siblings
expr_stmt|;
comment|/* Next in tdq group. */
name|struct
name|tdq_group
modifier|*
name|tdq_group
decl_stmt|;
comment|/* Our processor group. */
specifier|volatile
name|struct
name|td_sched
modifier|*
name|tdq_assigned
decl_stmt|;
comment|/* assigned by another CPU. */
else|#
directive|else
name|int
name|tdq_sysload
decl_stmt|;
comment|/* For loadavg, !ITHD load. */
endif|#
directive|endif
block|}
struct|;
end_struct

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * tdq groups are groups of processors which can cheaply share threads.  When  * one processor in the group goes idle it will check the runqs of the other  * processors in its group prior to halting and waiting for an interrupt.  * These groups are suitable for SMT (Symetric Multi-Threading) and not NUMA.  * In a numa environment we'd want an idle bitmap per group and a two tiered  * load balancer.  */
end_comment

begin_struct
struct|struct
name|tdq_group
block|{
name|int
name|tdg_cpus
decl_stmt|;
comment|/* Count of CPUs in this tdq group. */
name|cpumask_t
name|tdg_cpumask
decl_stmt|;
comment|/* Mask of cpus in this group. */
name|cpumask_t
name|tdg_idlemask
decl_stmt|;
comment|/* Idle cpus in this group. */
name|cpumask_t
name|tdg_mask
decl_stmt|;
comment|/* Bit mask for first cpu. */
name|int
name|tdg_load
decl_stmt|;
comment|/* Total load of this group. */
name|int
name|tdg_transferable
decl_stmt|;
comment|/* Transferable load of this group. */
name|LIST_HEAD
argument_list|(
argument_list|,
argument|tdq
argument_list|)
name|tdg_members
expr_stmt|;
comment|/* Linked list of all members. */
block|}
struct|;
end_struct

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * One thread queue per processor.  */
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_decl_stmt
specifier|static
name|cpumask_t
name|tdq_idle
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|tdg_maxid
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|tdq
name|tdq_cpu
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|tdq_group
name|tdq_groups
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|bal_tick
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|gbal_tick
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|balance_groups
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|TDQ_SELF
parameter_list|()
value|(&tdq_cpu[PCPU_GET(cpuid)])
end_define

begin_define
define|#
directive|define
name|TDQ_CPU
parameter_list|(
name|x
parameter_list|)
value|(&tdq_cpu[(x)])
end_define

begin_define
define|#
directive|define
name|TDQ_ID
parameter_list|(
name|x
parameter_list|)
value|((x) - tdq_cpu)
end_define

begin_define
define|#
directive|define
name|TDQ_GROUP
parameter_list|(
name|x
parameter_list|)
value|(&tdq_groups[(x)])
end_define

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* !SMP */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|tdq
name|tdq_cpu
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|TDQ_SELF
parameter_list|()
value|(&tdq_cpu)
end_define

begin_define
define|#
directive|define
name|TDQ_CPU
parameter_list|(
name|x
parameter_list|)
value|(&tdq_cpu)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_function_decl
specifier|static
name|struct
name|td_sched
modifier|*
name|sched_choose
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/* XXX Should be thread * */
end_comment

begin_function_decl
specifier|static
name|void
name|sched_slice
parameter_list|(
name|struct
name|td_sched
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_thread_priority
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|,
name|u_char
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sched_interact_score
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_interact_update
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_interact_fork
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_pctcpu_update
parameter_list|(
name|struct
name|td_sched
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/* Operations on per processor queues */
end_comment

begin_function_decl
specifier|static
name|struct
name|td_sched
modifier|*
name|tdq_choose
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_setup
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_load_add
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|td_sched
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_load_rem
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|td_sched
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|tdq_runq_add
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|td_sched
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|tdq_runq_rem
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|td_sched
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_nice_add
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_nice_rem
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|tdq_print
parameter_list|(
name|int
name|cpu
parameter_list|)
function_decl|;
end_function_decl

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function_decl
specifier|static
name|int
name|tdq_transfer
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|td_sched
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|td_sched
modifier|*
name|runq_steal
parameter_list|(
name|struct
name|runq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance_groups
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance_group
parameter_list|(
name|struct
name|tdq_group
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance_pair
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_move
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|tdq_idled
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_notify
parameter_list|(
name|struct
name|td_sched
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_assign
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|td_sched
modifier|*
name|tdq_steal
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_define
define|#
directive|define
name|THREAD_CAN_MIGRATE
parameter_list|(
name|ts
parameter_list|)
define|\
value|((ts)->ts_thread->td_pinned == 0&& ((ts)->ts_flags& TSF_BOUND) == 0)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_function
name|void
name|tdq_print
parameter_list|(
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|i
decl_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"tdq:\n"
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tload:           %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tload TIMESHARE: %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_load_timeshare
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|printf
argument_list|(
literal|"\tload transferable: %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_transferable
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|printf
argument_list|(
literal|"\tnicemin:\t%d\n"
argument_list|,
name|tdq
operator|->
name|tdq_nicemin
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tnice counts:\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|SCHED_PRI_NRESV
condition|;
name|i
operator|++
control|)
if|if
condition|(
name|tdq
operator|->
name|tdq_nice
index|[
name|i
index|]
condition|)
name|printf
argument_list|(
literal|"\t\t%d = %d\n"
argument_list|,
name|i
operator|-
name|SCHED_PRI_NHALF
argument_list|,
name|tdq
operator|->
name|tdq_nice
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|tdq_runq_add
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|ts
argument_list|)
condition|)
block|{
name|tdq
operator|->
name|tdq_transferable
operator|++
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_transferable
operator|++
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_XFERABLE
expr_stmt|;
block|}
endif|#
directive|endif
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_PREEMPTED
condition|)
name|flags
operator||=
name|SRQ_PREEMPTED
expr_stmt|;
name|runq_add
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|ts
argument_list|,
name|flags
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|tdq_runq_rem
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_XFERABLE
condition|)
block|{
name|tdq
operator|->
name|tdq_transferable
operator|--
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_transferable
operator|--
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_XFERABLE
expr_stmt|;
block|}
endif|#
directive|endif
name|runq_remove
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|tdq_load_add
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|)
block|{
name|int
name|class
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|class
operator|=
name|PRI_BASE
argument_list|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_pri_class
argument_list|)
expr_stmt|;
if|if
condition|(
name|class
operator|==
name|PRI_TIMESHARE
condition|)
name|tdq
operator|->
name|tdq_load_timeshare
operator|++
expr_stmt|;
name|tdq
operator|->
name|tdq_load
operator|++
expr_stmt|;
name|CTR1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"load: %d"
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
if|if
condition|(
name|class
operator|!=
name|PRI_ITHD
operator|&&
operator|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
ifdef|#
directive|ifdef
name|SMP
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_load
operator|++
expr_stmt|;
else|#
directive|else
name|tdq
operator|->
name|tdq_sysload
operator|++
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
name|tdq_nice_add
argument_list|(
name|tdq
argument_list|,
name|ts
operator|->
name|ts_thread
operator|->
name|td_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|tdq_load_rem
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|)
block|{
name|int
name|class
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|class
operator|=
name|PRI_BASE
argument_list|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_pri_class
argument_list|)
expr_stmt|;
if|if
condition|(
name|class
operator|==
name|PRI_TIMESHARE
condition|)
name|tdq
operator|->
name|tdq_load_timeshare
operator|--
expr_stmt|;
if|if
condition|(
name|class
operator|!=
name|PRI_ITHD
operator|&&
operator|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
ifdef|#
directive|ifdef
name|SMP
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_load
operator|--
expr_stmt|;
else|#
directive|else
name|tdq
operator|->
name|tdq_sysload
operator|--
expr_stmt|;
endif|#
directive|endif
name|tdq
operator|->
name|tdq_load
operator|--
expr_stmt|;
name|CTR1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"load: %d"
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_runq
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
name|tdq_nice_rem
argument_list|(
name|tdq
argument_list|,
name|ts
operator|->
name|ts_thread
operator|->
name|td_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|tdq_nice_add
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|int
name|nice
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* Normalize to zero. */
name|tdq
operator|->
name|tdq_nice
index|[
name|nice
operator|+
name|SCHED_PRI_NHALF
index|]
operator|++
expr_stmt|;
if|if
condition|(
name|nice
operator|<
name|tdq
operator|->
name|tdq_nicemin
operator|||
name|tdq
operator|->
name|tdq_load_timeshare
operator|==
literal|1
condition|)
name|tdq
operator|->
name|tdq_nicemin
operator|=
name|nice
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|tdq_nice_rem
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|int
name|nice
parameter_list|)
block|{
name|int
name|n
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* Normalize to zero. */
name|n
operator|=
name|nice
operator|+
name|SCHED_PRI_NHALF
expr_stmt|;
name|tdq
operator|->
name|tdq_nice
index|[
name|n
index|]
operator|--
expr_stmt|;
name|KASSERT
argument_list|(
name|tdq
operator|->
name|tdq_nice
index|[
name|n
index|]
operator|>=
literal|0
argument_list|,
operator|(
literal|"Negative nice count."
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If this wasn't the smallest nice value or there are more in 	 * this bucket we can just return.  Otherwise we have to recalculate 	 * the smallest nice. 	 */
if|if
condition|(
name|nice
operator|!=
name|tdq
operator|->
name|tdq_nicemin
operator|||
name|tdq
operator|->
name|tdq_nice
index|[
name|n
index|]
operator|!=
literal|0
operator|||
name|tdq
operator|->
name|tdq_load_timeshare
operator|==
literal|0
condition|)
return|return;
for|for
control|(
init|;
name|n
operator|<
name|SCHED_PRI_NRESV
condition|;
name|n
operator|++
control|)
if|if
condition|(
name|tdq
operator|->
name|tdq_nice
index|[
name|n
index|]
condition|)
block|{
name|tdq
operator|->
name|tdq_nicemin
operator|=
name|n
operator|-
name|SCHED_PRI_NHALF
expr_stmt|;
return|return;
block|}
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * sched_balance is a simple CPU load balancing algorithm.  It operates by  * finding the least loaded and most loaded cpu and equalizing their load  * by migrating some processes.  *  * Dealing only with two CPUs at a time has two advantages.  Firstly, most  * installations will only have 2 cpus.  Secondly, load balancing too much at  * once can have an unpleasant effect on the system.  The scheduler rarely has  * enough information to make perfect decisions.  So this algorithm chooses  * algorithm simplicity and more gradual effects on load in larger systems.  *  * It could be improved by considering the priorities and slices assigned to  * each task prior to balancing them.  There are many pathological cases with  * any approach and so the semi random algorithm below may work as well as any.  *  */
end_comment

begin_function
specifier|static
name|void
name|sched_balance
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|tdq_group
modifier|*
name|high
decl_stmt|;
name|struct
name|tdq_group
modifier|*
name|low
decl_stmt|;
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|int
name|cnt
decl_stmt|;
name|int
name|i
decl_stmt|;
name|bal_tick
operator|=
name|ticks
operator|+
operator|(
name|random
argument_list|()
operator|%
operator|(
name|hz
operator|*
literal|2
operator|)
operator|)
expr_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
condition|)
return|return;
name|low
operator|=
name|high
operator|=
name|NULL
expr_stmt|;
name|i
operator|=
name|random
argument_list|()
operator|%
operator|(
name|tdg_maxid
operator|+
literal|1
operator|)
expr_stmt|;
for|for
control|(
name|cnt
operator|=
literal|0
init|;
name|cnt
operator|<=
name|tdg_maxid
condition|;
name|cnt
operator|++
control|)
block|{
name|tdg
operator|=
name|TDQ_GROUP
argument_list|(
name|i
argument_list|)
expr_stmt|;
comment|/* 		 * Find the CPU with the highest load that has some 		 * threads to transfer. 		 */
if|if
condition|(
operator|(
name|high
operator|==
name|NULL
operator|||
name|tdg
operator|->
name|tdg_load
operator|>
name|high
operator|->
name|tdg_load
operator|)
operator|&&
name|tdg
operator|->
name|tdg_transferable
condition|)
name|high
operator|=
name|tdg
expr_stmt|;
if|if
condition|(
name|low
operator|==
name|NULL
operator|||
name|tdg
operator|->
name|tdg_load
operator|<
name|low
operator|->
name|tdg_load
condition|)
name|low
operator|=
name|tdg
expr_stmt|;
if|if
condition|(
operator|++
name|i
operator|>
name|tdg_maxid
condition|)
name|i
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|low
operator|!=
name|NULL
operator|&&
name|high
operator|!=
name|NULL
operator|&&
name|high
operator|!=
name|low
condition|)
name|sched_balance_pair
argument_list|(
name|LIST_FIRST
argument_list|(
operator|&
name|high
operator|->
name|tdg_members
argument_list|)
argument_list|,
name|LIST_FIRST
argument_list|(
operator|&
name|low
operator|->
name|tdg_members
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_balance_groups
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|gbal_tick
operator|=
name|ticks
operator|+
operator|(
name|random
argument_list|()
operator|%
operator|(
name|hz
operator|*
literal|2
operator|)
operator|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|smp_started
condition|)
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|tdg_maxid
condition|;
name|i
operator|++
control|)
name|sched_balance_group
argument_list|(
name|TDQ_GROUP
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_balance_group
parameter_list|(
name|struct
name|tdq_group
modifier|*
name|tdg
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|tdq
modifier|*
name|high
decl_stmt|;
name|struct
name|tdq
modifier|*
name|low
decl_stmt|;
name|int
name|load
decl_stmt|;
if|if
condition|(
name|tdg
operator|->
name|tdg_transferable
operator|==
literal|0
condition|)
return|return;
name|low
operator|=
name|NULL
expr_stmt|;
name|high
operator|=
name|NULL
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|tdq
argument_list|,
argument|&tdg->tdg_members
argument_list|,
argument|tdq_siblings
argument_list|)
block|{
name|load
operator|=
name|tdq
operator|->
name|tdq_load
expr_stmt|;
if|if
condition|(
name|high
operator|==
name|NULL
operator|||
name|load
operator|>
name|high
operator|->
name|tdq_load
condition|)
name|high
operator|=
name|tdq
expr_stmt|;
if|if
condition|(
name|low
operator|==
name|NULL
operator|||
name|load
operator|<
name|low
operator|->
name|tdq_load
condition|)
name|low
operator|=
name|tdq
expr_stmt|;
block|}
if|if
condition|(
name|high
operator|!=
name|NULL
operator|&&
name|low
operator|!=
name|NULL
operator|&&
name|high
operator|!=
name|low
condition|)
name|sched_balance_pair
argument_list|(
name|high
argument_list|,
name|low
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_balance_pair
parameter_list|(
name|struct
name|tdq
modifier|*
name|high
parameter_list|,
name|struct
name|tdq
modifier|*
name|low
parameter_list|)
block|{
name|int
name|transferable
decl_stmt|;
name|int
name|high_load
decl_stmt|;
name|int
name|low_load
decl_stmt|;
name|int
name|move
decl_stmt|;
name|int
name|diff
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * If we're transfering within a group we have to use this specific 	 * tdq's transferable count, otherwise we can steal from other members 	 * of the group. 	 */
if|if
condition|(
name|high
operator|->
name|tdq_group
operator|==
name|low
operator|->
name|tdq_group
condition|)
block|{
name|transferable
operator|=
name|high
operator|->
name|tdq_transferable
expr_stmt|;
name|high_load
operator|=
name|high
operator|->
name|tdq_load
expr_stmt|;
name|low_load
operator|=
name|low
operator|->
name|tdq_load
expr_stmt|;
block|}
else|else
block|{
name|transferable
operator|=
name|high
operator|->
name|tdq_group
operator|->
name|tdg_transferable
expr_stmt|;
name|high_load
operator|=
name|high
operator|->
name|tdq_group
operator|->
name|tdg_load
expr_stmt|;
name|low_load
operator|=
name|low
operator|->
name|tdq_group
operator|->
name|tdg_load
expr_stmt|;
block|}
if|if
condition|(
name|transferable
operator|==
literal|0
condition|)
return|return;
comment|/* 	 * Determine what the imbalance is and then adjust that to how many 	 * threads we actually have to give up (transferable). 	 */
name|diff
operator|=
name|high_load
operator|-
name|low_load
expr_stmt|;
name|move
operator|=
name|diff
operator|/
literal|2
expr_stmt|;
if|if
condition|(
name|diff
operator|&
literal|0x1
condition|)
name|move
operator|++
expr_stmt|;
name|move
operator|=
name|min
argument_list|(
name|move
argument_list|,
name|transferable
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|move
condition|;
name|i
operator|++
control|)
name|tdq_move
argument_list|(
name|high
argument_list|,
name|TDQ_ID
argument_list|(
name|low
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_function
specifier|static
name|void
name|tdq_move
parameter_list|(
name|struct
name|tdq
modifier|*
name|from
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|tdq
modifier|*
name|to
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|tdq
operator|=
name|from
expr_stmt|;
name|to
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|ts
operator|=
name|tdq_steal
argument_list|(
name|tdq
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|==
name|NULL
condition|)
block|{
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|tdg
operator|=
name|tdq
operator|->
name|tdq_group
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|tdq
argument_list|,
argument|&tdg->tdg_members
argument_list|,
argument|tdq_siblings
argument_list|)
block|{
if|if
condition|(
name|tdq
operator|==
name|from
operator|||
name|tdq
operator|->
name|tdq_transferable
operator|==
literal|0
condition|)
continue|continue;
name|ts
operator|=
name|tdq_steal
argument_list|(
name|tdq
argument_list|,
literal|1
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|ts
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"tdq_move: No threads available with a "
literal|"transferable count of %d\n"
argument_list|,
name|tdg
operator|->
name|tdg_transferable
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|tdq
operator|==
name|to
condition|)
return|return;
name|ts
operator|->
name|ts_state
operator|=
name|TSS_THREAD
expr_stmt|;
name|tdq_runq_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|tdq_notify
argument_list|(
name|ts
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|tdq_idled
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|struct
name|tdq
modifier|*
name|steal
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|tdg
operator|=
name|tdq
operator|->
name|tdq_group
expr_stmt|;
comment|/* 	 * If we're in a cpu group, try and steal threads from another cpu in 	 * the group before idling. 	 */
if|if
condition|(
name|tdg
operator|->
name|tdg_cpus
operator|>
literal|1
operator|&&
name|tdg
operator|->
name|tdg_transferable
condition|)
block|{
name|LIST_FOREACH
argument_list|(
argument|steal
argument_list|,
argument|&tdg->tdg_members
argument_list|,
argument|tdq_siblings
argument_list|)
block|{
if|if
condition|(
name|steal
operator|==
name|tdq
operator|||
name|steal
operator|->
name|tdq_transferable
operator|==
literal|0
condition|)
continue|continue;
name|ts
operator|=
name|tdq_steal
argument_list|(
name|steal
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|==
name|NULL
condition|)
continue|continue;
name|ts
operator|->
name|ts_state
operator|=
name|TSS_THREAD
expr_stmt|;
name|tdq_runq_rem
argument_list|(
name|steal
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|steal
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_INTERNAL
operator||
name|TSF_HOLD
expr_stmt|;
name|sched_add
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|,
name|SRQ_YIELDING
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
block|}
comment|/* 	 * We only set the idled bit when all of the cpus in the group are 	 * idle.  Otherwise we could get into a situation where a thread bounces 	 * back and forth between two idle cores on seperate physical CPUs. 	 */
name|tdg
operator|->
name|tdg_idlemask
operator||=
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
expr_stmt|;
if|if
condition|(
name|tdg
operator|->
name|tdg_idlemask
operator|!=
name|tdg
operator|->
name|tdg_cpumask
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|atomic_set_int
argument_list|(
operator|&
name|tdq_idle
argument_list|,
name|tdg
operator|->
name|tdg_mask
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|tdq_assign
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|nts
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
do|do
block|{
operator|*
operator|(
specifier|volatile
expr|struct
name|td_sched
operator|*
operator|*
operator|)
operator|&
name|ts
operator|=
name|tdq
operator|->
name|tdq_assigned
expr_stmt|;
block|}
do|while
condition|(
operator|!
name|atomic_cmpset_ptr
argument_list|(
operator|(
specifier|volatile
name|uintptr_t
operator|*
operator|)
operator|&
name|tdq
operator|->
name|tdq_assigned
argument_list|,
operator|(
name|uintptr_t
operator|)
name|ts
argument_list|,
operator|(
name|uintptr_t
operator|)
name|NULL
argument_list|)
condition|)
do|;
for|for
control|(
init|;
name|ts
operator|!=
name|NULL
condition|;
name|ts
operator|=
name|nts
control|)
block|{
name|nts
operator|=
name|ts
operator|->
name|ts_assign
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_load
operator|--
expr_stmt|;
name|tdq
operator|->
name|tdq_load
operator|--
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_ASSIGNED
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_REMOVED
condition|)
block|{
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_REMOVED
expr_stmt|;
continue|continue;
block|}
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_INTERNAL
operator||
name|TSF_HOLD
expr_stmt|;
name|sched_add
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|,
name|SRQ_YIELDING
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|tdq_notify
parameter_list|(
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pcpu
decl_stmt|;
name|int
name|class
decl_stmt|;
name|int
name|prio
decl_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
comment|/* XXX */
name|class
operator|=
name|PRI_BASE
argument_list|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_pri_class
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|class
operator|==
name|PRI_TIMESHARE
operator|||
name|class
operator|==
name|PRI_REALTIME
operator|)
operator|&&
operator|(
name|tdq_idle
operator|&
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_mask
operator|)
condition|)
name|atomic_clear_int
argument_list|(
operator|&
name|tdq_idle
argument_list|,
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_mask
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_load
operator|++
expr_stmt|;
name|tdq
operator|->
name|tdq_load
operator|++
expr_stmt|;
name|ts
operator|->
name|ts_cpu
operator|=
name|cpu
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_ASSIGNED
expr_stmt|;
name|prio
operator|=
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
expr_stmt|;
comment|/* 	 * Place a thread on another cpu's queue and force a resched. 	 */
do|do
block|{
operator|*
operator|(
specifier|volatile
expr|struct
name|td_sched
operator|*
operator|*
operator|)
operator|&
name|ts
operator|->
name|ts_assign
operator|=
name|tdq
operator|->
name|tdq_assigned
expr_stmt|;
block|}
do|while
condition|(
operator|!
name|atomic_cmpset_ptr
argument_list|(
operator|(
specifier|volatile
name|uintptr_t
operator|*
operator|)
operator|&
name|tdq
operator|->
name|tdq_assigned
argument_list|,
operator|(
name|uintptr_t
operator|)
name|ts
operator|->
name|ts_assign
argument_list|,
operator|(
name|uintptr_t
operator|)
name|ts
argument_list|)
condition|)
do|;
comment|/* 	 * Without sched_lock we could lose a race where we set NEEDRESCHED 	 * on a thread that is switched out before the IPI is delivered.  This 	 * would lead us to miss the resched.  This will be a problem once 	 * sched_lock is pushed down. 	 */
name|pcpu
operator|=
name|pcpu_find
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|td
operator|=
name|pcpu
operator|->
name|pc_curthread
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
operator|<
name|td
operator|->
name|td_priority
operator|||
name|td
operator|==
name|pcpu
operator|->
name|pc_idlethread
condition|)
block|{
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
name|ipi_selected
argument_list|(
literal|1
operator|<<
name|cpu
argument_list|,
name|IPI_AST
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|struct
name|td_sched
modifier|*
name|runq_steal
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|)
block|{
name|struct
name|rqhead
modifier|*
name|rqh
decl_stmt|;
name|struct
name|rqbits
modifier|*
name|rqb
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|word
decl_stmt|;
name|int
name|bit
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|rqb
operator|=
operator|&
name|rq
operator|->
name|rq_status
expr_stmt|;
for|for
control|(
name|word
operator|=
literal|0
init|;
name|word
operator|<
name|RQB_LEN
condition|;
name|word
operator|++
control|)
block|{
if|if
condition|(
name|rqb
operator|->
name|rqb_bits
index|[
name|word
index|]
operator|==
literal|0
condition|)
continue|continue;
for|for
control|(
name|bit
operator|=
literal|0
init|;
name|bit
operator|<
name|RQB_BPW
condition|;
name|bit
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|rqb
operator|->
name|rqb_bits
index|[
name|word
index|]
operator|&
operator|(
literal|1ul
operator|<<
name|bit
operator|)
operator|)
operator|==
literal|0
condition|)
continue|continue;
name|rqh
operator|=
operator|&
name|rq
operator|->
name|rq_queues
index|[
name|bit
operator|+
operator|(
name|word
operator|<<
name|RQB_L2BPW
operator|)
index|]
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|ts
argument_list|,
argument|rqh
argument_list|,
argument|ts_procq
argument_list|)
block|{
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|ts
argument_list|)
condition|)
return|return
operator|(
name|ts
operator|)
return|;
block|}
block|}
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|struct
name|td_sched
modifier|*
name|tdq_steal
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|int
name|stealidle
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
comment|/* 	 * Steal from next first to try to get a non-interactive task that 	 * may not have run for a while. 	 */
if|if
condition|(
operator|(
name|ts
operator|=
name|runq_steal
argument_list|(
name|tdq
operator|->
name|tdq_next
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
return|return
operator|(
name|ts
operator|)
return|;
if|if
condition|(
operator|(
name|ts
operator|=
name|runq_steal
argument_list|(
name|tdq
operator|->
name|tdq_curr
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
return|return
operator|(
name|ts
operator|)
return|;
if|if
condition|(
name|stealidle
condition|)
return|return
operator|(
name|runq_steal
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|)
operator|)
return|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_function
name|int
name|tdq_transfer
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|,
name|int
name|class
parameter_list|)
block|{
name|struct
name|tdq_group
modifier|*
name|ntdg
decl_stmt|;
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|struct
name|tdq
modifier|*
name|old
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|int
name|idx
decl_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|cpu
operator|=
literal|0
expr_stmt|;
comment|/* 	 * If our load exceeds a certain threshold we should attempt to 	 * reassign this thread.  The first candidate is the cpu that 	 * originally ran the thread.  If it is idle, assign it there,  	 * otherwise, pick an idle cpu. 	 * 	 * The threshold at which we start to reassign has a large impact 	 * on the overall performance of the system.  Tuned too high and 	 * some CPUs may idle.  Too low and there will be excess migration 	 * and context switches. 	 */
name|old
operator|=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
name|ntdg
operator|=
name|old
operator|->
name|tdq_group
expr_stmt|;
name|tdg
operator|=
name|tdq
operator|->
name|tdq_group
expr_stmt|;
if|if
condition|(
name|tdq_idle
condition|)
block|{
if|if
condition|(
name|tdq_idle
operator|&
name|ntdg
operator|->
name|tdg_mask
condition|)
block|{
name|cpu
operator|=
name|ffs
argument_list|(
name|ntdg
operator|->
name|tdg_idlemask
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"tdq_transfer: %p found old cpu %X "
literal|"in idlemask."
argument_list|,
name|ts
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
goto|goto
name|migrate
goto|;
block|}
block|}
comment|/* 		 * Multiple cpus could find this bit simultaneously 		 * but the race shouldn't be terrible. 		 */
name|cpu
operator|=
name|ffs
argument_list|(
name|tdq_idle
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"tdq_transfer: %p found %X "
literal|"in idlemask."
argument_list|,
name|ts
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
goto|goto
name|migrate
goto|;
block|}
block|}
name|idx
operator|=
literal|0
expr_stmt|;
if|#
directive|if
literal|0
block|if (old->tdq_load< tdq->tdq_load) { 		cpu = ts->ts_cpu + 1; 		CTR2(KTR_SCHED, "tdq_transfer: %p old cpu %X "  		    "load less than ours.", ts, cpu); 		goto migrate; 	}
comment|/* 	 * No new CPU was found, look for one with less load. 	 */
block|for (idx = 0; idx<= tdg_maxid; idx++) { 		ntdg = TDQ_GROUP(idx); 		if (ntdg->tdg_load
comment|/*+ (ntdg->tdg_cpus  * 2)*/
block|< tdg->tdg_load) { 			cpu = ffs(ntdg->tdg_cpumask); 			CTR2(KTR_SCHED, "tdq_transfer: %p cpu %X load less "  			    "than ours.", ts, cpu); 			goto migrate; 		} 	}
endif|#
directive|endif
comment|/* 	 * If another cpu in this group has idled, assign a thread over 	 * to them after checking to see if there are idled groups. 	 */
if|if
condition|(
name|tdg
operator|->
name|tdg_idlemask
condition|)
block|{
name|cpu
operator|=
name|ffs
argument_list|(
name|tdg
operator|->
name|tdg_idlemask
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"tdq_transfer: %p cpu %X idle in "
literal|"group."
argument_list|,
name|ts
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
goto|goto
name|migrate
goto|;
block|}
block|}
return|return
operator|(
literal|0
operator|)
return|;
name|migrate
label|:
comment|/* 	 * Now that we've found an idle CPU, migrate the thread. 	 */
name|cpu
operator|--
expr_stmt|;
name|ts
operator|->
name|ts_runq
operator|=
name|NULL
expr_stmt|;
name|tdq_notify
argument_list|(
name|ts
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* SMP */
end_comment

begin_comment
comment|/*  * Pick the highest priority task we have and return it.  */
end_comment

begin_function
specifier|static
name|struct
name|td_sched
modifier|*
name|tdq_choose
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
name|struct
name|runq
modifier|*
name|swap
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|nice
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|swap
operator|=
name|NULL
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|ts
operator|=
name|runq_choose
argument_list|(
name|tdq
operator|->
name|tdq_curr
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|==
name|NULL
condition|)
block|{
comment|/* 			 * We already swapped once and didn't get anywhere. 			 */
if|if
condition|(
name|swap
condition|)
break|break;
name|swap
operator|=
name|tdq
operator|->
name|tdq_curr
expr_stmt|;
name|tdq
operator|->
name|tdq_curr
operator|=
name|tdq
operator|->
name|tdq_next
expr_stmt|;
name|tdq
operator|->
name|tdq_next
operator|=
name|swap
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * If we encounter a slice of 0 the td_sched is in a 		 * TIMESHARE td_sched group and its nice was too far out 		 * of the range that receives slices.  		 */
name|nice
operator|=
name|ts
operator|->
name|ts_thread
operator|->
name|td_proc
operator|->
name|p_nice
operator|+
operator|(
literal|0
operator|-
name|tdq
operator|->
name|tdq_nicemin
operator|)
expr_stmt|;
if|#
directive|if
literal|0
block|if (ts->ts_slice == 0 || (nice> SCHED_SLICE_NTHRESH&& 		    ts->ts_thread->td_proc->p_nice != 0)) { 			runq_remove(ts->ts_runq, ts); 			sched_slice(ts); 			ts->ts_runq = tdq->tdq_next; 			runq_add(ts->ts_runq, ts, 0); 			continue; 		}
endif|#
directive|endif
return|return
operator|(
name|ts
operator|)
return|;
block|}
return|return
operator|(
name|runq_choose
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|tdq_setup
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
name|runq_init
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
name|runq_init
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
name|runq_init
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_curr
operator|=
operator|&
name|tdq
operator|->
name|tdq_timeshare
index|[
literal|0
index|]
expr_stmt|;
name|tdq
operator|->
name|tdq_next
operator|=
operator|&
name|tdq
operator|->
name|tdq_timeshare
index|[
literal|1
index|]
expr_stmt|;
name|tdq
operator|->
name|tdq_load
operator|=
literal|0
expr_stmt|;
name|tdq
operator|->
name|tdq_load_timeshare
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|int
name|i
decl_stmt|;
endif|#
directive|endif
comment|/* 	 * To avoid divide-by-zero, we set realstathz a dummy value 	 * in case which sched_clock() called before sched_initticks(). 	 */
name|realstathz
operator|=
name|hz
expr_stmt|;
name|slice_min
operator|=
operator|(
name|hz
operator|/
literal|100
operator|)
expr_stmt|;
comment|/* 10ms */
name|slice_max
operator|=
operator|(
name|hz
operator|/
literal|7
operator|)
expr_stmt|;
comment|/* ~140ms */
ifdef|#
directive|ifdef
name|SMP
name|balance_groups
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Initialize the tdqs. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
name|i
operator|++
control|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
operator|&
name|tdq_cpu
index|[
name|i
index|]
expr_stmt|;
name|tdq
operator|->
name|tdq_assigned
operator|=
name|NULL
expr_stmt|;
name|tdq_setup
argument_list|(
operator|&
name|tdq_cpu
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|smp_topology
operator|==
name|NULL
condition|)
block|{
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|cpus
decl_stmt|;
for|for
control|(
name|cpus
operator|=
literal|0
operator|,
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|CPU_ABSENT
argument_list|(
name|i
argument_list|)
condition|)
continue|continue;
name|tdq
operator|=
operator|&
name|tdq_cpu
index|[
name|i
index|]
expr_stmt|;
name|tdg
operator|=
operator|&
name|tdq_groups
index|[
name|cpus
index|]
expr_stmt|;
comment|/* 			 * Setup a tdq group with one member. 			 */
name|tdq
operator|->
name|tdq_transferable
operator|=
literal|0
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|=
name|tdg
expr_stmt|;
name|tdg
operator|->
name|tdg_cpus
operator|=
literal|1
expr_stmt|;
name|tdg
operator|->
name|tdg_idlemask
operator|=
literal|0
expr_stmt|;
name|tdg
operator|->
name|tdg_cpumask
operator|=
name|tdg
operator|->
name|tdg_mask
operator|=
literal|1
operator|<<
name|i
expr_stmt|;
name|tdg
operator|->
name|tdg_load
operator|=
literal|0
expr_stmt|;
name|tdg
operator|->
name|tdg_transferable
operator|=
literal|0
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|tdg
operator|->
name|tdg_members
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|tdg
operator|->
name|tdg_members
argument_list|,
name|tdq
argument_list|,
name|tdq_siblings
argument_list|)
expr_stmt|;
name|cpus
operator|++
expr_stmt|;
block|}
name|tdg_maxid
operator|=
name|cpus
operator|-
literal|1
expr_stmt|;
block|}
else|else
block|{
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|struct
name|cpu_group
modifier|*
name|cg
decl_stmt|;
name|int
name|j
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|smp_topology
operator|->
name|ct_count
condition|;
name|i
operator|++
control|)
block|{
name|cg
operator|=
operator|&
name|smp_topology
operator|->
name|ct_group
index|[
name|i
index|]
expr_stmt|;
name|tdg
operator|=
operator|&
name|tdq_groups
index|[
name|i
index|]
expr_stmt|;
comment|/* 			 * Initialize the group. 			 */
name|tdg
operator|->
name|tdg_idlemask
operator|=
literal|0
expr_stmt|;
name|tdg
operator|->
name|tdg_load
operator|=
literal|0
expr_stmt|;
name|tdg
operator|->
name|tdg_transferable
operator|=
literal|0
expr_stmt|;
name|tdg
operator|->
name|tdg_cpus
operator|=
name|cg
operator|->
name|cg_count
expr_stmt|;
name|tdg
operator|->
name|tdg_cpumask
operator|=
name|cg
operator|->
name|cg_mask
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|tdg
operator|->
name|tdg_members
argument_list|)
expr_stmt|;
comment|/* 			 * Find all of the group members and add them. 			 */
for|for
control|(
name|j
operator|=
literal|0
init|;
name|j
operator|<
name|MAXCPU
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|cg
operator|->
name|cg_mask
operator|&
operator|(
literal|1
operator|<<
name|j
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|tdg
operator|->
name|tdg_mask
operator|==
literal|0
condition|)
name|tdg
operator|->
name|tdg_mask
operator|=
literal|1
operator|<<
name|j
expr_stmt|;
name|tdq_cpu
index|[
name|j
index|]
operator|.
name|tdq_transferable
operator|=
literal|0
expr_stmt|;
name|tdq_cpu
index|[
name|j
index|]
operator|.
name|tdq_group
operator|=
name|tdg
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|tdg
operator|->
name|tdg_members
argument_list|,
operator|&
name|tdq_cpu
index|[
name|j
index|]
argument_list|,
name|tdq_siblings
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|tdg
operator|->
name|tdg_cpus
operator|>
literal|1
condition|)
name|balance_groups
operator|=
literal|1
expr_stmt|;
block|}
name|tdg_maxid
operator|=
name|smp_topology
operator|->
name|ct_count
operator|-
literal|1
expr_stmt|;
block|}
comment|/* 	 * Stagger the group and global load balancer so they do not 	 * interfere with each other. 	 */
name|bal_tick
operator|=
name|ticks
operator|+
name|hz
expr_stmt|;
if|if
condition|(
name|balance_groups
condition|)
name|gbal_tick
operator|=
name|ticks
operator|+
operator|(
name|hz
operator|/
literal|2
operator|)
expr_stmt|;
else|#
directive|else
name|tdq_setup
argument_list|(
name|TDQ_SELF
argument_list|()
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|tdq_load_add
argument_list|(
name|TDQ_SELF
argument_list|()
argument_list|,
operator|&
name|td_sched0
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|sched_initticks
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|realstathz
operator|=
name|stathz
condition|?
name|stathz
else|:
name|hz
expr_stmt|;
name|slice_min
operator|=
operator|(
name|realstathz
operator|/
literal|100
operator|)
expr_stmt|;
comment|/* 10ms */
name|slice_max
operator|=
operator|(
name|realstathz
operator|/
literal|7
operator|)
expr_stmt|;
comment|/* ~140ms */
name|tickincr
operator|=
operator|(
name|hz
operator|<<
literal|10
operator|)
operator|/
name|realstathz
expr_stmt|;
comment|/* 	 * XXX This does not work for values of stathz that are much 	 * larger than hz. 	 */
if|if
condition|(
name|tickincr
operator|==
literal|0
condition|)
name|tickincr
operator|=
literal|1
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Scale the scheduling priority according to the "interactivity" of this  * process.  */
end_comment

begin_function
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|int
name|pri
decl_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|!=
name|PRI_TIMESHARE
condition|)
return|return;
name|pri
operator|=
name|SCHED_PRI_INTERACT
argument_list|(
name|sched_interact_score
argument_list|(
name|td
argument_list|)
argument_list|)
expr_stmt|;
name|pri
operator|+=
name|SCHED_PRI_BASE
expr_stmt|;
name|pri
operator|+=
name|td
operator|->
name|td_proc
operator|->
name|p_nice
expr_stmt|;
if|if
condition|(
name|pri
operator|>
name|PRI_MAX_TIMESHARE
condition|)
name|pri
operator|=
name|PRI_MAX_TIMESHARE
expr_stmt|;
elseif|else
if|if
condition|(
name|pri
operator|<
name|PRI_MIN_TIMESHARE
condition|)
name|pri
operator|=
name|PRI_MIN_TIMESHARE
expr_stmt|;
name|sched_user_prio
argument_list|(
name|td
argument_list|,
name|pri
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_comment
comment|/*  * Calculate a time slice based on the properties of the process  * and the runq that we're on.  This is only for PRI_TIMESHARE threads.  */
end_comment

begin_function
specifier|static
name|void
name|sched_slice
parameter_list|(
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|td
operator|=
name|ts
operator|->
name|ts_thread
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
condition|)
block|{
name|ts
operator|->
name|ts_slice
operator|=
name|SCHED_SLICE_MIN
expr_stmt|;
return|return;
block|}
comment|/* 	 * Rationale: 	 * Threads in interactive procs get a minimal slice so that we 	 * quickly notice if it abuses its advantage. 	 * 	 * Threads in non-interactive procs are assigned a slice that is 	 * based on the procs nice value relative to the least nice procs 	 * on the run queue for this cpu. 	 * 	 * If the thread is less nice than all others it gets the maximum 	 * slice and other threads will adjust their slice relative to 	 * this when they first expire. 	 * 	 * There is 20 point window that starts relative to the least 	 * nice td_sched on the run queue.  Slice size is determined by 	 * the td_sched distance from the last nice thread. 	 * 	 * If the td_sched is outside of the window it will get no slice 	 * and will be reevaluated each time it is selected on the 	 * run queue.  The exception to this is nice 0 procs when 	 * a nice -20 is running.  They are always granted a minimum 	 * slice. 	 */
if|if
condition|(
operator|!
name|SCHED_INTERACTIVE
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|int
name|nice
decl_stmt|;
name|nice
operator|=
name|td
operator|->
name|td_proc
operator|->
name|p_nice
operator|+
operator|(
literal|0
operator|-
name|tdq
operator|->
name|tdq_nicemin
operator|)
expr_stmt|;
if|if
condition|(
name|tdq
operator|->
name|tdq_load_timeshare
operator|==
literal|0
operator|||
name|td
operator|->
name|td_proc
operator|->
name|p_nice
operator|<
name|tdq
operator|->
name|tdq_nicemin
condition|)
name|ts
operator|->
name|ts_slice
operator|=
name|SCHED_SLICE_MAX
expr_stmt|;
elseif|else
if|if
condition|(
name|nice
operator|<=
name|SCHED_SLICE_NTHRESH
condition|)
name|ts
operator|->
name|ts_slice
operator|=
name|SCHED_SLICE_NICE
argument_list|(
name|nice
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|td
operator|->
name|td_proc
operator|->
name|p_nice
operator|==
literal|0
condition|)
name|ts
operator|->
name|ts_slice
operator|=
name|SCHED_SLICE_MIN
expr_stmt|;
else|else
name|ts
operator|->
name|ts_slice
operator|=
name|SCHED_SLICE_MIN
expr_stmt|;
comment|/* 0 */
block|}
else|else
name|ts
operator|->
name|ts_slice
operator|=
name|SCHED_SLICE_INTERACTIVE
expr_stmt|;
return|return;
block|}
end_function

begin_comment
comment|/*  * This routine enforces a maximum limit on the amount of scheduling history  * kept.  It is called after either the slptime or runtime is adjusted.  * This routine will not operate correctly when slp or run times have been  * adjusted to more than double their maximum.  */
end_comment

begin_function
specifier|static
name|void
name|sched_interact_update
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|int
name|sum
decl_stmt|;
name|sum
operator|=
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|+
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
expr_stmt|;
if|if
condition|(
name|sum
operator|<
name|SCHED_SLP_RUN_MAX
condition|)
return|return;
comment|/* 	 * If we have exceeded by more than 1/5th then the algorithm below 	 * will not bring us back into range.  Dividing by two here forces 	 * us into the range of [4/5 * SCHED_INTERACT_MAX, SCHED_INTERACT_MAX] 	 */
if|if
condition|(
name|sum
operator|>
operator|(
name|SCHED_SLP_RUN_MAX
operator|/
literal|5
operator|)
operator|*
literal|6
condition|)
block|{
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|/=
literal|2
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
operator|/=
literal|2
expr_stmt|;
return|return;
block|}
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|=
operator|(
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|/
literal|5
operator|)
operator|*
literal|4
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
operator|=
operator|(
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
operator|/
literal|5
operator|)
operator|*
literal|4
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_interact_fork
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|int
name|ratio
decl_stmt|;
name|int
name|sum
decl_stmt|;
name|sum
operator|=
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|+
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
expr_stmt|;
if|if
condition|(
name|sum
operator|>
name|SCHED_SLP_RUN_FORK
condition|)
block|{
name|ratio
operator|=
name|sum
operator|/
name|SCHED_SLP_RUN_FORK
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|/=
name|ratio
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
operator|/=
name|ratio
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|int
name|sched_interact_score
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|int
name|div
decl_stmt|;
if|if
condition|(
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|>
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
condition|)
block|{
name|div
operator|=
name|max
argument_list|(
literal|1
argument_list|,
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|/
name|SCHED_INTERACT_HALF
argument_list|)
expr_stmt|;
return|return
operator|(
name|SCHED_INTERACT_HALF
operator|+
operator|(
name|SCHED_INTERACT_HALF
operator|-
operator|(
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
operator|/
name|div
operator|)
operator|)
operator|)
return|;
block|}
if|if
condition|(
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
operator|>
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
condition|)
block|{
name|div
operator|=
name|max
argument_list|(
literal|1
argument_list|,
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
operator|/
name|SCHED_INTERACT_HALF
argument_list|)
expr_stmt|;
return|return
operator|(
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|/
name|div
operator|)
return|;
block|}
comment|/* 	 * This can happen if slptime and runtime are 0. 	 */
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Very early in the boot some setup of scheduler-specific  * parts of proc0 and of soem scheduler resources needs to be done.  * Called from:  *  proc0_init()  */
end_comment

begin_function
name|void
name|schedinit
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * Set up the scheduler specific parts of proc0. 	 */
name|proc0
operator|.
name|p_sched
operator|=
name|NULL
expr_stmt|;
comment|/* XXX */
name|thread0
operator|.
name|td_sched
operator|=
operator|&
name|td_sched0
expr_stmt|;
name|td_sched0
operator|.
name|ts_thread
operator|=
operator|&
name|thread0
expr_stmt|;
name|td_sched0
operator|.
name|ts_state
operator|=
name|TSS_THREAD
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This is only somewhat accurate since given many processes of the same  * priority they will switch when their slices run out, which will be  * at most SCHED_SLICE_MAX.  */
end_comment

begin_function
name|int
name|sched_rr_interval
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
name|SCHED_SLICE_MAX
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_pctcpu_update
parameter_list|(
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|)
block|{
comment|/* 	 * Adjust counters and watermark for pctcpu calc. 	 */
if|if
condition|(
name|ts
operator|->
name|ts_ltick
operator|>
name|ticks
operator|-
name|SCHED_CPU_TICKS
condition|)
block|{
comment|/* 		 * Shift the tick count out so that the divide doesn't 		 * round away our results. 		 */
name|ts
operator|->
name|ts_ticks
operator|<<=
literal|10
expr_stmt|;
name|ts
operator|->
name|ts_ticks
operator|=
operator|(
name|ts
operator|->
name|ts_ticks
operator|/
operator|(
name|ticks
operator|-
name|ts
operator|->
name|ts_ftick
operator|)
operator|)
operator|*
name|SCHED_CPU_TICKS
expr_stmt|;
name|ts
operator|->
name|ts_ticks
operator|>>=
literal|10
expr_stmt|;
block|}
else|else
name|ts
operator|->
name|ts_ticks
operator|=
literal|0
expr_stmt|;
name|ts
operator|->
name|ts_ltick
operator|=
name|ticks
expr_stmt|;
name|ts
operator|->
name|ts_ftick
operator|=
name|ts
operator|->
name|ts_ltick
operator|-
name|SCHED_CPU_TICKS
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_thread_priority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|CTR6
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_prio: %p(%s) prio %d newprio %d by %p(%s)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|prio
argument_list|,
name|curthread
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|==
name|prio
condition|)
return|return;
if|if
condition|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
condition|)
block|{
comment|/* 		 * If the priority has been elevated due to priority 		 * propagation, we may have to move ourselves to a new 		 * queue.  We still call adjustrunqueue below in case kse 		 * needs to fix things up. 		 */
if|if
condition|(
name|prio
operator|<
name|td
operator|->
name|td_priority
operator|&&
name|ts
operator|->
name|ts_runq
operator|!=
name|NULL
operator|&&
operator|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_ASSIGNED
operator|)
operator|==
literal|0
operator|&&
name|ts
operator|->
name|ts_runq
operator|!=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
operator|->
name|tdq_curr
condition|)
block|{
name|runq_remove
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_runq
operator|=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
operator|->
name|tdq_curr
expr_stmt|;
name|runq_add
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|ts
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Hold this td_sched on this cpu so that sched_prio() doesn't 		 * cause excessive migration.  We only want migration to 		 * happen as the result of a wakeup. 		 */
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_HOLD
expr_stmt|;
name|adjustrunqueue
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_HOLD
expr_stmt|;
block|}
else|else
name|td
operator|->
name|td_priority
operator|=
name|prio
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Update a thread's priority when it is lent another thread's  * priority.  */
end_comment

begin_function
name|void
name|sched_lend_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|td
operator|->
name|td_flags
operator||=
name|TDF_BORROWING
expr_stmt|;
name|sched_thread_priority
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Restore a thread's priority when priority propagation is  * over.  The prio argument is the minimum priority the thread  * needs to have to satisfy other possible priority lending  * requests.  If the thread's regular priority is less  * important than prio, the thread will keep a priority boost  * of prio.  */
end_comment

begin_function
name|void
name|sched_unlend_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|base_pri
decl_stmt|;
if|if
condition|(
name|td
operator|->
name|td_base_pri
operator|>=
name|PRI_MIN_TIMESHARE
operator|&&
name|td
operator|->
name|td_base_pri
operator|<=
name|PRI_MAX_TIMESHARE
condition|)
name|base_pri
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
else|else
name|base_pri
operator|=
name|td
operator|->
name|td_base_pri
expr_stmt|;
if|if
condition|(
name|prio
operator|>=
name|base_pri
condition|)
block|{
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_BORROWING
expr_stmt|;
name|sched_thread_priority
argument_list|(
name|td
argument_list|,
name|base_pri
argument_list|)
expr_stmt|;
block|}
else|else
name|sched_lend_prio
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
comment|/* First, update the base priority. */
name|td
operator|->
name|td_base_pri
operator|=
name|prio
expr_stmt|;
comment|/* 	 * If the thread is borrowing another thread's priority, don't 	 * ever lower the priority. 	 */
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
operator|&&
name|td
operator|->
name|td_priority
operator|<
name|prio
condition|)
return|return;
comment|/* Change the real priority. */
name|oldprio
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|sched_thread_priority
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
comment|/* 	 * If the thread is on a turnstile, then let the turnstile update 	 * its state. 	 */
if|if
condition|(
name|TD_ON_LOCK
argument_list|(
name|td
argument_list|)
operator|&&
name|oldprio
operator|!=
name|prio
condition|)
name|turnstile_adjust
argument_list|(
name|td
argument_list|,
name|oldprio
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
name|td
operator|->
name|td_base_user_pri
operator|=
name|prio
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_UBORROWING
operator|&&
name|td
operator|->
name|td_user_pri
operator|<=
name|prio
condition|)
return|return;
name|oldprio
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|td
operator|->
name|td_user_pri
operator|=
name|prio
expr_stmt|;
if|if
condition|(
name|TD_ON_UPILOCK
argument_list|(
name|td
argument_list|)
operator|&&
name|oldprio
operator|!=
name|prio
condition|)
name|umtx_pi_adjust
argument_list|(
name|td
argument_list|,
name|oldprio
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_lend_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_UBORROWING
expr_stmt|;
name|oldprio
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|td
operator|->
name|td_user_pri
operator|=
name|prio
expr_stmt|;
if|if
condition|(
name|TD_ON_UPILOCK
argument_list|(
name|td
argument_list|)
operator|&&
name|oldprio
operator|!=
name|prio
condition|)
name|umtx_pi_adjust
argument_list|(
name|td
argument_list|,
name|oldprio
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_unlend_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|base_pri
decl_stmt|;
name|base_pri
operator|=
name|td
operator|->
name|td_base_user_pri
expr_stmt|;
if|if
condition|(
name|prio
operator|>=
name|base_pri
condition|)
block|{
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_UBORROWING
expr_stmt|;
name|sched_user_prio
argument_list|(
name|td
argument_list|,
name|base_pri
argument_list|)
expr_stmt|;
block|}
else|else
name|sched_lend_user_prio
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_switch
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|newtd
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|td
operator|->
name|td_lastcpu
operator|=
name|td
operator|->
name|td_oncpu
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|NOCPU
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_NEEDRESCHED
expr_stmt|;
name|td
operator|->
name|td_owepreempt
operator|=
literal|0
expr_stmt|;
comment|/* 	 * If the thread has been assigned it may be in the process of switching 	 * to the new cpu.  This is the case in sched_bind(). 	 */
if|if
condition|(
name|td
operator|==
name|PCPU_GET
argument_list|(
name|idlethread
argument_list|)
condition|)
block|{
name|TD_SET_CAN_RUN
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_ASSIGNED
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* We are ending our run so make our slot available again */
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
if|if
condition|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
condition|)
block|{
comment|/* 			 * Don't allow the thread to migrate 			 * from a preemption. 			 */
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_HOLD
expr_stmt|;
name|setrunqueue
argument_list|(
name|td
argument_list|,
operator|(
name|flags
operator|&
name|SW_PREEMPT
operator|)
condition|?
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
operator||
name|SRQ_PREEMPTED
else|:
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_HOLD
expr_stmt|;
block|}
block|}
if|if
condition|(
name|newtd
operator|!=
name|NULL
condition|)
block|{
comment|/* 		 * If we bring in a thread account for it as if it had been 		 * added to the run queue and then chosen. 		 */
name|newtd
operator|->
name|td_sched
operator|->
name|ts_flags
operator||=
name|TSF_DIDRUN
expr_stmt|;
name|newtd
operator|->
name|td_sched
operator|->
name|ts_runq
operator|=
name|tdq
operator|->
name|tdq_curr
expr_stmt|;
name|TD_SET_RUNNING
argument_list|(
name|newtd
argument_list|)
expr_stmt|;
name|tdq_load_add
argument_list|(
name|TDQ_SELF
argument_list|()
argument_list|,
name|newtd
operator|->
name|td_sched
argument_list|)
expr_stmt|;
block|}
else|else
name|newtd
operator|=
name|choosethread
argument_list|()
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|newtd
condition|)
block|{
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
if|if
condition|(
name|PMC_PROC_IS_USING_PMCS
argument_list|(
name|td
operator|->
name|td_proc
argument_list|)
condition|)
name|PMC_SWITCH_CONTEXT
argument_list|(
name|td
argument_list|,
name|PMC_FN_CSW_OUT
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|cpu_switch
argument_list|(
name|td
argument_list|,
name|newtd
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
if|if
condition|(
name|PMC_PROC_IS_USING_PMCS
argument_list|(
name|td
operator|->
name|td_proc
argument_list|)
condition|)
name|PMC_SWITCH_CONTEXT
argument_list|(
name|td
argument_list|,
name|PMC_FN_CSW_IN
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
name|sched_lock
operator|.
name|mtx_lock
operator|=
operator|(
name|uintptr_t
operator|)
name|td
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_nice
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|int
name|nice
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * We need to adjust the nice counts for running threads. 	 */
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
block|{
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_runq
operator|==
name|NULL
condition|)
continue|continue;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
name|tdq_nice_rem
argument_list|(
name|tdq
argument_list|,
name|p
operator|->
name|p_nice
argument_list|)
expr_stmt|;
name|tdq_nice_add
argument_list|(
name|tdq
argument_list|,
name|nice
argument_list|)
expr_stmt|;
block|}
block|}
name|p
operator|->
name|p_nice
operator|=
name|nice
expr_stmt|;
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|sched_sleep
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_slptime
operator|=
name|ticks
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_wakeup
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Let the procs know how long we slept for.  This is because process 	 * interactivity behavior is modeled in the procs. 	 */
if|if
condition|(
name|td
operator|->
name|td_sched
operator|->
name|ts_slptime
condition|)
block|{
name|int
name|hzticks
decl_stmt|;
name|hzticks
operator|=
operator|(
name|ticks
operator|-
name|td
operator|->
name|td_sched
operator|->
name|ts_slptime
operator|)
operator|<<
literal|10
expr_stmt|;
if|if
condition|(
name|hzticks
operator|>=
name|SCHED_SLP_RUN_MAX
condition|)
block|{
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
operator|=
name|SCHED_SLP_RUN_MAX
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
operator|+=
name|hzticks
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_slice
argument_list|(
name|td
operator|->
name|td_sched
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_slptime
operator|=
literal|0
expr_stmt|;
block|}
name|setrunqueue
argument_list|(
name|td
argument_list|,
name|SRQ_BORING
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Penalize the parent for creating a new child and initialize the child's  * priority.  */
end_comment

begin_function
name|void
name|sched_fork
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|sched_fork_thread
argument_list|(
name|td
argument_list|,
name|child
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_fork_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts2
decl_stmt|;
name|child
operator|->
name|td_sched
operator|->
name|skg_slptime
operator|=
name|td
operator|->
name|td_sched
operator|->
name|skg_slptime
expr_stmt|;
name|child
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|=
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
expr_stmt|;
name|child
operator|->
name|td_user_pri
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|child
operator|->
name|td_base_user_pri
operator|=
name|td
operator|->
name|td_base_user_pri
expr_stmt|;
name|sched_interact_fork
argument_list|(
name|child
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|+=
name|tickincr
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_newthread
argument_list|(
name|child
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|ts2
operator|=
name|child
operator|->
name|td_sched
expr_stmt|;
name|ts2
operator|->
name|ts_slice
operator|=
literal|1
expr_stmt|;
comment|/* Attempt to quickly learn interactivity. */
name|ts2
operator|->
name|ts_cpu
operator|=
name|ts
operator|->
name|ts_cpu
expr_stmt|;
name|ts2
operator|->
name|ts_runq
operator|=
name|NULL
expr_stmt|;
comment|/* Grab our parents cpu estimation information. */
name|ts2
operator|->
name|ts_ticks
operator|=
name|ts
operator|->
name|ts_ticks
expr_stmt|;
name|ts2
operator|->
name|ts_ltick
operator|=
name|ts
operator|->
name|ts_ltick
expr_stmt|;
name|ts2
operator|->
name|ts_ftick
operator|=
name|ts
operator|->
name|ts_ftick
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_class
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|class
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|nclass
decl_stmt|;
name|int
name|oclass
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|==
name|class
condition|)
return|return;
name|nclass
operator|=
name|PRI_BASE
argument_list|(
name|class
argument_list|)
expr_stmt|;
name|oclass
operator|=
name|PRI_BASE
argument_list|(
name|td
operator|->
name|td_pri_class
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
operator|!
operator|(
operator|(
name|ts
operator|->
name|ts_state
operator|!=
name|TSS_ONRUNQ
operator|&&
name|ts
operator|->
name|ts_state
operator|!=
name|TSS_THREAD
operator|)
operator|||
name|ts
operator|->
name|ts_runq
operator|==
name|NULL
operator|)
condition|)
block|{
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
comment|/* 		 * On SMP if we're on the RUNQ we must adjust the transferable 		 * count because could be changing to or from an interrupt 		 * class. 		 */
if|if
condition|(
name|ts
operator|->
name|ts_state
operator|==
name|TSS_ONRUNQ
condition|)
block|{
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|ts
argument_list|)
condition|)
block|{
name|tdq
operator|->
name|tdq_transferable
operator|--
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_transferable
operator|--
expr_stmt|;
block|}
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|ts
argument_list|)
condition|)
block|{
name|tdq
operator|->
name|tdq_transferable
operator|++
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_transferable
operator|++
expr_stmt|;
block|}
block|}
endif|#
directive|endif
if|if
condition|(
name|oclass
operator|==
name|PRI_TIMESHARE
condition|)
block|{
name|tdq
operator|->
name|tdq_load_timeshare
operator|--
expr_stmt|;
name|tdq_nice_rem
argument_list|(
name|tdq
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|nclass
operator|==
name|PRI_TIMESHARE
condition|)
block|{
name|tdq
operator|->
name|tdq_load_timeshare
operator|++
expr_stmt|;
name|tdq_nice_add
argument_list|(
name|tdq
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
block|}
block|}
name|td
operator|->
name|td_pri_class
operator|=
name|class
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return some of the child's priority and interactivity to the parent.  */
end_comment

begin_function
name|void
name|sched_exit
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_exit: %p(%s) prio %d"
argument_list|,
name|child
argument_list|,
name|child
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|child
operator|->
name|td_priority
argument_list|)
expr_stmt|;
name|sched_exit_thread
argument_list|(
name|FIRST_THREAD_IN_PROC
argument_list|(
name|p
argument_list|)
argument_list|,
name|child
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_exit_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_exit_thread: %p(%s) prio %d"
argument_list|,
name|child
argument_list|,
name|childproc
operator|->
name|p_comm
argument_list|,
name|child
operator|->
name|td_priority
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|+=
name|child
operator|->
name|td_sched
operator|->
name|skg_runtime
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|TDQ_CPU
argument_list|(
name|child
operator|->
name|td_sched
operator|->
name|ts_cpu
argument_list|)
argument_list|,
name|child
operator|->
name|td_sched
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_userret
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
comment|/* 	 * XXX we cheat slightly on the locking here to avoid locking in   	 * the usual case.  Setting td_priority here is essentially an 	 * incomplete workaround for not setting it properly elsewhere. 	 * Now that some interrupt handlers are threads, not setting it 	 * properly elsewhere can clobber it in the window between setting 	 * it here and returning to user mode, so don't waste time setting 	 * it perfectly here. 	 */
name|KASSERT
argument_list|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"thread with borrowed priority returning to userland"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|!=
name|td
operator|->
name|td_user_pri
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_priority
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|td
operator|->
name|td_base_pri
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|sched_clock
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|ticks
operator|>=
name|bal_tick
condition|)
name|sched_balance
argument_list|()
expr_stmt|;
if|if
condition|(
name|ticks
operator|>=
name|gbal_tick
operator|&&
name|balance_groups
condition|)
name|sched_balance_groups
argument_list|()
expr_stmt|;
comment|/* 	 * We could have been assigned a non real-time thread without an 	 * IPI. 	 */
if|if
condition|(
name|tdq
operator|->
name|tdq_assigned
condition|)
name|tdq_assign
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
comment|/* Potentially sets NEEDRESCHED */
endif|#
directive|endif
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
comment|/* Adjust ticks for pctcpu */
name|ts
operator|->
name|ts_ticks
operator|++
expr_stmt|;
name|ts
operator|->
name|ts_ltick
operator|=
name|ticks
expr_stmt|;
comment|/* Go up to one second beyond our max and then trim back down */
if|if
condition|(
name|ts
operator|->
name|ts_ftick
operator|+
name|SCHED_CPU_TICKS
operator|+
name|hz
operator|<
name|ts
operator|->
name|ts_ltick
condition|)
name|sched_pctcpu_update
argument_list|(
name|ts
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_IDLETD
condition|)
return|return;
comment|/* 	 * We only do slicing code for TIMESHARE threads. 	 */
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|!=
name|PRI_TIMESHARE
condition|)
return|return;
comment|/* 	 * We used a tick charge it to the thread so that we can compute our 	 * interactivity. 	 */
name|td
operator|->
name|td_sched
operator|->
name|skg_runtime
operator|+=
name|tickincr
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
comment|/* 	 * We used up one time slice. 	 */
if|if
condition|(
operator|--
name|ts
operator|->
name|ts_slice
operator|>
literal|0
condition|)
return|return;
comment|/* 	 * We're out of time, recompute priorities and requeue. 	 */
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_slice
argument_list|(
name|ts
argument_list|)
expr_stmt|;
if|if
condition|(
name|SCHED_CURR
argument_list|(
name|td
argument_list|,
name|ts
argument_list|)
condition|)
name|ts
operator|->
name|ts_runq
operator|=
name|tdq
operator|->
name|tdq_curr
expr_stmt|;
else|else
name|ts
operator|->
name|ts_runq
operator|=
name|tdq
operator|->
name|tdq_next
expr_stmt|;
name|tdq_load_add
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
block|}
end_function

begin_function
name|int
name|sched_runnable
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|load
decl_stmt|;
name|load
operator|=
literal|1
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|tdq
operator|->
name|tdq_assigned
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|tdq_assign
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
if|if
condition|(
operator|(
name|curthread
operator|->
name|td_flags
operator|&
name|TDF_IDLETD
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|tdq
operator|->
name|tdq_load
operator|>
literal|0
condition|)
goto|goto
name|out
goto|;
block|}
elseif|else
if|if
condition|(
name|tdq
operator|->
name|tdq_load
operator|-
literal|1
operator|>
literal|0
condition|)
goto|goto
name|out
goto|;
name|load
operator|=
literal|0
expr_stmt|;
name|out
label|:
return|return
operator|(
name|load
operator|)
return|;
block|}
end_function

begin_function
name|struct
name|td_sched
modifier|*
name|sched_choose
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|restart
label|:
if|if
condition|(
name|tdq
operator|->
name|tdq_assigned
condition|)
name|tdq_assign
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|ts
operator|=
name|tdq_choose
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
condition|)
block|{
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_pri_class
operator|==
name|PRI_IDLE
condition|)
if|if
condition|(
name|tdq_idled
argument_list|(
name|tdq
argument_list|)
operator|==
literal|0
condition|)
goto|goto
name|restart
goto|;
endif|#
directive|endif
name|tdq_runq_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_state
operator|=
name|TSS_THREAD
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_PREEMPTED
expr_stmt|;
return|return
operator|(
name|ts
operator|)
return|;
block|}
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|tdq_idled
argument_list|(
name|tdq
argument_list|)
operator|==
literal|0
condition|)
goto|goto
name|restart
goto|;
endif|#
directive|endif
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_add
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|preemptive
decl_stmt|;
name|int
name|canmigrate
decl_stmt|;
name|int
name|class
decl_stmt|;
name|CTR5
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_add: %p(%s) prio %d by %p(%s)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|curthread
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|canmigrate
operator|=
literal|1
expr_stmt|;
name|preemptive
operator|=
operator|!
operator|(
name|flags
operator|&
name|SRQ_YIELDING
operator|)
expr_stmt|;
name|class
operator|=
name|PRI_BASE
argument_list|(
name|td
operator|->
name|td_pri_class
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_INTERNAL
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_ASSIGNED
condition|)
block|{
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_REMOVED
condition|)
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_REMOVED
expr_stmt|;
return|return;
block|}
name|canmigrate
operator|=
name|THREAD_CAN_MIGRATE
argument_list|(
name|ts
argument_list|)
expr_stmt|;
comment|/* 	 * Don't migrate running threads here.  Force the long term balancer 	 * to do it. 	 */
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_HOLD
condition|)
block|{
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_HOLD
expr_stmt|;
name|canmigrate
operator|=
literal|0
expr_stmt|;
block|}
endif|#
directive|endif
name|KASSERT
argument_list|(
name|ts
operator|->
name|ts_state
operator|!=
name|TSS_ONRUNQ
argument_list|,
operator|(
literal|"sched_add: thread %p (%s) already in run queue"
operator|,
name|td
operator|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|->
name|td_proc
operator|->
name|p_sflag
operator|&
name|PS_INMEM
argument_list|,
operator|(
literal|"sched_add: process swapped out"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|ts
operator|->
name|ts_runq
operator|==
name|NULL
argument_list|,
operator|(
literal|"sched_add: thread %p is still assigned to a run queue"
operator|,
name|td
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|SRQ_PREEMPTED
condition|)
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_PREEMPTED
expr_stmt|;
switch|switch
condition|(
name|class
condition|)
block|{
case|case
name|PRI_ITHD
case|:
case|case
name|PRI_REALTIME
case|:
name|ts
operator|->
name|ts_runq
operator|=
name|tdq
operator|->
name|tdq_curr
expr_stmt|;
name|ts
operator|->
name|ts_slice
operator|=
name|SCHED_SLICE_MAX
expr_stmt|;
if|if
condition|(
name|canmigrate
condition|)
name|ts
operator|->
name|ts_cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
break|break;
case|case
name|PRI_TIMESHARE
case|:
if|if
condition|(
name|SCHED_CURR
argument_list|(
name|td
argument_list|,
name|ts
argument_list|)
condition|)
name|ts
operator|->
name|ts_runq
operator|=
name|tdq
operator|->
name|tdq_curr
expr_stmt|;
else|else
name|ts
operator|->
name|ts_runq
operator|=
name|tdq
operator|->
name|tdq_next
expr_stmt|;
break|break;
case|case
name|PRI_IDLE
case|:
comment|/* 		 * This is for priority prop. 		 */
if|if
condition|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
operator|<
name|PRI_MIN_IDLE
condition|)
name|ts
operator|->
name|ts_runq
operator|=
name|tdq
operator|->
name|tdq_curr
expr_stmt|;
else|else
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|tdq
operator|->
name|tdq_idle
expr_stmt|;
name|ts
operator|->
name|ts_slice
operator|=
name|SCHED_SLICE_MIN
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"Unknown pri class."
argument_list|)
expr_stmt|;
break|break;
block|}
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * If this thread is pinned or bound, notify the target cpu. 	 */
if|if
condition|(
operator|!
name|canmigrate
operator|&&
name|ts
operator|->
name|ts_cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
block|{
name|ts
operator|->
name|ts_runq
operator|=
name|NULL
expr_stmt|;
name|tdq_notify
argument_list|(
name|ts
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * If we had been idle, clear our bit in the group and potentially 	 * the global bitmap.  If not, see if we should transfer this thread. 	 */
if|if
condition|(
operator|(
name|class
operator|==
name|PRI_TIMESHARE
operator|||
name|class
operator|==
name|PRI_REALTIME
operator|)
operator|&&
operator|(
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_idlemask
operator|&
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * Check to see if our group is unidling, and if so, remove it 		 * from the global idle mask. 		 */
if|if
condition|(
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_idlemask
operator|==
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_cpumask
condition|)
name|atomic_clear_int
argument_list|(
operator|&
name|tdq_idle
argument_list|,
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_mask
argument_list|)
expr_stmt|;
comment|/* 		 * Now remove ourselves from the group specific idle mask. 		 */
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_idlemask
operator|&=
operator|~
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|canmigrate
operator|&&
name|tdq
operator|->
name|tdq_load
operator|>
literal|1
operator|&&
name|class
operator|!=
name|PRI_ITHD
condition|)
if|if
condition|(
name|tdq_transfer
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|,
name|class
argument_list|)
condition|)
return|return;
name|ts
operator|->
name|ts_cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<
name|curthread
operator|->
name|td_priority
operator|&&
name|ts
operator|->
name|ts_runq
operator|==
name|tdq
operator|->
name|tdq_curr
condition|)
name|curthread
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
if|if
condition|(
name|preemptive
operator|&&
name|maybe_preempt
argument_list|(
name|td
argument_list|)
condition|)
return|return;
name|ts
operator|->
name|ts_state
operator|=
name|TSS_ONRUNQ
expr_stmt|;
name|tdq_runq_add
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|tdq_load_add
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_rem
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|CTR5
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_rem: %p(%s) prio %d by %p(%s)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|curthread
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_PREEMPTED
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_ASSIGNED
condition|)
block|{
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_REMOVED
expr_stmt|;
return|return;
block|}
name|KASSERT
argument_list|(
operator|(
name|ts
operator|->
name|ts_state
operator|==
name|TSS_ONRUNQ
operator|)
argument_list|,
operator|(
literal|"sched_rem: thread not on run queue"
operator|)
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_state
operator|=
name|TSS_THREAD
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
name|tdq_runq_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|fixpt_t
name|sched_pctcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|fixpt_t
name|pctcpu
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|pctcpu
operator|=
literal|0
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|ts
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_ticks
condition|)
block|{
name|int
name|rtick
decl_stmt|;
comment|/* 		 * Don't update more frequently than twice a second.  Allowing 		 * this causes the cpu usage to decay away too quickly due to 		 * rounding errors. 		 */
if|if
condition|(
name|ts
operator|->
name|ts_ftick
operator|+
name|SCHED_CPU_TICKS
operator|<
name|ts
operator|->
name|ts_ltick
operator|||
name|ts
operator|->
name|ts_ltick
operator|<
operator|(
name|ticks
operator|-
operator|(
name|hz
operator|/
literal|2
operator|)
operator|)
condition|)
name|sched_pctcpu_update
argument_list|(
name|ts
argument_list|)
expr_stmt|;
comment|/* How many rtick per second ? */
name|rtick
operator|=
name|min
argument_list|(
name|ts
operator|->
name|ts_ticks
operator|/
name|SCHED_CPU_TIME
argument_list|,
name|SCHED_CPU_TICKS
argument_list|)
expr_stmt|;
name|pctcpu
operator|=
operator|(
name|FSCALE
operator|*
operator|(
operator|(
name|FSCALE
operator|*
name|rtick
operator|)
operator|/
name|realstathz
operator|)
operator|)
operator|>>
name|FSHIFT
expr_stmt|;
block|}
name|td
operator|->
name|td_proc
operator|->
name|p_swtime
operator|=
name|ts
operator|->
name|ts_ltick
operator|-
name|ts
operator|->
name|ts_ftick
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|pctcpu
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_bind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_BOUND
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
operator|==
name|cpu
condition|)
return|return;
comment|/* sched_rem without the runq_remove */
name|ts
operator|->
name|ts_state
operator|=
name|TSS_THREAD
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|tdq_notify
argument_list|(
name|ts
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
comment|/* When we return from mi_switch we'll be on the correct cpu. */
name|mi_switch
argument_list|(
name|SW_VOL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|sched_unbind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_BOUND
expr_stmt|;
block|}
end_function

begin_function
name|int
name|sched_is_bound
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
name|td
operator|->
name|td_sched
operator|->
name|ts_flags
operator|&
name|TSF_BOUND
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_relinquish
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
name|sched_prio
argument_list|(
name|td
argument_list|,
name|PRI_MAX_TIMESHARE
argument_list|)
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_VOL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|sched_load
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|int
name|total
decl_stmt|;
name|int
name|i
decl_stmt|;
name|total
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|tdg_maxid
condition|;
name|i
operator|++
control|)
name|total
operator|+=
name|TDQ_GROUP
argument_list|(
name|i
argument_list|)
operator|->
name|tdg_load
expr_stmt|;
return|return
operator|(
name|total
operator|)
return|;
else|#
directive|else
return|return
operator|(
name|TDQ_SELF
argument_list|()
operator|->
name|tdq_sysload
operator|)
return|;
endif|#
directive|endif
block|}
end_function

begin_function
name|int
name|sched_sizeof_proc
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|proc
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_sizeof_thread
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|thread
argument_list|)
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|td_sched
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_tick
parameter_list|(
name|void
parameter_list|)
block|{ }
end_function

begin_define
define|#
directive|define
name|KERN_SWITCH_INCLUDE
value|1
end_define

begin_include
include|#
directive|include
file|"kern/kern_switch.c"
end_include

end_unit

