begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2002-2007, Jeffrey Roberson<jeff@freebsd.org>  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice unmodified, this list of conditions, and the following  *    disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,  * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT  * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,  * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY  * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF  * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  */
end_comment

begin_comment
comment|/*  * This file implements the ULE scheduler.  ULE supports independent CPU  * run queues and fine grain locking.  It has superior interactive  * performance under load even on uni-processor systems.  *  * etymology:  *   ULE is the last three letters in schedule.  It owes its name to a  * generic user created for a scheduling system by Paul Mikesell at  * Isilon Systems and a general lack of creativity on the part of the author.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_hwpmc_hooks.h"
end_include

begin_include
include|#
directive|include
file|"opt_kdtrace.h"
end_include

begin_include
include|#
directive|include
file|"opt_sched.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kdb.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/resource.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysproto.h>
end_include

begin_include
include|#
directive|include
file|<sys/turnstile.h>
end_include

begin_include
include|#
directive|include
file|<sys/umtx.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/cpuset.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|KTRACE
end_ifdef

begin_include
include|#
directive|include
file|<sys/uio.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktrace.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
end_ifdef

begin_include
include|#
directive|include
file|<sys/pmckern.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|KDTRACE_HOOKS
end_ifdef

begin_include
include|#
directive|include
file|<sys/dtrace_bsd.h>
end_include

begin_decl_stmt
name|int
name|dtrace_vtime_active
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|dtrace_vtime_switch_func_t
name|dtrace_vtime_switch_func
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|__i386__
argument_list|)
operator|&&
operator|!
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|&&
operator|!
name|defined
argument_list|(
name|__arm__
argument_list|)
end_if

begin_error
error|#
directive|error
literal|"This architecture is not currently compatible with ULE"
end_error

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|KTR_ULE
value|0
end_define

begin_comment
comment|/*  * Thread scheduler specific section.  All fields are protected  * by the thread lock.  */
end_comment

begin_struct
struct|struct
name|td_sched
block|{
name|TAILQ_ENTRY
argument_list|(
argument|td_sched
argument_list|)
name|ts_procq
expr_stmt|;
comment|/* Run queue. */
name|struct
name|thread
modifier|*
name|ts_thread
decl_stmt|;
comment|/* Active associated thread. */
name|struct
name|runq
modifier|*
name|ts_runq
decl_stmt|;
comment|/* Run-queue we're queued on. */
name|short
name|ts_flags
decl_stmt|;
comment|/* TSF_* flags. */
name|u_char
name|ts_rqindex
decl_stmt|;
comment|/* Run queue index. */
name|u_char
name|ts_cpu
decl_stmt|;
comment|/* CPU that we have affinity for. */
name|int
name|ts_slice
decl_stmt|;
comment|/* Ticks of slice remaining. */
name|u_int
name|ts_slptime
decl_stmt|;
comment|/* Number of ticks we vol. slept */
name|u_int
name|ts_runtime
decl_stmt|;
comment|/* Number of ticks we were running */
comment|/* The following variables are only used for pctcpu calculation */
name|int
name|ts_ltick
decl_stmt|;
comment|/* Last tick that we were running on */
name|int
name|ts_incrtick
decl_stmt|;
comment|/* Last tick that we incremented on */
name|int
name|ts_ftick
decl_stmt|;
comment|/* First tick that we were running on */
name|int
name|ts_ticks
decl_stmt|;
comment|/* Tick count */
ifdef|#
directive|ifdef
name|SMP
name|int
name|ts_rltick
decl_stmt|;
comment|/* Real last tick, for affinity. */
endif|#
directive|endif
block|}
struct|;
end_struct

begin_comment
comment|/* flags kept in ts_flags */
end_comment

begin_define
define|#
directive|define
name|TSF_BOUND
value|0x0001
end_define

begin_comment
comment|/* Thread can not migrate. */
end_comment

begin_define
define|#
directive|define
name|TSF_XFERABLE
value|0x0002
end_define

begin_comment
comment|/* Thread was added as transferable. */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|td_sched
name|td_sched0
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|THREAD_CAN_MIGRATE
parameter_list|(
name|td
parameter_list|)
value|((td)->td_pinned == 0)
end_define

begin_define
define|#
directive|define
name|THREAD_CAN_SCHED
parameter_list|(
name|td
parameter_list|,
name|cpu
parameter_list|)
define|\
value|CPU_ISSET((cpu),&(td)->td_cpuset->cs_mask)
end_define

begin_comment
comment|/*  * Cpu percentage computation macros and defines.  *  * SCHED_TICK_SECS:	Number of seconds to average the cpu usage across.  * SCHED_TICK_TARG:	Number of hz ticks to average the cpu usage across.  * SCHED_TICK_MAX:	Maximum number of ticks before scaling back.  * SCHED_TICK_SHIFT:	Shift factor to avoid rounding away results.  * SCHED_TICK_HZ:	Compute the number of hz ticks for a given ticks count.  * SCHED_TICK_TOTAL:	Gives the amount of time we've been recording ticks.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_TICK_SECS
value|10
end_define

begin_define
define|#
directive|define
name|SCHED_TICK_TARG
value|(hz * SCHED_TICK_SECS)
end_define

begin_define
define|#
directive|define
name|SCHED_TICK_MAX
value|(SCHED_TICK_TARG + hz)
end_define

begin_define
define|#
directive|define
name|SCHED_TICK_SHIFT
value|10
end_define

begin_define
define|#
directive|define
name|SCHED_TICK_HZ
parameter_list|(
name|ts
parameter_list|)
value|((ts)->ts_ticks>> SCHED_TICK_SHIFT)
end_define

begin_define
define|#
directive|define
name|SCHED_TICK_TOTAL
parameter_list|(
name|ts
parameter_list|)
value|(max((ts)->ts_ltick - (ts)->ts_ftick, hz))
end_define

begin_comment
comment|/*  * These macros determine priorities for non-interactive threads.  They are  * assigned a priority based on their recent cpu utilization as expressed  * by the ratio of ticks to the tick total.  NHALF priorities at the start  * and end of the MIN to MAX timeshare range are only reachable with negative  * or positive nice respectively.  *  * PRI_RANGE:	Priority range for utilization dependent priorities.  * PRI_NRESV:	Number of nice values.  * PRI_TICKS:	Compute a priority in PRI_RANGE from the ticks count and total.  * PRI_NICE:	Determines the part of the priority inherited from nice.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_PRI_NRESV
value|(PRIO_MAX - PRIO_MIN)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_NHALF
value|(SCHED_PRI_NRESV / 2)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_MIN
value|(PRI_MIN_TIMESHARE + SCHED_PRI_NHALF)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_MAX
value|(PRI_MAX_TIMESHARE - SCHED_PRI_NHALF)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_RANGE
value|(SCHED_PRI_MAX - SCHED_PRI_MIN)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_TICKS
parameter_list|(
name|ts
parameter_list|)
define|\
value|(SCHED_TICK_HZ((ts)) /						\     (roundup(SCHED_TICK_TOTAL((ts)), SCHED_PRI_RANGE) / SCHED_PRI_RANGE))
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_NICE
parameter_list|(
name|nice
parameter_list|)
value|(nice)
end_define

begin_comment
comment|/*  * These determine the interactivity of a process.  Interactivity differs from  * cpu utilization in that it expresses the voluntary time slept vs time ran  * while cpu utilization includes all time not running.  This more accurately  * models the intent of the thread.  *  * SLP_RUN_MAX:	Maximum amount of sleep time + run time we'll accumulate  *		before throttling back.  * SLP_RUN_FORK:	Maximum slp+run time to inherit at fork time.  * INTERACT_MAX:	Maximum interactivity value.  Smaller is better.  * INTERACT_THRESH:	Threshhold for placement on the current runq.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_SLP_RUN_MAX
value|((hz * 5)<< SCHED_TICK_SHIFT)
end_define

begin_define
define|#
directive|define
name|SCHED_SLP_RUN_FORK
value|((hz / 2)<< SCHED_TICK_SHIFT)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_MAX
value|(100)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_HALF
value|(SCHED_INTERACT_MAX / 2)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_THRESH
value|(30)
end_define

begin_comment
comment|/*  * tickincr:		Converts a stathz tick into a hz domain scaled by  *			the shift factor.  Without the shift the error rate  *			due to rounding would be unacceptably high.  * realstathz:		stathz is sometimes 0 and run off of hz.  * sched_slice:		Runtime of each thread before rescheduling.  * preempt_thresh:	Priority threshold for preemption and remote IPIs.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|sched_interact
init|=
name|SCHED_INTERACT_THRESH
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|realstathz
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|tickincr
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|sched_slice
decl_stmt|;
end_decl_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|PREEMPTION
end_ifdef

begin_ifdef
ifdef|#
directive|ifdef
name|FULL_PREEMPTION
end_ifdef

begin_decl_stmt
specifier|static
name|int
name|preempt_thresh
init|=
name|PRI_MAX_IDLE
decl_stmt|;
end_decl_stmt

begin_else
else|#
directive|else
end_else

begin_decl_stmt
specifier|static
name|int
name|preempt_thresh
init|=
name|PRI_MIN_KERN
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_else
else|#
directive|else
end_else

begin_decl_stmt
specifier|static
name|int
name|preempt_thresh
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * tdq - per processor runqs and statistics.  All fields are protected by the  * tdq_lock.  The load and lowpri may be accessed without to avoid excess  * locking in sched_pickcpu();  */
end_comment

begin_struct
struct|struct
name|tdq
block|{
name|struct
name|mtx
modifier|*
name|tdq_lock
decl_stmt|;
comment|/* Pointer to group lock. */
name|struct
name|runq
name|tdq_realtime
decl_stmt|;
comment|/* real-time run queue. */
name|struct
name|runq
name|tdq_timeshare
decl_stmt|;
comment|/* timeshare run queue. */
name|struct
name|runq
name|tdq_idle
decl_stmt|;
comment|/* Queue of IDLE threads. */
name|int
name|tdq_load
decl_stmt|;
comment|/* Aggregate load. */
name|u_char
name|tdq_idx
decl_stmt|;
comment|/* Current insert index. */
name|u_char
name|tdq_ridx
decl_stmt|;
comment|/* Current removal index. */
ifdef|#
directive|ifdef
name|SMP
name|u_char
name|tdq_lowpri
decl_stmt|;
comment|/* Lowest priority thread. */
name|int
name|tdq_transferable
decl_stmt|;
comment|/* Transferable thread count. */
name|LIST_ENTRY
argument_list|(
argument|tdq
argument_list|)
name|tdq_siblings
expr_stmt|;
comment|/* Next in tdq group. */
name|struct
name|tdq_group
modifier|*
name|tdq_group
decl_stmt|;
comment|/* Our processor group. */
else|#
directive|else
name|int
name|tdq_sysload
decl_stmt|;
comment|/* For loadavg, !ITHD load. */
endif|#
directive|endif
block|}
name|__aligned
argument_list|(
literal|64
argument_list|)
struct|;
end_struct

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * tdq groups are groups of processors which can cheaply share threads.  When  * one processor in the group goes idle it will check the runqs of the other  * processors in its group prior to halting and waiting for an interrupt.  * These groups are suitable for SMT (Symetric Multi-Threading) and not NUMA.  * In a numa environment we'd want an idle bitmap per group and a two tiered  * load balancer.  */
end_comment

begin_struct
struct|struct
name|tdq_group
block|{
name|struct
name|mtx
name|tdg_lock
decl_stmt|;
comment|/* Protects all fields below. */
name|int
name|tdg_cpus
decl_stmt|;
comment|/* Count of CPUs in this tdq group. */
name|cpumask_t
name|tdg_cpumask
decl_stmt|;
comment|/* Mask of cpus in this group. */
name|cpumask_t
name|tdg_idlemask
decl_stmt|;
comment|/* Idle cpus in this group. */
name|cpumask_t
name|tdg_mask
decl_stmt|;
comment|/* Bit mask for first cpu. */
name|int
name|tdg_load
decl_stmt|;
comment|/* Total load of this group. */
name|int
name|tdg_transferable
decl_stmt|;
comment|/* Transferable load of this group. */
name|LIST_HEAD
argument_list|(
argument_list|,
argument|tdq
argument_list|)
name|tdg_members
expr_stmt|;
comment|/* Linked list of all members. */
name|char
name|tdg_name
index|[
literal|16
index|]
decl_stmt|;
comment|/* lock name. */
block|}
name|__aligned
argument_list|(
literal|64
argument_list|)
struct|;
end_struct

begin_define
define|#
directive|define
name|SCHED_AFFINITY_DEFAULT
value|(max(1, hz / 300))
end_define

begin_define
define|#
directive|define
name|SCHED_AFFINITY
parameter_list|(
name|ts
parameter_list|)
value|((ts)->ts_rltick> ticks - affinity)
end_define

begin_comment
comment|/*  * Run-time tunables.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|rebalance
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|balance_interval
init|=
literal|128
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Default set in sched_initticks(). */
end_comment

begin_decl_stmt
specifier|static
name|int
name|pick_pri
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|affinity
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|tryself
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|steal_htt
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|steal_idle
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|steal_thresh
init|=
literal|2
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|topology
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * One thread queue per processor.  */
end_comment

begin_decl_stmt
specifier|static
specifier|volatile
name|cpumask_t
name|tdq_idle
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|tdg_maxid
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|tdq
name|tdq_cpu
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|tdq_group
name|tdq_groups
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|tdq
modifier|*
name|balance_tdq
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|balance_group_ticks
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|balance_ticks
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|TDQ_SELF
parameter_list|()
value|(&tdq_cpu[PCPU_GET(cpuid)])
end_define

begin_define
define|#
directive|define
name|TDQ_CPU
parameter_list|(
name|x
parameter_list|)
value|(&tdq_cpu[(x)])
end_define

begin_define
define|#
directive|define
name|TDQ_ID
parameter_list|(
name|x
parameter_list|)
value|((int)((x) - tdq_cpu))
end_define

begin_define
define|#
directive|define
name|TDQ_GROUP
parameter_list|(
name|x
parameter_list|)
value|(&tdq_groups[(x)])
end_define

begin_define
define|#
directive|define
name|TDG_ID
parameter_list|(
name|x
parameter_list|)
value|((int)((x) - tdq_groups))
end_define

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* !SMP */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|tdq
name|tdq_cpu
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|tdq_lock
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|TDQ_ID
parameter_list|(
name|x
parameter_list|)
value|(0)
end_define

begin_define
define|#
directive|define
name|TDQ_SELF
parameter_list|()
value|(&tdq_cpu)
end_define

begin_define
define|#
directive|define
name|TDQ_CPU
parameter_list|(
name|x
parameter_list|)
value|(&tdq_cpu)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|TDQ_LOCK_ASSERT
parameter_list|(
name|t
parameter_list|,
name|type
parameter_list|)
value|mtx_assert(TDQ_LOCKPTR((t)), (type))
end_define

begin_define
define|#
directive|define
name|TDQ_LOCK
parameter_list|(
name|t
parameter_list|)
value|mtx_lock_spin(TDQ_LOCKPTR((t)))
end_define

begin_define
define|#
directive|define
name|TDQ_LOCK_FLAGS
parameter_list|(
name|t
parameter_list|,
name|f
parameter_list|)
value|mtx_lock_spin_flags(TDQ_LOCKPTR((t)), (f))
end_define

begin_define
define|#
directive|define
name|TDQ_UNLOCK
parameter_list|(
name|t
parameter_list|)
value|mtx_unlock_spin(TDQ_LOCKPTR((t)))
end_define

begin_define
define|#
directive|define
name|TDQ_LOCKPTR
parameter_list|(
name|t
parameter_list|)
value|((t)->tdq_lock)
end_define

begin_function_decl
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_thread_priority
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|,
name|u_char
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sched_interact_score
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_interact_update
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_interact_fork
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_pctcpu_update
parameter_list|(
name|struct
name|td_sched
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/* Operations on per processor queues */
end_comment

begin_function_decl
specifier|static
name|struct
name|td_sched
modifier|*
name|tdq_choose
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_setup
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_load_add
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|td_sched
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_load_rem
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|td_sched
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|tdq_runq_add
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|td_sched
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|tdq_runq_rem
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|td_sched
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|tdq_print
parameter_list|(
name|int
name|cpu
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|runq_print
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_add
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function_decl
specifier|static
name|void
name|tdq_move
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|tdq_idled
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tdq_notify
parameter_list|(
name|struct
name|td_sched
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|td_sched
modifier|*
name|tdq_steal
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|td_sched
modifier|*
name|runq_steal
parameter_list|(
name|struct
name|runq
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sched_pickcpu
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance_groups
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance_group
parameter_list|(
name|struct
name|tdq_group
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance_pair
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|tdq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
specifier|inline
name|struct
name|tdq
modifier|*
name|sched_setcpu
parameter_list|(
name|struct
name|td_sched
modifier|*
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
specifier|inline
name|void
name|thread_unblock_switch
parameter_list|(
name|struct
name|thread
modifier|*
parameter_list|,
name|struct
name|mtx
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|mtx
modifier|*
name|sched_switch_migrate
parameter_list|(
name|struct
name|tdq
modifier|*
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_function_decl
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_expr_stmt
name|SYSINIT
argument_list|(
name|sched_setup
argument_list|,
name|SI_SUB_RUN_QUEUE
argument_list|,
name|SI_ORDER_FIRST
argument_list|,
name|sched_setup
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function_decl
specifier|static
name|void
name|sched_initticks
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_expr_stmt
name|SYSINIT
argument_list|(
name|sched_initticks
argument_list|,
name|SI_SUB_CLOCKS
argument_list|,
name|SI_ORDER_THIRD
argument_list|,
name|sched_initticks
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Print the threads waiting on a run-queue.  */
end_comment

begin_function
specifier|static
name|void
name|runq_print
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|)
block|{
name|struct
name|rqhead
modifier|*
name|rqh
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|int
name|j
decl_stmt|;
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|RQB_LEN
condition|;
name|i
operator|++
control|)
block|{
name|printf
argument_list|(
literal|"\t\trunq bits %d 0x%zx\n"
argument_list|,
name|i
argument_list|,
name|rq
operator|->
name|rq_status
operator|.
name|rqb_bits
index|[
name|i
index|]
argument_list|)
expr_stmt|;
for|for
control|(
name|j
operator|=
literal|0
init|;
name|j
operator|<
name|RQB_BPW
condition|;
name|j
operator|++
control|)
if|if
condition|(
name|rq
operator|->
name|rq_status
operator|.
name|rqb_bits
index|[
name|i
index|]
operator|&
operator|(
literal|1ul
operator|<<
name|j
operator|)
condition|)
block|{
name|pri
operator|=
name|j
operator|+
operator|(
name|i
operator|<<
name|RQB_L2BPW
operator|)
expr_stmt|;
name|rqh
operator|=
operator|&
name|rq
operator|->
name|rq_queues
index|[
name|pri
index|]
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|ts
argument_list|,
argument|rqh
argument_list|,
argument|ts_procq
argument_list|)
block|{
name|printf
argument_list|(
literal|"\t\t\ttd %p(%s) priority %d rqindex %d pri %d\n"
argument_list|,
name|ts
operator|->
name|ts_thread
argument_list|,
name|ts
operator|->
name|ts_thread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
argument_list|,
name|ts
operator|->
name|ts_rqindex
argument_list|,
name|pri
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * Print the status of a per-cpu thread queue.  Should be a ddb show cmd.  */
end_comment

begin_function
name|void
name|tdq_print
parameter_list|(
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"tdq %d:\n"
argument_list|,
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tlockptr         %p\n"
argument_list|,
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tload:           %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\ttimeshare idx:  %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_idx
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\ttimeshare ridx: %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_ridx
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\trealtime runq:\n"
argument_list|)
expr_stmt|;
name|runq_print
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_realtime
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\ttimeshare runq:\n"
argument_list|)
expr_stmt|;
name|runq_print
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tidle runq:\n"
argument_list|)
expr_stmt|;
name|runq_print
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|printf
argument_list|(
literal|"\tload transferable: %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_transferable
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tlowest priority:   %d\n"
argument_list|,
name|tdq
operator|->
name|tdq_lowpri
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tgroup:             %d\n"
argument_list|,
name|TDG_ID
argument_list|(
name|tdq
operator|->
name|tdq_group
argument_list|)
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tLock name:         %s\n"
argument_list|,
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_name
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_define
define|#
directive|define
name|TS_RQ_PPQ
value|(((PRI_MAX_TIMESHARE - PRI_MIN_TIMESHARE) + 1) / RQ_NQS)
end_define

begin_comment
comment|/*  * Add a thread to the actual run-queue.  Keeps transferable counts up to  * date with what is actually on the run-queue.  Selects the correct  * queue position for timeshare threads.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|tdq_runq_add
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|)
condition|)
block|{
name|tdq
operator|->
name|tdq_transferable
operator|++
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_transferable
operator|++
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_XFERABLE
expr_stmt|;
block|}
endif|#
directive|endif
if|if
condition|(
name|ts
operator|->
name|ts_runq
operator|==
operator|&
name|tdq
operator|->
name|tdq_timeshare
condition|)
block|{
name|u_char
name|pri
decl_stmt|;
name|pri
operator|=
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
expr_stmt|;
name|KASSERT
argument_list|(
name|pri
operator|<=
name|PRI_MAX_TIMESHARE
operator|&&
name|pri
operator|>=
name|PRI_MIN_TIMESHARE
argument_list|,
operator|(
literal|"Invalid priority %d on timeshare runq"
operator|,
name|pri
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * This queue contains only priorities between MIN and MAX 		 * realtime.  Use the whole queue to represent these values. 		 */
if|if
condition|(
operator|(
name|flags
operator|&
operator|(
name|SRQ_BORROWING
operator||
name|SRQ_PREEMPTED
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|pri
operator|=
operator|(
name|pri
operator|-
name|PRI_MIN_TIMESHARE
operator|)
operator|/
name|TS_RQ_PPQ
expr_stmt|;
name|pri
operator|=
operator|(
name|pri
operator|+
name|tdq
operator|->
name|tdq_idx
operator|)
operator|%
name|RQ_NQS
expr_stmt|;
comment|/* 			 * This effectively shortens the queue by one so we 			 * can have a one slot difference between idx and 			 * ridx while we wait for threads to drain. 			 */
if|if
condition|(
name|tdq
operator|->
name|tdq_ridx
operator|!=
name|tdq
operator|->
name|tdq_idx
operator|&&
name|pri
operator|==
name|tdq
operator|->
name|tdq_ridx
condition|)
name|pri
operator|=
call|(
name|unsigned
name|char
call|)
argument_list|(
name|pri
operator|-
literal|1
argument_list|)
operator|%
name|RQ_NQS
expr_stmt|;
block|}
else|else
name|pri
operator|=
name|tdq
operator|->
name|tdq_ridx
expr_stmt|;
name|runq_add_pri
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|ts
argument_list|,
name|pri
argument_list|,
name|flags
argument_list|)
expr_stmt|;
block|}
else|else
name|runq_add
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|ts
argument_list|,
name|flags
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*   * Remove a thread from a run-queue.  This typically happens when a thread  * is selected to run.  Running threads are not on the queue and the  * transferable count does not reflect them.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|tdq_runq_rem
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|)
block|{
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|ts
operator|->
name|ts_runq
operator|!=
name|NULL
argument_list|,
operator|(
literal|"tdq_runq_remove: thread %p null ts_runq"
operator|,
name|ts
operator|->
name|ts_thread
operator|)
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_XFERABLE
condition|)
block|{
name|tdq
operator|->
name|tdq_transferable
operator|--
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_transferable
operator|--
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_XFERABLE
expr_stmt|;
block|}
endif|#
directive|endif
if|if
condition|(
name|ts
operator|->
name|ts_runq
operator|==
operator|&
name|tdq
operator|->
name|tdq_timeshare
condition|)
block|{
if|if
condition|(
name|tdq
operator|->
name|tdq_idx
operator|!=
name|tdq
operator|->
name|tdq_ridx
condition|)
name|runq_remove_idx
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|ts
argument_list|,
operator|&
name|tdq
operator|->
name|tdq_ridx
argument_list|)
expr_stmt|;
else|else
name|runq_remove_idx
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|ts
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
comment|/* 		 * For timeshare threads we update the priority here so 		 * the priority reflects the time we've been sleeping. 		 */
name|ts
operator|->
name|ts_ltick
operator|=
name|ticks
expr_stmt|;
name|sched_pctcpu_update
argument_list|(
name|ts
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|)
expr_stmt|;
block|}
else|else
name|runq_remove
argument_list|(
name|ts
operator|->
name|ts_runq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Load is maintained for all threads RUNNING and ON_RUNQ.  Add the load  * for this thread to the referenced thread queue.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_load_add
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|)
block|{
name|int
name|class
decl_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|class
operator|=
name|PRI_BASE
argument_list|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_pri_class
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_load
operator|++
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"cpu %d load: %d"
argument_list|,
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
if|if
condition|(
name|class
operator|!=
name|PRI_ITHD
operator|&&
operator|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
ifdef|#
directive|ifdef
name|SMP
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_load
operator|++
expr_stmt|;
else|#
directive|else
name|tdq
operator|->
name|tdq_sysload
operator|++
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  * Remove the load from a thread that is transitioning to a sleep state or  * exiting.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_load_rem
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|)
block|{
name|int
name|class
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|class
operator|=
name|PRI_BASE
argument_list|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_pri_class
argument_list|)
expr_stmt|;
if|if
condition|(
name|class
operator|!=
name|PRI_ITHD
operator|&&
operator|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
ifdef|#
directive|ifdef
name|SMP
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_load
operator|--
expr_stmt|;
else|#
directive|else
name|tdq
operator|->
name|tdq_sysload
operator|--
expr_stmt|;
endif|#
directive|endif
name|KASSERT
argument_list|(
name|tdq
operator|->
name|tdq_load
operator|!=
literal|0
argument_list|,
operator|(
literal|"tdq_load_rem: Removing with 0 load on queue %d"
operator|,
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
operator|)
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_load
operator|--
expr_stmt|;
name|CTR1
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"load: %d"
argument_list|,
name|tdq
operator|->
name|tdq_load
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_runq
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * sched_balance is a simple CPU load balancing algorithm.  It operates by  * finding the least loaded and most loaded cpu and equalizing their load  * by migrating some processes.  *  * Dealing only with two CPUs at a time has two advantages.  Firstly, most  * installations will only have 2 cpus.  Secondly, load balancing too much at  * once can have an unpleasant effect on the system.  The scheduler rarely has  * enough information to make perfect decisions.  So this algorithm chooses  * simplicity and more gradual effects on load in larger systems.  *  */
end_comment

begin_function
specifier|static
name|void
name|sched_balance
parameter_list|()
block|{
name|struct
name|tdq_group
modifier|*
name|high
decl_stmt|;
name|struct
name|tdq_group
modifier|*
name|low
decl_stmt|;
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|cnt
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * Select a random time between .5 * balance_interval and 	 * 1.5 * balance_interval. 	 */
name|balance_ticks
operator|=
name|max
argument_list|(
name|balance_interval
operator|/
literal|2
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|balance_ticks
operator|+=
name|random
argument_list|()
operator|%
name|balance_interval
expr_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
operator|||
name|rebalance
operator|==
literal|0
condition|)
return|return;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|low
operator|=
name|high
operator|=
name|NULL
expr_stmt|;
name|i
operator|=
name|random
argument_list|()
operator|%
operator|(
name|tdg_maxid
operator|+
literal|1
operator|)
expr_stmt|;
for|for
control|(
name|cnt
operator|=
literal|0
init|;
name|cnt
operator|<=
name|tdg_maxid
condition|;
name|cnt
operator|++
control|)
block|{
name|tdg
operator|=
name|TDQ_GROUP
argument_list|(
name|i
argument_list|)
expr_stmt|;
comment|/* 		 * Find the CPU with the highest load that has some 		 * threads to transfer. 		 */
if|if
condition|(
operator|(
name|high
operator|==
name|NULL
operator|||
name|tdg
operator|->
name|tdg_load
operator|>
name|high
operator|->
name|tdg_load
operator|)
operator|&&
name|tdg
operator|->
name|tdg_transferable
condition|)
name|high
operator|=
name|tdg
expr_stmt|;
if|if
condition|(
name|low
operator|==
name|NULL
operator|||
name|tdg
operator|->
name|tdg_load
operator|<
name|low
operator|->
name|tdg_load
condition|)
name|low
operator|=
name|tdg
expr_stmt|;
if|if
condition|(
operator|++
name|i
operator|>
name|tdg_maxid
condition|)
name|i
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|low
operator|!=
name|NULL
operator|&&
name|high
operator|!=
name|NULL
operator|&&
name|high
operator|!=
name|low
condition|)
name|sched_balance_pair
argument_list|(
name|LIST_FIRST
argument_list|(
operator|&
name|high
operator|->
name|tdg_members
argument_list|)
argument_list|,
name|LIST_FIRST
argument_list|(
operator|&
name|low
operator|->
name|tdg_members
argument_list|)
argument_list|)
expr_stmt|;
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Balance load between CPUs in a group.  Will only migrate within the group.  */
end_comment

begin_function
specifier|static
name|void
name|sched_balance_groups
parameter_list|()
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * Select a random time between .5 * balance_interval and 	 * 1.5 * balance_interval. 	 */
name|balance_group_ticks
operator|=
name|max
argument_list|(
name|balance_interval
operator|/
literal|2
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|balance_group_ticks
operator|+=
name|random
argument_list|()
operator|%
name|balance_interval
expr_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
operator|||
name|rebalance
operator|==
literal|0
condition|)
return|return;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|tdg_maxid
condition|;
name|i
operator|++
control|)
name|sched_balance_group
argument_list|(
name|TDQ_GROUP
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Finds the greatest imbalance between two tdqs in a group.  */
end_comment

begin_function
specifier|static
name|void
name|sched_balance_group
parameter_list|(
name|struct
name|tdq_group
modifier|*
name|tdg
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|tdq
modifier|*
name|high
decl_stmt|;
name|struct
name|tdq
modifier|*
name|low
decl_stmt|;
name|int
name|load
decl_stmt|;
if|if
condition|(
name|tdg
operator|->
name|tdg_transferable
operator|==
literal|0
condition|)
return|return;
name|low
operator|=
name|NULL
expr_stmt|;
name|high
operator|=
name|NULL
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|tdq
argument_list|,
argument|&tdg->tdg_members
argument_list|,
argument|tdq_siblings
argument_list|)
block|{
name|load
operator|=
name|tdq
operator|->
name|tdq_load
expr_stmt|;
if|if
condition|(
name|high
operator|==
name|NULL
operator|||
name|load
operator|>
name|high
operator|->
name|tdq_load
condition|)
name|high
operator|=
name|tdq
expr_stmt|;
if|if
condition|(
name|low
operator|==
name|NULL
operator|||
name|load
operator|<
name|low
operator|->
name|tdq_load
condition|)
name|low
operator|=
name|tdq
expr_stmt|;
block|}
if|if
condition|(
name|high
operator|!=
name|NULL
operator|&&
name|low
operator|!=
name|NULL
operator|&&
name|high
operator|!=
name|low
condition|)
name|sched_balance_pair
argument_list|(
name|high
argument_list|,
name|low
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Lock two thread queues using their address to maintain lock order.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_lock_pair
parameter_list|(
name|struct
name|tdq
modifier|*
name|one
parameter_list|,
name|struct
name|tdq
modifier|*
name|two
parameter_list|)
block|{
if|if
condition|(
name|one
operator|<
name|two
condition|)
block|{
name|TDQ_LOCK
argument_list|(
name|one
argument_list|)
expr_stmt|;
name|TDQ_LOCK_FLAGS
argument_list|(
name|two
argument_list|,
name|MTX_DUPOK
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|TDQ_LOCK
argument_list|(
name|two
argument_list|)
expr_stmt|;
name|TDQ_LOCK_FLAGS
argument_list|(
name|one
argument_list|,
name|MTX_DUPOK
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Unlock two thread queues.  Order is not important here.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_unlock_pair
parameter_list|(
name|struct
name|tdq
modifier|*
name|one
parameter_list|,
name|struct
name|tdq
modifier|*
name|two
parameter_list|)
block|{
name|TDQ_UNLOCK
argument_list|(
name|one
argument_list|)
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|two
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Transfer load between two imbalanced thread queues.  */
end_comment

begin_function
specifier|static
name|void
name|sched_balance_pair
parameter_list|(
name|struct
name|tdq
modifier|*
name|high
parameter_list|,
name|struct
name|tdq
modifier|*
name|low
parameter_list|)
block|{
name|int
name|transferable
decl_stmt|;
name|int
name|high_load
decl_stmt|;
name|int
name|low_load
decl_stmt|;
name|int
name|move
decl_stmt|;
name|int
name|diff
decl_stmt|;
name|int
name|i
decl_stmt|;
name|tdq_lock_pair
argument_list|(
name|high
argument_list|,
name|low
argument_list|)
expr_stmt|;
comment|/* 	 * If we're transfering within a group we have to use this specific 	 * tdq's transferable count, otherwise we can steal from other members 	 * of the group. 	 */
if|if
condition|(
name|high
operator|->
name|tdq_group
operator|==
name|low
operator|->
name|tdq_group
condition|)
block|{
name|transferable
operator|=
name|high
operator|->
name|tdq_transferable
expr_stmt|;
name|high_load
operator|=
name|high
operator|->
name|tdq_load
expr_stmt|;
name|low_load
operator|=
name|low
operator|->
name|tdq_load
expr_stmt|;
block|}
else|else
block|{
name|transferable
operator|=
name|high
operator|->
name|tdq_group
operator|->
name|tdg_transferable
expr_stmt|;
name|high_load
operator|=
name|high
operator|->
name|tdq_group
operator|->
name|tdg_load
expr_stmt|;
name|low_load
operator|=
name|low
operator|->
name|tdq_group
operator|->
name|tdg_load
expr_stmt|;
block|}
comment|/* 	 * Determine what the imbalance is and then adjust that to how many 	 * threads we actually have to give up (transferable). 	 */
if|if
condition|(
name|transferable
operator|!=
literal|0
condition|)
block|{
name|diff
operator|=
name|high_load
operator|-
name|low_load
expr_stmt|;
name|move
operator|=
name|diff
operator|/
literal|2
expr_stmt|;
if|if
condition|(
name|diff
operator|&
literal|0x1
condition|)
name|move
operator|++
expr_stmt|;
name|move
operator|=
name|min
argument_list|(
name|move
argument_list|,
name|transferable
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|move
condition|;
name|i
operator|++
control|)
name|tdq_move
argument_list|(
name|high
argument_list|,
name|low
argument_list|)
expr_stmt|;
comment|/* 		 * IPI the target cpu to force it to reschedule with the new 		 * workload. 		 */
name|ipi_selected
argument_list|(
literal|1
operator|<<
name|TDQ_ID
argument_list|(
name|low
argument_list|)
argument_list|,
name|IPI_PREEMPT
argument_list|)
expr_stmt|;
block|}
name|tdq_unlock_pair
argument_list|(
name|high
argument_list|,
name|low
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_comment
comment|/*  * Move a thread from one thread queue to another.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_move
parameter_list|(
name|struct
name|tdq
modifier|*
name|from
parameter_list|,
name|struct
name|tdq
modifier|*
name|to
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|from
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|to
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|from
expr_stmt|;
name|cpu
operator|=
name|TDQ_ID
argument_list|(
name|to
argument_list|)
expr_stmt|;
name|ts
operator|=
name|tdq_steal
argument_list|(
name|tdq
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|==
name|NULL
condition|)
block|{
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|tdg
operator|=
name|tdq
operator|->
name|tdq_group
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|tdq
argument_list|,
argument|&tdg->tdg_members
argument_list|,
argument|tdq_siblings
argument_list|)
block|{
if|if
condition|(
name|tdq
operator|==
name|from
operator|||
name|tdq
operator|->
name|tdq_transferable
operator|==
literal|0
condition|)
continue|continue;
name|ts
operator|=
name|tdq_steal
argument_list|(
name|tdq
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|ts
operator|==
name|NULL
condition|)
return|return;
block|}
if|if
condition|(
name|tdq
operator|==
name|to
condition|)
return|return;
name|td
operator|=
name|ts
operator|->
name|ts_thread
expr_stmt|;
comment|/* 	 * Although the run queue is locked the thread may be blocked.  Lock 	 * it to clear this and acquire the run-queue lock. 	 */
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
comment|/* Drop recursive lock on from acquired via thread_lock(). */
name|TDQ_UNLOCK
argument_list|(
name|from
argument_list|)
expr_stmt|;
name|sched_rem
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_cpu
operator|=
name|cpu
expr_stmt|;
name|td
operator|->
name|td_lock
operator|=
name|TDQ_LOCKPTR
argument_list|(
name|to
argument_list|)
expr_stmt|;
name|tdq_add
argument_list|(
name|to
argument_list|,
name|td
argument_list|,
name|SRQ_YIELDING
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This tdq has idled.  Try to steal a thread from another cpu and switch  * to it.  */
end_comment

begin_function
specifier|static
name|int
name|tdq_idled
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|struct
name|tdq
modifier|*
name|steal
decl_stmt|;
name|int
name|highload
decl_stmt|;
name|int
name|highcpu
decl_stmt|;
name|int
name|cpu
decl_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
operator|||
name|steal_idle
operator|==
literal|0
condition|)
return|return
operator|(
literal|1
operator|)
return|;
comment|/* We don't want to be preempted while we're iterating over tdqs */
name|spinlock_enter
argument_list|()
expr_stmt|;
name|tdg
operator|=
name|tdq
operator|->
name|tdq_group
expr_stmt|;
comment|/* 	 * If we're in a cpu group, try and steal threads from another cpu in 	 * the group before idling.  In a HTT group all cpus share the same 	 * run-queue lock, however, we still need a recursive lock to 	 * call tdq_move(). 	 */
if|if
condition|(
name|steal_htt
operator|&&
name|tdg
operator|->
name|tdg_cpus
operator|>
literal|1
operator|&&
name|tdg
operator|->
name|tdg_transferable
condition|)
block|{
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|steal
argument_list|,
argument|&tdg->tdg_members
argument_list|,
argument|tdq_siblings
argument_list|)
block|{
if|if
condition|(
name|steal
operator|==
name|tdq
operator|||
name|steal
operator|->
name|tdq_transferable
operator|==
literal|0
condition|)
continue|continue;
name|TDQ_LOCK
argument_list|(
name|steal
argument_list|)
expr_stmt|;
goto|goto
name|steal
goto|;
block|}
name|TDQ_UNLOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Find the least loaded CPU with a transferable thread and attempt 	 * to steal it.  We make a lockless pass and then verify that the 	 * thread is still available after locking. 	 */
for|for
control|(
init|;
condition|;
control|)
block|{
name|highcpu
operator|=
literal|0
expr_stmt|;
name|highload
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|cpu
operator|=
literal|0
init|;
name|cpu
operator|<=
name|mp_maxid
condition|;
name|cpu
operator|++
control|)
block|{
if|if
condition|(
name|CPU_ABSENT
argument_list|(
name|cpu
argument_list|)
condition|)
continue|continue;
name|steal
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|steal
operator|->
name|tdq_transferable
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|steal
operator|->
name|tdq_load
operator|<
name|highload
condition|)
continue|continue;
name|highload
operator|=
name|steal
operator|->
name|tdq_load
expr_stmt|;
name|highcpu
operator|=
name|cpu
expr_stmt|;
block|}
if|if
condition|(
name|highload
operator|<
name|steal_thresh
condition|)
break|break;
name|steal
operator|=
name|TDQ_CPU
argument_list|(
name|highcpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|steal
operator|==
name|tdq
condition|)
break|break;
name|tdq_lock_pair
argument_list|(
name|tdq
argument_list|,
name|steal
argument_list|)
expr_stmt|;
if|if
condition|(
name|steal
operator|->
name|tdq_load
operator|>=
name|steal_thresh
operator|&&
name|steal
operator|->
name|tdq_transferable
condition|)
goto|goto
name|steal
goto|;
name|tdq_unlock_pair
argument_list|(
name|tdq
argument_list|,
name|steal
argument_list|)
expr_stmt|;
block|}
name|spinlock_exit
argument_list|()
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
name|steal
label|:
name|spinlock_exit
argument_list|()
expr_stmt|;
name|tdq_move
argument_list|(
name|steal
argument_list|,
name|tdq
argument_list|)
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|steal
argument_list|)
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_VOL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|curthread
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Notify a remote cpu of new work.  Sends an IPI if criteria are met.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_notify
parameter_list|(
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|ctd
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pcpu
decl_stmt|;
name|int
name|cpri
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|cpu
operator|=
name|ts
operator|->
name|ts_cpu
expr_stmt|;
name|pri
operator|=
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
expr_stmt|;
name|pcpu
operator|=
name|pcpu_find
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|ctd
operator|=
name|pcpu
operator|->
name|pc_curthread
expr_stmt|;
name|cpri
operator|=
name|ctd
operator|->
name|td_priority
expr_stmt|;
comment|/* 	 * If our priority is not better than the current priority there is 	 * nothing to do. 	 */
if|if
condition|(
name|pri
operator|>
name|cpri
condition|)
return|return;
comment|/* 	 * Always IPI idle. 	 */
if|if
condition|(
name|cpri
operator|>
name|PRI_MIN_IDLE
condition|)
goto|goto
name|sendipi
goto|;
comment|/* 	 * If we're realtime or better and there is timeshare or worse running 	 * send an IPI. 	 */
if|if
condition|(
name|pri
operator|<
name|PRI_MAX_REALTIME
operator|&&
name|cpri
operator|>
name|PRI_MAX_REALTIME
condition|)
goto|goto
name|sendipi
goto|;
comment|/* 	 * Otherwise only IPI if we exceed the threshold. 	 */
if|if
condition|(
name|pri
operator|>
name|preempt_thresh
condition|)
return|return;
name|sendipi
label|:
name|ipi_selected
argument_list|(
literal|1
operator|<<
name|cpu
argument_list|,
name|IPI_PREEMPT
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Steals load from a timeshare queue.  Honors the rotating queue head  * index.  */
end_comment

begin_function
specifier|static
name|struct
name|td_sched
modifier|*
name|runq_steal_from
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|,
name|int
name|cpu
parameter_list|,
name|u_char
name|start
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|rqbits
modifier|*
name|rqb
decl_stmt|;
name|struct
name|rqhead
modifier|*
name|rqh
decl_stmt|;
name|int
name|first
decl_stmt|;
name|int
name|bit
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|int
name|i
decl_stmt|;
name|rqb
operator|=
operator|&
name|rq
operator|->
name|rq_status
expr_stmt|;
name|bit
operator|=
name|start
operator|&
operator|(
name|RQB_BPW
operator|-
literal|1
operator|)
expr_stmt|;
name|pri
operator|=
literal|0
expr_stmt|;
name|first
operator|=
literal|0
expr_stmt|;
name|again
label|:
for|for
control|(
name|i
operator|=
name|RQB_WORD
argument_list|(
name|start
argument_list|)
init|;
name|i
operator|<
name|RQB_LEN
condition|;
name|bit
operator|=
literal|0
operator|,
name|i
operator|++
control|)
block|{
if|if
condition|(
name|rqb
operator|->
name|rqb_bits
index|[
name|i
index|]
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|bit
operator|!=
literal|0
condition|)
block|{
for|for
control|(
name|pri
operator|=
name|bit
init|;
name|pri
operator|<
name|RQB_BPW
condition|;
name|pri
operator|++
control|)
if|if
condition|(
name|rqb
operator|->
name|rqb_bits
index|[
name|i
index|]
operator|&
operator|(
literal|1ul
operator|<<
name|pri
operator|)
condition|)
break|break;
if|if
condition|(
name|pri
operator|>=
name|RQB_BPW
condition|)
continue|continue;
block|}
else|else
name|pri
operator|=
name|RQB_FFS
argument_list|(
name|rqb
operator|->
name|rqb_bits
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|pri
operator|+=
operator|(
name|i
operator|<<
name|RQB_L2BPW
operator|)
expr_stmt|;
name|rqh
operator|=
operator|&
name|rq
operator|->
name|rq_queues
index|[
name|pri
index|]
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|ts
argument_list|,
argument|rqh
argument_list|,
argument|ts_procq
argument_list|)
block|{
if|if
condition|(
name|first
operator|&&
name|THREAD_CAN_MIGRATE
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|)
operator|&&
name|THREAD_CAN_SCHED
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|,
name|cpu
argument_list|)
condition|)
return|return
operator|(
name|ts
operator|)
return|;
name|first
operator|=
literal|1
expr_stmt|;
block|}
block|}
if|if
condition|(
name|start
operator|!=
literal|0
condition|)
block|{
name|start
operator|=
literal|0
expr_stmt|;
goto|goto
name|again
goto|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Steals load from a standard linear queue.  */
end_comment

begin_function
specifier|static
name|struct
name|td_sched
modifier|*
name|runq_steal
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|rqhead
modifier|*
name|rqh
decl_stmt|;
name|struct
name|rqbits
modifier|*
name|rqb
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|word
decl_stmt|;
name|int
name|bit
decl_stmt|;
name|rqb
operator|=
operator|&
name|rq
operator|->
name|rq_status
expr_stmt|;
for|for
control|(
name|word
operator|=
literal|0
init|;
name|word
operator|<
name|RQB_LEN
condition|;
name|word
operator|++
control|)
block|{
if|if
condition|(
name|rqb
operator|->
name|rqb_bits
index|[
name|word
index|]
operator|==
literal|0
condition|)
continue|continue;
for|for
control|(
name|bit
operator|=
literal|0
init|;
name|bit
operator|<
name|RQB_BPW
condition|;
name|bit
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|rqb
operator|->
name|rqb_bits
index|[
name|word
index|]
operator|&
operator|(
literal|1ul
operator|<<
name|bit
operator|)
operator|)
operator|==
literal|0
condition|)
continue|continue;
name|rqh
operator|=
operator|&
name|rq
operator|->
name|rq_queues
index|[
name|bit
operator|+
operator|(
name|word
operator|<<
name|RQB_L2BPW
operator|)
index|]
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|ts
argument_list|,
argument|rqh
argument_list|,
argument|ts_procq
argument_list|)
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|)
operator|&&
name|THREAD_CAN_SCHED
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|,
name|cpu
argument_list|)
condition|)
return|return
operator|(
name|ts
operator|)
return|;
block|}
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Attempt to steal a thread in priority order from a thread queue.  */
end_comment

begin_function
specifier|static
name|struct
name|td_sched
modifier|*
name|tdq_steal
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|ts
operator|=
name|runq_steal
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_realtime
argument_list|,
name|cpu
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
return|return
operator|(
name|ts
operator|)
return|;
if|if
condition|(
operator|(
name|ts
operator|=
name|runq_steal_from
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
argument_list|,
name|cpu
argument_list|,
name|tdq
operator|->
name|tdq_ridx
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
return|return
operator|(
name|ts
operator|)
return|;
return|return
operator|(
name|runq_steal
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|,
name|cpu
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Sets the thread lock and ts_cpu to match the requested cpu.  Unlocks the  * current lock and returns with the assigned queue locked.  */
end_comment

begin_function
specifier|static
specifier|inline
name|struct
name|tdq
modifier|*
name|sched_setcpu
parameter_list|(
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|,
name|int
name|cpu
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|ts
operator|->
name|ts_thread
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|td
operator|=
name|ts
operator|->
name|ts_thread
expr_stmt|;
name|ts
operator|->
name|ts_cpu
operator|=
name|cpu
expr_stmt|;
comment|/* If the lock matches just return the queue. */
if|if
condition|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
condition|)
return|return
operator|(
name|tdq
operator|)
return|;
ifdef|#
directive|ifdef
name|notyet
comment|/* 	 * If the thread isn't running its lockptr is a 	 * turnstile or a sleepqueue.  We can just lock_set without 	 * blocking. 	 */
if|if
condition|(
name|TD_CAN_RUN
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|thread_lock_set
argument_list|(
name|td
argument_list|,
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|tdq
operator|)
return|;
block|}
endif|#
directive|endif
comment|/* 	 * The hard case, migration, we need to block the thread first to 	 * prevent order reversals with other cpus locks. 	 */
name|spinlock_enter
argument_list|()
expr_stmt|;
name|thread_lock_block
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|thread_lock_unblock
argument_list|(
name|td
argument_list|,
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|spinlock_exit
argument_list|()
expr_stmt|;
return|return
operator|(
name|tdq
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Find the thread queue running the lowest priority thread.  */
end_comment

begin_function
specifier|static
name|int
name|tdq_lowestpri
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|lowpri
decl_stmt|;
name|int
name|lowcpu
decl_stmt|;
name|int
name|lowload
decl_stmt|;
name|int
name|load
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|lowload
operator|=
literal|0
expr_stmt|;
name|lowpri
operator|=
name|lowcpu
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|cpu
operator|=
literal|0
init|;
name|cpu
operator|<=
name|mp_maxid
condition|;
name|cpu
operator|++
control|)
block|{
if|if
condition|(
name|CPU_ABSENT
argument_list|(
name|cpu
argument_list|)
condition|)
continue|continue;
if|if
condition|(
operator|!
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|cpu
argument_list|)
condition|)
continue|continue;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|pri
operator|=
name|tdq
operator|->
name|tdq_lowpri
expr_stmt|;
name|load
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
operator|->
name|tdq_load
expr_stmt|;
name|CTR4
argument_list|(
name|KTR_ULE
argument_list|,
literal|"cpu %d pri %d lowcpu %d lowpri %d"
argument_list|,
name|cpu
argument_list|,
name|pri
argument_list|,
name|lowcpu
argument_list|,
name|lowpri
argument_list|)
expr_stmt|;
if|if
condition|(
name|pri
operator|<
name|lowpri
condition|)
continue|continue;
if|if
condition|(
name|lowpri
operator|&&
name|lowpri
operator|==
name|pri
operator|&&
name|load
operator|>
name|lowload
condition|)
continue|continue;
name|lowpri
operator|=
name|pri
expr_stmt|;
name|lowcpu
operator|=
name|cpu
expr_stmt|;
name|lowload
operator|=
name|load
expr_stmt|;
block|}
return|return
operator|(
name|lowcpu
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Find the thread queue with the least load.  */
end_comment

begin_function
specifier|static
name|int
name|tdq_lowestload
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|lowload
decl_stmt|;
name|int
name|lowpri
decl_stmt|;
name|int
name|lowcpu
decl_stmt|;
name|int
name|load
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|lowcpu
operator|=
literal|0
expr_stmt|;
name|lowload
operator|=
name|TDQ_CPU
argument_list|(
literal|0
argument_list|)
operator|->
name|tdq_load
expr_stmt|;
name|lowpri
operator|=
name|TDQ_CPU
argument_list|(
literal|0
argument_list|)
operator|->
name|tdq_lowpri
expr_stmt|;
for|for
control|(
name|cpu
operator|=
literal|1
init|;
name|cpu
operator|<=
name|mp_maxid
condition|;
name|cpu
operator|++
control|)
block|{
if|if
condition|(
name|CPU_ABSENT
argument_list|(
name|cpu
argument_list|)
condition|)
continue|continue;
if|if
condition|(
operator|!
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|cpu
argument_list|)
condition|)
continue|continue;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|load
operator|=
name|tdq
operator|->
name|tdq_load
expr_stmt|;
name|pri
operator|=
name|tdq
operator|->
name|tdq_lowpri
expr_stmt|;
name|CTR4
argument_list|(
name|KTR_ULE
argument_list|,
literal|"cpu %d load %d lowcpu %d lowload %d"
argument_list|,
name|cpu
argument_list|,
name|load
argument_list|,
name|lowcpu
argument_list|,
name|lowload
argument_list|)
expr_stmt|;
if|if
condition|(
name|load
operator|>
name|lowload
condition|)
continue|continue;
if|if
condition|(
name|load
operator|==
name|lowload
operator|&&
name|pri
operator|<
name|lowpri
condition|)
continue|continue;
name|lowcpu
operator|=
name|cpu
expr_stmt|;
name|lowload
operator|=
name|load
expr_stmt|;
name|lowpri
operator|=
name|pri
expr_stmt|;
block|}
return|return
operator|(
name|lowcpu
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Pick the destination cpu for sched_add().  Respects affinity and makes  * a determination based on load or priority of available processors.  */
end_comment

begin_function
specifier|static
name|int
name|sched_pickcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|cpumask_t
name|mask
decl_stmt|;
name|int
name|self
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|int
name|cpu
decl_stmt|;
name|self
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
condition|)
return|return
operator|(
name|self
operator|)
return|;
comment|/* 	 * Don't migrate a running thread from sched_switch(). 	 */
if|if
condition|(
name|flags
operator|&
name|SRQ_OURSELF
condition|)
block|{
name|CTR1
argument_list|(
name|KTR_ULE
argument_list|,
literal|"YIELDING %d"
argument_list|,
name|curthread
operator|->
name|td_priority
argument_list|)
expr_stmt|;
return|return
operator|(
name|self
operator|)
return|;
block|}
name|pri
operator|=
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
expr_stmt|;
name|cpu
operator|=
name|ts
operator|->
name|ts_cpu
expr_stmt|;
if|if
condition|(
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|cpu
argument_list|)
condition|)
block|{
comment|/* 		 * Regardless of affinity, if the last cpu is idle 		 * send it there. 		 */
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|tdq
operator|->
name|tdq_lowpri
operator|>
name|PRI_MIN_IDLE
condition|)
block|{
name|CTR5
argument_list|(
name|KTR_ULE
argument_list|,
literal|"ts_cpu %d idle, ltick %d ticks %d pri %d curthread %d"
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|,
name|ts
operator|->
name|ts_rltick
argument_list|,
name|ticks
argument_list|,
name|pri
argument_list|,
name|tdq
operator|->
name|tdq_lowpri
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|->
name|ts_cpu
operator|)
return|;
block|}
comment|/* 		 * If we have affinity, try to place it on the cpu we 		 * last ran on. 		 */
if|if
condition|(
name|SCHED_AFFINITY
argument_list|(
name|ts
argument_list|)
operator|&&
name|tdq
operator|->
name|tdq_lowpri
operator|>
name|pri
condition|)
block|{
name|CTR5
argument_list|(
name|KTR_ULE
argument_list|,
literal|"affinity for %d, ltick %d ticks %d pri %d curthread %d"
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|,
name|ts
operator|->
name|ts_rltick
argument_list|,
name|ticks
argument_list|,
name|pri
argument_list|,
name|tdq
operator|->
name|tdq_lowpri
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|->
name|ts_cpu
operator|)
return|;
block|}
block|}
comment|/* 	 * Look for an idle group. 	 */
name|CTR1
argument_list|(
name|KTR_ULE
argument_list|,
literal|"tdq_idle %X"
argument_list|,
name|tdq_idle
argument_list|)
expr_stmt|;
name|mask
operator|=
name|tdq_idle
expr_stmt|;
while|while
condition|(
operator|(
name|cpu
operator|=
name|ffs
argument_list|(
name|mask
argument_list|)
operator|)
operator|!=
literal|0
condition|)
block|{
operator|--
name|cpu
expr_stmt|;
if|if
condition|(
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|cpu
argument_list|)
condition|)
return|return
operator|(
name|cpu
operator|)
return|;
name|mask
operator|&=
operator|~
operator|(
literal|1
operator|<<
name|cpu
operator|)
expr_stmt|;
block|}
comment|/* 	 * If there are no idle cores see if we can run the thread locally. 	 * This may improve locality among sleepers and wakers when there 	 * is shared data. 	 */
if|if
condition|(
name|tryself
operator|&&
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|self
argument_list|)
operator|&&
name|pri
operator|<
name|curthread
operator|->
name|td_priority
condition|)
block|{
name|CTR1
argument_list|(
name|KTR_ULE
argument_list|,
literal|"tryself %d"
argument_list|,
name|curthread
operator|->
name|td_priority
argument_list|)
expr_stmt|;
return|return
operator|(
name|self
operator|)
return|;
block|}
comment|/*  	 * Now search for the cpu running the lowest priority thread with 	 * the least load. 	 */
if|if
condition|(
name|pick_pri
condition|)
name|cpu
operator|=
name|tdq_lowestpri
argument_list|(
name|td
argument_list|)
expr_stmt|;
else|else
name|cpu
operator|=
name|tdq_lowestload
argument_list|(
name|td
argument_list|)
expr_stmt|;
return|return
operator|(
name|cpu
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* SMP */
end_comment

begin_comment
comment|/*  * Pick the highest priority task we have and return it.  */
end_comment

begin_function
specifier|static
name|struct
name|td_sched
modifier|*
name|tdq_choose
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|runq_choose
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_realtime
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|!=
name|NULL
condition|)
return|return
operator|(
name|ts
operator|)
return|;
name|ts
operator|=
name|runq_choose_from
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
argument_list|,
name|tdq
operator|->
name|tdq_ridx
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|!=
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
operator|>=
name|PRI_MIN_TIMESHARE
argument_list|,
operator|(
literal|"tdq_choose: Invalid priority on timeshare queue %d"
operator|,
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|)
return|;
block|}
name|ts
operator|=
name|runq_choose
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|!=
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
operator|>=
name|PRI_MIN_IDLE
argument_list|,
operator|(
literal|"tdq_choose: Invalid priority on idle queue %d"
operator|,
name|ts
operator|->
name|ts_thread
operator|->
name|td_priority
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|)
return|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Initialize a thread queue.  */
end_comment

begin_function
specifier|static
name|void
name|tdq_setup
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
if|if
condition|(
name|bootverbose
condition|)
name|printf
argument_list|(
literal|"ULE: setup cpu %d\n"
argument_list|,
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|runq_init
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_realtime
argument_list|)
expr_stmt|;
name|runq_init
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
argument_list|)
expr_stmt|;
name|runq_init
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_idle
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_load
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function
specifier|static
name|void
name|tdg_setup
parameter_list|(
name|struct
name|tdq_group
modifier|*
name|tdg
parameter_list|)
block|{
if|if
condition|(
name|bootverbose
condition|)
name|printf
argument_list|(
literal|"ULE: setup cpu group %d\n"
argument_list|,
name|TDG_ID
argument_list|(
name|tdg
argument_list|)
argument_list|)
expr_stmt|;
name|snprintf
argument_list|(
name|tdg
operator|->
name|tdg_name
argument_list|,
sizeof|sizeof
argument_list|(
name|tdg
operator|->
name|tdg_name
argument_list|)
argument_list|,
literal|"sched lock %d"
argument_list|,
operator|(
name|int
operator|)
name|TDG_ID
argument_list|(
name|tdg
argument_list|)
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|tdg
operator|->
name|tdg_lock
argument_list|,
name|tdg
operator|->
name|tdg_name
argument_list|,
literal|"sched lock"
argument_list|,
name|MTX_SPIN
operator||
name|MTX_RECURSE
argument_list|)
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|tdg
operator|->
name|tdg_members
argument_list|)
expr_stmt|;
name|tdg
operator|->
name|tdg_load
operator|=
literal|0
expr_stmt|;
name|tdg
operator|->
name|tdg_transferable
operator|=
literal|0
expr_stmt|;
name|tdg
operator|->
name|tdg_cpus
operator|=
literal|0
expr_stmt|;
name|tdg
operator|->
name|tdg_mask
operator|=
literal|0
expr_stmt|;
name|tdg
operator|->
name|tdg_cpumask
operator|=
literal|0
expr_stmt|;
name|tdg
operator|->
name|tdg_idlemask
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|tdg_add
parameter_list|(
name|struct
name|tdq_group
modifier|*
name|tdg
parameter_list|,
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|)
block|{
if|if
condition|(
name|tdg
operator|->
name|tdg_mask
operator|==
literal|0
condition|)
name|tdg
operator|->
name|tdg_mask
operator||=
literal|1
operator|<<
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|tdg
operator|->
name|tdg_cpumask
operator||=
literal|1
operator|<<
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|tdg
operator|->
name|tdg_cpus
operator|++
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|=
name|tdg
expr_stmt|;
name|tdq
operator|->
name|tdq_lock
operator|=
operator|&
name|tdg
operator|->
name|tdg_lock
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|tdg
operator|->
name|tdg_members
argument_list|,
name|tdq
argument_list|,
name|tdq_siblings
argument_list|)
expr_stmt|;
if|if
condition|(
name|bootverbose
condition|)
name|printf
argument_list|(
literal|"ULE: adding cpu %d to group %d: cpus %d mask 0x%X\n"
argument_list|,
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|,
name|TDG_ID
argument_list|(
name|tdg
argument_list|)
argument_list|,
name|tdg
operator|->
name|tdg_cpus
argument_list|,
name|tdg
operator|->
name|tdg_cpumask
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_setup_topology
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|struct
name|cpu_group
modifier|*
name|cg
decl_stmt|;
name|int
name|balance_groups
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|i
decl_stmt|;
name|int
name|j
decl_stmt|;
name|topology
operator|=
literal|1
expr_stmt|;
name|balance_groups
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|smp_topology
operator|->
name|ct_count
condition|;
name|i
operator|++
control|)
block|{
name|cg
operator|=
operator|&
name|smp_topology
operator|->
name|ct_group
index|[
name|i
index|]
expr_stmt|;
name|tdg
operator|=
operator|&
name|tdq_groups
index|[
name|i
index|]
expr_stmt|;
comment|/* 		 * Initialize the group. 		 */
name|tdg_setup
argument_list|(
name|tdg
argument_list|)
expr_stmt|;
comment|/* 		 * Find all of the group members and add them. 		 */
for|for
control|(
name|j
operator|=
literal|0
init|;
name|j
operator|<
name|MAXCPU
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|cg
operator|->
name|cg_mask
operator|&
operator|(
literal|1
operator|<<
name|j
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|j
argument_list|)
expr_stmt|;
name|tdq_setup
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|tdg_add
argument_list|(
name|tdg
argument_list|,
name|tdq
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|tdg
operator|->
name|tdg_cpus
operator|>
literal|1
condition|)
name|balance_groups
operator|=
literal|1
expr_stmt|;
block|}
name|tdg_maxid
operator|=
name|smp_topology
operator|->
name|ct_count
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|balance_groups
condition|)
name|sched_balance_groups
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_setup_smp
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|cpus
decl_stmt|;
name|int
name|i
decl_stmt|;
for|for
control|(
name|cpus
operator|=
literal|0
operator|,
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|CPU_ABSENT
argument_list|(
name|i
argument_list|)
condition|)
continue|continue;
name|tdq
operator|=
operator|&
name|tdq_cpu
index|[
name|i
index|]
expr_stmt|;
name|tdg
operator|=
operator|&
name|tdq_groups
index|[
name|i
index|]
expr_stmt|;
comment|/* 		 * Setup a tdq group with one member. 		 */
name|tdg_setup
argument_list|(
name|tdg
argument_list|)
expr_stmt|;
name|tdq_setup
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|tdg_add
argument_list|(
name|tdg
argument_list|,
name|tdq
argument_list|)
expr_stmt|;
name|cpus
operator|++
expr_stmt|;
block|}
name|tdg_maxid
operator|=
name|cpus
operator|-
literal|1
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Fake a topology with one group containing all CPUs.  */
end_comment

begin_function
specifier|static
name|void
name|sched_fake_topo
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SCHED_FAKE_TOPOLOGY
specifier|static
name|struct
name|cpu_top
name|top
decl_stmt|;
specifier|static
name|struct
name|cpu_group
name|group
decl_stmt|;
name|top
operator|.
name|ct_count
operator|=
literal|1
expr_stmt|;
name|top
operator|.
name|ct_group
operator|=
operator|&
name|group
expr_stmt|;
name|group
operator|.
name|cg_mask
operator|=
name|all_cpus
expr_stmt|;
name|group
operator|.
name|cg_count
operator|=
name|mp_ncpus
expr_stmt|;
name|group
operator|.
name|cg_children
operator|=
literal|0
expr_stmt|;
name|smp_topology
operator|=
operator|&
name|top
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Setup the thread queues and initialize the topology based on MD  * information.  */
end_comment

begin_function
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|sched_fake_topo
argument_list|()
expr_stmt|;
comment|/* 	 * Setup tdqs based on a topology configuration or vanilla SMP based 	 * on mp_maxid. 	 */
if|if
condition|(
name|smp_topology
operator|==
name|NULL
condition|)
name|sched_setup_smp
argument_list|()
expr_stmt|;
else|else
name|sched_setup_topology
argument_list|()
expr_stmt|;
name|balance_tdq
operator|=
name|tdq
expr_stmt|;
name|sched_balance
argument_list|()
expr_stmt|;
else|#
directive|else
name|tdq_setup
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|tdq_lock
argument_list|,
literal|"sched lock"
argument_list|,
literal|"sched lock"
argument_list|,
name|MTX_SPIN
operator||
name|MTX_RECURSE
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_lock
operator|=
operator|&
name|tdq_lock
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * To avoid divide-by-zero, we set realstathz a dummy value 	 * in case which sched_clock() called before sched_initticks(). 	 */
name|realstathz
operator|=
name|hz
expr_stmt|;
name|sched_slice
operator|=
operator|(
name|realstathz
operator|/
literal|10
operator|)
expr_stmt|;
comment|/* ~100ms */
name|tickincr
operator|=
literal|1
operator|<<
name|SCHED_TICK_SHIFT
expr_stmt|;
comment|/* Add thread0's load since it's running. */
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|thread0
operator|.
name|td_lock
operator|=
name|TDQ_LOCKPTR
argument_list|(
name|TDQ_SELF
argument_list|()
argument_list|)
expr_stmt|;
name|tdq_load_add
argument_list|(
name|tdq
argument_list|,
operator|&
name|td_sched0
argument_list|)
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine determines the tickincr after stathz and hz are setup.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
specifier|static
name|void
name|sched_initticks
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|int
name|incr
decl_stmt|;
name|realstathz
operator|=
name|stathz
condition|?
name|stathz
else|:
name|hz
expr_stmt|;
name|sched_slice
operator|=
operator|(
name|realstathz
operator|/
literal|10
operator|)
expr_stmt|;
comment|/* ~100ms */
comment|/* 	 * tickincr is shifted out by 10 to avoid rounding errors due to 	 * hz not being evenly divisible by stathz on all platforms. 	 */
name|incr
operator|=
operator|(
name|hz
operator|<<
name|SCHED_TICK_SHIFT
operator|)
operator|/
name|realstathz
expr_stmt|;
comment|/* 	 * This does not work for values of stathz that are more than 	 * 1<< SCHED_TICK_SHIFT * hz.  In practice this does not happen. 	 */
if|if
condition|(
name|incr
operator|==
literal|0
condition|)
name|incr
operator|=
literal|1
expr_stmt|;
name|tickincr
operator|=
name|incr
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * Set the default balance interval now that we know 	 * what realstathz is. 	 */
name|balance_interval
operator|=
name|realstathz
expr_stmt|;
comment|/* 	 * Set steal thresh to roughly log2(mp_ncpu) but no greater than 4.  	 * This prevents excess thrashing on large machines and excess idle  	 * on smaller machines. 	 */
name|steal_thresh
operator|=
name|min
argument_list|(
name|fls
argument_list|(
name|mp_ncpus
argument_list|)
operator|-
literal|1
argument_list|,
literal|3
argument_list|)
expr_stmt|;
name|affinity
operator|=
name|SCHED_AFFINITY_DEFAULT
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  * This is the core of the interactivity algorithm.  Determines a score based  * on past behavior.  It is the ratio of sleep time to run time scaled to  * a [0, 100] integer.  This is the voluntary sleep time of a process, which  * differs from the cpu usage because it does not account for time spent  * waiting on a run-queue.  Would be prettier if we had floating point.  */
end_comment

begin_function
specifier|static
name|int
name|sched_interact_score
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|div
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
comment|/* 	 * The score is only needed if this is likely to be an interactive 	 * task.  Don't go through the expense of computing it if there's 	 * no chance. 	 */
if|if
condition|(
name|sched_interact
operator|<=
name|SCHED_INTERACT_HALF
operator|&&
name|ts
operator|->
name|ts_runtime
operator|>=
name|ts
operator|->
name|ts_slptime
condition|)
return|return
operator|(
name|SCHED_INTERACT_HALF
operator|)
return|;
if|if
condition|(
name|ts
operator|->
name|ts_runtime
operator|>
name|ts
operator|->
name|ts_slptime
condition|)
block|{
name|div
operator|=
name|max
argument_list|(
literal|1
argument_list|,
name|ts
operator|->
name|ts_runtime
operator|/
name|SCHED_INTERACT_HALF
argument_list|)
expr_stmt|;
return|return
operator|(
name|SCHED_INTERACT_HALF
operator|+
operator|(
name|SCHED_INTERACT_HALF
operator|-
operator|(
name|ts
operator|->
name|ts_slptime
operator|/
name|div
operator|)
operator|)
operator|)
return|;
block|}
if|if
condition|(
name|ts
operator|->
name|ts_slptime
operator|>
name|ts
operator|->
name|ts_runtime
condition|)
block|{
name|div
operator|=
name|max
argument_list|(
literal|1
argument_list|,
name|ts
operator|->
name|ts_slptime
operator|/
name|SCHED_INTERACT_HALF
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|->
name|ts_runtime
operator|/
name|div
operator|)
return|;
block|}
comment|/* runtime == slptime */
if|if
condition|(
name|ts
operator|->
name|ts_runtime
condition|)
return|return
operator|(
name|SCHED_INTERACT_HALF
operator|)
return|;
comment|/* 	 * This can happen if slptime and runtime are 0. 	 */
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Scale the scheduling priority according to the "interactivity" of this  * process.  */
end_comment

begin_function
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|int
name|score
decl_stmt|;
name|int
name|pri
decl_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|!=
name|PRI_TIMESHARE
condition|)
return|return;
comment|/* 	 * If the score is interactive we place the thread in the realtime 	 * queue with a priority that is less than kernel and interrupt 	 * priorities.  These threads are not subject to nice restrictions. 	 * 	 * Scores greater than this are placed on the normal timeshare queue 	 * where the priority is partially decided by the most recent cpu 	 * utilization and the rest is decided by nice value. 	 * 	 * The nice value of the process has a linear effect on the calculated 	 * score.  Negative nice values make it easier for a thread to be 	 * considered interactive. 	 */
name|score
operator|=
name|imax
argument_list|(
literal|0
argument_list|,
name|sched_interact_score
argument_list|(
name|td
argument_list|)
operator|+
name|td
operator|->
name|td_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
if|if
condition|(
name|score
operator|<
name|sched_interact
condition|)
block|{
name|pri
operator|=
name|PRI_MIN_REALTIME
expr_stmt|;
name|pri
operator|+=
operator|(
operator|(
name|PRI_MAX_REALTIME
operator|-
name|PRI_MIN_REALTIME
operator|)
operator|/
name|sched_interact
operator|)
operator|*
name|score
expr_stmt|;
name|KASSERT
argument_list|(
name|pri
operator|>=
name|PRI_MIN_REALTIME
operator|&&
name|pri
operator|<=
name|PRI_MAX_REALTIME
argument_list|,
operator|(
literal|"sched_priority: invalid interactive priority %d score %d"
operator|,
name|pri
operator|,
name|score
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pri
operator|=
name|SCHED_PRI_MIN
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_sched
operator|->
name|ts_ticks
condition|)
name|pri
operator|+=
name|SCHED_PRI_TICKS
argument_list|(
name|td
operator|->
name|td_sched
argument_list|)
expr_stmt|;
name|pri
operator|+=
name|SCHED_PRI_NICE
argument_list|(
name|td
operator|->
name|td_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pri
operator|>=
name|PRI_MIN_TIMESHARE
operator|&&
name|pri
operator|<=
name|PRI_MAX_TIMESHARE
argument_list|,
operator|(
literal|"sched_priority: invalid priority %d: nice %d, "
literal|"ticks %d ftick %d ltick %d tick pri %d"
operator|,
name|pri
operator|,
name|td
operator|->
name|td_proc
operator|->
name|p_nice
operator|,
name|td
operator|->
name|td_sched
operator|->
name|ts_ticks
operator|,
name|td
operator|->
name|td_sched
operator|->
name|ts_ftick
operator|,
name|td
operator|->
name|td_sched
operator|->
name|ts_ltick
operator|,
name|SCHED_PRI_TICKS
argument_list|(
name|td
operator|->
name|td_sched
argument_list|)
operator|)
argument_list|)
expr_stmt|;
block|}
name|sched_user_prio
argument_list|(
name|td
argument_list|,
name|pri
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_comment
comment|/*  * This routine enforces a maximum limit on the amount of scheduling history  * kept.  It is called after either the slptime or runtime is adjusted.  This  * function is ugly due to integer math.  */
end_comment

begin_function
specifier|static
name|void
name|sched_interact_update
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|u_int
name|sum
decl_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|sum
operator|=
name|ts
operator|->
name|ts_runtime
operator|+
name|ts
operator|->
name|ts_slptime
expr_stmt|;
if|if
condition|(
name|sum
operator|<
name|SCHED_SLP_RUN_MAX
condition|)
return|return;
comment|/* 	 * This only happens from two places: 	 * 1) We have added an unusual amount of run time from fork_exit. 	 * 2) We have added an unusual amount of sleep time from sched_sleep(). 	 */
if|if
condition|(
name|sum
operator|>
name|SCHED_SLP_RUN_MAX
operator|*
literal|2
condition|)
block|{
if|if
condition|(
name|ts
operator|->
name|ts_runtime
operator|>
name|ts
operator|->
name|ts_slptime
condition|)
block|{
name|ts
operator|->
name|ts_runtime
operator|=
name|SCHED_SLP_RUN_MAX
expr_stmt|;
name|ts
operator|->
name|ts_slptime
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|ts
operator|->
name|ts_slptime
operator|=
name|SCHED_SLP_RUN_MAX
expr_stmt|;
name|ts
operator|->
name|ts_runtime
operator|=
literal|1
expr_stmt|;
block|}
return|return;
block|}
comment|/* 	 * If we have exceeded by more than 1/5th then the algorithm below 	 * will not bring us back into range.  Dividing by two here forces 	 * us into the range of [4/5 * SCHED_INTERACT_MAX, SCHED_INTERACT_MAX] 	 */
if|if
condition|(
name|sum
operator|>
operator|(
name|SCHED_SLP_RUN_MAX
operator|/
literal|5
operator|)
operator|*
literal|6
condition|)
block|{
name|ts
operator|->
name|ts_runtime
operator|/=
literal|2
expr_stmt|;
name|ts
operator|->
name|ts_slptime
operator|/=
literal|2
expr_stmt|;
return|return;
block|}
name|ts
operator|->
name|ts_runtime
operator|=
operator|(
name|ts
operator|->
name|ts_runtime
operator|/
literal|5
operator|)
operator|*
literal|4
expr_stmt|;
name|ts
operator|->
name|ts_slptime
operator|=
operator|(
name|ts
operator|->
name|ts_slptime
operator|/
literal|5
operator|)
operator|*
literal|4
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Scale back the interactivity history when a child thread is created.  The  * history is inherited from the parent but the thread may behave totally  * differently.  For example, a shell spawning a compiler process.  We want  * to learn that the compiler is behaving badly very quickly.  */
end_comment

begin_function
specifier|static
name|void
name|sched_interact_fork
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|int
name|ratio
decl_stmt|;
name|int
name|sum
decl_stmt|;
name|sum
operator|=
name|td
operator|->
name|td_sched
operator|->
name|ts_runtime
operator|+
name|td
operator|->
name|td_sched
operator|->
name|ts_slptime
expr_stmt|;
if|if
condition|(
name|sum
operator|>
name|SCHED_SLP_RUN_FORK
condition|)
block|{
name|ratio
operator|=
name|sum
operator|/
name|SCHED_SLP_RUN_FORK
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_runtime
operator|/=
name|ratio
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_slptime
operator|/=
name|ratio
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Called from proc0_init() to setup the scheduler fields.  */
end_comment

begin_function
name|void
name|schedinit
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * Set up the scheduler specific parts of proc0. 	 */
name|proc0
operator|.
name|p_sched
operator|=
name|NULL
expr_stmt|;
comment|/* XXX */
name|thread0
operator|.
name|td_sched
operator|=
operator|&
name|td_sched0
expr_stmt|;
name|td_sched0
operator|.
name|ts_ltick
operator|=
name|ticks
expr_stmt|;
name|td_sched0
operator|.
name|ts_ftick
operator|=
name|ticks
expr_stmt|;
name|td_sched0
operator|.
name|ts_thread
operator|=
operator|&
name|thread0
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This is only somewhat accurate since given many processes of the same  * priority they will switch when their slices run out, which will be  * at most sched_slice stathz ticks.  */
end_comment

begin_function
name|int
name|sched_rr_interval
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* Convert sched_slice to hz */
return|return
operator|(
name|hz
operator|/
operator|(
name|realstathz
operator|/
name|sched_slice
operator|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Update the percent cpu tracking information when it is requested or  * the total history exceeds the maximum.  We keep a sliding history of  * tick counts that slowly decays.  This is less precise than the 4BSD  * mechanism since it happens with less regular and frequent events.  */
end_comment

begin_function
specifier|static
name|void
name|sched_pctcpu_update
parameter_list|(
name|struct
name|td_sched
modifier|*
name|ts
parameter_list|)
block|{
if|if
condition|(
name|ts
operator|->
name|ts_ticks
operator|==
literal|0
condition|)
return|return;
if|if
condition|(
name|ticks
operator|-
operator|(
name|hz
operator|/
literal|10
operator|)
operator|<
name|ts
operator|->
name|ts_ltick
operator|&&
name|SCHED_TICK_TOTAL
argument_list|(
name|ts
argument_list|)
operator|<
name|SCHED_TICK_MAX
condition|)
return|return;
comment|/* 	 * Adjust counters and watermark for pctcpu calc. 	 */
if|if
condition|(
name|ts
operator|->
name|ts_ltick
operator|>
name|ticks
operator|-
name|SCHED_TICK_TARG
condition|)
name|ts
operator|->
name|ts_ticks
operator|=
operator|(
name|ts
operator|->
name|ts_ticks
operator|/
operator|(
name|ticks
operator|-
name|ts
operator|->
name|ts_ftick
operator|)
operator|)
operator|*
name|SCHED_TICK_TARG
expr_stmt|;
else|else
name|ts
operator|->
name|ts_ticks
operator|=
literal|0
expr_stmt|;
name|ts
operator|->
name|ts_ltick
operator|=
name|ticks
expr_stmt|;
name|ts
operator|->
name|ts_ftick
operator|=
name|ts
operator|->
name|ts_ltick
operator|-
name|SCHED_TICK_TARG
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Adjust the priority of a thread.  Move it to the appropriate run-queue  * if necessary.  This is the back-end for several priority related  * functions.  */
end_comment

begin_function
specifier|static
name|void
name|sched_thread_priority
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|CTR6
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_prio: %p(%s) prio %d newprio %d by %p(%s)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|prio
argument_list|,
name|curthread
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|==
name|prio
condition|)
return|return;
if|if
condition|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
operator|&&
name|prio
operator|<
name|td
operator|->
name|td_priority
condition|)
block|{
comment|/* 		 * If the priority has been elevated due to priority 		 * propagation, we may have to move ourselves to a new 		 * queue.  This could be optimized to not re-add in some 		 * cases. 		 */
name|sched_rem
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_priority
operator|=
name|prio
expr_stmt|;
name|sched_add
argument_list|(
name|td
argument_list|,
name|SRQ_BORROWING
argument_list|)
expr_stmt|;
block|}
else|else
block|{
ifdef|#
directive|ifdef
name|SMP
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|prio
operator|<
name|tdq
operator|->
name|tdq_lowpri
condition|)
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|prio
expr_stmt|;
endif|#
directive|endif
name|td
operator|->
name|td_priority
operator|=
name|prio
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Update a thread's priority when it is lent another thread's  * priority.  */
end_comment

begin_function
name|void
name|sched_lend_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|td
operator|->
name|td_flags
operator||=
name|TDF_BORROWING
expr_stmt|;
name|sched_thread_priority
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Restore a thread's priority when priority propagation is  * over.  The prio argument is the minimum priority the thread  * needs to have to satisfy other possible priority lending  * requests.  If the thread's regular priority is less  * important than prio, the thread will keep a priority boost  * of prio.  */
end_comment

begin_function
name|void
name|sched_unlend_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|base_pri
decl_stmt|;
if|if
condition|(
name|td
operator|->
name|td_base_pri
operator|>=
name|PRI_MIN_TIMESHARE
operator|&&
name|td
operator|->
name|td_base_pri
operator|<=
name|PRI_MAX_TIMESHARE
condition|)
name|base_pri
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
else|else
name|base_pri
operator|=
name|td
operator|->
name|td_base_pri
expr_stmt|;
if|if
condition|(
name|prio
operator|>=
name|base_pri
condition|)
block|{
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_BORROWING
expr_stmt|;
name|sched_thread_priority
argument_list|(
name|td
argument_list|,
name|base_pri
argument_list|)
expr_stmt|;
block|}
else|else
name|sched_lend_prio
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Standard entry for setting the priority to an absolute value.  */
end_comment

begin_function
name|void
name|sched_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
comment|/* First, update the base priority. */
name|td
operator|->
name|td_base_pri
operator|=
name|prio
expr_stmt|;
comment|/* 	 * If the thread is borrowing another thread's priority, don't 	 * ever lower the priority. 	 */
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
operator|&&
name|td
operator|->
name|td_priority
operator|<
name|prio
condition|)
return|return;
comment|/* Change the real priority. */
name|oldprio
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|sched_thread_priority
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
comment|/* 	 * If the thread is on a turnstile, then let the turnstile update 	 * its state. 	 */
if|if
condition|(
name|TD_ON_LOCK
argument_list|(
name|td
argument_list|)
operator|&&
name|oldprio
operator|!=
name|prio
condition|)
name|turnstile_adjust
argument_list|(
name|td
argument_list|,
name|oldprio
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Set the base user priority, does not effect current running priority.  */
end_comment

begin_function
name|void
name|sched_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
name|td
operator|->
name|td_base_user_pri
operator|=
name|prio
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_UBORROWING
operator|&&
name|td
operator|->
name|td_user_pri
operator|<=
name|prio
condition|)
return|return;
name|oldprio
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|td
operator|->
name|td_user_pri
operator|=
name|prio
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_lend_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|oldprio
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_UBORROWING
expr_stmt|;
name|oldprio
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|td
operator|->
name|td_user_pri
operator|=
name|prio
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_unlend_user_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|u_char
name|base_pri
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|base_pri
operator|=
name|td
operator|->
name|td_base_user_pri
expr_stmt|;
if|if
condition|(
name|prio
operator|>=
name|base_pri
condition|)
block|{
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_UBORROWING
expr_stmt|;
name|sched_user_prio
argument_list|(
name|td
argument_list|,
name|base_pri
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sched_lend_user_prio
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Add the thread passed as 'newtd' to the run queue before selecting  * the next thread to run.  This is only used for KSE.  */
end_comment

begin_function
specifier|static
name|void
name|sched_switchin
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|spinlock_enter
argument_list|()
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|spinlock_exit
argument_list|()
expr_stmt|;
name|sched_setcpu
argument_list|(
name|td
operator|->
name|td_sched
argument_list|,
name|TDQ_ID
argument_list|(
name|tdq
argument_list|)
argument_list|,
name|SRQ_YIELDING
argument_list|)
expr_stmt|;
else|#
directive|else
name|td
operator|->
name|td_lock
operator|=
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|tdq_add
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|,
name|SRQ_YIELDING
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Handle migration from sched_switch().  This happens only for  * cpu binding.  */
end_comment

begin_function
specifier|static
name|struct
name|mtx
modifier|*
name|sched_switch_migrate
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdn
decl_stmt|;
name|tdn
operator|=
name|TDQ_CPU
argument_list|(
name|td
operator|->
name|td_sched
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * Do the lock dance required to avoid LOR.  We grab an extra 	 * spinlock nesting to prevent preemption while we're 	 * not holding either run-queue lock. 	 */
name|spinlock_enter
argument_list|()
expr_stmt|;
name|thread_lock_block
argument_list|(
name|td
argument_list|)
expr_stmt|;
comment|/* This releases the lock on tdq. */
comment|/* 	 * Acquire both run-queue locks before placing the thread on the new 	 * run-queue to avoid deadlocks created by placing a thread with a 	 * blocked lock on the run-queue of a remote processor.  The deadlock 	 * occurs when a third processor attempts to lock the two queues in 	 * question while the target processor is spinning with its own 	 * run-queue lock held while waiting for the blocked lock to clear. 	 */
if|if
condition|(
name|TDQ_LOCKPTR
argument_list|(
name|tdn
argument_list|)
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
condition|)
block|{
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|tdq_add
argument_list|(
name|tdn
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|tdq_notify
argument_list|(
name|td
operator|->
name|td_sched
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|tdq_lock_pair
argument_list|(
name|tdn
argument_list|,
name|tdq
argument_list|)
expr_stmt|;
name|tdq_add
argument_list|(
name|tdn
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|tdq_notify
argument_list|(
name|td
operator|->
name|td_sched
argument_list|)
expr_stmt|;
name|TDQ_UNLOCK
argument_list|(
name|tdn
argument_list|)
expr_stmt|;
block|}
name|spinlock_exit
argument_list|()
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
name|TDQ_LOCKPTR
argument_list|(
name|tdn
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Variadic version of thread_lock_unblock() that does not assume td_lock  * is blocked.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|thread_unblock_switch
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|mtx
modifier|*
name|mtx
parameter_list|)
block|{
name|atomic_store_rel_ptr
argument_list|(
operator|(
specifier|volatile
name|uintptr_t
operator|*
operator|)
operator|&
name|td
operator|->
name|td_lock
argument_list|,
operator|(
name|uintptr_t
operator|)
name|mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Switch threads.  This function has to handle threads coming in while  * blocked for some reason, running, or idle.  It also must deal with  * migrating a thread from one queue to another as running threads may  * be assigned elsewhere via binding.  */
end_comment

begin_function
name|void
name|sched_switch
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|newtd
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|mtx
modifier|*
name|mtx
decl_stmt|;
name|int
name|srqflag
decl_stmt|;
name|int
name|cpuid
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|mtx
operator|=
name|td
operator|->
name|td_lock
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|ts
operator|->
name|ts_rltick
operator|=
name|ticks
expr_stmt|;
if|if
condition|(
name|newtd
operator|&&
name|newtd
operator|->
name|td_priority
operator|<
name|tdq
operator|->
name|tdq_lowpri
condition|)
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|newtd
operator|->
name|td_priority
expr_stmt|;
endif|#
directive|endif
name|td
operator|->
name|td_lastcpu
operator|=
name|td
operator|->
name|td_oncpu
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|NOCPU
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_NEEDRESCHED
expr_stmt|;
name|td
operator|->
name|td_owepreempt
operator|=
literal|0
expr_stmt|;
comment|/* 	 * The lock pointer in an idle thread should never change.  Reset it 	 * to CAN_RUN as well. 	 */
if|if
condition|(
name|TD_IS_IDLETHREAD
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|TD_SET_CAN_RUN
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|srqflag
operator|=
operator|(
name|flags
operator|&
name|SW_PREEMPT
operator|)
condition|?
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
operator||
name|SRQ_PREEMPTED
else|:
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
operator|&&
operator|!
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|)
condition|)
name|ts
operator|->
name|ts_cpu
operator|=
name|sched_pickcpu
argument_list|(
name|td
argument_list|,
literal|0
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|ts
operator|->
name|ts_cpu
operator|==
name|cpuid
condition|)
name|tdq_add
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|,
name|srqflag
argument_list|)
expr_stmt|;
else|else
block|{
name|KASSERT
argument_list|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
operator|||
operator|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_BOUND
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"Thread %p shouldn't migrate"
operator|,
name|td
operator|)
argument_list|)
expr_stmt|;
name|mtx
operator|=
name|sched_switch_migrate
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|,
name|srqflag
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|/* This thread must be going to sleep. */
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|mtx
operator|=
name|thread_lock_block
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * We enter here with the thread blocked and assigned to the 	 * appropriate cpu run-queue or sleep-queue and with the current 	 * thread-queue locked. 	 */
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
operator||
name|MA_NOTRECURSED
argument_list|)
expr_stmt|;
comment|/* 	 * If KSE assigned a new thread just add it here and let choosethread 	 * select the best one. 	 */
if|if
condition|(
name|newtd
operator|!=
name|NULL
condition|)
name|sched_switchin
argument_list|(
name|tdq
argument_list|,
name|newtd
argument_list|)
expr_stmt|;
name|newtd
operator|=
name|choosethread
argument_list|()
expr_stmt|;
comment|/* 	 * Call the MD code to switch contexts if necessary. 	 */
if|if
condition|(
name|td
operator|!=
name|newtd
condition|)
block|{
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
if|if
condition|(
name|PMC_PROC_IS_USING_PMCS
argument_list|(
name|td
operator|->
name|td_proc
argument_list|)
condition|)
name|PMC_SWITCH_CONTEXT
argument_list|(
name|td
argument_list|,
name|PMC_FN_CSW_OUT
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
operator|->
name|mtx_lock
operator|=
operator|(
name|uintptr_t
operator|)
name|newtd
expr_stmt|;
ifdef|#
directive|ifdef
name|KDTRACE_HOOKS
comment|/* 		 * If DTrace has set the active vtime enum to anything 		 * other than INACTIVE (0), then it should have set the 		 * function to call. 		 */
if|if
condition|(
name|dtrace_vtime_active
condition|)
call|(
modifier|*
name|dtrace_vtime_switch_func
call|)
argument_list|(
name|newtd
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|cpu_switch
argument_list|(
name|td
argument_list|,
name|newtd
argument_list|,
name|mtx
argument_list|)
expr_stmt|;
comment|/* 		 * We may return from cpu_switch on a different cpu.  However, 		 * we always return with td_lock pointing to the current cpu's 		 * run queue lock. 		 */
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|HWPMC_HOOKS
if|if
condition|(
name|PMC_PROC_IS_USING_PMCS
argument_list|(
name|td
operator|->
name|td_proc
argument_list|)
condition|)
name|PMC_SWITCH_CONTEXT
argument_list|(
name|td
argument_list|,
name|PMC_FN_CSW_IN
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
else|else
name|thread_unblock_switch
argument_list|(
name|td
argument_list|,
name|mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Assert that all went well and return. 	 */
ifdef|#
directive|ifdef
name|SMP
comment|/* We should always get here with the lowest priority td possible */
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
endif|#
directive|endif
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
operator||
name|MA_NOTRECURSED
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|cpuid
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Adjust thread priorities as a result of a nice request.  */
end_comment

begin_function
name|void
name|sched_nice
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|int
name|nice
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PROC_SLOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|p
operator|->
name|p_nice
operator|=
name|nice
expr_stmt|;
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_prio
argument_list|(
name|td
argument_list|,
name|td
operator|->
name|td_base_user_pri
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Record the sleep time for the interactivity scorer.  */
end_comment

begin_function
name|void
name|sched_sleep
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_slptick
operator|=
name|ticks
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Schedule a thread to resume execution and record how long it voluntarily  * slept.  We also update the pctcpu, interactivity, and priority.  */
end_comment

begin_function
name|void
name|sched_wakeup
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|slptick
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
comment|/* 	 * If we slept for more than a tick update our interactivity and 	 * priority. 	 */
name|slptick
operator|=
name|td
operator|->
name|td_slptick
expr_stmt|;
name|td
operator|->
name|td_slptick
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|slptick
operator|&&
name|slptick
operator|!=
name|ticks
condition|)
block|{
name|u_int
name|hzticks
decl_stmt|;
name|hzticks
operator|=
operator|(
name|ticks
operator|-
name|slptick
operator|)
operator|<<
name|SCHED_TICK_SHIFT
expr_stmt|;
name|ts
operator|->
name|ts_slptime
operator|+=
name|hzticks
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_pctcpu_update
argument_list|(
name|ts
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
comment|/* Reset the slice value after we sleep. */
name|ts
operator|->
name|ts_slice
operator|=
name|sched_slice
expr_stmt|;
name|sched_add
argument_list|(
name|td
argument_list|,
name|SRQ_BORING
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Penalize the parent for creating a new child and initialize the child's  * priority.  */
end_comment

begin_function
name|void
name|sched_fork
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|sched_fork_thread
argument_list|(
name|td
argument_list|,
name|child
argument_list|)
expr_stmt|;
comment|/* 	 * Penalize the parent and child for forking. 	 */
name|sched_interact_fork
argument_list|(
name|child
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|child
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_runtime
operator|+=
name|tickincr
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Fork a new thread, may be within the same process.  */
end_comment

begin_function
name|void
name|sched_fork_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts2
decl_stmt|;
comment|/* 	 * Initialize child. 	 */
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|sched_newthread
argument_list|(
name|child
argument_list|)
expr_stmt|;
name|child
operator|->
name|td_lock
operator|=
name|TDQ_LOCKPTR
argument_list|(
name|TDQ_SELF
argument_list|()
argument_list|)
expr_stmt|;
name|child
operator|->
name|td_cpuset
operator|=
name|cpuset_ref
argument_list|(
name|td
operator|->
name|td_cpuset
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|ts2
operator|=
name|child
operator|->
name|td_sched
expr_stmt|;
name|ts2
operator|->
name|ts_cpu
operator|=
name|ts
operator|->
name|ts_cpu
expr_stmt|;
name|ts2
operator|->
name|ts_runq
operator|=
name|NULL
expr_stmt|;
comment|/* 	 * Grab our parents cpu estimation information and priority. 	 */
name|ts2
operator|->
name|ts_ticks
operator|=
name|ts
operator|->
name|ts_ticks
expr_stmt|;
name|ts2
operator|->
name|ts_ltick
operator|=
name|ts
operator|->
name|ts_ltick
expr_stmt|;
name|ts2
operator|->
name|ts_incrtick
operator|=
name|ts
operator|->
name|ts_incrtick
expr_stmt|;
name|ts2
operator|->
name|ts_ftick
operator|=
name|ts
operator|->
name|ts_ftick
expr_stmt|;
name|child
operator|->
name|td_user_pri
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|child
operator|->
name|td_base_user_pri
operator|=
name|td
operator|->
name|td_base_user_pri
expr_stmt|;
comment|/* 	 * And update interactivity score. 	 */
name|ts2
operator|->
name|ts_slptime
operator|=
name|ts
operator|->
name|ts_slptime
expr_stmt|;
name|ts2
operator|->
name|ts_runtime
operator|=
name|ts
operator|->
name|ts_runtime
expr_stmt|;
name|ts2
operator|->
name|ts_slice
operator|=
literal|1
expr_stmt|;
comment|/* Attempt to quickly learn interactivity. */
block|}
end_function

begin_comment
comment|/*  * Adjust the priority class of a thread.  */
end_comment

begin_function
name|void
name|sched_class
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|class
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|==
name|class
condition|)
return|return;
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * On SMP if we're on the RUNQ we must adjust the transferable 	 * count because could be changing to or from an interrupt 	 * class. 	 */
if|if
condition|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|td
operator|->
name|td_sched
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|tdq
operator|->
name|tdq_transferable
operator|--
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_transferable
operator|--
expr_stmt|;
block|}
name|td
operator|->
name|td_pri_class
operator|=
name|class
expr_stmt|;
if|if
condition|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|tdq
operator|->
name|tdq_transferable
operator|++
expr_stmt|;
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_transferable
operator|++
expr_stmt|;
block|}
block|}
endif|#
directive|endif
name|td
operator|->
name|td_pri_class
operator|=
name|class
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return some of the child's priority and interactivity to the parent.  */
end_comment

begin_function
name|void
name|sched_exit
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_exit: %p(%s) prio %d"
argument_list|,
name|child
argument_list|,
name|child
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|child
operator|->
name|td_priority
argument_list|)
expr_stmt|;
name|PROC_SLOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|=
name|FIRST_THREAD_IN_PROC
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|sched_exit_thread
argument_list|(
name|td
argument_list|,
name|child
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Penalize another thread for the time spent on this one.  This helps to  * worsen the priority and interactivity of processes which schedule batch  * jobs such as make.  This has little effect on the make process itself but  * causes new processes spawned by it to receive worse scores immediately.  */
end_comment

begin_function
name|void
name|sched_exit_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|CTR3
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_exit_thread: %p(%s) prio %d"
argument_list|,
name|child
argument_list|,
name|child
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|child
operator|->
name|td_priority
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|KSE
comment|/* 	 * KSE forks and exits so often that this penalty causes short-lived 	 * threads to always be non-interactive.  This causes mozilla to 	 * crawl under load. 	 */
if|if
condition|(
operator|(
name|td
operator|->
name|td_pflags
operator|&
name|TDP_SA
operator|)
operator|&&
name|td
operator|->
name|td_proc
operator|==
name|child
operator|->
name|td_proc
condition|)
return|return;
endif|#
directive|endif
comment|/* 	 * Give the child's runtime to the parent without returning the 	 * sleep time as a penalty to the parent.  This causes shells that 	 * launch expensive things to mark their children as expensive. 	 */
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_sched
operator|->
name|ts_runtime
operator|+=
name|child
operator|->
name|td_sched
operator|->
name|ts_runtime
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Fix priorities on return to user-space.  Priorities may be elevated due  * to static priorities in msleep() or similar.  */
end_comment

begin_function
name|void
name|sched_userret
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
comment|/* 	 * XXX we cheat slightly on the locking here to avoid locking in   	 * the usual case.  Setting td_priority here is essentially an 	 * incomplete workaround for not setting it properly elsewhere. 	 * Now that some interrupt handlers are threads, not setting it 	 * properly elsewhere can clobber it in the window between setting 	 * it here and returning to user mode, so don't waste time setting 	 * it perfectly here. 	 */
name|KASSERT
argument_list|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_BORROWING
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"thread with borrowed priority returning to userland"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|!=
name|td
operator|->
name|td_user_pri
condition|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_priority
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|td
operator|->
name|td_base_pri
operator|=
name|td
operator|->
name|td_user_pri
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Handle a stathz tick.  This is really only relevant for timeshare  * threads.  */
end_comment

begin_function
name|void
name|sched_clock
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * We run the long term load balancer infrequently on the first cpu. 	 */
if|if
condition|(
name|balance_tdq
operator|==
name|tdq
condition|)
block|{
if|if
condition|(
name|balance_ticks
operator|&&
operator|--
name|balance_ticks
operator|==
literal|0
condition|)
name|sched_balance
argument_list|()
expr_stmt|;
if|if
condition|(
name|balance_group_ticks
operator|&&
operator|--
name|balance_group_ticks
operator|==
literal|0
condition|)
name|sched_balance_groups
argument_list|()
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* 	 * Advance the insert index once for each tick to ensure that all 	 * threads get a chance to run. 	 */
if|if
condition|(
name|tdq
operator|->
name|tdq_idx
operator|==
name|tdq
operator|->
name|tdq_ridx
condition|)
block|{
name|tdq
operator|->
name|tdq_idx
operator|=
operator|(
name|tdq
operator|->
name|tdq_idx
operator|+
literal|1
operator|)
operator|%
name|RQ_NQS
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|tdq
operator|->
name|tdq_timeshare
operator|.
name|rq_queues
index|[
name|tdq
operator|->
name|tdq_ridx
index|]
argument_list|)
condition|)
name|tdq
operator|->
name|tdq_ridx
operator|=
name|tdq
operator|->
name|tdq_idx
expr_stmt|;
block|}
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|&
name|PRI_FIFO_BIT
condition|)
return|return;
if|if
condition|(
name|td
operator|->
name|td_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
block|{
comment|/* 		 * We used a tick; charge it to the thread so 		 * that we can compute our interactivity. 		 */
name|td
operator|->
name|td_sched
operator|->
name|ts_runtime
operator|+=
name|tickincr
expr_stmt|;
name|sched_interact_update
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * We used up one time slice. 	 */
if|if
condition|(
operator|--
name|ts
operator|->
name|ts_slice
operator|>
literal|0
condition|)
return|return;
comment|/* 	 * We're out of time, recompute priorities and requeue. 	 */
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Called once per hz tick.  Used for cpu utilization information.  This  * is easier than trying to scale based on stathz.  */
end_comment

begin_function
name|void
name|sched_tick
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|ts
operator|=
name|curthread
operator|->
name|td_sched
expr_stmt|;
comment|/* 	 * Ticks is updated asynchronously on a single cpu.  Check here to 	 * avoid incrementing ts_ticks multiple times in a single tick. 	 */
if|if
condition|(
name|ts
operator|->
name|ts_incrtick
operator|==
name|ticks
condition|)
return|return;
comment|/* Adjust ticks for pctcpu */
name|ts
operator|->
name|ts_ticks
operator|+=
literal|1
operator|<<
name|SCHED_TICK_SHIFT
expr_stmt|;
name|ts
operator|->
name|ts_incrtick
operator|=
name|ticks
expr_stmt|;
name|ts
operator|->
name|ts_ltick
operator|=
name|ticks
expr_stmt|;
comment|/* 	 * Update if we've exceeded our desired tick threshhold by over one 	 * second. 	 */
if|if
condition|(
name|ts
operator|->
name|ts_ftick
operator|+
name|SCHED_TICK_MAX
operator|<
name|ts
operator|->
name|ts_ltick
condition|)
name|sched_pctcpu_update
argument_list|(
name|ts
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return whether the current CPU has runnable tasks.  Used for in-kernel  * cooperative idle threads.  */
end_comment

begin_function
name|int
name|sched_runnable
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|load
decl_stmt|;
name|load
operator|=
literal|1
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|curthread
operator|->
name|td_flags
operator|&
name|TDF_IDLETD
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|tdq
operator|->
name|tdq_load
operator|>
literal|0
condition|)
goto|goto
name|out
goto|;
block|}
elseif|else
if|if
condition|(
name|tdq
operator|->
name|tdq_load
operator|-
literal|1
operator|>
literal|0
condition|)
goto|goto
name|out
goto|;
name|load
operator|=
literal|0
expr_stmt|;
name|out
label|:
return|return
operator|(
name|load
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Choose the highest priority thread to run.  The thread is removed from  * the run-queue while running however the load remains.  For SMP we set  * the tdq in the global idle bitmask if it idles here.  */
end_comment

begin_function
name|struct
name|thread
modifier|*
name|sched_choose
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|struct
name|tdq_group
modifier|*
name|tdg
decl_stmt|;
endif|#
directive|endif
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|tdq_choose
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
condition|)
block|{
name|tdq_runq_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
return|return
operator|(
name|ts
operator|->
name|ts_thread
operator|)
return|;
block|}
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * We only set the idled bit when all of the cpus in the group are 	 * idle.  Otherwise we could get into a situation where a thread bounces 	 * back and forth between two idle cores on seperate physical CPUs. 	 */
name|tdg
operator|=
name|tdq
operator|->
name|tdq_group
expr_stmt|;
name|tdg
operator|->
name|tdg_idlemask
operator||=
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
expr_stmt|;
if|if
condition|(
name|tdg
operator|->
name|tdg_idlemask
operator|==
name|tdg
operator|->
name|tdg_cpumask
condition|)
name|atomic_set_int
argument_list|(
operator|&
name|tdq_idle
argument_list|,
name|tdg
operator|->
name|tdg_mask
argument_list|)
expr_stmt|;
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|PRI_MAX_IDLE
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
name|PCPU_GET
argument_list|(
name|idlethread
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Set owepreempt if necessary.  Preemption never happens directly in ULE,  * we always request it once we exit a critical section.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|sched_setpreempt
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|ctd
decl_stmt|;
name|int
name|cpri
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|ctd
operator|=
name|curthread
expr_stmt|;
name|pri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|cpri
operator|=
name|ctd
operator|->
name|td_priority
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<
name|ctd
operator|->
name|td_priority
condition|)
name|curthread
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
if|if
condition|(
name|panicstr
operator|!=
name|NULL
operator|||
name|pri
operator|>=
name|cpri
operator|||
name|cold
operator|||
name|TD_IS_INHIBITED
argument_list|(
name|ctd
argument_list|)
condition|)
return|return;
comment|/* 	 * Always preempt IDLE threads.  Otherwise only if the preempting 	 * thread is an ithread. 	 */
if|if
condition|(
name|pri
operator|>
name|preempt_thresh
operator|&&
name|cpri
operator|<
name|PRI_MIN_IDLE
condition|)
return|return;
name|ctd
operator|->
name|td_owepreempt
operator|=
literal|1
expr_stmt|;
return|return;
block|}
end_function

begin_comment
comment|/*  * Add a thread to a thread queue.  Initializes priority, slice, runq, and  * add it to the appropriate queue.  This is the internal function called  * when the tdq is predetermined.  */
end_comment

begin_function
name|void
name|tdq_add
parameter_list|(
name|struct
name|tdq
modifier|*
name|tdq
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|int
name|class
decl_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|int
name|cpumask
decl_stmt|;
endif|#
directive|endif
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|td
operator|->
name|td_inhibitors
operator|==
literal|0
operator|)
argument_list|,
operator|(
literal|"sched_add: trying to run inhibited thread"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|TD_CAN_RUN
argument_list|(
name|td
argument_list|)
operator|||
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
operator|)
argument_list|,
operator|(
literal|"sched_add: bad thread state"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_INMEM
argument_list|,
operator|(
literal|"sched_add: thread swapped out"
operator|)
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|class
operator|=
name|PRI_BASE
argument_list|(
name|td
operator|->
name|td_pri_class
argument_list|)
expr_stmt|;
name|TD_SET_RUNQ
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_slice
operator|==
literal|0
condition|)
name|ts
operator|->
name|ts_slice
operator|=
name|sched_slice
expr_stmt|;
comment|/* 	 * Pick the run queue based on priority. 	 */
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<=
name|PRI_MAX_REALTIME
condition|)
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|tdq
operator|->
name|tdq_realtime
expr_stmt|;
elseif|else
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<=
name|PRI_MAX_TIMESHARE
condition|)
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|tdq
operator|->
name|tdq_timeshare
expr_stmt|;
else|else
name|ts
operator|->
name|ts_runq
operator|=
operator|&
name|tdq
operator|->
name|tdq_idle
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|cpumask
operator|=
literal|1
operator|<<
name|ts
operator|->
name|ts_cpu
expr_stmt|;
comment|/* 	 * If we had been idle, clear our bit in the group and potentially 	 * the global bitmap. 	 */
if|if
condition|(
operator|(
name|class
operator|!=
name|PRI_IDLE
operator|&&
name|class
operator|!=
name|PRI_ITHD
operator|)
operator|&&
operator|(
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_idlemask
operator|&
name|cpumask
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * Check to see if our group is unidling, and if so, remove it 		 * from the global idle mask. 		 */
if|if
condition|(
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_idlemask
operator|==
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_cpumask
condition|)
name|atomic_clear_int
argument_list|(
operator|&
name|tdq_idle
argument_list|,
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_mask
argument_list|)
expr_stmt|;
comment|/* 		 * Now remove ourselves from the group specific idle mask. 		 */
name|tdq
operator|->
name|tdq_group
operator|->
name|tdg_idlemask
operator|&=
operator|~
name|cpumask
expr_stmt|;
block|}
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<
name|tdq
operator|->
name|tdq_lowpri
condition|)
name|tdq
operator|->
name|tdq_lowpri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
endif|#
directive|endif
name|tdq_runq_add
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|tdq_load_add
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Select the target thread queue and add a thread to it.  Request  * preemption or IPI a remote processor if required.  */
end_comment

begin_function
name|void
name|sched_add
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|int
name|cpuid
decl_stmt|;
name|int
name|cpu
decl_stmt|;
endif|#
directive|endif
name|CTR5
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_add: %p(%s) prio %d by %p(%s)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|curthread
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
comment|/* 	 * Recalculate the priority before we select the target cpu or 	 * run-queue. 	 */
if|if
condition|(
name|PRI_BASE
argument_list|(
name|td
operator|->
name|td_pri_class
argument_list|)
operator|==
name|PRI_TIMESHARE
condition|)
name|sched_priority
argument_list|(
name|td
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
comment|/* 	 * Pick the destination cpu and if it isn't ours transfer to the 	 * target cpu. 	 */
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<=
name|PRI_MAX_ITHD
operator|&&
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
operator|&&
name|curthread
operator|->
name|td_intr_nesting_level
condition|)
name|ts
operator|->
name|ts_cpu
operator|=
name|cpuid
expr_stmt|;
if|if
condition|(
operator|!
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
condition|)
name|cpu
operator|=
name|ts
operator|->
name|ts_cpu
expr_stmt|;
else|else
name|cpu
operator|=
name|sched_pickcpu
argument_list|(
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|sched_setcpu
argument_list|(
name|ts
argument_list|,
name|cpu
argument_list|,
name|flags
argument_list|)
expr_stmt|;
name|tdq_add
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
operator|!=
name|cpuid
condition|)
block|{
name|tdq_notify
argument_list|(
name|ts
argument_list|)
expr_stmt|;
return|return;
block|}
else|#
directive|else
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
comment|/* 	 * Now that the thread is moving to the run-queue, set the lock 	 * to the scheduler's lock. 	 */
name|thread_lock_set
argument_list|(
name|td
argument_list|,
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|tdq_add
argument_list|(
name|tdq
argument_list|,
name|td
argument_list|,
name|flags
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
operator|!
operator|(
name|flags
operator|&
name|SRQ_YIELDING
operator|)
condition|)
name|sched_setpreempt
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove a thread from a run-queue without running it.  This is used  * when we're stealing a thread from a remote queue.  Otherwise all threads  * exit by calling sched_exit_thread() and sched_throw() themselves.  */
end_comment

begin_function
name|void
name|sched_rem
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|CTR5
argument_list|(
name|KTR_SCHED
argument_list|,
literal|"sched_rem: %p(%s) prio %d by %p(%s)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_priority
argument_list|,
name|curthread
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|ts
operator|->
name|ts_cpu
argument_list|)
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
argument_list|,
operator|(
literal|"sched_rem: thread not on run queue"
operator|)
argument_list|)
expr_stmt|;
name|tdq_runq_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|ts
argument_list|)
expr_stmt|;
name|TD_SET_CAN_RUN
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Fetch cpu utilization information.  Updates on demand.  */
end_comment

begin_function
name|fixpt_t
name|sched_pctcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|fixpt_t
name|pctcpu
decl_stmt|;
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|pctcpu
operator|=
literal|0
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|ts
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_ticks
condition|)
block|{
name|int
name|rtick
decl_stmt|;
name|sched_pctcpu_update
argument_list|(
name|ts
argument_list|)
expr_stmt|;
comment|/* How many rtick per second ? */
name|rtick
operator|=
name|min
argument_list|(
name|SCHED_TICK_HZ
argument_list|(
name|ts
argument_list|)
operator|/
name|SCHED_TICK_SECS
argument_list|,
name|hz
argument_list|)
expr_stmt|;
name|pctcpu
operator|=
operator|(
name|FSCALE
operator|*
operator|(
operator|(
name|FSCALE
operator|*
name|rtick
operator|)
operator|/
name|hz
operator|)
operator|)
operator|>>
name|FSHIFT
expr_stmt|;
block|}
return|return
operator|(
name|pctcpu
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Enforce affinity settings for a thread.  Called after adjustments to  * cpumask.  */
end_comment

begin_function
name|void
name|sched_affinity
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|THREAD_CAN_SCHED
argument_list|(
name|td
argument_list|,
name|ts
operator|->
name|ts_cpu
argument_list|)
condition|)
return|return;
if|if
condition|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|sched_rem
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|sched_add
argument_list|(
name|td
argument_list|,
name|SRQ_BORING
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|!
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
condition|)
return|return;
comment|/* 	 * Force a switch before returning to userspace.  If the 	 * target thread is not running locally send an ipi to force 	 * the issue. 	 */
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|curthread
condition|)
name|ipi_selected
argument_list|(
literal|1
operator|<<
name|ts
operator|->
name|ts_cpu
argument_list|,
name|IPI_PREEMPT
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  * Bind a thread to a target cpu.  */
end_comment

begin_function
name|void
name|sched_bind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
operator||
name|MA_NOTRECURSED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|==
name|curthread
argument_list|,
operator|(
literal|"sched_bind: can only bind curthread"
operator|)
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_BOUND
condition|)
name|sched_unbind
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|THREAD_CAN_MIGRATE
argument_list|(
name|td
argument_list|)
argument_list|,
operator|(
literal|"%p must be migratable"
operator|,
name|td
operator|)
argument_list|)
expr_stmt|;
name|ts
operator|->
name|ts_flags
operator||=
name|TSF_BOUND
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
operator|==
name|cpu
condition|)
return|return;
name|ts
operator|->
name|ts_cpu
operator|=
name|cpu
expr_stmt|;
comment|/* When we return from mi_switch we'll be on the correct cpu. */
name|mi_switch
argument_list|(
name|SW_VOL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  * Release a bound thread.  */
end_comment

begin_function
name|void
name|sched_unbind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|td
operator|==
name|curthread
argument_list|,
operator|(
literal|"sched_unbind: can only bind curthread"
operator|)
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
operator|(
name|ts
operator|->
name|ts_flags
operator|&
name|TSF_BOUND
operator|)
operator|==
literal|0
condition|)
return|return;
name|ts
operator|->
name|ts_flags
operator|&=
operator|~
name|TSF_BOUND
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|sched_unpin
argument_list|()
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
name|int
name|sched_is_bound
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|THREAD_LOCK_ASSERT
argument_list|(
name|td
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
name|td
operator|->
name|td_sched
operator|->
name|ts_flags
operator|&
name|TSF_BOUND
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Basic yield call.  */
end_comment

begin_function
name|void
name|sched_relinquish
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|SCHED_STAT_INC
argument_list|(
name|switch_relinquish
argument_list|)
expr_stmt|;
name|mi_switch
argument_list|(
name|SW_VOL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return the total system load.  */
end_comment

begin_function
name|int
name|sched_load
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|int
name|total
decl_stmt|;
name|int
name|i
decl_stmt|;
name|total
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|tdg_maxid
condition|;
name|i
operator|++
control|)
name|total
operator|+=
name|TDQ_GROUP
argument_list|(
name|i
argument_list|)
operator|->
name|tdg_load
expr_stmt|;
return|return
operator|(
name|total
operator|)
return|;
else|#
directive|else
return|return
operator|(
name|TDQ_SELF
argument_list|()
operator|->
name|tdq_sysload
operator|)
return|;
endif|#
directive|endif
block|}
end_function

begin_function
name|int
name|sched_sizeof_proc
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|proc
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_sizeof_thread
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|thread
argument_list|)
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|td_sched
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * The actual idle process.  */
end_comment

begin_function
name|void
name|sched_idletd
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|td
operator|=
name|curthread
expr_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|Giant
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
comment|/* ULE relies on preemption for idle interruption. */
for|for
control|(
init|;
condition|;
control|)
block|{
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|tdq_idled
argument_list|(
name|tdq
argument_list|)
condition|)
name|cpu_idle
argument_list|()
expr_stmt|;
else|#
directive|else
name|cpu_idle
argument_list|()
expr_stmt|;
endif|#
directive|endif
block|}
block|}
end_function

begin_comment
comment|/*  * A CPU is entering for the first time or a thread is exiting.  */
end_comment

begin_function
name|void
name|sched_throw
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|newtd
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|tdq
operator|=
name|TDQ_SELF
argument_list|()
expr_stmt|;
if|if
condition|(
name|td
operator|==
name|NULL
condition|)
block|{
comment|/* Correct spinlock nesting and acquire the correct lock. */
name|TDQ_LOCK
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|spinlock_exit
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|tdq_load_rem
argument_list|(
name|tdq
argument_list|,
name|td
operator|->
name|td_sched
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|curthread
operator|->
name|td_md
operator|.
name|md_spinlock_count
operator|==
literal|1
argument_list|,
operator|(
literal|"invalid count"
operator|)
argument_list|)
expr_stmt|;
name|newtd
operator|=
name|choosethread
argument_list|()
expr_stmt|;
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
operator|->
name|mtx_lock
operator|=
operator|(
name|uintptr_t
operator|)
name|newtd
expr_stmt|;
name|PCPU_SET
argument_list|(
name|switchtime
argument_list|,
name|cpu_ticks
argument_list|()
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|switchticks
argument_list|,
name|ticks
argument_list|)
expr_stmt|;
name|cpu_throw
argument_list|(
name|td
argument_list|,
name|newtd
argument_list|)
expr_stmt|;
comment|/* doesn't return */
block|}
end_function

begin_comment
comment|/*  * This is called from fork_exit().  Just acquire the correct locks and  * let fork do the rest of the work.  */
end_comment

begin_function
name|void
name|sched_fork_exit
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|td_sched
modifier|*
name|ts
decl_stmt|;
name|struct
name|tdq
modifier|*
name|tdq
decl_stmt|;
name|int
name|cpuid
decl_stmt|;
comment|/* 	 * Finish setting up thread glue so that it begins execution in a 	 * non-nested critical section with the scheduler lock held. 	 */
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|tdq
operator|=
name|TDQ_CPU
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|ts
operator|=
name|td
operator|->
name|td_sched
expr_stmt|;
if|if
condition|(
name|TD_IS_IDLETHREAD
argument_list|(
name|td
argument_list|)
condition|)
name|td
operator|->
name|td_lock
operator|=
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|td
operator|->
name|td_lock
operator|==
name|TDQ_LOCKPTR
argument_list|(
name|tdq
argument_list|)
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|cpuid
expr_stmt|;
name|TDQ_LOCK_ASSERT
argument_list|(
name|tdq
argument_list|,
name|MA_OWNED
operator||
name|MA_NOTRECURSED
argument_list|)
expr_stmt|;
block|}
end_function

begin_expr_stmt
specifier|static
name|SYSCTL_NODE
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|sched
argument_list|,
name|CTLFLAG_RW
argument_list|,
literal|0
argument_list|,
literal|"Scheduler"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_STRING
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|name
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|"ULE"
argument_list|,
literal|0
argument_list|,
literal|"Scheduler name"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|slice
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|sched_slice
argument_list|,
literal|0
argument_list|,
literal|"Slice size for timeshare threads"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|interact
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|sched_interact
argument_list|,
literal|0
argument_list|,
literal|"Interactivity score threshold"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|preempt_thresh
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|preempt_thresh
argument_list|,
literal|0
argument_list|,
literal|"Min priority for preemption, lower priorities have greater precedence"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|pick_pri
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|pick_pri
argument_list|,
literal|0
argument_list|,
literal|"Pick the target cpu based on priority rather than load."
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|affinity
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|affinity
argument_list|,
literal|0
argument_list|,
literal|"Number of hz ticks to keep thread affinity for"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|tryself
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|tryself
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|balance
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|rebalance
argument_list|,
literal|0
argument_list|,
literal|"Enables the long-term load balancer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|balance_interval
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|balance_interval
argument_list|,
literal|0
argument_list|,
literal|"Average frequency in stathz ticks to run the long-term balancer"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|steal_htt
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|steal_htt
argument_list|,
literal|0
argument_list|,
literal|"Steals work from another hyper-threaded core on idle"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|steal_idle
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|steal_idle
argument_list|,
literal|0
argument_list|,
literal|"Attempts to steal work from other cores before idling"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|steal_thresh
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|steal_thresh
argument_list|,
literal|0
argument_list|,
literal|"Minimum load on remote cpu before we'll steal"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|topology
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|topology
argument_list|,
literal|0
argument_list|,
literal|"True when a topology has been specified by the MD code."
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* ps compat.  All cpu percentages from ULE are weighted. */
end_comment

begin_decl_stmt
specifier|static
name|int
name|ccpu
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|ccpu
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ccpu
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_define
define|#
directive|define
name|KERN_SWITCH_INCLUDE
value|1
end_define

begin_include
include|#
directive|include
file|"kern/kern_switch.c"
end_include

end_unit

