begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2002-2003, Jeffrey Roberson<jeff@freebsd.org>  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice unmodified, this list of conditions, and the following  *    disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,  * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT  * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,  * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY  * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF  * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_define
define|#
directive|define
name|kse
value|td_sched
end_define

begin_include
include|#
directive|include
file|<opt_sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kdb.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/resource.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysproto.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|KTRACE
end_ifdef

begin_include
include|#
directive|include
file|<sys/uio.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktrace.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_define
define|#
directive|define
name|KTR_ULE
value|KTR_NFS
end_define

begin_comment
comment|/* decay 95% of `p_pctcpu' in 60 seconds; see CCPU_SHIFT before changing */
end_comment

begin_comment
comment|/* XXX This is bogus compatability crap for ps */
end_comment

begin_decl_stmt
specifier|static
name|fixpt_t
name|ccpu
init|=
literal|0.95122942450071400909
operator|*
name|FSCALE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* exp(-1/20) */
end_comment

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|ccpu
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|ccpu
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function_decl
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_macro
name|SYSINIT
argument_list|(
argument|sched_setup
argument_list|,
argument|SI_SUB_RUN_QUEUE
argument_list|,
argument|SI_ORDER_FIRST
argument_list|,
argument|sched_setup
argument_list|,
argument|NULL
argument_list|)
end_macro

begin_expr_stmt
specifier|static
name|SYSCTL_NODE
argument_list|(
name|_kern
argument_list|,
name|OID_AUTO
argument_list|,
name|sched
argument_list|,
name|CTLFLAG_RW
argument_list|,
literal|0
argument_list|,
literal|"Scheduler"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_STRING
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|name
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|"ule"
argument_list|,
literal|0
argument_list|,
literal|"Scheduler name"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|slice_min
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|slice_min
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|slice_min
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|slice_max
init|=
literal|10
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_kern_sched
argument_list|,
name|OID_AUTO
argument_list|,
name|slice_max
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|slice_max
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|realstathz
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|tickincr
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|PREEMPTION
end_ifdef

begin_function
specifier|static
name|void
name|printf_caddr_t
parameter_list|(
name|void
modifier|*
name|data
parameter_list|)
block|{
name|printf
argument_list|(
literal|"%s"
argument_list|,
operator|(
name|char
operator|*
operator|)
name|data
argument_list|)
expr_stmt|;
block|}
end_function

begin_decl_stmt
specifier|static
name|char
name|preempt_warning
index|[]
init|=
literal|"WARNING: Kernel PREEMPTION is unstable under SCHED_ULE.\n"
decl_stmt|;
end_decl_stmt

begin_macro
name|SYSINIT
argument_list|(
argument|preempt_warning
argument_list|,
argument|SI_SUB_COPYRIGHT
argument_list|,
argument|SI_ORDER_ANY
argument_list|,
argument|printf_caddr_t
argument_list|,
argument|preempt_warning
argument_list|)
end_macro

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * The schedulable entity that can be given a context to run.  * A process may have several of these. Probably one per processor  * but posibly a few more. In this universe they are grouped  * with a KSEG that contains the priority and niceness  * for the group.  */
end_comment

begin_struct
struct|struct
name|kse
block|{
name|TAILQ_ENTRY
argument_list|(
argument|kse
argument_list|)
name|ke_kglist
expr_stmt|;
comment|/* (*) Queue of threads in ke_ksegrp. */
name|TAILQ_ENTRY
argument_list|(
argument|kse
argument_list|)
name|ke_kgrlist
expr_stmt|;
comment|/* (*) Queue of threads in this state.*/
name|TAILQ_ENTRY
argument_list|(
argument|kse
argument_list|)
name|ke_procq
expr_stmt|;
comment|/* (j/z) Run queue. */
name|int
name|ke_flags
decl_stmt|;
comment|/* (j) KEF_* flags. */
name|struct
name|thread
modifier|*
name|ke_thread
decl_stmt|;
comment|/* (*) Active associated thread. */
name|fixpt_t
name|ke_pctcpu
decl_stmt|;
comment|/* (j) %cpu during p_swtime. */
name|u_char
name|ke_oncpu
decl_stmt|;
comment|/* (j) Which cpu we are on. */
name|char
name|ke_rqindex
decl_stmt|;
comment|/* (j) Run queue index. */
enum|enum
block|{
name|KES_THREAD
init|=
literal|0x0
block|,
comment|/* slaved to thread state */
name|KES_ONRUNQ
block|}
name|ke_state
enum|;
comment|/* (j) thread sched specific status. */
name|int
name|ke_slptime
decl_stmt|;
name|int
name|ke_pinned
decl_stmt|;
name|int
name|ke_slice
decl_stmt|;
name|struct
name|runq
modifier|*
name|ke_runq
decl_stmt|;
name|u_char
name|ke_cpu
decl_stmt|;
comment|/* CPU that we have affinity for. */
comment|/* The following variables are only used for pctcpu calculation */
name|int
name|ke_ltick
decl_stmt|;
comment|/* Last tick that we were running on */
name|int
name|ke_ftick
decl_stmt|;
comment|/* First tick that we were running on */
name|int
name|ke_ticks
decl_stmt|;
comment|/* Tick count */
block|}
struct|;
end_struct

begin_define
define|#
directive|define
name|td_kse
value|td_sched
end_define

begin_define
define|#
directive|define
name|td_slptime
value|td_kse->ke_slptime
end_define

begin_define
define|#
directive|define
name|ke_proc
value|ke_thread->td_proc
end_define

begin_define
define|#
directive|define
name|ke_ksegrp
value|ke_thread->td_ksegrp
end_define

begin_comment
comment|/* flags kept in ke_flags */
end_comment

begin_define
define|#
directive|define
name|KEF_SCHED0
value|0x00001
end_define

begin_comment
comment|/* For scheduler-specific use. */
end_comment

begin_define
define|#
directive|define
name|KEF_SCHED1
value|0x00002
end_define

begin_comment
comment|/* For scheduler-specific use. */
end_comment

begin_define
define|#
directive|define
name|KEF_SCHED2
value|0x00004
end_define

begin_comment
comment|/* For scheduler-specific use. */
end_comment

begin_define
define|#
directive|define
name|KEF_SCHED3
value|0x00008
end_define

begin_comment
comment|/* For scheduler-specific use. */
end_comment

begin_define
define|#
directive|define
name|KEF_DIDRUN
value|0x02000
end_define

begin_comment
comment|/* Thread actually ran. */
end_comment

begin_define
define|#
directive|define
name|KEF_EXIT
value|0x04000
end_define

begin_comment
comment|/* Thread is being killed. */
end_comment

begin_comment
comment|/*  * These datastructures are allocated within their parent datastructure but  * are scheduler specific.  */
end_comment

begin_define
define|#
directive|define
name|ke_assign
value|ke_procq.tqe_next
end_define

begin_define
define|#
directive|define
name|KEF_ASSIGNED
value|KEF_SCHED0
end_define

begin_comment
comment|/* Thread is being migrated. */
end_comment

begin_define
define|#
directive|define
name|KEF_BOUND
value|KEF_SCHED1
end_define

begin_comment
comment|/* Thread can not migrate. */
end_comment

begin_define
define|#
directive|define
name|KEF_XFERABLE
value|KEF_SCHED2
end_define

begin_comment
comment|/* Thread was added as transferable. */
end_comment

begin_define
define|#
directive|define
name|KEF_HOLD
value|KEF_SCHED3
end_define

begin_comment
comment|/* Thread is temporarily bound. */
end_comment

begin_struct
struct|struct
name|kg_sched
block|{
name|struct
name|thread
modifier|*
name|skg_last_assigned
decl_stmt|;
comment|/* (j) Last thread assigned to */
comment|/* the system scheduler */
name|int
name|skg_slptime
decl_stmt|;
comment|/* Number of ticks we vol. slept */
name|int
name|skg_runtime
decl_stmt|;
comment|/* Number of ticks we were running */
name|int
name|skg_avail_opennings
decl_stmt|;
comment|/* (j) Num unfilled slots in group.*/
name|int
name|skg_concurrency
decl_stmt|;
comment|/* (j) Num threads requested in group.*/
name|int
name|skg_runq_threads
decl_stmt|;
comment|/* (j) Num KSEs on runq. */
block|}
struct|;
end_struct

begin_define
define|#
directive|define
name|kg_last_assigned
value|kg_sched->skg_last_assigned
end_define

begin_define
define|#
directive|define
name|kg_avail_opennings
value|kg_sched->skg_avail_opennings
end_define

begin_define
define|#
directive|define
name|kg_concurrency
value|kg_sched->skg_concurrency
end_define

begin_define
define|#
directive|define
name|kg_runq_threads
value|kg_sched->skg_runq_threads
end_define

begin_define
define|#
directive|define
name|kg_runtime
value|kg_sched->skg_runtime
end_define

begin_define
define|#
directive|define
name|kg_slptime
value|kg_sched->skg_slptime
end_define

begin_decl_stmt
specifier|static
name|struct
name|kse
name|kse0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|kg_sched
name|kg_sched0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * The priority is primarily determined by the interactivity score.  Thus, we  * give lower(better) priorities to kse groups that use less CPU.  The nice  * value is then directly added to this to allow nice to have some effect  * on latency.  *  * PRI_RANGE:	Total priority range for timeshare threads.  * PRI_NRESV:	Number of nice values.  * PRI_BASE:	The start of the dynamic range.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_PRI_RANGE
value|(PRI_MAX_TIMESHARE - PRI_MIN_TIMESHARE + 1)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_NRESV
value|((PRIO_MAX - PRIO_MIN) + 1)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_NHALF
value|(SCHED_PRI_NRESV / 2)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_BASE
value|(PRI_MIN_TIMESHARE)
end_define

begin_define
define|#
directive|define
name|SCHED_PRI_INTERACT
parameter_list|(
name|score
parameter_list|)
define|\
value|((score) * SCHED_PRI_RANGE / SCHED_INTERACT_MAX)
end_define

begin_comment
comment|/*  * These determine the interactivity of a process.  *  * SLP_RUN_MAX:	Maximum amount of sleep time + run time we'll accumulate  *		before throttling back.  * SLP_RUN_FORK:	Maximum slp+run time to inherit at fork time.  * INTERACT_MAX:	Maximum interactivity value.  Smaller is better.  * INTERACT_THRESH:	Threshhold for placement on the current runq.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_SLP_RUN_MAX
value|((hz * 5)<< 10)
end_define

begin_define
define|#
directive|define
name|SCHED_SLP_RUN_FORK
value|((hz / 2)<< 10)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_MAX
value|(100)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_HALF
value|(SCHED_INTERACT_MAX / 2)
end_define

begin_define
define|#
directive|define
name|SCHED_INTERACT_THRESH
value|(30)
end_define

begin_comment
comment|/*  * These parameters and macros determine the size of the time slice that is  * granted to each thread.  *  * SLICE_MIN:	Minimum time slice granted, in units of ticks.  * SLICE_MAX:	Maximum time slice granted.  * SLICE_RANGE:	Range of available time slices scaled by hz.  * SLICE_SCALE:	The number slices granted per val in the range of [0, max].  * SLICE_NICE:  Determine the amount of slice granted to a scaled nice.  * SLICE_NTHRESH:	The nice cutoff point for slice assignment.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_SLICE_MIN
value|(slice_min)
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_MAX
value|(slice_max)
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_INTERACTIVE
value|(slice_max)
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_NTHRESH
value|(SCHED_PRI_NHALF - 1)
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_RANGE
value|(SCHED_SLICE_MAX - SCHED_SLICE_MIN + 1)
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_SCALE
parameter_list|(
name|val
parameter_list|,
name|max
parameter_list|)
value|(((val) * SCHED_SLICE_RANGE) / (max))
end_define

begin_define
define|#
directive|define
name|SCHED_SLICE_NICE
parameter_list|(
name|nice
parameter_list|)
define|\
value|(SCHED_SLICE_MAX - SCHED_SLICE_SCALE((nice), SCHED_SLICE_NTHRESH))
end_define

begin_comment
comment|/*  * This macro determines whether or not the thread belongs on the current or  * next run queue.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_INTERACTIVE
parameter_list|(
name|kg
parameter_list|)
define|\
value|(sched_interact_score(kg)< SCHED_INTERACT_THRESH)
end_define

begin_define
define|#
directive|define
name|SCHED_CURR
parameter_list|(
name|kg
parameter_list|,
name|ke
parameter_list|)
define|\
value|(ke->ke_thread->td_priority< kg->kg_user_pri ||			\     SCHED_INTERACTIVE(kg))
end_define

begin_comment
comment|/*  * Cpu percentage computation macros and defines.  *  * SCHED_CPU_TIME:	Number of seconds to average the cpu usage across.  * SCHED_CPU_TICKS:	Number of hz ticks to average the cpu usage across.  */
end_comment

begin_define
define|#
directive|define
name|SCHED_CPU_TIME
value|10
end_define

begin_define
define|#
directive|define
name|SCHED_CPU_TICKS
value|(hz * SCHED_CPU_TIME)
end_define

begin_comment
comment|/*  * kseq - per processor runqs and statistics.  */
end_comment

begin_struct
struct|struct
name|kseq
block|{
name|struct
name|runq
name|ksq_idle
decl_stmt|;
comment|/* Queue of IDLE threads. */
name|struct
name|runq
name|ksq_timeshare
index|[
literal|2
index|]
decl_stmt|;
comment|/* Run queues for !IDLE. */
name|struct
name|runq
modifier|*
name|ksq_next
decl_stmt|;
comment|/* Next timeshare queue. */
name|struct
name|runq
modifier|*
name|ksq_curr
decl_stmt|;
comment|/* Current queue. */
name|int
name|ksq_load_timeshare
decl_stmt|;
comment|/* Load for timeshare. */
name|int
name|ksq_load
decl_stmt|;
comment|/* Aggregate load. */
name|short
name|ksq_nice
index|[
name|SCHED_PRI_NRESV
index|]
decl_stmt|;
comment|/* KSEs in each nice bin. */
name|short
name|ksq_nicemin
decl_stmt|;
comment|/* Least nice. */
ifdef|#
directive|ifdef
name|SMP
name|int
name|ksq_transferable
decl_stmt|;
name|LIST_ENTRY
argument_list|(
argument|kseq
argument_list|)
name|ksq_siblings
expr_stmt|;
comment|/* Next in kseq group. */
name|struct
name|kseq_group
modifier|*
name|ksq_group
decl_stmt|;
comment|/* Our processor group. */
specifier|volatile
name|struct
name|kse
modifier|*
name|ksq_assigned
decl_stmt|;
comment|/* assigned by another CPU. */
else|#
directive|else
name|int
name|ksq_sysload
decl_stmt|;
comment|/* For loadavg, !ITHD load. */
endif|#
directive|endif
block|}
struct|;
end_struct

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * kseq groups are groups of processors which can cheaply share threads.  When  * one processor in the group goes idle it will check the runqs of the other  * processors in its group prior to halting and waiting for an interrupt.  * These groups are suitable for SMT (Symetric Multi-Threading) and not NUMA.  * In a numa environment we'd want an idle bitmap per group and a two tiered  * load balancer.  */
end_comment

begin_struct
struct|struct
name|kseq_group
block|{
name|int
name|ksg_cpus
decl_stmt|;
comment|/* Count of CPUs in this kseq group. */
name|cpumask_t
name|ksg_cpumask
decl_stmt|;
comment|/* Mask of cpus in this group. */
name|cpumask_t
name|ksg_idlemask
decl_stmt|;
comment|/* Idle cpus in this group. */
name|cpumask_t
name|ksg_mask
decl_stmt|;
comment|/* Bit mask for first cpu. */
name|int
name|ksg_load
decl_stmt|;
comment|/* Total load of this group. */
name|int
name|ksg_transferable
decl_stmt|;
comment|/* Transferable load of this group. */
name|LIST_HEAD
argument_list|(
argument_list|,
argument|kseq
argument_list|)
name|ksg_members
expr_stmt|;
comment|/* Linked list of all members. */
block|}
struct|;
end_struct

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * One kse queue per processor.  */
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_decl_stmt
specifier|static
name|cpumask_t
name|kseq_idle
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|ksg_maxid
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|kseq
name|kseq_cpu
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|kseq_group
name|kseq_groups
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|bal_tick
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|gbal_tick
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|KSEQ_SELF
parameter_list|()
value|(&kseq_cpu[PCPU_GET(cpuid)])
end_define

begin_define
define|#
directive|define
name|KSEQ_CPU
parameter_list|(
name|x
parameter_list|)
value|(&kseq_cpu[(x)])
end_define

begin_define
define|#
directive|define
name|KSEQ_ID
parameter_list|(
name|x
parameter_list|)
value|((x) - kseq_cpu)
end_define

begin_define
define|#
directive|define
name|KSEQ_GROUP
parameter_list|(
name|x
parameter_list|)
value|(&kseq_groups[(x)])
end_define

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* !SMP */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|kseq
name|kseq_cpu
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|KSEQ_SELF
parameter_list|()
value|(&kseq_cpu)
end_define

begin_define
define|#
directive|define
name|KSEQ_CPU
parameter_list|(
name|x
parameter_list|)
value|(&kseq_cpu)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_function_decl
specifier|static
name|void
name|slot_fill
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|kse
modifier|*
name|sched_choose
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/* XXX Should be thread * */
end_comment

begin_function_decl
specifier|static
name|void
name|sched_add_internal
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|preemptive
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_slice
parameter_list|(
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|sched_interact_score
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_interact_update
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_interact_fork
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_pctcpu_update
parameter_list|(
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/* Operations on per processor queues */
end_comment

begin_function_decl
specifier|static
name|struct
name|kse
modifier|*
name|kseq_choose
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|kseq_setup
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|kseq_load_add
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|kseq_load_rem
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|kseq_runq_add
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|kseq_runq_rem
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|kseq_nice_add
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|int
name|nice
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|kseq_nice_rem
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|int
name|nice
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|kseq_print
parameter_list|(
name|int
name|cpu
parameter_list|)
function_decl|;
end_function_decl

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_function_decl
specifier|static
name|int
name|kseq_transfer
parameter_list|(
name|struct
name|kseq
modifier|*
name|ksq
parameter_list|,
name|struct
name|kse
modifier|*
name|ke
parameter_list|,
name|int
name|class
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|kse
modifier|*
name|runq_steal
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance_groups
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance_group
parameter_list|(
name|struct
name|kseq_group
modifier|*
name|ksg
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|sched_balance_pair
parameter_list|(
name|struct
name|kseq
modifier|*
name|high
parameter_list|,
name|struct
name|kseq
modifier|*
name|low
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|kseq_move
parameter_list|(
name|struct
name|kseq
modifier|*
name|from
parameter_list|,
name|int
name|cpu
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|kseq_idled
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|kseq_notify
parameter_list|(
name|struct
name|kse
modifier|*
name|ke
parameter_list|,
name|int
name|cpu
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|kseq_assign
parameter_list|(
name|struct
name|kseq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|kse
modifier|*
name|kseq_steal
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|int
name|stealidle
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * On P4 Xeons the round-robin interrupt delivery is broken.  As a result of  * this, we can't pin interrupts to the cpu that they were delivered to,   * otherwise all ithreads only run on CPU 0.  */
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|__i386__
end_ifdef

begin_define
define|#
directive|define
name|KSE_CAN_MIGRATE
parameter_list|(
name|ke
parameter_list|,
name|class
parameter_list|)
define|\
value|((ke)->ke_thread->td_pinned == 0&& ((ke)->ke_flags& KEF_BOUND) == 0)
end_define

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* !__i386__ */
end_comment

begin_define
define|#
directive|define
name|KSE_CAN_MIGRATE
parameter_list|(
name|ke
parameter_list|,
name|class
parameter_list|)
define|\
value|((class) != PRI_ITHD&& (ke)->ke_thread->td_pinned == 0&&		\     ((ke)->ke_flags& KEF_BOUND) == 0)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* !__i386__ */
end_comment

begin_endif
endif|#
directive|endif
end_endif

begin_function
name|void
name|kseq_print
parameter_list|(
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|int
name|i
decl_stmt|;
name|kseq
operator|=
name|KSEQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"kseq:\n"
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tload:           %d\n"
argument_list|,
name|kseq
operator|->
name|ksq_load
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tload TIMESHARE: %d\n"
argument_list|,
name|kseq
operator|->
name|ksq_load_timeshare
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|printf
argument_list|(
literal|"\tload transferable: %d\n"
argument_list|,
name|kseq
operator|->
name|ksq_transferable
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|printf
argument_list|(
literal|"\tnicemin:\t%d\n"
argument_list|,
name|kseq
operator|->
name|ksq_nicemin
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\tnice counts:\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|SCHED_PRI_NRESV
condition|;
name|i
operator|++
control|)
if|if
condition|(
name|kseq
operator|->
name|ksq_nice
index|[
name|i
index|]
condition|)
name|printf
argument_list|(
literal|"\t\t%d = %d\n"
argument_list|,
name|i
operator|-
name|SCHED_PRI_NHALF
argument_list|,
name|kseq
operator|->
name|ksq_nice
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|kseq_runq_add
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|KSE_CAN_MIGRATE
argument_list|(
name|ke
argument_list|,
name|PRI_BASE
argument_list|(
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_pri_class
argument_list|)
argument_list|)
condition|)
block|{
name|kseq
operator|->
name|ksq_transferable
operator|++
expr_stmt|;
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_transferable
operator|++
expr_stmt|;
name|ke
operator|->
name|ke_flags
operator||=
name|KEF_XFERABLE
expr_stmt|;
block|}
endif|#
directive|endif
name|runq_add
argument_list|(
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|kseq_runq_rem
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|ke
operator|->
name|ke_flags
operator|&
name|KEF_XFERABLE
condition|)
block|{
name|kseq
operator|->
name|ksq_transferable
operator|--
expr_stmt|;
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_transferable
operator|--
expr_stmt|;
name|ke
operator|->
name|ke_flags
operator|&=
operator|~
name|KEF_XFERABLE
expr_stmt|;
block|}
endif|#
directive|endif
name|runq_remove
argument_list|(
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|kseq_load_add
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
block|{
name|int
name|class
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|class
operator|=
name|PRI_BASE
argument_list|(
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_pri_class
argument_list|)
expr_stmt|;
if|if
condition|(
name|class
operator|==
name|PRI_TIMESHARE
condition|)
name|kseq
operator|->
name|ksq_load_timeshare
operator|++
expr_stmt|;
name|kseq
operator|->
name|ksq_load
operator|++
expr_stmt|;
if|if
condition|(
name|class
operator|!=
name|PRI_ITHD
operator|&&
operator|(
name|ke
operator|->
name|ke_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
ifdef|#
directive|ifdef
name|SMP
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_load
operator|++
expr_stmt|;
else|#
directive|else
name|kseq
operator|->
name|ksq_sysload
operator|++
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
name|CTR6
argument_list|(
name|KTR_ULE
argument_list|,
literal|"Add kse %p to %p (slice: %d, pri: %d, nice: %d(%d))"
argument_list|,
name|ke
argument_list|,
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
operator|->
name|ke_slice
argument_list|,
name|ke
operator|->
name|ke_thread
operator|->
name|td_priority
argument_list|,
name|ke
operator|->
name|ke_proc
operator|->
name|p_nice
argument_list|,
name|kseq
operator|->
name|ksq_nicemin
argument_list|)
expr_stmt|;
if|if
condition|(
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
name|kseq_nice_add
argument_list|(
name|kseq
argument_list|,
name|ke
operator|->
name|ke_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|kseq_load_rem
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
block|{
name|int
name|class
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|class
operator|=
name|PRI_BASE
argument_list|(
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_pri_class
argument_list|)
expr_stmt|;
if|if
condition|(
name|class
operator|==
name|PRI_TIMESHARE
condition|)
name|kseq
operator|->
name|ksq_load_timeshare
operator|--
expr_stmt|;
if|if
condition|(
name|class
operator|!=
name|PRI_ITHD
operator|&&
operator|(
name|ke
operator|->
name|ke_proc
operator|->
name|p_flag
operator|&
name|P_NOLOAD
operator|)
operator|==
literal|0
condition|)
ifdef|#
directive|ifdef
name|SMP
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_load
operator|--
expr_stmt|;
else|#
directive|else
name|kseq
operator|->
name|ksq_sysload
operator|--
expr_stmt|;
endif|#
directive|endif
name|kseq
operator|->
name|ksq_load
operator|--
expr_stmt|;
name|ke
operator|->
name|ke_runq
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
name|kseq_nice_rem
argument_list|(
name|kseq
argument_list|,
name|ke
operator|->
name|ke_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|kseq_nice_add
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|int
name|nice
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* Normalize to zero. */
name|kseq
operator|->
name|ksq_nice
index|[
name|nice
operator|+
name|SCHED_PRI_NHALF
index|]
operator|++
expr_stmt|;
if|if
condition|(
name|nice
operator|<
name|kseq
operator|->
name|ksq_nicemin
operator|||
name|kseq
operator|->
name|ksq_load_timeshare
operator|==
literal|1
condition|)
name|kseq
operator|->
name|ksq_nicemin
operator|=
name|nice
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|kseq_nice_rem
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|int
name|nice
parameter_list|)
block|{
name|int
name|n
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* Normalize to zero. */
name|n
operator|=
name|nice
operator|+
name|SCHED_PRI_NHALF
expr_stmt|;
name|kseq
operator|->
name|ksq_nice
index|[
name|n
index|]
operator|--
expr_stmt|;
name|KASSERT
argument_list|(
name|kseq
operator|->
name|ksq_nice
index|[
name|n
index|]
operator|>=
literal|0
argument_list|,
operator|(
literal|"Negative nice count."
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If this wasn't the smallest nice value or there are more in 	 * this bucket we can just return.  Otherwise we have to recalculate 	 * the smallest nice. 	 */
if|if
condition|(
name|nice
operator|!=
name|kseq
operator|->
name|ksq_nicemin
operator|||
name|kseq
operator|->
name|ksq_nice
index|[
name|n
index|]
operator|!=
literal|0
operator|||
name|kseq
operator|->
name|ksq_load_timeshare
operator|==
literal|0
condition|)
return|return;
for|for
control|(
init|;
name|n
operator|<
name|SCHED_PRI_NRESV
condition|;
name|n
operator|++
control|)
if|if
condition|(
name|kseq
operator|->
name|ksq_nice
index|[
name|n
index|]
condition|)
block|{
name|kseq
operator|->
name|ksq_nicemin
operator|=
name|n
operator|-
name|SCHED_PRI_NHALF
expr_stmt|;
return|return;
block|}
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * sched_balance is a simple CPU load balancing algorithm.  It operates by  * finding the least loaded and most loaded cpu and equalizing their load  * by migrating some processes.  *  * Dealing only with two CPUs at a time has two advantages.  Firstly, most  * installations will only have 2 cpus.  Secondly, load balancing too much at  * once can have an unpleasant effect on the system.  The scheduler rarely has  * enough information to make perfect decisions.  So this algorithm chooses  * algorithm simplicity and more gradual effects on load in larger systems.  *  * It could be improved by considering the priorities and slices assigned to  * each task prior to balancing them.  There are many pathological cases with  * any approach and so the semi random algorithm below may work as well as any.  *  */
end_comment

begin_function
specifier|static
name|void
name|sched_balance
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|kseq_group
modifier|*
name|high
decl_stmt|;
name|struct
name|kseq_group
modifier|*
name|low
decl_stmt|;
name|struct
name|kseq_group
modifier|*
name|ksg
decl_stmt|;
name|int
name|cnt
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
condition|)
goto|goto
name|out
goto|;
name|low
operator|=
name|high
operator|=
name|NULL
expr_stmt|;
name|i
operator|=
name|random
argument_list|()
operator|%
operator|(
name|ksg_maxid
operator|+
literal|1
operator|)
expr_stmt|;
for|for
control|(
name|cnt
operator|=
literal|0
init|;
name|cnt
operator|<=
name|ksg_maxid
condition|;
name|cnt
operator|++
control|)
block|{
name|ksg
operator|=
name|KSEQ_GROUP
argument_list|(
name|i
argument_list|)
expr_stmt|;
comment|/* 		 * Find the CPU with the highest load that has some 		 * threads to transfer. 		 */
if|if
condition|(
operator|(
name|high
operator|==
name|NULL
operator|||
name|ksg
operator|->
name|ksg_load
operator|>
name|high
operator|->
name|ksg_load
operator|)
operator|&&
name|ksg
operator|->
name|ksg_transferable
condition|)
name|high
operator|=
name|ksg
expr_stmt|;
if|if
condition|(
name|low
operator|==
name|NULL
operator|||
name|ksg
operator|->
name|ksg_load
operator|<
name|low
operator|->
name|ksg_load
condition|)
name|low
operator|=
name|ksg
expr_stmt|;
if|if
condition|(
operator|++
name|i
operator|>
name|ksg_maxid
condition|)
name|i
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|low
operator|!=
name|NULL
operator|&&
name|high
operator|!=
name|NULL
operator|&&
name|high
operator|!=
name|low
condition|)
name|sched_balance_pair
argument_list|(
name|LIST_FIRST
argument_list|(
operator|&
name|high
operator|->
name|ksg_members
argument_list|)
argument_list|,
name|LIST_FIRST
argument_list|(
operator|&
name|low
operator|->
name|ksg_members
argument_list|)
argument_list|)
expr_stmt|;
name|out
label|:
name|bal_tick
operator|=
name|ticks
operator|+
operator|(
name|random
argument_list|()
operator|%
operator|(
name|hz
operator|*
literal|2
operator|)
operator|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_balance_groups
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|smp_started
condition|)
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|ksg_maxid
condition|;
name|i
operator|++
control|)
name|sched_balance_group
argument_list|(
name|KSEQ_GROUP
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
name|gbal_tick
operator|=
name|ticks
operator|+
operator|(
name|random
argument_list|()
operator|%
operator|(
name|hz
operator|*
literal|2
operator|)
operator|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_balance_group
parameter_list|(
name|struct
name|kseq_group
modifier|*
name|ksg
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|struct
name|kseq
modifier|*
name|high
decl_stmt|;
name|struct
name|kseq
modifier|*
name|low
decl_stmt|;
name|int
name|load
decl_stmt|;
if|if
condition|(
name|ksg
operator|->
name|ksg_transferable
operator|==
literal|0
condition|)
return|return;
name|low
operator|=
name|NULL
expr_stmt|;
name|high
operator|=
name|NULL
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|kseq
argument_list|,
argument|&ksg->ksg_members
argument_list|,
argument|ksq_siblings
argument_list|)
block|{
name|load
operator|=
name|kseq
operator|->
name|ksq_load
expr_stmt|;
if|if
condition|(
name|high
operator|==
name|NULL
operator|||
name|load
operator|>
name|high
operator|->
name|ksq_load
condition|)
name|high
operator|=
name|kseq
expr_stmt|;
if|if
condition|(
name|low
operator|==
name|NULL
operator|||
name|load
operator|<
name|low
operator|->
name|ksq_load
condition|)
name|low
operator|=
name|kseq
expr_stmt|;
block|}
if|if
condition|(
name|high
operator|!=
name|NULL
operator|&&
name|low
operator|!=
name|NULL
operator|&&
name|high
operator|!=
name|low
condition|)
name|sched_balance_pair
argument_list|(
name|high
argument_list|,
name|low
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_balance_pair
parameter_list|(
name|struct
name|kseq
modifier|*
name|high
parameter_list|,
name|struct
name|kseq
modifier|*
name|low
parameter_list|)
block|{
name|int
name|transferable
decl_stmt|;
name|int
name|high_load
decl_stmt|;
name|int
name|low_load
decl_stmt|;
name|int
name|move
decl_stmt|;
name|int
name|diff
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * If we're transfering within a group we have to use this specific 	 * kseq's transferable count, otherwise we can steal from other members 	 * of the group. 	 */
if|if
condition|(
name|high
operator|->
name|ksq_group
operator|==
name|low
operator|->
name|ksq_group
condition|)
block|{
name|transferable
operator|=
name|high
operator|->
name|ksq_transferable
expr_stmt|;
name|high_load
operator|=
name|high
operator|->
name|ksq_load
expr_stmt|;
name|low_load
operator|=
name|low
operator|->
name|ksq_load
expr_stmt|;
block|}
else|else
block|{
name|transferable
operator|=
name|high
operator|->
name|ksq_group
operator|->
name|ksg_transferable
expr_stmt|;
name|high_load
operator|=
name|high
operator|->
name|ksq_group
operator|->
name|ksg_load
expr_stmt|;
name|low_load
operator|=
name|low
operator|->
name|ksq_group
operator|->
name|ksg_load
expr_stmt|;
block|}
if|if
condition|(
name|transferable
operator|==
literal|0
condition|)
return|return;
comment|/* 	 * Determine what the imbalance is and then adjust that to how many 	 * kses we actually have to give up (transferable). 	 */
name|diff
operator|=
name|high_load
operator|-
name|low_load
expr_stmt|;
name|move
operator|=
name|diff
operator|/
literal|2
expr_stmt|;
if|if
condition|(
name|diff
operator|&
literal|0x1
condition|)
name|move
operator|++
expr_stmt|;
name|move
operator|=
name|min
argument_list|(
name|move
argument_list|,
name|transferable
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|move
condition|;
name|i
operator|++
control|)
name|kseq_move
argument_list|(
name|high
argument_list|,
name|KSEQ_ID
argument_list|(
name|low
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_function
specifier|static
name|void
name|kseq_move
parameter_list|(
name|struct
name|kseq
modifier|*
name|from
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|struct
name|kseq
modifier|*
name|to
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|kseq
operator|=
name|from
expr_stmt|;
name|to
operator|=
name|KSEQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|ke
operator|=
name|kseq_steal
argument_list|(
name|kseq
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|ke
operator|==
name|NULL
condition|)
block|{
name|struct
name|kseq_group
modifier|*
name|ksg
decl_stmt|;
name|ksg
operator|=
name|kseq
operator|->
name|ksq_group
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|kseq
argument_list|,
argument|&ksg->ksg_members
argument_list|,
argument|ksq_siblings
argument_list|)
block|{
if|if
condition|(
name|kseq
operator|==
name|from
operator|||
name|kseq
operator|->
name|ksq_transferable
operator|==
literal|0
condition|)
continue|continue;
name|ke
operator|=
name|kseq_steal
argument_list|(
name|kseq
argument_list|,
literal|1
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|ke
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"kseq_move: No KSEs available with a "
literal|"transferable count of %d\n"
argument_list|,
name|ksg
operator|->
name|ksg_transferable
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|kseq
operator|==
name|to
condition|)
return|return;
name|ke
operator|->
name|ke_state
operator|=
name|KES_THREAD
expr_stmt|;
name|kseq_runq_rem
argument_list|(
name|kseq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|kseq_load_rem
argument_list|(
name|kseq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|kseq_notify
argument_list|(
name|ke
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|kseq_idled
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|)
block|{
name|struct
name|kseq_group
modifier|*
name|ksg
decl_stmt|;
name|struct
name|kseq
modifier|*
name|steal
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|ksg
operator|=
name|kseq
operator|->
name|ksq_group
expr_stmt|;
comment|/* 	 * If we're in a cpu group, try and steal kses from another cpu in 	 * the group before idling. 	 */
if|if
condition|(
name|ksg
operator|->
name|ksg_cpus
operator|>
literal|1
operator|&&
name|ksg
operator|->
name|ksg_transferable
condition|)
block|{
name|LIST_FOREACH
argument_list|(
argument|steal
argument_list|,
argument|&ksg->ksg_members
argument_list|,
argument|ksq_siblings
argument_list|)
block|{
if|if
condition|(
name|steal
operator|==
name|kseq
operator|||
name|steal
operator|->
name|ksq_transferable
operator|==
literal|0
condition|)
continue|continue;
name|ke
operator|=
name|kseq_steal
argument_list|(
name|steal
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|ke
operator|==
name|NULL
condition|)
continue|continue;
name|ke
operator|->
name|ke_state
operator|=
name|KES_THREAD
expr_stmt|;
name|kseq_runq_rem
argument_list|(
name|steal
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|kseq_load_rem
argument_list|(
name|steal
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|sched_add_internal
argument_list|(
name|ke
operator|->
name|ke_thread
argument_list|,
literal|0
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
block|}
comment|/* 	 * We only set the idled bit when all of the cpus in the group are 	 * idle.  Otherwise we could get into a situation where a KSE bounces 	 * back and forth between two idle cores on seperate physical CPUs. 	 */
name|ksg
operator|->
name|ksg_idlemask
operator||=
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
expr_stmt|;
if|if
condition|(
name|ksg
operator|->
name|ksg_idlemask
operator|!=
name|ksg
operator|->
name|ksg_cpumask
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|atomic_set_int
argument_list|(
operator|&
name|kseq_idle
argument_list|,
name|ksg
operator|->
name|ksg_mask
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|kseq_assign
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|nke
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
do|do
block|{
operator|*
operator|(
specifier|volatile
expr|struct
name|kse
operator|*
operator|*
operator|)
operator|&
name|ke
operator|=
name|kseq
operator|->
name|ksq_assigned
expr_stmt|;
block|}
do|while
condition|(
operator|!
name|atomic_cmpset_ptr
argument_list|(
operator|&
name|kseq
operator|->
name|ksq_assigned
argument_list|,
name|ke
argument_list|,
name|NULL
argument_list|)
condition|)
do|;
for|for
control|(
init|;
name|ke
operator|!=
name|NULL
condition|;
name|ke
operator|=
name|nke
control|)
block|{
name|nke
operator|=
name|ke
operator|->
name|ke_assign
expr_stmt|;
name|ke
operator|->
name|ke_flags
operator|&=
operator|~
name|KEF_ASSIGNED
expr_stmt|;
name|sched_add_internal
argument_list|(
name|ke
operator|->
name|ke_thread
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|kseq_notify
parameter_list|(
name|struct
name|kse
modifier|*
name|ke
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pcpu
decl_stmt|;
name|int
name|prio
decl_stmt|;
name|ke
operator|->
name|ke_cpu
operator|=
name|cpu
expr_stmt|;
name|ke
operator|->
name|ke_flags
operator||=
name|KEF_ASSIGNED
expr_stmt|;
name|prio
operator|=
name|ke
operator|->
name|ke_thread
operator|->
name|td_priority
expr_stmt|;
name|kseq
operator|=
name|KSEQ_CPU
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
comment|/* 	 * Place a KSE on another cpu's queue and force a resched. 	 */
do|do
block|{
operator|*
operator|(
specifier|volatile
expr|struct
name|kse
operator|*
operator|*
operator|)
operator|&
name|ke
operator|->
name|ke_assign
operator|=
name|kseq
operator|->
name|ksq_assigned
expr_stmt|;
block|}
do|while
condition|(
operator|!
name|atomic_cmpset_ptr
argument_list|(
operator|&
name|kseq
operator|->
name|ksq_assigned
argument_list|,
name|ke
operator|->
name|ke_assign
argument_list|,
name|ke
argument_list|)
condition|)
do|;
comment|/* 	 * Without sched_lock we could lose a race where we set NEEDRESCHED 	 * on a thread that is switched out before the IPI is delivered.  This 	 * would lead us to miss the resched.  This will be a problem once 	 * sched_lock is pushed down. 	 */
name|pcpu
operator|=
name|pcpu_find
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|td
operator|=
name|pcpu
operator|->
name|pc_curthread
expr_stmt|;
if|if
condition|(
name|ke
operator|->
name|ke_thread
operator|->
name|td_priority
operator|<
name|td
operator|->
name|td_priority
operator|||
name|td
operator|==
name|pcpu
operator|->
name|pc_idlethread
condition|)
block|{
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
name|ipi_selected
argument_list|(
literal|1
operator|<<
name|cpu
argument_list|,
name|IPI_AST
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|struct
name|kse
modifier|*
name|runq_steal
parameter_list|(
name|struct
name|runq
modifier|*
name|rq
parameter_list|)
block|{
name|struct
name|rqhead
modifier|*
name|rqh
decl_stmt|;
name|struct
name|rqbits
modifier|*
name|rqb
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|int
name|word
decl_stmt|;
name|int
name|bit
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|rqb
operator|=
operator|&
name|rq
operator|->
name|rq_status
expr_stmt|;
for|for
control|(
name|word
operator|=
literal|0
init|;
name|word
operator|<
name|RQB_LEN
condition|;
name|word
operator|++
control|)
block|{
if|if
condition|(
name|rqb
operator|->
name|rqb_bits
index|[
name|word
index|]
operator|==
literal|0
condition|)
continue|continue;
for|for
control|(
name|bit
operator|=
literal|0
init|;
name|bit
operator|<
name|RQB_BPW
condition|;
name|bit
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|rqb
operator|->
name|rqb_bits
index|[
name|word
index|]
operator|&
operator|(
literal|1ul
operator|<<
name|bit
operator|)
operator|)
operator|==
literal|0
condition|)
continue|continue;
name|rqh
operator|=
operator|&
name|rq
operator|->
name|rq_queues
index|[
name|bit
operator|+
operator|(
name|word
operator|<<
name|RQB_L2BPW
operator|)
index|]
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|ke
argument_list|,
argument|rqh
argument_list|,
argument|ke_procq
argument_list|)
block|{
if|if
condition|(
name|KSE_CAN_MIGRATE
argument_list|(
name|ke
argument_list|,
name|PRI_BASE
argument_list|(
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_pri_class
argument_list|)
argument_list|)
condition|)
return|return
operator|(
name|ke
operator|)
return|;
block|}
block|}
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|struct
name|kse
modifier|*
name|kseq_steal
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|int
name|stealidle
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
comment|/* 	 * Steal from next first to try to get a non-interactive task that 	 * may not have run for a while. 	 */
if|if
condition|(
operator|(
name|ke
operator|=
name|runq_steal
argument_list|(
name|kseq
operator|->
name|ksq_next
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
return|return
operator|(
name|ke
operator|)
return|;
if|if
condition|(
operator|(
name|ke
operator|=
name|runq_steal
argument_list|(
name|kseq
operator|->
name|ksq_curr
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
return|return
operator|(
name|ke
operator|)
return|;
if|if
condition|(
name|stealidle
condition|)
return|return
operator|(
name|runq_steal
argument_list|(
operator|&
name|kseq
operator|->
name|ksq_idle
argument_list|)
operator|)
return|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_function
name|int
name|kseq_transfer
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|,
name|struct
name|kse
modifier|*
name|ke
parameter_list|,
name|int
name|class
parameter_list|)
block|{
name|struct
name|kseq_group
modifier|*
name|ksg
decl_stmt|;
name|int
name|cpu
decl_stmt|;
if|if
condition|(
name|smp_started
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|cpu
operator|=
literal|0
expr_stmt|;
comment|/* 	 * If our load exceeds a certain threshold we should attempt to 	 * reassign this thread.  The first candidate is the cpu that 	 * originally ran the thread.  If it is idle, assign it there,  	 * otherwise, pick an idle cpu. 	 * 	 * The threshold at which we start to reassign kses has a large impact 	 * on the overall performance of the system.  Tuned too high and 	 * some CPUs may idle.  Too low and there will be excess migration 	 * and context switches. 	 */
name|ksg
operator|=
name|kseq
operator|->
name|ksq_group
expr_stmt|;
if|if
condition|(
name|ksg
operator|->
name|ksg_load
operator|>
name|ksg
operator|->
name|ksg_cpus
operator|&&
name|kseq_idle
condition|)
block|{
name|ksg
operator|=
name|KSEQ_CPU
argument_list|(
name|ke
operator|->
name|ke_cpu
argument_list|)
operator|->
name|ksq_group
expr_stmt|;
if|if
condition|(
name|kseq_idle
operator|&
name|ksg
operator|->
name|ksg_mask
condition|)
block|{
name|cpu
operator|=
name|ffs
argument_list|(
name|ksg
operator|->
name|ksg_idlemask
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
condition|)
goto|goto
name|migrate
goto|;
block|}
comment|/* 		 * Multiple cpus could find this bit simultaneously 		 * but the race shouldn't be terrible. 		 */
name|cpu
operator|=
name|ffs
argument_list|(
name|kseq_idle
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
condition|)
goto|goto
name|migrate
goto|;
block|}
comment|/* 	 * If another cpu in this group has idled, assign a thread over 	 * to them after checking to see if there are idled groups. 	 */
name|ksg
operator|=
name|kseq
operator|->
name|ksq_group
expr_stmt|;
if|if
condition|(
name|ksg
operator|->
name|ksg_idlemask
condition|)
block|{
name|cpu
operator|=
name|ffs
argument_list|(
name|ksg
operator|->
name|ksg_idlemask
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu
condition|)
goto|goto
name|migrate
goto|;
block|}
comment|/* 	 * No new CPU was found. 	 */
return|return
operator|(
literal|0
operator|)
return|;
name|migrate
label|:
comment|/* 	 * Now that we've found an idle CPU, migrate the thread. 	 */
name|cpu
operator|--
expr_stmt|;
name|ke
operator|->
name|ke_runq
operator|=
name|NULL
expr_stmt|;
name|kseq_notify
argument_list|(
name|ke
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* SMP */
end_comment

begin_comment
comment|/*  * Pick the highest priority task we have and return it.  */
end_comment

begin_function
specifier|static
name|struct
name|kse
modifier|*
name|kseq_choose
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|struct
name|runq
modifier|*
name|swap
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|swap
operator|=
name|NULL
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|ke
operator|=
name|runq_choose
argument_list|(
name|kseq
operator|->
name|ksq_curr
argument_list|)
expr_stmt|;
if|if
condition|(
name|ke
operator|==
name|NULL
condition|)
block|{
comment|/* 			 * We already swapped once and didn't get anywhere. 			 */
if|if
condition|(
name|swap
condition|)
break|break;
name|swap
operator|=
name|kseq
operator|->
name|ksq_curr
expr_stmt|;
name|kseq
operator|->
name|ksq_curr
operator|=
name|kseq
operator|->
name|ksq_next
expr_stmt|;
name|kseq
operator|->
name|ksq_next
operator|=
name|swap
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * If we encounter a slice of 0 the kse is in a 		 * TIMESHARE kse group and its nice was too far out 		 * of the range that receives slices.  		 */
if|if
condition|(
name|ke
operator|->
name|ke_slice
operator|==
literal|0
condition|)
block|{
name|runq_remove
argument_list|(
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|sched_slice
argument_list|(
name|ke
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_runq
operator|=
name|kseq
operator|->
name|ksq_next
expr_stmt|;
name|runq_add
argument_list|(
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
continue|continue;
block|}
return|return
operator|(
name|ke
operator|)
return|;
block|}
return|return
operator|(
name|runq_choose
argument_list|(
operator|&
name|kseq
operator|->
name|ksq_idle
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|kseq_setup
parameter_list|(
name|struct
name|kseq
modifier|*
name|kseq
parameter_list|)
block|{
name|runq_init
argument_list|(
operator|&
name|kseq
operator|->
name|ksq_timeshare
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
name|runq_init
argument_list|(
operator|&
name|kseq
operator|->
name|ksq_timeshare
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
name|runq_init
argument_list|(
operator|&
name|kseq
operator|->
name|ksq_idle
argument_list|)
expr_stmt|;
name|kseq
operator|->
name|ksq_curr
operator|=
operator|&
name|kseq
operator|->
name|ksq_timeshare
index|[
literal|0
index|]
expr_stmt|;
name|kseq
operator|->
name|ksq_next
operator|=
operator|&
name|kseq
operator|->
name|ksq_timeshare
index|[
literal|1
index|]
expr_stmt|;
name|kseq
operator|->
name|ksq_load
operator|=
literal|0
expr_stmt|;
name|kseq
operator|->
name|ksq_load_timeshare
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_setup
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|int
name|balance_groups
decl_stmt|;
name|int
name|i
decl_stmt|;
endif|#
directive|endif
name|slice_min
operator|=
operator|(
name|hz
operator|/
literal|100
operator|)
expr_stmt|;
comment|/* 10ms */
name|slice_max
operator|=
operator|(
name|hz
operator|/
literal|7
operator|)
expr_stmt|;
comment|/* ~140ms */
ifdef|#
directive|ifdef
name|SMP
name|balance_groups
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Initialize the kseqs. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
name|i
operator|++
control|)
block|{
name|struct
name|kseq
modifier|*
name|ksq
decl_stmt|;
name|ksq
operator|=
operator|&
name|kseq_cpu
index|[
name|i
index|]
expr_stmt|;
name|ksq
operator|->
name|ksq_assigned
operator|=
name|NULL
expr_stmt|;
name|kseq_setup
argument_list|(
operator|&
name|kseq_cpu
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|smp_topology
operator|==
name|NULL
condition|)
block|{
name|struct
name|kseq_group
modifier|*
name|ksg
decl_stmt|;
name|struct
name|kseq
modifier|*
name|ksq
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
name|i
operator|++
control|)
block|{
name|ksq
operator|=
operator|&
name|kseq_cpu
index|[
name|i
index|]
expr_stmt|;
name|ksg
operator|=
operator|&
name|kseq_groups
index|[
name|i
index|]
expr_stmt|;
comment|/* 			 * Setup a kseq group with one member. 			 */
name|ksq
operator|->
name|ksq_transferable
operator|=
literal|0
expr_stmt|;
name|ksq
operator|->
name|ksq_group
operator|=
name|ksg
expr_stmt|;
name|ksg
operator|->
name|ksg_cpus
operator|=
literal|1
expr_stmt|;
name|ksg
operator|->
name|ksg_idlemask
operator|=
literal|0
expr_stmt|;
name|ksg
operator|->
name|ksg_cpumask
operator|=
name|ksg
operator|->
name|ksg_mask
operator|=
literal|1
operator|<<
name|i
expr_stmt|;
name|ksg
operator|->
name|ksg_load
operator|=
literal|0
expr_stmt|;
name|ksg
operator|->
name|ksg_transferable
operator|=
literal|0
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|ksg
operator|->
name|ksg_members
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|ksg
operator|->
name|ksg_members
argument_list|,
name|ksq
argument_list|,
name|ksq_siblings
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|struct
name|kseq_group
modifier|*
name|ksg
decl_stmt|;
name|struct
name|cpu_group
modifier|*
name|cg
decl_stmt|;
name|int
name|j
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|smp_topology
operator|->
name|ct_count
condition|;
name|i
operator|++
control|)
block|{
name|cg
operator|=
operator|&
name|smp_topology
operator|->
name|ct_group
index|[
name|i
index|]
expr_stmt|;
name|ksg
operator|=
operator|&
name|kseq_groups
index|[
name|i
index|]
expr_stmt|;
comment|/* 			 * Initialize the group. 			 */
name|ksg
operator|->
name|ksg_idlemask
operator|=
literal|0
expr_stmt|;
name|ksg
operator|->
name|ksg_load
operator|=
literal|0
expr_stmt|;
name|ksg
operator|->
name|ksg_transferable
operator|=
literal|0
expr_stmt|;
name|ksg
operator|->
name|ksg_cpus
operator|=
name|cg
operator|->
name|cg_count
expr_stmt|;
name|ksg
operator|->
name|ksg_cpumask
operator|=
name|cg
operator|->
name|cg_mask
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|ksg
operator|->
name|ksg_members
argument_list|)
expr_stmt|;
comment|/* 			 * Find all of the group members and add them. 			 */
for|for
control|(
name|j
operator|=
literal|0
init|;
name|j
operator|<
name|MAXCPU
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|cg
operator|->
name|cg_mask
operator|&
operator|(
literal|1
operator|<<
name|j
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|ksg
operator|->
name|ksg_mask
operator|==
literal|0
condition|)
name|ksg
operator|->
name|ksg_mask
operator|=
literal|1
operator|<<
name|j
expr_stmt|;
name|kseq_cpu
index|[
name|j
index|]
operator|.
name|ksq_transferable
operator|=
literal|0
expr_stmt|;
name|kseq_cpu
index|[
name|j
index|]
operator|.
name|ksq_group
operator|=
name|ksg
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|ksg
operator|->
name|ksg_members
argument_list|,
operator|&
name|kseq_cpu
index|[
name|j
index|]
argument_list|,
name|ksq_siblings
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|ksg
operator|->
name|ksg_cpus
operator|>
literal|1
condition|)
name|balance_groups
operator|=
literal|1
expr_stmt|;
block|}
name|ksg_maxid
operator|=
name|smp_topology
operator|->
name|ct_count
operator|-
literal|1
expr_stmt|;
block|}
comment|/* 	 * Stagger the group and global load balancer so they do not 	 * interfere with each other. 	 */
name|bal_tick
operator|=
name|ticks
operator|+
name|hz
expr_stmt|;
if|if
condition|(
name|balance_groups
condition|)
name|gbal_tick
operator|=
name|ticks
operator|+
operator|(
name|hz
operator|/
literal|2
operator|)
expr_stmt|;
else|#
directive|else
name|kseq_setup
argument_list|(
name|KSEQ_SELF
argument_list|()
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|kseq_load_add
argument_list|(
name|KSEQ_SELF
argument_list|()
argument_list|,
operator|&
name|kse0
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Scale the scheduling priority according to the "interactivity" of this  * process.  */
end_comment

begin_function
specifier|static
name|void
name|sched_priority
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
block|{
name|int
name|pri
decl_stmt|;
if|if
condition|(
name|kg
operator|->
name|kg_pri_class
operator|!=
name|PRI_TIMESHARE
condition|)
return|return;
name|pri
operator|=
name|SCHED_PRI_INTERACT
argument_list|(
name|sched_interact_score
argument_list|(
name|kg
argument_list|)
argument_list|)
expr_stmt|;
name|pri
operator|+=
name|SCHED_PRI_BASE
expr_stmt|;
name|pri
operator|+=
name|kg
operator|->
name|kg_proc
operator|->
name|p_nice
expr_stmt|;
if|if
condition|(
name|pri
operator|>
name|PRI_MAX_TIMESHARE
condition|)
name|pri
operator|=
name|PRI_MAX_TIMESHARE
expr_stmt|;
elseif|else
if|if
condition|(
name|pri
operator|<
name|PRI_MIN_TIMESHARE
condition|)
name|pri
operator|=
name|PRI_MIN_TIMESHARE
expr_stmt|;
name|kg
operator|->
name|kg_user_pri
operator|=
name|pri
expr_stmt|;
return|return;
block|}
end_function

begin_comment
comment|/*  * Calculate a time slice based on the properties of the kseg and the runq  * that we're on.  This is only for PRI_TIMESHARE ksegrps.  */
end_comment

begin_function
specifier|static
name|void
name|sched_slice
parameter_list|(
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|kg
operator|=
name|ke
operator|->
name|ke_ksegrp
expr_stmt|;
name|kseq
operator|=
name|KSEQ_CPU
argument_list|(
name|ke
operator|->
name|ke_cpu
argument_list|)
expr_stmt|;
comment|/* 	 * Rationale: 	 * KSEs in interactive ksegs get a minimal slice so that we 	 * quickly notice if it abuses its advantage. 	 * 	 * KSEs in non-interactive ksegs are assigned a slice that is 	 * based on the ksegs nice value relative to the least nice kseg 	 * on the run queue for this cpu. 	 * 	 * If the KSE is less nice than all others it gets the maximum 	 * slice and other KSEs will adjust their slice relative to 	 * this when they first expire. 	 * 	 * There is 20 point window that starts relative to the least 	 * nice kse on the run queue.  Slice size is determined by 	 * the kse distance from the last nice ksegrp. 	 * 	 * If the kse is outside of the window it will get no slice 	 * and will be reevaluated each time it is selected on the 	 * run queue.  The exception to this is nice 0 ksegs when 	 * a nice -20 is running.  They are always granted a minimum 	 * slice. 	 */
if|if
condition|(
operator|!
name|SCHED_INTERACTIVE
argument_list|(
name|kg
argument_list|)
condition|)
block|{
name|int
name|nice
decl_stmt|;
name|nice
operator|=
name|kg
operator|->
name|kg_proc
operator|->
name|p_nice
operator|+
operator|(
literal|0
operator|-
name|kseq
operator|->
name|ksq_nicemin
operator|)
expr_stmt|;
if|if
condition|(
name|kseq
operator|->
name|ksq_load_timeshare
operator|==
literal|0
operator|||
name|kg
operator|->
name|kg_proc
operator|->
name|p_nice
operator|<
name|kseq
operator|->
name|ksq_nicemin
condition|)
name|ke
operator|->
name|ke_slice
operator|=
name|SCHED_SLICE_MAX
expr_stmt|;
elseif|else
if|if
condition|(
name|nice
operator|<=
name|SCHED_SLICE_NTHRESH
condition|)
name|ke
operator|->
name|ke_slice
operator|=
name|SCHED_SLICE_NICE
argument_list|(
name|nice
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|kg
operator|->
name|kg_proc
operator|->
name|p_nice
operator|==
literal|0
condition|)
name|ke
operator|->
name|ke_slice
operator|=
name|SCHED_SLICE_MIN
expr_stmt|;
else|else
name|ke
operator|->
name|ke_slice
operator|=
literal|0
expr_stmt|;
block|}
else|else
name|ke
operator|->
name|ke_slice
operator|=
name|SCHED_SLICE_INTERACTIVE
expr_stmt|;
name|CTR6
argument_list|(
name|KTR_ULE
argument_list|,
literal|"Sliced %p(%d) (nice: %d, nicemin: %d, load: %d, interactive: %d)"
argument_list|,
name|ke
argument_list|,
name|ke
operator|->
name|ke_slice
argument_list|,
name|kg
operator|->
name|kg_proc
operator|->
name|p_nice
argument_list|,
name|kseq
operator|->
name|ksq_nicemin
argument_list|,
name|kseq
operator|->
name|ksq_load_timeshare
argument_list|,
name|SCHED_INTERACTIVE
argument_list|(
name|kg
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_comment
comment|/*  * This routine enforces a maximum limit on the amount of scheduling history  * kept.  It is called after either the slptime or runtime is adjusted.  * This routine will not operate correctly when slp or run times have been  * adjusted to more than double their maximum.  */
end_comment

begin_function
specifier|static
name|void
name|sched_interact_update
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
block|{
name|int
name|sum
decl_stmt|;
name|sum
operator|=
name|kg
operator|->
name|kg_runtime
operator|+
name|kg
operator|->
name|kg_slptime
expr_stmt|;
if|if
condition|(
name|sum
operator|<
name|SCHED_SLP_RUN_MAX
condition|)
return|return;
comment|/* 	 * If we have exceeded by more than 1/5th then the algorithm below 	 * will not bring us back into range.  Dividing by two here forces 	 * us into the range of [4/5 * SCHED_INTERACT_MAX, SCHED_INTERACT_MAX] 	 */
if|if
condition|(
name|sum
operator|>
operator|(
name|SCHED_SLP_RUN_MAX
operator|/
literal|5
operator|)
operator|*
literal|6
condition|)
block|{
name|kg
operator|->
name|kg_runtime
operator|/=
literal|2
expr_stmt|;
name|kg
operator|->
name|kg_slptime
operator|/=
literal|2
expr_stmt|;
return|return;
block|}
name|kg
operator|->
name|kg_runtime
operator|=
operator|(
name|kg
operator|->
name|kg_runtime
operator|/
literal|5
operator|)
operator|*
literal|4
expr_stmt|;
name|kg
operator|->
name|kg_slptime
operator|=
operator|(
name|kg
operator|->
name|kg_slptime
operator|/
literal|5
operator|)
operator|*
literal|4
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_interact_fork
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
block|{
name|int
name|ratio
decl_stmt|;
name|int
name|sum
decl_stmt|;
name|sum
operator|=
name|kg
operator|->
name|kg_runtime
operator|+
name|kg
operator|->
name|kg_slptime
expr_stmt|;
if|if
condition|(
name|sum
operator|>
name|SCHED_SLP_RUN_FORK
condition|)
block|{
name|ratio
operator|=
name|sum
operator|/
name|SCHED_SLP_RUN_FORK
expr_stmt|;
name|kg
operator|->
name|kg_runtime
operator|/=
name|ratio
expr_stmt|;
name|kg
operator|->
name|kg_slptime
operator|/=
name|ratio
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|int
name|sched_interact_score
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|)
block|{
name|int
name|div
decl_stmt|;
if|if
condition|(
name|kg
operator|->
name|kg_runtime
operator|>
name|kg
operator|->
name|kg_slptime
condition|)
block|{
name|div
operator|=
name|max
argument_list|(
literal|1
argument_list|,
name|kg
operator|->
name|kg_runtime
operator|/
name|SCHED_INTERACT_HALF
argument_list|)
expr_stmt|;
return|return
operator|(
name|SCHED_INTERACT_HALF
operator|+
operator|(
name|SCHED_INTERACT_HALF
operator|-
operator|(
name|kg
operator|->
name|kg_slptime
operator|/
name|div
operator|)
operator|)
operator|)
return|;
block|}
if|if
condition|(
name|kg
operator|->
name|kg_slptime
operator|>
name|kg
operator|->
name|kg_runtime
condition|)
block|{
name|div
operator|=
name|max
argument_list|(
literal|1
argument_list|,
name|kg
operator|->
name|kg_slptime
operator|/
name|SCHED_INTERACT_HALF
argument_list|)
expr_stmt|;
return|return
operator|(
name|kg
operator|->
name|kg_runtime
operator|/
name|div
operator|)
return|;
block|}
comment|/* 	 * This can happen if slptime and runtime are 0. 	 */
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Very early in the boot some setup of scheduler-specific  * parts of proc0 and of soem scheduler resources needs to be done.  * Called from:  *  proc0_init()  */
end_comment

begin_function
name|void
name|schedinit
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * Set up the scheduler specific parts of proc0. 	 */
name|ksegrp0
operator|.
name|kg_sched
operator|=
operator|&
name|kg_sched0
expr_stmt|;
name|proc0
operator|.
name|p_sched
operator|=
name|NULL
expr_stmt|;
comment|/* XXX */
name|thread0
operator|.
name|td_kse
operator|=
operator|&
name|kse0
expr_stmt|;
name|kse0
operator|.
name|ke_thread
operator|=
operator|&
name|thread0
expr_stmt|;
name|kse0
operator|.
name|ke_oncpu
operator|=
name|NOCPU
expr_stmt|;
comment|/* wrong.. can we use PCPU(cpuid) yet? */
name|kse0
operator|.
name|ke_state
operator|=
name|KES_THREAD
expr_stmt|;
name|kg_sched0
operator|.
name|skg_concurrency
operator|=
literal|1
expr_stmt|;
name|kg_sched0
operator|.
name|skg_avail_opennings
operator|=
literal|0
expr_stmt|;
comment|/* we are already running */
block|}
end_function

begin_comment
comment|/*  * This is only somewhat accurate since given many processes of the same  * priority they will switch when their slices run out, which will be  * at most SCHED_SLICE_MAX.  */
end_comment

begin_function
name|int
name|sched_rr_interval
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
name|SCHED_SLICE_MAX
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_pctcpu_update
parameter_list|(
name|struct
name|kse
modifier|*
name|ke
parameter_list|)
block|{
comment|/* 	 * Adjust counters and watermark for pctcpu calc. 	 */
if|if
condition|(
name|ke
operator|->
name|ke_ltick
operator|>
name|ticks
operator|-
name|SCHED_CPU_TICKS
condition|)
block|{
comment|/* 		 * Shift the tick count out so that the divide doesn't 		 * round away our results. 		 */
name|ke
operator|->
name|ke_ticks
operator|<<=
literal|10
expr_stmt|;
name|ke
operator|->
name|ke_ticks
operator|=
operator|(
name|ke
operator|->
name|ke_ticks
operator|/
operator|(
name|ticks
operator|-
name|ke
operator|->
name|ke_ftick
operator|)
operator|)
operator|*
name|SCHED_CPU_TICKS
expr_stmt|;
name|ke
operator|->
name|ke_ticks
operator|>>=
literal|10
expr_stmt|;
block|}
else|else
name|ke
operator|->
name|ke_ticks
operator|=
literal|0
expr_stmt|;
name|ke
operator|->
name|ke_ltick
operator|=
name|ticks
expr_stmt|;
name|ke
operator|->
name|ke_ftick
operator|=
name|ke
operator|->
name|ke_ltick
operator|-
name|SCHED_CPU_TICKS
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_prio
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|u_char
name|prio
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
condition|)
block|{
comment|/* 		 * If the priority has been elevated due to priority 		 * propagation, we may have to move ourselves to a new 		 * queue.  We still call adjustrunqueue below in case kse 		 * needs to fix things up. 		 */
if|if
condition|(
name|prio
operator|<
name|td
operator|->
name|td_priority
operator|&&
name|ke
operator|&&
operator|(
name|ke
operator|->
name|ke_flags
operator|&
name|KEF_ASSIGNED
operator|)
operator|==
literal|0
operator|&&
name|ke
operator|->
name|ke_runq
operator|!=
name|KSEQ_CPU
argument_list|(
name|ke
operator|->
name|ke_cpu
argument_list|)
operator|->
name|ksq_curr
condition|)
block|{
name|runq_remove
argument_list|(
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_runq
operator|=
name|KSEQ_CPU
argument_list|(
name|ke
operator|->
name|ke_cpu
argument_list|)
operator|->
name|ksq_curr
expr_stmt|;
name|runq_add
argument_list|(
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Hold this kse on this cpu so that sched_prio() doesn't 		 * cause excessive migration.  We only want migration to 		 * happen as the result of a wakeup. 		 */
name|ke
operator|->
name|ke_flags
operator||=
name|KEF_HOLD
expr_stmt|;
name|adjustrunqueue
argument_list|(
name|td
argument_list|,
name|prio
argument_list|)
expr_stmt|;
block|}
else|else
name|td
operator|->
name|td_priority
operator|=
name|prio
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_switch
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|newtd
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|td
operator|->
name|td_lastcpu
operator|=
name|td
operator|->
name|td_oncpu
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|NOCPU
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_NEEDRESCHED
expr_stmt|;
name|td
operator|->
name|td_pflags
operator|&=
operator|~
name|TDP_OWEPREEMPT
expr_stmt|;
comment|/* 	 * If we bring in a thread,  	 * then account for it as if it had been added to the run queue and then chosen. 	 */
if|if
condition|(
name|newtd
condition|)
block|{
name|newtd
operator|->
name|td_ksegrp
operator|->
name|kg_avail_opennings
operator|--
expr_stmt|;
name|newtd
operator|->
name|td_kse
operator|->
name|ke_flags
operator||=
name|KEF_DIDRUN
expr_stmt|;
name|TD_SET_RUNNING
argument_list|(
name|newtd
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If the KSE has been assigned it may be in the process of switching 	 * to the new cpu.  This is the case in sched_bind(). 	 */
if|if
condition|(
operator|(
name|ke
operator|->
name|ke_flags
operator|&
name|KEF_ASSIGNED
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|td
operator|==
name|PCPU_GET
argument_list|(
name|idlethread
argument_list|)
condition|)
block|{
name|TD_SET_CAN_RUN
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* We are ending our run so make our slot available again */
name|td
operator|->
name|td_ksegrp
operator|->
name|kg_avail_opennings
operator|++
expr_stmt|;
if|if
condition|(
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|kseq_load_rem
argument_list|(
name|KSEQ_CPU
argument_list|(
name|ke
operator|->
name|ke_cpu
argument_list|)
argument_list|,
name|ke
argument_list|)
expr_stmt|;
comment|/* 				 * Don't allow the thread to migrate 				 * from a preemption. 				 */
name|ke
operator|->
name|ke_flags
operator||=
name|KEF_HOLD
expr_stmt|;
name|setrunqueue
argument_list|(
name|td
argument_list|,
name|SRQ_OURSELF
operator||
name|SRQ_YIELDING
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|ke
operator|->
name|ke_runq
condition|)
block|{
name|kseq_load_rem
argument_list|(
name|KSEQ_CPU
argument_list|(
name|ke
operator|->
name|ke_cpu
argument_list|)
argument_list|,
name|ke
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_IDLETD
operator|)
operator|==
literal|0
condition|)
name|kdb_backtrace
argument_list|()
expr_stmt|;
comment|/* 				 * We will not be on the run queue. 				 * So we must be sleeping or similar. 				 */
if|if
condition|(
name|td
operator|->
name|td_proc
operator|->
name|p_flag
operator|&
name|P_HADTHREADS
condition|)
name|slot_fill
argument_list|(
name|td
operator|->
name|td_ksegrp
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|newtd
operator|!=
name|NULL
condition|)
block|{
name|kseq_load_add
argument_list|(
name|KSEQ_SELF
argument_list|()
argument_list|,
name|newtd
operator|->
name|td_kse
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_runq
operator|=
name|KSEQ_SELF
argument_list|()
operator|->
name|ksq_curr
expr_stmt|;
block|}
else|else
name|newtd
operator|=
name|choosethread
argument_list|()
expr_stmt|;
if|if
condition|(
name|td
operator|!=
name|newtd
condition|)
name|cpu_switch
argument_list|(
name|td
argument_list|,
name|newtd
argument_list|)
expr_stmt|;
name|sched_lock
operator|.
name|mtx_lock
operator|=
operator|(
name|uintptr_t
operator|)
name|td
expr_stmt|;
name|td
operator|->
name|td_oncpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_nice
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|int
name|nice
parameter_list|)
block|{
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * We need to adjust the nice counts for running KSEs. 	 */
name|FOREACH_KSEGRP_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|kg
argument_list|)
block|{
if|if
condition|(
name|kg
operator|->
name|kg_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
block|{
name|FOREACH_THREAD_IN_GROUP
argument_list|(
argument|kg
argument_list|,
argument|td
argument_list|)
block|{
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
if|if
condition|(
name|ke
operator|->
name|ke_runq
operator|==
name|NULL
condition|)
continue|continue;
name|kseq
operator|=
name|KSEQ_CPU
argument_list|(
name|ke
operator|->
name|ke_cpu
argument_list|)
expr_stmt|;
name|kseq_nice_rem
argument_list|(
name|kseq
argument_list|,
name|p
operator|->
name|p_nice
argument_list|)
expr_stmt|;
name|kseq_nice_add
argument_list|(
name|kseq
argument_list|,
name|nice
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|p
operator|->
name|p_nice
operator|=
name|nice
expr_stmt|;
name|FOREACH_KSEGRP_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|kg
argument_list|)
block|{
name|sched_priority
argument_list|(
name|kg
argument_list|)
expr_stmt|;
name|FOREACH_THREAD_IN_GROUP
argument_list|(
argument|kg
argument_list|,
argument|td
argument_list|)
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|sched_sleep
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_slptime
operator|=
name|ticks
expr_stmt|;
name|td
operator|->
name|td_base_pri
operator|=
name|td
operator|->
name|td_priority
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_ULE
argument_list|,
literal|"sleep thread %p (tick: %d)"
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_slptime
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_wakeup
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Let the kseg know how long we slept for.  This is because process 	 * interactivity behavior is modeled in the kseg. 	 */
if|if
condition|(
name|td
operator|->
name|td_slptime
condition|)
block|{
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|int
name|hzticks
decl_stmt|;
name|kg
operator|=
name|td
operator|->
name|td_ksegrp
expr_stmt|;
name|hzticks
operator|=
operator|(
name|ticks
operator|-
name|td
operator|->
name|td_slptime
operator|)
operator|<<
literal|10
expr_stmt|;
if|if
condition|(
name|hzticks
operator|>=
name|SCHED_SLP_RUN_MAX
condition|)
block|{
name|kg
operator|->
name|kg_slptime
operator|=
name|SCHED_SLP_RUN_MAX
expr_stmt|;
name|kg
operator|->
name|kg_runtime
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|kg
operator|->
name|kg_slptime
operator|+=
name|hzticks
expr_stmt|;
name|sched_interact_update
argument_list|(
name|kg
argument_list|)
expr_stmt|;
block|}
name|sched_priority
argument_list|(
name|kg
argument_list|)
expr_stmt|;
name|sched_slice
argument_list|(
name|td
operator|->
name|td_kse
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_ULE
argument_list|,
literal|"wakeup thread %p (%d ticks)"
argument_list|,
name|td
argument_list|,
name|hzticks
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_slptime
operator|=
literal|0
expr_stmt|;
block|}
name|setrunqueue
argument_list|(
name|td
argument_list|,
name|SRQ_BORING
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Penalize the parent for creating a new child and initialize the child's  * priority.  */
end_comment

begin_function
name|void
name|sched_fork
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|childtd
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|sched_fork_ksegrp
argument_list|(
name|td
argument_list|,
name|childtd
operator|->
name|td_ksegrp
argument_list|)
expr_stmt|;
name|sched_fork_thread
argument_list|(
name|td
argument_list|,
name|childtd
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_fork_ksegrp
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|ksegrp
modifier|*
name|child
parameter_list|)
block|{
name|struct
name|ksegrp
modifier|*
name|kg
init|=
name|td
operator|->
name|td_ksegrp
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|child
operator|->
name|kg_slptime
operator|=
name|kg
operator|->
name|kg_slptime
expr_stmt|;
name|child
operator|->
name|kg_runtime
operator|=
name|kg
operator|->
name|kg_runtime
expr_stmt|;
name|child
operator|->
name|kg_user_pri
operator|=
name|kg
operator|->
name|kg_user_pri
expr_stmt|;
name|sched_interact_fork
argument_list|(
name|child
argument_list|)
expr_stmt|;
name|kg
operator|->
name|kg_runtime
operator|+=
name|tickincr
operator|<<
literal|10
expr_stmt|;
name|sched_interact_update
argument_list|(
name|kg
argument_list|)
expr_stmt|;
name|CTR6
argument_list|(
name|KTR_ULE
argument_list|,
literal|"sched_fork_ksegrp: %d(%d, %d) - %d(%d, %d)"
argument_list|,
name|kg
operator|->
name|kg_proc
operator|->
name|p_pid
argument_list|,
name|kg
operator|->
name|kg_slptime
argument_list|,
name|kg
operator|->
name|kg_runtime
argument_list|,
name|child
operator|->
name|kg_proc
operator|->
name|p_pid
argument_list|,
name|child
operator|->
name|kg_slptime
argument_list|,
name|child
operator|->
name|kg_runtime
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_fork_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|child
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke2
decl_stmt|;
name|sched_newthread
argument_list|(
name|child
argument_list|)
expr_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|ke2
operator|=
name|child
operator|->
name|td_kse
expr_stmt|;
name|ke2
operator|->
name|ke_slice
operator|=
literal|1
expr_stmt|;
comment|/* Attempt to quickly learn interactivity. */
name|ke2
operator|->
name|ke_cpu
operator|=
name|ke
operator|->
name|ke_cpu
expr_stmt|;
name|ke2
operator|->
name|ke_runq
operator|=
name|NULL
expr_stmt|;
comment|/* Grab our parents cpu estimation information. */
name|ke2
operator|->
name|ke_ticks
operator|=
name|ke
operator|->
name|ke_ticks
expr_stmt|;
name|ke2
operator|->
name|ke_ltick
operator|=
name|ke
operator|->
name|ke_ltick
expr_stmt|;
name|ke2
operator|->
name|ke_ftick
operator|=
name|ke
operator|->
name|ke_ftick
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_class
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|,
name|int
name|class
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|int
name|nclass
decl_stmt|;
name|int
name|oclass
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|kg
operator|->
name|kg_pri_class
operator|==
name|class
condition|)
return|return;
name|nclass
operator|=
name|PRI_BASE
argument_list|(
name|class
argument_list|)
expr_stmt|;
name|oclass
operator|=
name|PRI_BASE
argument_list|(
name|kg
operator|->
name|kg_pri_class
argument_list|)
expr_stmt|;
name|FOREACH_THREAD_IN_GROUP
argument_list|(
argument|kg
argument_list|,
argument|td
argument_list|)
block|{
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
if|if
condition|(
name|ke
operator|->
name|ke_state
operator|!=
name|KES_ONRUNQ
operator|&&
name|ke
operator|->
name|ke_state
operator|!=
name|KES_THREAD
condition|)
continue|continue;
name|kseq
operator|=
name|KSEQ_CPU
argument_list|(
name|ke
operator|->
name|ke_cpu
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
comment|/* 		 * On SMP if we're on the RUNQ we must adjust the transferable 		 * count because could be changing to or from an interrupt 		 * class. 		 */
if|if
condition|(
name|ke
operator|->
name|ke_state
operator|==
name|KES_ONRUNQ
condition|)
block|{
if|if
condition|(
name|KSE_CAN_MIGRATE
argument_list|(
name|ke
argument_list|,
name|oclass
argument_list|)
condition|)
block|{
name|kseq
operator|->
name|ksq_transferable
operator|--
expr_stmt|;
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_transferable
operator|--
expr_stmt|;
block|}
if|if
condition|(
name|KSE_CAN_MIGRATE
argument_list|(
name|ke
argument_list|,
name|nclass
argument_list|)
condition|)
block|{
name|kseq
operator|->
name|ksq_transferable
operator|++
expr_stmt|;
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_transferable
operator|++
expr_stmt|;
block|}
block|}
endif|#
directive|endif
if|if
condition|(
name|oclass
operator|==
name|PRI_TIMESHARE
condition|)
block|{
name|kseq
operator|->
name|ksq_load_timeshare
operator|--
expr_stmt|;
name|kseq_nice_rem
argument_list|(
name|kseq
argument_list|,
name|kg
operator|->
name|kg_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|nclass
operator|==
name|PRI_TIMESHARE
condition|)
block|{
name|kseq
operator|->
name|ksq_load_timeshare
operator|++
expr_stmt|;
name|kseq_nice_add
argument_list|(
name|kseq
argument_list|,
name|kg
operator|->
name|kg_proc
operator|->
name|p_nice
argument_list|)
expr_stmt|;
block|}
block|}
name|kg
operator|->
name|kg_pri_class
operator|=
name|class
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return some of the child's priority and interactivity to the parent.  * Avoid using sched_exit_thread to avoid having to decide which  * thread in the parent gets the honour since it isn't used.  */
end_comment

begin_function
name|void
name|sched_exit
parameter_list|(
name|struct
name|proc
modifier|*
name|p
parameter_list|,
name|struct
name|thread
modifier|*
name|childtd
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|sched_exit_ksegrp
argument_list|(
name|FIRST_KSEGRP_IN_PROC
argument_list|(
name|p
argument_list|)
argument_list|,
name|childtd
argument_list|)
expr_stmt|;
name|kseq_load_rem
argument_list|(
name|KSEQ_CPU
argument_list|(
name|childtd
operator|->
name|td_kse
operator|->
name|ke_cpu
argument_list|)
argument_list|,
name|childtd
operator|->
name|td_kse
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_exit_ksegrp
parameter_list|(
name|struct
name|ksegrp
modifier|*
name|kg
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
comment|/* kg->kg_slptime += td->td_ksegrp->kg_slptime; */
name|kg
operator|->
name|kg_runtime
operator|+=
name|td
operator|->
name|td_ksegrp
operator|->
name|kg_runtime
expr_stmt|;
name|sched_interact_update
argument_list|(
name|kg
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_exit_thread
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|thread
modifier|*
name|childtd
parameter_list|)
block|{
name|kseq_load_rem
argument_list|(
name|KSEQ_CPU
argument_list|(
name|childtd
operator|->
name|td_kse
operator|->
name|ke_cpu
argument_list|)
argument_list|,
name|childtd
operator|->
name|td_kse
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_clock
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|kseq
operator|=
name|KSEQ_SELF
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|ticks
operator|==
name|bal_tick
condition|)
name|sched_balance
argument_list|()
expr_stmt|;
if|if
condition|(
name|ticks
operator|==
name|gbal_tick
condition|)
name|sched_balance_groups
argument_list|()
expr_stmt|;
comment|/* 	 * We could have been assigned a non real-time thread without an 	 * IPI. 	 */
if|if
condition|(
name|kseq
operator|->
name|ksq_assigned
condition|)
name|kseq_assign
argument_list|(
name|kseq
argument_list|)
expr_stmt|;
comment|/* Potentially sets NEEDRESCHED */
endif|#
directive|endif
comment|/* 	 * sched_setup() apparently happens prior to stathz being set.  We 	 * need to resolve the timers earlier in the boot so we can avoid 	 * calculating this here. 	 */
if|if
condition|(
name|realstathz
operator|==
literal|0
condition|)
block|{
name|realstathz
operator|=
name|stathz
condition|?
name|stathz
else|:
name|hz
expr_stmt|;
name|tickincr
operator|=
name|hz
operator|/
name|realstathz
expr_stmt|;
comment|/* 		 * XXX This does not work for values of stathz that are much 		 * larger than hz. 		 */
if|if
condition|(
name|tickincr
operator|==
literal|0
condition|)
name|tickincr
operator|=
literal|1
expr_stmt|;
block|}
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|kg
operator|=
name|ke
operator|->
name|ke_ksegrp
expr_stmt|;
comment|/* Adjust ticks for pctcpu */
name|ke
operator|->
name|ke_ticks
operator|++
expr_stmt|;
name|ke
operator|->
name|ke_ltick
operator|=
name|ticks
expr_stmt|;
comment|/* Go up to one second beyond our max and then trim back down */
if|if
condition|(
name|ke
operator|->
name|ke_ftick
operator|+
name|SCHED_CPU_TICKS
operator|+
name|hz
operator|<
name|ke
operator|->
name|ke_ltick
condition|)
name|sched_pctcpu_update
argument_list|(
name|ke
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_IDLETD
condition|)
return|return;
name|CTR4
argument_list|(
name|KTR_ULE
argument_list|,
literal|"Tick thread %p (slice: %d, slptime: %d, runtime: %d)"
argument_list|,
name|td
argument_list|,
name|ke
operator|->
name|ke_slice
argument_list|,
name|kg
operator|->
name|kg_slptime
operator|>>
literal|10
argument_list|,
name|kg
operator|->
name|kg_runtime
operator|>>
literal|10
argument_list|)
expr_stmt|;
comment|/* 	 * We only do slicing code for TIMESHARE ksegrps. 	 */
if|if
condition|(
name|kg
operator|->
name|kg_pri_class
operator|!=
name|PRI_TIMESHARE
condition|)
return|return;
comment|/* 	 * We used a tick charge it to the ksegrp so that we can compute our 	 * interactivity. 	 */
name|kg
operator|->
name|kg_runtime
operator|+=
name|tickincr
operator|<<
literal|10
expr_stmt|;
name|sched_interact_update
argument_list|(
name|kg
argument_list|)
expr_stmt|;
comment|/* 	 * We used up one time slice. 	 */
if|if
condition|(
operator|--
name|ke
operator|->
name|ke_slice
operator|>
literal|0
condition|)
return|return;
comment|/* 	 * We're out of time, recompute priorities and requeue. 	 */
name|kseq_load_rem
argument_list|(
name|kseq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|sched_priority
argument_list|(
name|kg
argument_list|)
expr_stmt|;
name|sched_slice
argument_list|(
name|ke
argument_list|)
expr_stmt|;
if|if
condition|(
name|SCHED_CURR
argument_list|(
name|kg
argument_list|,
name|ke
argument_list|)
condition|)
name|ke
operator|->
name|ke_runq
operator|=
name|kseq
operator|->
name|ksq_curr
expr_stmt|;
else|else
name|ke
operator|->
name|ke_runq
operator|=
name|kseq
operator|->
name|ksq_next
expr_stmt|;
name|kseq_load_add
argument_list|(
name|kseq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
block|}
end_function

begin_function
name|int
name|sched_runnable
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|int
name|load
decl_stmt|;
name|load
operator|=
literal|1
expr_stmt|;
name|kseq
operator|=
name|KSEQ_SELF
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|kseq
operator|->
name|ksq_assigned
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|kseq_assign
argument_list|(
name|kseq
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
if|if
condition|(
operator|(
name|curthread
operator|->
name|td_flags
operator|&
name|TDF_IDLETD
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|kseq
operator|->
name|ksq_load
operator|>
literal|0
condition|)
goto|goto
name|out
goto|;
block|}
elseif|else
if|if
condition|(
name|kseq
operator|->
name|ksq_load
operator|-
literal|1
operator|>
literal|0
condition|)
goto|goto
name|out
goto|;
name|load
operator|=
literal|0
expr_stmt|;
name|out
label|:
return|return
operator|(
name|load
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_userret
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|kg
operator|=
name|td
operator|->
name|td_ksegrp
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_priority
operator|!=
name|kg
operator|->
name|kg_user_pri
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_priority
operator|=
name|kg
operator|->
name|kg_user_pri
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|struct
name|kse
modifier|*
name|sched_choose
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|kseq
operator|=
name|KSEQ_SELF
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|restart
label|:
if|if
condition|(
name|kseq
operator|->
name|ksq_assigned
condition|)
name|kseq_assign
argument_list|(
name|kseq
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|ke
operator|=
name|kseq_choose
argument_list|(
name|kseq
argument_list|)
expr_stmt|;
if|if
condition|(
name|ke
condition|)
block|{
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_pri_class
operator|==
name|PRI_IDLE
condition|)
if|if
condition|(
name|kseq_idled
argument_list|(
name|kseq
argument_list|)
operator|==
literal|0
condition|)
goto|goto
name|restart
goto|;
endif|#
directive|endif
name|kseq_runq_rem
argument_list|(
name|kseq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_state
operator|=
name|KES_THREAD
expr_stmt|;
if|if
condition|(
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_pri_class
operator|==
name|PRI_TIMESHARE
condition|)
block|{
name|CTR4
argument_list|(
name|KTR_ULE
argument_list|,
literal|"Run thread %p from %p (slice: %d, pri: %d)"
argument_list|,
name|ke
operator|->
name|ke_thread
argument_list|,
name|ke
operator|->
name|ke_runq
argument_list|,
name|ke
operator|->
name|ke_slice
argument_list|,
name|ke
operator|->
name|ke_thread
operator|->
name|td_priority
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|ke
operator|)
return|;
block|}
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|kseq_idled
argument_list|(
name|kseq
argument_list|)
operator|==
literal|0
condition|)
goto|goto
name|restart
goto|;
endif|#
directive|endif
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_add
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
comment|/* let jeff work out how to map the flags better */
comment|/* I'm open to suggestions */
if|if
condition|(
name|flags
operator|&
name|SRQ_YIELDING
condition|)
comment|/* 		 * Preempting during switching can be bad JUJU 		 * especially for KSE processes 		 */
name|sched_add_internal
argument_list|(
name|td
argument_list|,
literal|0
argument_list|)
expr_stmt|;
else|else
name|sched_add_internal
argument_list|(
name|td
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sched_add_internal
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|preemptive
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|struct
name|ksegrp
modifier|*
name|kg
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|int
name|canmigrate
decl_stmt|;
endif|#
directive|endif
name|int
name|class
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|kg
operator|=
name|td
operator|->
name|td_ksegrp
expr_stmt|;
if|if
condition|(
name|ke
operator|->
name|ke_flags
operator|&
name|KEF_ASSIGNED
condition|)
return|return;
name|kseq
operator|=
name|KSEQ_SELF
argument_list|()
expr_stmt|;
name|KASSERT
argument_list|(
name|ke
operator|->
name|ke_state
operator|!=
name|KES_ONRUNQ
argument_list|,
operator|(
literal|"sched_add: kse %p (%s) already in run queue"
operator|,
name|ke
operator|,
name|ke
operator|->
name|ke_proc
operator|->
name|p_comm
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|ke
operator|->
name|ke_proc
operator|->
name|p_sflag
operator|&
name|PS_INMEM
argument_list|,
operator|(
literal|"sched_add: process swapped out"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|ke
operator|->
name|ke_runq
operator|==
name|NULL
argument_list|,
operator|(
literal|"sched_add: KSE %p is still assigned to a run queue"
operator|,
name|ke
operator|)
argument_list|)
expr_stmt|;
name|class
operator|=
name|PRI_BASE
argument_list|(
name|kg
operator|->
name|kg_pri_class
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|class
condition|)
block|{
case|case
name|PRI_ITHD
case|:
case|case
name|PRI_REALTIME
case|:
name|ke
operator|->
name|ke_runq
operator|=
name|kseq
operator|->
name|ksq_curr
expr_stmt|;
name|ke
operator|->
name|ke_slice
operator|=
name|SCHED_SLICE_MAX
expr_stmt|;
name|ke
operator|->
name|ke_cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
break|break;
case|case
name|PRI_TIMESHARE
case|:
if|if
condition|(
name|SCHED_CURR
argument_list|(
name|kg
argument_list|,
name|ke
argument_list|)
condition|)
name|ke
operator|->
name|ke_runq
operator|=
name|kseq
operator|->
name|ksq_curr
expr_stmt|;
else|else
name|ke
operator|->
name|ke_runq
operator|=
name|kseq
operator|->
name|ksq_next
expr_stmt|;
break|break;
case|case
name|PRI_IDLE
case|:
comment|/* 		 * This is for priority prop. 		 */
if|if
condition|(
name|ke
operator|->
name|ke_thread
operator|->
name|td_priority
operator|<
name|PRI_MIN_IDLE
condition|)
name|ke
operator|->
name|ke_runq
operator|=
name|kseq
operator|->
name|ksq_curr
expr_stmt|;
else|else
name|ke
operator|->
name|ke_runq
operator|=
operator|&
name|kseq
operator|->
name|ksq_idle
expr_stmt|;
name|ke
operator|->
name|ke_slice
operator|=
name|SCHED_SLICE_MIN
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"Unknown pri class."
argument_list|)
expr_stmt|;
break|break;
block|}
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * Don't migrate running threads here.  Force the long term balancer 	 * to do it. 	 */
name|canmigrate
operator|=
name|KSE_CAN_MIGRATE
argument_list|(
name|ke
argument_list|,
name|class
argument_list|)
expr_stmt|;
if|if
condition|(
name|ke
operator|->
name|ke_flags
operator|&
name|KEF_HOLD
condition|)
block|{
name|ke
operator|->
name|ke_flags
operator|&=
operator|~
name|KEF_HOLD
expr_stmt|;
name|canmigrate
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * If this thread is pinned or bound, notify the target cpu. 	 */
if|if
condition|(
operator|!
name|canmigrate
operator|&&
name|ke
operator|->
name|ke_cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
block|{
name|ke
operator|->
name|ke_runq
operator|=
name|NULL
expr_stmt|;
name|kseq_notify
argument_list|(
name|ke
argument_list|,
name|ke
operator|->
name|ke_cpu
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * If we had been idle, clear our bit in the group and potentially 	 * the global bitmap.  If not, see if we should transfer this thread. 	 */
if|if
condition|(
operator|(
name|class
operator|==
name|PRI_TIMESHARE
operator|||
name|class
operator|==
name|PRI_REALTIME
operator|)
operator|&&
operator|(
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_idlemask
operator|&
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * Check to see if our group is unidling, and if so, remove it 		 * from the global idle mask. 		 */
if|if
condition|(
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_idlemask
operator|==
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_cpumask
condition|)
name|atomic_clear_int
argument_list|(
operator|&
name|kseq_idle
argument_list|,
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_mask
argument_list|)
expr_stmt|;
comment|/* 		 * Now remove ourselves from the group specific idle mask. 		 */
name|kseq
operator|->
name|ksq_group
operator|->
name|ksg_idlemask
operator|&=
operator|~
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|kseq
operator|->
name|ksq_load
operator|>
literal|1
operator|&&
name|canmigrate
condition|)
if|if
condition|(
name|kseq_transfer
argument_list|(
name|kseq
argument_list|,
name|ke
argument_list|,
name|class
argument_list|)
condition|)
return|return;
name|ke
operator|->
name|ke_cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * XXX With preemption this is not necessary. 	 */
if|if
condition|(
name|td
operator|->
name|td_priority
operator|<
name|curthread
operator|->
name|td_priority
operator|&&
name|ke
operator|->
name|ke_runq
operator|==
name|kseq
operator|->
name|ksq_curr
condition|)
name|curthread
operator|->
name|td_flags
operator||=
name|TDF_NEEDRESCHED
expr_stmt|;
if|if
condition|(
name|preemptive
operator|&&
name|maybe_preempt
argument_list|(
name|td
argument_list|)
condition|)
return|return;
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_runq_threads
operator|++
expr_stmt|;
name|ke
operator|->
name|ke_state
operator|=
name|KES_ONRUNQ
expr_stmt|;
name|kseq_runq_add
argument_list|(
name|kseq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|kseq_load_add
argument_list|(
name|kseq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sched_rem
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|struct
name|kseq
modifier|*
name|kseq
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
comment|/* 	 * It is safe to just return here because sched_rem() is only ever 	 * used in places where we're immediately going to add the 	 * kse back on again.  In that case it'll be added with the correct 	 * thread and priority when the caller drops the sched_lock. 	 */
if|if
condition|(
name|ke
operator|->
name|ke_flags
operator|&
name|KEF_ASSIGNED
condition|)
return|return;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|ke
operator|->
name|ke_state
operator|==
name|KES_ONRUNQ
operator|)
argument_list|,
operator|(
literal|"sched_rem: KSE not on run queue"
operator|)
argument_list|)
expr_stmt|;
name|ke
operator|->
name|ke_state
operator|=
name|KES_THREAD
expr_stmt|;
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_runq_threads
operator|--
expr_stmt|;
name|kseq
operator|=
name|KSEQ_CPU
argument_list|(
name|ke
operator|->
name|ke_cpu
argument_list|)
expr_stmt|;
name|kseq_runq_rem
argument_list|(
name|kseq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|kseq_load_rem
argument_list|(
name|kseq
argument_list|,
name|ke
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|fixpt_t
name|sched_pctcpu
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|fixpt_t
name|pctcpu
decl_stmt|;
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|pctcpu
operator|=
literal|0
expr_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
if|if
condition|(
name|ke
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|ke
operator|->
name|ke_ticks
condition|)
block|{
name|int
name|rtick
decl_stmt|;
comment|/* 		 * Don't update more frequently than twice a second.  Allowing 		 * this causes the cpu usage to decay away too quickly due to 		 * rounding errors. 		 */
if|if
condition|(
name|ke
operator|->
name|ke_ftick
operator|+
name|SCHED_CPU_TICKS
operator|<
name|ke
operator|->
name|ke_ltick
operator|||
name|ke
operator|->
name|ke_ltick
operator|<
operator|(
name|ticks
operator|-
operator|(
name|hz
operator|/
literal|2
operator|)
operator|)
condition|)
name|sched_pctcpu_update
argument_list|(
name|ke
argument_list|)
expr_stmt|;
comment|/* How many rtick per second ? */
name|rtick
operator|=
name|min
argument_list|(
name|ke
operator|->
name|ke_ticks
operator|/
name|SCHED_CPU_TIME
argument_list|,
name|SCHED_CPU_TICKS
argument_list|)
expr_stmt|;
name|pctcpu
operator|=
operator|(
name|FSCALE
operator|*
operator|(
operator|(
name|FSCALE
operator|*
name|rtick
operator|)
operator|/
name|realstathz
operator|)
operator|)
operator|>>
name|FSHIFT
expr_stmt|;
block|}
name|ke
operator|->
name|ke_proc
operator|->
name|p_swtime
operator|=
name|ke
operator|->
name|ke_ltick
operator|-
name|ke
operator|->
name|ke_ftick
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|pctcpu
operator|)
return|;
block|}
end_function

begin_function
name|void
name|sched_bind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|cpu
parameter_list|)
block|{
name|struct
name|kse
modifier|*
name|ke
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|ke
operator|=
name|td
operator|->
name|td_kse
expr_stmt|;
name|ke
operator|->
name|ke_flags
operator||=
name|KEF_BOUND
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
operator|==
name|cpu
condition|)
return|return;
comment|/* sched_rem without the runq_remove */
name|ke
operator|->
name|ke_state
operator|=
name|KES_THREAD
expr_stmt|;
name|ke
operator|->
name|ke_ksegrp
operator|->
name|kg_runq_threads
operator|--
expr_stmt|;
name|kseq_load_rem
argument_list|(
name|KSEQ_CPU
argument_list|(
name|ke
operator|->
name|ke_cpu
argument_list|)
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|kseq_notify
argument_list|(
name|ke
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
comment|/* When we return from mi_switch we'll be on the correct cpu. */
name|mi_switch
argument_list|(
name|SW_VOL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|sched_unbind
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|sched_lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_kse
operator|->
name|ke_flags
operator|&=
operator|~
name|KEF_BOUND
expr_stmt|;
block|}
end_function

begin_function
name|int
name|sched_load
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|int
name|total
decl_stmt|;
name|int
name|i
decl_stmt|;
name|total
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|ksg_maxid
condition|;
name|i
operator|++
control|)
name|total
operator|+=
name|KSEQ_GROUP
argument_list|(
name|i
argument_list|)
operator|->
name|ksg_load
expr_stmt|;
return|return
operator|(
name|total
operator|)
return|;
else|#
directive|else
return|return
operator|(
name|KSEQ_SELF
argument_list|()
operator|->
name|ksq_sysload
operator|)
return|;
endif|#
directive|endif
block|}
end_function

begin_function
name|int
name|sched_sizeof_ksegrp
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|ksegrp
argument_list|)
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|kg_sched
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_sizeof_proc
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|proc
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|int
name|sched_sizeof_thread
parameter_list|(
name|void
parameter_list|)
block|{
return|return
operator|(
sizeof|sizeof
argument_list|(
expr|struct
name|thread
argument_list|)
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|td_sched
argument_list|)
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|KERN_SWITCH_INCLUDE
value|1
end_define

begin_include
include|#
directive|include
file|"kern/kern_switch.c"
end_include

end_unit

