begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1991 Regents of the University of California.  * Copyright (c) 1994 John S. Dyson  * Copyright (c) 1994 David Greenman  * Copyright (c) 2005-2010 Alan L. Cox<alc@cs.rice.edu>  * Copyright (c) 2014-2016 Svatopluk Kraus<skra@FreeBSD.org>  * Copyright (c) 2014-2016 Michal Meloun<mmel@FreeBSD.org>  * All rights reserved.  *  * This code is derived from software contributed to Berkeley by  * the Systems Programming Group of the University of Utah Computer  * Science Department and William Jolitz of UUNET Technologies Inc.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from:	@(#)pmap.c	7.7 (Berkeley)	5/12/91  */
end_comment

begin_comment
comment|/*-  * Copyright (c) 2003 Networks Associates Technology, Inc.  * All rights reserved.  *  * This software was developed for the FreeBSD Project by Jake Burkholder,  * Safeport Network Services, and Network Associates Laboratories, the  * Security Research Division of Network Associates, Inc. under  * DARPA/SPAWAR contract N66001-01-C-8035 ("CBOSS"), as part of the DARPA  * CHATS research program.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *	Manages physical address maps.  *  *	Since the information managed by this module is  *	also stored by the logical address mapping module,  *	this module may throw away valid virtual-to-physical  *	mappings at almost any time.  However, invalidations  *	of virtual-to-physical mappings must be done as  *	requested.  *  *	In order to cope with hardware architectures which  *	make virtual-to-physical map invalidates expensive,  *	this module may delay invalidate or reduced protection  *	operations until such time as they are actually  *	necessary.  This module is given full information as  *	to which processors are currently using which maps,  *	and to when physical maps must be made correct.  */
end_comment

begin_include
include|#
directive|include
file|"opt_vm.h"
end_include

begin_include
include|#
directive|include
file|"opt_pmap.h"
end_include

begin_include
include|#
directive|include
file|"opt_ddb.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mman.h>
end_include

begin_include
include|#
directive|include
file|<sys/sf_buf.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_include
include|#
directive|include
file|<ddb/ddb.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|<machine/physmem.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<vm/pmap.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_phys.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_reserv.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_include
include|#
directive|include
file|<machine/pmap_var.h>
end_include

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/pcb.h>
end_include

begin_include
include|#
directive|include
file|<machine/sf_buf.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_ifndef
ifndef|#
directive|ifndef
name|PMAP_SHPGPERPROC
end_ifndef

begin_define
define|#
directive|define
name|PMAP_SHPGPERPROC
value|200
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifndef
ifndef|#
directive|ifndef
name|DIAGNOSTIC
end_ifndef

begin_define
define|#
directive|define
name|PMAP_INLINE
value|__inline
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PMAP_INLINE
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|PMAP_DEBUG
end_ifdef

begin_function_decl
specifier|static
name|void
name|pmap_zero_page_check
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|pmap_debug
parameter_list|(
name|int
name|level
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|int
name|pmap_pid_dump
parameter_list|(
name|int
name|pid
parameter_list|)
function_decl|;
end_function_decl

begin_define
define|#
directive|define
name|PDEBUG
parameter_list|(
name|_lev_
parameter_list|,
name|_stat_
parameter_list|)
define|\
value|if (pmap_debug_level>= (_lev_)) \ 		((_stat_))
end_define

begin_define
define|#
directive|define
name|dprintf
value|printf
end_define

begin_decl_stmt
name|int
name|pmap_debug_level
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* PMAP_DEBUG */
end_comment

begin_define
define|#
directive|define
name|PDEBUG
parameter_list|(
name|_lev_
parameter_list|,
name|_stat_
parameter_list|)
end_define

begin_comment
comment|/* Nothing */
end_comment

begin_define
define|#
directive|define
name|dprintf
parameter_list|(
name|x
parameter_list|,
name|arg
modifier|...
parameter_list|)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* PMAP_DEBUG */
end_comment

begin_comment
comment|/*  *  Level 2 page tables map definion ('max' is excluded).  */
end_comment

begin_define
define|#
directive|define
name|PT2V_MIN_ADDRESS
value|((vm_offset_t)PT2MAP)
end_define

begin_define
define|#
directive|define
name|PT2V_MAX_ADDRESS
value|((vm_offset_t)PT2MAP + PT2MAP_SIZE)
end_define

begin_define
define|#
directive|define
name|UPT2V_MIN_ADDRESS
value|((vm_offset_t)PT2MAP)
end_define

begin_define
define|#
directive|define
name|UPT2V_MAX_ADDRESS
define|\
value|((vm_offset_t)(PT2MAP + (KERNBASE>> PT2MAP_SHIFT)))
end_define

begin_comment
comment|/*  *  Promotion to a 1MB (PTE1) page mapping requires that the corresponding  *  4KB (PTE2) page mappings have identical settings for the following fields:  */
end_comment

begin_define
define|#
directive|define
name|PTE2_PROMOTE
value|(PTE2_V | PTE2_A | PTE2_NM | PTE2_S | PTE2_NG |	\ 			 PTE2_NX | PTE2_RO | PTE2_U | PTE2_W |		\ 			 PTE2_ATTR_MASK)
end_define

begin_define
define|#
directive|define
name|PTE1_PROMOTE
value|(PTE1_V | PTE1_A | PTE1_NM | PTE1_S | PTE1_NG |	\ 			 PTE1_NX | PTE1_RO | PTE1_U | PTE1_W |		\ 			 PTE1_ATTR_MASK)
end_define

begin_define
define|#
directive|define
name|ATTR_TO_L1
parameter_list|(
name|l2_attr
parameter_list|)
value|((((l2_attr)& L2_TEX0) ? L1_S_TEX0 : 0) | \ 				 (((l2_attr)& L2_C)    ? L1_S_C    : 0) | \ 				 (((l2_attr)& L2_B)    ? L1_S_B    : 0) | \ 				 (((l2_attr)& PTE2_A)  ? PTE1_A    : 0) | \ 				 (((l2_attr)& PTE2_NM) ? PTE1_NM   : 0) | \ 				 (((l2_attr)& PTE2_S)  ? PTE1_S    : 0) | \ 				 (((l2_attr)& PTE2_NG) ? PTE1_NG   : 0) | \ 				 (((l2_attr)& PTE2_NX) ? PTE1_NX   : 0) | \ 				 (((l2_attr)& PTE2_RO) ? PTE1_RO   : 0) | \ 				 (((l2_attr)& PTE2_U)  ? PTE1_U    : 0) | \ 				 (((l2_attr)& PTE2_W)  ? PTE1_W    : 0))
end_define

begin_define
define|#
directive|define
name|ATTR_TO_L2
parameter_list|(
name|l1_attr
parameter_list|)
value|((((l1_attr)& L1_S_TEX0) ? L2_TEX0 : 0) | \ 				 (((l1_attr)& L1_S_C)    ? L2_C    : 0) | \ 				 (((l1_attr)& L1_S_B)    ? L2_B    : 0) | \ 				 (((l1_attr)& PTE1_A)    ? PTE2_A  : 0) | \ 				 (((l1_attr)& PTE1_NM)   ? PTE2_NM : 0) | \ 				 (((l1_attr)& PTE1_S)    ? PTE2_S  : 0) | \ 				 (((l1_attr)& PTE1_NG)   ? PTE2_NG : 0) | \ 				 (((l1_attr)& PTE1_NX)   ? PTE2_NX : 0) | \ 				 (((l1_attr)& PTE1_RO)   ? PTE2_RO : 0) | \ 				 (((l1_attr)& PTE1_U)    ? PTE2_U  : 0) | \ 				 (((l1_attr)& PTE1_W)    ? PTE2_W  : 0))
end_define

begin_comment
comment|/*  *  PTE2 descriptors creation macros.  */
end_comment

begin_define
define|#
directive|define
name|PTE2_ATTR_DEFAULT
value|vm_memattr_to_pte2(VM_MEMATTR_DEFAULT)
end_define

begin_define
define|#
directive|define
name|PTE2_ATTR_PT
value|vm_memattr_to_pte2(pt_memattr)
end_define

begin_define
define|#
directive|define
name|PTE2_KPT
parameter_list|(
name|pa
parameter_list|)
value|PTE2_KERN(pa, PTE2_AP_KRW, PTE2_ATTR_PT)
end_define

begin_define
define|#
directive|define
name|PTE2_KPT_NG
parameter_list|(
name|pa
parameter_list|)
value|PTE2_KERN_NG(pa, PTE2_AP_KRW, PTE2_ATTR_PT)
end_define

begin_define
define|#
directive|define
name|PTE2_KRW
parameter_list|(
name|pa
parameter_list|)
value|PTE2_KERN(pa, PTE2_AP_KRW, PTE2_ATTR_DEFAULT)
end_define

begin_define
define|#
directive|define
name|PTE2_KRO
parameter_list|(
name|pa
parameter_list|)
value|PTE2_KERN(pa, PTE2_AP_KR, PTE2_ATTR_DEFAULT)
end_define

begin_define
define|#
directive|define
name|PV_STATS
end_define

begin_ifdef
ifdef|#
directive|ifdef
name|PV_STATS
end_ifdef

begin_define
define|#
directive|define
name|PV_STAT
parameter_list|(
name|x
parameter_list|)
value|do { x ; } while (0)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PV_STAT
parameter_list|(
name|x
parameter_list|)
value|do { } while (0)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  *  The boot_pt1 is used temporary in very early boot stage as L1 page table.  *  We can init many things with no memory allocation thanks to its static  *  allocation and this brings two main advantages:  *  (1) other cores can be started very simply,  *  (2) various boot loaders can be supported as its arguments can be processed  *      in virtual address space and can be moved to safe location before  *      first allocation happened.  *  Only disadvantage is that boot_pt1 is used only in very early boot stage.  *  However, the table is uninitialized and so lays in bss. Therefore kernel  *  image size is not influenced.  *  *  QQQ: In the future, maybe, boot_pt1 can be used for soft reset and  *       CPU suspend/resume game.  */
end_comment

begin_decl_stmt
specifier|extern
name|pt1_entry_t
name|boot_pt1
index|[]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_paddr_t
name|base_pt1
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|pt1_entry_t
modifier|*
name|kern_pt1
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|pt2_entry_t
modifier|*
name|kern_pt2tab
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|pt2_entry_t
modifier|*
name|PT2MAP
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|uint32_t
name|ttb_flags
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|vm_memattr_t
name|pt_memattr
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|ttb_entry_t
name|pmap_kern_ttb
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|pmap
name|kernel_pmap_store
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|LIST_HEAD
argument_list|(
name|pmaplist
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|pmaplist
name|allpmaps
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|allpmaps_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|virtual_avail
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* VA of first avail page (after kernel bss) */
end_comment

begin_decl_stmt
name|vm_offset_t
name|virtual_end
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* VA of last avail page (end of kernel AS) */
end_comment

begin_decl_stmt
specifier|static
name|vm_offset_t
name|kernel_vm_end_new
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|kernel_vm_end
init|=
name|KERNBASE
operator|+
name|NKPT2PG
operator|*
name|NPT2_IN_PG
operator|*
name|PTE1_SIZE
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|vm_max_kernel_address
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_paddr_t
name|kernel_l1pa
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|rwlock
name|__aligned
argument_list|(
name|CACHE_LINE_SIZE
argument_list|)
name|pvh_global_lock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  *  Data for the pv entry allocation mechanism  */
end_comment

begin_expr_stmt
specifier|static
name|TAILQ_HEAD
argument_list|(
argument|pch
argument_list|,
argument|pv_chunk
argument_list|)
name|pv_chunks
operator|=
name|TAILQ_HEAD_INITIALIZER
argument_list|(
name|pv_chunks
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pv_entry_count
init|=
literal|0
decl_stmt|,
name|pv_entry_max
init|=
literal|0
decl_stmt|,
name|pv_entry_high_water
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|md_page
modifier|*
name|pv_table
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* XXX: Is it used only the list in md_page? */
end_comment

begin_decl_stmt
specifier|static
name|int
name|shpgperproc
init|=
name|PMAP_SHPGPERPROC
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|pv_chunk
modifier|*
name|pv_chunkbase
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* KVA block for pv_chunks */
end_comment

begin_decl_stmt
name|int
name|pv_maxchunks
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* How many chunks we have KVA for */
end_comment

begin_decl_stmt
name|vm_offset_t
name|pv_vafree
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* freelist stored in the PTE */
end_comment

begin_decl_stmt
name|vm_paddr_t
name|first_managed_pa
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|pa_to_pvh
parameter_list|(
name|pa
parameter_list|)
value|(&pv_table[pte1_index(pa - first_managed_pa)])
end_define

begin_comment
comment|/*  *  All those kernel PT submaps that BSD is so fond of  */
end_comment

begin_decl_stmt
name|caddr_t
name|_tmppt
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|msgbuf
modifier|*
name|msgbufp
init|=
name|NULL
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* XXX move it to machdep.c */
end_comment

begin_comment
comment|/*  *  Crashdump maps.  */
end_comment

begin_decl_stmt
specifier|static
name|caddr_t
name|crashdumpmap
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|pt2_entry_t
modifier|*
name|PMAP1
init|=
name|NULL
decl_stmt|,
modifier|*
name|PMAP2
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|pt2_entry_t
modifier|*
name|PADDR1
init|=
name|NULL
decl_stmt|,
modifier|*
name|PADDR2
decl_stmt|;
end_decl_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_decl_stmt
specifier|static
name|pt2_entry_t
modifier|*
name|PMAP3
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|pt2_entry_t
modifier|*
name|PADDR3
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|PMAP3cpu
name|__unused
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* for SMP only */
end_comment

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_decl_stmt
specifier|static
name|int
name|PMAP1cpu
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|PMAP1changedcpu
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_debug
argument_list|,
name|OID_AUTO
argument_list|,
name|PMAP1changedcpu
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|PMAP1changedcpu
argument_list|,
literal|0
argument_list|,
literal|"Number of times pmap_pte2_quick changed CPU with same PMAP1"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|int
name|PMAP1changed
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_debug
argument_list|,
name|OID_AUTO
argument_list|,
name|PMAP1changed
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|PMAP1changed
argument_list|,
literal|0
argument_list|,
literal|"Number of times pmap_pte2_quick changed PMAP1"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|PMAP1unchanged
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_debug
argument_list|,
name|OID_AUTO
argument_list|,
name|PMAP1unchanged
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|PMAP1unchanged
argument_list|,
literal|0
argument_list|,
literal|"Number of times pmap_pte2_quick didn't change PMAP1"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|PMAP2mutex
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|__inline
name|void
name|pt2_wirecount_init
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_demote_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt1_entry_t
modifier|*
name|pte1p
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|cache_icache_sync_fresh
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  *  Function to set the debug level of the pmap code.  */
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|PMAP_DEBUG
end_ifdef

begin_function
name|void
name|pmap_debug
parameter_list|(
name|int
name|level
parameter_list|)
block|{
name|pmap_debug_level
operator|=
name|level
expr_stmt|;
name|dprintf
argument_list|(
literal|"pmap_debug: level=%d\n"
argument_list|,
name|pmap_debug_level
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* PMAP_DEBUG */
end_comment

begin_comment
comment|/*  *  This table must corespond with memory attribute configuration in vm.h.  *  First entry is used for normal system mapping.  *  *  Device memory is always marked as shared.  *  Normal memory is shared only in SMP .  *  Not outer shareable bits are not used yet.  *  Class 6 cannot be used on ARM11.  */
end_comment

begin_define
define|#
directive|define
name|TEXDEF_TYPE_SHIFT
value|0
end_define

begin_define
define|#
directive|define
name|TEXDEF_TYPE_MASK
value|0x3
end_define

begin_define
define|#
directive|define
name|TEXDEF_INNER_SHIFT
value|2
end_define

begin_define
define|#
directive|define
name|TEXDEF_INNER_MASK
value|0x3
end_define

begin_define
define|#
directive|define
name|TEXDEF_OUTER_SHIFT
value|4
end_define

begin_define
define|#
directive|define
name|TEXDEF_OUTER_MASK
value|0x3
end_define

begin_define
define|#
directive|define
name|TEXDEF_NOS_SHIFT
value|6
end_define

begin_define
define|#
directive|define
name|TEXDEF_NOS_MASK
value|0x1
end_define

begin_define
define|#
directive|define
name|TEX
parameter_list|(
name|t
parameter_list|,
name|i
parameter_list|,
name|o
parameter_list|,
name|s
parameter_list|)
define|\
value|((t)<< TEXDEF_TYPE_SHIFT) |	\ 		((i)<< TEXDEF_INNER_SHIFT) |	\ 		((o)<< TEXDEF_OUTER_SHIFT | 	\ 		((s)<< TEXDEF_NOS_SHIFT))
end_define

begin_decl_stmt
specifier|static
name|uint32_t
name|tex_class
index|[
literal|8
index|]
init|=
block|{
comment|/*	    type      inner cache outer cache */
name|TEX
argument_list|(
name|PRRR_MEM
argument_list|,
name|NMRR_WB_WA
argument_list|,
name|NMRR_WB_WA
argument_list|,
literal|0
argument_list|)
block|,
comment|/* 0 - ATTR_WB_WA	*/
name|TEX
argument_list|(
name|PRRR_MEM
argument_list|,
name|NMRR_NC
argument_list|,
name|NMRR_NC
argument_list|,
literal|0
argument_list|)
block|,
comment|/* 1 - ATTR_NOCACHE	*/
name|TEX
argument_list|(
name|PRRR_DEV
argument_list|,
name|NMRR_NC
argument_list|,
name|NMRR_NC
argument_list|,
literal|0
argument_list|)
block|,
comment|/* 2 - ATTR_DEVICE	*/
name|TEX
argument_list|(
name|PRRR_SO
argument_list|,
name|NMRR_NC
argument_list|,
name|NMRR_NC
argument_list|,
literal|0
argument_list|)
block|,
comment|/* 3 - ATTR_SO	*/
name|TEX
argument_list|(
name|PRRR_MEM
argument_list|,
name|NMRR_WT
argument_list|,
name|NMRR_WT
argument_list|,
literal|0
argument_list|)
block|,
comment|/* 4 - ATTR_WT	*/
name|TEX
argument_list|(
name|PRRR_MEM
argument_list|,
name|NMRR_NC
argument_list|,
name|NMRR_NC
argument_list|,
literal|0
argument_list|)
block|,
comment|/* 5 - NOT USED YET	*/
name|TEX
argument_list|(
name|PRRR_MEM
argument_list|,
name|NMRR_NC
argument_list|,
name|NMRR_NC
argument_list|,
literal|0
argument_list|)
block|,
comment|/* 6 - NOT USED YET	*/
name|TEX
argument_list|(
name|PRRR_MEM
argument_list|,
name|NMRR_NC
argument_list|,
name|NMRR_NC
argument_list|,
literal|0
argument_list|)
block|,
comment|/* 7 - NOT USED YET	*/
block|}
decl_stmt|;
end_decl_stmt

begin_undef
undef|#
directive|undef
name|TEX
end_undef

begin_decl_stmt
specifier|static
name|uint32_t
name|pte2_attr_tab
index|[
literal|8
index|]
init|=
block|{
name|PTE2_ATTR_WB_WA
block|,
comment|/* 0 - VM_MEMATTR_WB_WA */
name|PTE2_ATTR_NOCACHE
block|,
comment|/* 1 - VM_MEMATTR_NOCACHE */
name|PTE2_ATTR_DEVICE
block|,
comment|/* 2 - VM_MEMATTR_DEVICE */
name|PTE2_ATTR_SO
block|,
comment|/* 3 - VM_MEMATTR_SO */
name|PTE2_ATTR_WT
block|,
comment|/* 4 - VM_MEMATTR_WRITE_THROUGH */
literal|0
block|,
comment|/* 5 - NOT USED YET */
literal|0
block|,
comment|/* 6 - NOT USED YET */
literal|0
comment|/* 7 - NOT USED YET */
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|VM_MEMATTR_WB_WA
operator|==
literal|0
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|VM_MEMATTR_NOCACHE
operator|==
literal|1
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|VM_MEMATTR_DEVICE
operator|==
literal|2
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|VM_MEMATTR_SO
operator|==
literal|3
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|VM_MEMATTR_WRITE_THROUGH
operator|==
literal|4
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
specifier|inline
name|uint32_t
name|vm_memattr_to_pte2
parameter_list|(
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|u_int
operator|)
name|ma
operator|<
literal|5
argument_list|,
operator|(
literal|"%s: bad vm_memattr_t %d"
operator|,
name|__func__
operator|,
name|ma
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|pte2_attr_tab
index|[
operator|(
name|u_int
operator|)
name|ma
index|]
operator|)
return|;
block|}
end_function

begin_function
specifier|static
specifier|inline
name|uint32_t
name|vm_page_pte2_attr
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
return|return
operator|(
name|vm_memattr_to_pte2
argument_list|(
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Convert TEX definition entry to TTB flags.  */
end_comment

begin_function
specifier|static
name|uint32_t
name|encode_ttb_flags
parameter_list|(
name|int
name|idx
parameter_list|)
block|{
name|uint32_t
name|inner
decl_stmt|,
name|outer
decl_stmt|,
name|nos
decl_stmt|,
name|reg
decl_stmt|;
name|inner
operator|=
operator|(
name|tex_class
index|[
name|idx
index|]
operator|>>
name|TEXDEF_INNER_SHIFT
operator|)
operator|&
name|TEXDEF_INNER_MASK
expr_stmt|;
name|outer
operator|=
operator|(
name|tex_class
index|[
name|idx
index|]
operator|>>
name|TEXDEF_OUTER_SHIFT
operator|)
operator|&
name|TEXDEF_OUTER_MASK
expr_stmt|;
name|nos
operator|=
operator|(
name|tex_class
index|[
name|idx
index|]
operator|>>
name|TEXDEF_NOS_SHIFT
operator|)
operator|&
name|TEXDEF_NOS_MASK
expr_stmt|;
name|reg
operator|=
name|nos
operator|<<
literal|5
expr_stmt|;
name|reg
operator||=
name|outer
operator|<<
literal|3
expr_stmt|;
if|if
condition|(
name|cpuinfo
operator|.
name|coherent_walk
condition|)
name|reg
operator||=
operator|(
name|inner
operator|&
literal|0x1
operator|)
operator|<<
literal|6
expr_stmt|;
name|reg
operator||=
operator|(
name|inner
operator|&
literal|0x2
operator|)
operator|>>
literal|1
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|ARM_SMP_UP
argument_list|(
name|reg
operator||=
literal|1
operator|<<
literal|1
argument_list|, 	)
expr_stmt|;
endif|#
directive|endif
return|return
name|reg
return|;
block|}
end_function

begin_comment
comment|/*  *  Set TEX remapping registers in current CPU.  */
end_comment

begin_function
name|void
name|pmap_set_tex
parameter_list|(
name|void
parameter_list|)
block|{
name|uint32_t
name|prrr
decl_stmt|,
name|nmrr
decl_stmt|;
name|uint32_t
name|type
decl_stmt|,
name|inner
decl_stmt|,
name|outer
decl_stmt|,
name|nos
decl_stmt|;
name|int
name|i
decl_stmt|;
ifdef|#
directive|ifdef
name|PMAP_PTE_NOCACHE
comment|/* XXX fixme */
if|if
condition|(
name|cpuinfo
operator|.
name|coherent_walk
condition|)
block|{
name|pt_memattr
operator|=
name|VM_MEMATTR_WB_WA
expr_stmt|;
name|ttb_flags
operator|=
name|encode_ttb_flags
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pt_memattr
operator|=
name|VM_MEMATTR_NOCACHE
expr_stmt|;
name|ttb_flags
operator|=
name|encode_ttb_flags
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
else|#
directive|else
name|pt_memattr
operator|=
name|VM_MEMATTR_WB_WA
expr_stmt|;
name|ttb_flags
operator|=
name|encode_ttb_flags
argument_list|(
literal|0
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|prrr
operator|=
literal|0
expr_stmt|;
name|nmrr
operator|=
literal|0
expr_stmt|;
comment|/* Build remapping register from TEX classes. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|8
condition|;
name|i
operator|++
control|)
block|{
name|type
operator|=
operator|(
name|tex_class
index|[
name|i
index|]
operator|>>
name|TEXDEF_TYPE_SHIFT
operator|)
operator|&
name|TEXDEF_TYPE_MASK
expr_stmt|;
name|inner
operator|=
operator|(
name|tex_class
index|[
name|i
index|]
operator|>>
name|TEXDEF_INNER_SHIFT
operator|)
operator|&
name|TEXDEF_INNER_MASK
expr_stmt|;
name|outer
operator|=
operator|(
name|tex_class
index|[
name|i
index|]
operator|>>
name|TEXDEF_OUTER_SHIFT
operator|)
operator|&
name|TEXDEF_OUTER_MASK
expr_stmt|;
name|nos
operator|=
operator|(
name|tex_class
index|[
name|i
index|]
operator|>>
name|TEXDEF_NOS_SHIFT
operator|)
operator|&
name|TEXDEF_NOS_MASK
expr_stmt|;
name|prrr
operator||=
name|type
operator|<<
operator|(
name|i
operator|*
literal|2
operator|)
expr_stmt|;
name|prrr
operator||=
name|nos
operator|<<
operator|(
name|i
operator|+
literal|24
operator|)
expr_stmt|;
name|nmrr
operator||=
name|inner
operator|<<
operator|(
name|i
operator|*
literal|2
operator|)
expr_stmt|;
name|nmrr
operator||=
name|outer
operator|<<
operator|(
name|i
operator|*
literal|2
operator|+
literal|16
operator|)
expr_stmt|;
block|}
comment|/* Add shareable bits for device memory. */
name|prrr
operator||=
name|PRRR_DS0
operator||
name|PRRR_DS1
expr_stmt|;
comment|/* Add shareable bits for normal memory in SMP case. */
ifdef|#
directive|ifdef
name|SMP
name|ARM_SMP_UP
argument_list|(
name|prrr
operator||=
name|PRRR_NS1
argument_list|, 	)
expr_stmt|;
endif|#
directive|endif
name|cp15_prrr_set
argument_list|(
name|prrr
argument_list|)
expr_stmt|;
name|cp15_nmrr_set
argument_list|(
name|nmrr
argument_list|)
expr_stmt|;
comment|/* Caches are disabled, so full TLB flush should be enough. */
name|tlb_flush_all_local
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remap one vm_meattr class to another one. This can be useful as  * workaround for SOC errata, e.g. if devices must be accessed using  * SO memory class.  *  * !!! Please note that this function is absolutely last resort thing.  * It should not be used under normal circumstances. !!!  *  * Usage rules:  * - it shall be called after pmap_bootstrap_prepare() and before  *   cpu_mp_start() (thus only on boot CPU). In practice, it's expected  *   to be called from platform_attach() or platform_late_init().  *  * - if remapping doesn't change caching mode, or until uncached class  *   is remapped to any kind of cached one, then no other restriction exists.  *  * - if pmap_remap_vm_attr() changes caching mode, but both (original and  *   remapped) remain cached, then caller is resposible for calling  *   of dcache_wbinv_poc_all().  *  * - remapping of any kind of cached class to uncached is not permitted.  */
end_comment

begin_function
name|void
name|pmap_remap_vm_attr
parameter_list|(
name|vm_memattr_t
name|old_attr
parameter_list|,
name|vm_memattr_t
name|new_attr
parameter_list|)
block|{
name|int
name|old_idx
decl_stmt|,
name|new_idx
decl_stmt|;
comment|/* Map VM memattrs to indexes to tex_class table. */
name|old_idx
operator|=
name|pte2_attr_tab
index|[
operator|(
name|int
operator|)
name|old_attr
index|]
expr_stmt|;
name|new_idx
operator|=
name|pte2_attr_tab
index|[
operator|(
name|int
operator|)
name|new_attr
index|]
expr_stmt|;
comment|/* Replace TEX attribute and apply it. */
name|tex_class
index|[
name|old_idx
index|]
operator|=
name|tex_class
index|[
name|new_idx
index|]
expr_stmt|;
name|pmap_set_tex
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * KERNBASE must be multiple of NPT2_IN_PG * PTE1_SIZE. In other words,  * KERNBASE is mapped by first L2 page table in L2 page table page. It  * meets same constrain due to PT2MAP being placed just under KERNBASE.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
operator|(
name|KERNBASE
operator|&
operator|(
name|NPT2_IN_PG
operator|*
name|PTE1_SIZE
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
operator|(
name|KERNBASE
operator|-
name|VM_MAXUSER_ADDRESS
operator|)
operator|>=
name|PT2MAP_SIZE
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *  In crazy dreams, PAGE_SIZE could be a multiple of PTE2_SIZE in general.  *  For now, anyhow, the following check must be fulfilled.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
name|PAGE_SIZE
operator|==
name|PTE2_SIZE
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *  We don't want to mess up MI code with all MMU and PMAP definitions,  *  so some things, which depend on other ones, are defined independently.  *  Now, it is time to check that we don't screw up something.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
name|PDRSHIFT
operator|==
name|PTE1_SHIFT
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *  Check L1 and L2 page table entries definitions consistency.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
name|NB_IN_PT1
operator|==
operator|(
sizeof|sizeof
argument_list|(
name|pt1_entry_t
argument_list|)
operator|*
name|NPTE1_IN_PT1
operator|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|NB_IN_PT2
operator|==
operator|(
sizeof|sizeof
argument_list|(
name|pt2_entry_t
argument_list|)
operator|*
name|NPTE2_IN_PT2
operator|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *  Check L2 page tables page consistency.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
name|PAGE_SIZE
operator|==
operator|(
name|NPT2_IN_PG
operator|*
name|NB_IN_PT2
operator|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
operator|(
literal|1
operator|<<
name|PT2PG_SHIFT
operator|)
operator|==
name|NPT2_IN_PG
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *  Check PT2TAB consistency.  *  PT2TAB_ENTRIES is defined as a division of NPTE1_IN_PT1 by NPT2_IN_PG.  *  This should be done without remainder.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
name|NPTE1_IN_PT1
operator|==
operator|(
name|PT2TAB_ENTRIES
operator|*
name|NPT2_IN_PG
operator|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *	A PT2MAP magic.  *  *  All level 2 page tables (PT2s) are mapped continuously and accordingly  *  into PT2MAP address space. As PT2 size is less than PAGE_SIZE, this can  *  be done only if PAGE_SIZE is a multiple of PT2 size. All PT2s in one page  *  must be used together, but not necessary at once. The first PT2 in a page  *  must map things on correctly aligned address and the others must follow  *  in right order.  */
end_comment

begin_define
define|#
directive|define
name|NB_IN_PT2TAB
value|(PT2TAB_ENTRIES * sizeof(pt2_entry_t))
end_define

begin_define
define|#
directive|define
name|NPT2_IN_PT2TAB
value|(NB_IN_PT2TAB / NB_IN_PT2)
end_define

begin_define
define|#
directive|define
name|NPG_IN_PT2TAB
value|(NB_IN_PT2TAB / PAGE_SIZE)
end_define

begin_comment
comment|/*  *  Check PT2TAB consistency.  *  NPT2_IN_PT2TAB is defined as a division of NB_IN_PT2TAB by NB_IN_PT2.  *  NPG_IN_PT2TAB is defined as a division of NB_IN_PT2TAB by PAGE_SIZE.  *  The both should be done without remainder.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
name|NB_IN_PT2TAB
operator|==
operator|(
name|NPT2_IN_PT2TAB
operator|*
name|NB_IN_PT2
operator|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|NB_IN_PT2TAB
operator|==
operator|(
name|NPG_IN_PT2TAB
operator|*
name|PAGE_SIZE
operator|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *  The implementation was made general, however, with the assumption  *  bellow in mind. In case of another value of NPG_IN_PT2TAB,  *  the code should be once more rechecked.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
name|NPG_IN_PT2TAB
operator|==
literal|1
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *  Get offset of PT2 in a page  *  associated with given PT1 index.  */
end_comment

begin_function
specifier|static
name|__inline
name|u_int
name|page_pt2off
parameter_list|(
name|u_int
name|pt1_idx
parameter_list|)
block|{
return|return
operator|(
operator|(
name|pt1_idx
operator|&
name|PT2PG_MASK
operator|)
operator|*
name|NB_IN_PT2
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Get physical address of PT2  *  associated with given PT2s page and PT1 index.  */
end_comment

begin_function
specifier|static
name|__inline
name|vm_paddr_t
name|page_pt2pa
parameter_list|(
name|vm_paddr_t
name|pgpa
parameter_list|,
name|u_int
name|pt1_idx
parameter_list|)
block|{
return|return
operator|(
name|pgpa
operator|+
name|page_pt2off
argument_list|(
name|pt1_idx
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Get first entry of PT2  *  associated with given PT2s page and PT1 index.  */
end_comment

begin_function
specifier|static
name|__inline
name|pt2_entry_t
modifier|*
name|page_pt2
parameter_list|(
name|vm_offset_t
name|pgva
parameter_list|,
name|u_int
name|pt1_idx
parameter_list|)
block|{
return|return
operator|(
operator|(
name|pt2_entry_t
operator|*
operator|)
operator|(
name|pgva
operator|+
name|page_pt2off
argument_list|(
name|pt1_idx
argument_list|)
operator|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Get virtual address of PT2s page (mapped in PT2MAP)  *  which holds PT2 which holds entry which maps given virtual address.  */
end_comment

begin_function
specifier|static
name|__inline
name|vm_offset_t
name|pt2map_pt2pg
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|va
operator|&=
operator|~
operator|(
name|NPT2_IN_PG
operator|*
name|PTE1_SIZE
operator|-
literal|1
operator|)
expr_stmt|;
return|return
operator|(
operator|(
name|vm_offset_t
operator|)
name|pt2map_entry
argument_list|(
name|va
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*****************************************************************************  *  *     THREE pmap initialization milestones exist:  *  *  locore.S  *    -> fundamental init (including MMU) in ASM  *  *  initarm()  *    -> fundamental init continues in C  *    -> first available physical address is known  *  *    pmap_bootstrap_prepare() -> FIRST PMAP MILESTONE (first epoch begins)  *      -> basic (safe) interface for physical address allocation is made  *      -> basic (safe) interface for virtual mapping is made  *      -> limited not SMP coherent work is possible  *  *    -> more fundamental init continues in C  *    -> locks and some more things are available  *    -> all fundamental allocations and mappings are done  *  *    pmap_bootstrap() -> SECOND PMAP MILESTONE (second epoch begins)  *      -> phys_avail[] and virtual_avail is set  *      -> control is passed to vm subsystem  *      -> physical and virtual address allocation are off limit  *      -> low level mapping functions, some SMP coherent,  *         are available, which cannot be used before vm subsystem  *         is being inited  *  *  mi_startup()  *    -> vm subsystem is being inited  *  *      pmap_init() -> THIRD PMAP MILESTONE (third epoch begins)  *        -> pmap is fully inited  *  *****************************************************************************/
end_comment

begin_comment
comment|/*****************************************************************************  *  *	PMAP first stage initialization and utility functions  *	for pre-bootstrap epoch.  *  *  After pmap_bootstrap_prepare() is called, the following functions  *  can be used:  *  *  (1) strictly only for this stage functions for physical page allocations,  *      virtual space allocations, and mappings:  *  *  vm_paddr_t pmap_preboot_get_pages(u_int num);  *  void pmap_preboot_map_pages(vm_paddr_t pa, vm_offset_t va, u_int num);  *  vm_offset_t pmap_preboot_reserve_pages(u_int num);  *  vm_offset_t pmap_preboot_get_vpages(u_int num);  *  void pmap_preboot_map_attr(vm_paddr_t pa, vm_offset_t va, vm_size_t size,  *      vm_prot_t prot, vm_memattr_t attr);  *  *  (2) for all stages:  *  *  vm_paddr_t pmap_kextract(vm_offset_t va);  *  *  NOTE: This is not SMP coherent stage.  *  *****************************************************************************/
end_comment

begin_define
define|#
directive|define
name|KERNEL_P2V
parameter_list|(
name|pa
parameter_list|)
define|\
value|((vm_offset_t)((pa) - arm_physmem_kernaddr + KERNVIRTADDR))
end_define

begin_define
define|#
directive|define
name|KERNEL_V2P
parameter_list|(
name|va
parameter_list|)
define|\
value|((vm_paddr_t)((va) - KERNVIRTADDR + arm_physmem_kernaddr))
end_define

begin_decl_stmt
specifier|static
name|vm_paddr_t
name|last_paddr
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  *  Pre-bootstrap epoch page allocator.  */
end_comment

begin_function
name|vm_paddr_t
name|pmap_preboot_get_pages
parameter_list|(
name|u_int
name|num
parameter_list|)
block|{
name|vm_paddr_t
name|ret
decl_stmt|;
name|ret
operator|=
name|last_paddr
expr_stmt|;
name|last_paddr
operator|+=
name|num
operator|*
name|PAGE_SIZE
expr_stmt|;
return|return
operator|(
name|ret
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	The fundamental initialization of PMAP stuff.  *  *  Some things already happened in locore.S and some things could happen  *  before pmap_bootstrap_prepare() is called, so let's recall what is done:  *  1. Caches are disabled.  *  2. We are running on virtual addresses already with 'boot_pt1'  *     as L1 page table.  *  3. So far, all virtual addresses can be converted to physical ones and  *     vice versa by the following macros:  *       KERNEL_P2V(pa) .... physical to virtual ones,  *       KERNEL_V2P(va) .... virtual to physical ones.  *  *  What is done herein:  *  1. The 'boot_pt1' is replaced by real kernel L1 page table 'kern_pt1'.  *  2. PT2MAP magic is brought to live.  *  3. Basic preboot functions for page allocations and mappings can be used.  *  4. Everything is prepared for L1 cache enabling.  *  *  Variations:  *  1. To use second TTB register, so kernel and users page tables will be  *     separated. This way process forking - pmap_pinit() - could be faster,  *     it saves physical pages and KVA per a process, and it's simple change.  *     However, it will lead, due to hardware matter, to the following:  *     (a) 2G space for kernel and 2G space for users.  *     (b) 1G space for kernel in low addresses and 3G for users above it.  *     A question is: Is the case (b) really an option? Note that case (b)  *     does save neither physical memory and KVA.  */
end_comment

begin_function
name|void
name|pmap_bootstrap_prepare
parameter_list|(
name|vm_paddr_t
name|last
parameter_list|)
block|{
name|vm_paddr_t
name|pt2pg_pa
decl_stmt|,
name|pt2tab_pa
decl_stmt|,
name|pa
decl_stmt|,
name|size
decl_stmt|;
name|vm_offset_t
name|pt2pg_va
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|u_int
name|i
decl_stmt|;
name|uint32_t
name|actlr_mask
decl_stmt|,
name|actlr_set
decl_stmt|,
name|l1_attr
decl_stmt|;
comment|/* 	 * Now, we are going to make real kernel mapping. Note that we are 	 * already running on some mapping made in locore.S and we expect 	 * that it's large enough to ensure nofault access to physical memory 	 * allocated herein before switch. 	 * 	 * As kernel image and everything needed before are and will be mapped 	 * by section mappings, we align last physical address to PTE1_SIZE. 	 */
name|last_paddr
operator|=
name|pte1_roundup
argument_list|(
name|last
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate and zero page(s) for kernel L1 page table. 	 * 	 * Note that it's first allocation on space which was PTE1_SIZE 	 * aligned and as such base_pt1 is aligned to NB_IN_PT1 too. 	 */
name|base_pt1
operator|=
name|pmap_preboot_get_pages
argument_list|(
name|NPG_IN_PT1
argument_list|)
expr_stmt|;
name|kern_pt1
operator|=
operator|(
name|pt1_entry_t
operator|*
operator|)
name|KERNEL_P2V
argument_list|(
name|base_pt1
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|kern_pt1
argument_list|,
name|NB_IN_PT1
argument_list|)
expr_stmt|;
name|pte1_sync_range
argument_list|(
name|kern_pt1
argument_list|,
name|NB_IN_PT1
argument_list|)
expr_stmt|;
comment|/* Allocate and zero page(s) for kernel PT2TAB. */
name|pt2tab_pa
operator|=
name|pmap_preboot_get_pages
argument_list|(
name|NPG_IN_PT2TAB
argument_list|)
expr_stmt|;
name|kern_pt2tab
operator|=
operator|(
name|pt2_entry_t
operator|*
operator|)
name|KERNEL_P2V
argument_list|(
name|pt2tab_pa
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
name|kern_pt2tab
argument_list|,
name|NB_IN_PT2TAB
argument_list|)
expr_stmt|;
name|pte2_sync_range
argument_list|(
name|kern_pt2tab
argument_list|,
name|NB_IN_PT2TAB
argument_list|)
expr_stmt|;
comment|/* Allocate and zero page(s) for kernel L2 page tables. */
name|pt2pg_pa
operator|=
name|pmap_preboot_get_pages
argument_list|(
name|NKPT2PG
argument_list|)
expr_stmt|;
name|pt2pg_va
operator|=
name|KERNEL_P2V
argument_list|(
name|pt2pg_pa
argument_list|)
expr_stmt|;
name|size
operator|=
name|NKPT2PG
operator|*
name|PAGE_SIZE
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|pt2pg_va
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|pte2_sync_range
argument_list|(
operator|(
name|pt2_entry_t
operator|*
operator|)
name|pt2pg_va
argument_list|,
name|size
argument_list|)
expr_stmt|;
comment|/* 	 * Add a physical memory segment (vm_phys_seg) corresponding to the 	 * preallocated pages for kernel L2 page tables so that vm_page 	 * structures representing these pages will be created. The vm_page 	 * structures are required for promotion of the corresponding kernel 	 * virtual addresses to section mappings. 	 */
name|vm_phys_add_seg
argument_list|(
name|pt2tab_pa
argument_list|,
name|pmap_preboot_get_pages
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Insert allocated L2 page table pages to PT2TAB and make 	 * link to all PT2s in L1 page table. See how kernel_vm_end 	 * is initialized. 	 * 	 * We play simple and safe. So every KVA will have underlaying 	 * L2 page table, even kernel image mapped by sections. 	 */
name|pte2p
operator|=
name|kern_pt2tab_entry
argument_list|(
name|KERNBASE
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|pt2pg_pa
init|;
name|pa
operator|<
name|pt2pg_pa
operator|+
name|size
condition|;
name|pa
operator|+=
name|PTE2_SIZE
control|)
name|pt2tab_store
argument_list|(
name|pte2p
operator|++
argument_list|,
name|PTE2_KPT
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|kern_pte1
argument_list|(
name|KERNBASE
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|pt2pg_pa
init|;
name|pa
operator|<
name|pt2pg_pa
operator|+
name|size
condition|;
name|pa
operator|+=
name|NB_IN_PT2
control|)
name|pte1_store
argument_list|(
name|pte1p
operator|++
argument_list|,
name|PTE1_LINK
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Make section mappings for kernel. */
name|l1_attr
operator|=
name|ATTR_TO_L1
argument_list|(
name|PTE2_ATTR_DEFAULT
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|kern_pte1
argument_list|(
name|KERNBASE
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|KERNEL_V2P
argument_list|(
name|KERNBASE
argument_list|)
init|;
name|pa
operator|<
name|last
condition|;
name|pa
operator|+=
name|PTE1_SIZE
control|)
name|pte1_store
argument_list|(
name|pte1p
operator|++
argument_list|,
name|PTE1_KERN
argument_list|(
name|pa
argument_list|,
name|PTE1_AP_KRW
argument_list|,
name|l1_attr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Get free and aligned space for PT2MAP and make L1 page table links 	 * to L2 page tables held in PT2TAB. 	 * 	 * Note that pages holding PT2s are stored in PT2TAB as pt2_entry_t 	 * descriptors and PT2TAB page(s) itself is(are) used as PT2s. Thus 	 * each entry in PT2TAB maps all PT2s in a page. This implies that 	 * virtual address of PT2MAP must be aligned to NPT2_IN_PG * PTE1_SIZE. 	 */
name|PT2MAP
operator|=
operator|(
name|pt2_entry_t
operator|*
operator|)
operator|(
name|KERNBASE
operator|-
name|PT2MAP_SIZE
operator|)
expr_stmt|;
name|pte1p
operator|=
name|kern_pte1
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PT2MAP
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|pt2tab_pa
operator|,
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPT2_IN_PT2TAB
condition|;
name|i
operator|++
operator|,
name|pa
operator|+=
name|NB_IN_PT2
control|)
block|{
name|pte1_store
argument_list|(
name|pte1p
operator|++
argument_list|,
name|PTE1_LINK
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Store PT2TAB in PT2TAB itself, i.e. self reference mapping. 	 * Each pmap will hold own PT2TAB, so the mapping should be not global. 	 */
name|pte2p
operator|=
name|kern_pt2tab_entry
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PT2MAP
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|pt2tab_pa
operator|,
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPG_IN_PT2TAB
condition|;
name|i
operator|++
operator|,
name|pa
operator|+=
name|PTE2_SIZE
control|)
block|{
name|pt2tab_store
argument_list|(
name|pte2p
operator|++
argument_list|,
name|PTE2_KPT_NG
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Choose correct L2 page table and make mappings for allocations 	 * made herein which replaces temporary locore.S mappings after a while. 	 * Note that PT2MAP cannot be used until we switch to kern_pt1. 	 * 	 * Note, that these allocations started aligned on 1M section and 	 * kernel PT1 was allocated first. Making of mappings must follow 	 * order of physical allocations as we've used KERNEL_P2V() macro 	 * for virtual addresses resolution. 	 */
name|pte2p
operator|=
name|kern_pt2tab_entry
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|kern_pt1
argument_list|)
expr_stmt|;
name|pt2pg_va
operator|=
name|KERNEL_P2V
argument_list|(
name|pte2_pa
argument_list|(
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|page_pt2
argument_list|(
name|pt2pg_va
argument_list|,
name|pte1_index
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|kern_pt1
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Make mapping for kernel L1 page table. */
for|for
control|(
name|pa
operator|=
name|base_pt1
operator|,
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPG_IN_PT1
condition|;
name|i
operator|++
operator|,
name|pa
operator|+=
name|PTE2_SIZE
control|)
name|pte2_store
argument_list|(
name|pte2p
operator|++
argument_list|,
name|PTE2_KPT
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Make mapping for kernel PT2TAB. */
for|for
control|(
name|pa
operator|=
name|pt2tab_pa
operator|,
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPG_IN_PT2TAB
condition|;
name|i
operator|++
operator|,
name|pa
operator|+=
name|PTE2_SIZE
control|)
name|pte2_store
argument_list|(
name|pte2p
operator|++
argument_list|,
name|PTE2_KPT
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Finally, switch from 'boot_pt1' to 'kern_pt1'. */
name|pmap_kern_ttb
operator|=
name|base_pt1
operator||
name|ttb_flags
expr_stmt|;
name|cpuinfo_get_actlr_modifier
argument_list|(
operator|&
name|actlr_mask
argument_list|,
operator|&
name|actlr_set
argument_list|)
expr_stmt|;
name|reinit_mmu
argument_list|(
name|pmap_kern_ttb
argument_list|,
name|actlr_mask
argument_list|,
name|actlr_set
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the first available KVA. As kernel image is mapped by 	 * sections, we are leaving some gap behind. 	 */
name|virtual_avail
operator|=
operator|(
name|vm_offset_t
operator|)
name|kern_pt2tab
operator|+
name|NPG_IN_PT2TAB
operator|*
name|PAGE_SIZE
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Setup L2 page table page for given KVA.  *  Used in pre-bootstrap epoch.  *  *  Note that we have allocated NKPT2PG pages for L2 page tables in advance  *  and used them for mapping KVA starting from KERNBASE. However, this is not  *  enough. Vectors and devices need L2 page tables too. Note that they are  *  even above VM_MAX_KERNEL_ADDRESS.  */
end_comment

begin_function
specifier|static
name|__inline
name|vm_paddr_t
name|pmap_preboot_pt2pg_setup
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|vm_paddr_t
name|pt2pg_pa
decl_stmt|;
comment|/* Get associated entry in PT2TAB. */
name|pte2p
operator|=
name|kern_pt2tab_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
comment|/* Just return, if PT2s page exists already. */
name|pte2
operator|=
name|pt2tab_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
return|return
operator|(
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
operator|)
return|;
name|KASSERT
argument_list|(
name|va
operator|>=
name|VM_MAX_KERNEL_ADDRESS
argument_list|,
operator|(
literal|"%s: NKPT2PG too small"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate page for PT2s and insert it to PT2TAB. 	 * In other words, map it into PT2MAP space. 	 */
name|pt2pg_pa
operator|=
name|pmap_preboot_get_pages
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|pt2tab_store
argument_list|(
name|pte2p
argument_list|,
name|PTE2_KPT
argument_list|(
name|pt2pg_pa
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Zero all PT2s in allocated page. */
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|pt2map_pt2pg
argument_list|(
name|va
argument_list|)
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|pte2_sync_range
argument_list|(
operator|(
name|pt2_entry_t
operator|*
operator|)
name|pt2map_pt2pg
argument_list|(
name|va
argument_list|)
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
return|return
operator|(
name|pt2pg_pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Setup L2 page table for given KVA.  *  Used in pre-bootstrap epoch.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_preboot_pt2_setup
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|vm_paddr_t
name|pt2pg_pa
decl_stmt|,
name|pt2_pa
decl_stmt|;
comment|/* Setup PT2's page. */
name|pt2pg_pa
operator|=
name|pmap_preboot_pt2pg_setup
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pt2_pa
operator|=
name|page_pt2pa
argument_list|(
name|pt2pg_pa
argument_list|,
name|pte1_index
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Insert PT2 to PT1. */
name|pte1p
operator|=
name|kern_pte1
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|PTE1_LINK
argument_list|(
name|pt2_pa
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Get L2 page entry associated with given KVA.  *  Used in pre-bootstrap epoch.  */
end_comment

begin_function
specifier|static
name|__inline
name|pt2_entry_t
modifier|*
name|pmap_preboot_vtopte2
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
comment|/* Setup PT2 if needed. */
name|pte1p
operator|=
name|kern_pte1
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte1_is_valid
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
condition|)
comment|/* XXX - sections ?! */
name|pmap_preboot_pt2_setup
argument_list|(
name|va
argument_list|)
expr_stmt|;
return|return
operator|(
name|pt2map_entry
argument_list|(
name|va
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Pre-bootstrap epoch page(s) mapping(s).  */
end_comment

begin_function
name|void
name|pmap_preboot_map_pages
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|u_int
name|num
parameter_list|)
block|{
name|u_int
name|i
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
comment|/* Map all the pages. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|num
condition|;
name|i
operator|++
control|)
block|{
name|pte2p
operator|=
name|pmap_preboot_vtopte2
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|PTE2_KRW
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *  Pre-bootstrap epoch virtual space alocator.  */
end_comment

begin_function
name|vm_offset_t
name|pmap_preboot_reserve_pages
parameter_list|(
name|u_int
name|num
parameter_list|)
block|{
name|u_int
name|i
decl_stmt|;
name|vm_offset_t
name|start
decl_stmt|,
name|va
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
comment|/* Allocate virtual space. */
name|start
operator|=
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|num
operator|*
name|PAGE_SIZE
expr_stmt|;
comment|/* Zero the mapping. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|num
condition|;
name|i
operator|++
control|)
block|{
name|pte2p
operator|=
name|pmap_preboot_vtopte2
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
return|return
operator|(
name|start
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Pre-bootstrap epoch page(s) allocation and mapping(s).  */
end_comment

begin_function
name|vm_offset_t
name|pmap_preboot_get_vpages
parameter_list|(
name|u_int
name|num
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
comment|/* Allocate physical page(s). */
name|pa
operator|=
name|pmap_preboot_get_pages
argument_list|(
name|num
argument_list|)
expr_stmt|;
comment|/* Allocate virtual space. */
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|num
operator|*
name|PAGE_SIZE
expr_stmt|;
comment|/* Map and zero all. */
name|pmap_preboot_map_pages
argument_list|(
name|pa
argument_list|,
name|va
argument_list|,
name|num
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|num
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
return|return
operator|(
name|va
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Pre-bootstrap epoch page mapping(s) with attributes.  */
end_comment

begin_function
name|void
name|pmap_preboot_map_attr
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|vm_memattr_t
name|attr
parameter_list|)
block|{
name|u_int
name|num
decl_stmt|;
name|u_int
name|l1_attr
decl_stmt|,
name|l1_prot
decl_stmt|,
name|l2_prot
decl_stmt|,
name|l2_attr
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|l2_prot
operator|=
name|prot
operator|&
name|VM_PROT_WRITE
condition|?
name|PTE2_AP_KRW
else|:
name|PTE2_AP_KR
expr_stmt|;
name|l2_prot
operator||=
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
condition|?
name|PTE2_X
else|:
name|PTE2_NX
expr_stmt|;
name|l2_attr
operator|=
name|vm_memattr_to_pte2
argument_list|(
name|attr
argument_list|)
expr_stmt|;
name|l1_prot
operator|=
name|ATTR_TO_L1
argument_list|(
name|l2_prot
argument_list|)
expr_stmt|;
name|l1_attr
operator|=
name|ATTR_TO_L1
argument_list|(
name|l2_attr
argument_list|)
expr_stmt|;
comment|/* Map all the pages. */
name|num
operator|=
name|round_page
argument_list|(
name|size
argument_list|)
expr_stmt|;
while|while
condition|(
name|num
operator|>
literal|0
condition|)
block|{
if|if
condition|(
operator|(
operator|(
operator|(
name|va
operator||
name|pa
operator|)
operator|&
name|PTE1_OFFSET
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|num
operator|>=
name|PTE1_SIZE
operator|)
condition|)
block|{
name|pte1p
operator|=
name|kern_pte1
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|PTE1_KERN
argument_list|(
name|pa
argument_list|,
name|l1_prot
argument_list|,
name|l1_attr
argument_list|)
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PTE1_SIZE
expr_stmt|;
name|pa
operator|+=
name|PTE1_SIZE
expr_stmt|;
name|num
operator|-=
name|PTE1_SIZE
expr_stmt|;
block|}
else|else
block|{
name|pte2p
operator|=
name|pmap_preboot_vtopte2
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|PTE2_KERN
argument_list|(
name|pa
argument_list|,
name|l2_prot
argument_list|,
name|l2_attr
argument_list|)
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|num
operator|-=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *  Extract from the kernel page table the physical address  *  that is mapped by the given virtual address "va".  */
end_comment

begin_function
name|vm_paddr_t
name|pmap_kextract
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|kern_pte1
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pa
operator|=
name|pte1_pa
argument_list|(
name|pte1
argument_list|)
operator||
operator|(
name|va
operator|&
name|PTE1_OFFSET
operator|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
comment|/* 		 * We should beware of concurrent promotion that changes 		 * pte1 at this point. However, it's not a problem as PT2 		 * page is preserved by promotion in PT2TAB. So even if 		 * it happens, using of PT2MAP is still safe. 		 * 		 * QQQ: However, concurrent removing is a problem which 		 *      ends in abort on PT2MAP space. Locking must be used 		 *      to deal with this. 		 */
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pt2map_entry
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
name|pa
operator|=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
operator||
operator|(
name|va
operator|&
name|PTE2_OFFSET
operator|)
expr_stmt|;
block|}
else|else
block|{
name|panic
argument_list|(
literal|"%s: va %#x pte1 %#x"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pte1
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Extract from the kernel page table the physical address  *  that is mapped by the given virtual address "va". Also  *  return L2 page table entry which maps the address.  *  *  This is only intended to be used for panic dumps.  */
end_comment

begin_function
name|vm_paddr_t
name|pmap_dump_kextract
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|pt2_entry_t
modifier|*
name|pte2p
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|kern_pte1
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pa
operator|=
name|pte1_pa
argument_list|(
name|pte1
argument_list|)
operator||
operator|(
name|va
operator|&
name|PTE1_OFFSET
operator|)
expr_stmt|;
name|pte2
operator|=
name|pa
operator||
name|ATTR_TO_L2
argument_list|(
name|pte1
argument_list|)
operator||
name|PTE2_V
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pt2map_entry
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
name|pa
operator|=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pte2
operator|=
literal|0
expr_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|pte2p
operator|!=
name|NULL
condition|)
operator|*
name|pte2p
operator|=
name|pte2
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*****************************************************************************  *  *	PMAP second stage initialization and utility functions  *	for bootstrap epoch.  *  *  After pmap_bootstrap() is called, the following functions for  *  mappings can be used:  *  *  void pmap_kenter(vm_offset_t va, vm_paddr_t pa);  *  void pmap_kremove(vm_offset_t va);  *  vm_offset_t pmap_map(vm_offset_t *virt, vm_paddr_t start, vm_paddr_t end,  *      int prot);  *  *  NOTE: This is not SMP coherent stage. And physical page allocation is not  *        allowed during this stage.  *  *****************************************************************************/
end_comment

begin_comment
comment|/*  *  Initialize kernel PMAP locks and lists, kernel_pmap itself, and  *  reserve various virtual spaces for temporary mappings.  */
end_comment

begin_function
name|void
name|pmap_bootstrap
parameter_list|(
name|vm_offset_t
name|firstaddr
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|unused
name|__unused
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
comment|/* 	 * Initialize the kernel pmap (which is statically allocated). 	 */
name|PMAP_LOCK_INIT
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|kernel_l1pa
operator|=
operator|(
name|vm_paddr_t
operator|)
name|kern_pt1
expr_stmt|;
comment|/* for libkvm */
name|kernel_pmap
operator|->
name|pm_pt1
operator|=
name|kern_pt1
expr_stmt|;
name|kernel_pmap
operator|->
name|pm_pt2tab
operator|=
name|kern_pt2tab
expr_stmt|;
name|CPU_FILL
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
comment|/* don't allow deactivation */
name|TAILQ_INIT
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the global pv list lock. 	 */
name|rw_init
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
literal|"pmap pv global"
argument_list|)
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|allpmaps
argument_list|)
expr_stmt|;
comment|/* 	 * Request a spin mutex so that changes to allpmaps cannot be 	 * preempted by smp_rendezvous_cpus(). 	 */
name|mtx_init
argument_list|(
operator|&
name|allpmaps_lock
argument_list|,
literal|"allpmaps"
argument_list|,
name|NULL
argument_list|,
name|MTX_SPIN
argument_list|)
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|allpmaps
argument_list|,
name|kernel_pmap
argument_list|,
name|pm_list
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
comment|/* 	 * Reserve some special page table entries/VA space for temporary 	 * mapping of pages. 	 */
define|#
directive|define
name|SYSMAP
parameter_list|(
name|c
parameter_list|,
name|p
parameter_list|,
name|v
parameter_list|,
name|n
parameter_list|)
value|do {		\ 	v = (c)pmap_preboot_reserve_pages(n);	\ 	p = pt2map_entry((vm_offset_t)v);	\ 	} while (0)
comment|/* 	 * Local CMAP1/CMAP2 are used for zeroing and copying pages. 	 * Local CMAP2 is also used for data cache cleaning. 	 */
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|,
literal|"SYSMAPS"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|SYSMAP
argument_list|(
name|caddr_t
argument_list|,
name|pc
operator|->
name|pc_cmap1_pte2p
argument_list|,
name|pc
operator|->
name|pc_cmap1_addr
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|SYSMAP
argument_list|(
name|caddr_t
argument_list|,
name|pc
operator|->
name|pc_cmap2_pte2p
argument_list|,
name|pc
operator|->
name|pc_cmap2_addr
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|SYSMAP
argument_list|(
name|vm_offset_t
argument_list|,
name|pc
operator|->
name|pc_qmap_pte2p
argument_list|,
name|pc
operator|->
name|pc_qmap_addr
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * Crashdump maps. 	 */
name|SYSMAP
argument_list|(
name|caddr_t
argument_list|,
name|unused
argument_list|,
name|crashdumpmap
argument_list|,
name|MAXDUMPPGS
argument_list|)
expr_stmt|;
comment|/* 	 * _tmppt is used for reading arbitrary physical pages via /dev/mem. 	 */
name|SYSMAP
argument_list|(
name|caddr_t
argument_list|,
name|unused
argument_list|,
name|_tmppt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * PADDR1 and PADDR2 are used by pmap_pte2_quick() and pmap_pte2(), 	 * respectively. PADDR3 is used by pmap_pte2_ddb(). 	 */
name|SYSMAP
argument_list|(
name|pt2_entry_t
operator|*
argument_list|,
name|PMAP1
argument_list|,
name|PADDR1
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|SYSMAP
argument_list|(
name|pt2_entry_t
operator|*
argument_list|,
name|PMAP2
argument_list|,
name|PADDR2
argument_list|,
literal|1
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|DDB
name|SYSMAP
argument_list|(
name|pt2_entry_t
operator|*
argument_list|,
name|PMAP3
argument_list|,
name|PADDR3
argument_list|,
literal|1
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|mtx_init
argument_list|(
operator|&
name|PMAP2mutex
argument_list|,
literal|"PMAP2"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* 	 * Note that in very short time in initarm(), we are going to 	 * initialize phys_avail[] array and no further page allocation 	 * can happen after that until vm subsystem will be initialized. 	 */
name|kernel_vm_end_new
operator|=
name|kernel_vm_end
expr_stmt|;
name|virtual_end
operator|=
name|vm_max_kernel_address
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_init_reserved_pages
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|vm_offset_t
name|pages
decl_stmt|;
name|int
name|i
decl_stmt|;
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
block|{
name|pc
operator|=
name|pcpu_find
argument_list|(
name|i
argument_list|)
expr_stmt|;
comment|/* 		 * Skip if the mapping has already been initialized, 		 * i.e. this is the BSP. 		 */
if|if
condition|(
name|pc
operator|->
name|pc_cmap1_addr
operator|!=
literal|0
condition|)
continue|continue;
name|mtx_init
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|,
literal|"SYSMAPS"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|pages
operator|=
name|kva_alloc
argument_list|(
name|PAGE_SIZE
operator|*
literal|3
argument_list|)
expr_stmt|;
if|if
condition|(
name|pages
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: unable to allocate KVA"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_cmap1_pte2p
operator|=
name|pt2map_entry
argument_list|(
name|pages
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_cmap2_pte2p
operator|=
name|pt2map_entry
argument_list|(
name|pages
operator|+
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_qmap_pte2p
operator|=
name|pt2map_entry
argument_list|(
name|pages
operator|+
operator|(
name|PAGE_SIZE
operator|*
literal|2
operator|)
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_cmap1_addr
operator|=
operator|(
name|caddr_t
operator|)
name|pages
expr_stmt|;
name|pc
operator|->
name|pc_cmap2_addr
operator|=
call|(
name|caddr_t
call|)
argument_list|(
name|pages
operator|+
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_qmap_addr
operator|=
name|pages
operator|+
operator|(
name|PAGE_SIZE
operator|*
literal|2
operator|)
expr_stmt|;
block|}
block|}
end_function

begin_expr_stmt
name|SYSINIT
argument_list|(
name|rpages_init
argument_list|,
name|SI_SUB_CPU
argument_list|,
name|SI_ORDER_ANY
argument_list|,
name|pmap_init_reserved_pages
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *  The function can already be use in second initialization stage.  *  As such, the function DOES NOT call pmap_growkernel() where PT2  *  allocation can happen. So if used, be sure that PT2 for given  *  virtual address is allocated already!  *  *  Add a wired page to the kva.  *  Note: not SMP coherent.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_kenter_prot_attr
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|uint32_t
name|prot
parameter_list|,
name|uint32_t
name|attr
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|pte1p
operator|=
name|kern_pte1
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte1_is_valid
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
condition|)
block|{
comment|/* XXX - sections ?! */
comment|/* 		 * This is a very low level function, so PT2 and particularly 		 * PT2PG associated with given virtual address must be already 		 * allocated. It's a pain mainly during pmap initialization 		 * stage. However, called after pmap initialization with 		 * virtual address not under kernel_vm_end will lead to 		 * the same misery. 		 */
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2_load
argument_list|(
name|kern_pt2tab_entry
argument_list|(
name|va
argument_list|)
argument_list|)
argument_list|)
condition|)
name|panic
argument_list|(
literal|"%s: kernel PT2 not allocated!"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
name|pte2p
operator|=
name|pt2map_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|PTE2_KERN
argument_list|(
name|pa
argument_list|,
name|prot
argument_list|,
name|attr
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|PMAP_INLINE
name|void
name|pmap_kenter
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|pmap_kenter_prot_attr
argument_list|(
name|va
argument_list|,
name|pa
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|PTE2_ATTR_DEFAULT
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Remove a page from the kernel pagetables.  *  Note: not SMP coherent.  */
end_comment

begin_function
name|PMAP_INLINE
name|void
name|pmap_kremove
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|pte2p
operator|=
name|pt2map_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Share new kernel PT2PG with all pmaps.  *  The caller is responsible for maintaining TLB consistency.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_kenter_pt2tab
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|pt2_entry_t
name|npte2
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pmap
argument_list|,
argument|&allpmaps
argument_list|,
argument|pm_list
argument_list|)
block|{
name|pte2p
operator|=
name|pmap_pt2tab_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pt2tab_store
argument_list|(
name|pte2p
argument_list|,
name|npte2
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Share new kernel PTE1 with all pmaps.  *  The caller is responsible for maintaining TLB consistency.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_kenter_pte1
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|pt1_entry_t
name|npte1
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pmap
argument_list|,
argument|&allpmaps
argument_list|,
argument|pm_list
argument_list|)
block|{
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Used to map a range of physical addresses into kernel  *  virtual address space.  *  *  The value passed in '*virt' is a suggested virtual address for  *  the mapping. Architectures which can support a direct-mapped  *  physical to virtual region can return the appropriate address  *  within that region, leaving '*virt' unchanged. Other  *  architectures should map the pages starting at '*virt' and  *  update '*virt' with the first usable address after the mapped  *  region.  *  *  NOTE: Read the comments above pmap_kenter_prot_attr() as  *        the function is used herein!  */
end_comment

begin_function
name|vm_offset_t
name|pmap_map
parameter_list|(
name|vm_offset_t
modifier|*
name|virt
parameter_list|,
name|vm_paddr_t
name|start
parameter_list|,
name|vm_paddr_t
name|end
parameter_list|,
name|int
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|,
name|sva
decl_stmt|;
name|vm_paddr_t
name|pte1_offset
decl_stmt|;
name|pt1_entry_t
name|npte1
decl_stmt|;
name|uint32_t
name|l1prot
decl_stmt|,
name|l2prot
decl_stmt|;
name|uint32_t
name|l1attr
decl_stmt|,
name|l2attr
decl_stmt|;
name|PDEBUG
argument_list|(
literal|1
argument_list|,
name|printf
argument_list|(
literal|"%s: virt = %#x, start = %#x, end = %#x (size = %#x),"
literal|" prot = %d\n"
argument_list|,
name|__func__
argument_list|,
operator|*
name|virt
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
name|end
operator|-
name|start
argument_list|,
name|prot
argument_list|)
argument_list|)
expr_stmt|;
name|l2prot
operator|=
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
condition|?
name|PTE2_AP_KRW
else|:
name|PTE2_AP_KR
expr_stmt|;
name|l2prot
operator||=
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
condition|?
name|PTE2_X
else|:
name|PTE2_NX
expr_stmt|;
name|l1prot
operator|=
name|ATTR_TO_L1
argument_list|(
name|l2prot
argument_list|)
expr_stmt|;
name|l2attr
operator|=
name|PTE2_ATTR_DEFAULT
expr_stmt|;
name|l1attr
operator|=
name|ATTR_TO_L1
argument_list|(
name|l2attr
argument_list|)
expr_stmt|;
name|va
operator|=
operator|*
name|virt
expr_stmt|;
comment|/* 	 * Does the physical address range's size and alignment permit at 	 * least one section mapping to be created? 	 */
name|pte1_offset
operator|=
name|start
operator|&
name|PTE1_OFFSET
expr_stmt|;
if|if
condition|(
operator|(
name|end
operator|-
name|start
operator|)
operator|-
operator|(
operator|(
name|PTE1_SIZE
operator|-
name|pte1_offset
operator|)
operator|&
name|PTE1_OFFSET
operator|)
operator|>=
name|PTE1_SIZE
condition|)
block|{
comment|/* 		 * Increase the starting virtual address so that its alignment 		 * does not preclude the use of section mappings. 		 */
if|if
condition|(
operator|(
name|va
operator|&
name|PTE1_OFFSET
operator|)
operator|<
name|pte1_offset
condition|)
name|va
operator|=
name|pte1_trunc
argument_list|(
name|va
argument_list|)
operator|+
name|pte1_offset
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|va
operator|&
name|PTE1_OFFSET
operator|)
operator|>
name|pte1_offset
condition|)
name|va
operator|=
name|pte1_roundup
argument_list|(
name|va
argument_list|)
operator|+
name|pte1_offset
expr_stmt|;
block|}
name|sva
operator|=
name|va
expr_stmt|;
while|while
condition|(
name|start
operator|<
name|end
condition|)
block|{
if|if
condition|(
operator|(
name|start
operator|&
name|PTE1_OFFSET
operator|)
operator|==
literal|0
operator|&&
name|end
operator|-
name|start
operator|>=
name|PTE1_SIZE
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|va
operator|&
name|PTE1_OFFSET
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: misaligned va %#x"
operator|,
name|__func__
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
name|npte1
operator|=
name|PTE1_KERN
argument_list|(
name|start
argument_list|,
name|l1prot
argument_list|,
name|l1attr
argument_list|)
expr_stmt|;
name|pmap_kenter_pte1
argument_list|(
name|va
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PTE1_SIZE
expr_stmt|;
name|start
operator|+=
name|PTE1_SIZE
expr_stmt|;
block|}
else|else
block|{
name|pmap_kenter_prot_attr
argument_list|(
name|va
argument_list|,
name|start
argument_list|,
name|l2prot
argument_list|,
name|l2attr
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|start
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
name|tlb_flush_range
argument_list|(
name|sva
argument_list|,
name|va
operator|-
name|sva
argument_list|)
expr_stmt|;
operator|*
name|virt
operator|=
name|va
expr_stmt|;
return|return
operator|(
name|sva
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Make a temporary mapping for a physical address.  *  This is only intended to be used for panic dumps.  */
end_comment

begin_function
name|void
modifier|*
name|pmap_kenter_temporary
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|int
name|i
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
comment|/* QQQ: 'i' should be less or equal to MAXDUMPPGS. */
name|va
operator|=
operator|(
name|vm_offset_t
operator|)
name|crashdumpmap
operator|+
operator|(
name|i
operator|*
name|PAGE_SIZE
operator|)
expr_stmt|;
name|pmap_kenter
argument_list|(
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|tlb_flush_local
argument_list|(
name|va
argument_list|)
expr_stmt|;
return|return
operator|(
operator|(
name|void
operator|*
operator|)
name|crashdumpmap
operator|)
return|;
block|}
end_function

begin_comment
comment|/*************************************  *  *  TLB& cache maintenance routines.  *  *************************************/
end_comment

begin_comment
comment|/*  *  We inline these within pmap.c for speed.  */
end_comment

begin_function
name|PMAP_INLINE
name|void
name|pmap_tlb_flush
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
operator|!
name|CPU_EMPTY
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
condition|)
name|tlb_flush
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|PMAP_INLINE
name|void
name|pmap_tlb_flush_range
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
operator|!
name|CPU_EMPTY
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
condition|)
name|tlb_flush_range
argument_list|(
name|sva
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Abuse the pte2 nodes for unmapped kva to thread a kva freelist through.  *  Requirements:  *   - Must deal with pages in order to ensure that none of the PTE2_* bits  *     are ever set, PTE2_V in particular.  *   - Assumes we can write to pte2s without pte2_store() atomic ops.  *   - Assumes nothing will ever test these addresses for 0 to indicate  *     no mapping instead of correctly checking PTE2_V.  *   - Assumes a vm_offset_t will fit in a pte2 (true for arm).  *  Because PTE2_V is never set, there can be no mappings to invalidate.  */
end_comment

begin_function
specifier|static
name|vm_offset_t
name|pmap_pte2list_alloc
parameter_list|(
name|vm_offset_t
modifier|*
name|head
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|va
operator|=
operator|*
name|head
expr_stmt|;
if|if
condition|(
name|va
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_ptelist_alloc: exhausted ptelist KVA"
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|pt2map_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
operator|*
name|head
operator|=
operator|*
name|pte2p
expr_stmt|;
if|if
condition|(
operator|*
name|head
operator|&
name|PTE2_V
condition|)
name|panic
argument_list|(
literal|"%s: va with PTE2_V set!"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
operator|*
name|pte2p
operator|=
literal|0
expr_stmt|;
return|return
operator|(
name|va
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_pte2list_free
parameter_list|(
name|vm_offset_t
modifier|*
name|head
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
if|if
condition|(
name|va
operator|&
name|PTE2_V
condition|)
name|panic
argument_list|(
literal|"%s: freeing va with PTE2_V set!"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|pt2map_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
operator|*
name|pte2p
operator|=
operator|*
name|head
expr_stmt|;
comment|/* virtual! PTE2_V is 0 though */
operator|*
name|head
operator|=
name|va
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_pte2list_init
parameter_list|(
name|vm_offset_t
modifier|*
name|head
parameter_list|,
name|void
modifier|*
name|base
parameter_list|,
name|int
name|npages
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
operator|*
name|head
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
name|npages
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|va
operator|=
operator|(
name|vm_offset_t
operator|)
name|base
operator|+
name|i
operator|*
name|PAGE_SIZE
expr_stmt|;
name|pmap_pte2list_free
argument_list|(
name|head
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*****************************************************************************  *  *	PMAP third and final stage initialization.  *  *  After pmap_init() is called, PMAP subsystem is fully initialized.  *  *****************************************************************************/
end_comment

begin_expr_stmt
name|SYSCTL_NODE
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|pmap
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|"VM/pmap parameters"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_max
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_max
argument_list|,
literal|0
argument_list|,
literal|"Max number of PV entries"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|shpgperproc
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|shpgperproc
argument_list|,
literal|0
argument_list|,
literal|"Page share factor per proc"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|nkpt2pg
init|=
name|NKPT2PG
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|nkpt2pg
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|nkpt2pg
argument_list|,
literal|0
argument_list|,
literal|"Pre-allocated pages for kernel PT2s"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|sp_enabled
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|sp_enabled
argument_list|,
name|CTLFLAG_RDTUN
operator||
name|CTLFLAG_NOFETCH
argument_list|,
operator|&
name|sp_enabled
argument_list|,
literal|0
argument_list|,
literal|"Are large page mappings enabled?"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
specifier|static
name|SYSCTL_NODE
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pte1
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|"1MB page mapping counters"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pte1_demotions
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pte1
argument_list|,
name|OID_AUTO
argument_list|,
name|demotions
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pte1_demotions
argument_list|,
literal|0
argument_list|,
literal|"1MB page demotions"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pte1_mappings
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pte1
argument_list|,
name|OID_AUTO
argument_list|,
name|mappings
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pte1_mappings
argument_list|,
literal|0
argument_list|,
literal|"1MB page mappings"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pte1_p_failures
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pte1
argument_list|,
name|OID_AUTO
argument_list|,
name|p_failures
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pte1_p_failures
argument_list|,
literal|0
argument_list|,
literal|"1MB page promotion failures"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pte1_promotions
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pte1
argument_list|,
name|OID_AUTO
argument_list|,
name|promotions
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pte1_promotions
argument_list|,
literal|0
argument_list|,
literal|"1MB page promotions"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pte1_kern_demotions
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pte1
argument_list|,
name|OID_AUTO
argument_list|,
name|kern_demotions
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pte1_kern_demotions
argument_list|,
literal|0
argument_list|,
literal|"1MB page kernel demotions"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pte1_kern_promotions
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pte1
argument_list|,
name|OID_AUTO
argument_list|,
name|kern_promotions
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pte1_kern_promotions
argument_list|,
literal|0
argument_list|,
literal|"1MB page kernel promotions"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|__inline
name|ttb_entry_t
name|pmap_ttb_get
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
return|return
operator|(
name|vtophys
argument_list|(
name|pmap
operator|->
name|pm_pt1
argument_list|)
operator||
name|ttb_flags
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Initialize a vm_page's machine-dependent fields.  *  *  Variations:  *  1. Pages for L2 page tables are always not managed. So, pv_list and  *     pt2_wirecount can share same physical space. However, proper  *     initialization on a page alloc for page tables and reinitialization  *     on the page free must be ensured.  */
end_comment

begin_function
name|void
name|pmap_page_init
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|TAILQ_INIT
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
expr_stmt|;
name|pt2_wirecount_init
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pat_mode
operator|=
name|VM_MEMATTR_DEFAULT
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Virtualization for faster way how to zero whole page.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pagezero
parameter_list|(
name|void
modifier|*
name|page
parameter_list|)
block|{
name|bzero
argument_list|(
name|page
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Zero L2 page table page.  *  Use same KVA as in pmap_zero_page().  */
end_comment

begin_function
specifier|static
name|__inline
name|vm_paddr_t
name|pmap_pt2pg_zero
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|cmap2_pte2p
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * XXX: For now, we map whole page even if it's already zero, 	 *      to sync it even if the sync is only DSB. 	 */
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap2_pte2p
operator|=
name|pc
operator|->
name|pc_cmap2_pte2p
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_load
argument_list|(
name|cmap2_pte2p
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: CMAP2 busy"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|cmap2_pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|pa
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
comment|/*  Even VM_ALLOC_ZERO request is only advisory. */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pagezero
argument_list|(
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|pte2_sync_range
argument_list|(
operator|(
name|pt2_entry_t
operator|*
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|cmap2_pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
comment|/* 	 * Unpin the thread before releasing the lock.  Otherwise the thread 	 * could be rescheduled while still bound to the current CPU, only 	 * to unpin itself immediately upon resuming execution. 	 */
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Init just allocated page as L2 page table(s) holder  *  and return its physical address.  */
end_comment

begin_function
specifier|static
name|__inline
name|vm_paddr_t
name|pmap_pt2pg_init
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
comment|/* Check page attributes. */
if|if
condition|(
name|m
operator|->
name|md
operator|.
name|pat_mode
operator|!=
name|pt_memattr
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|pt_memattr
argument_list|)
expr_stmt|;
comment|/* Zero page and init wire counts. */
name|pa
operator|=
name|pmap_pt2pg_zero
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pt2_wirecount_init
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Map page to PT2MAP address space for given pmap. 	 * Note that PT2MAP space is shared with all pmaps. 	 */
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|pmap_kenter_pt2tab
argument_list|(
name|va
argument_list|,
name|PTE2_KPT
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
else|else
block|{
name|pte2p
operator|=
name|pmap_pt2tab_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pt2tab_store
argument_list|(
name|pte2p
argument_list|,
name|PTE2_KPT_NG
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Initialize the pmap module.  *  Called by vm_init, to initialize any structures that the pmap  *  system needs to map virtual memory.  */
end_comment

begin_function
name|void
name|pmap_init
parameter_list|(
name|void
parameter_list|)
block|{
name|vm_size_t
name|s
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|u_int
name|i
decl_stmt|,
name|pte1_idx
decl_stmt|,
name|pv_npg
decl_stmt|;
name|PDEBUG
argument_list|(
literal|1
argument_list|,
name|printf
argument_list|(
literal|"%s: phys_start = %#x\n"
argument_list|,
name|__func__
argument_list|,
name|PHYSADDR
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the vm page array entries for kernel pmap's 	 * L2 page table pages allocated in advance. 	 */
name|pte1_idx
operator|=
name|pte1_index
argument_list|(
name|KERNBASE
operator|-
name|PT2MAP_SIZE
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|kern_pt2tab_entry
argument_list|(
name|KERNBASE
operator|-
name|PT2MAP_SIZE
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nkpt2pg
operator|+
name|NPG_IN_PT2TAB
condition|;
name|i
operator|++
operator|,
name|pte2p
operator|++
control|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
argument_list|,
operator|(
literal|"%s: no valid entry"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|pa
operator|=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|>=
name|vm_page_array
operator|&&
name|m
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"%s: L2 page table page is out of range"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|pindex
operator|=
name|pte1_idx
expr_stmt|;
name|m
operator|->
name|phys_addr
operator|=
name|pa
expr_stmt|;
name|pte1_idx
operator|+=
name|NPT2_IN_PG
expr_stmt|;
block|}
comment|/* 	 * Initialize the address space (zone) for the pv entries.  Set a 	 * high water mark so that the system can recover from excessive 	 * numbers of pv entries. 	 */
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.pmap.shpgperproc"
argument_list|,
operator|&
name|shpgperproc
argument_list|)
expr_stmt|;
name|pv_entry_max
operator|=
name|shpgperproc
operator|*
name|maxproc
operator|+
name|vm_cnt
operator|.
name|v_page_count
expr_stmt|;
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.pmap.pv_entries"
argument_list|,
operator|&
name|pv_entry_max
argument_list|)
expr_stmt|;
name|pv_entry_max
operator|=
name|roundup
argument_list|(
name|pv_entry_max
argument_list|,
name|_NPCPV
argument_list|)
expr_stmt|;
name|pv_entry_high_water
operator|=
literal|9
operator|*
operator|(
name|pv_entry_max
operator|/
literal|10
operator|)
expr_stmt|;
comment|/* 	 * Are large page mappings enabled? 	 */
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.pmap.sp_enabled"
argument_list|,
operator|&
name|sp_enabled
argument_list|)
expr_stmt|;
if|if
condition|(
name|sp_enabled
condition|)
block|{
name|KASSERT
argument_list|(
name|MAXPAGESIZES
operator|>
literal|1
operator|&&
name|pagesizes
index|[
literal|1
index|]
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: can't assign to pagesizes[1]"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|pagesizes
index|[
literal|1
index|]
operator|=
name|PTE1_SIZE
expr_stmt|;
block|}
comment|/* 	 * Calculate the size of the pv head table for sections. 	 * Handle the possibility that "vm_phys_segs[...].end" is zero. 	 * Note that the table is only for sections which could be promoted. 	 */
name|first_managed_pa
operator|=
name|pte1_trunc
argument_list|(
name|vm_phys_segs
index|[
literal|0
index|]
operator|.
name|start
argument_list|)
expr_stmt|;
name|pv_npg
operator|=
operator|(
name|pte1_trunc
argument_list|(
name|vm_phys_segs
index|[
name|vm_phys_nsegs
operator|-
literal|1
index|]
operator|.
name|end
operator|-
name|PAGE_SIZE
argument_list|)
operator|-
name|first_managed_pa
operator|)
operator|/
name|PTE1_SIZE
operator|+
literal|1
expr_stmt|;
comment|/* 	 * Allocate memory for the pv head table for sections. 	 */
name|s
operator|=
call|(
name|vm_size_t
call|)
argument_list|(
name|pv_npg
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|md_page
argument_list|)
argument_list|)
expr_stmt|;
name|s
operator|=
name|round_page
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|pv_table
operator|=
operator|(
expr|struct
name|md_page
operator|*
operator|)
name|kmem_malloc
argument_list|(
name|kernel_arena
argument_list|,
name|s
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pv_npg
condition|;
name|i
operator|++
control|)
name|TAILQ_INIT
argument_list|(
operator|&
name|pv_table
index|[
name|i
index|]
operator|.
name|pv_list
argument_list|)
expr_stmt|;
name|pv_maxchunks
operator|=
name|MAX
argument_list|(
name|pv_entry_max
operator|/
name|_NPCPV
argument_list|,
name|maxproc
argument_list|)
expr_stmt|;
name|pv_chunkbase
operator|=
operator|(
expr|struct
name|pv_chunk
operator|*
operator|)
name|kva_alloc
argument_list|(
name|PAGE_SIZE
operator|*
name|pv_maxchunks
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv_chunkbase
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"%s: not enough kvm for pv chunks"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pmap_pte2list_init
argument_list|(
operator|&
name|pv_vafree
argument_list|,
name|pv_chunkbase
argument_list|,
name|pv_maxchunks
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Add a list of wired pages to the kva  *  this routine is only used for temporary  *  kernel mappings that do not need to have  *  page modification or references recorded.  *  Note that old mappings are simply written  *  over.  The page *must* be wired.  *  Note: SMP coherent.  Uses a ranged shootdown IPI.  */
end_comment

begin_function
name|void
name|pmap_qenter
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|u_int
name|anychanged
decl_stmt|;
name|pt2_entry_t
modifier|*
name|epte2p
decl_stmt|,
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|anychanged
operator|=
literal|0
expr_stmt|;
name|pte2p
operator|=
name|pt2map_entry
argument_list|(
name|sva
argument_list|)
expr_stmt|;
name|epte2p
operator|=
name|pte2p
operator|+
name|count
expr_stmt|;
while|while
condition|(
name|pte2p
operator|<
name|epte2p
condition|)
block|{
name|m
operator|=
operator|*
name|ma
operator|++
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
operator|!=
name|pa
operator|)
operator|||
operator|(
name|pte2_attr
argument_list|(
name|pte2
argument_list|)
operator|!=
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
operator|)
condition|)
block|{
name|anychanged
operator|++
expr_stmt|;
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|PTE2_KERN
argument_list|(
name|pa
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|pte2p
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|__predict_false
argument_list|(
name|anychanged
argument_list|)
condition|)
name|tlb_flush_range
argument_list|(
name|sva
argument_list|,
name|count
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  This routine tears out page mappings from the  *  kernel -- it is meant only for temporary mappings.  *  Note: SMP coherent.  Uses a ranged shootdown IPI.  */
end_comment

begin_function
name|void
name|pmap_qremove
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|pmap_kremove
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|tlb_flush_range
argument_list|(
name|sva
argument_list|,
name|va
operator|-
name|sva
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Are we current address space or kernel?  */
end_comment

begin_function
specifier|static
name|__inline
name|int
name|pmap_is_current
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
return|return
operator|(
name|pmap
operator|==
name|kernel_pmap
operator|||
operator|(
name|pmap
operator|==
name|vmspace_pmap
argument_list|(
name|curthread
operator|->
name|td_proc
operator|->
name|p_vmspace
argument_list|)
operator|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  If the given pmap is not the current or kernel pmap, the returned  *  pte2 must be released by passing it to pmap_pte2_release().  */
end_comment

begin_function
specifier|static
name|pt2_entry_t
modifier|*
name|pmap_pte2
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt1_entry_t
name|pte1
decl_stmt|;
name|vm_paddr_t
name|pt2pg_pa
decl_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
name|panic
argument_list|(
literal|"%s: attempt to map PTE1"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
comment|/* Are we current address space or kernel? */
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
return|return
operator|(
name|pt2map_entry
argument_list|(
name|va
argument_list|)
operator|)
return|;
comment|/* Note that L2 page table size is not equal to PAGE_SIZE. */
name|pt2pg_pa
operator|=
name|trunc_page
argument_list|(
name|pte1_link_pa
argument_list|(
name|pte1
argument_list|)
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|PMAP2mutex
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_pa
argument_list|(
name|pte2_load
argument_list|(
name|PMAP2
argument_list|)
argument_list|)
operator|!=
name|pt2pg_pa
condition|)
block|{
name|pte2_store
argument_list|(
name|PMAP2
argument_list|,
name|PTE2_KPT
argument_list|(
name|pt2pg_pa
argument_list|)
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PADDR2
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|PADDR2
operator|+
operator|(
name|arm32_btop
argument_list|(
name|va
argument_list|)
operator|&
operator|(
name|NPTE2_IN_PG
operator|-
literal|1
operator|)
operator|)
operator|)
return|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Releases a pte2 that was obtained from pmap_pte2().  *  Be prepared for the pte2p being NULL.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_pte2_release
parameter_list|(
name|pt2_entry_t
modifier|*
name|pte2p
parameter_list|)
block|{
if|if
condition|(
operator|(
name|pt2_entry_t
operator|*
operator|)
operator|(
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pte2p
argument_list|)
operator|)
operator|==
name|PADDR2
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|PMAP2mutex
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *  Super fast pmap_pte2 routine best used when scanning  *  the pv lists.  This eliminates many coarse-grained  *  invltlb calls.  Note that many of the pv list  *  scans are across different pmaps.  It is very wasteful  *  to do an entire tlb flush for checking a single mapping.  *  *  If the given pmap is not the current pmap, pvh_global_lock  *  must be held and curthread pinned to a CPU.  */
end_comment

begin_function
specifier|static
name|pt2_entry_t
modifier|*
name|pmap_pte2_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt1_entry_t
name|pte1
decl_stmt|;
name|vm_paddr_t
name|pt2pg_pa
decl_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
name|panic
argument_list|(
literal|"%s: attempt to map PTE1"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
comment|/* Are we current address space or kernel? */
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
return|return
operator|(
name|pt2map_entry
argument_list|(
name|va
argument_list|)
operator|)
return|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|curthread
operator|->
name|td_pinned
operator|>
literal|0
argument_list|,
operator|(
literal|"%s: curthread not pinned"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
comment|/* Note that L2 page table size is not equal to PAGE_SIZE. */
name|pt2pg_pa
operator|=
name|trunc_page
argument_list|(
name|pte1_link_pa
argument_list|(
name|pte1
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_pa
argument_list|(
name|pte2_load
argument_list|(
name|PMAP1
argument_list|)
argument_list|)
operator|!=
name|pt2pg_pa
condition|)
block|{
name|pte2_store
argument_list|(
name|PMAP1
argument_list|,
name|PTE2_KPT
argument_list|(
name|pt2pg_pa
argument_list|)
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|PMAP1cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|tlb_flush_local
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PADDR1
argument_list|)
expr_stmt|;
name|PMAP1changed
operator|++
expr_stmt|;
block|}
elseif|else
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|PMAP1cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
block|{
name|PMAP1cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|tlb_flush_local
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PADDR1
argument_list|)
expr_stmt|;
name|PMAP1changedcpu
operator|++
expr_stmt|;
block|}
else|else
endif|#
directive|endif
name|PMAP1unchanged
operator|++
expr_stmt|;
return|return
operator|(
name|PADDR1
operator|+
operator|(
name|arm32_btop
argument_list|(
name|va
argument_list|)
operator|&
operator|(
name|NPTE2_IN_PG
operator|-
literal|1
operator|)
operator|)
operator|)
return|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Routine: pmap_extract  *  Function:  * 	Extract the physical page address associated  *	with the given map/virtual_address pair.  */
end_comment

begin_function
name|vm_paddr_t
name|pmap_extract
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
name|pa
operator|=
name|pte1_pa
argument_list|(
name|pte1
argument_list|)
operator||
operator|(
name|va
operator|&
name|PTE1_OFFSET
operator|)
expr_stmt|;
elseif|else
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pte2p
operator|=
name|pmap_pte2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pa
operator|=
name|pte2_pa
argument_list|(
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
argument_list|)
operator||
operator|(
name|va
operator|&
name|PTE2_OFFSET
operator|)
expr_stmt|;
name|pmap_pte2_release
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
block|}
else|else
name|pa
operator|=
literal|0
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Routine: pmap_extract_and_hold  *  Function:  *	Atomically extract and hold the physical page  *	with the given pmap and virtual address pair  *	if that mapping permits the given protection.  */
end_comment

begin_function
name|vm_page_t
name|pmap_extract_and_hold
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|,
name|lockpa
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|,
modifier|*
name|pte2p
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|lockpa
operator|=
literal|0
expr_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
operator|(
name|pte1
operator|&
name|PTE1_RO
operator|)
operator|||
operator|!
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
condition|)
block|{
name|pa
operator|=
name|pte1_pa
argument_list|(
name|pte1
argument_list|)
operator||
operator|(
name|va
operator|&
name|PTE1_OFFSET
operator|)
expr_stmt|;
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|pa
argument_list|,
operator|&
name|lockpa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pte2p
operator|=
name|pmap_pte2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|pmap_pte2_release
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
operator|&&
operator|(
operator|!
operator|(
name|pte2
operator|&
name|PTE2_RO
operator|)
operator|||
operator|!
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|)
condition|)
block|{
name|pa
operator|=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|pa
argument_list|,
operator|&
name|lockpa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
name|PA_UNLOCK_COND
argument_list|(
name|lockpa
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Grow the number of kernel L2 page table entries, if needed.  */
end_comment

begin_function
name|void
name|pmap_growkernel
parameter_list|(
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_paddr_t
name|pt2pg_pa
decl_stmt|,
name|pt2_pa
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|PDEBUG
argument_list|(
literal|1
argument_list|,
name|printf
argument_list|(
literal|"%s: addr = %#x\n"
argument_list|,
name|__func__
argument_list|,
name|addr
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * All the time kernel_vm_end is first KVA for which underlying 	 * L2 page table is either not allocated or linked from L1 page table 	 * (not considering sections). Except for two possible cases: 	 * 	 *   (1) in the very beginning as long as pmap_growkernel() was 	 *       not called, it could be first unused KVA (which is not 	 *       rounded up to PTE1_SIZE), 	 * 	 *   (2) when all KVA space is mapped and kernel_map->max_offset 	 *       address is not rounded up to PTE1_SIZE. (For example, 	 *       it could be 0xFFFFFFFF.) 	 */
name|kernel_vm_end
operator|=
name|pte1_roundup
argument_list|(
name|kernel_vm_end
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|kernel_map
operator|->
name|system_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|addr
operator|=
name|roundup2
argument_list|(
name|addr
argument_list|,
name|PTE1_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|addr
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
name|addr
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
while|while
condition|(
name|kernel_vm_end
operator|<
name|addr
condition|)
block|{
name|pte1
operator|=
name|pte1_load
argument_list|(
name|kern_pte1
argument_list|(
name|kernel_vm_end
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_valid
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|kernel_vm_end
operator|+=
name|PTE1_SIZE
expr_stmt|;
if|if
condition|(
name|kernel_vm_end
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
block|{
name|kernel_vm_end
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
break|break;
block|}
continue|continue;
block|}
comment|/* 		 * kernel_vm_end_new is used in pmap_pinit() when kernel 		 * mappings are entered to new pmap all at once to avoid race 		 * between pmap_kenter_pte1() and kernel_vm_end increase. 		 * The same aplies to pmap_kenter_pt2tab(). 		 */
name|kernel_vm_end_new
operator|=
name|kernel_vm_end
operator|+
name|PTE1_SIZE
expr_stmt|;
name|pte2
operator|=
name|pt2tab_load
argument_list|(
name|kern_pt2tab_entry
argument_list|(
name|kernel_vm_end
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
block|{
comment|/* 			 * Install new PT2s page into kernel PT2TAB. 			 */
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|pte1_index
argument_list|(
name|kernel_vm_end
argument_list|)
operator|&
operator|~
name|PT2PG_MASK
argument_list|,
name|VM_ALLOC_INTERRUPT
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"%s: no memory to grow kernel"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
comment|/* 			 * QQQ: To link all new L2 page tables from L1 page 			 *      table now and so pmap_kenter_pte1() them 			 *      at once together with pmap_kenter_pt2tab() 			 *      could be nice speed up. However, 			 *      pmap_growkernel() does not happen so often... 			 * QQQ: The other TTBR is another option. 			 */
name|pt2pg_pa
operator|=
name|pmap_pt2pg_init
argument_list|(
name|kernel_pmap
argument_list|,
name|kernel_vm_end
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
else|else
name|pt2pg_pa
operator|=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
name|pt2_pa
operator|=
name|page_pt2pa
argument_list|(
name|pt2pg_pa
argument_list|,
name|pte1_index
argument_list|(
name|kernel_vm_end
argument_list|)
argument_list|)
expr_stmt|;
name|pmap_kenter_pte1
argument_list|(
name|kernel_vm_end
argument_list|,
name|PTE1_LINK
argument_list|(
name|pt2_pa
argument_list|)
argument_list|)
expr_stmt|;
name|kernel_vm_end
operator|=
name|kernel_vm_end_new
expr_stmt|;
if|if
condition|(
name|kernel_vm_end
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
block|{
name|kernel_vm_end
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
break|break;
block|}
block|}
block|}
end_function

begin_function
specifier|static
name|int
name|kvm_size
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|unsigned
name|long
name|ksize
init|=
name|vm_max_kernel_address
operator|-
name|KERNBASE
decl_stmt|;
return|return
operator|(
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
operator|&
name|ksize
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
operator|)
return|;
block|}
end_function

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|kvm_size
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|kvm_size
argument_list|,
literal|"IU"
argument_list|,
literal|"Size of KVM"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|kvm_free
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|unsigned
name|long
name|kfree
init|=
name|vm_max_kernel_address
operator|-
name|kernel_vm_end
decl_stmt|;
return|return
operator|(
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
operator|&
name|kfree
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
operator|)
return|;
block|}
end_function

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|kvm_free
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|kvm_free
argument_list|,
literal|"IU"
argument_list|,
literal|"Amount of KVM free"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/***********************************************  *  *  Pmap allocation/deallocation routines.  *  ***********************************************/
end_comment

begin_comment
comment|/*  *  Initialize the pmap for the swapper process.  */
end_comment

begin_function
name|void
name|pmap_pinit0
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|PDEBUG
argument_list|(
literal|1
argument_list|,
name|printf
argument_list|(
literal|"%s: pmap = %p\n"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_INIT
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Kernel page table directory and pmap stuff around is already 	 * initialized, we are using it right now and here. So, finish 	 * only PMAP structures initialization for process0 ... 	 * 	 * Since the L1 page table and PT2TAB is shared with the kernel pmap, 	 * which is already included in the list "allpmaps", this pmap does 	 * not need to be inserted into that list. 	 */
name|pmap
operator|->
name|pm_pt1
operator|=
name|kern_pt1
expr_stmt|;
name|pmap
operator|->
name|pm_pt2tab
operator|=
name|kern_pt2tab
expr_stmt|;
name|CPU_ZERO
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pmap
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
name|pmap
operator|->
name|pm_stats
argument_list|)
expr_stmt|;
name|CPU_SET
argument_list|(
literal|0
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pte1_copy_nosync
parameter_list|(
name|pt1_entry_t
modifier|*
name|spte1p
parameter_list|,
name|pt1_entry_t
modifier|*
name|dpte1p
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|u_int
name|idx
decl_stmt|,
name|count
decl_stmt|;
name|idx
operator|=
name|pte1_index
argument_list|(
name|sva
argument_list|)
expr_stmt|;
name|count
operator|=
operator|(
name|pte1_index
argument_list|(
name|eva
argument_list|)
operator|-
name|idx
operator|+
literal|1
operator|)
operator|*
sizeof|sizeof
argument_list|(
name|pt1_entry_t
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|spte1p
operator|+
name|idx
argument_list|,
name|dpte1p
operator|+
name|idx
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pt2tab_copy_nosync
parameter_list|(
name|pt2_entry_t
modifier|*
name|spte2p
parameter_list|,
name|pt2_entry_t
modifier|*
name|dpte2p
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|u_int
name|idx
decl_stmt|,
name|count
decl_stmt|;
name|idx
operator|=
name|pt2tab_index
argument_list|(
name|sva
argument_list|)
expr_stmt|;
name|count
operator|=
operator|(
name|pt2tab_index
argument_list|(
name|eva
argument_list|)
operator|-
name|idx
operator|+
literal|1
operator|)
operator|*
sizeof|sizeof
argument_list|(
name|pt2_entry_t
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|spte2p
operator|+
name|idx
argument_list|,
name|dpte2p
operator|+
name|idx
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Initialize a preallocated and zeroed pmap structure,  *  such as one in a vmspace structure.  */
end_comment

begin_function
name|int
name|pmap_pinit
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|,
name|pt2tab_pa
decl_stmt|;
name|u_int
name|i
decl_stmt|;
name|PDEBUG
argument_list|(
literal|6
argument_list|,
name|printf
argument_list|(
literal|"%s: pmap = %p, pm_pt1 = %p\n"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|pmap
operator|->
name|pm_pt1
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * No need to allocate L2 page table space yet but we do need 	 * a valid L1 page table and PT2TAB table. 	 * 	 * Install shared kernel mappings to these tables. It's a little 	 * tricky as some parts of KVA are reserved for vectors, devices, 	 * and whatever else. These parts are supposed to be above 	 * vm_max_kernel_address. Thus two regions should be installed: 	 * 	 *   (1)<KERNBASE, kernel_vm_end), 	 *   (2)<vm_max_kernel_address, 0xFFFFFFFF>. 	 * 	 * QQQ: The second region should be stable enough to be installed 	 *      only once in time when the tables are allocated. 	 * QQQ: Maybe copy of both regions at once could be faster ... 	 * QQQ: Maybe the other TTBR is an option. 	 * 	 * Finally, install own PT2TAB table to these tables. 	 */
if|if
condition|(
name|pmap
operator|->
name|pm_pt1
operator|==
name|NULL
condition|)
block|{
name|pmap
operator|->
name|pm_pt1
operator|=
operator|(
name|pt1_entry_t
operator|*
operator|)
name|kmem_alloc_contig
argument_list|(
name|kernel_arena
argument_list|,
name|NB_IN_PT1
argument_list|,
name|M_NOWAIT
operator||
name|M_ZERO
argument_list|,
literal|0
argument_list|,
operator|-
literal|1UL
argument_list|,
name|NB_IN_PT1
argument_list|,
literal|0
argument_list|,
name|pt_memattr
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_pt1
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
block|}
if|if
condition|(
name|pmap
operator|->
name|pm_pt2tab
operator|==
name|NULL
condition|)
block|{
comment|/* 		 * QQQ: (1) PT2TAB must be contiguous. If PT2TAB is one page 		 *      only, what should be the only size for 32 bit systems, 		 *      then we could allocate it with vm_page_alloc() and all 		 *      the stuff needed as other L2 page table pages. 		 *      (2) Note that a process PT2TAB is special L2 page table 		 *      page. Its mapping in kernel_arena is permanent and can 		 *      be used no matter which process is current. Its mapping 		 *      in PT2MAP can be used only for current process. 		 */
name|pmap
operator|->
name|pm_pt2tab
operator|=
operator|(
name|pt2_entry_t
operator|*
operator|)
name|kmem_alloc_attr
argument_list|(
name|kernel_arena
argument_list|,
name|NB_IN_PT2TAB
argument_list|,
name|M_NOWAIT
operator||
name|M_ZERO
argument_list|,
literal|0
argument_list|,
operator|-
literal|1UL
argument_list|,
name|pt_memattr
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_pt2tab
operator|==
name|NULL
condition|)
block|{
comment|/* 			 * QQQ: As struct pmap is allocated from UMA with 			 *      UMA_ZONE_NOFREE flag, it's important to leave 			 *      no allocation in pmap if initialization failed. 			 */
name|kmem_free
argument_list|(
name|kernel_arena
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|pmap
operator|->
name|pm_pt1
argument_list|,
name|NB_IN_PT1
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_pt1
operator|=
name|NULL
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
comment|/* 		 * QQQ: Each L2 page table page vm_page_t has pindex set to 		 *      pte1 index of virtual address mapped by this page. 		 *      It's not valid for non kernel PT2TABs themselves. 		 *      The pindex of these pages can not be altered because 		 *      of the way how they are allocated now. However, it 		 *      should not be a problem. 		 */
block|}
name|mtx_lock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
comment|/* 	 * To avoid race with pmap_kenter_pte1() and pmap_kenter_pt2tab(), 	 * kernel_vm_end_new is used here instead of kernel_vm_end. 	 */
name|pte1_copy_nosync
argument_list|(
name|kern_pt1
argument_list|,
name|pmap
operator|->
name|pm_pt1
argument_list|,
name|KERNBASE
argument_list|,
name|kernel_vm_end_new
operator|-
literal|1
argument_list|)
expr_stmt|;
name|pte1_copy_nosync
argument_list|(
name|kern_pt1
argument_list|,
name|pmap
operator|->
name|pm_pt1
argument_list|,
name|vm_max_kernel_address
argument_list|,
literal|0xFFFFFFFF
argument_list|)
expr_stmt|;
name|pt2tab_copy_nosync
argument_list|(
name|kern_pt2tab
argument_list|,
name|pmap
operator|->
name|pm_pt2tab
argument_list|,
name|KERNBASE
argument_list|,
name|kernel_vm_end_new
operator|-
literal|1
argument_list|)
expr_stmt|;
name|pt2tab_copy_nosync
argument_list|(
name|kern_pt2tab
argument_list|,
name|pmap
operator|->
name|pm_pt2tab
argument_list|,
name|vm_max_kernel_address
argument_list|,
literal|0xFFFFFFFF
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|allpmaps
argument_list|,
name|pmap
argument_list|,
name|pm_list
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
comment|/* 	 * Store PT2MAP PT2 pages (a.k.a. PT2TAB) in PT2TAB itself. 	 * I.e. self reference mapping.  The PT2TAB is private, however mapped 	 * into shared PT2MAP space, so the mapping should be not global. 	 */
name|pt2tab_pa
operator|=
name|vtophys
argument_list|(
name|pmap
operator|->
name|pm_pt2tab
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|pmap_pt2tab_entry
argument_list|(
name|pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|PT2MAP
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|pt2tab_pa
operator|,
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPG_IN_PT2TAB
condition|;
name|i
operator|++
operator|,
name|pa
operator|+=
name|PTE2_SIZE
control|)
block|{
name|pt2tab_store
argument_list|(
name|pte2p
operator|++
argument_list|,
name|PTE2_KPT_NG
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* Insert PT2MAP PT2s into pmap PT1. */
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|PT2MAP
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|pt2tab_pa
operator|,
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPT2_IN_PT2TAB
condition|;
name|i
operator|++
operator|,
name|pa
operator|+=
name|NB_IN_PT2
control|)
block|{
name|pte1_store
argument_list|(
name|pte1p
operator|++
argument_list|,
name|PTE1_LINK
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Now synchronize new mapping which was made above. 	 */
name|pte1_sync_range
argument_list|(
name|pmap
operator|->
name|pm_pt1
argument_list|,
name|NB_IN_PT1
argument_list|)
expr_stmt|;
name|pte2_sync_range
argument_list|(
name|pmap
operator|->
name|pm_pt2tab
argument_list|,
name|NB_IN_PT2TAB
argument_list|)
expr_stmt|;
name|CPU_ZERO
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pmap
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
name|pmap
operator|->
name|pm_stats
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|INVARIANTS
end_ifdef

begin_function
specifier|static
name|boolean_t
name|pt2tab_user_is_empty
parameter_list|(
name|pt2_entry_t
modifier|*
name|tab
parameter_list|)
block|{
name|u_int
name|i
decl_stmt|,
name|end
decl_stmt|;
name|end
operator|=
name|pt2tab_index
argument_list|(
name|VM_MAXUSER_ADDRESS
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|end
condition|;
name|i
operator|++
control|)
if|if
condition|(
name|tab
index|[
name|i
index|]
operator|!=
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  *  Release any resources held by the given physical map.  *  Called when a pmap initialized by pmap_pinit is being released.  *  Should only be called if the map contains no valid mappings.  */
end_comment

begin_function
name|void
name|pmap_release
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|INVARIANTS
name|vm_offset_t
name|start
decl_stmt|,
name|end
decl_stmt|;
endif|#
directive|endif
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: pmap resident count %ld != 0"
operator|,
name|__func__
operator|,
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pt2tab_user_is_empty
argument_list|(
name|pmap
operator|->
name|pm_pt2tab
argument_list|)
argument_list|,
operator|(
literal|"%s: has allocated user PT2(s)"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|CPU_EMPTY
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
argument_list|,
operator|(
literal|"%s: pmap %p is active on some CPU(s)"
operator|,
name|__func__
operator|,
name|pmap
operator|)
argument_list|)
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
name|LIST_REMOVE
argument_list|(
name|pmap
argument_list|,
name|pm_list
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|INVARIANTS
name|start
operator|=
name|pte1_index
argument_list|(
name|KERNBASE
argument_list|)
operator|*
sizeof|sizeof
argument_list|(
name|pt1_entry_t
argument_list|)
expr_stmt|;
name|end
operator|=
operator|(
name|pte1_index
argument_list|(
literal|0xFFFFFFFF
argument_list|)
operator|+
literal|1
operator|)
operator|*
sizeof|sizeof
argument_list|(
name|pt1_entry_t
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|char
operator|*
operator|)
name|pmap
operator|->
name|pm_pt1
operator|+
name|start
argument_list|,
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|start
operator|=
name|pt2tab_index
argument_list|(
name|KERNBASE
argument_list|)
operator|*
sizeof|sizeof
argument_list|(
name|pt2_entry_t
argument_list|)
expr_stmt|;
name|end
operator|=
operator|(
name|pt2tab_index
argument_list|(
literal|0xFFFFFFFF
argument_list|)
operator|+
literal|1
operator|)
operator|*
sizeof|sizeof
argument_list|(
name|pt2_entry_t
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|char
operator|*
operator|)
name|pmap
operator|->
name|pm_pt2tab
operator|+
name|start
argument_list|,
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * We are leaving PT1 and PT2TAB allocated on released pmap, 	 * so hopefully UMA vmspace_zone will always be inited with 	 * UMA_ZONE_NOFREE flag. 	 */
block|}
end_function

begin_comment
comment|/*********************************************************  *  *  L2 table pages and their pages management routines.  *  *********************************************************/
end_comment

begin_comment
comment|/*  *  Virtual interface for L2 page table wire counting.  *  *  Each L2 page table in a page has own counter which counts a number of  *  valid mappings in a table. Global page counter counts mappings in all  *  tables in a page plus a single itself mapping in PT2TAB.  *  *  During a promotion we leave the associated L2 page table counter  *  untouched, so the table (strictly speaking a page which holds it)  *  is never freed if promoted.  *  *  If a page m->wire_count == 1 then no valid mappings exist in any L2 page  *  table in the page and the page itself is only mapped in PT2TAB.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pt2_wirecount_init
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|i
decl_stmt|;
comment|/* 	 * Note: A page m is allocated with VM_ALLOC_WIRED flag and 	 *       m->wire_count should be already set correctly. 	 *       So, there is no need to set it again herein. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPT2_IN_PG
condition|;
name|i
operator|++
control|)
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|i
index|]
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pt2_wirecount_inc
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|uint32_t
name|pte1_idx
parameter_list|)
block|{
comment|/* 	 * Note: A just modificated pte2 (i.e. already allocated) 	 *       is acquiring one extra reference which must be 	 *       explicitly cleared. It influences the KASSERTs herein. 	 *       All L2 page tables in a page always belong to the same 	 *       pmap, so we allow only one extra reference for the page. 	 */
name|KASSERT
argument_list|(
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_idx
operator|&
name|PT2PG_MASK
index|]
operator|<
operator|(
name|NPTE2_IN_PT2
operator|+
literal|1
operator|)
argument_list|,
operator|(
literal|"%s: PT2 is overflowing ..."
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|<=
operator|(
name|NPTE2_IN_PG
operator|+
literal|1
operator|)
argument_list|,
operator|(
literal|"%s: PT2PG is overflowing ..."
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|++
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_idx
operator|&
name|PT2PG_MASK
index|]
operator|++
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pt2_wirecount_dec
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|uint32_t
name|pte1_idx
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_idx
operator|&
name|PT2PG_MASK
index|]
operator|!=
literal|0
argument_list|,
operator|(
literal|"%s: PT2 is underflowing ..."
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|>
literal|1
argument_list|,
operator|(
literal|"%s: PT2PG is underflowing ..."
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|--
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_idx
operator|&
name|PT2PG_MASK
index|]
operator|--
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pt2_wirecount_set
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|uint32_t
name|pte1_idx
parameter_list|,
name|uint16_t
name|count
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|count
operator|<=
name|NPTE2_IN_PT2
argument_list|,
operator|(
literal|"%s: invalid count %u"
operator|,
name|__func__
operator|,
name|count
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|>
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_idx
operator|&
name|PT2PG_MASK
index|]
argument_list|,
operator|(
literal|"%s: PT2PG corrupting (%u, %u) ..."
operator|,
name|__func__
operator|,
name|m
operator|->
name|wire_count
operator|,
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_idx
operator|&
name|PT2PG_MASK
index|]
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|-=
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_idx
operator|&
name|PT2PG_MASK
index|]
expr_stmt|;
name|m
operator|->
name|wire_count
operator|+=
name|count
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_idx
operator|&
name|PT2PG_MASK
index|]
operator|=
name|count
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|<=
operator|(
name|NPTE2_IN_PG
operator|+
literal|1
operator|)
argument_list|,
operator|(
literal|"%s: PT2PG is overflowed (%u) ..."
operator|,
name|__func__
operator|,
name|m
operator|->
name|wire_count
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|uint32_t
name|pt2_wirecount_get
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|uint32_t
name|pte1_idx
parameter_list|)
block|{
return|return
operator|(
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_idx
operator|&
name|PT2PG_MASK
index|]
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|boolean_t
name|pt2_is_empty
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
return|return
operator|(
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_index
argument_list|(
name|va
argument_list|)
operator|&
name|PT2PG_MASK
index|]
operator|==
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|boolean_t
name|pt2_is_full
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
return|return
operator|(
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|pte1_index
argument_list|(
name|va
argument_list|)
operator|&
name|PT2PG_MASK
index|]
operator|==
name|NPTE2_IN_PT2
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|boolean_t
name|pt2pg_is_empty
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
return|return
operator|(
name|m
operator|->
name|wire_count
operator|==
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  This routine is called if the L2 page table  *  is not mapped correctly.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|_pmap_allocpte2
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|u_int
name|flags
parameter_list|)
block|{
name|uint32_t
name|pte1_idx
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_paddr_t
name|pt2pg_pa
decl_stmt|,
name|pt2_pa
decl_stmt|;
name|pte1_idx
operator|=
name|pte1_index
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap
operator|->
name|pm_pt1
operator|+
name|pte1_idx
expr_stmt|;
name|KASSERT
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: pm_pt1[%#x] is not zero: %#x"
operator|,
name|__func__
operator|,
name|pte1_idx
operator|,
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
operator|)
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pt2tab_load
argument_list|(
name|pmap_pt2tab_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
block|{
comment|/* 		 * Install new PT2s page into pmap PT2TAB. 		 */
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|pte1_idx
operator|&
operator|~
name|PT2PG_MASK
argument_list|,
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|flags
operator|&
name|PMAP_ENTER_NOSLEEP
operator|)
operator|==
literal|0
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
comment|/* 			 * Indicate the need to retry.  While waiting, 			 * the L2 page table page may have been allocated. 			 */
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
name|pt2pg_pa
operator|=
name|pmap_pt2pg_init
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pt2pg_pa
operator|=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pt2pg_pa
argument_list|)
expr_stmt|;
block|}
name|pt2_wirecount_inc
argument_list|(
name|m
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
name|pt2_pa
operator|=
name|page_pt2pa
argument_list|(
name|pt2pg_pa
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|PTE1_LINK
argument_list|(
name|pt2_pa
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|vm_page_t
name|pmap_allocpte2
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|u_int
name|flags
parameter_list|)
block|{
name|u_int
name|pte1_idx
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|pte1
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|pte1_idx
operator|=
name|pte1_index
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|retry
label|:
name|pte1p
operator|=
name|pmap
operator|->
name|pm_pt1
operator|+
name|pte1_idx
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
comment|/* 	 * This supports switching from a 1MB page to a 	 * normal 4K page. 	 */
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
operator|(
name|void
operator|)
name|pmap_demote_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 		 * Reload pte1 after demotion. 		 * 		 * Note: Demotion can even fail as either PT2 is not find for 		 *       the virtual address or PT2PG can not be allocated. 		 */
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If the L2 page table page is mapped, we just increment the 	 * hold count, and activate it. 	 */
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte1_link_pa
argument_list|(
name|pte1
argument_list|)
argument_list|)
expr_stmt|;
name|pt2_wirecount_inc
argument_list|(
name|m
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Here if the PT2 isn't mapped, or if it has 		 * been deallocated. 		 */
name|m
operator|=
name|_pmap_allocpte2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
operator|&&
operator|(
name|flags
operator|&
name|PMAP_ENTER_NOSLEEP
operator|)
operator|==
literal|0
condition|)
goto|goto
name|retry
goto|;
block|}
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pmap_free_zero_pages
parameter_list|(
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
while|while
condition|(
operator|(
name|m
operator|=
name|SLIST_FIRST
argument_list|(
name|free
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|SLIST_REMOVE_HEAD
argument_list|(
name|free
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
comment|/* Preserve the page's PG_ZERO setting. */
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *  Schedule the specified unused L2 page table page to be freed. Specifically,  *  add the page to the specified list of pages that will be released to the  *  physical memory manager after the TLB has been updated.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_add_delayed_free_list
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
comment|/* 	 * Put page on a list so that it is released after 	 * *ALL* TLB shootdown is done 	 */
ifdef|#
directive|ifdef
name|PMAP_DEBUG
name|pmap_zero_page_check
argument_list|(
name|m
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|m
operator|->
name|flags
operator||=
name|PG_ZERO
expr_stmt|;
name|SLIST_INSERT_HEAD
argument_list|(
name|free
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Unwire L2 page tables page.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_unwire_pt2pg
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|opte1
name|__unused
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|uint32_t
name|i
decl_stmt|;
name|KASSERT
argument_list|(
name|pt2pg_is_empty
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"%s: pmap %p PT2PG %p wired"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Unmap all L2 page tables in the page from L1 page table. 	 * 	 * QQQ: Individual L2 page tables (except the last one) can be unmapped 	 * earlier. However, we are doing that this way. 	 */
name|KASSERT
argument_list|(
name|m
operator|->
name|pindex
operator|==
operator|(
name|pte1_index
argument_list|(
name|va
argument_list|)
operator|&
operator|~
name|PT2PG_MASK
operator|)
argument_list|,
operator|(
literal|"%s: pmap %p va %#x PT2PG %p bad index"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|va
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap
operator|->
name|pm_pt1
operator|+
name|m
operator|->
name|pindex
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPT2_IN_PG
condition|;
name|i
operator|++
operator|,
name|pte1p
operator|++
control|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|md
operator|.
name|pt2_wirecount
index|[
name|i
index|]
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: pmap %p PT2 %u (PG %p) wired"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|i
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|opte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_link
argument_list|(
name|opte1
argument_list|)
condition|)
block|{
name|pte1_clear
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
comment|/* 			 * Flush intermediate TLB cache. 			 */
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
operator|(
name|m
operator|->
name|pindex
operator|+
name|i
operator|)
operator|<<
name|PTE1_SHIFT
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|INVARIANTS
else|else
name|KASSERT
argument_list|(
operator|(
name|opte1
operator|==
literal|0
operator|)
operator|||
name|pte1_is_section
argument_list|(
name|opte1
argument_list|)
argument_list|,
operator|(
literal|"%s: pmap %p va %#x bad pte1 %x at %u"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|va
operator|,
name|opte1
operator|,
name|i
operator|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
comment|/* 	 * Unmap the page from PT2TAB. 	 */
name|pte2p
operator|=
name|pmap_pt2tab_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|pt2tab_load_clear
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|pt2map_pt2pg
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
comment|/* 	 * This is a release store so that the ordinary store unmapping 	 * the L2 page table page is globally performed before TLB shoot- 	 * down is begun. 	 */
name|atomic_subtract_rel_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Decrements a L2 page table page's wire count, which is used to record the  *  number of valid page table entries within the page.  If the wire count  *  drops to zero, then the page table page is unmapped.  Returns TRUE if the  *  page table page was unmapped and FALSE otherwise.  */
end_comment

begin_function
specifier|static
name|__inline
name|boolean_t
name|pmap_unwire_pt2
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|pt2_wirecount_dec
argument_list|(
name|m
argument_list|,
name|pte1_index
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pt2pg_is_empty
argument_list|(
name|m
argument_list|)
condition|)
block|{
comment|/* 		 * QQQ: Wire count is zero, so whole page should be zero and 		 *      we can set PG_ZERO flag to it. 		 *      Note that when promotion is enabled, it takes some 		 *      more efforts. See pmap_unwire_pt2_all() below. 		 */
name|pmap_unwire_pt2pg
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|pmap_add_delayed_free_list
argument_list|(
name|m
argument_list|,
name|free
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Drop a L2 page table page's wire count at once, which is used to record  *  the number of valid L2 page table entries within the page. If the wire  *  count drops to zero, then the L2 page table page is unmapped.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_unwire_pt2_all
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|u_int
name|pte1_idx
init|=
name|pte1_index
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|pindex
operator|==
operator|(
name|pte1_idx
operator|&
operator|~
name|PT2PG_MASK
operator|)
argument_list|,
operator|(
literal|"%s: PT2 page's pindex is wrong"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|>
name|pt2_wirecount_get
argument_list|(
name|m
argument_list|,
name|pte1_idx
argument_list|)
argument_list|,
operator|(
literal|"%s: bad pt2 wire count %u> %u"
operator|,
name|__func__
operator|,
name|m
operator|->
name|wire_count
operator|,
name|pt2_wirecount_get
argument_list|(
name|m
argument_list|,
name|pte1_idx
argument_list|)
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * It's possible that the L2 page table was never used. 	 * It happened in case that a section was created without promotion. 	 */
if|if
condition|(
name|pt2_is_full
argument_list|(
name|m
argument_list|,
name|va
argument_list|)
condition|)
block|{
name|pt2_wirecount_set
argument_list|(
name|m
argument_list|,
name|pte1_idx
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 		 * QQQ: We clear L2 page table now, so when L2 page table page 		 *      is going to be freed, we can set it PG_ZERO flag ... 		 *      This function is called only on section mappings, so 		 *      hopefully it's not to big overload. 		 * 		 * XXX: If pmap is current, existing PT2MAP mapping could be 		 *      used for zeroing. 		 */
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|page_pt2off
argument_list|(
name|pte1_idx
argument_list|)
argument_list|,
name|NB_IN_PT2
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|INVARIANTS
else|else
name|KASSERT
argument_list|(
name|pt2_is_empty
argument_list|(
name|m
argument_list|,
name|va
argument_list|)
argument_list|,
operator|(
literal|"%s: PT2 is not empty (%u)"
operator|,
name|__func__
operator|,
name|pt2_wirecount_get
argument_list|(
name|m
argument_list|,
name|pte1_idx
argument_list|)
operator|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|pt2pg_is_empty
argument_list|(
name|m
argument_list|)
condition|)
block|{
name|pmap_unwire_pt2pg
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|pmap_add_delayed_free_list
argument_list|(
name|m
argument_list|,
name|free
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *  After removing a L2 page table entry, this routine is used to  *  conditionally free the page, and manage the hold/wire counts.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_unuse_pt2
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|pt1_entry_t
name|pte1
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
if|if
condition|(
name|va
operator|>=
name|VM_MAXUSER_ADDRESS
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte1_link_pa
argument_list|(
name|pte1
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|pmap_unwire_pt2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|mpte
argument_list|,
name|free
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*************************************  *  *  Page management routines.  *  *************************************/
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|pv_chunk
argument_list|)
operator|==
name|PAGE_SIZE
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|_NPCM
operator|==
literal|11
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|_NPCPV
operator|==
literal|336
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
specifier|static
name|__inline
expr|struct
name|pv_chunk
operator|*
name|pv_to_chunk
argument_list|(
argument|pv_entry_t pv
argument_list|)
block|{
return|return
operator|(
operator|(
expr|struct
name|pv_chunk
operator|*
operator|)
operator|(
operator|(
name|uintptr_t
operator|)
name|pv
operator|&
operator|~
operator|(
name|uintptr_t
operator|)
name|PAGE_MASK
operator|)
operator|)
return|;
block|}
end_expr_stmt

begin_define
define|#
directive|define
name|PV_PMAP
parameter_list|(
name|pv
parameter_list|)
value|(pv_to_chunk(pv)->pc_pmap)
end_define

begin_define
define|#
directive|define
name|PC_FREE0_9
value|0xfffffffful
end_define

begin_comment
comment|/* Free values for index 0 through 9 */
end_comment

begin_define
define|#
directive|define
name|PC_FREE10
value|0x0000fffful
end_define

begin_comment
comment|/* Free values for index 10 */
end_comment

begin_decl_stmt
specifier|static
specifier|const
name|uint32_t
name|pc_freemask
index|[
name|_NPCM
index|]
init|=
block|{
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE10
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_count
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_count
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entries"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|PV_STATS
end_ifdef

begin_decl_stmt
specifier|static
name|int
name|pc_chunk_count
decl_stmt|,
name|pc_chunk_allocs
decl_stmt|,
name|pc_chunk_frees
decl_stmt|,
name|pc_chunk_tryfail
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_count
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_count
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry chunks"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_allocs
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_allocs
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry chunks allocated"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_frees
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_frees
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry chunks frees"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_tryfail
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_tryfail
argument_list|,
literal|0
argument_list|,
literal|"Number of times tried to get a chunk page but failed."
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|pv_entry_frees
decl_stmt|,
name|pv_entry_allocs
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|pv_entry_spare
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_frees
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_frees
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry frees"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_allocs
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_allocs
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry allocs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_spare
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_spare
argument_list|,
literal|0
argument_list|,
literal|"Current number of spare pv entries"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  *  Is given page managed?  */
end_comment

begin_function
specifier|static
name|__inline
name|bool
name|is_managed
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
return|return
operator|(
name|false
operator|)
return|;
return|return
operator|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|bool
name|pte1_is_managed
parameter_list|(
name|pt1_entry_t
name|pte1
parameter_list|)
block|{
return|return
operator|(
name|is_managed
argument_list|(
name|pte1_pa
argument_list|(
name|pte1
argument_list|)
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|bool
name|pte2_is_managed
parameter_list|(
name|pt2_entry_t
name|pte2
parameter_list|)
block|{
return|return
operator|(
name|is_managed
argument_list|(
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  We are in a serious low memory condition.  Resort to  *  drastic measures to free some pages so we can allocate  *  another pv entry chunk.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|pmap_pv_reclaim
parameter_list|(
name|pmap_t
name|locked_pmap
parameter_list|)
block|{
name|struct
name|pch
name|newtail
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|tpte2
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|m_pc
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|uint32_t
name|inuse
decl_stmt|;
name|int
name|bit
decl_stmt|,
name|field
decl_stmt|,
name|freed
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|locked_pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pmap
operator|=
name|NULL
expr_stmt|;
name|m_pc
operator|=
name|NULL
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|newtail
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|pc
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pv_chunks
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
operator|(
name|pv_vafree
operator|==
literal|0
operator|||
name|SLIST_EMPTY
argument_list|(
operator|&
name|free
argument_list|)
operator|)
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|pc
operator|->
name|pc_pmap
condition|)
block|{
if|if
condition|(
name|pmap
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|pmap
operator|!=
name|locked_pmap
condition|)
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|pmap
operator|=
name|pc
operator|->
name|pc_pmap
expr_stmt|;
comment|/* Avoid deadlock and lock recursion. */
if|if
condition|(
name|pmap
operator|>
name|locked_pmap
condition|)
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|pmap
operator|!=
name|locked_pmap
operator|&&
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pmap
operator|=
name|NULL
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|newtail
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
continue|continue;
block|}
block|}
comment|/* 		 * Destroy every non-wired, 4 KB page mapping in the chunk. 		 */
name|freed
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
for|for
control|(
name|inuse
operator|=
operator|~
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&
name|pc_freemask
index|[
name|field
index|]
init|;
name|inuse
operator|!=
literal|0
condition|;
name|inuse
operator|&=
operator|~
operator|(
literal|1UL
operator|<<
name|bit
operator|)
control|)
block|{
name|bit
operator|=
name|ffs
argument_list|(
name|inuse
argument_list|)
operator|-
literal|1
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|field
operator|*
literal|32
operator|+
name|bit
index|]
expr_stmt|;
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
condition|)
continue|continue;
name|pte2p
operator|=
name|pmap_pte2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|tpte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte2
operator|&
name|PTE2_W
operator|)
operator|==
literal|0
condition|)
name|tpte2
operator|=
name|pte2_load_clear
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|pmap_pte2_release
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte2
operator|&
name|PTE2_W
operator|)
operator|!=
literal|0
condition|)
continue|continue;
name|KASSERT
argument_list|(
name|tpte2
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_pv_reclaim: pmap %p va %#x zero pte"
operator|,
name|pmap
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte2_pa
argument_list|(
name|tpte2
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_dirty
argument_list|(
name|tpte2
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte2
operator|&
name|PTE2_A
operator|)
operator|!=
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
block|{
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
block|}
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
literal|1UL
operator|<<
name|bit
expr_stmt|;
name|pmap_unuse_pt2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
name|freed
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|freed
operator|==
literal|0
condition|)
block|{
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|newtail
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* Every freed mapping is for a 4 KB page. */
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|-=
name|freed
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_frees
operator|+=
name|freed
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|+=
name|freed
argument_list|)
expr_stmt|;
name|pv_entry_count
operator|-=
name|freed
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|!=
name|pc_freemask
index|[
name|field
index|]
condition|)
block|{
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|newtail
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
comment|/* 				 * One freed pv entry in locked_pmap is 				 * sufficient. 				 */
if|if
condition|(
name|pmap
operator|==
name|locked_pmap
condition|)
goto|goto
name|out
goto|;
break|break;
block|}
if|if
condition|(
name|field
operator|==
name|_NPCM
condition|)
block|{
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|-=
name|_NPCPV
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_count
operator|--
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_frees
operator|++
argument_list|)
expr_stmt|;
comment|/* Entire chunk is free; return it. */
name|m_pc
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pmap_kextract
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|pmap_pte2list_free
argument_list|(
operator|&
name|pv_vafree
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
name|out
label|:
name|TAILQ_CONCAT
argument_list|(
operator|&
name|pv_chunks
argument_list|,
operator|&
name|newtail
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|pmap
operator|!=
name|locked_pmap
condition|)
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|m_pc
operator|==
name|NULL
operator|&&
name|pv_vafree
operator|!=
literal|0
operator|&&
name|SLIST_EMPTY
argument_list|(
operator|&
name|free
argument_list|)
condition|)
block|{
name|m_pc
operator|=
name|SLIST_FIRST
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|SLIST_REMOVE_HEAD
argument_list|(
operator|&
name|free
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
comment|/* Recycle a freed page table page. */
name|m_pc
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
return|return
operator|(
name|m_pc
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|free_pv_chunk
parameter_list|(
name|struct
name|pv_chunk
modifier|*
name|pc
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|-=
name|_NPCPV
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_count
operator|--
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_frees
operator|++
argument_list|)
expr_stmt|;
comment|/* entire chunk is free, return it */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pmap_kextract
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
name|PQ_NONE
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_pte2list_free
argument_list|(
operator|&
name|pv_vafree
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Free the pv_entry back to the free list.  */
end_comment

begin_function
specifier|static
name|void
name|free_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pv_entry_t
name|pv
parameter_list|)
block|{
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|int
name|idx
decl_stmt|,
name|field
decl_stmt|,
name|bit
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_frees
operator|++
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|++
argument_list|)
expr_stmt|;
name|pv_entry_count
operator|--
expr_stmt|;
name|pc
operator|=
name|pv_to_chunk
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|idx
operator|=
name|pv
operator|-
operator|&
name|pc
operator|->
name|pc_pventry
index|[
literal|0
index|]
expr_stmt|;
name|field
operator|=
name|idx
operator|/
literal|32
expr_stmt|;
name|bit
operator|=
name|idx
operator|%
literal|32
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
literal|1ul
operator|<<
name|bit
expr_stmt|;
for|for
control|(
name|idx
operator|=
literal|0
init|;
name|idx
operator|<
name|_NPCM
condition|;
name|idx
operator|++
control|)
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
name|idx
index|]
operator|!=
name|pc_freemask
index|[
name|idx
index|]
condition|)
block|{
comment|/* 			 * 98% of the time, pc is already at the head of the 			 * list.  If it isn't already, move it to the head. 			 */
if|if
condition|(
name|__predict_false
argument_list|(
name|TAILQ_FIRST
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
operator|!=
name|pc
argument_list|)
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|free_pv_chunk
argument_list|(
name|pc
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Get a new pv_entry, allocating a block from the system  *  when needed.  */
end_comment

begin_function
specifier|static
name|pv_entry_t
name|get_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|boolean_t
name|try
parameter_list|)
block|{
specifier|static
specifier|const
name|struct
name|timeval
name|printinterval
init|=
block|{
literal|60
block|,
literal|0
block|}
decl_stmt|;
specifier|static
name|struct
name|timeval
name|lastprint
decl_stmt|;
name|int
name|bit
decl_stmt|,
name|field
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_allocs
operator|++
argument_list|)
expr_stmt|;
name|pv_entry_count
operator|++
expr_stmt|;
if|if
condition|(
name|pv_entry_count
operator|>
name|pv_entry_high_water
condition|)
if|if
condition|(
name|ratecheck
argument_list|(
operator|&
name|lastprint
argument_list|,
operator|&
name|printinterval
argument_list|)
condition|)
name|printf
argument_list|(
literal|"Approaching the limit on PV entries, consider "
literal|"increasing either the vm.pmap.shpgperproc or the "
literal|"vm.pmap.pv_entry_max tunable.\n"
argument_list|)
expr_stmt|;
name|retry
label|:
name|pc
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
if|if
condition|(
name|pc
operator|!=
name|NULL
condition|)
block|{
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
condition|)
block|{
name|bit
operator|=
name|ffs
argument_list|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
argument_list|)
operator|-
literal|1
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|field
operator|<
name|_NPCM
condition|)
block|{
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|field
operator|*
literal|32
operator|+
name|bit
index|]
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&=
operator|~
operator|(
literal|1ul
operator|<<
name|bit
operator|)
expr_stmt|;
comment|/* If this was the last item, move it to tail */
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|!=
literal|0
condition|)
block|{
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|--
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
comment|/* not full, return */
block|}
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|--
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
block|}
block|}
comment|/* 	 * Access to the pte2list "pv_vafree" is synchronized by the pvh 	 * global lock.  If "pv_vafree" is currently non-empty, it will 	 * remain non-empty until pmap_pte2list_alloc() completes. 	 */
if|if
condition|(
name|pv_vafree
operator|==
literal|0
operator|||
operator|(
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|try
condition|)
block|{
name|pv_entry_count
operator|--
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_tryfail
operator|++
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|m
operator|=
name|pmap_pv_reclaim
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
goto|goto
name|retry
goto|;
block|}
name|PV_STAT
argument_list|(
name|pc_chunk_count
operator|++
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_allocs
operator|++
argument_list|)
expr_stmt|;
name|pc
operator|=
operator|(
expr|struct
name|pv_chunk
operator|*
operator|)
name|pmap_pte2list_alloc
argument_list|(
operator|&
name|pv_vafree
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|,
operator|&
name|m
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_pmap
operator|=
name|pmap
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|=
name|pc_freemask
index|[
literal|0
index|]
operator|&
operator|~
literal|1ul
expr_stmt|;
comment|/* preallocated bit 0 */
for|for
control|(
name|field
operator|=
literal|1
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|=
name|pc_freemask
index|[
name|field
index|]
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
literal|0
index|]
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|+=
name|_NPCPV
operator|-
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Create a pv entry for page at pa for  *  (pmap, va).  */
end_comment

begin_function
specifier|static
name|void
name|pmap_insert_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pv_entry_t
name|pmap_pvh_remove
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|&&
name|va
operator|==
name|pv
operator|->
name|pv_va
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
return|return
operator|(
name|pv
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_pvh_free
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
name|pvh
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pv
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_pvh_free: pv not found"
operator|)
argument_list|)
expr_stmt|;
name|free_pv_entry
argument_list|(
name|pmap
argument_list|,
name|pv
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_remove_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|pmap_pvh_free
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_pv_demote_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_offset_t
name|va_last
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pa
operator|&
name|PTE1_OFFSET
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_pv_demote_pte1: pa is not 1mpage aligned"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Transfer the 1mpage's pv entry for this mapping to the first 	 * page's pv list. 	 */
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|va
operator|=
name|pte1_trunc
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
name|pvh
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pv
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_pv_demote_pte1: pv not found"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
comment|/* Instantiate the remaining NPTE2_IN_PT2 - 1 pv entries. */
name|va_last
operator|=
name|va
operator|+
name|PTE1_SIZE
operator|-
name|PAGE_SIZE
expr_stmt|;
do|do
block|{
name|m
operator|++
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_pv_demote_pte1: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pmap_insert_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|va
operator|<
name|va_last
condition|)
do|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_pv_promote_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_offset_t
name|va_last
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pa
operator|&
name|PTE1_OFFSET
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_pv_promote_pte1: pa is not 1mpage aligned"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Transfer the first page's pv entry for this mapping to the 	 * 1mpage's pv list.  Aside from avoiding the cost of a call 	 * to get_pv_entry(), a transfer avoids the possibility that 	 * get_pv_entry() calls pmap_pv_reclaim() and that pmap_pv_reclaim() 	 * removes one of the mappings that is being promoted. 	 */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|va
operator|=
name|pte1_trunc
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pv
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_pv_promote_pte1: pv not found"
operator|)
argument_list|)
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
comment|/* Free the remaining NPTE2_IN_PT2 - 1 pv entries. */
name|va_last
operator|=
name|va
operator|+
name|PTE1_SIZE
operator|-
name|PAGE_SIZE
expr_stmt|;
do|do
block|{
name|m
operator|++
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pmap_pvh_free
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|va
operator|<
name|va_last
condition|)
do|;
block|}
end_function

begin_comment
comment|/*  *  Conditionally create a pv entry.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_try_insert_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv_entry_count
operator|<
name|pv_entry_high_water
operator|&&
operator|(
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|TRUE
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Create the pv entries for each of the pages within a section.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_pv_insert_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv_entry_count
operator|<
name|pv_entry_high_water
operator|&&
operator|(
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|TRUE
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_function
specifier|static
specifier|inline
name|void
name|pmap_tlb_flush_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pt1_entry_t
name|npte1
parameter_list|)
block|{
comment|/* Kill all the small mappings or the big one only. */
if|if
condition|(
name|pte1_is_section
argument_list|(
name|npte1
argument_list|)
condition|)
name|pmap_tlb_flush_range
argument_list|(
name|pmap
argument_list|,
name|pte1_trunc
argument_list|(
name|va
argument_list|)
argument_list|,
name|PTE1_SIZE
argument_list|)
expr_stmt|;
else|else
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|pte1_trunc
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Update kernel pte1 on all pmaps.  *  *  The following function is called only on one cpu with disabled interrupts.  *  In SMP case, smp_rendezvous_cpus() is used to stop other cpus. This way  *  nobody can invoke explicit hardware table walk during the update of pte1.  *  Unsolicited hardware table walk can still happen, invoked by speculative  *  data or instruction prefetch or even by speculative hardware table walk.  *  *  The break-before-make approach should be implemented here. However, it's  *  not so easy to do that for kernel mappings as it would be unhappy to unmap  *  itself unexpectedly but voluntarily.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_update_pte1_kernel
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|pt1_entry_t
name|npte1
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
comment|/* 	 * Get current pmap. Interrupts should be disabled here 	 * so PCPU_GET() is done atomically. 	 */
name|pmap
operator|=
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|NULL
condition|)
name|pmap
operator|=
name|kernel_pmap
expr_stmt|;
comment|/* 	 * (1) Change pte1 on current pmap. 	 * (2) Flush all obsolete TLB entries on current CPU. 	 * (3) Change pte1 on all pmaps. 	 * (4) Flush all obsolete TLB entries on all CPUs in SMP case. 	 */
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
comment|/* Kill all the small mappings or the big one only. */
if|if
condition|(
name|pte1_is_section
argument_list|(
name|npte1
argument_list|)
condition|)
block|{
name|pmap_pte1_kern_promotions
operator|++
expr_stmt|;
name|tlb_flush_range_local
argument_list|(
name|pte1_trunc
argument_list|(
name|va
argument_list|)
argument_list|,
name|PTE1_SIZE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pmap_pte1_kern_demotions
operator|++
expr_stmt|;
name|tlb_flush_local
argument_list|(
name|pte1_trunc
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * In SMP case, this function is called when all cpus are at smp 	 * rendezvous, so there is no need to use 'allpmaps_lock' lock here. 	 * In UP case, the function is called with this lock locked. 	 */
name|LIST_FOREACH
argument_list|(
argument|pmap
argument_list|,
argument|&allpmaps
argument_list|,
argument|pm_list
argument_list|)
block|{
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|SMP
comment|/* Kill all the small mappings or the big one only. */
if|if
condition|(
name|pte1_is_section
argument_list|(
name|npte1
argument_list|)
condition|)
name|tlb_flush_range
argument_list|(
name|pte1_trunc
argument_list|(
name|va
argument_list|)
argument_list|,
name|PTE1_SIZE
argument_list|)
expr_stmt|;
else|else
name|tlb_flush
argument_list|(
name|pte1_trunc
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_struct
struct|struct
name|pte1_action
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|pt1_entry_t
name|npte1
decl_stmt|;
name|u_int
name|update
decl_stmt|;
comment|/* CPU that updates the PTE1 */
block|}
struct|;
end_struct

begin_function
specifier|static
name|void
name|pmap_update_pte1_action
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|struct
name|pte1_action
modifier|*
name|act
init|=
name|arg
decl_stmt|;
if|if
condition|(
name|act
operator|->
name|update
operator|==
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
name|pmap_update_pte1_kernel
argument_list|(
name|act
operator|->
name|va
argument_list|,
name|act
operator|->
name|npte1
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Change pte1 on current pmap.  *  Note that kernel pte1 must be changed on all pmaps.  *  *  According to the architecture reference manual published by ARM,  *  the behaviour is UNPREDICTABLE when two or more TLB entries map the same VA.  *  According to this manual, UNPREDICTABLE behaviours must never happen in  *  a viable system. In contrast, on x86 processors, it is not specified which  *  TLB entry mapping the virtual address will be used, but the MMU doesn't  *  generate a bogus translation the way it does on Cortex-A8 rev 2 (Beaglebone  *  Black).  *  *  It's a problem when either promotion or demotion is being done. The pte1  *  update and appropriate TLB flush must be done atomically in general.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_change_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt1_entry_t
modifier|*
name|pte1p
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pt1_entry_t
name|npte1
parameter_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|struct
name|pte1_action
name|act
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|act
operator|.
name|va
operator|=
name|va
expr_stmt|;
name|act
operator|.
name|npte1
operator|=
name|npte1
expr_stmt|;
name|act
operator|.
name|update
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|smp_rendezvous_cpus
argument_list|(
name|all_cpus
argument_list|,
name|smp_no_rendezvous_barrier
argument_list|,
name|pmap_update_pte1_action
argument_list|,
name|NULL
argument_list|,
operator|&
name|act
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|register_t
name|cspr
decl_stmt|;
comment|/* 		 * Use break-before-make approach for changing userland 		 * mappings. It can cause L1 translation aborts on other 		 * cores in SMP case. So, special treatment is implemented 		 * in pmap_fault(). To reduce the likelihood that another core 		 * will be affected by the broken mapping, disable interrupts 		 * until the mapping change is completed. 		 */
name|cspr
operator|=
name|disable_interrupts
argument_list|(
name|PSR_I
operator||
name|PSR_F
argument_list|)
expr_stmt|;
name|pte1_clear
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
name|pmap_tlb_flush_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
name|restore_interrupts
argument_list|(
name|cspr
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_else
else|#
directive|else
end_else

begin_function
specifier|static
name|void
name|pmap_change_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt1_entry_t
modifier|*
name|pte1p
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pt1_entry_t
name|npte1
parameter_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
name|pmap_update_pte1_kernel
argument_list|(
name|va
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|register_t
name|cspr
decl_stmt|;
comment|/* 		 * Use break-before-make approach for changing userland 		 * mappings. It's absolutely safe in UP case when interrupts 		 * are disabled. 		 */
name|cspr
operator|=
name|disable_interrupts
argument_list|(
name|PSR_I
operator||
name|PSR_F
argument_list|)
expr_stmt|;
name|pte1_clear
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
name|pmap_tlb_flush_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
name|restore_interrupts
argument_list|(
name|cspr
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  *  Tries to promote the NPTE2_IN_PT2, contiguous 4KB page mappings that are  *  within a single page table page (PT2) to a single 1MB page mapping.  *  For promotion to occur, two conditions must be met: (1) the 4KB page  *  mappings must map aligned, contiguous physical memory and (2) the 4KB page  *  mappings must have identical characteristics.  *  *  Managed (PG_MANAGED) mappings within the kernel address space are not  *  promoted.  The reason is that kernel PTE1s are replicated in each pmap but  *  pmap_remove_write(), pmap_clear_modify(), and pmap_clear_reference() only  *  read the PTE1 from the kernel pmap.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_promote_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt1_entry_t
modifier|*
name|pte1p
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt1_entry_t
name|npte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|fpte2p
decl_stmt|,
name|fpte2
decl_stmt|,
name|fpte2_fav
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|vm_offset_t
name|pteva
name|__unused
decl_stmt|;
name|vm_page_t
name|m
name|__unused
decl_stmt|;
name|PDEBUG
argument_list|(
literal|6
argument_list|,
name|printf
argument_list|(
literal|"%s(%p): try for va %#x pte1 %#x at %p\n"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|,
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|,
name|pte1p
argument_list|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Examine the first PTE2 in the specified PT2. Abort if this PTE2 is 	 * either invalid, unused, or does not map the first 4KB physical page 	 * within a 1MB page. 	 */
name|fpte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|pte1_trunc
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
name|fpte2
operator|=
name|pte2_load
argument_list|(
name|fpte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|fpte2
operator|&
operator|(
operator|(
name|PTE2_FRAME
operator|&
name|PTE1_OFFSET
operator|)
operator||
name|PTE2_A
operator||
name|PTE2_V
operator|)
operator|)
operator|!=
operator|(
name|PTE2_A
operator||
name|PTE2_V
operator|)
condition|)
block|{
name|pmap_pte1_p_failures
operator|++
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: failure(1) for va %#x in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|fpte2
argument_list|)
operator|&&
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|pmap_pte1_p_failures
operator|++
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: failure(2) for va %#x in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|fpte2
operator|&
operator|(
name|PTE2_NM
operator||
name|PTE2_RO
operator|)
operator|)
operator|==
name|PTE2_NM
condition|)
block|{
comment|/* 		 * When page is not modified, PTE2_RO can be set without 		 * a TLB invalidation. 		 */
name|fpte2
operator||=
name|PTE2_RO
expr_stmt|;
name|pte2_store
argument_list|(
name|fpte2p
argument_list|,
name|fpte2
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Examine each of the other PTE2s in the specified PT2. Abort if this 	 * PTE2 maps an unexpected 4KB physical page or does not have identical 	 * characteristics to the first PTE2. 	 */
name|fpte2_fav
operator|=
operator|(
name|fpte2
operator|&
operator|(
name|PTE2_FRAME
operator||
name|PTE2_A
operator||
name|PTE2_V
operator|)
operator|)
expr_stmt|;
name|fpte2_fav
operator|+=
name|PTE1_SIZE
operator|-
name|PTE2_SIZE
expr_stmt|;
comment|/* examine from the end */
for|for
control|(
name|pte2p
operator|=
name|fpte2p
operator|+
name|NPTE2_IN_PT2
operator|-
literal|1
init|;
name|pte2p
operator|>
name|fpte2p
condition|;
name|pte2p
operator|--
control|)
block|{
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte2
operator|&
operator|(
name|PTE2_FRAME
operator||
name|PTE2_A
operator||
name|PTE2_V
operator|)
operator|)
operator|!=
name|fpte2_fav
condition|)
block|{
name|pmap_pte1_p_failures
operator|++
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: failure(3) for va %#x in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|pte2
operator|&
operator|(
name|PTE2_NM
operator||
name|PTE2_RO
operator|)
operator|)
operator|==
name|PTE2_NM
condition|)
block|{
comment|/* 			 * When page is not modified, PTE2_RO can be set 			 * without a TLB invalidation. See note above. 			 */
name|pte2
operator||=
name|PTE2_RO
expr_stmt|;
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|pte2
argument_list|)
expr_stmt|;
name|pteva
operator|=
name|pte1_trunc
argument_list|(
name|va
argument_list|)
operator||
operator|(
name|pte2
operator|&
name|PTE1_OFFSET
operator|&
name|PTE2_FRAME
operator|)
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: protect for va %#x in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|pteva
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|pte2
operator|&
name|PTE2_PROMOTE
operator|)
operator|!=
operator|(
name|fpte2
operator|&
name|PTE2_PROMOTE
operator|)
condition|)
block|{
name|pmap_pte1_p_failures
operator|++
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: failure(4) for va %#x in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
name|fpte2_fav
operator|-=
name|PTE2_SIZE
expr_stmt|;
block|}
comment|/* 	 * The page table page in its current state will stay in PT2TAB 	 * until the PTE1 mapping the section is demoted by pmap_demote_pte1() 	 * or destroyed by pmap_remove_pte1(). 	 * 	 * Note that L2 page table size is not equal to PAGE_SIZE. 	 */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|trunc_page
argument_list|(
name|pte1_link_pa
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|>=
name|vm_page_array
operator|&&
name|m
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"%s: PT2 page is out of range"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|pindex
operator|==
operator|(
name|pte1_index
argument_list|(
name|va
argument_list|)
operator|&
operator|~
name|PT2PG_MASK
operator|)
argument_list|,
operator|(
literal|"%s: PT2 page's pindex is wrong"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Get pte1 from pte2 format. 	 */
name|npte1
operator|=
operator|(
name|fpte2
operator|&
name|PTE1_FRAME
operator|)
operator||
name|ATTR_TO_L1
argument_list|(
name|fpte2
argument_list|)
operator||
name|PTE1_V
expr_stmt|;
comment|/* 	 * Promote the pv entries. 	 */
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|fpte2
argument_list|)
condition|)
name|pmap_pv_promote_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pte1_pa
argument_list|(
name|npte1
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Promote the mappings. 	 */
name|pmap_change_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|va
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
name|pmap_pte1_promotions
operator|++
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: success for va %#x in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|PDEBUG
argument_list|(
literal|6
argument_list|,
name|printf
argument_list|(
literal|"%s(%p): success for va %#x pte1 %#x(%#x) at %p\n"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|,
name|npte1
argument_list|,
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|,
name|pte1p
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Zero L2 page table page.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_clear_pt2
parameter_list|(
name|pt2_entry_t
modifier|*
name|fpte2p
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
for|for
control|(
name|pte2p
operator|=
name|fpte2p
init|;
name|pte2p
operator|<
name|fpte2p
operator|+
name|NPTE2_IN_PT2
condition|;
name|pte2p
operator|++
control|)
name|pte2_clear
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Removes a 1MB page mapping from the kernel pmap.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_remove_kernel_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt1_entry_t
modifier|*
name|pte1p
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|uint32_t
name|pte1_idx
decl_stmt|;
name|pt2_entry_t
modifier|*
name|fpte2p
decl_stmt|;
name|vm_paddr_t
name|pt2_pa
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|=
name|pmap_pt2_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
comment|/* 		 * QQQ: Is this function called only on promoted pte1? 		 *      We certainly do section mappings directly 		 *      (without promotion) in kernel !!! 		 */
name|panic
argument_list|(
literal|"%s: missing pt2 page"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pte1_idx
operator|=
name|pte1_index
argument_list|(
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the L2 page table. 	 */
name|fpte2p
operator|=
name|page_pt2
argument_list|(
name|pt2map_pt2pg
argument_list|(
name|va
argument_list|)
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
name|pmap_clear_pt2
argument_list|(
name|fpte2p
argument_list|)
expr_stmt|;
comment|/* 	 * Remove the mapping. 	 */
name|pt2_pa
operator|=
name|page_pt2pa
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
name|pmap_kenter_pte1
argument_list|(
name|va
argument_list|,
name|PTE1_LINK
argument_list|(
name|pt2_pa
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * QQQ: We do not need to invalidate PT2MAP mapping 	 * as we did not change it. I.e. the L2 page table page 	 * was and still is mapped the same way. 	 */
block|}
end_function

begin_comment
comment|/*  *  Do the things to unmap a section in a process  */
end_comment

begin_function
specifier|static
name|void
name|pmap_remove_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt1_entry_t
modifier|*
name|pte1p
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|pt1_entry_t
name|opte1
decl_stmt|;
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|vm_offset_t
name|eva
decl_stmt|,
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|PDEBUG
argument_list|(
literal|6
argument_list|,
name|printf
argument_list|(
literal|"%s(%p): va %#x pte1 %#x at %p\n"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|sva
argument_list|,
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|,
name|pte1p
argument_list|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|sva
operator|&
name|PTE1_OFFSET
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: sva is not 1mpage aligned"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Clear and invalidate the mapping. It should occupy one and only TLB 	 * entry. So, pmap_tlb_flush() called with aligned address should be 	 * sufficient. 	 */
name|opte1
operator|=
name|pte1_load_clear
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_wired
argument_list|(
name|opte1
argument_list|)
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|-=
name|PTE1_SIZE
operator|/
name|PAGE_SIZE
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|-=
name|PTE1_SIZE
operator|/
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
name|pte1_is_managed
argument_list|(
name|opte1
argument_list|)
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pte1_pa
argument_list|(
name|opte1
argument_list|)
argument_list|)
expr_stmt|;
name|pmap_pvh_free
argument_list|(
name|pvh
argument_list|,
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|eva
operator|=
name|sva
operator|+
name|PTE1_SIZE
expr_stmt|;
for|for
control|(
name|va
operator|=
name|sva
operator|,
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte1_pa
argument_list|(
name|opte1
argument_list|)
argument_list|)
init|;
name|va
operator|<
name|eva
condition|;
name|va
operator|+=
name|PAGE_SIZE
operator|,
name|m
operator|++
control|)
block|{
if|if
condition|(
name|pte1_is_dirty
argument_list|(
name|opte1
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|opte1
operator|&
name|PTE1_A
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
comment|/* 		 * L2 page table(s) can't be removed from kernel map as 		 * kernel counts on it (stuff around pmap_growkernel()). 		 */
name|pmap_remove_kernel_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|sva
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Get associated L2 page table page. 		 * It's possible that the page was never allocated. 		 */
name|m
operator|=
name|pmap_pt2_page
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|!=
name|NULL
condition|)
name|pmap_unwire_pt2_all
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
name|m
argument_list|,
name|free
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *  Fills L2 page table page with mappings to consecutive physical pages.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_fill_pt2
parameter_list|(
name|pt2_entry_t
modifier|*
name|fpte2p
parameter_list|,
name|pt2_entry_t
name|npte2
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
for|for
control|(
name|pte2p
operator|=
name|fpte2p
init|;
name|pte2p
operator|<
name|fpte2p
operator|+
name|NPTE2_IN_PT2
condition|;
name|pte2p
operator|++
control|)
block|{
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|npte2
argument_list|)
expr_stmt|;
name|npte2
operator|+=
name|PTE2_SIZE
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *  Tries to demote a 1MB page mapping. If demotion fails, the  *  1MB page mapping is invalidated.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_demote_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt1_entry_t
modifier|*
name|pte1p
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt1_entry_t
name|opte1
decl_stmt|,
name|npte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|fpte2p
decl_stmt|,
name|npte2
decl_stmt|;
name|vm_paddr_t
name|pt2pg_pa
decl_stmt|,
name|pt2_pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|uint32_t
name|pte1_idx
decl_stmt|,
name|isnew
init|=
literal|0
decl_stmt|;
name|PDEBUG
argument_list|(
literal|6
argument_list|,
name|printf
argument_list|(
literal|"%s(%p): try for va %#x pte1 %#x at %p\n"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|,
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|,
name|pte1p
argument_list|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|opte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pte1_is_section
argument_list|(
name|opte1
argument_list|)
argument_list|,
operator|(
literal|"%s: opte1 not a section"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|opte1
operator|&
name|PTE1_A
operator|)
operator|==
literal|0
operator|||
operator|(
name|m
operator|=
name|pmap_pt2_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
operator|!
name|pte1_is_wired
argument_list|(
name|opte1
argument_list|)
argument_list|,
operator|(
literal|"%s: PT2 page for a wired mapping is missing"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Invalidate the 1MB page mapping and return 		 * "failure" if the mapping was never accessed or the 		 * allocation of the new page table page fails. 		 */
if|if
condition|(
operator|(
name|opte1
operator|&
name|PTE1_A
operator|)
operator|==
literal|0
operator|||
operator|(
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|pte1_index
argument_list|(
name|va
argument_list|)
operator|&
operator|~
name|PT2PG_MASK
argument_list|,
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_WIRED
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|pmap_remove_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|pte1_trunc
argument_list|(
name|va
argument_list|)
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: failure for va %#x in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
name|isnew
operator|=
literal|1
expr_stmt|;
comment|/* 		 * We init all L2 page tables in the page even if 		 * we are going to change everything for one L2 page 		 * table in a while. 		 */
name|pt2pg_pa
operator|=
name|pmap_pt2pg_init
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
block|{
if|if
condition|(
name|pt2_is_empty
argument_list|(
name|m
argument_list|,
name|va
argument_list|)
condition|)
name|isnew
operator|=
literal|1
expr_stmt|;
comment|/* Demoting section w/o promotion. */
ifdef|#
directive|ifdef
name|INVARIANTS
else|else
name|KASSERT
argument_list|(
name|pt2_is_full
argument_list|(
name|m
argument_list|,
name|va
argument_list|)
argument_list|,
operator|(
literal|"%s: bad PT2 wire"
literal|" count %u"
operator|,
name|__func__
operator|,
name|pt2_wirecount_get
argument_list|(
name|m
argument_list|,
name|pte1_index
argument_list|(
name|va
argument_list|)
argument_list|)
operator|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
block|}
name|pt2pg_pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pte1_idx
operator|=
name|pte1_index
argument_list|(
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * If the pmap is current, then the PT2MAP can provide access to 	 * the page table page (promoted L2 page tables are not unmapped). 	 * Otherwise, temporarily map the L2 page table page (m) into 	 * the kernel's address space at either PADDR1 or PADDR2. 	 * 	 * Note that L2 page table size is not equal to PAGE_SIZE. 	 */
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
name|fpte2p
operator|=
name|page_pt2
argument_list|(
name|pt2map_pt2pg
argument_list|(
name|va
argument_list|)
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|curthread
operator|->
name|td_pinned
operator|>
literal|0
operator|&&
name|rw_wowned
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
condition|)
block|{
if|if
condition|(
name|pte2_pa
argument_list|(
name|pte2_load
argument_list|(
name|PMAP1
argument_list|)
argument_list|)
operator|!=
name|pt2pg_pa
condition|)
block|{
name|pte2_store
argument_list|(
name|PMAP1
argument_list|,
name|PTE2_KPT
argument_list|(
name|pt2pg_pa
argument_list|)
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|PMAP1cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|tlb_flush_local
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PADDR1
argument_list|)
expr_stmt|;
name|PMAP1changed
operator|++
expr_stmt|;
block|}
elseif|else
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|PMAP1cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
block|{
name|PMAP1cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|tlb_flush_local
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PADDR1
argument_list|)
expr_stmt|;
name|PMAP1changedcpu
operator|++
expr_stmt|;
block|}
else|else
endif|#
directive|endif
name|PMAP1unchanged
operator|++
expr_stmt|;
name|fpte2p
operator|=
name|page_pt2
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PADDR1
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_lock
argument_list|(
operator|&
name|PMAP2mutex
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_pa
argument_list|(
name|pte2_load
argument_list|(
name|PMAP2
argument_list|)
argument_list|)
operator|!=
name|pt2pg_pa
condition|)
block|{
name|pte2_store
argument_list|(
name|PMAP2
argument_list|,
name|PTE2_KPT
argument_list|(
name|pt2pg_pa
argument_list|)
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PADDR2
argument_list|)
expr_stmt|;
block|}
name|fpte2p
operator|=
name|page_pt2
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PADDR2
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
block|}
name|pt2_pa
operator|=
name|page_pt2pa
argument_list|(
name|pt2pg_pa
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
name|npte1
operator|=
name|PTE1_LINK
argument_list|(
name|pt2_pa
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|opte1
operator|&
name|PTE1_A
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"%s: opte1 is missing PTE1_A"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|opte1
operator|&
operator|(
name|PTE1_NM
operator||
name|PTE1_RO
operator|)
operator|)
operator|!=
name|PTE1_NM
argument_list|,
operator|(
literal|"%s: opte1 has PTE1_NM"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 *  Get pte2 from pte1 format. 	*/
name|npte2
operator|=
name|pte1_pa
argument_list|(
name|opte1
argument_list|)
operator||
name|ATTR_TO_L2
argument_list|(
name|opte1
argument_list|)
operator||
name|PTE2_V
expr_stmt|;
comment|/* 	 * If the L2 page table page is new, initialize it. If the mapping 	 * has changed attributes, update the page table entries. 	 */
if|if
condition|(
name|isnew
operator|!=
literal|0
condition|)
block|{
name|pt2_wirecount_set
argument_list|(
name|m
argument_list|,
name|pte1_idx
argument_list|,
name|NPTE2_IN_PT2
argument_list|)
expr_stmt|;
name|pmap_fill_pt2
argument_list|(
name|fpte2p
argument_list|,
name|npte2
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|pte2_load
argument_list|(
name|fpte2p
argument_list|)
operator|&
name|PTE2_PROMOTE
operator|)
operator|!=
operator|(
name|npte2
operator|&
name|PTE2_PROMOTE
operator|)
condition|)
name|pmap_fill_pt2
argument_list|(
name|fpte2p
argument_list|,
name|npte2
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pte2_pa
argument_list|(
name|pte2_load
argument_list|(
name|fpte2p
argument_list|)
argument_list|)
operator|==
name|pte2_pa
argument_list|(
name|npte2
argument_list|)
argument_list|,
operator|(
literal|"%s: fpte2p and npte2 map different physical addresses"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|fpte2p
operator|==
name|PADDR2
condition|)
name|mtx_unlock
argument_list|(
operator|&
name|PMAP2mutex
argument_list|)
expr_stmt|;
comment|/* 	 * Demote the mapping. This pmap is locked. The old PTE1 has 	 * PTE1_A set. If the old PTE1 has not PTE1_RO set, it also 	 * has not PTE1_NM set. Thus, there is no danger of a race with 	 * another processor changing the setting of PTE1_A and/or PTE1_NM 	 * between the read above and the store below. 	 */
name|pmap_change_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|va
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
comment|/* 	 * Demote the pv entry. This depends on the earlier demotion 	 * of the mapping. Specifically, the (re)creation of a per- 	 * page pv entry might trigger the execution of pmap_pv_reclaim(), 	 * which might reclaim a newly (re)created per-page pv entry 	 * and destroy the associated mapping. In order to destroy 	 * the mapping, the PTE1 must have already changed from mapping 	 * the 1mpage to referencing the page table page. 	 */
if|if
condition|(
name|pte1_is_managed
argument_list|(
name|opte1
argument_list|)
condition|)
name|pmap_pv_demote_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pte1_pa
argument_list|(
name|opte1
argument_list|)
argument_list|)
expr_stmt|;
name|pmap_pte1_demotions
operator|++
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: success for va %#x in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|PDEBUG
argument_list|(
literal|6
argument_list|,
name|printf
argument_list|(
literal|"%s(%p): success for va %#x pte1 %#x(%#x) at %p\n"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|,
name|npte1
argument_list|,
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|,
name|pte1p
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Insert the given physical page (p) at  *	the specified virtual address (v) in the  *	target physical map with the protection requested.  *  *	If specified, the page will be wired down, meaning  *	that the related pte can not be reclaimed.  *  *	NB:  This is the only routine which MAY NOT lazy-evaluate  *	or lose information.  That is, this routine must actually  *	insert this page into the given map NOW.  */
end_comment

begin_function
name|int
name|pmap_enter
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|u_int
name|flags
parameter_list|,
name|int8_t
name|psind
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|pt2_entry_t
name|npte2
decl_stmt|,
name|opte2
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_paddr_t
name|opa
decl_stmt|,
name|pa
decl_stmt|;
name|vm_page_t
name|mpte2
decl_stmt|,
name|om
decl_stmt|;
name|boolean_t
name|wired
decl_stmt|;
name|va
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|mpte2
operator|=
name|NULL
expr_stmt|;
name|wired
operator|=
operator|(
name|flags
operator|&
name|PMAP_ENTER_WIRED
operator|)
operator|!=
literal|0
expr_stmt|;
name|KASSERT
argument_list|(
name|va
operator|<=
name|vm_max_kernel_address
argument_list|,
operator|(
literal|"%s: toobig"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|va
operator|<
name|UPT2V_MIN_ADDRESS
operator|||
name|va
operator|>=
name|UPT2V_MAX_ADDRESS
argument_list|,
operator|(
literal|"%s: invalid to pmap_enter page table pages (va: 0x%x)"
operator|,
name|__func__
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|&&
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
comment|/* 	 * In the case that a page table page is not 	 * resident, we are creating it here. 	 */
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
block|{
name|mpte2
operator|=
name|pmap_allocpte2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte2
operator|==
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|flags
operator|&
name|PMAP_ENTER_NOSLEEP
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_allocpte2 failed with sleep allowed"
operator|)
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_RESOURCE_SHORTAGE
operator|)
return|;
block|}
block|}
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
condition|)
name|panic
argument_list|(
literal|"%s: attempted on 1MB page"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2p
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"%s: invalid L1 page table entry va=%#x"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|om
operator|=
name|NULL
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|opte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|opa
operator|=
name|pte2_pa
argument_list|(
name|opte2
argument_list|)
expr_stmt|;
comment|/* 	 * Mapping has not changed, must be protection or wiring change. 	 */
if|if
condition|(
name|pte2_is_valid
argument_list|(
name|opte2
argument_list|)
operator|&&
operator|(
name|opa
operator|==
name|pa
operator|)
condition|)
block|{
comment|/* 		 * Wiring change, just update stats. We don't worry about 		 * wiring PT2 pages as they remain resident as long as there 		 * are valid mappings in them. Hence, if a user page is wired, 		 * the PT2 page will be also. 		 */
if|if
condition|(
name|wired
operator|&&
operator|!
name|pte2_is_wired
argument_list|(
name|opte2
argument_list|)
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
elseif|else
if|if
condition|(
operator|!
name|wired
operator|&&
name|pte2_is_wired
argument_list|(
name|opte2
argument_list|)
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
comment|/* 		 * Remove extra pte2 reference 		 */
if|if
condition|(
name|mpte2
condition|)
name|pt2_wirecount_dec
argument_list|(
name|mpte2
argument_list|,
name|pte1_index
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|opte2
argument_list|)
condition|)
name|om
operator|=
name|m
expr_stmt|;
goto|goto
name|validate
goto|;
block|}
comment|/* 	 * QQQ: We think that changing physical address on writeable mapping 	 *      is not safe. Well, maybe on kernel address space with correct 	 *      locking, it can make a sense. However, we have no idea why 	 *      anyone should do that on user address space. Are we wrong? 	 */
name|KASSERT
argument_list|(
operator|(
name|opa
operator|==
literal|0
operator|)
operator|||
operator|(
name|opa
operator|==
name|pa
operator|)
operator|||
operator|!
name|pte2_is_valid
argument_list|(
name|opte2
argument_list|)
operator|||
operator|(
operator|(
name|opte2
operator|&
name|PTE2_RO
operator|)
operator|!=
literal|0
operator|)
argument_list|,
operator|(
literal|"%s: pmap %p va %#x(%#x) opa %#x pa %#x - gotcha %#x %#x!"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|va
operator|,
name|opte2
operator|,
name|opa
operator|,
name|pa
operator|,
name|flags
operator|,
name|prot
operator|)
argument_list|)
expr_stmt|;
name|pv
operator|=
name|NULL
expr_stmt|;
comment|/* 	 * Mapping has changed, invalidate old range and fall through to 	 * handle validating new mapping. 	 */
if|if
condition|(
name|opa
condition|)
block|{
if|if
condition|(
name|pte2_is_wired
argument_list|(
name|opte2
argument_list|)
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|opte2
argument_list|)
condition|)
block|{
name|om
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|opa
argument_list|)
expr_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
operator|&
name|om
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Remove extra pte2 reference 		 */
if|if
condition|(
name|mpte2
operator|!=
name|NULL
condition|)
name|pt2_wirecount_dec
argument_list|(
name|mpte2
argument_list|,
name|va
operator|>>
name|PTE1_SHIFT
argument_list|)
expr_stmt|;
block|}
else|else
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
comment|/* 	 * Enter on the PV list if part of our managed memory. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|va
operator|<
name|kmi
operator|.
name|clean_sva
operator|||
name|va
operator|>=
name|kmi
operator|.
name|clean_eva
argument_list|,
operator|(
literal|"%s: managed mapping within the clean submap"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv
operator|==
name|NULL
condition|)
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pv
operator|!=
name|NULL
condition|)
name|free_pv_entry
argument_list|(
name|pmap
argument_list|,
name|pv
argument_list|)
expr_stmt|;
comment|/* 	 * Increment counters 	 */
if|if
condition|(
name|wired
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
name|validate
label|:
comment|/* 	 * Now validate mapping with desired protection/wiring. 	 */
name|npte2
operator|=
name|PTE2
argument_list|(
name|pa
argument_list|,
name|PTE2_NM
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
block|{
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|npte2
argument_list|)
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
else|else
name|npte2
operator||=
name|PTE2_RO
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|npte2
operator||=
name|PTE2_NX
expr_stmt|;
if|if
condition|(
name|wired
condition|)
name|npte2
operator||=
name|PTE2_W
expr_stmt|;
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|npte2
operator||=
name|PTE2_U
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|kernel_pmap
condition|)
name|npte2
operator||=
name|PTE2_NG
expr_stmt|;
comment|/* 	 * If the mapping or permission bits are different, we need 	 * to update the pte2. 	 * 	 * QQQ: Think again and again what to do 	 *      if the mapping is going to be changed! 	 */
if|if
condition|(
operator|(
name|opte2
operator|&
operator|~
operator|(
name|PTE2_NM
operator||
name|PTE2_A
operator|)
operator|)
operator|!=
operator|(
name|npte2
operator|&
operator|~
operator|(
name|PTE2_NM
operator||
name|PTE2_A
operator|)
operator|)
condition|)
block|{
comment|/* 		 * Sync icache if exec permission and attribute VM_MEMATTR_WB_WA 		 * is set. Do it now, before the mapping is stored and made 		 * valid for hardware table walk. If done later, there is a race 		 * for other threads of current process in lazy loading case. 		 * Don't do it for kernel memory which is mapped with exec 		 * permission even if the memory isn't going to hold executable 		 * code. The only time when icache sync is needed is after 		 * kernel module is loaded and the relocation info is processed. 		 * And it's done in elf_cpu_load_file(). 		 * 		 * QQQ: (1) Does it exist any better way where 		 *          or how to sync icache? 		 *      (2) Now, we do it on a page basis. 		 */
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|&&
name|pmap
operator|!=
name|kernel_pmap
operator|&&
name|m
operator|->
name|md
operator|.
name|pat_mode
operator|==
name|VM_MEMATTR_WB_WA
operator|&&
operator|(
name|opa
operator|!=
name|pa
operator|||
operator|(
name|opte2
operator|&
name|PTE2_NX
operator|)
operator|)
condition|)
name|cache_icache_sync_fresh
argument_list|(
name|va
argument_list|,
name|pa
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|npte2
operator||=
name|PTE2_A
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|VM_PROT_WRITE
condition|)
name|npte2
operator|&=
operator|~
name|PTE2_NM
expr_stmt|;
if|if
condition|(
name|opte2
operator|&
name|PTE2_V
condition|)
block|{
comment|/* Change mapping with break-before-make approach. */
name|opte2
operator|=
name|pte2_load_clear
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|npte2
argument_list|)
expr_stmt|;
if|if
condition|(
name|opte2
operator|&
name|PTE2_A
condition|)
block|{
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|opte2
argument_list|)
condition|)
name|vm_page_aflag_set
argument_list|(
name|om
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pte2_is_dirty
argument_list|(
name|opte2
argument_list|)
condition|)
block|{
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|opte2
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|om
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|opte2
argument_list|)
operator|&&
name|TAILQ_EMPTY
argument_list|(
operator|&
name|om
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
operator|(
name|om
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
operator|||
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pa_to_pvh
argument_list|(
name|opa
argument_list|)
operator|->
name|pv_list
argument_list|)
operator|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|om
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
else|else
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|npte2
argument_list|)
expr_stmt|;
block|}
if|#
directive|if
literal|0
block|else {
comment|/* 		 * QQQ: In time when both access and not mofified bits are 		 *      emulated by software, this should not happen. Some 		 *      analysis is need, if this really happen. Missing 		 *      tlb flush somewhere could be the reason. 		 */
block|panic("%s: pmap %p va %#x opte2 %x npte2 %x !!", __func__, pmap, 		    va, opte2, npte2); 	}
endif|#
directive|endif
comment|/* 	 * If both the L2 page table page and the reservation are fully 	 * populated, then attempt promotion. 	 */
if|if
condition|(
operator|(
name|mpte2
operator|==
name|NULL
operator|||
name|pt2_is_full
argument_list|(
name|mpte2
argument_list|,
name|va
argument_list|)
operator|)
operator|&&
name|sp_enabled
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
name|vm_reserv_level_iffullpop
argument_list|(
name|m
argument_list|)
operator|==
literal|0
condition|)
name|pmap_promote_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_SUCCESS
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Do the things to unmap a page in a process.  */
end_comment

begin_function
specifier|static
name|int
name|pmap_remove_pte2
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt2_entry_t
modifier|*
name|pte2p
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|pt2_entry_t
name|opte2
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* Clear and invalidate the mapping. */
name|opte2
operator|=
name|pte2_load_clear
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pte2_is_valid
argument_list|(
name|opte2
argument_list|)
argument_list|,
operator|(
literal|"%s: pmap %p va %#x not link pte2 %#x"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|va
operator|,
name|opte2
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|opte2
operator|&
name|PTE2_W
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|-=
literal|1
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|-=
literal|1
expr_stmt|;
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|opte2
argument_list|)
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte2_pa
argument_list|(
name|opte2
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_dirty
argument_list|(
name|opte2
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|opte2
operator|&
name|PTE2_A
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|pmap_remove_entry
argument_list|(
name|pmap
argument_list|,
name|m
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|pmap_unuse_pt2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|free
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Remove a single page from a process address space.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_remove_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|curthread
operator|->
name|td_pinned
operator|>
literal|0
argument_list|,
operator|(
literal|"%s: curthread not pinned"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
operator|)
operator|==
name|NULL
operator|||
operator|!
name|pte2_is_valid
argument_list|(
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
argument_list|)
condition|)
return|return;
name|pmap_remove_pte2
argument_list|(
name|pmap
argument_list|,
name|pte2p
argument_list|,
name|va
argument_list|,
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Remove the given range of addresses from the specified map.  *  *  It is assumed that the start and end are properly  *  rounded to the page size.  */
end_comment

begin_function
name|void
name|pmap_remove
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|vm_offset_t
name|nextva
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|pte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
comment|/* 	 * Perform an unsynchronized read. This is, however, safe. 	 */
if|if
condition|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
condition|)
return|return;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Special handling of removing one page. A very common 	 * operation and easy to short circuit some code. 	 */
if|if
condition|(
name|sva
operator|+
name|PAGE_SIZE
operator|==
name|eva
condition|)
block|{
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pmap_remove_page
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
goto|goto
name|out
goto|;
block|}
block|}
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|nextva
control|)
block|{
comment|/* 		 * Calculate address for next L2 page table. 		 */
name|nextva
operator|=
name|pte1_trunc
argument_list|(
name|sva
operator|+
name|PTE1_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|nextva
operator|<
name|sva
condition|)
name|nextva
operator|=
name|eva
expr_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
condition|)
break|break;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
comment|/* 		 * Weed out invalid mappings. Note: we assume that the L1 page 		 * table is always allocated, and in kernel virtual. 		 */
if|if
condition|(
name|pte1
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
comment|/* 			 * Are we removing the entire large page?  If not, 			 * demote the mapping and fall through. 			 */
if|if
condition|(
name|sva
operator|+
name|PTE1_SIZE
operator|==
name|nextva
operator|&&
name|eva
operator|>=
name|nextva
condition|)
block|{
name|pmap_remove_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|sva
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
continue|continue;
block|}
elseif|else
if|if
condition|(
operator|!
name|pmap_demote_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|sva
argument_list|)
condition|)
block|{
comment|/* The large page mapping was destroyed. */
continue|continue;
block|}
ifdef|#
directive|ifdef
name|INVARIANTS
else|else
block|{
comment|/* Update pte1 after demotion. */
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
name|KASSERT
argument_list|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
argument_list|,
operator|(
literal|"%s: pmap %p va %#x pte1 %#x at %p"
literal|" is not link"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|sva
operator|,
name|pte1
operator|,
name|pte1p
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Limit our scan to either the end of the va represented 		 * by the current L2 page table page, or to the end of the 		 * range being removed. 		 */
if|if
condition|(
name|nextva
operator|>
name|eva
condition|)
name|nextva
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|nextva
condition|;
name|pte2p
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
continue|continue;
if|if
condition|(
name|pmap_remove_pte2
argument_list|(
name|pmap
argument_list|,
name|pte2p
argument_list|,
name|sva
argument_list|,
operator|&
name|free
argument_list|)
condition|)
break|break;
block|}
block|}
name|out
label|:
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Routine:	pmap_remove_all  *	Function:  *		Removes this physical page from  *		all physical maps in which it resides.  *		Reflects back modify bits to the pager.  *  *	Notes:  *		Original versions of this routine were very  *		inefficient because they iteratively called  *		pmap_remove (slow...)  */
end_comment

begin_function
name|void
name|pmap_remove_all
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|opte2
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: page %p is not managed"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
goto|goto
name|small_mappings
goto|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|pmap_demote_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|small_mappings
label|:
while|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pte1_is_section
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
argument_list|,
operator|(
literal|"%s: found "
literal|"a 1mpage in page %p's pv list"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|opte2
operator|=
name|pte2_load_clear
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pte2_is_valid
argument_list|(
name|opte2
argument_list|)
argument_list|,
operator|(
literal|"%s: pmap %p va %x zero pte2"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|pv
operator|->
name|pv_va
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_wired
argument_list|(
name|opte2
argument_list|)
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
if|if
condition|(
name|opte2
operator|&
name|PTE2_A
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
comment|/* 		 * Update the vm_page_t clean and reference bits. 		 */
if|if
condition|(
name|pte2_is_dirty
argument_list|(
name|opte2
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_unuse_pt2
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|free_pv_entry
argument_list|(
name|pmap
argument_list|,
name|pv
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Just subroutine for pmap_remove_pages() to reasonably satisfy  *  good coding style, a.k.a. 80 character line width limit hell.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_remove_pte1_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt1_entry_t
name|pte1
parameter_list|,
name|pv_entry_t
name|pv
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mt
decl_stmt|,
name|mpt2pg
decl_stmt|;
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pa
operator|=
name|pte1_pa
argument_list|(
name|pte1
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|phys_addr
operator|==
name|pa
argument_list|,
operator|(
literal|"%s: vm_page_t %p addr mismatch %#x %#x"
operator|,
name|__func__
operator|,
name|m
operator|,
name|m
operator|->
name|phys_addr
operator|,
name|pa
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
operator|||
name|m
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"%s: bad pte1 %#x"
operator|,
name|__func__
operator|,
name|pte1
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_dirty
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
for|for
control|(
name|mt
operator|=
name|m
init|;
name|mt
operator|<
operator|&
name|m
index|[
name|PTE1_SIZE
operator|/
name|PAGE_SIZE
index|]
condition|;
name|mt
operator|++
control|)
name|vm_page_dirty
argument_list|(
name|mt
argument_list|)
expr_stmt|;
block|}
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|-=
name|PTE1_SIZE
operator|/
name|PAGE_SIZE
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
block|{
for|for
control|(
name|mt
operator|=
name|m
init|;
name|mt
operator|<
operator|&
name|m
index|[
name|PTE1_SIZE
operator|/
name|PAGE_SIZE
index|]
condition|;
name|mt
operator|++
control|)
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|mt
operator|->
name|md
operator|.
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|mt
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
name|mpt2pg
operator|=
name|pmap_pt2_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpt2pg
operator|!=
name|NULL
condition|)
name|pmap_unwire_pt2_all
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
name|mpt2pg
argument_list|,
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Just subroutine for pmap_remove_pages() to reasonably satisfy  *  good coding style, a.k.a. 80 character line width limit hell.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_remove_pte2_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt2_entry_t
name|pte2
parameter_list|,
name|pv_entry_t
name|pv
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pa
operator|=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|phys_addr
operator|==
name|pa
argument_list|,
operator|(
literal|"%s: vm_page_t %p addr mismatch %#x %#x"
operator|,
name|__func__
operator|,
name|m
operator|,
name|m
operator|->
name|phys_addr
operator|,
name|pa
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
operator|||
name|m
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"%s: bad pte2 %#x"
operator|,
name|__func__
operator|,
name|pte2
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_dirty
argument_list|(
name|pte2
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
name|pmap_unuse_pt2
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Remove all pages from specified address space this aids process  *  exit speeds. Also, this code is special cased for current process  *  only, but can have the more generic (and slightly slower) mode enabled.  *  This is much faster than pmap_remove in the case of running down  *  an entire address space.  */
end_comment

begin_function
name|void
name|pmap_remove_pages
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|pte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|,
modifier|*
name|npc
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|int
name|field
decl_stmt|,
name|idx
decl_stmt|;
name|int32_t
name|bit
decl_stmt|;
name|uint32_t
name|inuse
decl_stmt|,
name|bitmask
decl_stmt|;
name|boolean_t
name|allfree
decl_stmt|;
comment|/* 	 * Assert that the given pmap is only active on the current 	 * CPU.  Unfortunately, we cannot block another CPU from 	 * activating the pmap while this function is executing. 	 */
name|KASSERT
argument_list|(
name|pmap
operator|==
name|vmspace_pmap
argument_list|(
name|curthread
operator|->
name|td_proc
operator|->
name|p_vmspace
argument_list|)
argument_list|,
operator|(
literal|"%s: non-current pmap %p"
operator|,
name|__func__
operator|,
name|pmap
operator|)
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|SMP
argument_list|)
operator|&&
name|defined
argument_list|(
name|INVARIANTS
argument_list|)
block|{
name|cpuset_t
name|other_cpus
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|other_cpus
operator|=
name|pmap
operator|->
name|pm_active
expr_stmt|;
name|CPU_CLR
argument_list|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|,
operator|&
name|other_cpus
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|KASSERT
argument_list|(
name|CPU_EMPTY
argument_list|(
operator|&
name|other_cpus
argument_list|)
argument_list|,
operator|(
literal|"%s: pmap %p active on other cpus"
operator|,
name|__func__
operator|,
name|pmap
operator|)
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|pc
argument_list|,
argument|&pmap->pm_pvchunk
argument_list|,
argument|pc_list
argument_list|,
argument|npc
argument_list|)
block|{
name|KASSERT
argument_list|(
name|pc
operator|->
name|pc_pmap
operator|==
name|pmap
argument_list|,
operator|(
literal|"%s: wrong pmap %p %p"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|pc
operator|->
name|pc_pmap
operator|)
argument_list|)
expr_stmt|;
name|allfree
operator|=
name|TRUE
expr_stmt|;
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
name|inuse
operator|=
operator|(
operator|~
operator|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|)
operator|)
operator|&
name|pc_freemask
index|[
name|field
index|]
expr_stmt|;
while|while
condition|(
name|inuse
operator|!=
literal|0
condition|)
block|{
name|bit
operator|=
name|ffs
argument_list|(
name|inuse
argument_list|)
operator|-
literal|1
expr_stmt|;
name|bitmask
operator|=
literal|1UL
operator|<<
name|bit
expr_stmt|;
name|idx
operator|=
name|field
operator|*
literal|32
operator|+
name|bit
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|idx
index|]
expr_stmt|;
name|inuse
operator|&=
operator|~
name|bitmask
expr_stmt|;
comment|/* 				 * Note that we cannot remove wired pages 				 * from a process' mapping at this time 				 */
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
if|if
condition|(
name|pte1_is_wired
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|allfree
operator|=
name|FALSE
expr_stmt|;
continue|continue;
block|}
name|pte1_clear
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
name|pmap_remove_pte1_quick
argument_list|(
name|pmap
argument_list|,
name|pte1
argument_list|,
name|pv
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pte2p
operator|=
name|pt2map_entry
argument_list|(
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
block|{
name|printf
argument_list|(
literal|"%s: pmap %p va %#x "
literal|"pte2 %#x\n"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
name|pte2
argument_list|)
expr_stmt|;
name|panic
argument_list|(
literal|"bad pte2"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pte2_is_wired
argument_list|(
name|pte2
argument_list|)
condition|)
block|{
name|allfree
operator|=
name|FALSE
expr_stmt|;
continue|continue;
block|}
name|pte2_clear
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|pmap_remove_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|pte2
argument_list|,
name|pv
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|printf
argument_list|(
literal|"%s: pmap %p va %#x pte1 %#x\n"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
name|pte1
argument_list|)
expr_stmt|;
name|panic
argument_list|(
literal|"bad pte1"
argument_list|)
expr_stmt|;
block|}
comment|/* Mark free */
name|PV_STAT
argument_list|(
name|pv_entry_frees
operator|++
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|++
argument_list|)
expr_stmt|;
name|pv_entry_count
operator|--
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
name|bitmask
expr_stmt|;
block|}
block|}
if|if
condition|(
name|allfree
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|free_pv_chunk
argument_list|(
name|pc
argument_list|)
expr_stmt|;
block|}
block|}
name|tlb_flush_all_ng_local
argument_list|()
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  This code makes some *MAJOR* assumptions:  *  1. Current pmap& pmap exists.  *  2. Not wired.  *  3. Read access.  *  4. No L2 page table pages.  *  but is *MUCH* faster than pmap_enter...  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|pmap_enter_quick_locked
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|vm_page_t
name|mpt2pg
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|uint32_t
name|l2prot
decl_stmt|;
name|KASSERT
argument_list|(
name|va
operator|<
name|kmi
operator|.
name|clean_sva
operator|||
name|va
operator|>=
name|kmi
operator|.
name|clean_eva
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"%s: managed mapping within the clean submap"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * In the case that a L2 page table page is not 	 * resident, we are creating it here. 	 */
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
block|{
name|u_int
name|pte1_idx
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|,
modifier|*
name|pte1p
decl_stmt|;
name|vm_paddr_t
name|pt2_pa
decl_stmt|;
comment|/* 		 * Get L1 page table things. 		 */
name|pte1_idx
operator|=
name|pte1_index
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpt2pg
operator|&&
operator|(
name|mpt2pg
operator|->
name|pindex
operator|==
operator|(
name|pte1_idx
operator|&
operator|~
name|PT2PG_MASK
operator|)
operator|)
condition|)
block|{
comment|/* 			 * Each of NPT2_IN_PG L2 page tables on the page can 			 * come here. Make sure that associated L1 page table 			 * link is established. 			 * 			 * QQQ: It comes that we don't establish all links to 			 *      L2 page tables for newly allocated L2 page 			 *      tables page. 			 */
name|KASSERT
argument_list|(
operator|!
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
argument_list|,
operator|(
literal|"%s: pte1 %#x is section"
operator|,
name|__func__
operator|,
name|pte1
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pt2_pa
operator|=
name|page_pt2pa
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|mpt2pg
argument_list|)
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|PTE1_LINK
argument_list|(
name|pt2_pa
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|pt2_wirecount_inc
argument_list|(
name|mpt2pg
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * If the L2 page table page is mapped, we just 			 * increment the hold count, and activate it. 			 */
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
return|return
operator|(
name|NULL
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|mpt2pg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte1_link_pa
argument_list|(
name|pte1
argument_list|)
argument_list|)
expr_stmt|;
name|pt2_wirecount_inc
argument_list|(
name|mpt2pg
argument_list|,
name|pte1_idx
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mpt2pg
operator|=
name|_pmap_allocpte2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|PMAP_ENTER_NOSLEEP
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpt2pg
operator|==
name|NULL
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
block|}
block|}
block|}
else|else
block|{
name|mpt2pg
operator|=
name|NULL
expr_stmt|;
block|}
comment|/* 	 * This call to pt2map_entry() makes the assumption that we are 	 * entering the page into the current pmap.  In order to support 	 * quick entry into any pmap, one would likely use pmap_pte2_quick(). 	 * But that isn't as quick as pt2map_entry(). 	 */
name|pte2p
operator|=
name|pt2map_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
block|{
if|if
condition|(
name|mpt2pg
operator|!=
name|NULL
condition|)
block|{
comment|/* 			 * Remove extra pte2 reference 			 */
name|pt2_wirecount_dec
argument_list|(
name|mpt2pg
argument_list|,
name|pte1_index
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
name|mpt2pg
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
comment|/* 	 * Enter on the PV list if part of our managed memory. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|&&
operator|!
name|pmap_try_insert_pv_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|)
condition|)
block|{
if|if
condition|(
name|mpt2pg
operator|!=
name|NULL
condition|)
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_unwire_pt2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|mpt2pg
argument_list|,
operator|&
name|free
argument_list|)
condition|)
block|{
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
name|mpt2pg
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
comment|/* 	 * Increment counters 	 */
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
comment|/* 	 * Now validate mapping with RO protection 	 */
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|l2prot
operator|=
name|PTE2_RO
operator||
name|PTE2_NM
expr_stmt|;
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|l2prot
operator||=
name|PTE2_U
operator||
name|PTE2_NG
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|l2prot
operator||=
name|PTE2_NX
expr_stmt|;
elseif|else
if|if
condition|(
name|m
operator|->
name|md
operator|.
name|pat_mode
operator|==
name|VM_MEMATTR_WB_WA
operator|&&
name|pmap
operator|!=
name|kernel_pmap
condition|)
block|{
comment|/* 		 * Sync icache if exec permission and attribute VM_MEMATTR_WB_WA 		 * is set. QQQ: For more info, see comments in pmap_enter(). 		 */
name|cache_icache_sync_fresh
argument_list|(
name|va
argument_list|,
name|pa
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|PTE2
argument_list|(
name|pa
argument_list|,
name|l2prot
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|mpt2pg
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_enter_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|pmap_enter_quick_locked
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Tries to create 1MB page mapping.  Returns TRUE if successful and  *  FALSE otherwise.  Fails if (1) a page table page cannot be allocated without  *  blocking, (2) a mapping already exists at the specified virtual address, or  *  (3) a pv entry cannot be allocated without reclaiming another pv entry.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_enter_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|uint32_t
name|l1prot
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_valid
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
condition|)
block|{
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: failure for va %#lx in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 		 * Abort this mapping if its PV entry could not be created. 		 */
if|if
condition|(
operator|!
name|pmap_pv_insert_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
condition|)
block|{
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: failure for va %#lx in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
block|}
comment|/* 	 * Increment counters. 	 */
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|+=
name|PTE1_SIZE
operator|/
name|PAGE_SIZE
expr_stmt|;
comment|/* 	 * Map the section. 	 * 	 * QQQ: Why VM_PROT_WRITE is not evaluated and the mapping is 	 *      made readonly? 	 */
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|l1prot
operator|=
name|PTE1_RO
operator||
name|PTE1_NM
expr_stmt|;
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|l1prot
operator||=
name|PTE1_U
operator||
name|PTE1_NG
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|l1prot
operator||=
name|PTE1_NX
expr_stmt|;
elseif|else
if|if
condition|(
name|m
operator|->
name|md
operator|.
name|pat_mode
operator|==
name|VM_MEMATTR_WB_WA
operator|&&
name|pmap
operator|!=
name|kernel_pmap
condition|)
block|{
comment|/* 		 * Sync icache if exec permission and attribute VM_MEMATTR_WB_WA 		 * is set. QQQ: For more info, see comments in pmap_enter(). 		 */
name|cache_icache_sync_fresh
argument_list|(
name|va
argument_list|,
name|pa
argument_list|,
name|PTE1_SIZE
argument_list|)
expr_stmt|;
block|}
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|PTE1
argument_list|(
name|pa
argument_list|,
name|l1prot
argument_list|,
name|ATTR_TO_L1
argument_list|(
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|pmap_pte1_mappings
operator|++
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: success for va %#lx in pmap %p"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Maps a sequence of resident pages belonging to the same object.  *  The sequence begins with the given page m_start.  This page is  *  mapped at the given virtual address start.  Each subsequent page is  *  mapped at a virtual address that is offset from start by the same  *  amount as the page is offset from m_start within the object.  The  *  last page in the sequence is the page with the largest offset from  *  m_start that can be mapped at a virtual address less than the given  *  virtual address end.  Not every virtual page between start and end  *  is mapped; only those for which a resident page exists with the  *  corresponding offset from m_start are mapped.  */
end_comment

begin_function
name|void
name|pmap_enter_object
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|start
parameter_list|,
name|vm_offset_t
name|end
parameter_list|,
name|vm_page_t
name|m_start
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mpt2pg
decl_stmt|;
name|vm_pindex_t
name|diff
decl_stmt|,
name|psize
decl_stmt|;
name|PDEBUG
argument_list|(
literal|6
argument_list|,
name|printf
argument_list|(
literal|"%s: pmap %p start %#x end  %#x m %p prot %#x\n"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
name|m_start
argument_list|,
name|prot
argument_list|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m_start
operator|->
name|object
argument_list|)
expr_stmt|;
name|psize
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|mpt2pg
operator|=
name|NULL
expr_stmt|;
name|m
operator|=
name|m_start
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
while|while
condition|(
name|m
operator|!=
name|NULL
operator|&&
operator|(
name|diff
operator|=
name|m
operator|->
name|pindex
operator|-
name|m_start
operator|->
name|pindex
operator|)
operator|<
name|psize
condition|)
block|{
name|va
operator|=
name|start
operator|+
name|ptoa
argument_list|(
name|diff
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|va
operator|&
name|PTE1_OFFSET
operator|)
operator|==
literal|0
operator|&&
name|va
operator|+
name|PTE1_SIZE
operator|<=
name|end
operator|&&
name|m
operator|->
name|psind
operator|==
literal|1
operator|&&
name|sp_enabled
operator|&&
name|pmap_enter_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|)
condition|)
name|m
operator|=
operator|&
name|m
index|[
name|PTE1_SIZE
operator|/
name|PAGE_SIZE
operator|-
literal|1
index|]
expr_stmt|;
else|else
name|mpt2pg
operator|=
name|pmap_enter_quick_locked
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
name|mpt2pg
argument_list|)
expr_stmt|;
name|m
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  This code maps large physical mmap regions into the  *  processor address space.  Note that some shortcuts  *  are taken, but the code works.  */
end_comment

begin_function
name|void
name|pmap_object_init_pt
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|,
name|pte2_pa
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|vm_memattr_t
name|pat_mode
decl_stmt|;
name|u_int
name|l1attr
decl_stmt|,
name|l1prot
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|object
operator|->
name|type
operator|==
name|OBJT_DEVICE
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_SG
argument_list|,
operator|(
literal|"%s: non-device object"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|addr
operator|&
name|PTE1_OFFSET
operator|)
operator|==
literal|0
operator|&&
operator|(
name|size
operator|&
name|PTE1_OFFSET
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|vm_object_populate
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|pindex
operator|+
name|atop
argument_list|(
name|size
argument_list|)
argument_list|)
condition|)
return|return;
name|p
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|p
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
argument_list|,
operator|(
literal|"%s: invalid page %p"
operator|,
name|__func__
operator|,
name|p
operator|)
argument_list|)
expr_stmt|;
name|pat_mode
operator|=
name|p
operator|->
name|md
operator|.
name|pat_mode
expr_stmt|;
comment|/* 		 * Abort the mapping if the first page is not physically 		 * aligned to a 1MB page boundary. 		 */
name|pte2_pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_pa
operator|&
name|PTE1_OFFSET
condition|)
return|return;
comment|/* 		 * Skip the first page. Abort the mapping if the rest of 		 * the pages are not physically contiguous or have differing 		 * memory attributes. 		 */
name|p
operator|=
name|TAILQ_NEXT
argument_list|(
name|p
argument_list|,
name|listq
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|pte2_pa
operator|+
name|PAGE_SIZE
init|;
name|pa
operator|<
name|pte2_pa
operator|+
name|size
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
block|{
name|KASSERT
argument_list|(
name|p
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
argument_list|,
operator|(
literal|"%s: invalid page %p"
operator|,
name|__func__
operator|,
name|p
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pa
operator|!=
name|VM_PAGE_TO_PHYS
argument_list|(
name|p
argument_list|)
operator|||
name|pat_mode
operator|!=
name|p
operator|->
name|md
operator|.
name|pat_mode
condition|)
return|return;
name|p
operator|=
name|TAILQ_NEXT
argument_list|(
name|p
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Map using 1MB pages. 		 * 		 * QQQ: Well, we are mapping a section, so same condition must 		 * be hold like during promotion. It looks that only RW mapping 		 * is done here, so readonly mapping must be done elsewhere. 		 */
name|l1prot
operator|=
name|PTE1_U
operator||
name|PTE1_NG
operator||
name|PTE1_RW
operator||
name|PTE1_M
operator||
name|PTE1_A
expr_stmt|;
name|l1attr
operator|=
name|ATTR_TO_L1
argument_list|(
name|vm_memattr_to_pte2
argument_list|(
name|pat_mode
argument_list|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|pte2_pa
init|;
name|pa
operator|<
name|pte2_pa
operator|+
name|size
condition|;
name|pa
operator|+=
name|PTE1_SIZE
control|)
block|{
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte1_is_valid
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
condition|)
block|{
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|PTE1
argument_list|(
name|pa
argument_list|,
name|l1prot
argument_list|,
name|l1attr
argument_list|)
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|+=
name|PTE1_SIZE
operator|/
name|PAGE_SIZE
expr_stmt|;
name|pmap_pte1_mappings
operator|++
expr_stmt|;
block|}
comment|/* Else continue on if the PTE1 is already valid. */
name|addr
operator|+=
name|PTE1_SIZE
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *  Do the things to protect a 1mpage in a process.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_protect_pte1
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt1_entry_t
modifier|*
name|pte1p
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|pt1_entry_t
name|npte1
decl_stmt|,
name|opte1
decl_stmt|;
name|vm_offset_t
name|eva
decl_stmt|,
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|sva
operator|&
name|PTE1_OFFSET
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: sva is not 1mpage aligned"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|opte1
operator|=
name|npte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_managed
argument_list|(
name|opte1
argument_list|)
operator|&&
name|pte1_is_dirty
argument_list|(
name|opte1
argument_list|)
condition|)
block|{
name|eva
operator|=
name|sva
operator|+
name|PTE1_SIZE
expr_stmt|;
for|for
control|(
name|va
operator|=
name|sva
operator|,
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte1_pa
argument_list|(
name|opte1
argument_list|)
argument_list|)
init|;
name|va
operator|<
name|eva
condition|;
name|va
operator|+=
name|PAGE_SIZE
operator|,
name|m
operator|++
control|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
condition|)
name|npte1
operator||=
name|PTE1_RO
operator||
name|PTE1_NM
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|npte1
operator||=
name|PTE1_NX
expr_stmt|;
comment|/* 	 * QQQ: Herein, execute permission is never set. 	 *      It only can be cleared. So, no icache 	 *      syncing is needed. 	 */
if|if
condition|(
name|npte1
operator|!=
name|opte1
condition|)
block|{
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|npte1
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	Set the physical protection on the  *	specified range of this map as requested.  */
end_comment

begin_function
name|void
name|pmap_protect
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|boolean_t
name|pv_lists_locked
decl_stmt|;
name|vm_offset_t
name|nextva
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|pte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|opte2
decl_stmt|,
name|npte2
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|prot
operator|&
operator|~
name|VM_PROT_ALL
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"invalid prot %x"
operator|,
name|prot
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|prot
operator|==
name|VM_PROT_NONE
condition|)
block|{
name|pmap_remove
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|prot
operator|&
operator|(
name|VM_PROT_WRITE
operator||
name|VM_PROT_EXECUTE
operator|)
operator|)
operator|==
operator|(
name|VM_PROT_WRITE
operator||
name|VM_PROT_EXECUTE
operator|)
condition|)
return|return;
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
name|pv_lists_locked
operator|=
name|FALSE
expr_stmt|;
else|else
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
name|resume
label|:
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
block|}
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|nextva
control|)
block|{
comment|/* 		 * Calculate address for next L2 page table. 		 */
name|nextva
operator|=
name|pte1_trunc
argument_list|(
name|sva
operator|+
name|PTE1_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|nextva
operator|<
name|sva
condition|)
name|nextva
operator|=
name|eva
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
comment|/* 		 * Weed out invalid mappings. Note: we assume that L1 page 		 * page table is always allocated, and in kernel virtual. 		 */
if|if
condition|(
name|pte1
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
comment|/* 			 * Are we protecting the entire large page?  If not, 			 * demote the mapping and fall through. 			 */
if|if
condition|(
name|sva
operator|+
name|PTE1_SIZE
operator|==
name|nextva
operator|&&
name|eva
operator|>=
name|nextva
condition|)
block|{
name|pmap_protect_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|sva
argument_list|,
name|prot
argument_list|)
expr_stmt|;
continue|continue;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|pv_lists_locked
condition|)
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
if|if
condition|(
operator|!
name|rw_try_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|resume
goto|;
block|}
name|sched_pin
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|pmap_demote_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|sva
argument_list|)
condition|)
block|{
comment|/* 					 * The large page mapping 					 * was destroyed. 					 */
continue|continue;
block|}
ifdef|#
directive|ifdef
name|INVARIANTS
else|else
block|{
comment|/* Update pte1 after demotion */
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
block|}
name|KASSERT
argument_list|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
argument_list|,
operator|(
literal|"%s: pmap %p va %#x pte1 %#x at %p"
literal|" is not link"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|sva
operator|,
name|pte1
operator|,
name|pte1p
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Limit our scan to either the end of the va represented 		 * by the current L2 page table page, or to the end of the 		 * range being protected. 		 */
if|if
condition|(
name|nextva
operator|>
name|eva
condition|)
name|nextva
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|nextva
condition|;
name|pte2p
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|opte2
operator|=
name|npte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|opte2
argument_list|)
condition|)
continue|continue;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|opte2
argument_list|)
operator|&&
name|pte2_is_dirty
argument_list|(
name|opte2
argument_list|)
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte2_pa
argument_list|(
name|opte2
argument_list|)
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|npte2
operator||=
name|PTE2_RO
operator||
name|PTE2_NM
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|npte2
operator||=
name|PTE2_NX
expr_stmt|;
comment|/* 			 * QQQ: Herein, execute permission is never set. 			 *      It only can be cleared. So, no icache 			 *      syncing is needed. 			 */
if|if
condition|(
name|npte2
operator|!=
name|opte2
condition|)
block|{
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|npte2
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|pv_lists_locked
condition|)
block|{
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	pmap_pvh_wired_mappings:  *  *	Return the updated number "count" of managed mappings that are wired.  */
end_comment

begin_function
specifier|static
name|int
name|pmap_pvh_wired_mappings
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
if|if
condition|(
name|pte1_is_wired
argument_list|(
name|pte1
argument_list|)
condition|)
name|count
operator|++
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
argument_list|,
operator|(
literal|"%s: pte1 %#x is not link"
operator|,
name|__func__
operator|,
name|pte1
operator|)
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_wired
argument_list|(
name|pte2
argument_list|)
condition|)
name|count
operator|++
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_page_wired_mappings:  *  *	Return the number of managed mappings to the given physical page  *	that are wired.  */
end_comment

begin_function
name|int
name|pmap_page_wired_mappings
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|count
decl_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|count
operator|)
return|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|count
operator|=
name|pmap_pvh_wired_mappings
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|count
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|count
operator|=
name|pmap_pvh_wired_mappings
argument_list|(
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Returns TRUE if any of the given mappings were used to modify  *  physical memory.  Otherwise, returns FALSE.  Both page and 1mpage  *  mappings are supported.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_is_modified_pvh
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|rv
operator|=
name|pte1_is_dirty
argument_list|(
name|pte1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
argument_list|,
operator|(
literal|"%s: pte1 %#x is not link"
operator|,
name|__func__
operator|,
name|pte1
operator|)
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
argument_list|)
expr_stmt|;
name|rv
operator|=
name|pte2_is_dirty
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
condition|)
break|break;
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_modified:  *  *	Return whether or not the specified physical page was modified  *	in any physical maps.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_modified
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: page %p is not managed"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not exclusive busied, then PGA_WRITEABLE cannot be 	 * concurrently set while the object is locked.  Thus, if PGA_WRITEABLE 	 * is clear, no PTE2s can have PG_M set. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|rv
operator|=
name|pmap_is_modified_pvh
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|)
operator|||
operator|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
name|pmap_is_modified_pvh
argument_list|(
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
operator|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_prefaultable:  *  *	Return whether or not the specified virtual address is eligible  *	for prefault.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_prefaultable
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pt2map_entry
argument_list|(
name|addr
argument_list|)
argument_list|)
expr_stmt|;
name|rv
operator|=
operator|!
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Returns TRUE if any of the given mappings were referenced and FALSE  *  otherwise. Both page and 1mpage mappings are supported.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_is_referenced_pvh
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|rv
operator|=
operator|(
name|pte1
operator|&
operator|(
name|PTE1_A
operator||
name|PTE1_V
operator|)
operator|)
operator|==
operator|(
name|PTE1_A
operator||
name|PTE1_V
operator|)
expr_stmt|;
block|}
else|else
block|{
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
argument_list|)
expr_stmt|;
name|rv
operator|=
operator|(
name|pte2
operator|&
operator|(
name|PTE2_A
operator||
name|PTE2_V
operator|)
operator|)
operator|==
operator|(
name|PTE2_A
operator||
name|PTE2_V
operator|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
condition|)
break|break;
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_referenced:  *  *	Return whether or not the specified physical page was referenced  *	in any physical maps.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_referenced
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: page %p is not managed"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|rv
operator|=
name|pmap_is_referenced_pvh
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|)
operator|||
operator|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
name|pmap_is_referenced_pvh
argument_list|(
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
operator|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_ts_referenced:  *  *	Return a count of reference bits for a page, clearing those bits.  *	It is not necessary for every reference bit to be cleared, but it  *	is necessary that 0 only be returned when there are truly no  *	reference bits set.  *  *	As an optimization, update the page's dirty field if a modified bit is  *	found while counting reference bits.  This opportunistic update can be  *	performed at low cost and can eliminate the need for some future calls  *	to pmap_is_modified().  However, since this function stops after  *	finding PMAP_TS_REFERENCED_MAX reference bits, it may not detect some  *	dirty pages.  Those dirty pages will only be detected by a future call  *	to pmap_is_modified().  */
end_comment

begin_function
name|int
name|pmap_ts_referenced
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|,
name|pvf
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|opte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|opte2
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|int
name|rtval
init|=
literal|0
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: page %p is not managed"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
operator|||
operator|(
name|pvf
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
operator|)
operator|==
name|NULL
condition|)
goto|goto
name|small_mappings
goto|;
name|pv
operator|=
name|pvf
expr_stmt|;
do|do
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|opte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_dirty
argument_list|(
name|opte1
argument_list|)
condition|)
block|{
comment|/* 			 * Although "opte1" is mapping a 1MB page, because 			 * this function is called at a 4KB page granularity, 			 * we only update the 4KB page under test. 			 */
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|opte1
operator|&
name|PTE1_A
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * Since this reference bit is shared by 256 4KB pages, 			 * it should not be cleared every time it is tested. 			 * Apply a simple "hash" function on the physical page 			 * number, the virtual section number, and the pmap 			 * address to select one 4KB page out of the 256 			 * on which testing the reference bit will result 			 * in clearing that bit. This function is designed 			 * to avoid the selection of the same 4KB page 			 * for every 1MB page mapping. 			 * 			 * On demotion, a mapping that hasn't been referenced 			 * is simply destroyed.  To avoid the possibility of a 			 * subsequent page fault on a demoted wired mapping, 			 * always leave its reference bit set.  Moreover, 			 * since the section is wired, the current state of 			 * its reference bit won't affect page replacement. 			 */
if|if
condition|(
operator|(
operator|(
operator|(
name|pa
operator|>>
name|PAGE_SHIFT
operator|)
operator|^
operator|(
name|pv
operator|->
name|pv_va
operator|>>
name|PTE1_SHIFT
operator|)
operator|^
operator|(
name|uintptr_t
operator|)
name|pmap
operator|)
operator|&
operator|(
name|NPTE2_IN_PG
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
operator|&&
operator|!
name|pte1_is_wired
argument_list|(
name|opte1
argument_list|)
condition|)
block|{
name|pte1_clear_bit
argument_list|(
name|pte1p
argument_list|,
name|PTE1_A
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
block|}
name|rtval
operator|++
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Rotate the PV list if it has more than one entry. */
if|if
condition|(
name|TAILQ_NEXT
argument_list|(
name|pv
argument_list|,
name|pv_next
argument_list|)
operator|!=
name|NULL
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|rtval
operator|>=
name|PMAP_TS_REFERENCED_MAX
condition|)
goto|goto
name|out
goto|;
block|}
do|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
operator|)
operator|!=
name|pvf
condition|)
do|;
name|small_mappings
label|:
if|if
condition|(
operator|(
name|pvf
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|==
name|NULL
condition|)
goto|goto
name|out
goto|;
name|pv
operator|=
name|pvf
expr_stmt|;
do|do
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pte1_is_link
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
argument_list|,
operator|(
literal|"%s: not found a link in page %p's pv list"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|opte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_dirty
argument_list|(
name|opte2
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|opte2
operator|&
name|PTE2_A
operator|)
operator|!=
literal|0
condition|)
block|{
name|pte2_clear_bit
argument_list|(
name|pte2p
argument_list|,
name|PTE2_A
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|rtval
operator|++
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Rotate the PV list if it has more than one entry. */
if|if
condition|(
name|TAILQ_NEXT
argument_list|(
name|pv
argument_list|,
name|pv_next
argument_list|)
operator|!=
name|NULL
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
block|}
block|}
do|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|!=
name|pvf
operator|&&
name|rtval
operator|<
name|PMAP_TS_REFERENCED_MAX
condition|)
do|;
name|out
label|:
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rtval
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Clear the wired attribute from the mappings for the specified range of  *	addresses in the given pmap.  Every valid mapping within that range  *	must have the wired attribute set.  In contrast, invalid mappings  *	cannot have the wired attribute set, so they are ignored.  *  *	The wired attribute of the page table entry is not a hardware feature,  *	so there is no need to invalidate any TLB entries.  */
end_comment

begin_function
name|void
name|pmap_unwire
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|vm_offset_t
name|nextva
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|pte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|boolean_t
name|pv_lists_locked
decl_stmt|;
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
name|pv_lists_locked
operator|=
name|FALSE
expr_stmt|;
else|else
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
name|resume
label|:
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
block|}
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|nextva
control|)
block|{
name|nextva
operator|=
name|pte1_trunc
argument_list|(
name|sva
operator|+
name|PTE1_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|nextva
operator|<
name|sva
condition|)
name|nextva
operator|=
name|eva
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
comment|/* 		 * Weed out invalid mappings. Note: we assume that L1 page 		 * page table is always allocated, and in kernel virtual. 		 */
if|if
condition|(
name|pte1
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|pte1_is_wired
argument_list|(
name|pte1
argument_list|)
condition|)
name|panic
argument_list|(
literal|"%s: pte1 %#x not wired"
argument_list|,
name|__func__
argument_list|,
name|pte1
argument_list|)
expr_stmt|;
comment|/* 			 * Are we unwiring the entire large page?  If not, 			 * demote the mapping and fall through. 			 */
if|if
condition|(
name|sva
operator|+
name|PTE1_SIZE
operator|==
name|nextva
operator|&&
name|eva
operator|>=
name|nextva
condition|)
block|{
name|pte1_clear_bit
argument_list|(
name|pte1p
argument_list|,
name|PTE1_W
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|-=
name|PTE1_SIZE
operator|/
name|PAGE_SIZE
expr_stmt|;
continue|continue;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|pv_lists_locked
condition|)
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
if|if
condition|(
operator|!
name|rw_try_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Repeat sva. */
goto|goto
name|resume
goto|;
block|}
name|sched_pin
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|pmap_demote_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|sva
argument_list|)
condition|)
name|panic
argument_list|(
literal|"%s: demotion failed"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|INVARIANTS
else|else
block|{
comment|/* Update pte1 after demotion */
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
block|}
name|KASSERT
argument_list|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
argument_list|,
operator|(
literal|"%s: pmap %p va %#x pte1 %#x at %p"
literal|" is not link"
operator|,
name|__func__
operator|,
name|pmap
operator|,
name|sva
operator|,
name|pte1
operator|,
name|pte1p
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Limit our scan to either the end of the va represented 		 * by the current L2 page table page, or to the end of the 		 * range being protected. 		 */
if|if
condition|(
name|nextva
operator|>
name|eva
condition|)
name|nextva
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|nextva
condition|;
name|pte2p
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
continue|continue;
if|if
condition|(
operator|!
name|pte2_is_wired
argument_list|(
name|pte2
argument_list|)
condition|)
name|panic
argument_list|(
literal|"%s: pte2 %#x is missing PTE2_W"
argument_list|,
name|__func__
argument_list|,
name|pte2
argument_list|)
expr_stmt|;
comment|/* 			 * PTE2_W must be cleared atomically. Although the pmap 			 * lock synchronizes access to PTE2_W, another processor 			 * could be changing PTE2_NM and/or PTE2_A concurrently. 			 */
name|pte2_clear_bit
argument_list|(
name|pte2p
argument_list|,
name|PTE2_W
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pv_lists_locked
condition|)
block|{
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Clear the write and modified bits in each of the given page's mappings.  */
end_comment

begin_function
name|void
name|pmap_remove_write
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|next_pv
decl_stmt|,
name|pv
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|opte2
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: page %p is not managed"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not exclusive busied, then PGA_WRITEABLE cannot be 	 * set by another thread while the object is locked.  Thus, 	 * if PGA_WRITEABLE is clear, no page table entries need updating. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
goto|goto
name|small_mappings
goto|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|,
argument|next_pv
argument_list|)
block|{
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
operator|&
name|PTE1_RO
operator|)
condition|)
operator|(
name|void
operator|)
name|pmap_demote_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|small_mappings
label|:
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pte1_is_section
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
argument_list|,
operator|(
literal|"%s: found"
literal|" a section in page %p's pv list"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|opte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|opte2
operator|&
name|PTE2_RO
operator|)
condition|)
block|{
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|opte2
operator||
name|PTE2_RO
operator||
name|PTE2_NM
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_dirty
argument_list|(
name|opte2
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Apply the given advice to the specified range of addresses within the  *	given pmap.  Depending on the advice, clear the referenced and/or  *	modified flags in each mapping and set the mapped page's dirty field.  */
end_comment

begin_function
name|void
name|pmap_advise
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|int
name|advice
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|opte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|vm_offset_t
name|pdnxt
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|boolean_t
name|pv_lists_locked
decl_stmt|;
if|if
condition|(
name|advice
operator|!=
name|MADV_DONTNEED
operator|&&
name|advice
operator|!=
name|MADV_FREE
condition|)
return|return;
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
name|pv_lists_locked
operator|=
name|FALSE
expr_stmt|;
else|else
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
name|resume
label|:
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
block|}
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|pdnxt
control|)
block|{
name|pdnxt
operator|=
name|pte1_trunc
argument_list|(
name|sva
operator|+
name|PTE1_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|pdnxt
operator|<
name|sva
condition|)
name|pdnxt
operator|=
name|eva
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|opte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte1_is_valid
argument_list|(
name|opte1
argument_list|)
condition|)
comment|/* XXX */
continue|continue;
elseif|else
if|if
condition|(
name|pte1_is_section
argument_list|(
name|opte1
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|pte1_is_managed
argument_list|(
name|opte1
argument_list|)
condition|)
continue|continue;
if|if
condition|(
operator|!
name|pv_lists_locked
condition|)
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
if|if
condition|(
operator|!
name|rw_try_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|resume
goto|;
block|}
name|sched_pin
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|pmap_demote_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|sva
argument_list|)
condition|)
block|{
comment|/* 				 * The large page mapping was destroyed. 				 */
continue|continue;
block|}
comment|/* 			 * Unless the page mappings are wired, remove the 			 * mapping to a single page so that a subsequent 			 * access may repromote.  Since the underlying L2 page 			 * table is fully populated, this removal never 			 * frees a L2 page table page. 			 */
if|if
condition|(
operator|!
name|pte1_is_wired
argument_list|(
name|opte1
argument_list|)
condition|)
block|{
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pte2_is_valid
argument_list|(
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
argument_list|)
argument_list|,
operator|(
literal|"%s: invalid PTE2"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|pmap_remove_pte2
argument_list|(
name|pmap
argument_list|,
name|pte2p
argument_list|,
name|sva
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pdnxt
operator|>
name|eva
condition|)
name|pdnxt
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|pdnxt
condition|;
name|pte2p
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
operator|||
operator|!
name|pte2_is_managed
argument_list|(
name|pte2
argument_list|)
condition|)
continue|continue;
elseif|else
if|if
condition|(
name|pte2_is_dirty
argument_list|(
name|pte2
argument_list|)
condition|)
block|{
if|if
condition|(
name|advice
operator|==
name|MADV_DONTNEED
condition|)
block|{
comment|/* 					 * Future calls to pmap_is_modified() 					 * can be avoided by making the page 					 * dirty now. 					 */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|pte2_set_bit
argument_list|(
name|pte2p
argument_list|,
name|PTE2_NM
argument_list|)
expr_stmt|;
name|pte2_clear_bit
argument_list|(
name|pte2p
argument_list|,
name|PTE2_A
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|pte2
operator|&
name|PTE2_A
operator|)
operator|!=
literal|0
condition|)
name|pte2_clear_bit
argument_list|(
name|pte2p
argument_list|,
name|PTE2_A
argument_list|)
expr_stmt|;
else|else
continue|continue;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pv_lists_locked
condition|)
block|{
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Clear the modify bits on the specified physical page.  */
end_comment

begin_function
name|void
name|pmap_clear_modify
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|next_pv
decl_stmt|,
name|pv
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|opte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|opte2
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: page %p is not managed"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"%s: page %p is exclusive busy"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not PGA_WRITEABLE, then no PTE2s can have PTE2_NM 	 * cleared. If the object containing the page is locked and the page 	 * is not exclusive busied, then PGA_WRITEABLE cannot be concurrently 	 * set. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
goto|goto
name|small_mappings
goto|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|,
argument|next_pv
argument_list|)
block|{
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|opte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|opte1
operator|&
name|PTE1_RO
operator|)
condition|)
block|{
if|if
condition|(
name|pmap_demote_pte1
argument_list|(
name|pmap
argument_list|,
name|pte1p
argument_list|,
name|va
argument_list|)
operator|&&
operator|!
name|pte1_is_wired
argument_list|(
name|opte1
argument_list|)
condition|)
block|{
comment|/* 				 * Write protect the mapping to a 				 * single page so that a subsequent 				 * write access may repromote. 				 */
name|va
operator|+=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator|-
name|pte1_pa
argument_list|(
name|opte1
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|opte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|opte2
operator|&
name|PTE2_V
operator|)
condition|)
block|{
name|pte2_set_bit
argument_list|(
name|pte2p
argument_list|,
name|PTE2_NM
operator||
name|PTE2_RO
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|small_mappings
label|:
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pte1_is_section
argument_list|(
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
argument_list|)
argument_list|,
operator|(
literal|"%s: found"
literal|" a section in page %p's pv list"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_dirty
argument_list|(
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
argument_list|)
condition|)
block|{
name|pte2_set_bit
argument_list|(
name|pte2p
argument_list|,
name|PTE2_NM
argument_list|)
expr_stmt|;
name|pmap_tlb_flush
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Sets the memory attribute for the specified page.  */
end_comment

begin_function
name|void
name|pmap_page_set_memattr
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|cmap2_pte2p
decl_stmt|;
name|vm_memattr_t
name|oma
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|oma
operator|=
name|m
operator|->
name|md
operator|.
name|pat_mode
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pat_mode
operator|=
name|ma
expr_stmt|;
name|CTR5
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: page %p - 0x%08X oma: %d, ma: %d"
argument_list|,
name|__func__
argument_list|,
name|m
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|oma
argument_list|,
name|ma
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
return|return;
if|#
directive|if
literal|0
comment|/* 	 * If "m" is a normal page, flush it from the cache. 	 * 	 * First, try to find an existing mapping of the page by sf 	 * buffer. sf_buf_invalidate_cache() modifies mapping and 	 * flushes the cache. 	 */
block|if (sf_buf_invalidate_cache(m, oma)) 		return;
endif|#
directive|endif
comment|/* 	 * If page is not mapped by sf buffer, map the page 	 * transient and do invalidation. 	 */
if|if
condition|(
name|ma
operator|!=
name|oma
condition|)
block|{
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap2_pte2p
operator|=
name|pc
operator|->
name|pc_cmap2_pte2p
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_load
argument_list|(
name|cmap2_pte2p
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: CMAP2 busy"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|cmap2_pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|pa
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|vm_memattr_to_pte2
argument_list|(
name|ma
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|dcache_wbinv_poc
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|,
name|pa
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|cmap2_pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *  Miscellaneous support routines follow  */
end_comment

begin_comment
comment|/*  *  Returns TRUE if the given page is mapped individually or as part of  *  a 1mpage.  Otherwise, returns FALSE.  */
end_comment

begin_function
name|boolean_t
name|pmap_page_is_mapped
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|boolean_t
name|rv
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|rv
operator|=
operator|!
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|||
operator|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
operator|!
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
operator|->
name|pv_list
argument_list|)
operator|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *  Returns true if the pmap's pv is one of the first  *  16 pvs linked to from this page.  This count may  *  be changed upwards or downwards in the future; it  *  is only necessary that true be returned for a small  *  subset of pmaps for proper page aging.  */
end_comment

begin_function
name|boolean_t
name|pmap_page_exists_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|int
name|loops
init|=
literal|0
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: page %p is not managed"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|==
name|pmap
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
name|loops
operator|++
expr_stmt|;
if|if
condition|(
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
if|if
condition|(
operator|!
name|rv
operator|&&
name|loops
operator|<
literal|16
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|==
name|pmap
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
name|loops
operator|++
expr_stmt|;
if|if
condition|(
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
block|}
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_zero_page zeros the specified hardware page by mapping  *	the page into KVM and using bzero to clear its contents.  */
end_comment

begin_function
name|void
name|pmap_zero_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|cmap2_pte2p
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap2_pte2p
operator|=
name|pc
operator|->
name|pc_cmap2_pte2p
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_load
argument_list|(
name|cmap2_pte2p
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: CMAP2 busy"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|cmap2_pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|pagezero
argument_list|(
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|cmap2_pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	pmap_zero_page_area zeros the specified hardware page by mapping  *	the page into KVM and using bzero to clear its contents.  *  *	off and size may not cover an area beyond a single hardware page.  */
end_comment

begin_function
name|void
name|pmap_zero_page_area
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|cmap2_pte2p
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap2_pte2p
operator|=
name|pc
operator|->
name|pc_cmap2_pte2p
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_load
argument_list|(
name|cmap2_pte2p
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: CMAP2 busy"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|cmap2_pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|off
operator|==
literal|0
operator|&&
name|size
operator|==
name|PAGE_SIZE
condition|)
name|pagezero
argument_list|(
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
else|else
name|bzero
argument_list|(
name|pc
operator|->
name|pc_cmap2_addr
operator|+
name|off
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|cmap2_pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	pmap_copy_page copies the specified (machine independent)  *	page by mapping the page into virtual memory and using  *	bcopy to copy the page, one machine dependent page at a  *	time.  */
end_comment

begin_function
name|void
name|pmap_copy_page
parameter_list|(
name|vm_page_t
name|src
parameter_list|,
name|vm_page_t
name|dst
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|cmap1_pte2p
decl_stmt|,
modifier|*
name|cmap2_pte2p
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap1_pte2p
operator|=
name|pc
operator|->
name|pc_cmap1_pte2p
expr_stmt|;
name|cmap2_pte2p
operator|=
name|pc
operator|->
name|pc_cmap2_pte2p
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_load
argument_list|(
name|cmap1_pte2p
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: CMAP1 busy"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_load
argument_list|(
name|cmap2_pte2p
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: CMAP2 busy"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|cmap1_pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|src
argument_list|)
argument_list|,
name|PTE2_AP_KR
operator||
name|PTE2_NM
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|src
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|cmap2_pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|dst
argument_list|)
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|dst
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|pc
operator|->
name|pc_cmap1_addr
argument_list|,
name|pc
operator|->
name|pc_cmap2_addr
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|cmap1_pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap1_addr
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|cmap2_pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_decl_stmt
name|int
name|unmapped_buf_allowed
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|pmap_copy_pages
parameter_list|(
name|vm_page_t
name|ma
index|[]
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
name|mb
index|[]
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|cmap1_pte2p
decl_stmt|,
modifier|*
name|cmap2_pte2p
decl_stmt|;
name|vm_page_t
name|a_pg
decl_stmt|,
name|b_pg
decl_stmt|;
name|char
modifier|*
name|a_cp
decl_stmt|,
modifier|*
name|b_cp
decl_stmt|;
name|vm_offset_t
name|a_pg_offset
decl_stmt|,
name|b_pg_offset
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|int
name|cnt
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap1_pte2p
operator|=
name|pc
operator|->
name|pc_cmap1_pte2p
expr_stmt|;
name|cmap2_pte2p
operator|=
name|pc
operator|->
name|pc_cmap2_pte2p
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_load
argument_list|(
name|cmap1_pte2p
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_copy_pages: CMAP1 busy"
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_load
argument_list|(
name|cmap2_pte2p
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_copy_pages: CMAP2 busy"
argument_list|)
expr_stmt|;
while|while
condition|(
name|xfersize
operator|>
literal|0
condition|)
block|{
name|a_pg
operator|=
name|ma
index|[
name|a_offset
operator|>>
name|PAGE_SHIFT
index|]
expr_stmt|;
name|a_pg_offset
operator|=
name|a_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|xfersize
argument_list|,
name|PAGE_SIZE
operator|-
name|a_pg_offset
argument_list|)
expr_stmt|;
name|b_pg
operator|=
name|mb
index|[
name|b_offset
operator|>>
name|PAGE_SHIFT
index|]
expr_stmt|;
name|b_pg_offset
operator|=
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|cnt
argument_list|,
name|PAGE_SIZE
operator|-
name|b_pg_offset
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|cmap1_pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|a_pg
argument_list|)
argument_list|,
name|PTE2_AP_KR
operator||
name|PTE2_NM
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|a_pg
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|tlb_flush_local
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap1_addr
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|cmap2_pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|b_pg
argument_list|)
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|b_pg
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|tlb_flush_local
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|a_cp
operator|=
name|pc
operator|->
name|pc_cmap1_addr
operator|+
name|a_pg_offset
expr_stmt|;
name|b_cp
operator|=
name|pc
operator|->
name|pc_cmap2_addr
operator|+
name|b_pg_offset
expr_stmt|;
name|bcopy
argument_list|(
name|a_cp
argument_list|,
name|b_cp
argument_list|,
name|cnt
argument_list|)
expr_stmt|;
name|a_offset
operator|+=
name|cnt
expr_stmt|;
name|b_offset
operator|+=
name|cnt
expr_stmt|;
name|xfersize
operator|-=
name|cnt
expr_stmt|;
block|}
name|pte2_clear
argument_list|(
name|cmap1_pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap1_addr
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|cmap2_pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|vm_offset_t
name|pmap_quick_enter_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|critical_enter
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|pte2p
operator|=
name|pc
operator|->
name|pc_qmap_pte2p
expr_stmt|;
name|KASSERT
argument_list|(
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: PTE2 busy"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|pc
operator|->
name|pc_qmap_addr
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_quick_remove_page
parameter_list|(
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|pte2p
operator|=
name|pc
operator|->
name|pc_qmap_pte2p
expr_stmt|;
name|KASSERT
argument_list|(
name|addr
operator|==
name|pc
operator|->
name|pc_qmap_addr
argument_list|,
operator|(
literal|"%s: invalid address"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"%s: PTE2 not in use"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
name|pc
operator|->
name|pc_qmap_addr
argument_list|)
expr_stmt|;
name|critical_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Copy the range specified by src_addr/len  *	from the source map to the range dst_addr/len  *	in the destination map.  *  *	This routine is only advisory and need not do anything.  */
end_comment

begin_function
name|void
name|pmap_copy
parameter_list|(
name|pmap_t
name|dst_pmap
parameter_list|,
name|pmap_t
name|src_pmap
parameter_list|,
name|vm_offset_t
name|dst_addr
parameter_list|,
name|vm_size_t
name|len
parameter_list|,
name|vm_offset_t
name|src_addr
parameter_list|)
block|{
name|struct
name|spglist
name|free
decl_stmt|;
name|vm_offset_t
name|addr
decl_stmt|;
name|vm_offset_t
name|end_addr
init|=
name|src_addr
operator|+
name|len
decl_stmt|;
name|vm_offset_t
name|nextva
decl_stmt|;
if|if
condition|(
name|dst_addr
operator|!=
name|src_addr
condition|)
return|return;
if|if
condition|(
operator|!
name|pmap_is_current
argument_list|(
name|src_pmap
argument_list|)
condition|)
return|return;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|dst_pmap
operator|<
name|src_pmap
condition|)
block|{
name|PMAP_LOCK
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|src_pmap
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|PMAP_LOCK
argument_list|(
name|src_pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
block|}
name|sched_pin
argument_list|()
expr_stmt|;
for|for
control|(
name|addr
operator|=
name|src_addr
init|;
name|addr
operator|<
name|end_addr
condition|;
name|addr
operator|=
name|nextva
control|)
block|{
name|pt2_entry_t
modifier|*
name|src_pte2p
decl_stmt|,
modifier|*
name|dst_pte2p
decl_stmt|;
name|vm_page_t
name|dst_mpt2pg
decl_stmt|,
name|src_mpt2pg
decl_stmt|;
name|pt1_entry_t
name|src_pte1
decl_stmt|;
name|u_int
name|pte1_idx
decl_stmt|;
name|KASSERT
argument_list|(
name|addr
operator|<
name|VM_MAXUSER_ADDRESS
argument_list|,
operator|(
literal|"%s: invalid to pmap_copy page tables"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|nextva
operator|=
name|pte1_trunc
argument_list|(
name|addr
operator|+
name|PTE1_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|nextva
operator|<
name|addr
condition|)
name|nextva
operator|=
name|end_addr
expr_stmt|;
name|pte1_idx
operator|=
name|pte1_index
argument_list|(
name|addr
argument_list|)
expr_stmt|;
name|src_pte1
operator|=
name|src_pmap
operator|->
name|pm_pt1
index|[
name|pte1_idx
index|]
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|src_pte1
argument_list|)
condition|)
block|{
if|if
condition|(
operator|(
name|addr
operator|&
name|PTE1_OFFSET
operator|)
operator|!=
literal|0
operator|||
operator|(
name|addr
operator|+
name|PTE1_SIZE
operator|)
operator|>
name|end_addr
condition|)
continue|continue;
if|if
condition|(
name|dst_pmap
operator|->
name|pm_pt1
index|[
name|pte1_idx
index|]
operator|==
literal|0
operator|&&
operator|(
operator|!
name|pte1_is_managed
argument_list|(
name|src_pte1
argument_list|)
operator|||
name|pmap_pv_insert_pte1
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|pte1_pa
argument_list|(
name|src_pte1
argument_list|)
argument_list|)
operator|)
condition|)
block|{
name|dst_pmap
operator|->
name|pm_pt1
index|[
name|pte1_idx
index|]
operator|=
name|src_pte1
operator|&
operator|~
name|PTE1_W
expr_stmt|;
name|dst_pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|+=
name|PTE1_SIZE
operator|/
name|PAGE_SIZE
expr_stmt|;
name|pmap_pte1_mappings
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
elseif|else
if|if
condition|(
operator|!
name|pte1_is_link
argument_list|(
name|src_pte1
argument_list|)
condition|)
continue|continue;
name|src_mpt2pg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte1_link_pa
argument_list|(
name|src_pte1
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 		 * We leave PT2s to be linked from PT1 even if they are not 		 * referenced until all PT2s in a page are without reference. 		 * 		 * QQQ: It could be changed ... 		 */
if|#
directive|if
literal|0
comment|/* single_pt2_link_is_cleared */
block|KASSERT(pt2_wirecount_get(src_mpt2pg, pte1_idx)> 0, 		    ("%s: source page table page is unused", __func__));
else|#
directive|else
if|if
condition|(
name|pt2_wirecount_get
argument_list|(
name|src_mpt2pg
argument_list|,
name|pte1_idx
argument_list|)
operator|==
literal|0
condition|)
continue|continue;
endif|#
directive|endif
if|if
condition|(
name|nextva
operator|>
name|end_addr
condition|)
name|nextva
operator|=
name|end_addr
expr_stmt|;
name|src_pte2p
operator|=
name|pt2map_entry
argument_list|(
name|addr
argument_list|)
expr_stmt|;
while|while
condition|(
name|addr
operator|<
name|nextva
condition|)
block|{
name|pt2_entry_t
name|temp_pte2
decl_stmt|;
name|temp_pte2
operator|=
name|pte2_load
argument_list|(
name|src_pte2p
argument_list|)
expr_stmt|;
comment|/* 			 * we only virtual copy managed pages 			 */
if|if
condition|(
name|pte2_is_managed
argument_list|(
name|temp_pte2
argument_list|)
condition|)
block|{
name|dst_mpt2pg
operator|=
name|pmap_allocpte2
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|PMAP_ENTER_NOSLEEP
argument_list|)
expr_stmt|;
if|if
condition|(
name|dst_mpt2pg
operator|==
name|NULL
condition|)
goto|goto
name|out
goto|;
name|dst_pte2p
operator|=
name|pmap_pte2_quick
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2_load
argument_list|(
name|dst_pte2p
argument_list|)
argument_list|)
operator|&&
name|pmap_try_insert_pv_entry
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte2_pa
argument_list|(
name|temp_pte2
argument_list|)
argument_list|)
argument_list|)
condition|)
block|{
comment|/* 					 * Clear the wired, modified, and 					 * accessed (referenced) bits 					 * during the copy. 					 */
name|temp_pte2
operator|&=
operator|~
operator|(
name|PTE2_W
operator||
name|PTE2_A
operator|)
expr_stmt|;
name|temp_pte2
operator||=
name|PTE2_NM
expr_stmt|;
name|pte2_store
argument_list|(
name|dst_pte2p
argument_list|,
name|temp_pte2
argument_list|)
expr_stmt|;
name|dst_pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
block|}
else|else
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_unwire_pt2
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|dst_mpt2pg
argument_list|,
operator|&
name|free
argument_list|)
condition|)
block|{
name|pmap_tlb_flush
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
goto|goto
name|out
goto|;
block|}
if|if
condition|(
name|pt2_wirecount_get
argument_list|(
name|dst_mpt2pg
argument_list|,
name|pte1_idx
argument_list|)
operator|>=
name|pt2_wirecount_get
argument_list|(
name|src_mpt2pg
argument_list|,
name|pte1_idx
argument_list|)
condition|)
break|break;
block|}
name|addr
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|src_pte2p
operator|++
expr_stmt|;
block|}
block|}
name|out
label|:
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|src_pmap
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Increase the starting virtual address of the given mapping if a  *	different alignment might result in more section mappings.  */
end_comment

begin_function
name|void
name|pmap_align_superpage
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_ooffset_t
name|offset
parameter_list|,
name|vm_offset_t
modifier|*
name|addr
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|vm_offset_t
name|pte1_offset
decl_stmt|;
if|if
condition|(
name|size
operator|<
name|PTE1_SIZE
condition|)
return|return;
if|if
condition|(
name|object
operator|!=
name|NULL
operator|&&
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_COLORED
operator|)
operator|!=
literal|0
condition|)
name|offset
operator|+=
name|ptoa
argument_list|(
name|object
operator|->
name|pg_color
argument_list|)
expr_stmt|;
name|pte1_offset
operator|=
name|offset
operator|&
name|PTE1_OFFSET
expr_stmt|;
if|if
condition|(
name|size
operator|-
operator|(
operator|(
name|PTE1_SIZE
operator|-
name|pte1_offset
operator|)
operator|&
name|PTE1_OFFSET
operator|)
operator|<
name|PTE1_SIZE
operator|||
operator|(
operator|*
name|addr
operator|&
name|PTE1_OFFSET
operator|)
operator|==
name|pte1_offset
condition|)
return|return;
if|if
condition|(
operator|(
operator|*
name|addr
operator|&
name|PTE1_OFFSET
operator|)
operator|<
name|pte1_offset
condition|)
operator|*
name|addr
operator|=
name|pte1_trunc
argument_list|(
operator|*
name|addr
argument_list|)
operator|+
name|pte1_offset
expr_stmt|;
else|else
operator|*
name|addr
operator|=
name|pte1_roundup
argument_list|(
operator|*
name|addr
argument_list|)
operator|+
name|pte1_offset
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_activate
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|,
name|oldpmap
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|,
name|ttb
decl_stmt|;
name|PDEBUG
argument_list|(
literal|9
argument_list|,
name|printf
argument_list|(
literal|"%s: td = %08x\n"
argument_list|,
name|__func__
argument_list|,
operator|(
name|uint32_t
operator|)
name|td
argument_list|)
argument_list|)
expr_stmt|;
name|critical_enter
argument_list|()
expr_stmt|;
name|pmap
operator|=
name|vmspace_pmap
argument_list|(
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
argument_list|)
expr_stmt|;
name|oldpmap
operator|=
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
expr_stmt|;
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|SMP
argument_list|)
name|CPU_CLR_ATOMIC
argument_list|(
name|cpuid
argument_list|,
operator|&
name|oldpmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|CPU_SET_ATOMIC
argument_list|(
name|cpuid
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
else|#
directive|else
name|CPU_CLR
argument_list|(
name|cpuid
argument_list|,
operator|&
name|oldpmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|CPU_SET
argument_list|(
name|cpuid
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|ttb
operator|=
name|pmap_ttb_get
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * pmap_activate is for the current thread on the current cpu 	 */
name|td
operator|->
name|td_pcb
operator|->
name|pcb_pagedir
operator|=
name|ttb
expr_stmt|;
name|cp15_ttbr_set
argument_list|(
name|ttb
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|critical_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Perform the pmap work for mincore.  */
end_comment

begin_function
name|int
name|pmap_mincore
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|vm_paddr_t
modifier|*
name|locked_pa
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|pte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|bool
name|managed
decl_stmt|;
name|int
name|val
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pa
operator|=
name|trunc_page
argument_list|(
name|pte1_pa
argument_list|(
name|pte1
argument_list|)
operator||
operator|(
name|addr
operator|&
name|PTE1_OFFSET
operator|)
argument_list|)
expr_stmt|;
name|managed
operator|=
name|pte1_is_managed
argument_list|(
name|pte1
argument_list|)
expr_stmt|;
name|val
operator|=
name|MINCORE_SUPER
operator||
name|MINCORE_INCORE
expr_stmt|;
if|if
condition|(
name|pte1_is_dirty
argument_list|(
name|pte1
argument_list|)
condition|)
name|val
operator||=
name|MINCORE_MODIFIED
operator||
name|MINCORE_MODIFIED_OTHER
expr_stmt|;
if|if
condition|(
name|pte1
operator|&
name|PTE1_A
condition|)
name|val
operator||=
name|MINCORE_REFERENCED
operator||
name|MINCORE_REFERENCED_OTHER
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pte2p
operator|=
name|pmap_pte2
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|pmap_pte2_release
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|pa
operator|=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
name|managed
operator|=
name|pte2_is_managed
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
name|val
operator|=
name|MINCORE_INCORE
expr_stmt|;
if|if
condition|(
name|pte2_is_dirty
argument_list|(
name|pte2
argument_list|)
condition|)
name|val
operator||=
name|MINCORE_MODIFIED
operator||
name|MINCORE_MODIFIED_OTHER
expr_stmt|;
if|if
condition|(
name|pte2
operator|&
name|PTE2_A
condition|)
name|val
operator||=
name|MINCORE_REFERENCED
operator||
name|MINCORE_REFERENCED_OTHER
expr_stmt|;
block|}
else|else
block|{
name|managed
operator|=
name|false
expr_stmt|;
name|val
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|val
operator|&
operator|(
name|MINCORE_MODIFIED_OTHER
operator||
name|MINCORE_REFERENCED_OTHER
operator|)
operator|)
operator|!=
operator|(
name|MINCORE_MODIFIED_OTHER
operator||
name|MINCORE_REFERENCED_OTHER
operator|)
operator|&&
name|managed
condition|)
block|{
comment|/* Ensure that "PHYS_TO_VM_PAGE(pa)->object" doesn't change. */
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|pa
argument_list|,
name|locked_pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
block|}
else|else
name|PA_UNLOCK_COND
argument_list|(
operator|*
name|locked_pa
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|val
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_kenter_device
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|vm_offset_t
name|sva
decl_stmt|;
name|uint32_t
name|l2attr
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|size
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: device mapping not page-sized"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|sva
operator|=
name|va
expr_stmt|;
name|l2attr
operator|=
name|vm_memattr_to_pte2
argument_list|(
name|VM_MEMATTR_DEVICE
argument_list|)
expr_stmt|;
while|while
condition|(
name|size
operator|!=
literal|0
condition|)
block|{
name|pmap_kenter_prot_attr
argument_list|(
name|va
argument_list|,
name|pa
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|l2attr
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|size
operator|-=
name|PAGE_SIZE
expr_stmt|;
block|}
name|tlb_flush_range
argument_list|(
name|sva
argument_list|,
name|va
operator|-
name|sva
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_kremove_device
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|vm_offset_t
name|sva
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|size
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: device mapping not page-sized"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|sva
operator|=
name|va
expr_stmt|;
while|while
condition|(
name|size
operator|!=
literal|0
condition|)
block|{
name|pmap_kremove
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|size
operator|-=
name|PAGE_SIZE
expr_stmt|;
block|}
name|tlb_flush_range
argument_list|(
name|sva
argument_list|,
name|va
operator|-
name|sva
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_set_pcb_pagedir
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|struct
name|pcb
modifier|*
name|pcb
parameter_list|)
block|{
name|pcb
operator|->
name|pcb_pagedir
operator|=
name|pmap_ttb_get
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Clean L1 data cache range by physical address.  *  The range must be within a single page.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_dcache_wb_pou
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|uint32_t
name|attr
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|cmap2_pte2p
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|(
name|pa
operator|&
name|PAGE_MASK
operator|)
operator|+
name|size
operator|)
operator|<=
name|PAGE_SIZE
argument_list|,
operator|(
literal|"%s: not on single page"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap2_pte2p
operator|=
name|pc
operator|->
name|pc_cmap2_pte2p
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_load
argument_list|(
name|cmap2_pte2p
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: CMAP2 busy"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|cmap2_pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|pa
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|attr
argument_list|)
argument_list|)
expr_stmt|;
name|dcache_wb_pou
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
operator|+
operator|(
name|pa
operator|&
name|PAGE_MASK
operator|)
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|cmap2_pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  Sync instruction cache range which is not mapped yet.  */
end_comment

begin_function
name|void
name|cache_icache_sync_fresh
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|uint32_t
name|len
decl_stmt|,
name|offset
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
comment|/* Write back d-cache on given address range. */
name|offset
operator|=
name|pa
operator|&
name|PAGE_MASK
expr_stmt|;
for|for
control|(
init|;
name|size
operator|!=
literal|0
condition|;
name|size
operator|-=
name|len
operator|,
name|pa
operator|+=
name|len
operator|,
name|offset
operator|=
literal|0
control|)
block|{
name|len
operator|=
name|min
argument_list|(
name|PAGE_SIZE
operator|-
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|!=
name|NULL
argument_list|,
operator|(
literal|"%s: vm_page_t is null for %#x"
operator|,
name|__func__
operator|,
name|pa
operator|)
argument_list|)
expr_stmt|;
name|pmap_dcache_wb_pou
argument_list|(
name|pa
argument_list|,
name|len
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * I-cache is VIPT. Only way how to flush all virtual mappings 	 * on given physical address is to invalidate all i-cache. 	 */
name|icache_inv_all
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_sync_icache
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
comment|/* Write back d-cache on given address range. */
if|if
condition|(
name|va
operator|>=
name|VM_MIN_KERNEL_ADDRESS
condition|)
block|{
name|dcache_wb_pou
argument_list|(
name|va
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|uint32_t
name|len
decl_stmt|,
name|offset
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|offset
operator|=
name|va
operator|&
name|PAGE_MASK
expr_stmt|;
for|for
control|(
init|;
name|size
operator|!=
literal|0
condition|;
name|size
operator|-=
name|len
operator|,
name|va
operator|+=
name|len
operator|,
name|offset
operator|=
literal|0
control|)
block|{
name|pa
operator|=
name|pmap_extract
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* offset is preserved */
name|len
operator|=
name|min
argument_list|(
name|PAGE_SIZE
operator|-
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|!=
name|NULL
argument_list|,
operator|(
literal|"%s: vm_page_t is null for %#x"
operator|,
name|__func__
operator|,
name|pa
operator|)
argument_list|)
expr_stmt|;
name|pmap_dcache_wb_pou
argument_list|(
name|pa
argument_list|,
name|len
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * I-cache is VIPT. Only way how to flush all virtual mappings 	 * on given physical address is to invalidate all i-cache. 	 */
name|icache_inv_all
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *  The implementation of pmap_fault() uses IN_RANGE2() macro which  *  depends on the fact that given range size is a power of 2.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
name|powerof2
argument_list|(
name|NB_IN_PT1
argument_list|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|powerof2
argument_list|(
name|PT2MAP_SIZE
argument_list|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_define
define|#
directive|define
name|IN_RANGE2
parameter_list|(
name|addr
parameter_list|,
name|start
parameter_list|,
name|size
parameter_list|)
define|\
value|((vm_offset_t)(start) == ((vm_offset_t)(addr)& ~((size) - 1)))
end_define

begin_comment
comment|/*  *  Handle access and R/W emulation faults.  */
end_comment

begin_function
name|int
name|pmap_fault
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|far
parameter_list|,
name|uint32_t
name|fsr
parameter_list|,
name|int
name|idx
parameter_list|,
name|bool
name|usermode
parameter_list|)
block|{
name|pt1_entry_t
modifier|*
name|pte1p
decl_stmt|,
name|pte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
if|if
condition|(
name|pmap
operator|==
name|NULL
condition|)
name|pmap
operator|=
name|kernel_pmap
expr_stmt|;
comment|/* 	 * In kernel, we should never get abort with FAR which is in range of 	 * pmap->pm_pt1 or PT2MAP address spaces. If it happens, stop here 	 * and print out a useful abort message and even get to the debugger 	 * otherwise it likely ends with never ending loop of aborts. 	 */
if|if
condition|(
name|__predict_false
argument_list|(
name|IN_RANGE2
argument_list|(
name|far
argument_list|,
name|pmap
operator|->
name|pm_pt1
argument_list|,
name|NB_IN_PT1
argument_list|)
argument_list|)
condition|)
block|{
comment|/* 		 * All L1 tables should always be mapped and present. 		 * However, we check only current one herein. For user mode, 		 * only permission abort from malicious user is not fatal. 		 * And alignment abort as it may have higher priority. 		 */
if|if
condition|(
operator|!
name|usermode
operator|||
operator|(
name|idx
operator|!=
name|FAULT_ALIGN
operator|&&
name|idx
operator|!=
name|FAULT_PERM_L2
operator|)
condition|)
block|{
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: pmap %#x pm_pt1 %#x far %#x"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|pmap
operator|->
name|pm_pt1
argument_list|,
name|far
argument_list|)
expr_stmt|;
name|panic
argument_list|(
literal|"%s: pm_pt1 abort"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|KERN_INVALID_ADDRESS
operator|)
return|;
block|}
if|if
condition|(
name|__predict_false
argument_list|(
name|IN_RANGE2
argument_list|(
name|far
argument_list|,
name|PT2MAP
argument_list|,
name|PT2MAP_SIZE
argument_list|)
argument_list|)
condition|)
block|{
comment|/* 		 * PT2MAP should be always mapped and present in current 		 * L1 table. However, only existing L2 tables are mapped 		 * in PT2MAP. For user mode, only L2 translation abort and 		 * permission abort from malicious user is not fatal. 		 * And alignment abort as it may have higher priority. 		 */
if|if
condition|(
operator|!
name|usermode
operator|||
operator|(
name|idx
operator|!=
name|FAULT_ALIGN
operator|&&
name|idx
operator|!=
name|FAULT_TRAN_L2
operator|&&
name|idx
operator|!=
name|FAULT_PERM_L2
operator|)
condition|)
block|{
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: pmap %#x PT2MAP %#x far %#x"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|PT2MAP
argument_list|,
name|far
argument_list|)
expr_stmt|;
name|panic
argument_list|(
literal|"%s: PT2MAP abort"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|KERN_INVALID_ADDRESS
operator|)
return|;
block|}
comment|/* 	 * A pmap lock is used below for handling of access and R/W emulation 	 * aborts. They were handled by atomic operations before so some 	 * analysis of new situation is needed to answer the following question: 	 * Is it safe to use the lock even for these aborts? 	 * 	 * There may happen two cases in general: 	 * 	 * (1) Aborts while the pmap lock is locked already - this should not 	 * happen as pmap lock is not recursive. However, under pmap lock only 	 * internal kernel data should be accessed and such data should be 	 * mapped with A bit set and NM bit cleared. If double abort happens, 	 * then a mapping of data which has caused it must be fixed. Further, 	 * all new mappings are always made with A bit set and the bit can be 	 * cleared only on managed mappings. 	 * 	 * (2) Aborts while another lock(s) is/are locked - this already can 	 * happen. However, there is no difference here if it's either access or 	 * R/W emulation abort, or if it's some other abort. 	 */
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
comment|/* 	 * Special treatment is due to break-before-make approach done when 	 * pte1 is updated for userland mapping during section promotion or 	 * demotion. If not caught here, pmap_enter() can find a section 	 * mapping on faulting address. That is not allowed. 	 */
if|if
condition|(
name|idx
operator|==
name|FAULT_TRAN_L1
operator|&&
name|usermode
operator|&&
name|cp15_ats1cur_check
argument_list|(
name|far
argument_list|)
operator|==
literal|0
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_SUCCESS
operator|)
return|;
block|}
endif|#
directive|endif
comment|/* 	 * Accesss bits for page and section. Note that the entry 	 * is not in TLB yet, so TLB flush is not necessary. 	 * 	 * QQQ: This is hardware emulation, we do not call userret() 	 *      for aborts from user mode. 	 */
if|if
condition|(
name|idx
operator|==
name|FAULT_ACCESS_L2
condition|)
block|{
name|pte2p
operator|=
name|pt2map_entry
argument_list|(
name|far
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
block|{
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|pte2
operator||
name|PTE2_A
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_SUCCESS
operator|)
return|;
block|}
block|}
if|if
condition|(
name|idx
operator|==
name|FAULT_ACCESS_L1
condition|)
block|{
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|far
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|pte1
operator||
name|PTE1_A
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_SUCCESS
operator|)
return|;
block|}
block|}
comment|/* 	 * Handle modify bits for page and section. Note that the modify 	 * bit is emulated by software. So PTEx_RO is software read only 	 * bit and PTEx_NM flag is real hardware read only bit. 	 * 	 * QQQ: This is hardware emulation, we do not call userret() 	 *      for aborts from user mode. 	 */
if|if
condition|(
operator|(
name|fsr
operator|&
name|FSR_WNR
operator|)
operator|&&
operator|(
name|idx
operator|==
name|FAULT_PERM_L2
operator|)
condition|)
block|{
name|pte2p
operator|=
name|pt2map_entry
argument_list|(
name|far
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
operator|&&
operator|!
operator|(
name|pte2
operator|&
name|PTE2_RO
operator|)
operator|&&
operator|(
name|pte2
operator|&
name|PTE2_NM
operator|)
condition|)
block|{
name|pte2_store
argument_list|(
name|pte2p
argument_list|,
name|pte2
operator|&
operator|~
name|PTE2_NM
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
name|trunc_page
argument_list|(
name|far
argument_list|)
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_SUCCESS
operator|)
return|;
block|}
block|}
if|if
condition|(
operator|(
name|fsr
operator|&
name|FSR_WNR
operator|)
operator|&&
operator|(
name|idx
operator|==
name|FAULT_PERM_L1
operator|)
condition|)
block|{
name|pte1p
operator|=
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|far
argument_list|)
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pte1p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
operator|&&
operator|!
operator|(
name|pte1
operator|&
name|PTE1_RO
operator|)
operator|&&
operator|(
name|pte1
operator|&
name|PTE1_NM
operator|)
condition|)
block|{
name|pte1_store
argument_list|(
name|pte1p
argument_list|,
name|pte1
operator|&
operator|~
name|PTE1_NM
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
name|pte1_trunc
argument_list|(
name|far
argument_list|)
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_SUCCESS
operator|)
return|;
block|}
block|}
comment|/* 	 * QQQ: The previous code, mainly fast handling of access and 	 *      modify bits aborts, could be moved to ASM. Now we are 	 *      starting to deal with not fast aborts. 	 */
ifdef|#
directive|ifdef
name|INVARIANTS
comment|/* 	 * Read an entry in PT2TAB associated with both pmap and far. 	 * It's safe because PT2TAB is always mapped. 	 */
name|pte2
operator|=
name|pt2tab_load
argument_list|(
name|pmap_pt2tab_entry
argument_list|(
name|pmap
argument_list|,
name|far
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
block|{
comment|/* 		 * Now, when we know that L2 page table is allocated, 		 * we can use PT2MAP to get L2 page table entry. 		 */
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pt2map_entry
argument_list|(
name|far
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
block|{
comment|/* 			 * If L2 page table entry is valid, make sure that 			 * L1 page table entry is valid too.  Note that we 			 * leave L2 page entries untouched when promoted. 			 */
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|far
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte1_is_valid
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|panic
argument_list|(
literal|"%s: missing L1 page entry (%p, %#x)"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|far
argument_list|)
expr_stmt|;
block|}
block|}
block|}
endif|#
directive|endif
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_FAILURE
operator|)
return|;
block|}
end_function

begin_if
if|#
directive|if
name|defined
argument_list|(
name|PMAP_DEBUG
argument_list|)
end_if

begin_comment
comment|/*  *  Reusing of KVA used in pmap_zero_page function !!!  */
end_comment

begin_function
specifier|static
name|void
name|pmap_zero_page_check
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|pt2_entry_t
modifier|*
name|cmap2_pte2p
decl_stmt|;
name|uint32_t
modifier|*
name|p
decl_stmt|,
modifier|*
name|end
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap2_pte2p
operator|=
name|pc
operator|->
name|pc_cmap2_pte2p
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_load
argument_list|(
name|cmap2_pte2p
argument_list|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: CMAP2 busy"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pte2_store
argument_list|(
name|cmap2_pte2p
argument_list|,
name|PTE2_KERN_NG
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|PTE2_AP_KRW
argument_list|,
name|vm_page_pte2_attr
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|end
operator|=
operator|(
name|uint32_t
operator|*
operator|)
operator|(
name|pc
operator|->
name|pc_cmap2_addr
operator|+
name|PAGE_SIZE
operator|)
expr_stmt|;
for|for
control|(
name|p
operator|=
operator|(
name|uint32_t
operator|*
operator|)
name|pc
operator|->
name|pc_cmap2_addr
init|;
name|p
operator|<
name|end
condition|;
name|p
operator|++
control|)
if|if
condition|(
operator|*
name|p
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: page %p not zero, va: %p"
argument_list|,
name|__func__
argument_list|,
name|m
argument_list|,
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|pte2_clear
argument_list|(
name|cmap2_pte2p
argument_list|)
expr_stmt|;
name|tlb_flush
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap2_addr
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|pmap_pid_dump
parameter_list|(
name|int
name|pid
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
name|int
name|npte2
init|=
literal|0
decl_stmt|;
name|int
name|i
decl_stmt|,
name|j
decl_stmt|,
name|index
decl_stmt|;
name|sx_slock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
name|FOREACH_PROC_IN_SYSTEM
argument_list|(
argument|p
argument_list|)
block|{
if|if
condition|(
name|p
operator|->
name|p_pid
operator|!=
name|pid
operator|||
name|p
operator|->
name|p_vmspace
operator|==
name|NULL
condition|)
continue|continue;
name|index
operator|=
literal|0
expr_stmt|;
name|pmap
operator|=
name|vmspace_pmap
argument_list|(
name|p
operator|->
name|p_vmspace
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPTE1_IN_PT1
condition|;
name|i
operator|++
control|)
block|{
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|vm_offset_t
name|base
decl_stmt|,
name|va
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|base
operator|=
name|i
operator|<<
name|PTE1_SHIFT
expr_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pt1
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
comment|/* 				 * QQQ: Do something here! 				 */
block|}
elseif|else
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
for|for
control|(
name|j
operator|=
literal|0
init|;
name|j
operator|<
name|NPTE2_IN_PT2
condition|;
name|j
operator|++
control|)
block|{
name|va
operator|=
name|base
operator|+
operator|(
name|j
operator|<<
name|PAGE_SHIFT
operator|)
expr_stmt|;
if|if
condition|(
name|va
operator|>=
name|VM_MIN_KERNEL_ADDRESS
condition|)
block|{
if|if
condition|(
name|index
condition|)
block|{
name|index
operator|=
literal|0
expr_stmt|;
name|printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|npte2
operator|)
return|;
block|}
name|pte2p
operator|=
name|pmap_pte2
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
name|pmap_pte2_release
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
continue|continue;
name|pa
operator|=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"va: 0x%x, pa: 0x%x, h: %d, w:"
literal|" %d, f: 0x%x"
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|m
operator|->
name|hold_count
argument_list|,
name|m
operator|->
name|wire_count
argument_list|,
name|m
operator|->
name|flags
argument_list|)
expr_stmt|;
name|npte2
operator|++
expr_stmt|;
name|index
operator|++
expr_stmt|;
if|if
condition|(
name|index
operator|>=
literal|2
condition|)
block|{
name|index
operator|=
literal|0
expr_stmt|;
name|printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|printf
argument_list|(
literal|" "
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|npte2
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_function
specifier|static
name|pt2_entry_t
modifier|*
name|pmap_pte2_ddb
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt1_entry_t
name|pte1
decl_stmt|;
name|vm_paddr_t
name|pt2pg_pa
decl_stmt|;
name|pte1
operator|=
name|pte1_load
argument_list|(
name|pmap_pte1
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
return|return
operator|(
name|pt2map_entry
argument_list|(
name|va
argument_list|)
operator|)
return|;
comment|/* Note that L2 page table size is not equal to PAGE_SIZE. */
name|pt2pg_pa
operator|=
name|trunc_page
argument_list|(
name|pte1_link_pa
argument_list|(
name|pte1
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2_pa
argument_list|(
name|pte2_load
argument_list|(
name|PMAP3
argument_list|)
argument_list|)
operator|!=
name|pt2pg_pa
condition|)
block|{
name|pte2_store
argument_list|(
name|PMAP3
argument_list|,
name|PTE2_KPT
argument_list|(
name|pt2pg_pa
argument_list|)
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|PMAP3cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|tlb_flush_local
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PADDR3
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|SMP
elseif|else
if|if
condition|(
name|PMAP3cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
block|{
name|PMAP3cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|tlb_flush_local
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PADDR3
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
return|return
operator|(
name|PADDR3
operator|+
operator|(
name|arm32_btop
argument_list|(
name|va
argument_list|)
operator|&
operator|(
name|NPTE2_IN_PG
operator|-
literal|1
operator|)
operator|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|dump_pmap
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|printf
argument_list|(
literal|"pmap %p\n"
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"  pm_pt1: %p\n"
argument_list|,
name|pmap
operator|->
name|pm_pt1
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"  pm_pt2tab: %p\n"
argument_list|,
name|pmap
operator|->
name|pm_pt2tab
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"  pm_active: 0x%08lX\n"
argument_list|,
name|pmap
operator|->
name|pm_active
operator|.
name|__bits
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
block|}
end_function

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|pmaps
argument_list|,
argument|pmap_list_pmaps
argument_list|)
end_macro

begin_block
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pmap
argument_list|,
argument|&allpmaps
argument_list|,
argument|pm_list
argument_list|)
block|{
name|dump_pmap
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
block|}
end_block

begin_function
specifier|static
name|int
name|pte2_class
parameter_list|(
name|pt2_entry_t
name|pte2
parameter_list|)
block|{
name|int
name|cls
decl_stmt|;
name|cls
operator|=
operator|(
name|pte2
operator|>>
literal|2
operator|)
operator|&
literal|0x03
expr_stmt|;
name|cls
operator||=
operator|(
name|pte2
operator|>>
literal|4
operator|)
operator|&
literal|0x04
expr_stmt|;
return|return
operator|(
name|cls
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|dump_section
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|uint32_t
name|pte1_idx
parameter_list|)
block|{ }
end_function

begin_function
specifier|static
name|void
name|dump_link
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|uint32_t
name|pte1_idx
parameter_list|,
name|boolean_t
name|invalid_ok
parameter_list|)
block|{
name|uint32_t
name|i
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|pt2_entry_t
modifier|*
name|pte2p
decl_stmt|,
name|pte2
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|va
operator|=
name|pte1_idx
operator|<<
name|PTE1_SHIFT
expr_stmt|;
name|pte2p
operator|=
name|pmap_pte2_ddb
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPTE2_IN_PT2
condition|;
name|i
operator|++
operator|,
name|pte2p
operator|++
operator|,
name|va
operator|+=
name|PAGE_SIZE
control|)
block|{
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pte2p
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
block|{
name|printf
argument_list|(
literal|" 0x%08X: 0x%08X"
argument_list|,
name|va
argument_list|,
name|pte2
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|invalid_ok
condition|)
name|printf
argument_list|(
literal|" - not valid !!!"
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|" 0x%08X: 0x%08X, TEX%d, s:%d, g:%d, m:%p"
argument_list|,
name|va
argument_list|,
name|pte2
argument_list|,
name|pte2_class
argument_list|(
name|pte2
argument_list|)
argument_list|,
operator|!
operator|!
operator|(
name|pte2
operator|&
name|PTE2_S
operator|)
argument_list|,
operator|!
operator|(
name|pte2
operator|&
name|PTE2_NG
operator|)
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|!=
name|NULL
condition|)
block|{
name|printf
argument_list|(
literal|" v:%d h:%d w:%d f:0x%04X\n"
argument_list|,
name|m
operator|->
name|valid
argument_list|,
name|m
operator|->
name|hold_count
argument_list|,
name|m
operator|->
name|wire_count
argument_list|,
name|m
operator|->
name|flags
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
specifier|static
name|__inline
name|boolean_t
name|is_pv_chunk_space
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
if|if
condition|(
operator|(
operator|(
operator|(
name|vm_offset_t
operator|)
name|pv_chunkbase
operator|)
operator|<=
name|va
operator|)
operator|&&
operator|(
name|va
operator|<
operator|(
operator|(
name|vm_offset_t
operator|)
name|pv_chunkbase
operator|+
name|PAGE_SIZE
operator|*
name|pv_maxchunks
operator|)
operator|)
condition|)
return|return
operator|(
name|TRUE
operator|)
return|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|pmap
argument_list|,
argument|pmap_pmap_print
argument_list|)
end_macro

begin_block
block|{
comment|/* XXX convert args. */
name|pmap_t
name|pmap
init|=
operator|(
name|pmap_t
operator|)
name|addr
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|eva
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|uint32_t
name|i
decl_stmt|;
name|boolean_t
name|invalid_ok
decl_stmt|,
name|dump_link_ok
decl_stmt|,
name|dump_pv_chunk
decl_stmt|;
if|if
condition|(
name|have_addr
condition|)
block|{
name|pmap_t
name|pm
decl_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pm
argument_list|,
argument|&allpmaps
argument_list|,
argument|pm_list
argument_list|)
if|if
condition|(
name|pm
operator|==
name|pmap
condition|)
break|break;
if|if
condition|(
name|pm
operator|==
name|NULL
condition|)
block|{
name|printf
argument_list|(
literal|"given pmap %p is not in allpmaps list\n"
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
else|else
name|pmap
operator|=
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
expr_stmt|;
name|eva
operator|=
operator|(
name|modif
index|[
literal|0
index|]
operator|==
literal|'u'
operator|)
condition|?
name|VM_MAXUSER_ADDRESS
else|:
literal|0xFFFFFFFF
expr_stmt|;
name|dump_pv_chunk
operator|=
name|FALSE
expr_stmt|;
comment|/* XXX evaluate from modif[] */
name|printf
argument_list|(
literal|"pmap: 0x%08X\n"
argument_list|,
operator|(
name|uint32_t
operator|)
name|pmap
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"PT2MAP: 0x%08X\n"
argument_list|,
operator|(
name|uint32_t
operator|)
name|PT2MAP
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"pt2tab: 0x%08X\n"
argument_list|,
operator|(
name|uint32_t
operator|)
name|pmap
operator|->
name|pm_pt2tab
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPTE1_IN_PT1
condition|;
name|i
operator|++
control|)
block|{
name|pte1
operator|=
name|pte1_load
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pt1
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1
operator|==
literal|0
condition|)
continue|continue;
name|va
operator|=
name|i
operator|<<
name|PTE1_SHIFT
expr_stmt|;
if|if
condition|(
name|va
operator|>=
name|eva
condition|)
break|break;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|printf
argument_list|(
literal|"0x%08X: Section 0x%08X, s:%d g:%d\n"
argument_list|,
name|va
argument_list|,
name|pte1
argument_list|,
operator|!
operator|!
operator|(
name|pte1
operator|&
name|PTE1_S
operator|)
argument_list|,
operator|!
operator|(
name|pte1
operator|&
name|PTE1_NG
operator|)
argument_list|)
expr_stmt|;
name|dump_section
argument_list|(
name|pmap
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|dump_link_ok
operator|=
name|TRUE
expr_stmt|;
name|invalid_ok
operator|=
name|FALSE
expr_stmt|;
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pmap_pt2tab_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte1_link_pa
argument_list|(
name|pte1
argument_list|)
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"0x%08X: Link 0x%08X, pt2tab: 0x%08X m: %p"
argument_list|,
name|va
argument_list|,
name|pte1
argument_list|,
name|pte2
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|is_pv_chunk_space
argument_list|(
name|va
argument_list|)
condition|)
block|{
name|printf
argument_list|(
literal|" - pv_chunk space"
argument_list|)
expr_stmt|;
if|if
condition|(
name|dump_pv_chunk
condition|)
name|invalid_ok
operator|=
name|TRUE
expr_stmt|;
else|else
name|dump_link_ok
operator|=
name|FALSE
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|m
operator|!=
name|NULL
condition|)
name|printf
argument_list|(
literal|" w:%d w2:%u"
argument_list|,
name|m
operator|->
name|wire_count
argument_list|,
name|pt2_wirecount_get
argument_list|(
name|m
argument_list|,
name|pte1_index
argument_list|(
name|va
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2
operator|==
literal|0
condition|)
name|printf
argument_list|(
literal|" !!! pt2tab entry is ZERO"
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|pte2_pa
argument_list|(
name|pte1
argument_list|)
operator|!=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
condition|)
name|printf
argument_list|(
literal|" !!! pt2tab entry is DIFFERENT - m: %p"
argument_list|,
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
if|if
condition|(
name|dump_link_ok
condition|)
name|dump_link
argument_list|(
name|pmap
argument_list|,
name|i
argument_list|,
name|invalid_ok
argument_list|)
expr_stmt|;
block|}
else|else
name|printf
argument_list|(
literal|"0x%08X: Invalid entry 0x%08X\n"
argument_list|,
name|va
argument_list|,
name|pte1
argument_list|)
expr_stmt|;
block|}
block|}
end_block

begin_function
specifier|static
name|void
name|dump_pt2tab
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|uint32_t
name|i
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|printf
argument_list|(
literal|"PT2TAB:\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PT2TAB_ENTRIES
condition|;
name|i
operator|++
control|)
block|{
name|pte2
operator|=
name|pte2_load
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pt2tab
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pte2_is_valid
argument_list|(
name|pte2
argument_list|)
condition|)
continue|continue;
name|va
operator|=
name|i
operator|<<
name|PT2TAB_SHIFT
expr_stmt|;
name|pa
operator|=
name|pte2_pa
argument_list|(
name|pte2
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|" 0x%08X: 0x%08X, TEX%d, s:%d, m:%p"
argument_list|,
name|va
argument_list|,
name|pte2
argument_list|,
name|pte2_class
argument_list|(
name|pte2
argument_list|)
argument_list|,
operator|!
operator|!
operator|(
name|pte2
operator|&
name|PTE2_S
operator|)
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|!=
name|NULL
condition|)
name|printf
argument_list|(
literal|" , h: %d, w: %d, f: 0x%04X pidx: %lld"
argument_list|,
name|m
operator|->
name|hold_count
argument_list|,
name|m
operator|->
name|wire_count
argument_list|,
name|m
operator|->
name|flags
argument_list|,
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|pmap_pt2tab
argument_list|,
argument|pmap_pt2tab_print
argument_list|)
end_macro

begin_block
block|{
comment|/* XXX convert args. */
name|pmap_t
name|pmap
init|=
operator|(
name|pmap_t
operator|)
name|addr
decl_stmt|;
name|pt1_entry_t
name|pte1
decl_stmt|;
name|pt2_entry_t
name|pte2
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|uint32_t
name|i
decl_stmt|,
name|start
decl_stmt|;
if|if
condition|(
name|have_addr
condition|)
block|{
name|printf
argument_list|(
literal|"supported only on current pmap\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|pmap
operator|=
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"curpmap: 0x%08X\n"
argument_list|,
operator|(
name|uint32_t
operator|)
name|pmap
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"PT2MAP: 0x%08X\n"
argument_list|,
operator|(
name|uint32_t
operator|)
name|PT2MAP
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"pt2tab: 0x%08X\n"
argument_list|,
operator|(
name|uint32_t
operator|)
name|pmap
operator|->
name|pm_pt2tab
argument_list|)
expr_stmt|;
name|start
operator|=
name|pte1_index
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|PT2MAP
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|start
init|;
name|i
operator|<
operator|(
name|start
operator|+
name|NPT2_IN_PT2TAB
operator|)
condition|;
name|i
operator|++
control|)
block|{
name|pte1
operator|=
name|pte1_load
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pt1
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte1
operator|==
literal|0
condition|)
continue|continue;
name|va
operator|=
name|i
operator|<<
name|PTE1_SHIFT
expr_stmt|;
if|if
condition|(
name|pte1_is_section
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|printf
argument_list|(
literal|"0x%08X: Section 0x%08X, s:%d\n"
argument_list|,
name|va
argument_list|,
name|pte1
argument_list|,
operator|!
operator|!
operator|(
name|pte1
operator|&
name|PTE1_S
operator|)
argument_list|)
expr_stmt|;
name|dump_section
argument_list|(
name|pmap
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pte1_is_link
argument_list|(
name|pte1
argument_list|)
condition|)
block|{
name|pte2
operator|=
name|pte2_load
argument_list|(
name|pmap_pt2tab_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"0x%08X: Link 0x%08X, pt2tab: 0x%08X\n"
argument_list|,
name|va
argument_list|,
name|pte1
argument_list|,
name|pte2
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte2
operator|==
literal|0
condition|)
name|printf
argument_list|(
literal|"  !!! pt2tab entry is ZERO\n"
argument_list|)
expr_stmt|;
block|}
else|else
name|printf
argument_list|(
literal|"0x%08X: Invalid entry 0x%08X\n"
argument_list|,
name|va
argument_list|,
name|pte1
argument_list|)
expr_stmt|;
block|}
name|dump_pt2tab
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

end_unit

