begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1991 Regents of the University of California.  * All rights reserved.  * Copyright (c) 1994 John S. Dyson  * All rights reserved.  * Copyright (c) 1994 David Greenman  * All rights reserved.  * Copyright (c) 2003 Peter Wemm  * All rights reserved.  * Copyright (c) 2005-2010 Alan L. Cox<alc@cs.rice.edu>  * All rights reserved.  *  * This code is derived from software contributed to Berkeley by  * the Systems Programming Group of the University of Utah Computer  * Science Department and William Jolitz of UUNET Technologies Inc.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. All advertising materials mentioning features or use of this software  *    must display the following acknowledgement:  *	This product includes software developed by the University of  *	California, Berkeley and its contributors.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from:	@(#)pmap.c	7.7 (Berkeley)	5/12/91  */
end_comment

begin_comment
comment|/*-  * Copyright (c) 2003 Networks Associates Technology, Inc.  * All rights reserved.  *  * This software was developed for the FreeBSD Project by Jake Burkholder,  * Safeport Network Services, and Network Associates Laboratories, the  * Security Research Division of Network Associates, Inc. under  * DARPA/SPAWAR contract N66001-01-C-8035 ("CBOSS"), as part of the DARPA  * CHATS research program.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  */
end_comment

begin_define
define|#
directive|define
name|AMD64_NPT_AWARE
end_define

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *	Manages physical address maps.  *  *	Since the information managed by this module is  *	also stored by the logical address mapping module,  *	this module may throw away valid virtual-to-physical  *	mappings at almost any time.  However, invalidations  *	of virtual-to-physical mappings must be done as  *	requested.  *  *	In order to cope with hardware architectures which  *	make virtual-to-physical map invalidates expensive,  *	this module may delay invalidate or reduced protection  *	operations until such time as they are actually  *	necessary.  This module is given full information as  *	to which processors are currently using which maps,  *	and to when physical maps must be made correct.  */
end_comment

begin_include
include|#
directive|include
file|"opt_pmap.h"
end_include

begin_include
include|#
directive|include
file|"opt_vm.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/bitstring.h>
end_include

begin_include
include|#
directive|include
file|<sys/bus.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mman.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/turnstile.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmem.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_phys.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_radix.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_reserv.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<machine/intr_machdep.h>
end_include

begin_include
include|#
directive|include
file|<x86/apicvar.h>
end_include

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/cputypes.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_include
include|#
directive|include
file|<machine/pcb.h>
end_include

begin_include
include|#
directive|include
file|<machine/specialreg.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|__inline
name|boolean_t
name|pmap_type_guest
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
return|return
operator|(
operator|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_EPT
operator|)
operator|||
operator|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_RVI
operator|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|boolean_t
name|pmap_emulate_ad_bits
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
return|return
operator|(
operator|(
name|pmap
operator|->
name|pm_flags
operator|&
name|PMAP_EMULATE_AD_BITS
operator|)
operator|!=
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pt_entry_t
name|pmap_valid_bit
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|pt_entry_t
name|mask
decl_stmt|;
switch|switch
condition|(
name|pmap
operator|->
name|pm_type
condition|)
block|{
case|case
name|PT_X86
case|:
case|case
name|PT_RVI
case|:
name|mask
operator|=
name|X86_PG_V
expr_stmt|;
break|break;
case|case
name|PT_EPT
case|:
if|if
condition|(
name|pmap_emulate_ad_bits
argument_list|(
name|pmap
argument_list|)
condition|)
name|mask
operator|=
name|EPT_PG_EMUL_V
expr_stmt|;
else|else
name|mask
operator|=
name|EPT_PG_READ
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"pmap_valid_bit: invalid pm_type %d"
argument_list|,
name|pmap
operator|->
name|pm_type
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|mask
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pt_entry_t
name|pmap_rw_bit
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|pt_entry_t
name|mask
decl_stmt|;
switch|switch
condition|(
name|pmap
operator|->
name|pm_type
condition|)
block|{
case|case
name|PT_X86
case|:
case|case
name|PT_RVI
case|:
name|mask
operator|=
name|X86_PG_RW
expr_stmt|;
break|break;
case|case
name|PT_EPT
case|:
if|if
condition|(
name|pmap_emulate_ad_bits
argument_list|(
name|pmap
argument_list|)
condition|)
name|mask
operator|=
name|EPT_PG_EMUL_RW
expr_stmt|;
else|else
name|mask
operator|=
name|EPT_PG_WRITE
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"pmap_rw_bit: invalid pm_type %d"
argument_list|,
name|pmap
operator|->
name|pm_type
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|mask
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pt_entry_t
name|pmap_global_bit
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|pt_entry_t
name|mask
decl_stmt|;
switch|switch
condition|(
name|pmap
operator|->
name|pm_type
condition|)
block|{
case|case
name|PT_X86
case|:
name|mask
operator|=
name|X86_PG_G
expr_stmt|;
break|break;
case|case
name|PT_RVI
case|:
case|case
name|PT_EPT
case|:
name|mask
operator|=
literal|0
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"pmap_global_bit: invalid pm_type %d"
argument_list|,
name|pmap
operator|->
name|pm_type
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|mask
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pt_entry_t
name|pmap_accessed_bit
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|pt_entry_t
name|mask
decl_stmt|;
switch|switch
condition|(
name|pmap
operator|->
name|pm_type
condition|)
block|{
case|case
name|PT_X86
case|:
case|case
name|PT_RVI
case|:
name|mask
operator|=
name|X86_PG_A
expr_stmt|;
break|break;
case|case
name|PT_EPT
case|:
if|if
condition|(
name|pmap_emulate_ad_bits
argument_list|(
name|pmap
argument_list|)
condition|)
name|mask
operator|=
name|EPT_PG_READ
expr_stmt|;
else|else
name|mask
operator|=
name|EPT_PG_A
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"pmap_accessed_bit: invalid pm_type %d"
argument_list|,
name|pmap
operator|->
name|pm_type
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|mask
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pt_entry_t
name|pmap_modified_bit
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|pt_entry_t
name|mask
decl_stmt|;
switch|switch
condition|(
name|pmap
operator|->
name|pm_type
condition|)
block|{
case|case
name|PT_X86
case|:
case|case
name|PT_RVI
case|:
name|mask
operator|=
name|X86_PG_M
expr_stmt|;
break|break;
case|case
name|PT_EPT
case|:
if|if
condition|(
name|pmap_emulate_ad_bits
argument_list|(
name|pmap
argument_list|)
condition|)
name|mask
operator|=
name|EPT_PG_WRITE
expr_stmt|;
else|else
name|mask
operator|=
name|EPT_PG_M
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"pmap_modified_bit: invalid pm_type %d"
argument_list|,
name|pmap
operator|->
name|pm_type
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|mask
operator|)
return|;
block|}
end_function

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|DIAGNOSTIC
argument_list|)
end_if

begin_ifdef
ifdef|#
directive|ifdef
name|__GNUC_GNU_INLINE__
end_ifdef

begin_define
define|#
directive|define
name|PMAP_INLINE
value|__attribute__((__gnu_inline__)) inline
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PMAP_INLINE
value|extern inline
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PMAP_INLINE
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|PV_STATS
end_ifdef

begin_define
define|#
directive|define
name|PV_STAT
parameter_list|(
name|x
parameter_list|)
value|do { x ; } while (0)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PV_STAT
parameter_list|(
name|x
parameter_list|)
value|do { } while (0)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|pa_index
parameter_list|(
name|pa
parameter_list|)
value|((pa)>> PDRSHIFT)
end_define

begin_define
define|#
directive|define
name|pa_to_pvh
parameter_list|(
name|pa
parameter_list|)
value|(&pv_table[pa_index(pa)])
end_define

begin_define
define|#
directive|define
name|NPV_LIST_LOCKS
value|MAXCPU
end_define

begin_define
define|#
directive|define
name|PHYS_TO_PV_LIST_LOCK
parameter_list|(
name|pa
parameter_list|)
define|\
value|(&pv_list_locks[pa_index(pa) % NPV_LIST_LOCKS])
end_define

begin_define
define|#
directive|define
name|CHANGE_PV_LIST_LOCK_TO_PHYS
parameter_list|(
name|lockp
parameter_list|,
name|pa
parameter_list|)
value|do {	\ 	struct rwlock **_lockp = (lockp);		\ 	struct rwlock *_new_lock;			\ 							\ 	_new_lock = PHYS_TO_PV_LIST_LOCK(pa);		\ 	if (_new_lock != *_lockp) {			\ 		if (*_lockp != NULL)			\ 			rw_wunlock(*_lockp);		\ 		*_lockp = _new_lock;			\ 		rw_wlock(*_lockp);			\ 	}						\ } while (0)
end_define

begin_define
define|#
directive|define
name|CHANGE_PV_LIST_LOCK_TO_VM_PAGE
parameter_list|(
name|lockp
parameter_list|,
name|m
parameter_list|)
define|\
value|CHANGE_PV_LIST_LOCK_TO_PHYS(lockp, VM_PAGE_TO_PHYS(m))
end_define

begin_define
define|#
directive|define
name|RELEASE_PV_LIST_LOCK
parameter_list|(
name|lockp
parameter_list|)
value|do {	\ 	struct rwlock **_lockp = (lockp);		\ 							\ 	if (*_lockp != NULL) {				\ 		rw_wunlock(*_lockp);			\ 		*_lockp = NULL;				\ 	}						\ } while (0)
end_define

begin_define
define|#
directive|define
name|VM_PAGE_TO_PV_LIST_LOCK
parameter_list|(
name|m
parameter_list|)
define|\
value|PHYS_TO_PV_LIST_LOCK(VM_PAGE_TO_PHYS(m))
end_define

begin_decl_stmt
name|struct
name|pmap
name|kernel_pmap_store
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|virtual_avail
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* VA of first avail page (after kernel bss) */
end_comment

begin_decl_stmt
name|vm_offset_t
name|virtual_end
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* VA of last avail page (end of kernel AS) */
end_comment

begin_decl_stmt
name|int
name|nkpt
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|nkpt
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|nkpt
argument_list|,
literal|0
argument_list|,
literal|"Number of kernel page table pages allocated on bootup"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|ndmpdp
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_paddr_t
name|dmaplimit
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|kernel_vm_end
init|=
name|VM_MIN_KERNEL_ADDRESS
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|pt_entry_t
name|pg_nx
decl_stmt|;
end_decl_stmt

begin_expr_stmt
specifier|static
name|SYSCTL_NODE
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|pmap
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|"VM/pmap parameters"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pat_works
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pat_works
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pat_works
argument_list|,
literal|1
argument_list|,
literal|"Is page attribute table fully functional?"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pg_ps_enabled
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pg_ps_enabled
argument_list|,
name|CTLFLAG_RDTUN
operator||
name|CTLFLAG_NOFETCH
argument_list|,
operator|&
name|pg_ps_enabled
argument_list|,
literal|0
argument_list|,
literal|"Are large page mappings enabled?"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_define
define|#
directive|define
name|PAT_INDEX_SIZE
value|8
end_define

begin_decl_stmt
specifier|static
name|int
name|pat_index
index|[
name|PAT_INDEX_SIZE
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* cache mode to PAT index conversion */
end_comment

begin_decl_stmt
specifier|static
name|u_int64_t
name|KPTphys
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* phys addr of kernel level 1 */
end_comment

begin_decl_stmt
specifier|static
name|u_int64_t
name|KPDphys
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* phys addr of kernel level 2 */
end_comment

begin_decl_stmt
name|u_int64_t
name|KPDPphys
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* phys addr of kernel level 3 */
end_comment

begin_decl_stmt
name|u_int64_t
name|KPML4phys
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* phys addr of kernel level 4 */
end_comment

begin_decl_stmt
specifier|static
name|u_int64_t
name|DMPDphys
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* phys addr of direct mapped level 2 */
end_comment

begin_decl_stmt
specifier|static
name|u_int64_t
name|DMPDPphys
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* phys addr of direct mapped level 3 */
end_comment

begin_decl_stmt
specifier|static
name|int
name|ndmpdpphys
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* number of DMPDPphys pages */
end_comment

begin_comment
comment|/*  * pmap_mapdev support pre initialization (i.e. console)  */
end_comment

begin_define
define|#
directive|define
name|PMAP_PREINIT_MAPPING_COUNT
value|8
end_define

begin_struct
specifier|static
struct|struct
name|pmap_preinit_mapping
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_size_t
name|sz
decl_stmt|;
name|int
name|mode
decl_stmt|;
block|}
name|pmap_preinit_mapping
index|[
name|PMAP_PREINIT_MAPPING_COUNT
index|]
struct|;
end_struct

begin_decl_stmt
specifier|static
name|int
name|pmap_initialized
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Data for the pv entry allocation mechanism.  * Updates to pv_invl_gen are protected by the pv_list_locks[]  * elements, but reads are not.  */
end_comment

begin_expr_stmt
specifier|static
name|TAILQ_HEAD
argument_list|(
argument|pch
argument_list|,
argument|pv_chunk
argument_list|)
name|pv_chunks
operator|=
name|TAILQ_HEAD_INITIALIZER
argument_list|(
name|pv_chunks
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|pv_chunks_mutex
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|rwlock
name|pv_list_locks
index|[
name|NPV_LIST_LOCKS
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pv_invl_gen
index|[
name|NPV_LIST_LOCKS
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|md_page
modifier|*
name|pv_table
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|md_page
name|pv_dummy
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * All those kernel PT submaps that BSD is so fond of  */
end_comment

begin_decl_stmt
name|pt_entry_t
modifier|*
name|CMAP1
init|=
name|NULL
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|caddr_t
name|CADDR1
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|vm_offset_t
name|qframe
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|qframe_mtx
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|pmap_flags
init|=
name|PMAP_PDE_SUPERPAGE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* flags for x86 pmaps */
end_comment

begin_decl_stmt
name|int
name|pmap_pcid_enabled
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pcid_enabled
argument_list|,
name|CTLFLAG_RDTUN
operator||
name|CTLFLAG_NOFETCH
argument_list|,
operator|&
name|pmap_pcid_enabled
argument_list|,
literal|0
argument_list|,
literal|"Is TLB Context ID enabled ?"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|invpcid_works
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|invpcid_works
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|invpcid_works
argument_list|,
literal|0
argument_list|,
literal|"Is the invpcid instruction available ?"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|pmap_pcid_save_cnt_proc
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|uint64_t
name|res
decl_stmt|;
name|res
operator|=
literal|0
expr_stmt|;
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
block|{
name|res
operator|+=
name|cpuid_to_pcpu
index|[
name|i
index|]
operator|->
name|pc_pm_save_cnt
expr_stmt|;
block|}
return|return
operator|(
name|sysctl_handle_64
argument_list|(
name|oidp
argument_list|,
operator|&
name|res
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
operator|)
return|;
block|}
end_function

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pcid_save_cnt
argument_list|,
name|CTLTYPE_U64
operator||
name|CTLFLAG_RW
operator||
name|CTLFLAG_MPSAFE
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
name|pmap_pcid_save_cnt_proc
argument_list|,
literal|"QU"
argument_list|,
literal|"Count of saved TLB context on switch"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
specifier|static
name|LIST_HEAD
argument_list|(
argument_list|,
argument|pmap_invl_gen
argument_list|)
name|pmap_invl_gen_tracker
operator|=
name|LIST_HEAD_INITIALIZER
argument_list|(
operator|&
name|pmap_invl_gen_tracker
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|invl_gen_mtx
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_invl_gen
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Fake lock object to satisfy turnstiles interface. */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|lock_object
name|invl_gen_ts
init|=
block|{
operator|.
name|lo_name
operator|=
literal|"invlts"
block|, }
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|PMAP_ASSERT_NOT_IN_DI
parameter_list|()
define|\
value|KASSERT(curthread->td_md.md_invl_gen.gen == 0, ("DI already started"))
end_define

begin_comment
comment|/*  * Start a new Delayed Invalidation (DI) block of code, executed by  * the current thread.  Within a DI block, the current thread may  * destroy both the page table and PV list entries for a mapping and  * then release the corresponding PV list lock before ensuring that  * the mapping is flushed from the TLBs of any processors with the  * pmap active.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_delayed_invl_started
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|pmap_invl_gen
modifier|*
name|invl_gen
decl_stmt|;
name|u_long
name|currgen
decl_stmt|;
name|invl_gen
operator|=
operator|&
name|curthread
operator|->
name|td_md
operator|.
name|md_invl_gen
expr_stmt|;
name|PMAP_ASSERT_NOT_IN_DI
argument_list|()
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|invl_gen_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|LIST_EMPTY
argument_list|(
operator|&
name|pmap_invl_gen_tracker
argument_list|)
condition|)
name|currgen
operator|=
name|pmap_invl_gen
expr_stmt|;
else|else
name|currgen
operator|=
name|LIST_FIRST
argument_list|(
operator|&
name|pmap_invl_gen_tracker
argument_list|)
operator|->
name|gen
expr_stmt|;
name|invl_gen
operator|->
name|gen
operator|=
name|currgen
operator|+
literal|1
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|pmap_invl_gen_tracker
argument_list|,
name|invl_gen
argument_list|,
name|link
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|invl_gen_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Finish the DI block, previously started by the current thread.  All  * required TLB flushes for the pages marked by  * pmap_delayed_invl_page() must be finished before this function is  * called.  *  * This function works by bumping the global DI generation number to  * the generation number of the current thread's DI, unless there is a  * pending DI that started earlier.  In the latter case, bumping the  * global DI generation number would incorrectly signal that the  * earlier DI had finished.  Instead, this function bumps the earlier  * DI's generation number to match the generation number of the  * current thread's DI.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_delayed_invl_finished
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|pmap_invl_gen
modifier|*
name|invl_gen
decl_stmt|,
modifier|*
name|next
decl_stmt|;
name|struct
name|turnstile
modifier|*
name|ts
decl_stmt|;
name|invl_gen
operator|=
operator|&
name|curthread
operator|->
name|td_md
operator|.
name|md_invl_gen
expr_stmt|;
name|KASSERT
argument_list|(
name|invl_gen
operator|->
name|gen
operator|!=
literal|0
argument_list|,
operator|(
literal|"missed invl_started"
operator|)
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|invl_gen_mtx
argument_list|)
expr_stmt|;
name|next
operator|=
name|LIST_NEXT
argument_list|(
name|invl_gen
argument_list|,
name|link
argument_list|)
expr_stmt|;
if|if
condition|(
name|next
operator|==
name|NULL
condition|)
block|{
name|turnstile_chain_lock
argument_list|(
operator|&
name|invl_gen_ts
argument_list|)
expr_stmt|;
name|ts
operator|=
name|turnstile_lookup
argument_list|(
operator|&
name|invl_gen_ts
argument_list|)
expr_stmt|;
name|pmap_invl_gen
operator|=
name|invl_gen
operator|->
name|gen
expr_stmt|;
if|if
condition|(
name|ts
operator|!=
name|NULL
condition|)
block|{
name|turnstile_broadcast
argument_list|(
name|ts
argument_list|,
name|TS_SHARED_QUEUE
argument_list|)
expr_stmt|;
name|turnstile_unpend
argument_list|(
name|ts
argument_list|,
name|TS_SHARED_LOCK
argument_list|)
expr_stmt|;
block|}
name|turnstile_chain_unlock
argument_list|(
operator|&
name|invl_gen_ts
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|next
operator|->
name|gen
operator|=
name|invl_gen
operator|->
name|gen
expr_stmt|;
block|}
name|LIST_REMOVE
argument_list|(
name|invl_gen
argument_list|,
name|link
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|invl_gen_mtx
argument_list|)
expr_stmt|;
name|invl_gen
operator|->
name|gen
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|PV_STATS
end_ifdef

begin_decl_stmt
specifier|static
name|long
name|invl_wait
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|invl_wait
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|invl_wait
argument_list|,
literal|0
argument_list|,
literal|"Number of times DI invalidation blocked pmap_remove_all/write"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|u_long
modifier|*
name|pmap_delayed_invl_genp
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
return|return
operator|(
operator|&
name|pv_invl_gen
index|[
name|pa_index
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
operator|%
name|NPV_LIST_LOCKS
index|]
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Ensure that all currently executing DI blocks, that need to flush  * TLB for the given page m, actually flushed the TLB at the time the  * function returned.  If the page m has an empty PV list and we call  * pmap_delayed_invl_wait(), upon its return we know that no CPU has a  * valid mapping for the page m in either its page table or TLB.  *  * This function works by blocking until the global DI generation  * number catches up with the generation number associated with the  * given page m and its PV list.  Since this function's callers  * typically own an object lock and sometimes own a page lock, it  * cannot sleep.  Instead, it blocks on a turnstile to relinquish the  * processor.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_delayed_invl_wait
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|turnstile
modifier|*
name|ts
decl_stmt|;
name|u_long
modifier|*
name|m_gen
decl_stmt|;
ifdef|#
directive|ifdef
name|PV_STATS
name|bool
name|accounted
init|=
name|false
decl_stmt|;
endif|#
directive|endif
name|td
operator|=
name|curthread
expr_stmt|;
name|m_gen
operator|=
name|pmap_delayed_invl_genp
argument_list|(
name|m
argument_list|)
expr_stmt|;
while|while
condition|(
operator|*
name|m_gen
operator|>
name|pmap_invl_gen
condition|)
block|{
ifdef|#
directive|ifdef
name|PV_STATS
if|if
condition|(
operator|!
name|accounted
condition|)
block|{
name|atomic_add_long
argument_list|(
operator|&
name|invl_wait
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|accounted
operator|=
name|true
expr_stmt|;
block|}
endif|#
directive|endif
name|ts
operator|=
name|turnstile_trywait
argument_list|(
operator|&
name|invl_gen_ts
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|m_gen
operator|>
name|pmap_invl_gen
condition|)
name|turnstile_wait
argument_list|(
name|ts
argument_list|,
name|NULL
argument_list|,
name|TS_SHARED_QUEUE
argument_list|)
expr_stmt|;
else|else
name|turnstile_cancel
argument_list|(
name|ts
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Mark the page m's PV list as participating in the current thread's  * DI block.  Any threads concurrently using m's PV list to remove or  * restrict all mappings to m will wait for the current thread's DI  * block to complete before proceeding.  *  * The function works by setting the DI generation number for m's PV  * list to at least the DI generation number of the current thread.  * This forces a caller of pmap_delayed_invl_wait() to block until  * current thread calls pmap_delayed_invl_finished().  */
end_comment

begin_function
specifier|static
name|void
name|pmap_delayed_invl_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_long
name|gen
decl_stmt|,
modifier|*
name|m_gen
decl_stmt|;
name|rw_assert
argument_list|(
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|gen
operator|=
name|curthread
operator|->
name|td_md
operator|.
name|md_invl_gen
operator|.
name|gen
expr_stmt|;
if|if
condition|(
name|gen
operator|==
literal|0
condition|)
return|return;
name|m_gen
operator|=
name|pmap_delayed_invl_genp
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|m_gen
operator|<
name|gen
condition|)
operator|*
name|m_gen
operator|=
name|gen
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Crashdump maps.  */
end_comment

begin_decl_stmt
specifier|static
name|caddr_t
name|crashdumpmap
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|void
name|free_pv_chunk
parameter_list|(
name|struct
name|pv_chunk
modifier|*
name|pc
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|free_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pv_entry_t
name|pv
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|pv_entry_t
name|get_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|popcnt_pc_map_pq
parameter_list|(
name|uint64_t
modifier|*
name|map
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|reclaim_pv_chunk
parameter_list|(
name|pmap_t
name|locked_pmap
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|reserve_pv_entries
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|int
name|needed
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pv_demote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_pv_insert_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pv_promote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pvh_free
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|pv_entry_t
name|pmap_pvh_remove
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_change_attr_locked
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|int
name|mode
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_demote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_demote_pde_locked
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_demote_pdpe
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pdp_entry_t
modifier|*
name|pdpe
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_enter_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|pmap_enter_quick_locked
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|vm_page_t
name|mpte
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_fill_ptp
parameter_list|(
name|pt_entry_t
modifier|*
name|firstpte
parameter_list|,
name|pt_entry_t
name|newpte
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_insert_pt_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|mpte
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_invalidate_pde_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|pde
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_kenter_attr
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|int
name|mode
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pde_attr
parameter_list|(
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|int
name|cache_bits
parameter_list|,
name|int
name|mask
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_promote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_protect_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pte_attr
parameter_list|(
name|pt_entry_t
modifier|*
name|pte
parameter_list|,
name|int
name|cache_bits
parameter_list|,
name|int
name|mask
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_remove_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pdq
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_remove_pte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt_entry_t
modifier|*
name|ptq
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|pd_entry_t
name|ptepde
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|pmap_remove_pt_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_remove_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|bool
name|pmap_remove_ptes
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_try_insert_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_update_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_update_pde_invalidate
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|pde
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|_pmap_allocpte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_pindex_t
name|ptepindex
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|pmap_allocpde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|pmap_allocpte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|_pmap_unwire_ptp
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_unuse_pt
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|pd_entry_t
parameter_list|,
name|struct
name|spglist
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_offset_t
name|pmap_kmem_choose
parameter_list|(
name|vm_offset_t
name|addr
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Move the kernel virtual free pointer to the next  * 2MB.  This is used to help improve performance  * by using a large (2MB) page for much of the kernel  * (.text, .data, .bss)  */
end_comment

begin_function
specifier|static
name|vm_offset_t
name|pmap_kmem_choose
parameter_list|(
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|vm_offset_t
name|newaddr
init|=
name|addr
decl_stmt|;
name|newaddr
operator|=
name|roundup2
argument_list|(
name|addr
argument_list|,
name|NBPDR
argument_list|)
expr_stmt|;
return|return
operator|(
name|newaddr
operator|)
return|;
block|}
end_function

begin_comment
comment|/********************/
end_comment

begin_comment
comment|/* Inline functions */
end_comment

begin_comment
comment|/********************/
end_comment

begin_comment
comment|/* Return a non-clipped PD index for a given VA */
end_comment

begin_function
specifier|static
name|__inline
name|vm_pindex_t
name|pmap_pde_pindex
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
return|return
operator|(
name|va
operator|>>
name|PDRSHIFT
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Return a pointer to the PML4 slot that corresponds to a VA */
end_comment

begin_function
specifier|static
name|__inline
name|pml4_entry_t
modifier|*
name|pmap_pml4e
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
return|return
operator|(
operator|&
name|pmap
operator|->
name|pm_pml4
index|[
name|pmap_pml4e_index
argument_list|(
name|va
argument_list|)
index|]
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Return a pointer to the PDP slot that corresponds to a VA */
end_comment

begin_function
specifier|static
name|__inline
name|pdp_entry_t
modifier|*
name|pmap_pml4e_to_pdpe
parameter_list|(
name|pml4_entry_t
modifier|*
name|pml4e
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|pdpe
operator|=
operator|(
name|pdp_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
operator|*
name|pml4e
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
return|return
operator|(
operator|&
name|pdpe
index|[
name|pmap_pdpe_index
argument_list|(
name|va
argument_list|)
index|]
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Return a pointer to the PDP slot that corresponds to a VA */
end_comment

begin_function
specifier|static
name|__inline
name|pdp_entry_t
modifier|*
name|pmap_pdpe
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pml4_entry_t
modifier|*
name|pml4e
decl_stmt|;
name|pt_entry_t
name|PG_V
decl_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pml4e
operator|=
name|pmap_pml4e
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pml4e
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
return|return
operator|(
name|pmap_pml4e_to_pdpe
argument_list|(
name|pml4e
argument_list|,
name|va
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Return a pointer to the PD slot that corresponds to a VA */
end_comment

begin_function
specifier|static
name|__inline
name|pd_entry_t
modifier|*
name|pmap_pdpe_to_pde
parameter_list|(
name|pdp_entry_t
modifier|*
name|pdpe
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pde
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
operator|*
name|pdpe
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
return|return
operator|(
operator|&
name|pde
index|[
name|pmap_pde_index
argument_list|(
name|va
argument_list|)
index|]
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Return a pointer to the PD slot that corresponds to a VA */
end_comment

begin_function
specifier|static
name|__inline
name|pd_entry_t
modifier|*
name|pmap_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|pt_entry_t
name|PG_V
decl_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pdpe
operator|=
name|pmap_pdpe
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pdpe
operator|==
name|NULL
operator|||
operator|(
operator|*
name|pdpe
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
return|return
operator|(
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|va
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Return a pointer to the PT slot that corresponds to a VA */
end_comment

begin_function
specifier|static
name|__inline
name|pt_entry_t
modifier|*
name|pmap_pde_to_pte
parameter_list|(
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pte
operator|=
operator|(
name|pt_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
operator|*
name|pde
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
return|return
operator|(
operator|&
name|pte
index|[
name|pmap_pte_index
argument_list|(
name|va
argument_list|)
index|]
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Return a pointer to the PT slot that corresponds to a VA */
end_comment

begin_function
specifier|static
name|__inline
name|pt_entry_t
modifier|*
name|pmap_pte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
name|PG_V
decl_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pde
operator|==
name|NULL
operator|||
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
comment|/* compat with i386 pmap_pte() */
return|return
operator|(
operator|(
name|pt_entry_t
operator|*
operator|)
name|pde
operator|)
return|;
return|return
operator|(
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|va
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pmap_resident_count_inc
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|+=
name|count
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pmap_resident_count_dec
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|>=
name|count
argument_list|,
operator|(
literal|"pmap %p resident count underflow %ld %d"
operator|,
name|pmap
operator|,
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|,
name|count
operator|)
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|-=
name|count
expr_stmt|;
block|}
end_function

begin_function
name|PMAP_INLINE
name|pt_entry_t
modifier|*
name|vtopte
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|u_int64_t
name|mask
init|=
operator|(
operator|(
literal|1ul
operator|<<
operator|(
name|NPTEPGSHIFT
operator|+
name|NPDEPGSHIFT
operator|+
name|NPDPEPGSHIFT
operator|+
name|NPML4EPGSHIFT
operator|)
operator|)
operator|-
literal|1
operator|)
decl_stmt|;
name|KASSERT
argument_list|(
name|va
operator|>=
name|VM_MAXUSER_ADDRESS
argument_list|,
operator|(
literal|"vtopte on a uva/gpa 0x%0lx"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|PTmap
operator|+
operator|(
operator|(
name|va
operator|>>
name|PAGE_SHIFT
operator|)
operator|&
name|mask
operator|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pd_entry_t
modifier|*
name|vtopde
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|u_int64_t
name|mask
init|=
operator|(
operator|(
literal|1ul
operator|<<
operator|(
name|NPDEPGSHIFT
operator|+
name|NPDPEPGSHIFT
operator|+
name|NPML4EPGSHIFT
operator|)
operator|)
operator|-
literal|1
operator|)
decl_stmt|;
name|KASSERT
argument_list|(
name|va
operator|>=
name|VM_MAXUSER_ADDRESS
argument_list|,
operator|(
literal|"vtopde on a uva/gpa 0x%0lx"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|PDmap
operator|+
operator|(
operator|(
name|va
operator|>>
name|PDRSHIFT
operator|)
operator|&
name|mask
operator|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|u_int64_t
name|allocpages
parameter_list|(
name|vm_paddr_t
modifier|*
name|firstaddr
parameter_list|,
name|int
name|n
parameter_list|)
block|{
name|u_int64_t
name|ret
decl_stmt|;
name|ret
operator|=
operator|*
name|firstaddr
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|ret
argument_list|,
name|n
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
operator|*
name|firstaddr
operator|+=
name|n
operator|*
name|PAGE_SIZE
expr_stmt|;
return|return
operator|(
name|ret
operator|)
return|;
block|}
end_function

begin_expr_stmt
name|CTASSERT
argument_list|(
name|powerof2
argument_list|(
name|NDMPML4E
argument_list|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/* number of kernel PDP slots */
end_comment

begin_define
define|#
directive|define
name|NKPDPE
parameter_list|(
name|ptpgs
parameter_list|)
value|howmany(ptpgs, NPDEPG)
end_define

begin_function
specifier|static
name|void
name|nkpt_init
parameter_list|(
name|vm_paddr_t
name|addr
parameter_list|)
block|{
name|int
name|pt_pages
decl_stmt|;
ifdef|#
directive|ifdef
name|NKPT
name|pt_pages
operator|=
name|NKPT
expr_stmt|;
else|#
directive|else
name|pt_pages
operator|=
name|howmany
argument_list|(
name|addr
argument_list|,
literal|1
operator|<<
name|PDRSHIFT
argument_list|)
expr_stmt|;
name|pt_pages
operator|+=
name|NKPDPE
argument_list|(
name|pt_pages
argument_list|)
expr_stmt|;
comment|/* 	 * Add some slop beyond the bare minimum required for bootstrapping 	 * the kernel. 	 * 	 * This is quite important when allocating KVA for kernel modules. 	 * The modules are required to be linked in the negative 2GB of 	 * the address space.  If we run out of KVA in this region then 	 * pmap_growkernel() will need to allocate page table pages to map 	 * the entire 512GB of KVA space which is an unnecessary tax on 	 * physical memory. 	 * 	 * Secondly, device memory mapped as part of setting up the low- 	 * level console(s) is taken from KVA, starting at virtual_avail. 	 * This is because cninit() is called after pmap_bootstrap() but 	 * before vm_init() and pmap_init(). 20MB for a frame buffer is 	 * not uncommon. 	 */
name|pt_pages
operator|+=
literal|32
expr_stmt|;
comment|/* 64MB additional slop. */
endif|#
directive|endif
name|nkpt
operator|=
name|pt_pages
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|create_pagetables
parameter_list|(
name|vm_paddr_t
modifier|*
name|firstaddr
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|j
decl_stmt|,
name|ndm1g
decl_stmt|,
name|nkpdpe
decl_stmt|;
name|pt_entry_t
modifier|*
name|pt_p
decl_stmt|;
name|pd_entry_t
modifier|*
name|pd_p
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdp_p
decl_stmt|;
name|pml4_entry_t
modifier|*
name|p4_p
decl_stmt|;
comment|/* Allocate page table pages for the direct map */
name|ndmpdp
operator|=
name|howmany
argument_list|(
name|ptoa
argument_list|(
name|Maxmem
argument_list|)
argument_list|,
name|NBPDP
argument_list|)
expr_stmt|;
if|if
condition|(
name|ndmpdp
operator|<
literal|4
condition|)
comment|/* Minimum 4GB of dirmap */
name|ndmpdp
operator|=
literal|4
expr_stmt|;
name|ndmpdpphys
operator|=
name|howmany
argument_list|(
name|ndmpdp
argument_list|,
name|NPDPEPG
argument_list|)
expr_stmt|;
if|if
condition|(
name|ndmpdpphys
operator|>
name|NDMPML4E
condition|)
block|{
comment|/* 		 * Each NDMPML4E allows 512 GB, so limit to that, 		 * and then readjust ndmpdp and ndmpdpphys. 		 */
name|printf
argument_list|(
literal|"NDMPML4E limits system to %d GB\n"
argument_list|,
name|NDMPML4E
operator|*
literal|512
argument_list|)
expr_stmt|;
name|Maxmem
operator|=
name|atop
argument_list|(
name|NDMPML4E
operator|*
name|NBPML4
argument_list|)
expr_stmt|;
name|ndmpdpphys
operator|=
name|NDMPML4E
expr_stmt|;
name|ndmpdp
operator|=
name|NDMPML4E
operator|*
name|NPDEPG
expr_stmt|;
block|}
name|DMPDPphys
operator|=
name|allocpages
argument_list|(
name|firstaddr
argument_list|,
name|ndmpdpphys
argument_list|)
expr_stmt|;
name|ndm1g
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|amd_feature
operator|&
name|AMDID_PAGE1GB
operator|)
operator|!=
literal|0
condition|)
name|ndm1g
operator|=
name|ptoa
argument_list|(
name|Maxmem
argument_list|)
operator|>>
name|PDPSHIFT
expr_stmt|;
if|if
condition|(
name|ndm1g
operator|<
name|ndmpdp
condition|)
name|DMPDphys
operator|=
name|allocpages
argument_list|(
name|firstaddr
argument_list|,
name|ndmpdp
operator|-
name|ndm1g
argument_list|)
expr_stmt|;
name|dmaplimit
operator|=
operator|(
name|vm_paddr_t
operator|)
name|ndmpdp
operator|<<
name|PDPSHIFT
expr_stmt|;
comment|/* Allocate pages */
name|KPML4phys
operator|=
name|allocpages
argument_list|(
name|firstaddr
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|KPDPphys
operator|=
name|allocpages
argument_list|(
name|firstaddr
argument_list|,
name|NKPML4E
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate the initial number of kernel page table pages required to 	 * bootstrap.  We defer this until after all memory-size dependent 	 * allocations are done (e.g. direct map), so that we don't have to 	 * build in too much slop in our estimate. 	 * 	 * Note that when NKPML4E> 1, we have an empty page underneath 	 * all but the KPML4I'th one, so we need NKPML4E-1 extra (zeroed) 	 * pages.  (pmap_enter requires a PD page to exist for each KPML4E.) 	 */
name|nkpt_init
argument_list|(
operator|*
name|firstaddr
argument_list|)
expr_stmt|;
name|nkpdpe
operator|=
name|NKPDPE
argument_list|(
name|nkpt
argument_list|)
expr_stmt|;
name|KPTphys
operator|=
name|allocpages
argument_list|(
name|firstaddr
argument_list|,
name|nkpt
argument_list|)
expr_stmt|;
name|KPDphys
operator|=
name|allocpages
argument_list|(
name|firstaddr
argument_list|,
name|nkpdpe
argument_list|)
expr_stmt|;
comment|/* Fill in the underlying page table pages */
comment|/* Nominally read-only (but really R/W) from zero to physfree */
comment|/* XXX not fully used, underneath 2M pages */
name|pt_p
operator|=
operator|(
name|pt_entry_t
operator|*
operator|)
name|KPTphys
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|ptoa
argument_list|(
name|i
argument_list|)
operator|<
operator|*
name|firstaddr
condition|;
name|i
operator|++
control|)
name|pt_p
index|[
name|i
index|]
operator|=
name|ptoa
argument_list|(
name|i
argument_list|)
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|X86_PG_G
expr_stmt|;
comment|/* Now map the page tables at their location within PTmap */
name|pd_p
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|KPDphys
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nkpt
condition|;
name|i
operator|++
control|)
name|pd_p
index|[
name|i
index|]
operator|=
operator|(
name|KPTphys
operator|+
name|ptoa
argument_list|(
name|i
argument_list|)
operator|)
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
expr_stmt|;
comment|/* Map from zero to end of allocations under 2M pages */
comment|/* This replaces some of the KPTphys entries above */
for|for
control|(
name|i
operator|=
literal|0
init|;
operator|(
name|i
operator|<<
name|PDRSHIFT
operator|)
operator|<
operator|*
name|firstaddr
condition|;
name|i
operator|++
control|)
name|pd_p
index|[
name|i
index|]
operator|=
operator|(
name|i
operator|<<
name|PDRSHIFT
operator|)
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|PG_PS
operator||
name|X86_PG_G
expr_stmt|;
comment|/* And connect up the PD to the PDP (leaving room for L4 pages) */
name|pdp_p
operator|=
operator|(
name|pdp_entry_t
operator|*
operator|)
operator|(
name|KPDPphys
operator|+
name|ptoa
argument_list|(
name|KPML4I
operator|-
name|KPML4BASE
argument_list|)
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nkpdpe
condition|;
name|i
operator|++
control|)
name|pdp_p
index|[
name|i
operator|+
name|KPDPI
index|]
operator|=
operator|(
name|KPDphys
operator|+
name|ptoa
argument_list|(
name|i
argument_list|)
operator|)
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|PG_U
expr_stmt|;
comment|/* 	 * Now, set up the direct map region using 2MB and/or 1GB pages.  If 	 * the end of physical memory is not aligned to a 1GB page boundary, 	 * then the residual physical memory is mapped with 2MB pages.  Later, 	 * if pmap_mapdev{_attr}() uses the direct map for non-write-back 	 * memory, pmap_change_attr() will demote any 2MB or 1GB page mappings 	 * that are partially used.  	 */
name|pd_p
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|DMPDphys
expr_stmt|;
for|for
control|(
name|i
operator|=
name|NPDEPG
operator|*
name|ndm1g
operator|,
name|j
operator|=
literal|0
init|;
name|i
operator|<
name|NPDEPG
operator|*
name|ndmpdp
condition|;
name|i
operator|++
operator|,
name|j
operator|++
control|)
block|{
name|pd_p
index|[
name|j
index|]
operator|=
operator|(
name|vm_paddr_t
operator|)
name|i
operator|<<
name|PDRSHIFT
expr_stmt|;
comment|/* Preset PG_M and PG_A because demotion expects it. */
name|pd_p
index|[
name|j
index|]
operator||=
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|PG_PS
operator||
name|X86_PG_G
operator||
name|X86_PG_M
operator||
name|X86_PG_A
operator||
name|pg_nx
expr_stmt|;
block|}
name|pdp_p
operator|=
operator|(
name|pdp_entry_t
operator|*
operator|)
name|DMPDPphys
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|ndm1g
condition|;
name|i
operator|++
control|)
block|{
name|pdp_p
index|[
name|i
index|]
operator|=
operator|(
name|vm_paddr_t
operator|)
name|i
operator|<<
name|PDPSHIFT
expr_stmt|;
comment|/* Preset PG_M and PG_A because demotion expects it. */
name|pdp_p
index|[
name|i
index|]
operator||=
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|PG_PS
operator||
name|X86_PG_G
operator||
name|X86_PG_M
operator||
name|X86_PG_A
operator||
name|pg_nx
expr_stmt|;
block|}
for|for
control|(
name|j
operator|=
literal|0
init|;
name|i
operator|<
name|ndmpdp
condition|;
name|i
operator|++
operator|,
name|j
operator|++
control|)
block|{
name|pdp_p
index|[
name|i
index|]
operator|=
name|DMPDphys
operator|+
name|ptoa
argument_list|(
name|j
argument_list|)
expr_stmt|;
name|pdp_p
index|[
name|i
index|]
operator||=
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|PG_U
expr_stmt|;
block|}
comment|/* And recursively map PML4 to itself in order to get PTmap */
name|p4_p
operator|=
operator|(
name|pml4_entry_t
operator|*
operator|)
name|KPML4phys
expr_stmt|;
name|p4_p
index|[
name|PML4PML4I
index|]
operator|=
name|KPML4phys
expr_stmt|;
name|p4_p
index|[
name|PML4PML4I
index|]
operator||=
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|PG_U
expr_stmt|;
comment|/* Connect the Direct Map slot(s) up to the PML4. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|ndmpdpphys
condition|;
name|i
operator|++
control|)
block|{
name|p4_p
index|[
name|DMPML4I
operator|+
name|i
index|]
operator|=
name|DMPDPphys
operator|+
name|ptoa
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|p4_p
index|[
name|DMPML4I
operator|+
name|i
index|]
operator||=
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|PG_U
expr_stmt|;
block|}
comment|/* Connect the KVA slots up to the PML4 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NKPML4E
condition|;
name|i
operator|++
control|)
block|{
name|p4_p
index|[
name|KPML4BASE
operator|+
name|i
index|]
operator|=
name|KPDPphys
operator|+
name|ptoa
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|p4_p
index|[
name|KPML4BASE
operator|+
name|i
index|]
operator||=
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|PG_U
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	Bootstrap the system enough to run with virtual memory.  *  *	On amd64 this is called after mapping has already been enabled  *	and just syncs the pmap module with what has already been done.  *	[We can't call it easily with mapping off since the kernel is not  *	mapped with PA == VA, hence we would have to relocate every address  *	from the linked base (virtual) address "KERNBASE" to the actual  *	(physical) address starting relative to 0]  */
end_comment

begin_function
name|void
name|pmap_bootstrap
parameter_list|(
name|vm_paddr_t
modifier|*
name|firstaddr
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * Create an initial set of page tables to run the kernel in. 	 */
name|create_pagetables
argument_list|(
name|firstaddr
argument_list|)
expr_stmt|;
comment|/* 	 * Add a physical memory segment (vm_phys_seg) corresponding to the 	 * preallocated kernel page table pages so that vm_page structures 	 * representing these pages will be created.  The vm_page structures 	 * are required for promotion of the corresponding kernel virtual 	 * addresses to superpage mappings. 	 */
name|vm_phys_add_seg
argument_list|(
name|KPTphys
argument_list|,
name|KPTphys
operator|+
name|ptoa
argument_list|(
name|nkpt
argument_list|)
argument_list|)
expr_stmt|;
name|virtual_avail
operator|=
operator|(
name|vm_offset_t
operator|)
name|KERNBASE
operator|+
operator|*
name|firstaddr
expr_stmt|;
name|virtual_avail
operator|=
name|pmap_kmem_choose
argument_list|(
name|virtual_avail
argument_list|)
expr_stmt|;
name|virtual_end
operator|=
name|VM_MAX_KERNEL_ADDRESS
expr_stmt|;
comment|/* XXX do %cr0 as well */
name|load_cr4
argument_list|(
name|rcr4
argument_list|()
operator||
name|CR4_PGE
argument_list|)
expr_stmt|;
name|load_cr3
argument_list|(
name|KPML4phys
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu_stdext_feature
operator|&
name|CPUID_STDEXT_SMEP
condition|)
name|load_cr4
argument_list|(
name|rcr4
argument_list|()
operator||
name|CR4_SMEP
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the kernel pmap (which is statically allocated). 	 */
name|PMAP_LOCK_INIT
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|kernel_pmap
operator|->
name|pm_pml4
operator|=
operator|(
name|pdp_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|KPML4phys
argument_list|)
expr_stmt|;
name|kernel_pmap
operator|->
name|pm_cr3
operator|=
name|KPML4phys
expr_stmt|;
name|CPU_FILL
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
comment|/* don't allow deactivation */
name|TAILQ_INIT
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
name|kernel_pmap
operator|->
name|pm_flags
operator|=
name|pmap_flags
expr_stmt|;
comment|/* 	 * Initialize the TLB invalidations generation number lock. 	 */
name|mtx_init
argument_list|(
operator|&
name|invl_gen_mtx
argument_list|,
literal|"invlgn"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* 	 * Reserve some special page table entries/VA space for temporary 	 * mapping of pages. 	 */
define|#
directive|define
name|SYSMAP
parameter_list|(
name|c
parameter_list|,
name|p
parameter_list|,
name|v
parameter_list|,
name|n
parameter_list|)
define|\
value|v = (c)va; va += ((n)*PAGE_SIZE); p = pte; pte += (n);
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * Crashdump maps.  The first page is reused as CMAP1 for the 	 * memory test. 	 */
name|SYSMAP
argument_list|(
argument|caddr_t
argument_list|,
argument|CMAP1
argument_list|,
argument|crashdumpmap
argument_list|,
argument|MAXDUMPPGS
argument_list|)
name|CADDR1
operator|=
name|crashdumpmap
expr_stmt|;
name|virtual_avail
operator|=
name|va
expr_stmt|;
comment|/* 	 * Initialize the PAT MSR. 	 * pmap_init_pat() clears and sets CR4_PGE, which, as a 	 * side-effect, invalidates stale PG_G TLB entries that might 	 * have been created in our pre-boot environment. 	 */
name|pmap_init_pat
argument_list|()
expr_stmt|;
comment|/* Initialize TLB Context Id. */
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.pmap.pcid_enabled"
argument_list|,
operator|&
name|pmap_pcid_enabled
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|cpu_feature2
operator|&
name|CPUID2_PCID
operator|)
operator|!=
literal|0
operator|&&
name|pmap_pcid_enabled
condition|)
block|{
comment|/* Check for INVPCID support */
name|invpcid_works
operator|=
operator|(
name|cpu_stdext_feature
operator|&
name|CPUID_STDEXT_INVPCID
operator|)
operator|!=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
name|i
operator|++
control|)
block|{
name|kernel_pmap
operator|->
name|pm_pcids
index|[
name|i
index|]
operator|.
name|pm_pcid
operator|=
name|PMAP_PCID_KERN
expr_stmt|;
name|kernel_pmap
operator|->
name|pm_pcids
index|[
name|i
index|]
operator|.
name|pm_gen
operator|=
literal|1
expr_stmt|;
block|}
name|PCPU_SET
argument_list|(
name|pcid_next
argument_list|,
name|PMAP_PCID_KERN
operator|+
literal|1
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|pcid_gen
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 		 * pcpu area for APs is zeroed during AP startup. 		 * pc_pcid_next and pc_pcid_gen are initialized by AP 		 * during pcpu setup. 		 */
name|load_cr4
argument_list|(
name|rcr4
argument_list|()
operator||
name|CR4_PCIDE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pmap_pcid_enabled
operator|=
literal|0
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Setup the PAT MSR.  */
end_comment

begin_function
name|void
name|pmap_init_pat
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|pat_table
index|[
name|PAT_INDEX_SIZE
index|]
decl_stmt|;
name|uint64_t
name|pat_msr
decl_stmt|;
name|u_long
name|cr0
decl_stmt|,
name|cr4
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* Bail if this CPU doesn't implement PAT. */
if|if
condition|(
operator|(
name|cpu_feature
operator|&
name|CPUID_PAT
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"no PAT??"
argument_list|)
expr_stmt|;
comment|/* Set default PAT index table. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PAT_INDEX_SIZE
condition|;
name|i
operator|++
control|)
name|pat_table
index|[
name|i
index|]
operator|=
operator|-
literal|1
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_BACK
index|]
operator|=
literal|0
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_THROUGH
index|]
operator|=
literal|1
expr_stmt|;
name|pat_table
index|[
name|PAT_UNCACHEABLE
index|]
operator|=
literal|3
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_COMBINING
index|]
operator|=
literal|3
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_PROTECTED
index|]
operator|=
literal|3
expr_stmt|;
name|pat_table
index|[
name|PAT_UNCACHED
index|]
operator|=
literal|3
expr_stmt|;
comment|/* Initialize default PAT entries. */
name|pat_msr
operator|=
name|PAT_VALUE
argument_list|(
literal|0
argument_list|,
name|PAT_WRITE_BACK
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|1
argument_list|,
name|PAT_WRITE_THROUGH
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|2
argument_list|,
name|PAT_UNCACHED
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|3
argument_list|,
name|PAT_UNCACHEABLE
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|4
argument_list|,
name|PAT_WRITE_BACK
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|5
argument_list|,
name|PAT_WRITE_THROUGH
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|6
argument_list|,
name|PAT_UNCACHED
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|7
argument_list|,
name|PAT_UNCACHEABLE
argument_list|)
expr_stmt|;
if|if
condition|(
name|pat_works
condition|)
block|{
comment|/* 		 * Leave the indices 0-3 at the default of WB, WT, UC-, and UC. 		 * Program 5 and 6 as WP and WC. 		 * Leave 4 and 7 as WB and UC. 		 */
name|pat_msr
operator|&=
operator|~
operator|(
name|PAT_MASK
argument_list|(
literal|5
argument_list|)
operator||
name|PAT_MASK
argument_list|(
literal|6
argument_list|)
operator|)
expr_stmt|;
name|pat_msr
operator||=
name|PAT_VALUE
argument_list|(
literal|5
argument_list|,
name|PAT_WRITE_PROTECTED
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|6
argument_list|,
name|PAT_WRITE_COMBINING
argument_list|)
expr_stmt|;
name|pat_table
index|[
name|PAT_UNCACHED
index|]
operator|=
literal|2
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_PROTECTED
index|]
operator|=
literal|5
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_COMBINING
index|]
operator|=
literal|6
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Just replace PAT Index 2 with WC instead of UC-. 		 */
name|pat_msr
operator|&=
operator|~
name|PAT_MASK
argument_list|(
literal|2
argument_list|)
expr_stmt|;
name|pat_msr
operator||=
name|PAT_VALUE
argument_list|(
literal|2
argument_list|,
name|PAT_WRITE_COMBINING
argument_list|)
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_COMBINING
index|]
operator|=
literal|2
expr_stmt|;
block|}
comment|/* Disable PGE. */
name|cr4
operator|=
name|rcr4
argument_list|()
expr_stmt|;
name|load_cr4
argument_list|(
name|cr4
operator|&
operator|~
name|CR4_PGE
argument_list|)
expr_stmt|;
comment|/* Disable caches (CD = 1, NW = 0). */
name|cr0
operator|=
name|rcr0
argument_list|()
expr_stmt|;
name|load_cr0
argument_list|(
operator|(
name|cr0
operator|&
operator|~
name|CR0_NW
operator|)
operator||
name|CR0_CD
argument_list|)
expr_stmt|;
comment|/* Flushes caches and TLBs. */
name|wbinvd
argument_list|()
expr_stmt|;
name|invltlb
argument_list|()
expr_stmt|;
comment|/* Update PAT and index table. */
name|wrmsr
argument_list|(
name|MSR_PAT
argument_list|,
name|pat_msr
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PAT_INDEX_SIZE
condition|;
name|i
operator|++
control|)
name|pat_index
index|[
name|i
index|]
operator|=
name|pat_table
index|[
name|i
index|]
expr_stmt|;
comment|/* Flush caches and TLBs again. */
name|wbinvd
argument_list|()
expr_stmt|;
name|invltlb
argument_list|()
expr_stmt|;
comment|/* Restore caches and PGE. */
name|load_cr0
argument_list|(
name|cr0
argument_list|)
expr_stmt|;
name|load_cr4
argument_list|(
name|cr4
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Initialize a vm_page's machine-dependent fields.  */
end_comment

begin_function
name|void
name|pmap_page_init
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|TAILQ_INIT
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pat_mode
operator|=
name|PAT_WRITE_BACK
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Initialize the pmap module.  *	Called by vm_init, to initialize any structures that the pmap  *	system needs to map virtual memory.  */
end_comment

begin_function
name|void
name|pmap_init
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|pmap_preinit_mapping
modifier|*
name|ppim
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
name|vm_size_t
name|s
decl_stmt|;
name|int
name|error
decl_stmt|,
name|i
decl_stmt|,
name|pv_npg
decl_stmt|;
comment|/* 	 * Initialize the vm page array entries for the kernel pmap's 	 * page table pages. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|nkpt
condition|;
name|i
operator|++
control|)
block|{
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|KPTphys
operator|+
operator|(
name|i
operator|<<
name|PAGE_SHIFT
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|>=
name|vm_page_array
operator|&&
name|mpte
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"pmap_init: page table page is out of range"
operator|)
argument_list|)
expr_stmt|;
name|mpte
operator|->
name|pindex
operator|=
name|pmap_pde_pindex
argument_list|(
name|KERNBASE
argument_list|)
operator|+
name|i
expr_stmt|;
name|mpte
operator|->
name|phys_addr
operator|=
name|KPTphys
operator|+
operator|(
name|i
operator|<<
name|PAGE_SHIFT
operator|)
expr_stmt|;
block|}
comment|/* 	 * If the kernel is running on a virtual machine, then it must assume 	 * that MCA is enabled by the hypervisor.  Moreover, the kernel must 	 * be prepared for the hypervisor changing the vendor and family that 	 * are reported by CPUID.  Consequently, the workaround for AMD Family 	 * 10h Erratum 383 is enabled if the processor's feature set does not 	 * include at least one feature that is only supported by older Intel 	 * or newer AMD processors. 	 */
if|if
condition|(
name|vm_guest
operator|!=
name|VM_GUEST_NO
operator|&&
operator|(
name|cpu_feature
operator|&
name|CPUID_SS
operator|)
operator|==
literal|0
operator|&&
operator|(
name|cpu_feature2
operator|&
operator|(
name|CPUID2_SSSE3
operator||
name|CPUID2_SSE41
operator||
name|CPUID2_AESNI
operator||
name|CPUID2_AVX
operator||
name|CPUID2_XSAVE
operator|)
operator|)
operator|==
literal|0
operator|&&
operator|(
name|amd_feature2
operator|&
operator|(
name|AMDID2_XOP
operator||
name|AMDID2_FMA4
operator|)
operator|)
operator|==
literal|0
condition|)
name|workaround_erratum383
operator|=
literal|1
expr_stmt|;
comment|/* 	 * Are large page mappings enabled? 	 */
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.pmap.pg_ps_enabled"
argument_list|,
operator|&
name|pg_ps_enabled
argument_list|)
expr_stmt|;
if|if
condition|(
name|pg_ps_enabled
condition|)
block|{
name|KASSERT
argument_list|(
name|MAXPAGESIZES
operator|>
literal|1
operator|&&
name|pagesizes
index|[
literal|1
index|]
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_init: can't assign to pagesizes[1]"
operator|)
argument_list|)
expr_stmt|;
name|pagesizes
index|[
literal|1
index|]
operator|=
name|NBPDR
expr_stmt|;
block|}
comment|/* 	 * Initialize the pv chunk list mutex. 	 */
name|mtx_init
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|,
literal|"pmap pv chunk list"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the pool of pv list locks. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPV_LIST_LOCKS
condition|;
name|i
operator|++
control|)
name|rw_init
argument_list|(
operator|&
name|pv_list_locks
index|[
name|i
index|]
argument_list|,
literal|"pmap pv list"
argument_list|)
expr_stmt|;
comment|/* 	 * Calculate the size of the pv head table for superpages. 	 */
name|pv_npg
operator|=
name|howmany
argument_list|(
name|vm_phys_segs
index|[
name|vm_phys_nsegs
operator|-
literal|1
index|]
operator|.
name|end
argument_list|,
name|NBPDR
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate memory for the pv head table for superpages. 	 */
name|s
operator|=
call|(
name|vm_size_t
call|)
argument_list|(
name|pv_npg
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|md_page
argument_list|)
argument_list|)
expr_stmt|;
name|s
operator|=
name|round_page
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|pv_table
operator|=
operator|(
expr|struct
name|md_page
operator|*
operator|)
name|kmem_malloc
argument_list|(
name|kernel_arena
argument_list|,
name|s
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pv_npg
condition|;
name|i
operator|++
control|)
name|TAILQ_INIT
argument_list|(
operator|&
name|pv_table
index|[
name|i
index|]
operator|.
name|pv_list
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|pv_dummy
operator|.
name|pv_list
argument_list|)
expr_stmt|;
name|pmap_initialized
operator|=
literal|1
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PMAP_PREINIT_MAPPING_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|ppim
operator|=
name|pmap_preinit_mapping
operator|+
name|i
expr_stmt|;
if|if
condition|(
name|ppim
operator|->
name|va
operator|==
literal|0
condition|)
continue|continue;
comment|/* Make the direct map consistent */
if|if
condition|(
name|ppim
operator|->
name|pa
operator|<
name|dmaplimit
operator|&&
name|ppim
operator|->
name|pa
operator|+
name|ppim
operator|->
name|sz
operator|<
name|dmaplimit
condition|)
block|{
operator|(
name|void
operator|)
name|pmap_change_attr
argument_list|(
name|PHYS_TO_DMAP
argument_list|(
name|ppim
operator|->
name|pa
argument_list|)
argument_list|,
name|ppim
operator|->
name|sz
argument_list|,
name|ppim
operator|->
name|mode
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|bootverbose
condition|)
continue|continue;
name|printf
argument_list|(
literal|"PPIM %u: PA=%#lx, VA=%#lx, size=%#lx, mode=%#x\n"
argument_list|,
name|i
argument_list|,
name|ppim
operator|->
name|pa
argument_list|,
name|ppim
operator|->
name|va
argument_list|,
name|ppim
operator|->
name|sz
argument_list|,
name|ppim
operator|->
name|mode
argument_list|)
expr_stmt|;
block|}
name|mtx_init
argument_list|(
operator|&
name|qframe_mtx
argument_list|,
literal|"qfrmlk"
argument_list|,
name|NULL
argument_list|,
name|MTX_SPIN
argument_list|)
expr_stmt|;
name|error
operator|=
name|vmem_alloc
argument_list|(
name|kernel_arena
argument_list|,
name|PAGE_SIZE
argument_list|,
name|M_BESTFIT
operator||
name|M_WAITOK
argument_list|,
operator|(
name|vmem_addr_t
operator|*
operator|)
operator|&
name|qframe
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"qframe allocation failed"
argument_list|)
expr_stmt|;
block|}
end_function

begin_expr_stmt
specifier|static
name|SYSCTL_NODE
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pde
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|"2MB page mapping counters"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pde_demotions
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pde
argument_list|,
name|OID_AUTO
argument_list|,
name|demotions
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pde_demotions
argument_list|,
literal|0
argument_list|,
literal|"2MB page demotions"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pde_mappings
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pde
argument_list|,
name|OID_AUTO
argument_list|,
name|mappings
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pde_mappings
argument_list|,
literal|0
argument_list|,
literal|"2MB page mappings"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pde_p_failures
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pde
argument_list|,
name|OID_AUTO
argument_list|,
name|p_failures
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pde_p_failures
argument_list|,
literal|0
argument_list|,
literal|"2MB page promotion failures"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pde_promotions
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pde
argument_list|,
name|OID_AUTO
argument_list|,
name|promotions
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pde_promotions
argument_list|,
literal|0
argument_list|,
literal|"2MB page promotions"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
specifier|static
name|SYSCTL_NODE
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pdpe
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|"1GB page mapping counters"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pdpe_demotions
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pdpe
argument_list|,
name|OID_AUTO
argument_list|,
name|demotions
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pdpe_demotions
argument_list|,
literal|0
argument_list|,
literal|"1GB page demotions"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/***************************************************  * Low level helper routines.....  ***************************************************/
end_comment

begin_function
specifier|static
name|pt_entry_t
name|pmap_swap_pat
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt_entry_t
name|entry
parameter_list|)
block|{
name|int
name|x86_pat_bits
init|=
name|X86_PG_PTE_PAT
operator||
name|X86_PG_PDE_PAT
decl_stmt|;
switch|switch
condition|(
name|pmap
operator|->
name|pm_type
condition|)
block|{
case|case
name|PT_X86
case|:
case|case
name|PT_RVI
case|:
comment|/* Verify that both PAT bits are not set at the same time */
name|KASSERT
argument_list|(
operator|(
name|entry
operator|&
name|x86_pat_bits
operator|)
operator|!=
name|x86_pat_bits
argument_list|,
operator|(
literal|"Invalid PAT bits in entry %#lx"
operator|,
name|entry
operator|)
argument_list|)
expr_stmt|;
comment|/* Swap the PAT bits if one of them is set */
if|if
condition|(
operator|(
name|entry
operator|&
name|x86_pat_bits
operator|)
operator|!=
literal|0
condition|)
name|entry
operator|^=
name|x86_pat_bits
expr_stmt|;
break|break;
case|case
name|PT_EPT
case|:
comment|/* 		 * Nothing to do - the memory attributes are represented 		 * the same way for regular pages and superpages. 		 */
break|break;
default|default:
name|panic
argument_list|(
literal|"pmap_switch_pat_bits: bad pm_type %d"
argument_list|,
name|pmap
operator|->
name|pm_type
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|entry
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Determine the appropriate bits to set in a PTE or PDE for a specified  * caching mode.  */
end_comment

begin_function
name|int
name|pmap_cache_bits
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|int
name|mode
parameter_list|,
name|boolean_t
name|is_pde
parameter_list|)
block|{
name|int
name|cache_bits
decl_stmt|,
name|pat_flag
decl_stmt|,
name|pat_idx
decl_stmt|;
if|if
condition|(
name|mode
operator|<
literal|0
operator|||
name|mode
operator|>=
name|PAT_INDEX_SIZE
operator|||
name|pat_index
index|[
name|mode
index|]
operator|<
literal|0
condition|)
name|panic
argument_list|(
literal|"Unknown caching mode %d\n"
argument_list|,
name|mode
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|pmap
operator|->
name|pm_type
condition|)
block|{
case|case
name|PT_X86
case|:
case|case
name|PT_RVI
case|:
comment|/* The PAT bit is different for PTE's and PDE's. */
name|pat_flag
operator|=
name|is_pde
condition|?
name|X86_PG_PDE_PAT
else|:
name|X86_PG_PTE_PAT
expr_stmt|;
comment|/* Map the caching mode to a PAT index. */
name|pat_idx
operator|=
name|pat_index
index|[
name|mode
index|]
expr_stmt|;
comment|/* Map the 3-bit index value into the PAT, PCD, and PWT bits. */
name|cache_bits
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|pat_idx
operator|&
literal|0x4
condition|)
name|cache_bits
operator||=
name|pat_flag
expr_stmt|;
if|if
condition|(
name|pat_idx
operator|&
literal|0x2
condition|)
name|cache_bits
operator||=
name|PG_NC_PCD
expr_stmt|;
if|if
condition|(
name|pat_idx
operator|&
literal|0x1
condition|)
name|cache_bits
operator||=
name|PG_NC_PWT
expr_stmt|;
break|break;
case|case
name|PT_EPT
case|:
name|cache_bits
operator|=
name|EPT_PG_IGNORE_PAT
operator||
name|EPT_PG_MEMORY_TYPE
argument_list|(
name|mode
argument_list|)
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"unsupported pmap type %d"
argument_list|,
name|pmap
operator|->
name|pm_type
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|cache_bits
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|pmap_cache_mask
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|boolean_t
name|is_pde
parameter_list|)
block|{
name|int
name|mask
decl_stmt|;
switch|switch
condition|(
name|pmap
operator|->
name|pm_type
condition|)
block|{
case|case
name|PT_X86
case|:
case|case
name|PT_RVI
case|:
name|mask
operator|=
name|is_pde
condition|?
name|X86_PG_PDE_CACHE
else|:
name|X86_PG_PTE_CACHE
expr_stmt|;
break|break;
case|case
name|PT_EPT
case|:
name|mask
operator|=
name|EPT_PG_IGNORE_PAT
operator||
name|EPT_PG_MEMORY_TYPE
argument_list|(
literal|0x7
argument_list|)
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"pmap_cache_mask: invalid pm_type %d"
argument_list|,
name|pmap
operator|->
name|pm_type
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|mask
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|boolean_t
name|pmap_ps_enabled
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
return|return
operator|(
name|pg_ps_enabled
operator|&&
operator|(
name|pmap
operator|->
name|pm_flags
operator|&
name|PMAP_PDE_SUPERPAGE
operator|)
operator|!=
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_update_pde_store
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
block|{
switch|switch
condition|(
name|pmap
operator|->
name|pm_type
condition|)
block|{
case|case
name|PT_X86
case|:
break|break;
case|case
name|PT_RVI
case|:
case|case
name|PT_EPT
case|:
comment|/* 		 * XXX 		 * This is a little bogus since the generation number is 		 * supposed to be bumped up when a region of the address 		 * space is invalidated in the page tables. 		 * 		 * In this case the old PDE entry is valid but yet we want 		 * to make sure that any mappings using the old entry are 		 * invalidated in the TLB. 		 * 		 * The reason this works as expected is because we rendezvous 		 * "all" host cpus and force any vcpu context to exit as a 		 * side-effect. 		 */
name|atomic_add_acq_long
argument_list|(
operator|&
name|pmap
operator|->
name|pm_eptgen
argument_list|,
literal|1
argument_list|)
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"pmap_update_pde_store: bad pm_type %d"
argument_list|,
name|pmap
operator|->
name|pm_type
argument_list|)
expr_stmt|;
block|}
name|pde_store
argument_list|(
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * After changing the page size for the specified virtual address in the page  * table, flush the corresponding entries from the processor's TLB.  Only the  * calling processor's TLB is affected.  *  * The calling thread must be pinned to a processor.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_update_pde_invalidate
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
block|{
name|pt_entry_t
name|PG_G
decl_stmt|;
if|if
condition|(
name|pmap_type_guest
argument_list|(
name|pmap
argument_list|)
condition|)
return|return;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_X86
argument_list|,
operator|(
literal|"pmap_update_pde_invalidate: invalid type %d"
operator|,
name|pmap
operator|->
name|pm_type
operator|)
argument_list|)
expr_stmt|;
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|newpde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
condition|)
comment|/* Demotion: flush a specific 2MB page mapping. */
name|invlpg
argument_list|(
name|va
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|newpde
operator|&
name|PG_G
operator|)
operator|==
literal|0
condition|)
comment|/* 		 * Promotion: flush every 4KB page mapping from the TLB 		 * because there are too many to flush individually. 		 */
name|invltlb
argument_list|()
expr_stmt|;
else|else
block|{
comment|/* 		 * Promotion: flush every 4KB page mapping from the TLB, 		 * including any global (PG_G) mappings. 		 */
name|invltlb_glob
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * For SMP, these functions have to use the IPI mechanism for coherence.  *  * N.B.: Before calling any of the following TLB invalidation functions,  * the calling processor must ensure that all stores updating a non-  * kernel page table are globally performed.  Otherwise, another  * processor could cache an old, pre-update entry without being  * invalidated.  This can happen one of two ways: (1) The pmap becomes  * active on another processor after its pm_active field is checked by  * one of the following functions but before a store updating the page  * table is globally performed. (2) The pmap becomes active on another  * processor before its pm_active field is checked but due to  * speculative loads one of the following functions stills reads the  * pmap as inactive on the other processor.  *   * The kernel page table is exempt because its pm_active field is  * immutable.  The kernel page table is always active on every  * processor.  */
end_comment

begin_comment
comment|/*  * Interrupt the cpus that are executing in the guest context.  * This will force the vcpu to exit and the cached EPT mappings  * will be invalidated by the host before the next vmresume.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_invalidate_ept
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|int
name|ipinum
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|CPU_ISSET
argument_list|(
name|curcpu
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
argument_list|,
operator|(
literal|"pmap_invalidate_ept: absurd pm_active"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * The TLB mappings associated with a vcpu context are not 	 * flushed each time a different vcpu is chosen to execute. 	 * 	 * This is in contrast with a process's vtop mappings that 	 * are flushed from the TLB on each context switch. 	 * 	 * Therefore we need to do more than just a TLB shootdown on 	 * the active cpus in 'pmap->pm_active'. To do this we keep 	 * track of the number of invalidations performed on this pmap. 	 * 	 * Each vcpu keeps a cache of this counter and compares it 	 * just before a vmresume. If the counter is out-of-date an 	 * invept will be done to flush stale mappings from the TLB. 	 */
name|atomic_add_acq_long
argument_list|(
operator|&
name|pmap
operator|->
name|pm_eptgen
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * Force the vcpu to exit and trap back into the hypervisor. 	 */
name|ipinum
operator|=
name|pmap
operator|->
name|pm_flags
operator|&
name|PMAP_NESTED_IPIMASK
expr_stmt|;
name|ipi_selected
argument_list|(
name|pmap
operator|->
name|pm_active
argument_list|,
name|ipinum
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_invalidate_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|cpuset_t
modifier|*
name|mask
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|,
name|i
decl_stmt|;
if|if
condition|(
name|pmap_type_guest
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pmap_invalidate_ept
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_X86
argument_list|,
operator|(
literal|"pmap_invalidate_page: invalid type %d"
operator|,
name|pmap
operator|->
name|pm_type
operator|)
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|invlpg
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|mask
operator|=
operator|&
name|all_cpus
expr_stmt|;
block|}
else|else
block|{
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
condition|)
name|invlpg
argument_list|(
name|va
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|pmap_pcid_enabled
condition|)
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|pmap_pcid_enabled
condition|)
block|{
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
block|{
if|if
condition|(
name|cpuid
operator|!=
name|i
condition|)
name|pmap
operator|->
name|pm_pcids
index|[
name|i
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
block|}
name|mask
operator|=
operator|&
name|pmap
operator|->
name|pm_active
expr_stmt|;
block|}
name|smp_masked_invlpg
argument_list|(
operator|*
name|mask
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/* 4k PTEs -- Chosen to exceed the total size of Broadwell L2 TLB */
end_comment

begin_define
define|#
directive|define
name|PMAP_INVLPG_THRESHOLD
value|(4 * 1024 * PAGE_SIZE)
end_define

begin_function
name|void
name|pmap_invalidate_range
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|cpuset_t
modifier|*
name|mask
decl_stmt|;
name|vm_offset_t
name|addr
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|,
name|i
decl_stmt|;
if|if
condition|(
name|eva
operator|-
name|sva
operator|>=
name|PMAP_INVLPG_THRESHOLD
condition|)
block|{
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|pmap_type_guest
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pmap_invalidate_ept
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_X86
argument_list|,
operator|(
literal|"pmap_invalidate_range: invalid type %d"
operator|,
name|pmap
operator|->
name|pm_type
operator|)
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
for|for
control|(
name|addr
operator|=
name|sva
init|;
name|addr
operator|<
name|eva
condition|;
name|addr
operator|+=
name|PAGE_SIZE
control|)
name|invlpg
argument_list|(
name|addr
argument_list|)
expr_stmt|;
name|mask
operator|=
operator|&
name|all_cpus
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|pmap
operator|==
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
condition|)
block|{
for|for
control|(
name|addr
operator|=
name|sva
init|;
name|addr
operator|<
name|eva
condition|;
name|addr
operator|+=
name|PAGE_SIZE
control|)
name|invlpg
argument_list|(
name|addr
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pmap_pcid_enabled
condition|)
block|{
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|pmap_pcid_enabled
condition|)
block|{
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
block|{
if|if
condition|(
name|cpuid
operator|!=
name|i
condition|)
name|pmap
operator|->
name|pm_pcids
index|[
name|i
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
block|}
name|mask
operator|=
operator|&
name|pmap
operator|->
name|pm_active
expr_stmt|;
block|}
name|smp_masked_invlpg_range
argument_list|(
operator|*
name|mask
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_invalidate_all
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|cpuset_t
modifier|*
name|mask
decl_stmt|;
name|struct
name|invpcid_descr
name|d
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|,
name|i
decl_stmt|;
if|if
condition|(
name|pmap_type_guest
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pmap_invalidate_ept
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_X86
argument_list|,
operator|(
literal|"pmap_invalidate_all: invalid type %d"
operator|,
name|pmap
operator|->
name|pm_type
operator|)
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
if|if
condition|(
name|pmap_pcid_enabled
operator|&&
name|invpcid_works
condition|)
block|{
name|bzero
argument_list|(
operator|&
name|d
argument_list|,
sizeof|sizeof
argument_list|(
name|d
argument_list|)
argument_list|)
expr_stmt|;
name|invpcid
argument_list|(
operator|&
name|d
argument_list|,
name|INVPCID_CTXGLOB
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|invltlb_glob
argument_list|()
expr_stmt|;
block|}
name|mask
operator|=
operator|&
name|all_cpus
expr_stmt|;
block|}
else|else
block|{
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
condition|)
block|{
if|if
condition|(
name|pmap_pcid_enabled
condition|)
block|{
if|if
condition|(
name|invpcid_works
condition|)
block|{
name|d
operator|.
name|pcid
operator|=
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_pcid
expr_stmt|;
name|d
operator|.
name|pad
operator|=
literal|0
expr_stmt|;
name|d
operator|.
name|addr
operator|=
literal|0
expr_stmt|;
name|invpcid
argument_list|(
operator|&
name|d
argument_list|,
name|INVPCID_CTX
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|load_cr3
argument_list|(
name|pmap
operator|->
name|pm_cr3
operator||
name|pmap
operator|->
name|pm_pcids
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
operator|.
name|pm_pcid
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|invltlb
argument_list|()
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|pmap_pcid_enabled
condition|)
block|{
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|pmap_pcid_enabled
condition|)
block|{
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
block|{
if|if
condition|(
name|cpuid
operator|!=
name|i
condition|)
name|pmap
operator|->
name|pm_pcids
index|[
name|i
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
block|}
name|mask
operator|=
operator|&
name|pmap
operator|->
name|pm_active
expr_stmt|;
block|}
name|smp_masked_invltlb
argument_list|(
operator|*
name|mask
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_invalidate_cache
parameter_list|(
name|void
parameter_list|)
block|{
name|sched_pin
argument_list|()
expr_stmt|;
name|wbinvd
argument_list|()
expr_stmt|;
name|smp_cache_flush
argument_list|()
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_struct
struct|struct
name|pde_action
block|{
name|cpuset_t
name|invalidate
decl_stmt|;
comment|/* processors that invalidate their TLB */
name|pmap_t
name|pmap
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pd_entry_t
name|newpde
decl_stmt|;
name|u_int
name|store
decl_stmt|;
comment|/* processor that updates the PDE */
block|}
struct|;
end_struct

begin_function
specifier|static
name|void
name|pmap_update_pde_action
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|struct
name|pde_action
modifier|*
name|act
init|=
name|arg
decl_stmt|;
if|if
condition|(
name|act
operator|->
name|store
operator|==
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
name|pmap_update_pde_store
argument_list|(
name|act
operator|->
name|pmap
argument_list|,
name|act
operator|->
name|pde
argument_list|,
name|act
operator|->
name|newpde
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_update_pde_teardown
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|struct
name|pde_action
modifier|*
name|act
init|=
name|arg
decl_stmt|;
if|if
condition|(
name|CPU_ISSET
argument_list|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|,
operator|&
name|act
operator|->
name|invalidate
argument_list|)
condition|)
name|pmap_update_pde_invalidate
argument_list|(
name|act
operator|->
name|pmap
argument_list|,
name|act
operator|->
name|va
argument_list|,
name|act
operator|->
name|newpde
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Change the page size for the specified virtual address in a way that  * prevents any possibility of the TLB ever having two entries that map the  * same virtual address using different page sizes.  This is the recommended  * workaround for Erratum 383 on AMD Family 10h processors.  It prevents a  * machine check exception for a TLB state that is improperly diagnosed as a  * hardware error.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_update_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
block|{
name|struct
name|pde_action
name|act
decl_stmt|;
name|cpuset_t
name|active
decl_stmt|,
name|other_cpus
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|other_cpus
operator|=
name|all_cpus
expr_stmt|;
name|CPU_CLR
argument_list|(
name|cpuid
argument_list|,
operator|&
name|other_cpus
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
name|pmap_type_guest
argument_list|(
name|pmap
argument_list|)
condition|)
name|active
operator|=
name|all_cpus
expr_stmt|;
else|else
block|{
name|active
operator|=
name|pmap
operator|->
name|pm_active
expr_stmt|;
block|}
if|if
condition|(
name|CPU_OVERLAP
argument_list|(
operator|&
name|active
argument_list|,
operator|&
name|other_cpus
argument_list|)
condition|)
block|{
name|act
operator|.
name|store
operator|=
name|cpuid
expr_stmt|;
name|act
operator|.
name|invalidate
operator|=
name|active
expr_stmt|;
name|act
operator|.
name|va
operator|=
name|va
expr_stmt|;
name|act
operator|.
name|pmap
operator|=
name|pmap
expr_stmt|;
name|act
operator|.
name|pde
operator|=
name|pde
expr_stmt|;
name|act
operator|.
name|newpde
operator|=
name|newpde
expr_stmt|;
name|CPU_SET
argument_list|(
name|cpuid
argument_list|,
operator|&
name|active
argument_list|)
expr_stmt|;
name|smp_rendezvous_cpus
argument_list|(
name|active
argument_list|,
name|smp_no_rendezvous_barrier
argument_list|,
name|pmap_update_pde_action
argument_list|,
name|pmap_update_pde_teardown
argument_list|,
operator|&
name|act
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pmap_update_pde_store
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
if|if
condition|(
name|CPU_ISSET
argument_list|(
name|cpuid
argument_list|,
operator|&
name|active
argument_list|)
condition|)
name|pmap_update_pde_invalidate
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* !SMP */
end_comment

begin_comment
comment|/*  * Normal, non-SMP, invalidation functions.  */
end_comment

begin_function
name|void
name|pmap_invalidate_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
if|if
condition|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_RVI
operator|||
name|pmap
operator|->
name|pm_type
operator|==
name|PT_EPT
condition|)
block|{
name|pmap
operator|->
name|pm_eptgen
operator|++
expr_stmt|;
return|return;
block|}
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_X86
argument_list|,
operator|(
literal|"pmap_invalidate_range: unknown type %d"
operator|,
name|pmap
operator|->
name|pm_type
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
name|pmap
operator|==
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
condition|)
name|invlpg
argument_list|(
name|va
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|pmap_pcid_enabled
condition|)
name|pmap
operator|->
name|pm_pcids
index|[
literal|0
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_invalidate_range
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|vm_offset_t
name|addr
decl_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_RVI
operator|||
name|pmap
operator|->
name|pm_type
operator|==
name|PT_EPT
condition|)
block|{
name|pmap
operator|->
name|pm_eptgen
operator|++
expr_stmt|;
return|return;
block|}
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_X86
argument_list|,
operator|(
literal|"pmap_invalidate_range: unknown type %d"
operator|,
name|pmap
operator|->
name|pm_type
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
name|pmap
operator|==
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
condition|)
block|{
for|for
control|(
name|addr
operator|=
name|sva
init|;
name|addr
operator|<
name|eva
condition|;
name|addr
operator|+=
name|PAGE_SIZE
control|)
name|invlpg
argument_list|(
name|addr
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pmap_pcid_enabled
condition|)
block|{
name|pmap
operator|->
name|pm_pcids
index|[
literal|0
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|pmap_invalidate_all
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|struct
name|invpcid_descr
name|d
decl_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_RVI
operator|||
name|pmap
operator|->
name|pm_type
operator|==
name|PT_EPT
condition|)
block|{
name|pmap
operator|->
name|pm_eptgen
operator|++
expr_stmt|;
return|return;
block|}
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_X86
argument_list|,
operator|(
literal|"pmap_invalidate_all: unknown type %d"
operator|,
name|pmap
operator|->
name|pm_type
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
if|if
condition|(
name|pmap_pcid_enabled
operator|&&
name|invpcid_works
condition|)
block|{
name|bzero
argument_list|(
operator|&
name|d
argument_list|,
sizeof|sizeof
argument_list|(
name|d
argument_list|)
argument_list|)
expr_stmt|;
name|invpcid
argument_list|(
operator|&
name|d
argument_list|,
name|INVPCID_CTXGLOB
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|invltlb_glob
argument_list|()
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|pmap
operator|==
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
condition|)
block|{
if|if
condition|(
name|pmap_pcid_enabled
condition|)
block|{
if|if
condition|(
name|invpcid_works
condition|)
block|{
name|d
operator|.
name|pcid
operator|=
name|pmap
operator|->
name|pm_pcids
index|[
literal|0
index|]
operator|.
name|pm_pcid
expr_stmt|;
name|d
operator|.
name|pad
operator|=
literal|0
expr_stmt|;
name|d
operator|.
name|addr
operator|=
literal|0
expr_stmt|;
name|invpcid
argument_list|(
operator|&
name|d
argument_list|,
name|INVPCID_CTX
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|load_cr3
argument_list|(
name|pmap
operator|->
name|pm_cr3
operator||
name|pmap
operator|->
name|pm_pcids
index|[
literal|0
index|]
operator|.
name|pm_pcid
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|invltlb
argument_list|()
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|pmap_pcid_enabled
condition|)
block|{
name|pmap
operator|->
name|pm_pcids
index|[
literal|0
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
block|}
end_function

begin_function
name|PMAP_INLINE
name|void
name|pmap_invalidate_cache
parameter_list|(
name|void
parameter_list|)
block|{
name|wbinvd
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_update_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
block|{
name|pmap_update_pde_store
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
name|pmap
operator|==
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
condition|)
name|pmap_update_pde_invalidate
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
else|else
name|pmap
operator|->
name|pm_pcids
index|[
literal|0
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* !SMP */
end_comment

begin_function
specifier|static
name|void
name|pmap_invalidate_pde_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|pde
parameter_list|)
block|{
comment|/* 	 * When the PDE has PG_PROMOTED set, the 2MB page mapping was created 	 * by a promotion that did not invalidate the 512 4KB page mappings 	 * that might exist in the TLB.  Consequently, at this point, the TLB 	 * may hold both 4KB and 2MB page mappings for the address range [va, 	 * va + NBPDR).  Therefore, the entire range must be invalidated here. 	 * In contrast, when PG_PROMOTED is clear, the TLB will not hold any 	 * 4KB page mappings for the address range [va, va + NBPDR), and so a 	 * single INVLPG suffices to invalidate the 2MB page mapping from the 	 * TLB. 	 */
if|if
condition|(
operator|(
name|pde
operator|&
name|PG_PROMOTED
operator|)
operator|!=
literal|0
condition|)
name|pmap_invalidate_range
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|va
operator|+
name|NBPDR
operator|-
literal|1
argument_list|)
expr_stmt|;
else|else
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_define
define|#
directive|define
name|PMAP_CLFLUSH_THRESHOLD
value|(2 * 1024 * 1024)
end_define

begin_function
name|void
name|pmap_invalidate_cache_range
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|boolean_t
name|force
parameter_list|)
block|{
if|if
condition|(
name|force
condition|)
block|{
name|sva
operator|&=
operator|~
call|(
name|vm_offset_t
call|)
argument_list|(
name|cpu_clflush_line_size
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
operator|(
name|sva
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_invalidate_cache_range: sva not page-aligned"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|eva
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_invalidate_cache_range: eva not page-aligned"
operator|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|cpu_feature
operator|&
name|CPUID_SS
operator|)
operator|!=
literal|0
operator|&&
operator|!
name|force
condition|)
empty_stmt|;
comment|/* If "Self Snoop" is supported and allowed, do nothing. */
elseif|else
if|if
condition|(
operator|(
name|cpu_stdext_feature
operator|&
name|CPUID_STDEXT_CLFLUSHOPT
operator|)
operator|!=
literal|0
operator|&&
name|eva
operator|-
name|sva
operator|<
name|PMAP_CLFLUSH_THRESHOLD
condition|)
block|{
comment|/* 		 * XXX: Some CPUs fault, hang, or trash the local APIC 		 * registers if we use CLFLUSH on the local APIC 		 * range.  The local APIC is always uncached, so we 		 * don't need to flush for that range anyway. 		 */
if|if
condition|(
name|pmap_kextract
argument_list|(
name|sva
argument_list|)
operator|==
name|lapic_paddr
condition|)
return|return;
comment|/* 		 * Otherwise, do per-cache line flush.  Use the sfence 		 * instruction to insure that previous stores are 		 * included in the write-back.  The processor 		 * propagates flush to other processors in the cache 		 * coherence domain. 		 */
name|sfence
argument_list|()
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|+=
name|cpu_clflush_line_size
control|)
name|clflushopt
argument_list|(
name|sva
argument_list|)
expr_stmt|;
name|sfence
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|cpu_feature
operator|&
name|CPUID_CLFSH
operator|)
operator|!=
literal|0
operator|&&
name|eva
operator|-
name|sva
operator|<
name|PMAP_CLFLUSH_THRESHOLD
condition|)
block|{
if|if
condition|(
name|pmap_kextract
argument_list|(
name|sva
argument_list|)
operator|==
name|lapic_paddr
condition|)
return|return;
comment|/* 		 * Writes are ordered by CLFLUSH on Intel CPUs. 		 */
if|if
condition|(
name|cpu_vendor_id
operator|!=
name|CPU_VENDOR_INTEL
condition|)
name|mfence
argument_list|()
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|+=
name|cpu_clflush_line_size
control|)
name|clflush
argument_list|(
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu_vendor_id
operator|!=
name|CPU_VENDOR_INTEL
condition|)
name|mfence
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * No targeted cache flush methods are supported by CPU, 		 * or the supplied range is bigger than 2MB. 		 * Globally invalidate cache. 		 */
name|pmap_invalidate_cache
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Remove the specified set of pages from the data and instruction caches.  *  * In contrast to pmap_invalidate_cache_range(), this function does not  * rely on the CPU's self-snoop feature, because it is intended for use  * when moving pages into a different cache domain.  */
end_comment

begin_function
name|void
name|pmap_invalidate_cache_pages
parameter_list|(
name|vm_page_t
modifier|*
name|pages
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|vm_offset_t
name|daddr
decl_stmt|,
name|eva
decl_stmt|;
name|int
name|i
decl_stmt|;
name|bool
name|useclflushopt
decl_stmt|;
name|useclflushopt
operator|=
operator|(
name|cpu_stdext_feature
operator|&
name|CPUID_STDEXT_CLFLUSHOPT
operator|)
operator|!=
literal|0
expr_stmt|;
if|if
condition|(
name|count
operator|>=
name|PMAP_CLFLUSH_THRESHOLD
operator|/
name|PAGE_SIZE
operator|||
operator|(
operator|(
name|cpu_feature
operator|&
name|CPUID_CLFSH
operator|)
operator|==
literal|0
operator|&&
operator|!
name|useclflushopt
operator|)
condition|)
name|pmap_invalidate_cache
argument_list|()
expr_stmt|;
else|else
block|{
if|if
condition|(
name|useclflushopt
condition|)
name|sfence
argument_list|()
expr_stmt|;
elseif|else
if|if
condition|(
name|cpu_vendor_id
operator|!=
name|CPU_VENDOR_INTEL
condition|)
name|mfence
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|daddr
operator|=
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|pages
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|eva
operator|=
name|daddr
operator|+
name|PAGE_SIZE
expr_stmt|;
for|for
control|(
init|;
name|daddr
operator|<
name|eva
condition|;
name|daddr
operator|+=
name|cpu_clflush_line_size
control|)
block|{
if|if
condition|(
name|useclflushopt
condition|)
name|clflushopt
argument_list|(
name|daddr
argument_list|)
expr_stmt|;
else|else
name|clflush
argument_list|(
name|daddr
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|useclflushopt
condition|)
name|sfence
argument_list|()
expr_stmt|;
elseif|else
if|if
condition|(
name|cpu_vendor_id
operator|!=
name|CPU_VENDOR_INTEL
condition|)
name|mfence
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	Routine:	pmap_extract  *	Function:  *		Extract the physical page address associated  *		with the given map/virtual_address pair.  */
end_comment

begin_function
name|vm_paddr_t
name|pmap_extract
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pdpe
operator|=
name|pmap_pdpe
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pdpe
operator|!=
name|NULL
operator|&&
operator|(
operator|*
name|pdpe
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
name|pa
operator|=
operator|(
operator|*
name|pdpe
operator|&
name|PG_PS_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PDPMASK
operator|)
expr_stmt|;
else|else
block|{
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
name|pa
operator|=
operator|(
operator|*
name|pde
operator|&
name|PG_PS_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PDRMASK
operator|)
expr_stmt|;
block|}
else|else
block|{
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pa
operator|=
operator|(
operator|*
name|pte
operator|&
name|PG_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Routine:	pmap_extract_and_hold  *	Function:  *		Atomically extract and hold the physical page  *		with the given pmap and virtual address pair  *		if that mapping permits the given protection.  */
end_comment

begin_function
name|vm_page_t
name|pmap_extract_and_hold
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|pd_entry_t
name|pde
decl_stmt|,
modifier|*
name|pdep
decl_stmt|;
name|pt_entry_t
name|pte
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|pdep
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pdep
operator|!=
name|NULL
operator|&&
operator|(
name|pde
operator|=
operator|*
name|pdep
operator|)
condition|)
block|{
if|if
condition|(
name|pde
operator|&
name|PG_PS
condition|)
block|{
if|if
condition|(
operator|(
name|pde
operator|&
name|PG_RW
operator|)
operator|||
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
operator|(
name|pde
operator|&
name|PG_PS_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PDRMASK
operator|)
argument_list|,
operator|&
name|pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|(
name|pde
operator|&
name|PG_PS_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PDRMASK
operator|)
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|pte
operator|=
operator|*
name|pmap_pde_to_pte
argument_list|(
name|pdep
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|&
name|PG_V
operator|)
operator|&&
operator|(
operator|(
name|pte
operator|&
name|PG_RW
operator|)
operator|||
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
operator|)
condition|)
block|{
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|pte
operator|&
name|PG_FRAME
argument_list|,
operator|&
name|pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|PA_UNLOCK_COND
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
name|vm_paddr_t
name|pmap_kextract
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
name|pde
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
if|if
condition|(
name|va
operator|>=
name|DMAP_MIN_ADDRESS
operator|&&
name|va
operator|<
name|DMAP_MAX_ADDRESS
condition|)
block|{
name|pa
operator|=
name|DMAP_TO_PHYS
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pde
operator|=
operator|*
name|vtopde
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pde
operator|&
name|PG_PS
condition|)
block|{
name|pa
operator|=
operator|(
name|pde
operator|&
name|PG_PS_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PDRMASK
operator|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * Beware of a concurrent promotion that changes the 			 * PDE at this point!  For example, vtopte() must not 			 * be used to access the PTE because it would use the 			 * new PDE.  It is, however, safe to use the old PDE 			 * because the page table page is preserved by the 			 * promotion. 			 */
name|pa
operator|=
operator|*
name|pmap_pde_to_pte
argument_list|(
operator|&
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pa
operator|=
operator|(
name|pa
operator|&
name|PG_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
block|}
block|}
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/***************************************************  * Low level mapping routines.....  ***************************************************/
end_comment

begin_comment
comment|/*  * Add a wired page to the kva.  * Note: not SMP coherent.  */
end_comment

begin_function
name|PMAP_INLINE
name|void
name|pmap_kenter
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte_store
argument_list|(
name|pte
argument_list|,
name|pa
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|X86_PG_G
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pmap_kenter_attr
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|int
name|mode
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|int
name|cache_bits
decl_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|cache_bits
operator|=
name|pmap_cache_bits
argument_list|(
name|kernel_pmap
argument_list|,
name|mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|pte_store
argument_list|(
name|pte
argument_list|,
name|pa
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|X86_PG_G
operator||
name|cache_bits
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove a page from the kernel pagetables.  * Note: not SMP coherent.  */
end_comment

begin_function
name|PMAP_INLINE
name|void
name|pmap_kremove
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte_clear
argument_list|(
name|pte
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Used to map a range of physical addresses into kernel  *	virtual address space.  *  *	The value passed in '*virt' is a suggested virtual address for  *	the mapping. Architectures which can support a direct-mapped  *	physical to virtual region can return the appropriate address  *	within that region, leaving '*virt' unchanged. Other  *	architectures should map the pages starting at '*virt' and  *	update '*virt' with the first usable address after the mapped  *	region.  */
end_comment

begin_function
name|vm_offset_t
name|pmap_map
parameter_list|(
name|vm_offset_t
modifier|*
name|virt
parameter_list|,
name|vm_paddr_t
name|start
parameter_list|,
name|vm_paddr_t
name|end
parameter_list|,
name|int
name|prot
parameter_list|)
block|{
return|return
name|PHYS_TO_DMAP
argument_list|(
name|start
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/*  * Add a list of wired pages to the kva  * this routine is only used for temporary  * kernel mappings that do not need to have  * page modification or references recorded.  * Note that old mappings are simply written  * over.  The page *must* be wired.  * Note: SMP coherent.  Uses a ranged shootdown IPI.  */
end_comment

begin_function
name|void
name|pmap_qenter
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|endpte
decl_stmt|,
name|oldpte
decl_stmt|,
name|pa
decl_stmt|,
modifier|*
name|pte
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|cache_bits
decl_stmt|;
name|oldpte
operator|=
literal|0
expr_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|sva
argument_list|)
expr_stmt|;
name|endpte
operator|=
name|pte
operator|+
name|count
expr_stmt|;
while|while
condition|(
name|pte
operator|<
name|endpte
condition|)
block|{
name|m
operator|=
operator|*
name|ma
operator|++
expr_stmt|;
name|cache_bits
operator|=
name|pmap_cache_bits
argument_list|(
name|kernel_pmap
argument_list|,
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|cache_bits
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_FRAME
operator||
name|X86_PG_PTE_CACHE
operator|)
operator|)
operator|!=
name|pa
condition|)
block|{
name|oldpte
operator||=
operator|*
name|pte
expr_stmt|;
name|pte_store
argument_list|(
name|pte
argument_list|,
name|pa
operator||
name|X86_PG_G
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
argument_list|)
expr_stmt|;
block|}
name|pte
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|__predict_false
argument_list|(
operator|(
name|oldpte
operator|&
name|X86_PG_V
operator|)
operator|!=
literal|0
argument_list|)
condition|)
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|sva
operator|+
name|count
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine tears out page mappings from the  * kernel -- it is meant only for temporary mappings.  * Note: SMP coherent.  Uses a ranged shootdown IPI.  */
end_comment

begin_function
name|void
name|pmap_qremove
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|va
operator|>=
name|VM_MIN_KERNEL_ADDRESS
argument_list|,
operator|(
literal|"usermode va %lx"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
name|pmap_kremove
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/***************************************************  * Page table page management routines.....  ***************************************************/
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_free_zero_pages
parameter_list|(
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
while|while
condition|(
operator|(
name|m
operator|=
name|SLIST_FIRST
argument_list|(
name|free
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|SLIST_REMOVE_HEAD
argument_list|(
name|free
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
comment|/* Preserve the page's PG_ZERO setting. */
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Schedule the specified unused page table page to be freed.  Specifically,  * add the page to the specified list of pages that will be released to the  * physical memory manager after the TLB has been updated.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_add_delayed_free_list
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|boolean_t
name|set_PG_ZERO
parameter_list|)
block|{
if|if
condition|(
name|set_PG_ZERO
condition|)
name|m
operator|->
name|flags
operator||=
name|PG_ZERO
expr_stmt|;
else|else
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|SLIST_INSERT_HEAD
argument_list|(
name|free
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Inserts the specified page table page into the specified pmap's collection  * of idle page table pages.  Each of a pmap's page table pages is responsible  * for mapping a distinct range of virtual addresses.  The pmap's collection is  * ordered by this virtual address range.  */
end_comment

begin_function
specifier|static
name|__inline
name|int
name|pmap_insert_pt_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|mpte
parameter_list|)
block|{
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
name|vm_radix_insert
argument_list|(
operator|&
name|pmap
operator|->
name|pm_root
argument_list|,
name|mpte
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Removes the page table page mapping the specified virtual address from the  * specified pmap's collection of idle page table pages, and returns it.  * Otherwise, returns NULL if there is no page table page corresponding to the  * specified virtual address.  */
end_comment

begin_function
specifier|static
name|__inline
name|vm_page_t
name|pmap_remove_pt_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
name|vm_radix_remove
argument_list|(
operator|&
name|pmap
operator|->
name|pm_root
argument_list|,
name|pmap_pde_pindex
argument_list|(
name|va
argument_list|)
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Decrements a page table page's wire count, which is used to record the  * number of valid page table entries within the page.  If the wire count  * drops to zero, then the page table page is unmapped.  Returns TRUE if the  * page table page was unmapped and FALSE otherwise.  */
end_comment

begin_function
specifier|static
specifier|inline
name|boolean_t
name|pmap_unwire_ptp
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
operator|--
name|m
operator|->
name|wire_count
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|_pmap_unwire_ptp
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|free
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|_pmap_unwire_ptp
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * unmap the page table page 	 */
if|if
condition|(
name|m
operator|->
name|pindex
operator|>=
operator|(
name|NUPDE
operator|+
name|NUPDPE
operator|)
condition|)
block|{
comment|/* PDP page */
name|pml4_entry_t
modifier|*
name|pml4
decl_stmt|;
name|pml4
operator|=
name|pmap_pml4e
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
operator|*
name|pml4
operator|=
literal|0
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|m
operator|->
name|pindex
operator|>=
name|NUPDE
condition|)
block|{
comment|/* PD page */
name|pdp_entry_t
modifier|*
name|pdp
decl_stmt|;
name|pdp
operator|=
name|pmap_pdpe
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
operator|*
name|pdp
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
comment|/* PTE page */
name|pd_entry_t
modifier|*
name|pd
decl_stmt|;
name|pd
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
operator|*
name|pd
operator|=
literal|0
expr_stmt|;
block|}
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|pindex
operator|<
name|NUPDE
condition|)
block|{
comment|/* We just released a PT, unhold the matching PD */
name|vm_page_t
name|pdpg
decl_stmt|;
name|pdpg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pmap_pdpe
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|pmap_unwire_ptp
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pdpg
argument_list|,
name|free
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|m
operator|->
name|pindex
operator|>=
name|NUPDE
operator|&&
name|m
operator|->
name|pindex
operator|<
operator|(
name|NUPDE
operator|+
name|NUPDPE
operator|)
condition|)
block|{
comment|/* We just released a PD, unhold the matching PDP */
name|vm_page_t
name|pdppg
decl_stmt|;
name|pdppg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pmap_pml4e
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|pmap_unwire_ptp
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pdppg
argument_list|,
name|free
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * This is a release store so that the ordinary store unmapping 	 * the page table page is globally performed before TLB shoot- 	 * down is begun. 	 */
name|atomic_subtract_rel_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/*  	 * Put page on a list so that it is released after 	 * *ALL* TLB shootdown is done 	 */
name|pmap_add_delayed_free_list
argument_list|(
name|m
argument_list|,
name|free
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * After removing a page table entry, this routine is used to  * conditionally free the page, and manage the hold/wire counts.  */
end_comment

begin_function
specifier|static
name|int
name|pmap_unuse_pt
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|ptepde
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|vm_page_t
name|mpte
decl_stmt|;
if|if
condition|(
name|va
operator|>=
name|VM_MAXUSER_ADDRESS
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|KASSERT
argument_list|(
name|ptepde
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_unuse_pt: ptepde != 0"
operator|)
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|ptepde
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
return|return
operator|(
name|pmap_unwire_ptp
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|mpte
argument_list|,
name|free
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_pinit0
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|PMAP_LOCK_INIT
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_pml4
operator|=
operator|(
name|pml4_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|KPML4phys
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_cr3
operator|=
name|KPML4phys
expr_stmt|;
name|pmap
operator|->
name|pm_root
operator|.
name|rt_root
operator|=
literal|0
expr_stmt|;
name|CPU_ZERO
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pmap
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
name|pmap
operator|->
name|pm_stats
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_flags
operator|=
name|pmap_flags
expr_stmt|;
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
block|{
name|pmap
operator|->
name|pm_pcids
index|[
name|i
index|]
operator|.
name|pm_pcid
operator|=
name|PMAP_PCID_NONE
expr_stmt|;
name|pmap
operator|->
name|pm_pcids
index|[
name|i
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|kernel_pmap
argument_list|)
expr_stmt|;
name|pmap_activate
argument_list|(
name|curthread
argument_list|)
expr_stmt|;
name|CPU_FILL
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_pinit_pml4
parameter_list|(
name|vm_page_t
name|pml4pg
parameter_list|)
block|{
name|pml4_entry_t
modifier|*
name|pm_pml4
decl_stmt|;
name|int
name|i
decl_stmt|;
name|pm_pml4
operator|=
operator|(
name|pml4_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|pml4pg
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Wire in kernel global address entries. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NKPML4E
condition|;
name|i
operator|++
control|)
block|{
name|pm_pml4
index|[
name|KPML4BASE
operator|+
name|i
index|]
operator|=
operator|(
name|KPDPphys
operator|+
name|ptoa
argument_list|(
name|i
argument_list|)
operator|)
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|PG_U
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|ndmpdpphys
condition|;
name|i
operator|++
control|)
block|{
name|pm_pml4
index|[
name|DMPML4I
operator|+
name|i
index|]
operator|=
operator|(
name|DMPDPphys
operator|+
name|ptoa
argument_list|(
name|i
argument_list|)
operator|)
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|PG_U
expr_stmt|;
block|}
comment|/* install self-referential address mapping entry(s) */
name|pm_pml4
index|[
name|PML4PML4I
index|]
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|pml4pg
argument_list|)
operator||
name|X86_PG_V
operator||
name|X86_PG_RW
operator||
name|X86_PG_A
operator||
name|X86_PG_M
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Initialize a preallocated and zeroed pmap structure,  * such as one in a vmspace structure.  */
end_comment

begin_function
name|int
name|pmap_pinit_type
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|enum
name|pmap_type
name|pm_type
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|vm_page_t
name|pml4pg
decl_stmt|;
name|vm_paddr_t
name|pml4phys
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * allocate the page directory page 	 */
while|while
condition|(
operator|(
name|pml4pg
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
operator|)
operator|==
name|NULL
condition|)
name|VM_WAIT
expr_stmt|;
name|pml4phys
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|pml4pg
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_pml4
operator|=
operator|(
name|pml4_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|pml4phys
argument_list|)
expr_stmt|;
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
block|{
name|pmap
operator|->
name|pm_pcids
index|[
name|i
index|]
operator|.
name|pm_pcid
operator|=
name|PMAP_PCID_NONE
expr_stmt|;
name|pmap
operator|->
name|pm_pcids
index|[
name|i
index|]
operator|.
name|pm_gen
operator|=
literal|0
expr_stmt|;
block|}
name|pmap
operator|->
name|pm_cr3
operator|=
operator|~
literal|0
expr_stmt|;
comment|/* initialize to an invalid value */
if|if
condition|(
operator|(
name|pml4pg
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pagezero
argument_list|(
name|pmap
operator|->
name|pm_pml4
argument_list|)
expr_stmt|;
comment|/* 	 * Do not install the host kernel mappings in the nested page 	 * tables. These mappings are meaningless in the guest physical 	 * address space. 	 */
if|if
condition|(
operator|(
name|pmap
operator|->
name|pm_type
operator|=
name|pm_type
operator|)
operator|==
name|PT_X86
condition|)
block|{
name|pmap
operator|->
name|pm_cr3
operator|=
name|pml4phys
expr_stmt|;
name|pmap_pinit_pml4
argument_list|(
name|pml4pg
argument_list|)
expr_stmt|;
block|}
name|pmap
operator|->
name|pm_root
operator|.
name|rt_root
operator|=
literal|0
expr_stmt|;
name|CPU_ZERO
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pmap
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
name|pmap
operator|->
name|pm_stats
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_flags
operator|=
name|flags
expr_stmt|;
name|pmap
operator|->
name|pm_eptgen
operator|=
literal|0
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_function
name|int
name|pmap_pinit
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
return|return
operator|(
name|pmap_pinit_type
argument_list|(
name|pmap
argument_list|,
name|PT_X86
argument_list|,
name|pmap_flags
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This routine is called if the desired page table page does not exist.  *  * If page table page allocation fails, this routine may sleep before  * returning NULL.  It sleeps only if a lock pointer was given.  *  * Note: If a page allocation fails at page table level two or three,  * one or two pages may be held during the wait, only to be released  * afterwards.  This conservative approach is easily argued to avoid  * race conditions.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|_pmap_allocpte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_pindex_t
name|ptepindex
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|,
name|pdppg
decl_stmt|,
name|pdpg
decl_stmt|;
name|pt_entry_t
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate a page table page. 	 */
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|ptepindex
argument_list|,
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|lockp
operator|!=
name|NULL
condition|)
block|{
name|RELEASE_PV_LIST_LOCK
argument_list|(
name|lockp
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_ASSERT_NOT_IN_DI
argument_list|()
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Indicate the need to retry.  While waiting, the page table 		 * page may have been allocated. 		 */
return|return
operator|(
name|NULL
operator|)
return|;
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Map the pagetable page into the process address space, if 	 * it isn't already there. 	 */
if|if
condition|(
name|ptepindex
operator|>=
operator|(
name|NUPDE
operator|+
name|NUPDPE
operator|)
condition|)
block|{
name|pml4_entry_t
modifier|*
name|pml4
decl_stmt|;
name|vm_pindex_t
name|pml4index
decl_stmt|;
comment|/* Wire up a new PDPE page */
name|pml4index
operator|=
name|ptepindex
operator|-
operator|(
name|NUPDE
operator|+
name|NUPDPE
operator|)
expr_stmt|;
name|pml4
operator|=
operator|&
name|pmap
operator|->
name|pm_pml4
index|[
name|pml4index
index|]
expr_stmt|;
operator|*
name|pml4
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|PG_U
operator||
name|PG_RW
operator||
name|PG_V
operator||
name|PG_A
operator||
name|PG_M
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ptepindex
operator|>=
name|NUPDE
condition|)
block|{
name|vm_pindex_t
name|pml4index
decl_stmt|;
name|vm_pindex_t
name|pdpindex
decl_stmt|;
name|pml4_entry_t
modifier|*
name|pml4
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdp
decl_stmt|;
comment|/* Wire up a new PDE page */
name|pdpindex
operator|=
name|ptepindex
operator|-
name|NUPDE
expr_stmt|;
name|pml4index
operator|=
name|pdpindex
operator|>>
name|NPML4EPGSHIFT
expr_stmt|;
name|pml4
operator|=
operator|&
name|pmap
operator|->
name|pm_pml4
index|[
name|pml4index
index|]
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pml4
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* Have to allocate a new pdp, recurse */
if|if
condition|(
name|_pmap_allocpte
argument_list|(
name|pmap
argument_list|,
name|NUPDE
operator|+
name|NUPDPE
operator|+
name|pml4index
argument_list|,
name|lockp
argument_list|)
operator|==
name|NULL
condition|)
block|{
operator|--
name|m
operator|->
name|wire_count
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_free_zero
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
block|}
else|else
block|{
comment|/* Add reference to pdp page */
name|pdppg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pml4
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|pdppg
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
name|pdp
operator|=
operator|(
name|pdp_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
operator|*
name|pml4
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
comment|/* Now find the pdp page */
name|pdp
operator|=
operator|&
name|pdp
index|[
name|pdpindex
operator|&
operator|(
operator|(
literal|1ul
operator|<<
name|NPDPEPGSHIFT
operator|)
operator|-
literal|1
operator|)
index|]
expr_stmt|;
operator|*
name|pdp
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|PG_U
operator||
name|PG_RW
operator||
name|PG_V
operator||
name|PG_A
operator||
name|PG_M
expr_stmt|;
block|}
else|else
block|{
name|vm_pindex_t
name|pml4index
decl_stmt|;
name|vm_pindex_t
name|pdpindex
decl_stmt|;
name|pml4_entry_t
modifier|*
name|pml4
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdp
decl_stmt|;
name|pd_entry_t
modifier|*
name|pd
decl_stmt|;
comment|/* Wire up a new PTE page */
name|pdpindex
operator|=
name|ptepindex
operator|>>
name|NPDPEPGSHIFT
expr_stmt|;
name|pml4index
operator|=
name|pdpindex
operator|>>
name|NPML4EPGSHIFT
expr_stmt|;
comment|/* First, find the pdp and check that its valid. */
name|pml4
operator|=
operator|&
name|pmap
operator|->
name|pm_pml4
index|[
name|pml4index
index|]
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pml4
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* Have to allocate a new pd, recurse */
if|if
condition|(
name|_pmap_allocpte
argument_list|(
name|pmap
argument_list|,
name|NUPDE
operator|+
name|pdpindex
argument_list|,
name|lockp
argument_list|)
operator|==
name|NULL
condition|)
block|{
operator|--
name|m
operator|->
name|wire_count
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_free_zero
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|pdp
operator|=
operator|(
name|pdp_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
operator|*
name|pml4
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|pdp
operator|=
operator|&
name|pdp
index|[
name|pdpindex
operator|&
operator|(
operator|(
literal|1ul
operator|<<
name|NPDPEPGSHIFT
operator|)
operator|-
literal|1
operator|)
index|]
expr_stmt|;
block|}
else|else
block|{
name|pdp
operator|=
operator|(
name|pdp_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
operator|*
name|pml4
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|pdp
operator|=
operator|&
name|pdp
index|[
name|pdpindex
operator|&
operator|(
operator|(
literal|1ul
operator|<<
name|NPDPEPGSHIFT
operator|)
operator|-
literal|1
operator|)
index|]
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdp
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* Have to allocate a new pd, recurse */
if|if
condition|(
name|_pmap_allocpte
argument_list|(
name|pmap
argument_list|,
name|NUPDE
operator|+
name|pdpindex
argument_list|,
name|lockp
argument_list|)
operator|==
name|NULL
condition|)
block|{
operator|--
name|m
operator|->
name|wire_count
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_free_zero
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
block|}
else|else
block|{
comment|/* Add reference to the pd page */
name|pdpg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pdp
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|pdpg
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
block|}
name|pd
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
operator|*
name|pdp
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
comment|/* Now we know where the page directory page is */
name|pd
operator|=
operator|&
name|pd
index|[
name|ptepindex
operator|&
operator|(
operator|(
literal|1ul
operator|<<
name|NPDEPGSHIFT
operator|)
operator|-
literal|1
operator|)
index|]
expr_stmt|;
operator|*
name|pd
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|PG_U
operator||
name|PG_RW
operator||
name|PG_V
operator||
name|PG_A
operator||
name|PG_M
expr_stmt|;
block|}
name|pmap_resident_count_inc
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|vm_page_t
name|pmap_allocpde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|vm_pindex_t
name|pdpindex
decl_stmt|,
name|ptepindex
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_page_t
name|pdpg
decl_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|pdpe
operator|=
name|pmap_pdpe
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pdpe
operator|!=
name|NULL
operator|&&
operator|(
operator|*
name|pdpe
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* Add a reference to the pd page. */
name|pdpg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pdpe
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|pdpg
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* Allocate a pd page. */
name|ptepindex
operator|=
name|pmap_pde_pindex
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pdpindex
operator|=
name|ptepindex
operator|>>
name|NPDPEPGSHIFT
expr_stmt|;
name|pdpg
operator|=
name|_pmap_allocpte
argument_list|(
name|pmap
argument_list|,
name|NUPDE
operator|+
name|pdpindex
argument_list|,
name|lockp
argument_list|)
expr_stmt|;
if|if
condition|(
name|pdpg
operator|==
name|NULL
operator|&&
name|lockp
operator|!=
name|NULL
condition|)
goto|goto
name|retry
goto|;
block|}
return|return
operator|(
name|pdpg
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|vm_page_t
name|pmap_allocpte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|vm_pindex_t
name|ptepindex
decl_stmt|;
name|pd_entry_t
modifier|*
name|pd
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Calculate pagetable page index 	 */
name|ptepindex
operator|=
name|pmap_pde_pindex
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|retry
label|:
comment|/* 	 * Get the page directory entry 	 */
name|pd
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * This supports switching from a 2MB page to a 	 * normal 4K page. 	 */
if|if
condition|(
name|pd
operator|!=
name|NULL
operator|&&
operator|(
operator|*
name|pd
operator|&
operator|(
name|PG_PS
operator||
name|PG_V
operator|)
operator|)
operator|==
operator|(
name|PG_PS
operator||
name|PG_V
operator|)
condition|)
block|{
if|if
condition|(
operator|!
name|pmap_demote_pde_locked
argument_list|(
name|pmap
argument_list|,
name|pd
argument_list|,
name|va
argument_list|,
name|lockp
argument_list|)
condition|)
block|{
comment|/* 			 * Invalidation of the 2MB page mapping may have caused 			 * the deallocation of the underlying PD page. 			 */
name|pd
operator|=
name|NULL
expr_stmt|;
block|}
block|}
comment|/* 	 * If the page table page is mapped, we just increment the 	 * hold count, and activate it. 	 */
if|if
condition|(
name|pd
operator|!=
name|NULL
operator|&&
operator|(
operator|*
name|pd
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pd
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Here if the pte page isn't mapped, or if it has been 		 * deallocated. 		 */
name|m
operator|=
name|_pmap_allocpte
argument_list|(
name|pmap
argument_list|,
name|ptepindex
argument_list|,
name|lockp
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
operator|&&
name|lockp
operator|!=
name|NULL
condition|)
goto|goto
name|retry
goto|;
block|}
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/***************************************************  * Pmap allocation/deallocation routines.  ***************************************************/
end_comment

begin_comment
comment|/*  * Release any resources held by the given physical map.  * Called when a pmap initialized by pmap_pinit is being released.  * Should only be called if the map contains no valid mappings.  */
end_comment

begin_function
name|void
name|pmap_release
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_release: pmap resident count %ld != 0"
operator|,
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|vm_radix_is_empty
argument_list|(
operator|&
name|pmap
operator|->
name|pm_root
argument_list|)
argument_list|,
operator|(
literal|"pmap_release: pmap has reserved page table page(s)"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|CPU_EMPTY
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
argument_list|,
operator|(
literal|"releasing active pmap %p"
operator|,
name|pmap
operator|)
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|DMAP_TO_PHYS
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pmap
operator|->
name|pm_pml4
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NKPML4E
condition|;
name|i
operator|++
control|)
comment|/* KVA */
name|pmap
operator|->
name|pm_pml4
index|[
name|KPML4BASE
operator|+
name|i
index|]
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|ndmpdpphys
condition|;
name|i
operator|++
control|)
comment|/* Direct Map */
name|pmap
operator|->
name|pm_pml4
index|[
name|DMPML4I
operator|+
name|i
index|]
operator|=
literal|0
expr_stmt|;
name|pmap
operator|->
name|pm_pml4
index|[
name|PML4PML4I
index|]
operator|=
literal|0
expr_stmt|;
comment|/* Recursive Mapping */
name|m
operator|->
name|wire_count
operator|--
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_free_zero
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_escape
end_escape

begin_function
specifier|static
name|int
name|kvm_size
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|unsigned
name|long
name|ksize
init|=
name|VM_MAX_KERNEL_ADDRESS
operator|-
name|VM_MIN_KERNEL_ADDRESS
decl_stmt|;
return|return
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
operator|&
name|ksize
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
return|;
block|}
end_function

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|kvm_size
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|kvm_size
argument_list|,
literal|"LU"
argument_list|,
literal|"Size of KVM"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|kvm_free
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|unsigned
name|long
name|kfree
init|=
name|VM_MAX_KERNEL_ADDRESS
operator|-
name|kernel_vm_end
decl_stmt|;
return|return
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
operator|&
name|kfree
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
return|;
block|}
end_function

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|kvm_free
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|kvm_free
argument_list|,
literal|"LU"
argument_list|,
literal|"Amount of KVM free"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * grow the number of kernel page table entries, if needed  */
end_comment

begin_function
name|void
name|pmap_growkernel
parameter_list|(
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|vm_paddr_t
name|paddr
decl_stmt|;
name|vm_page_t
name|nkpg
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|,
name|newpdir
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|kernel_map
operator|->
name|system_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Return if "addr" is within the range of kernel page table pages 	 * that were preallocated during pmap bootstrap.  Moreover, leave 	 * "kernel_vm_end" and the kernel page table as they were. 	 * 	 * The correctness of this action is based on the following 	 * argument: vm_map_insert() allocates contiguous ranges of the 	 * kernel virtual address space.  It calls this function if a range 	 * ends after "kernel_vm_end".  If the kernel is mapped between 	 * "kernel_vm_end" and "addr", then the range cannot begin at 	 * "kernel_vm_end".  In fact, its beginning address cannot be less 	 * than the kernel.  Thus, there is no immediate need to allocate 	 * any new kernel page table pages between "kernel_vm_end" and 	 * "KERNBASE". 	 */
if|if
condition|(
name|KERNBASE
operator|<
name|addr
operator|&&
name|addr
operator|<=
name|KERNBASE
operator|+
name|nkpt
operator|*
name|NBPDR
condition|)
return|return;
name|addr
operator|=
name|roundup2
argument_list|(
name|addr
argument_list|,
name|NBPDR
argument_list|)
expr_stmt|;
if|if
condition|(
name|addr
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
name|addr
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
while|while
condition|(
name|kernel_vm_end
operator|<
name|addr
condition|)
block|{
name|pdpe
operator|=
name|pmap_pdpe
argument_list|(
name|kernel_pmap
argument_list|,
name|kernel_vm_end
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|X86_PG_V
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* We need a new PDP entry */
name|nkpg
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|kernel_vm_end
operator|>>
name|PDPSHIFT
argument_list|,
name|VM_ALLOC_INTERRUPT
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|nkpg
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_growkernel: no memory to grow kernel"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|nkpg
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|nkpg
argument_list|)
expr_stmt|;
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|nkpg
argument_list|)
expr_stmt|;
operator|*
name|pdpe
operator|=
call|(
name|pdp_entry_t
call|)
argument_list|(
name|paddr
operator||
name|X86_PG_V
operator||
name|X86_PG_RW
operator||
name|X86_PG_A
operator||
name|X86_PG_M
argument_list|)
expr_stmt|;
continue|continue;
comment|/* try again */
block|}
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|kernel_vm_end
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|X86_PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
name|kernel_vm_end
operator|=
operator|(
name|kernel_vm_end
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|kernel_vm_end
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
block|{
name|kernel_vm_end
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
break|break;
block|}
continue|continue;
block|}
name|nkpg
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|pmap_pde_pindex
argument_list|(
name|kernel_vm_end
argument_list|)
argument_list|,
name|VM_ALLOC_INTERRUPT
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|nkpg
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_growkernel: no memory to grow kernel"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|nkpg
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|nkpg
argument_list|)
expr_stmt|;
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|nkpg
argument_list|)
expr_stmt|;
name|newpdir
operator|=
name|paddr
operator||
name|X86_PG_V
operator||
name|X86_PG_RW
operator||
name|X86_PG_A
operator||
name|X86_PG_M
expr_stmt|;
name|pde_store
argument_list|(
name|pde
argument_list|,
name|newpdir
argument_list|)
expr_stmt|;
name|kernel_vm_end
operator|=
operator|(
name|kernel_vm_end
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|kernel_vm_end
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
block|{
name|kernel_vm_end
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
break|break;
block|}
block|}
block|}
end_function

begin_comment
comment|/***************************************************  * page management routines.  ***************************************************/
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|pv_chunk
argument_list|)
operator|==
name|PAGE_SIZE
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|_NPCM
operator|==
literal|3
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|_NPCPV
operator|==
literal|168
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
specifier|static
name|__inline
expr|struct
name|pv_chunk
operator|*
name|pv_to_chunk
argument_list|(
argument|pv_entry_t pv
argument_list|)
block|{
return|return
operator|(
operator|(
expr|struct
name|pv_chunk
operator|*
operator|)
operator|(
operator|(
name|uintptr_t
operator|)
name|pv
operator|&
operator|~
operator|(
name|uintptr_t
operator|)
name|PAGE_MASK
operator|)
operator|)
return|;
block|}
end_expr_stmt

begin_define
define|#
directive|define
name|PV_PMAP
parameter_list|(
name|pv
parameter_list|)
value|(pv_to_chunk(pv)->pc_pmap)
end_define

begin_define
define|#
directive|define
name|PC_FREE0
value|0xfffffffffffffffful
end_define

begin_define
define|#
directive|define
name|PC_FREE1
value|0xfffffffffffffffful
end_define

begin_define
define|#
directive|define
name|PC_FREE2
value|0x000000fffffffffful
end_define

begin_decl_stmt
specifier|static
specifier|const
name|uint64_t
name|pc_freemask
index|[
name|_NPCM
index|]
init|=
block|{
name|PC_FREE0
block|,
name|PC_FREE1
block|,
name|PC_FREE2
block|}
decl_stmt|;
end_decl_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|PV_STATS
end_ifdef

begin_decl_stmt
specifier|static
name|int
name|pc_chunk_count
decl_stmt|,
name|pc_chunk_allocs
decl_stmt|,
name|pc_chunk_frees
decl_stmt|,
name|pc_chunk_tryfail
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_count
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_count
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry chunks"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_allocs
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_allocs
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry chunks allocated"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_frees
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_frees
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry chunks frees"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_tryfail
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_tryfail
argument_list|,
literal|0
argument_list|,
literal|"Number of times tried to get a chunk page but failed."
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|pv_entry_frees
decl_stmt|,
name|pv_entry_allocs
decl_stmt|,
name|pv_entry_count
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|pv_entry_spare
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_frees
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_frees
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry frees"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_allocs
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_allocs
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry allocs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_count
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_count
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entries"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_spare
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_spare
argument_list|,
literal|0
argument_list|,
literal|"Current number of spare pv entries"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * We are in a serious low memory condition.  Resort to  * drastic measures to free some pages so we can allocate  * another pv entry chunk.  *  * Returns NULL if PV entries were reclaimed from the specified pmap.  *  * We do not, however, unmap 2mpages because subsequent accesses will  * allocate per-page pv entries until repromotion occurs, thereby  * exacerbating the shortage of free pv entries.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|reclaim_pv_chunk
parameter_list|(
name|pmap_t
name|locked_pmap
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|struct
name|pch
name|new_tail
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|tpte
decl_stmt|;
name|pt_entry_t
name|PG_G
decl_stmt|,
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|m_pc
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|uint64_t
name|inuse
decl_stmt|;
name|int
name|bit
decl_stmt|,
name|field
decl_stmt|,
name|freed
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|locked_pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|lockp
operator|!=
name|NULL
argument_list|,
operator|(
literal|"reclaim_pv_chunk: lockp is NULL"
operator|)
argument_list|)
expr_stmt|;
name|pmap
operator|=
name|NULL
expr_stmt|;
name|m_pc
operator|=
name|NULL
expr_stmt|;
name|PG_G
operator|=
name|PG_A
operator|=
name|PG_M
operator|=
name|PG_RW
operator|=
literal|0
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|new_tail
argument_list|)
expr_stmt|;
name|pmap_delayed_invl_started
argument_list|()
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|pc
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pv_chunks
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
name|SLIST_EMPTY
argument_list|(
operator|&
name|free
argument_list|)
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|pc
operator|->
name|pc_pmap
condition|)
block|{
if|if
condition|(
name|pmap
operator|!=
name|NULL
condition|)
block|{
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|locked_pmap
condition|)
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|pmap_delayed_invl_finished
argument_list|()
expr_stmt|;
name|pmap_delayed_invl_started
argument_list|()
expr_stmt|;
name|pmap
operator|=
name|pc
operator|->
name|pc_pmap
expr_stmt|;
comment|/* Avoid deadlock and lock recursion. */
if|if
condition|(
name|pmap
operator|>
name|locked_pmap
condition|)
block|{
name|RELEASE_PV_LIST_LOCK
argument_list|(
name|lockp
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pmap
operator|!=
name|locked_pmap
operator|&&
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pmap
operator|=
name|NULL
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|new_tail
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Destroy every non-wired, 4 KB page mapping in the chunk. 		 */
name|freed
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
for|for
control|(
name|inuse
operator|=
operator|~
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&
name|pc_freemask
index|[
name|field
index|]
init|;
name|inuse
operator|!=
literal|0
condition|;
name|inuse
operator|&=
operator|~
operator|(
literal|1UL
operator|<<
name|bit
operator|)
control|)
block|{
name|bit
operator|=
name|bsfq
argument_list|(
name|inuse
argument_list|)
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|field
operator|*
literal|64
operator|+
name|bit
index|]
expr_stmt|;
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
continue|continue;
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_W
operator|)
operator|!=
literal|0
condition|)
continue|continue;
name|tpte
operator|=
name|pte_load_clear
argument_list|(
name|pte
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_G
operator|)
operator|!=
literal|0
condition|)
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|tpte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_VM_PAGE
argument_list|(
name|lockp
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
block|{
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
block|}
name|pmap_delayed_invl_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
literal|1UL
operator|<<
name|bit
expr_stmt|;
name|pmap_unuse_pt
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
operator|*
name|pde
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
name|freed
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|freed
operator|==
literal|0
condition|)
block|{
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|new_tail
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* Every freed mapping is for a 4 KB page. */
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
name|freed
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_frees
argument_list|,
name|freed
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
name|freed
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_long
argument_list|(
operator|&
name|pv_entry_count
argument_list|,
name|freed
argument_list|)
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|==
name|PC_FREE0
operator|&&
name|pc
operator|->
name|pc_map
index|[
literal|1
index|]
operator|==
name|PC_FREE1
operator|&&
name|pc
operator|->
name|pc_map
index|[
literal|2
index|]
operator|==
name|PC_FREE2
condition|)
block|{
name|PV_STAT
argument_list|(
name|atomic_subtract_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
name|_NPCPV
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_int
argument_list|(
operator|&
name|pc_chunk_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pc_chunk_frees
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Entire chunk is free; return it. */
name|m_pc
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|DMAP_TO_PHYS
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
argument_list|)
expr_stmt|;
name|dump_drop_page
argument_list|(
name|m_pc
operator|->
name|phys_addr
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
break|break;
block|}
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|new_tail
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
comment|/* One freed pv entry in locked_pmap is sufficient. */
if|if
condition|(
name|pmap
operator|==
name|locked_pmap
condition|)
break|break;
block|}
name|TAILQ_CONCAT
argument_list|(
operator|&
name|pv_chunks
argument_list|,
operator|&
name|new_tail
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|NULL
condition|)
block|{
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|locked_pmap
condition|)
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|pmap_delayed_invl_finished
argument_list|()
expr_stmt|;
if|if
condition|(
name|m_pc
operator|==
name|NULL
operator|&&
operator|!
name|SLIST_EMPTY
argument_list|(
operator|&
name|free
argument_list|)
condition|)
block|{
name|m_pc
operator|=
name|SLIST_FIRST
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|SLIST_REMOVE_HEAD
argument_list|(
operator|&
name|free
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
comment|/* Recycle a freed page table page. */
name|m_pc
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
return|return
operator|(
name|m_pc
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * free the pv_entry back to the free list  */
end_comment

begin_function
specifier|static
name|void
name|free_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pv_entry_t
name|pv
parameter_list|)
block|{
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|int
name|idx
decl_stmt|,
name|field
decl_stmt|,
name|bit
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_frees
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_long
argument_list|(
operator|&
name|pv_entry_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|pc
operator|=
name|pv_to_chunk
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|idx
operator|=
name|pv
operator|-
operator|&
name|pc
operator|->
name|pc_pventry
index|[
literal|0
index|]
expr_stmt|;
name|field
operator|=
name|idx
operator|/
literal|64
expr_stmt|;
name|bit
operator|=
name|idx
operator|%
literal|64
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
literal|1ul
operator|<<
name|bit
expr_stmt|;
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|!=
name|PC_FREE0
operator|||
name|pc
operator|->
name|pc_map
index|[
literal|1
index|]
operator|!=
name|PC_FREE1
operator|||
name|pc
operator|->
name|pc_map
index|[
literal|2
index|]
operator|!=
name|PC_FREE2
condition|)
block|{
comment|/* 98% of the time, pc is already at the head of the list. */
if|if
condition|(
name|__predict_false
argument_list|(
name|pc
operator|!=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
argument_list|)
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|free_pv_chunk
argument_list|(
name|pc
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|free_pv_chunk
parameter_list|(
name|struct
name|pv_chunk
modifier|*
name|pc
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
name|_NPCPV
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_int
argument_list|(
operator|&
name|pc_chunk_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pc_chunk_frees
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
comment|/* entire chunk is free, return it */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|DMAP_TO_PHYS
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
argument_list|)
expr_stmt|;
name|dump_drop_page
argument_list|(
name|m
operator|->
name|phys_addr
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
name|PQ_NONE
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Returns a new PV entry, allocating a new PV chunk from the system when  * needed.  If this PV chunk allocation fails and a PV list lock pointer was  * given, a PV chunk is reclaimed from an arbitrary pmap.  Otherwise, NULL is  * returned.  *  * The given PV list lock may be released.  */
end_comment

begin_function
specifier|static
name|pv_entry_t
name|get_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|int
name|bit
decl_stmt|,
name|field
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_allocs
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|retry
label|:
name|pc
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
if|if
condition|(
name|pc
operator|!=
name|NULL
condition|)
block|{
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
condition|)
block|{
name|bit
operator|=
name|bsfq
argument_list|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|field
operator|<
name|_NPCM
condition|)
block|{
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|field
operator|*
literal|64
operator|+
name|bit
index|]
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&=
operator|~
operator|(
literal|1ul
operator|<<
name|bit
operator|)
expr_stmt|;
comment|/* If this was the last item, move it to tail */
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|==
literal|0
operator|&&
name|pc
operator|->
name|pc_map
index|[
literal|1
index|]
operator|==
literal|0
operator|&&
name|pc
operator|->
name|pc_map
index|[
literal|2
index|]
operator|==
literal|0
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
block|}
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
block|}
block|}
comment|/* No free items, allocate another chunk */
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|lockp
operator|==
name|NULL
condition|)
block|{
name|PV_STAT
argument_list|(
name|pc_chunk_tryfail
operator|++
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|m
operator|=
name|reclaim_pv_chunk
argument_list|(
name|pmap
argument_list|,
name|lockp
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
goto|goto
name|retry
goto|;
block|}
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pc_chunk_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pc_chunk_allocs
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|dump_add_page
argument_list|(
name|m
operator|->
name|phys_addr
argument_list|)
expr_stmt|;
name|pc
operator|=
operator|(
name|void
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|m
operator|->
name|phys_addr
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_pmap
operator|=
name|pmap
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|=
name|PC_FREE0
operator|&
operator|~
literal|1ul
expr_stmt|;
comment|/* preallocated bit 0 */
name|pc
operator|->
name|pc_map
index|[
literal|1
index|]
operator|=
name|PC_FREE1
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
literal|2
index|]
operator|=
name|PC_FREE2
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
literal|0
index|]
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
name|_NPCPV
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns the number of one bits within the given PV chunk map.  *  * The erratas for Intel processors state that "POPCNT Instruction May  * Take Longer to Execute Than Expected".  It is believed that the  * issue is the spurious dependency on the destination register.  * Provide a hint to the register rename logic that the destination  * value is overwritten, by clearing it, as suggested in the  * optimization manual.  It should be cheap for unaffected processors  * as well.  *  * Reference numbers for erratas are  * 4th Gen Core: HSD146  * 5th Gen Core: BDM85  * 6th Gen Core: SKL029  */
end_comment

begin_function
specifier|static
name|int
name|popcnt_pc_map_pq
parameter_list|(
name|uint64_t
modifier|*
name|map
parameter_list|)
block|{
name|u_long
name|result
decl_stmt|,
name|tmp
decl_stmt|;
asm|__asm __volatile("xorl %k0,%k0;popcntq %2,%0;"
literal|"xorl %k1,%k1;popcntq %3,%1;addl %k1,%k0;"
literal|"xorl %k1,%k1;popcntq %4,%1;addl %k1,%k0"
operator|:
literal|"=&r"
operator|(
name|result
operator|)
operator|,
literal|"=&r"
operator|(
name|tmp
operator|)
operator|:
literal|"m"
operator|(
name|map
index|[
literal|0
index|]
operator|)
operator|,
literal|"m"
operator|(
name|map
index|[
literal|1
index|]
operator|)
operator|,
literal|"m"
operator|(
name|map
index|[
literal|2
index|]
operator|)
block|)
function|;
end_function

begin_return
return|return
operator|(
name|result
operator|)
return|;
end_return

begin_comment
unit|}
comment|/*  * Ensure that the number of spare PV entries in the specified pmap meets or  * exceeds the given count, "needed".  *  * The given PV list lock may be released.  */
end_comment

begin_function
unit|static
name|void
name|reserve_pv_entries
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|int
name|needed
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|struct
name|pch
name|new_tail
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|int
name|avail
decl_stmt|,
name|free
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|lockp
operator|!=
name|NULL
argument_list|,
operator|(
literal|"reserve_pv_entries: lockp is NULL"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Newly allocated PV chunks must be stored in a private list until 	 * the required number of PV chunks have been allocated.  Otherwise, 	 * reclaim_pv_chunk() could recycle one of these chunks.  In 	 * contrast, these chunks must be added to the pmap upon allocation. 	 */
name|TAILQ_INIT
argument_list|(
operator|&
name|new_tail
argument_list|)
expr_stmt|;
name|retry
label|:
name|avail
operator|=
literal|0
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pc
argument_list|,
argument|&pmap->pm_pvchunk
argument_list|,
argument|pc_list
argument_list|)
block|{
ifndef|#
directive|ifndef
name|__POPCNT__
if|if
condition|(
operator|(
name|cpu_feature2
operator|&
name|CPUID2_POPCNT
operator|)
operator|==
literal|0
condition|)
name|bit_count
argument_list|(
operator|(
name|bitstr_t
operator|*
operator|)
name|pc
operator|->
name|pc_map
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|pc
operator|->
name|pc_map
argument_list|)
operator|*
name|NBBY
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
else|else
endif|#
directive|endif
name|free
operator|=
name|popcnt_pc_map_pq
argument_list|(
name|pc
operator|->
name|pc_map
argument_list|)
expr_stmt|;
if|if
condition|(
name|free
operator|==
literal|0
condition|)
break|break;
name|avail
operator|+=
name|free
expr_stmt|;
if|if
condition|(
name|avail
operator|>=
name|needed
condition|)
break|break;
block|}
for|for
control|(
init|;
name|avail
operator|<
name|needed
condition|;
name|avail
operator|+=
name|_NPCPV
control|)
block|{
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|m
operator|=
name|reclaim_pv_chunk
argument_list|(
name|pmap
argument_list|,
name|lockp
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
goto|goto
name|retry
goto|;
block|}
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pc_chunk_count
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pc_chunk_allocs
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|dump_add_page
argument_list|(
name|m
operator|->
name|phys_addr
argument_list|)
expr_stmt|;
name|pc
operator|=
operator|(
name|void
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|m
operator|->
name|phys_addr
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_pmap
operator|=
name|pmap
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|=
name|PC_FREE0
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
literal|1
index|]
operator|=
name|PC_FREE1
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
literal|2
index|]
operator|=
name|PC_FREE2
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|new_tail
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
name|_NPCPV
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|TAILQ_EMPTY
argument_list|(
operator|&
name|new_tail
argument_list|)
condition|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
name|TAILQ_CONCAT
argument_list|(
operator|&
name|pv_chunks
argument_list|,
operator|&
name|new_tail
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pv_chunks_mutex
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * First find and then remove the pv entry for the specified pmap and virtual  * address from the specified pv list.  Returns the pv entry if found and NULL  * otherwise.  This operation can be performed on pv lists for either 4KB or  * 2MB page mappings.  */
end_comment

begin_function
specifier|static
name|__inline
name|pv_entry_t
name|pmap_pvh_remove
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|&&
name|va
operator|==
name|pv
operator|->
name|pv_va
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|pvh
operator|->
name|pv_gen
operator|++
expr_stmt|;
break|break;
block|}
block|}
return|return
operator|(
name|pv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * After demotion from a 2MB page mapping to 512 4KB page mappings,  * destroy the pv entry for the 2MB page mapping and reinstantiate the pv  * entries for each of the 4KB page mappings.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_pv_demote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_offset_t
name|va_last
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|bit
decl_stmt|,
name|field
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pa
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_pv_demote_pde: pa is not 2mpage aligned"
operator|)
argument_list|)
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_PHYS
argument_list|(
name|lockp
argument_list|,
name|pa
argument_list|)
expr_stmt|;
comment|/* 	 * Transfer the 2mpage's pv entry for this mapping to the first 	 * page's pv list.  Once this transfer begins, the pv list lock 	 * must not be released until the last pv entry is reinstantiated. 	 */
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|va
operator|=
name|trunc_2mpage
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
name|pvh
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pv
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_pv_demote_pde: pv not found"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
comment|/* Instantiate the remaining NPTEPG - 1 pv entries. */
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_allocs
argument_list|,
name|NPTEPG
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|va_last
operator|=
name|va
operator|+
name|NBPDR
operator|-
name|PAGE_SIZE
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|pc
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|!=
literal|0
operator|||
name|pc
operator|->
name|pc_map
index|[
literal|1
index|]
operator|!=
literal|0
operator|||
name|pc
operator|->
name|pc_map
index|[
literal|2
index|]
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_pv_demote_pde: missing spare"
operator|)
argument_list|)
expr_stmt|;
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
while|while
condition|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
condition|)
block|{
name|bit
operator|=
name|bsfq
argument_list|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&=
operator|~
operator|(
literal|1ul
operator|<<
name|bit
operator|)
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|field
operator|*
literal|64
operator|+
name|bit
index|]
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|m
operator|++
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_pv_demote_pde: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
if|if
condition|(
name|va
operator|==
name|va_last
condition|)
goto|goto
name|out
goto|;
block|}
block|}
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
block|}
name|out
label|:
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|==
literal|0
operator|&&
name|pc
operator|->
name|pc_map
index|[
literal|1
index|]
operator|==
literal|0
operator|&&
name|pc
operator|->
name|pc_map
index|[
literal|2
index|]
operator|==
literal|0
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
block|}
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_count
argument_list|,
name|NPTEPG
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
name|NPTEPG
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * After promotion from 512 4KB page mappings to a single 2MB page mapping,  * replace the many pv entries for the 4KB page mappings by a single pv entry  * for the 2MB page mapping.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_pv_promote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_offset_t
name|va_last
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pa
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_pv_promote_pde: pa is not 2mpage aligned"
operator|)
argument_list|)
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_PHYS
argument_list|(
name|lockp
argument_list|,
name|pa
argument_list|)
expr_stmt|;
comment|/* 	 * Transfer the first page's pv entry for this mapping to the 2mpage's 	 * pv list.  Aside from avoiding the cost of a call to get_pv_entry(), 	 * a transfer avoids the possibility that get_pv_entry() calls 	 * reclaim_pv_chunk() and that reclaim_pv_chunk() removes one of the 	 * mappings that is being promoted. 	 */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|va
operator|=
name|trunc_2mpage
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pv
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_pv_promote_pde: pv not found"
operator|)
argument_list|)
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|pvh
operator|->
name|pv_gen
operator|++
expr_stmt|;
comment|/* Free the remaining NPTEPG - 1 pv entries. */
name|va_last
operator|=
name|va
operator|+
name|NBPDR
operator|-
name|PAGE_SIZE
expr_stmt|;
do|do
block|{
name|m
operator|++
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pmap_pvh_free
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|va
operator|<
name|va_last
condition|)
do|;
block|}
end_function

begin_comment
comment|/*  * First find and then destroy the pv entry for the specified pmap and virtual  * address.  This operation can be performed on pv lists for either 4KB or 2MB  * page mappings.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_pvh_free
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
name|pvh
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pv
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_pvh_free: pv not found"
operator|)
argument_list|)
expr_stmt|;
name|free_pv_entry
argument_list|(
name|pmap
argument_list|,
name|pv
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Conditionally create the PV entry for a 4KB page mapping if the required  * memory can be allocated without resorting to reclamation.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_try_insert_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* Pass NULL instead of the lock pointer to disable reclamation. */
if|if
condition|(
operator|(
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|NULL
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_VM_PAGE
argument_list|(
name|lockp
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Conditionally create the PV entry for a 2MB page mapping if the required  * memory can be allocated without resorting to reclamation.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_pv_insert_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* Pass NULL instead of the lock pointer to disable reclamation. */
if|if
condition|(
operator|(
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|NULL
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_PHYS
argument_list|(
name|lockp
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|pvh
operator|->
name|pv_gen
operator|++
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Fills a page table page with mappings to consecutive physical pages.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_fill_ptp
parameter_list|(
name|pt_entry_t
modifier|*
name|firstpte
parameter_list|,
name|pt_entry_t
name|newpte
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
for|for
control|(
name|pte
operator|=
name|firstpte
init|;
name|pte
operator|<
name|firstpte
operator|+
name|NPTEPG
condition|;
name|pte
operator|++
control|)
block|{
operator|*
name|pte
operator|=
name|newpte
expr_stmt|;
name|newpte
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Tries to demote a 2MB page mapping.  If demotion fails, the 2MB page  * mapping is invalidated.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_demote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|lock
operator|=
name|NULL
expr_stmt|;
name|rv
operator|=
name|pmap_demote_pde_locked
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|boolean_t
name|pmap_demote_pde_locked
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|pd_entry_t
name|newpde
decl_stmt|,
name|oldpde
decl_stmt|;
name|pt_entry_t
modifier|*
name|firstpte
decl_stmt|,
name|newpte
decl_stmt|;
name|pt_entry_t
name|PG_A
decl_stmt|,
name|PG_G
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_paddr_t
name|mptepa
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|vm_offset_t
name|sva
decl_stmt|;
name|int
name|PG_PTE_CACHE
decl_stmt|;
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_PTE_CACHE
operator|=
name|pmap_cache_mask
argument_list|(
name|pmap
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|oldpde
operator|=
operator|*
name|pde
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|oldpde
operator|&
operator|(
name|PG_PS
operator||
name|PG_V
operator|)
operator|)
operator|==
operator|(
name|PG_PS
operator||
name|PG_V
operator|)
argument_list|,
operator|(
literal|"pmap_demote_pde: oldpde is missing PG_PS and/or PG_V"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_A
operator|)
operator|==
literal|0
operator|||
operator|(
name|mpte
operator|=
name|pmap_remove_pt_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|oldpde
operator|&
name|PG_W
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_demote_pde: page table page for a wired mapping"
literal|" is missing"
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Invalidate the 2MB page mapping and return "failure" if the 		 * mapping was never accessed or the allocation of the new 		 * page table page fails.  If the 2MB page mapping belongs to 		 * the direct map region of the kernel's address space, then 		 * the page allocation request specifies the highest possible 		 * priority (VM_ALLOC_INTERRUPT).  Otherwise, the priority is 		 * normal.  Page table pages are preallocated for every other 		 * part of the kernel address space, so the direct map region 		 * is the only part of the kernel address space that must be 		 * handled here. 		 */
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_A
operator|)
operator|==
literal|0
operator|||
operator|(
name|mpte
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|pmap_pde_pindex
argument_list|(
name|va
argument_list|)
argument_list|,
operator|(
name|va
operator|>=
name|DMAP_MIN_ADDRESS
operator|&&
name|va
operator|<
name|DMAP_MAX_ADDRESS
condition|?
name|VM_ALLOC_INTERRUPT
else|:
name|VM_ALLOC_NORMAL
operator|)
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|sva
operator|=
name|trunc_2mpage
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pmap_remove_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|sva
argument_list|,
operator|&
name|free
argument_list|,
name|lockp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_G
operator|)
operator|==
literal|0
condition|)
name|pmap_invalidate_pde_page
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
name|oldpde
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_demote_pde: failure for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|pmap_resident_count_inc
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
name|mptepa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|mpte
argument_list|)
expr_stmt|;
name|firstpte
operator|=
operator|(
name|pt_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|mptepa
argument_list|)
expr_stmt|;
name|newpde
operator|=
name|mptepa
operator||
name|PG_M
operator||
name|PG_A
operator||
operator|(
name|oldpde
operator|&
name|PG_U
operator|)
operator||
name|PG_RW
operator||
name|PG_V
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|oldpde
operator|&
name|PG_A
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_demote_pde: oldpde is missing PG_A"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|oldpde
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|!=
name|PG_RW
argument_list|,
operator|(
literal|"pmap_demote_pde: oldpde is missing PG_M"
operator|)
argument_list|)
expr_stmt|;
name|newpte
operator|=
name|oldpde
operator|&
operator|~
name|PG_PS
expr_stmt|;
name|newpte
operator|=
name|pmap_swap_pat
argument_list|(
name|pmap
argument_list|,
name|newpte
argument_list|)
expr_stmt|;
comment|/* 	 * If the page table page is new, initialize it. 	 */
if|if
condition|(
name|mpte
operator|->
name|wire_count
operator|==
literal|1
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|=
name|NPTEPG
expr_stmt|;
name|pmap_fill_ptp
argument_list|(
name|firstpte
argument_list|,
name|newpte
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
operator|(
operator|*
name|firstpte
operator|&
name|PG_FRAME
operator|)
operator|==
operator|(
name|newpte
operator|&
name|PG_FRAME
operator|)
argument_list|,
operator|(
literal|"pmap_demote_pde: firstpte and newpte map different physical"
literal|" addresses"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the mapping has changed attributes, update the page table 	 * entries. 	 */
if|if
condition|(
operator|(
operator|*
name|firstpte
operator|&
name|PG_PTE_PROMOTE
operator|)
operator|!=
operator|(
name|newpte
operator|&
name|PG_PTE_PROMOTE
operator|)
condition|)
name|pmap_fill_ptp
argument_list|(
name|firstpte
argument_list|,
name|newpte
argument_list|)
expr_stmt|;
comment|/* 	 * The spare PV entries must be reserved prior to demoting the 	 * mapping, that is, prior to changing the PDE.  Otherwise, the state 	 * of the PDE and the PV lists will be inconsistent, which can result 	 * in reclaim_pv_chunk() attempting to remove a PV entry from the 	 * wrong PV list and pmap_pv_demote_pde() failing to find the expected 	 * PV entry for the 2MB page mapping that is being demoted. 	 */
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
name|reserve_pv_entries
argument_list|(
name|pmap
argument_list|,
name|NPTEPG
operator|-
literal|1
argument_list|,
name|lockp
argument_list|)
expr_stmt|;
comment|/* 	 * Demote the mapping.  This pmap is locked.  The old PDE has 	 * PG_A set.  If the old PDE has PG_RW set, it also has PG_M 	 * set.  Thus, there is no danger of a race with another 	 * processor changing the setting of PG_A and/or PG_M between 	 * the read above and the store below.  	 */
if|if
condition|(
name|workaround_erratum383
condition|)
name|pmap_update_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
else|else
name|pde_store
argument_list|(
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
comment|/* 	 * Invalidate a stale recursive mapping of the page table page. 	 */
if|if
condition|(
name|va
operator|>=
name|VM_MAXUSER_ADDRESS
condition|)
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|vtopte
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Demote the PV entry. 	 */
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
name|pmap_pv_demote_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|oldpde
operator|&
name|PG_PS_FRAME
argument_list|,
name|lockp
argument_list|)
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|pmap_pde_demotions
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_demote_pde: success for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * pmap_remove_kernel_pde: Remove a kernel superpage mapping.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_remove_kernel_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
name|newpde
decl_stmt|;
name|vm_paddr_t
name|mptepa
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
name|KASSERT
argument_list|(
name|pmap
operator|==
name|kernel_pmap
argument_list|,
operator|(
literal|"pmap %p is not kernel_pmap"
operator|,
name|pmap
operator|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|pmap_remove_pt_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_remove_kernel_pde: Missing pt page."
argument_list|)
expr_stmt|;
name|mptepa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|mpte
argument_list|)
expr_stmt|;
name|newpde
operator|=
name|mptepa
operator||
name|X86_PG_M
operator||
name|X86_PG_A
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
expr_stmt|;
comment|/* 	 * Initialize the page table page. 	 */
name|pagezero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|mptepa
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Demote the mapping. 	 */
if|if
condition|(
name|workaround_erratum383
condition|)
name|pmap_update_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
else|else
name|pde_store
argument_list|(
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
comment|/* 	 * Invalidate a stale recursive mapping of the page table page. 	 */
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|vtopte
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * pmap_remove_pde: do the things to unmap a superpage in a process  */
end_comment

begin_function
specifier|static
name|int
name|pmap_remove_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pdq
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pd_entry_t
name|oldpde
decl_stmt|;
name|vm_offset_t
name|eva
decl_stmt|,
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mpte
decl_stmt|;
name|pt_entry_t
name|PG_G
decl_stmt|,
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|;
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|sva
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_pde: sva is not 2mpage aligned"
operator|)
argument_list|)
expr_stmt|;
name|oldpde
operator|=
name|pte_load_clear
argument_list|(
name|pdq
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpde
operator|&
name|PG_W
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|-=
name|NBPDR
operator|/
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_G
operator|)
operator|!=
literal|0
condition|)
name|pmap_invalidate_pde_page
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|oldpde
argument_list|)
expr_stmt|;
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
name|NBPDR
operator|/
name|PAGE_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpde
operator|&
name|PG_MANAGED
condition|)
block|{
name|CHANGE_PV_LIST_LOCK_TO_PHYS
argument_list|(
name|lockp
argument_list|,
name|oldpde
operator|&
name|PG_PS_FRAME
argument_list|)
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|oldpde
operator|&
name|PG_PS_FRAME
argument_list|)
expr_stmt|;
name|pmap_pvh_free
argument_list|(
name|pvh
argument_list|,
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|eva
operator|=
name|sva
operator|+
name|NBPDR
expr_stmt|;
for|for
control|(
name|va
operator|=
name|sva
operator|,
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|oldpde
operator|&
name|PG_PS_FRAME
argument_list|)
init|;
name|va
operator|<
name|eva
condition|;
name|va
operator|+=
name|PAGE_SIZE
operator|,
name|m
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|oldpde
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpde
operator|&
name|PG_A
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|pmap_delayed_invl_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|pmap_remove_kernel_pde
argument_list|(
name|pmap
argument_list|,
name|pdq
argument_list|,
name|sva
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mpte
operator|=
name|pmap_remove_pt_page
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|->
name|wire_count
operator|==
name|NPTEPG
argument_list|,
operator|(
literal|"pmap_remove_pde: pte page wire count error"
operator|)
argument_list|)
expr_stmt|;
name|mpte
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
name|pmap_add_delayed_free_list
argument_list|(
name|mpte
argument_list|,
name|free
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|(
name|pmap_unuse_pt
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
operator|*
name|pmap_pdpe
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
argument_list|,
name|free
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * pmap_remove_pte: do the things to unmap a page in a process  */
end_comment

begin_function
specifier|static
name|int
name|pmap_remove_pte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt_entry_t
modifier|*
name|ptq
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|ptepde
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pt_entry_t
name|oldpte
decl_stmt|,
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|oldpte
operator|=
name|pte_load_clear
argument_list|(
name|ptq
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpte
operator|&
name|PG_W
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|-=
literal|1
expr_stmt|;
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpte
operator|&
name|PG_MANAGED
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|oldpte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|oldpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpte
operator|&
name|PG_A
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_VM_PAGE
argument_list|(
name|lockp
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|pmap_pvh_free
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
name|pmap_delayed_invl_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|pmap_unuse_pt
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|ptepde
argument_list|,
name|free
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Remove a single page from a process address space  */
end_comment

begin_function
specifier|static
name|void
name|pmap_remove_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_V
decl_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
return|return;
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
return|return;
name|lock
operator|=
name|NULL
expr_stmt|;
name|pmap_remove_pte
argument_list|(
name|pmap
argument_list|,
name|pte
argument_list|,
name|va
argument_list|,
operator|*
name|pde
argument_list|,
name|free
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Removes the specified range of addresses from the page table page.  */
end_comment

begin_function
specifier|static
name|bool
name|pmap_remove_ptes
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|pt_entry_t
name|PG_G
decl_stmt|,
modifier|*
name|pte
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|bool
name|anyvalid
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|anyvalid
operator|=
name|false
expr_stmt|;
name|va
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|eva
condition|;
name|pte
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
if|if
condition|(
operator|*
name|pte
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|va
operator|!=
name|eva
condition|)
block|{
name|pmap_invalidate_range
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|va
operator|=
name|eva
expr_stmt|;
block|}
continue|continue;
block|}
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_G
operator|)
operator|==
literal|0
condition|)
name|anyvalid
operator|=
name|true
expr_stmt|;
elseif|else
if|if
condition|(
name|va
operator|==
name|eva
condition|)
name|va
operator|=
name|sva
expr_stmt|;
if|if
condition|(
name|pmap_remove_pte
argument_list|(
name|pmap
argument_list|,
name|pte
argument_list|,
name|sva
argument_list|,
operator|*
name|pde
argument_list|,
name|free
argument_list|,
name|lockp
argument_list|)
condition|)
block|{
name|sva
operator|+=
name|PAGE_SIZE
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|va
operator|!=
name|eva
condition|)
name|pmap_invalidate_range
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|sva
argument_list|)
expr_stmt|;
return|return
operator|(
name|anyvalid
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Remove the given range of addresses from the specified map.  *  *	It is assumed that the start and end are properly  *	rounded to the page size.  */
end_comment

begin_function
name|void
name|pmap_remove
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|vm_offset_t
name|va_next
decl_stmt|;
name|pml4_entry_t
modifier|*
name|pml4e
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|pd_entry_t
name|ptpaddr
decl_stmt|,
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
name|PG_G
decl_stmt|,
name|PG_V
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|int
name|anyvalid
decl_stmt|;
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Perform an unsynchronized read.  This is, however, safe. 	 */
if|if
condition|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
condition|)
return|return;
name|anyvalid
operator|=
literal|0
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|pmap_delayed_invl_started
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * special handling of removing one page.  a very 	 * common operation and easy to short circuit some 	 * code. 	 */
if|if
condition|(
name|sva
operator|+
name|PAGE_SIZE
operator|==
name|eva
condition|)
block|{
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|pde
operator|&&
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_remove_page
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
name|pde
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
goto|goto
name|out
goto|;
block|}
block|}
name|lock
operator|=
name|NULL
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|va_next
control|)
block|{
if|if
condition|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
condition|)
break|break;
name|pml4e
operator|=
name|pmap_pml4e
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pml4e
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPML4
operator|)
operator|&
operator|~
name|PML4MASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
name|pdpe
operator|=
name|pmap_pml4e_to_pdpe
argument_list|(
name|pml4e
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPDP
operator|)
operator|&
operator|~
name|PDPMASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Calculate index for next page table. 		 */
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|ptpaddr
operator|=
operator|*
name|pde
expr_stmt|;
comment|/* 		 * Weed out invalid mappings. 		 */
if|if
condition|(
name|ptpaddr
operator|==
literal|0
condition|)
continue|continue;
comment|/* 		 * Check for large page. 		 */
if|if
condition|(
operator|(
name|ptpaddr
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * Are we removing the entire large page?  If not, 			 * demote the mapping and fall through. 			 */
if|if
condition|(
name|sva
operator|+
name|NBPDR
operator|==
name|va_next
operator|&&
name|eva
operator|>=
name|va_next
condition|)
block|{
comment|/* 				 * The TLB entry for a PG_G mapping is 				 * invalidated by pmap_remove_pde(). 				 */
if|if
condition|(
operator|(
name|ptpaddr
operator|&
name|PG_G
operator|)
operator|==
literal|0
condition|)
name|anyvalid
operator|=
literal|1
expr_stmt|;
name|pmap_remove_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|sva
argument_list|,
operator|&
name|free
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
continue|continue;
block|}
elseif|else
if|if
condition|(
operator|!
name|pmap_demote_pde_locked
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|sva
argument_list|,
operator|&
name|lock
argument_list|)
condition|)
block|{
comment|/* The large page mapping was destroyed. */
continue|continue;
block|}
else|else
name|ptpaddr
operator|=
operator|*
name|pde
expr_stmt|;
block|}
comment|/* 		 * Limit our scan to either the end of the va represented 		 * by the current page table page, or to the end of the 		 * range being removed. 		 */
if|if
condition|(
name|va_next
operator|>
name|eva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
if|if
condition|(
name|pmap_remove_ptes
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
name|va_next
argument_list|,
name|pde
argument_list|,
operator|&
name|free
argument_list|,
operator|&
name|lock
argument_list|)
condition|)
name|anyvalid
operator|=
literal|1
expr_stmt|;
block|}
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|out
label|:
if|if
condition|(
name|anyvalid
condition|)
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_delayed_invl_finished
argument_list|()
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Routine:	pmap_remove_all  *	Function:  *		Removes this physical page from  *		all physical maps in which it resides.  *		Reflects back modify bits to the pager.  *  *	Notes:  *		Original versions of this routine were very  *		inefficient because they iteratively called  *		pmap_remove (slow...)  */
end_comment

begin_function
name|void
name|pmap_remove_all
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|tpte
decl_stmt|,
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|int
name|pvh_gen
decl_stmt|,
name|md_gen
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_all: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pvh
operator|=
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|?
operator|&
name|pv_dummy
else|:
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|retry
label|:
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pvh_gen
operator|=
name|pvh
operator|->
name|pv_gen
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvh_gen
operator|!=
name|pvh
operator|->
name|pv_gen
condition|)
block|{
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
block|}
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|pmap_demote_pde_locked
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
while|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pvh_gen
operator|=
name|pvh
operator|->
name|pv_gen
expr_stmt|;
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvh_gen
operator|!=
name|pvh
operator|->
name|pv_gen
operator|||
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
condition|)
block|{
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
block|}
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_all: found"
literal|" a 2mpage in page %p's pv list"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|tpte
operator|=
name|pte_load_clear
argument_list|(
name|pte
argument_list|)
expr_stmt|;
if|if
condition|(
name|tpte
operator|&
name|PG_W
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
if|if
condition|(
name|tpte
operator|&
name|PG_A
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
comment|/* 		 * Update the vm_page_t clean and reference bits. 		 */
if|if
condition|(
operator|(
name|tpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_unuse_pt
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
operator|*
name|pde
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
name|free_pv_entry
argument_list|(
name|pmap
argument_list|,
name|pv
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|pmap_delayed_invl_wait
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * pmap_protect_pde: do the things to protect a 2mpage in a process  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_protect_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|pd_entry_t
name|newpde
decl_stmt|,
name|oldpde
decl_stmt|;
name|vm_offset_t
name|eva
decl_stmt|,
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|boolean_t
name|anychanged
decl_stmt|;
name|pt_entry_t
name|PG_G
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|;
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|sva
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_protect_pde: sva is not 2mpage aligned"
operator|)
argument_list|)
expr_stmt|;
name|anychanged
operator|=
name|FALSE
expr_stmt|;
name|retry
label|:
name|oldpde
operator|=
name|newpde
operator|=
operator|*
name|pde
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
operator|(
name|PG_MANAGED
operator||
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_MANAGED
operator||
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
name|eva
operator|=
name|sva
operator|+
name|NBPDR
expr_stmt|;
for|for
control|(
name|va
operator|=
name|sva
operator|,
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|oldpde
operator|&
name|PG_PS_FRAME
argument_list|)
init|;
name|va
operator|<
name|eva
condition|;
name|va
operator|+=
name|PAGE_SIZE
operator|,
name|m
operator|++
control|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
condition|)
name|newpde
operator|&=
operator|~
operator|(
name|PG_RW
operator||
name|PG_M
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|newpde
operator||=
name|pg_nx
expr_stmt|;
if|if
condition|(
name|newpde
operator|!=
name|oldpde
condition|)
block|{
comment|/* 		 * As an optimization to future operations on this PDE, clear 		 * PG_PROMOTED.  The impending invalidation will remove any 		 * lingering 4KB page mappings from the TLB. 		 */
if|if
condition|(
operator|!
name|atomic_cmpset_long
argument_list|(
name|pde
argument_list|,
name|oldpde
argument_list|,
name|newpde
operator|&
operator|~
name|PG_PROMOTED
argument_list|)
condition|)
goto|goto
name|retry
goto|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_G
operator|)
operator|!=
literal|0
condition|)
name|pmap_invalidate_pde_page
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|oldpde
argument_list|)
expr_stmt|;
else|else
name|anychanged
operator|=
name|TRUE
expr_stmt|;
block|}
return|return
operator|(
name|anychanged
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Set the physical protection on the  *	specified range of this map as requested.  */
end_comment

begin_function
name|void
name|pmap_protect
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|va_next
decl_stmt|;
name|pml4_entry_t
modifier|*
name|pml4e
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|pd_entry_t
name|ptpaddr
decl_stmt|,
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_G
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|boolean_t
name|anychanged
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|prot
operator|&
operator|~
name|VM_PROT_ALL
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"invalid prot %x"
operator|,
name|prot
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|prot
operator|==
name|VM_PROT_NONE
condition|)
block|{
name|pmap_remove
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|prot
operator|&
operator|(
name|VM_PROT_WRITE
operator||
name|VM_PROT_EXECUTE
operator|)
operator|)
operator|==
operator|(
name|VM_PROT_WRITE
operator||
name|VM_PROT_EXECUTE
operator|)
condition|)
return|return;
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|anychanged
operator|=
name|FALSE
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|va_next
control|)
block|{
name|pml4e
operator|=
name|pmap_pml4e
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pml4e
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPML4
operator|)
operator|&
operator|~
name|PML4MASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
name|pdpe
operator|=
name|pmap_pml4e_to_pdpe
argument_list|(
name|pml4e
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPDP
operator|)
operator|&
operator|~
name|PDPMASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|ptpaddr
operator|=
operator|*
name|pde
expr_stmt|;
comment|/* 		 * Weed out invalid mappings. 		 */
if|if
condition|(
name|ptpaddr
operator|==
literal|0
condition|)
continue|continue;
comment|/* 		 * Check for large page. 		 */
if|if
condition|(
operator|(
name|ptpaddr
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * Are we protecting the entire large page?  If not, 			 * demote the mapping and fall through. 			 */
if|if
condition|(
name|sva
operator|+
name|NBPDR
operator|==
name|va_next
operator|&&
name|eva
operator|>=
name|va_next
condition|)
block|{
comment|/* 				 * The TLB entry for a PG_G mapping is 				 * invalidated by pmap_protect_pde(). 				 */
if|if
condition|(
name|pmap_protect_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|sva
argument_list|,
name|prot
argument_list|)
condition|)
name|anychanged
operator|=
name|TRUE
expr_stmt|;
continue|continue;
block|}
elseif|else
if|if
condition|(
operator|!
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|sva
argument_list|)
condition|)
block|{
comment|/* 				 * The large page mapping was destroyed. 				 */
continue|continue;
block|}
block|}
if|if
condition|(
name|va_next
operator|>
name|eva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|va_next
condition|;
name|pte
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
name|pt_entry_t
name|obits
decl_stmt|,
name|pbits
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|retry
label|:
name|obits
operator|=
name|pbits
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|pbits
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|pbits
operator|&
operator|(
name|PG_MANAGED
operator||
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_MANAGED
operator||
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pbits
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|pbits
operator|&=
operator|~
operator|(
name|PG_RW
operator||
name|PG_M
operator|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|pbits
operator||=
name|pg_nx
expr_stmt|;
if|if
condition|(
name|pbits
operator|!=
name|obits
condition|)
block|{
if|if
condition|(
operator|!
name|atomic_cmpset_long
argument_list|(
name|pte
argument_list|,
name|obits
argument_list|,
name|pbits
argument_list|)
condition|)
goto|goto
name|retry
goto|;
if|if
condition|(
name|obits
operator|&
name|PG_G
condition|)
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
else|else
name|anychanged
operator|=
name|TRUE
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|anychanged
condition|)
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Tries to promote the 512, contiguous 4KB page mappings that are within a  * single page table page (PTP) to a single 2MB page mapping.  For promotion  * to occur, two conditions must be met: (1) the 4KB page mappings must map  * aligned, contiguous physical memory and (2) the 4KB page mappings must have  * identical characteristics.   */
end_comment

begin_function
specifier|static
name|void
name|pmap_promote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|pd_entry_t
name|newpde
decl_stmt|;
name|pt_entry_t
modifier|*
name|firstpte
decl_stmt|,
name|oldpte
decl_stmt|,
name|pa
decl_stmt|,
modifier|*
name|pte
decl_stmt|;
name|pt_entry_t
name|PG_G
decl_stmt|,
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
name|int
name|PG_PTE_CACHE
decl_stmt|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_PTE_CACHE
operator|=
name|pmap_cache_mask
argument_list|(
name|pmap
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Examine the first PTE in the specified PTP.  Abort if this PTE is 	 * either invalid, unused, or does not map the first 4KB physical page 	 * within a 2MB page.  	 */
name|firstpte
operator|=
operator|(
name|pt_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
operator|*
name|pde
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|setpde
label|:
name|newpde
operator|=
operator|*
name|firstpte
expr_stmt|;
if|if
condition|(
operator|(
name|newpde
operator|&
operator|(
operator|(
name|PG_FRAME
operator|&
name|PDRMASK
operator|)
operator||
name|PG_A
operator||
name|PG_V
operator|)
operator|)
operator|!=
operator|(
name|PG_A
operator||
name|PG_V
operator|)
condition|)
block|{
name|atomic_add_long
argument_list|(
operator|&
name|pmap_pde_p_failures
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: failure for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|newpde
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
name|PG_RW
condition|)
block|{
comment|/* 		 * When PG_M is already clear, PG_RW can be cleared without 		 * a TLB invalidation. 		 */
if|if
condition|(
operator|!
name|atomic_cmpset_long
argument_list|(
name|firstpte
argument_list|,
name|newpde
argument_list|,
name|newpde
operator|&
operator|~
name|PG_RW
argument_list|)
condition|)
goto|goto
name|setpde
goto|;
name|newpde
operator|&=
operator|~
name|PG_RW
expr_stmt|;
block|}
comment|/* 	 * Examine each of the other PTEs in the specified PTP.  Abort if this 	 * PTE maps an unexpected 4KB physical page or does not have identical 	 * characteristics to the first PTE. 	 */
name|pa
operator|=
operator|(
name|newpde
operator|&
operator|(
name|PG_PS_FRAME
operator||
name|PG_A
operator||
name|PG_V
operator|)
operator|)
operator|+
name|NBPDR
operator|-
name|PAGE_SIZE
expr_stmt|;
for|for
control|(
name|pte
operator|=
name|firstpte
operator|+
name|NPTEPG
operator|-
literal|1
init|;
name|pte
operator|>
name|firstpte
condition|;
name|pte
operator|--
control|)
block|{
name|setpte
label|:
name|oldpte
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|oldpte
operator|&
operator|(
name|PG_FRAME
operator||
name|PG_A
operator||
name|PG_V
operator|)
operator|)
operator|!=
name|pa
condition|)
block|{
name|atomic_add_long
argument_list|(
operator|&
name|pmap_pde_p_failures
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: failure for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|oldpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
name|PG_RW
condition|)
block|{
comment|/* 			 * When PG_M is already clear, PG_RW can be cleared 			 * without a TLB invalidation. 			 */
if|if
condition|(
operator|!
name|atomic_cmpset_long
argument_list|(
name|pte
argument_list|,
name|oldpte
argument_list|,
name|oldpte
operator|&
operator|~
name|PG_RW
argument_list|)
condition|)
goto|goto
name|setpte
goto|;
name|oldpte
operator|&=
operator|~
name|PG_RW
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: protect for va %#lx"
literal|" in pmap %p"
argument_list|,
operator|(
name|oldpte
operator|&
name|PG_FRAME
operator|&
name|PDRMASK
operator|)
operator||
operator|(
name|va
operator|&
operator|~
name|PDRMASK
operator|)
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|oldpte
operator|&
name|PG_PTE_PROMOTE
operator|)
operator|!=
operator|(
name|newpde
operator|&
name|PG_PTE_PROMOTE
operator|)
condition|)
block|{
name|atomic_add_long
argument_list|(
operator|&
name|pmap_pde_p_failures
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: failure for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
name|pa
operator|-=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* 	 * Save the page table page in its current state until the PDE 	 * mapping the superpage is demoted by pmap_demote_pde() or 	 * destroyed by pmap_remove_pde().  	 */
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pde
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|>=
name|vm_page_array
operator|&&
name|mpte
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"pmap_promote_pde: page table page is out of range"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|->
name|pindex
operator|==
name|pmap_pde_pindex
argument_list|(
name|va
argument_list|)
argument_list|,
operator|(
literal|"pmap_promote_pde: page table page's pindex is wrong"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_insert_pt_page
argument_list|(
name|pmap
argument_list|,
name|mpte
argument_list|)
condition|)
block|{
name|atomic_add_long
argument_list|(
operator|&
name|pmap_pde_p_failures
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: failure for va %#lx in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * Promote the pv entries. 	 */
if|if
condition|(
operator|(
name|newpde
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
name|pmap_pv_promote_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|newpde
operator|&
name|PG_PS_FRAME
argument_list|,
name|lockp
argument_list|)
expr_stmt|;
comment|/* 	 * Propagate the PAT index to its proper position. 	 */
name|newpde
operator|=
name|pmap_swap_pat
argument_list|(
name|pmap
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
comment|/* 	 * Map the superpage. 	 */
if|if
condition|(
name|workaround_erratum383
condition|)
name|pmap_update_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pde
argument_list|,
name|PG_PS
operator||
name|newpde
argument_list|)
expr_stmt|;
else|else
name|pde_store
argument_list|(
name|pde
argument_list|,
name|PG_PROMOTED
operator||
name|PG_PS
operator||
name|newpde
argument_list|)
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|pmap_pde_promotions
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: success for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Insert the given physical page (p) at  *	the specified virtual address (v) in the  *	target physical map with the protection requested.  *  *	If specified, the page will be wired down, meaning  *	that the related pte can not be reclaimed.  *  *	NB:  This is the only routine which MAY NOT lazy-evaluate  *	or lose information.  That is, this routine must actually  *	insert this page into the given map NOW.  *  *	When destroying both a page table and PV entry, this function  *	performs the TLB invalidation before releasing the PV list  *	lock, so we do not need pmap_delayed_invl_page() calls here.  */
end_comment

begin_function
name|int
name|pmap_enter
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|u_int
name|flags
parameter_list|,
name|int8_t
name|psind
name|__unused
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_G
decl_stmt|,
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|pt_entry_t
name|newpte
decl_stmt|,
name|origpte
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_paddr_t
name|opa
decl_stmt|,
name|pa
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|,
name|om
decl_stmt|;
name|int
name|rv
decl_stmt|;
name|boolean_t
name|nosleep
decl_stmt|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|va
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|va
operator|<=
name|VM_MAX_KERNEL_ADDRESS
argument_list|,
operator|(
literal|"pmap_enter: toobig"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|va
operator|<
name|UPT_MIN_ADDRESS
operator|||
name|va
operator|>=
name|UPT_MAX_ADDRESS
argument_list|,
operator|(
literal|"pmap_enter: invalid to pmap_enter page table pages (va: 0x%lx)"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
operator|||
name|va
operator|<
name|kmi
operator|.
name|clean_sva
operator|||
name|va
operator|>=
name|kmi
operator|.
name|clean_eva
argument_list|,
operator|(
literal|"pmap_enter: managed mapping within the clean submap"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|&&
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|newpte
operator|=
call|(
name|pt_entry_t
call|)
argument_list|(
name|pa
operator||
name|PG_A
operator||
name|PG_V
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|flags
operator|&
name|VM_PROT_WRITE
operator|)
operator|!=
literal|0
condition|)
name|newpte
operator||=
name|PG_M
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|!=
literal|0
condition|)
name|newpte
operator||=
name|PG_RW
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|newpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|!=
name|PG_M
argument_list|,
operator|(
literal|"pmap_enter: flags includes VM_PROT_WRITE but prot doesn't"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|newpte
operator||=
name|pg_nx
expr_stmt|;
if|if
condition|(
operator|(
name|flags
operator|&
name|PMAP_ENTER_WIRED
operator|)
operator|!=
literal|0
condition|)
name|newpte
operator||=
name|PG_W
expr_stmt|;
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|newpte
operator||=
name|PG_U
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|newpte
operator||=
name|PG_G
expr_stmt|;
name|newpte
operator||=
name|pmap_cache_bits
argument_list|(
name|pmap
argument_list|,
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * Set modified bit gratuitously for writeable mappings if 	 * the page is unmanaged. We do not want to take a fault 	 * to do the dirty bit accounting for these mappings. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|newpte
operator|&
name|PG_RW
operator|)
operator|!=
literal|0
condition|)
name|newpte
operator||=
name|PG_M
expr_stmt|;
block|}
else|else
name|newpte
operator||=
name|PG_MANAGED
expr_stmt|;
name|mpte
operator|=
name|NULL
expr_stmt|;
name|lock
operator|=
name|NULL
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * In the case that a page table page is not 	 * resident, we are creating it here. 	 */
name|retry
label|:
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pde
operator|!=
name|NULL
operator|&&
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|!=
literal|0
operator|&&
operator|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
operator|||
name|pmap_demote_pde_locked
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|,
operator|&
name|lock
argument_list|)
operator|)
condition|)
block|{
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
operator|&&
name|mpte
operator|==
name|NULL
condition|)
block|{
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pde
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|mpte
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
block|{
comment|/* 		 * Here if the pte page isn't mapped, or if it has been 		 * deallocated. 		 */
name|nosleep
operator|=
operator|(
name|flags
operator|&
name|PMAP_ENTER_NOSLEEP
operator|)
operator|!=
literal|0
expr_stmt|;
name|mpte
operator|=
name|_pmap_allocpte
argument_list|(
name|pmap
argument_list|,
name|pmap_pde_pindex
argument_list|(
name|va
argument_list|)
argument_list|,
name|nosleep
condition|?
name|NULL
else|:
operator|&
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|==
name|NULL
operator|&&
name|nosleep
condition|)
block|{
name|rv
operator|=
name|KERN_RESOURCE_SHORTAGE
expr_stmt|;
goto|goto
name|out
goto|;
block|}
goto|goto
name|retry
goto|;
block|}
else|else
name|panic
argument_list|(
literal|"pmap_enter: invalid page directory va=%#lx"
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|origpte
operator|=
operator|*
name|pte
expr_stmt|;
comment|/* 	 * Is the specified virtual address already mapped? 	 */
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * Wiring change, just update stats. We don't worry about 		 * wiring PT pages as they remain resident as long as there 		 * are valid mappings in them. Hence, if a user page is wired, 		 * the PT page will be also. 		 */
if|if
condition|(
operator|(
name|newpte
operator|&
name|PG_W
operator|)
operator|!=
literal|0
operator|&&
operator|(
name|origpte
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|newpte
operator|&
name|PG_W
operator|)
operator|==
literal|0
operator|&&
operator|(
name|origpte
operator|&
name|PG_W
operator|)
operator|!=
literal|0
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
comment|/* 		 * Remove the extra PT page reference. 		 */
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|--
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|->
name|wire_count
operator|>
literal|0
argument_list|,
operator|(
literal|"pmap_enter: missing reference to page table page,"
literal|" va: 0x%lx"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Has the physical page changed? 		 */
name|opa
operator|=
name|origpte
operator|&
name|PG_FRAME
expr_stmt|;
if|if
condition|(
name|opa
operator|==
name|pa
condition|)
block|{
comment|/* 			 * No, might be a protection or wiring change. 			 */
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
operator|&&
operator|(
name|newpte
operator|&
name|PG_RW
operator|)
operator|!=
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|origpte
operator|^
name|newpte
operator|)
operator|&
operator|~
operator|(
name|PG_M
operator||
name|PG_A
operator|)
operator|)
operator|==
literal|0
condition|)
goto|goto
name|unchanged
goto|;
goto|goto
name|validate
goto|;
block|}
block|}
else|else
block|{
comment|/* 		 * Increment the counters. 		 */
if|if
condition|(
operator|(
name|newpte
operator|&
name|PG_W
operator|)
operator|!=
literal|0
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
name|pmap_resident_count_inc
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Enter on the PV list if part of our managed memory. 	 */
if|if
condition|(
operator|(
name|newpte
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
block|{
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_PHYS
argument_list|(
operator|&
name|lock
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
if|if
condition|(
operator|(
name|newpte
operator|&
name|PG_RW
operator|)
operator|!=
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Update the PTE. 	 */
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
name|validate
label|:
name|origpte
operator|=
name|pte_load_store
argument_list|(
name|pte
argument_list|,
name|newpte
argument_list|)
expr_stmt|;
name|opa
operator|=
name|origpte
operator|&
name|PG_FRAME
expr_stmt|;
if|if
condition|(
name|opa
operator|!=
name|pa
condition|)
block|{
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
block|{
name|om
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|opa
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|origpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|om
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|om
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|CHANGE_PV_LIST_LOCK_TO_PHYS
argument_list|(
operator|&
name|lock
argument_list|,
name|opa
argument_list|)
expr_stmt|;
name|pmap_pvh_free
argument_list|(
operator|&
name|om
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|om
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|!=
literal|0
operator|&&
name|TAILQ_EMPTY
argument_list|(
operator|&
name|om
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
operator|(
name|om
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
operator|||
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pa_to_pvh
argument_list|(
name|opa
argument_list|)
operator|->
name|pv_list
argument_list|)
operator|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|om
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
operator|(
name|newpte
operator|&
name|PG_M
operator|)
operator|==
literal|0
operator|&&
operator|(
name|origpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 			 * Although the PTE may still have PG_RW set, TLB 			 * invalidation may nonetheless be required because 			 * the PTE no longer has PG_M set. 			 */
block|}
elseif|else
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_NX
operator|)
operator|!=
literal|0
operator|||
operator|(
name|newpte
operator|&
name|PG_NX
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 			 * This PTE change does not require TLB invalidation. 			 */
goto|goto
name|unchanged
goto|;
block|}
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
else|else
name|pte_store
argument_list|(
name|pte
argument_list|,
name|newpte
argument_list|)
expr_stmt|;
name|unchanged
label|:
comment|/* 	 * If both the page table page and the reservation are fully 	 * populated, then attempt promotion. 	 */
if|if
condition|(
operator|(
name|mpte
operator|==
name|NULL
operator|||
name|mpte
operator|->
name|wire_count
operator|==
name|NPTEPG
operator|)
operator|&&
name|pmap_ps_enabled
argument_list|(
name|pmap
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
name|vm_reserv_level_iffullpop
argument_list|(
name|m
argument_list|)
operator|==
literal|0
condition|)
name|pmap_promote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|rv
operator|=
name|KERN_SUCCESS
expr_stmt|;
name|out
label|:
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Tries to create a 2MB page mapping.  Returns TRUE if successful and FALSE  * otherwise.  Fails if (1) a page table page cannot be allocated without  * blocking, (2) a mapping already exists at the specified virtual address, or  * (3) a pv entry cannot be allocated without reclaiming another pv entry.   */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_enter_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|,
name|newpde
decl_stmt|;
name|pt_entry_t
name|PG_V
decl_stmt|;
name|vm_page_t
name|pdpg
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pdpg
operator|=
name|pmap_allocpde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|NULL
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_enter_pde: failure for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
name|pde
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|pdpg
argument_list|)
argument_list|)
expr_stmt|;
name|pde
operator|=
operator|&
name|pde
index|[
name|pmap_pde_index
argument_list|(
name|va
argument_list|)
index|]
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|pdpg
operator|->
name|wire_count
operator|>
literal|1
argument_list|,
operator|(
literal|"pmap_enter_pde: pdpg's wire count is too low"
operator|)
argument_list|)
expr_stmt|;
name|pdpg
operator|->
name|wire_count
operator|--
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_enter_pde: failure for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
name|newpde
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|pmap_cache_bits
argument_list|(
name|pmap
argument_list|,
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|1
argument_list|)
operator||
name|PG_PS
operator||
name|PG_V
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|newpde
operator||=
name|PG_MANAGED
expr_stmt|;
comment|/* 		 * Abort this mapping if its PV entry could not be created. 		 */
if|if
condition|(
operator|!
name|pmap_pv_insert_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|lockp
argument_list|)
condition|)
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_unwire_ptp
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pdpg
argument_list|,
operator|&
name|free
argument_list|)
condition|)
block|{
comment|/* 				 * Although "va" is not mapped, paging- 				 * structure caches could nonetheless have 				 * entries that refer to the freed page table 				 * pages.  Invalidate those entries. 				 */
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_enter_pde: failure for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
block|}
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|newpde
operator||=
name|pg_nx
expr_stmt|;
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|newpde
operator||=
name|PG_U
expr_stmt|;
comment|/* 	 * Increment counters. 	 */
name|pmap_resident_count_inc
argument_list|(
name|pmap
argument_list|,
name|NBPDR
operator|/
name|PAGE_SIZE
argument_list|)
expr_stmt|;
comment|/* 	 * Map the superpage.  (This is not a promoted mapping; there will not 	 * be any lingering 4KB page mappings in the TLB.) 	 */
name|pde_store
argument_list|(
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|pmap_pde_mappings
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_enter_pde: success for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Maps a sequence of resident pages belonging to the same object.  * The sequence begins with the given page m_start.  This page is  * mapped at the given virtual address start.  Each subsequent page is  * mapped at a virtual address that is offset from start by the same  * amount as the page is offset from m_start within the object.  The  * last page in the sequence is the page with the largest offset from  * m_start that can be mapped at a virtual address less than the given  * virtual address end.  Not every virtual page between start and end  * is mapped; only those for which a resident page exists with the  * corresponding offset from m_start are mapped.  */
end_comment

begin_function
name|void
name|pmap_enter_object
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|start
parameter_list|,
name|vm_offset_t
name|end
parameter_list|,
name|vm_page_t
name|m_start
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mpte
decl_stmt|;
name|vm_pindex_t
name|diff
decl_stmt|,
name|psize
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m_start
operator|->
name|object
argument_list|)
expr_stmt|;
name|psize
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|NULL
expr_stmt|;
name|m
operator|=
name|m_start
expr_stmt|;
name|lock
operator|=
name|NULL
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
while|while
condition|(
name|m
operator|!=
name|NULL
operator|&&
operator|(
name|diff
operator|=
name|m
operator|->
name|pindex
operator|-
name|m_start
operator|->
name|pindex
operator|)
operator|<
name|psize
condition|)
block|{
name|va
operator|=
name|start
operator|+
name|ptoa
argument_list|(
name|diff
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|va
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
operator|&&
name|va
operator|+
name|NBPDR
operator|<=
name|end
operator|&&
name|m
operator|->
name|psind
operator|==
literal|1
operator|&&
name|pmap_ps_enabled
argument_list|(
name|pmap
argument_list|)
operator|&&
name|pmap_enter_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
operator|&
name|lock
argument_list|)
condition|)
name|m
operator|=
operator|&
name|m
index|[
name|NBPDR
operator|/
name|PAGE_SIZE
operator|-
literal|1
index|]
expr_stmt|;
else|else
name|mpte
operator|=
name|pmap_enter_quick_locked
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
name|mpte
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|m
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * this code makes some *MAJOR* assumptions:  * 1. Current pmap& pmap exists.  * 2. Not wired.  * 3. Read access.  * 4. No page table pages.  * but is *MUCH* faster than pmap_enter...  */
end_comment

begin_function
name|void
name|pmap_enter_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|lock
operator|=
name|NULL
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|pmap_enter_quick_locked
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
name|NULL
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|vm_page_t
name|pmap_enter_quick_locked
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|vm_page_t
name|mpte
parameter_list|,
name|struct
name|rwlock
modifier|*
modifier|*
name|lockp
parameter_list|)
block|{
name|struct
name|spglist
name|free
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|KASSERT
argument_list|(
name|va
operator|<
name|kmi
operator|.
name|clean_sva
operator|||
name|va
operator|>=
name|kmi
operator|.
name|clean_eva
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_enter_quick_locked: managed mapping within the clean submap"
operator|)
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * In the case that a page table page is not 	 * resident, we are creating it here. 	 */
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
block|{
name|vm_pindex_t
name|ptepindex
decl_stmt|;
name|pd_entry_t
modifier|*
name|ptepa
decl_stmt|;
comment|/* 		 * Calculate pagetable page index 		 */
name|ptepindex
operator|=
name|pmap_pde_pindex
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|&&
operator|(
name|mpte
operator|->
name|pindex
operator|==
name|ptepindex
operator|)
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * Get the page directory entry 			 */
name|ptepa
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 			 * If the page table page is mapped, we just increment 			 * the hold count, and activate it.  Otherwise, we 			 * attempt to allocate a page table page.  If this 			 * attempt fails, we don't retry.  Instead, we give up. 			 */
if|if
condition|(
name|ptepa
operator|&&
operator|(
operator|*
name|ptepa
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|*
name|ptepa
operator|&
name|PG_PS
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|ptepa
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|mpte
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* 				 * Pass NULL instead of the PV list lock 				 * pointer, because we don't intend to sleep. 				 */
name|mpte
operator|=
name|_pmap_allocpte
argument_list|(
name|pmap
argument_list|,
name|ptepindex
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|==
name|NULL
condition|)
return|return
operator|(
name|mpte
operator|)
return|;
block|}
block|}
name|pte
operator|=
operator|(
name|pt_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|mpte
argument_list|)
argument_list|)
expr_stmt|;
name|pte
operator|=
operator|&
name|pte
index|[
name|pmap_pte_index
argument_list|(
name|va
argument_list|)
index|]
expr_stmt|;
block|}
else|else
block|{
name|mpte
operator|=
name|NULL
expr_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|*
name|pte
condition|)
block|{
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|--
expr_stmt|;
name|mpte
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|mpte
operator|)
return|;
block|}
comment|/* 	 * Enter on the PV list if part of our managed memory. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|&&
operator|!
name|pmap_try_insert_pv_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|lockp
argument_list|)
condition|)
block|{
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_unwire_ptp
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|mpte
argument_list|,
operator|&
name|free
argument_list|)
condition|)
block|{
comment|/* 				 * Although "va" is not mapped, paging- 				 * structure caches could nonetheless have 				 * entries that refer to the freed page table 				 * pages.  Invalidate those entries. 				 */
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
name|mpte
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|mpte
operator|)
return|;
block|}
comment|/* 	 * Increment counters 	 */
name|pmap_resident_count_inc
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|pmap_cache_bits
argument_list|(
name|pmap
argument_list|,
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|pa
operator||=
name|pg_nx
expr_stmt|;
comment|/* 	 * Now validate mapping with RO protection 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
name|pte_store
argument_list|(
name|pte
argument_list|,
name|pa
operator||
name|PG_V
operator||
name|PG_U
argument_list|)
expr_stmt|;
else|else
name|pte_store
argument_list|(
name|pte
argument_list|,
name|pa
operator||
name|PG_V
operator||
name|PG_U
operator||
name|PG_MANAGED
argument_list|)
expr_stmt|;
return|return
operator|(
name|mpte
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Make a temporary mapping for a physical address.  This is only intended  * to be used for panic dumps.  */
end_comment

begin_function
name|void
modifier|*
name|pmap_kenter_temporary
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|int
name|i
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|va
operator|=
operator|(
name|vm_offset_t
operator|)
name|crashdumpmap
operator|+
operator|(
name|i
operator|*
name|PAGE_SIZE
operator|)
expr_stmt|;
name|pmap_kenter
argument_list|(
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|invlpg
argument_list|(
name|va
argument_list|)
expr_stmt|;
return|return
operator|(
operator|(
name|void
operator|*
operator|)
name|crashdumpmap
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This code maps large physical mmap regions into the  * processor address space.  Note that some shortcuts  * are taken, but the code works.  */
end_comment

begin_function
name|void
name|pmap_object_init_pt
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|,
name|ptepa
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|,
name|pdpg
decl_stmt|;
name|int
name|pat_mode
decl_stmt|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|object
operator|->
name|type
operator|==
name|OBJT_DEVICE
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_SG
argument_list|,
operator|(
literal|"pmap_object_init_pt: non-device object"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|addr
operator|&
operator|(
name|NBPDR
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
operator|&&
operator|(
name|size
operator|&
operator|(
name|NBPDR
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|pmap_ps_enabled
argument_list|(
name|pmap
argument_list|)
condition|)
return|return;
if|if
condition|(
operator|!
name|vm_object_populate
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|pindex
operator|+
name|atop
argument_list|(
name|size
argument_list|)
argument_list|)
condition|)
return|return;
name|p
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|p
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
argument_list|,
operator|(
literal|"pmap_object_init_pt: invalid page %p"
operator|,
name|p
operator|)
argument_list|)
expr_stmt|;
name|pat_mode
operator|=
name|p
operator|->
name|md
operator|.
name|pat_mode
expr_stmt|;
comment|/* 		 * Abort the mapping if the first page is not physically 		 * aligned to a 2MB page boundary. 		 */
name|ptepa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|ptepa
operator|&
operator|(
name|NBPDR
operator|-
literal|1
operator|)
condition|)
return|return;
comment|/* 		 * Skip the first page.  Abort the mapping if the rest of 		 * the pages are not physically contiguous or have differing 		 * memory attributes. 		 */
name|p
operator|=
name|TAILQ_NEXT
argument_list|(
name|p
argument_list|,
name|listq
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|ptepa
operator|+
name|PAGE_SIZE
init|;
name|pa
operator|<
name|ptepa
operator|+
name|size
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
block|{
name|KASSERT
argument_list|(
name|p
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
argument_list|,
operator|(
literal|"pmap_object_init_pt: invalid page %p"
operator|,
name|p
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pa
operator|!=
name|VM_PAGE_TO_PHYS
argument_list|(
name|p
argument_list|)
operator|||
name|pat_mode
operator|!=
name|p
operator|->
name|md
operator|.
name|pat_mode
condition|)
return|return;
name|p
operator|=
name|TAILQ_NEXT
argument_list|(
name|p
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Map using 2MB pages.  Since "ptepa" is 2M aligned and 		 * "size" is a multiple of 2M, adding the PAT setting to "pa" 		 * will not affect the termination of this loop. 		 */
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|ptepa
operator||
name|pmap_cache_bits
argument_list|(
name|pmap
argument_list|,
name|pat_mode
argument_list|,
literal|1
argument_list|)
init|;
name|pa
operator|<
name|ptepa
operator|+
name|size
condition|;
name|pa
operator|+=
name|NBPDR
control|)
block|{
name|pdpg
operator|=
name|pmap_allocpde
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|pdpg
operator|==
name|NULL
condition|)
block|{
comment|/* 				 * The creation of mappings below is only an 				 * optimization.  If a page directory page 				 * cannot be allocated without blocking, 				 * continue on to the next mapping rather than 				 * blocking. 				 */
name|addr
operator|+=
name|NBPDR
expr_stmt|;
continue|continue;
block|}
name|pde
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|pdpg
argument_list|)
argument_list|)
expr_stmt|;
name|pde
operator|=
operator|&
name|pde
index|[
name|pmap_pde_index
argument_list|(
name|addr
argument_list|)
index|]
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|pde_store
argument_list|(
name|pde
argument_list|,
name|pa
operator||
name|PG_PS
operator||
name|PG_M
operator||
name|PG_A
operator||
name|PG_U
operator||
name|PG_RW
operator||
name|PG_V
argument_list|)
expr_stmt|;
name|pmap_resident_count_inc
argument_list|(
name|pmap
argument_list|,
name|NBPDR
operator|/
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|pmap_pde_mappings
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Continue on if the PDE is already valid. */
name|pdpg
operator|->
name|wire_count
operator|--
expr_stmt|;
name|KASSERT
argument_list|(
name|pdpg
operator|->
name|wire_count
operator|>
literal|0
argument_list|,
operator|(
literal|"pmap_object_init_pt: missing reference "
literal|"to page directory page, va: 0x%lx"
operator|,
name|addr
operator|)
argument_list|)
expr_stmt|;
block|}
name|addr
operator|+=
name|NBPDR
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	Clear the wired attribute from the mappings for the specified range of  *	addresses in the given pmap.  Every valid mapping within that range  *	must have the wired attribute set.  In contrast, invalid mappings  *	cannot have the wired attribute set, so they are ignored.  *  *	The wired attribute of the page table entry is not a hardware  *	feature, so there is no need to invalidate any TLB entries.  *	Since pmap_demote_pde() for the wired entry must never fail,  *	pmap_delayed_invl_started()/finished() calls around the  *	function are not needed.  */
end_comment

begin_function
name|void
name|pmap_unwire
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|vm_offset_t
name|va_next
decl_stmt|;
name|pml4_entry_t
modifier|*
name|pml4e
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_V
decl_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|va_next
control|)
block|{
name|pml4e
operator|=
name|pmap_pml4e
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pml4e
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPML4
operator|)
operator|&
operator|~
name|PML4MASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
name|pdpe
operator|=
name|pmap_pml4e_to_pdpe
argument_list|(
name|pml4e
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPDP
operator|)
operator|&
operator|~
name|PDPMASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_unwire: pde %#jx is missing PG_W"
argument_list|,
operator|(
name|uintmax_t
operator|)
operator|*
name|pde
argument_list|)
expr_stmt|;
comment|/* 			 * Are we unwiring the entire large page?  If not, 			 * demote the mapping and fall through. 			 */
if|if
condition|(
name|sva
operator|+
name|NBPDR
operator|==
name|va_next
operator|&&
name|eva
operator|>=
name|va_next
condition|)
block|{
name|atomic_clear_long
argument_list|(
name|pde
argument_list|,
name|PG_W
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|-=
name|NBPDR
operator|/
name|PAGE_SIZE
expr_stmt|;
continue|continue;
block|}
elseif|else
if|if
condition|(
operator|!
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|sva
argument_list|)
condition|)
name|panic
argument_list|(
literal|"pmap_unwire: demotion failed"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|va_next
operator|>
name|eva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|va_next
condition|;
name|pte
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_unwire: pte %#jx is missing PG_W"
argument_list|,
operator|(
name|uintmax_t
operator|)
operator|*
name|pte
argument_list|)
expr_stmt|;
comment|/* 			 * PG_W must be cleared atomically.  Although the pmap 			 * lock synchronizes access to PG_W, another processor 			 * could be setting PG_M and/or PG_A concurrently. 			 */
name|atomic_clear_long
argument_list|(
name|pte
argument_list|,
name|PG_W
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Copy the range specified by src_addr/len  *	from the source map to the range dst_addr/len  *	in the destination map.  *  *	This routine is only advisory and need not do anything.  */
end_comment

begin_function
name|void
name|pmap_copy
parameter_list|(
name|pmap_t
name|dst_pmap
parameter_list|,
name|pmap_t
name|src_pmap
parameter_list|,
name|vm_offset_t
name|dst_addr
parameter_list|,
name|vm_size_t
name|len
parameter_list|,
name|vm_offset_t
name|src_addr
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|vm_offset_t
name|addr
decl_stmt|;
name|vm_offset_t
name|end_addr
init|=
name|src_addr
operator|+
name|len
decl_stmt|;
name|vm_offset_t
name|va_next
decl_stmt|;
name|vm_page_t
name|dst_pdpg
decl_stmt|,
name|dstmpte
decl_stmt|,
name|srcmpte
decl_stmt|;
name|pt_entry_t
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_V
decl_stmt|;
if|if
condition|(
name|dst_addr
operator|!=
name|src_addr
condition|)
return|return;
if|if
condition|(
name|dst_pmap
operator|->
name|pm_type
operator|!=
name|src_pmap
operator|->
name|pm_type
condition|)
return|return;
comment|/* 	 * EPT page table entries that require emulation of A/D bits are 	 * sensitive to clearing the PG_A bit (aka EPT_PG_READ). Although 	 * we clear PG_M (aka EPT_PG_WRITE) concomitantly, the PG_U bit 	 * (aka EPT_PG_EXECUTE) could still be set. Since some EPT 	 * implementations flag an EPT misconfiguration for exec-only 	 * mappings we skip this function entirely for emulated pmaps. 	 */
if|if
condition|(
name|pmap_emulate_ad_bits
argument_list|(
name|dst_pmap
argument_list|)
condition|)
return|return;
name|lock
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|dst_pmap
operator|<
name|src_pmap
condition|)
block|{
name|PMAP_LOCK
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|src_pmap
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|PMAP_LOCK
argument_list|(
name|src_pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
block|}
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
for|for
control|(
name|addr
operator|=
name|src_addr
init|;
name|addr
operator|<
name|end_addr
condition|;
name|addr
operator|=
name|va_next
control|)
block|{
name|pt_entry_t
modifier|*
name|src_pte
decl_stmt|,
modifier|*
name|dst_pte
decl_stmt|;
name|pml4_entry_t
modifier|*
name|pml4e
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|pd_entry_t
name|srcptepaddr
decl_stmt|,
modifier|*
name|pde
decl_stmt|;
name|KASSERT
argument_list|(
name|addr
operator|<
name|UPT_MIN_ADDRESS
argument_list|,
operator|(
literal|"pmap_copy: invalid to pmap_copy page tables"
operator|)
argument_list|)
expr_stmt|;
name|pml4e
operator|=
name|pmap_pml4e
argument_list|(
name|src_pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pml4e
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|addr
operator|+
name|NBPML4
operator|)
operator|&
operator|~
name|PML4MASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|addr
condition|)
name|va_next
operator|=
name|end_addr
expr_stmt|;
continue|continue;
block|}
name|pdpe
operator|=
name|pmap_pml4e_to_pdpe
argument_list|(
name|pml4e
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|addr
operator|+
name|NBPDP
operator|)
operator|&
operator|~
name|PDPMASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|addr
condition|)
name|va_next
operator|=
name|end_addr
expr_stmt|;
continue|continue;
block|}
name|va_next
operator|=
operator|(
name|addr
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|addr
condition|)
name|va_next
operator|=
name|end_addr
expr_stmt|;
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|addr
argument_list|)
expr_stmt|;
name|srcptepaddr
operator|=
operator|*
name|pde
expr_stmt|;
if|if
condition|(
name|srcptepaddr
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|srcptepaddr
operator|&
name|PG_PS
condition|)
block|{
if|if
condition|(
operator|(
name|addr
operator|&
name|PDRMASK
operator|)
operator|!=
literal|0
operator|||
name|addr
operator|+
name|NBPDR
operator|>
name|end_addr
condition|)
continue|continue;
name|dst_pdpg
operator|=
name|pmap_allocpde
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|dst_pdpg
operator|==
name|NULL
condition|)
break|break;
name|pde
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|dst_pdpg
argument_list|)
argument_list|)
expr_stmt|;
name|pde
operator|=
operator|&
name|pde
index|[
name|pmap_pde_index
argument_list|(
name|addr
argument_list|)
index|]
expr_stmt|;
if|if
condition|(
operator|*
name|pde
operator|==
literal|0
operator|&&
operator|(
operator|(
name|srcptepaddr
operator|&
name|PG_MANAGED
operator|)
operator|==
literal|0
operator|||
name|pmap_pv_insert_pde
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|srcptepaddr
operator|&
name|PG_PS_FRAME
argument_list|,
operator|&
name|lock
argument_list|)
operator|)
condition|)
block|{
operator|*
name|pde
operator|=
name|srcptepaddr
operator|&
operator|~
name|PG_W
expr_stmt|;
name|pmap_resident_count_inc
argument_list|(
name|dst_pmap
argument_list|,
name|NBPDR
operator|/
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|atomic_add_long
argument_list|(
operator|&
name|pmap_pde_mappings
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
name|dst_pdpg
operator|->
name|wire_count
operator|--
expr_stmt|;
continue|continue;
block|}
name|srcptepaddr
operator|&=
name|PG_FRAME
expr_stmt|;
name|srcmpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|srcptepaddr
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|srcmpte
operator|->
name|wire_count
operator|>
literal|0
argument_list|,
operator|(
literal|"pmap_copy: source page table page is unused"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|va_next
operator|>
name|end_addr
condition|)
name|va_next
operator|=
name|end_addr
expr_stmt|;
name|src_pte
operator|=
operator|(
name|pt_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|srcptepaddr
argument_list|)
expr_stmt|;
name|src_pte
operator|=
operator|&
name|src_pte
index|[
name|pmap_pte_index
argument_list|(
name|addr
argument_list|)
index|]
expr_stmt|;
name|dstmpte
operator|=
name|NULL
expr_stmt|;
while|while
condition|(
name|addr
operator|<
name|va_next
condition|)
block|{
name|pt_entry_t
name|ptetemp
decl_stmt|;
name|ptetemp
operator|=
operator|*
name|src_pte
expr_stmt|;
comment|/* 			 * we only virtual copy managed pages 			 */
if|if
condition|(
operator|(
name|ptetemp
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|dstmpte
operator|!=
name|NULL
operator|&&
name|dstmpte
operator|->
name|pindex
operator|==
name|pmap_pde_pindex
argument_list|(
name|addr
argument_list|)
condition|)
name|dstmpte
operator|->
name|wire_count
operator|++
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|dstmpte
operator|=
name|pmap_allocpte
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|NULL
argument_list|)
operator|)
operator|==
name|NULL
condition|)
goto|goto
name|out
goto|;
name|dst_pte
operator|=
operator|(
name|pt_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|dstmpte
argument_list|)
argument_list|)
expr_stmt|;
name|dst_pte
operator|=
operator|&
name|dst_pte
index|[
name|pmap_pte_index
argument_list|(
name|addr
argument_list|)
index|]
expr_stmt|;
if|if
condition|(
operator|*
name|dst_pte
operator|==
literal|0
operator|&&
name|pmap_try_insert_pv_entry
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|PHYS_TO_VM_PAGE
argument_list|(
name|ptetemp
operator|&
name|PG_FRAME
argument_list|)
argument_list|,
operator|&
name|lock
argument_list|)
condition|)
block|{
comment|/* 					 * Clear the wired, modified, and 					 * accessed (referenced) bits 					 * during the copy. 					 */
operator|*
name|dst_pte
operator|=
name|ptetemp
operator|&
operator|~
operator|(
name|PG_W
operator||
name|PG_M
operator||
name|PG_A
operator|)
expr_stmt|;
name|pmap_resident_count_inc
argument_list|(
name|dst_pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_unwire_ptp
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|dstmpte
argument_list|,
operator|&
name|free
argument_list|)
condition|)
block|{
comment|/* 						 * Although "addr" is not 						 * mapped, paging-structure 						 * caches could nonetheless 						 * have entries that refer to 						 * the freed page table pages. 						 * Invalidate those entries. 						 */
name|pmap_invalidate_page
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
goto|goto
name|out
goto|;
block|}
if|if
condition|(
name|dstmpte
operator|->
name|wire_count
operator|>=
name|srcmpte
operator|->
name|wire_count
condition|)
break|break;
block|}
name|addr
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|src_pte
operator|++
expr_stmt|;
block|}
block|}
name|out
label|:
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|src_pmap
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Zero the specified hardware page.  */
end_comment

begin_function
name|void
name|pmap_zero_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_offset_t
name|va
init|=
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
decl_stmt|;
name|pagezero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Zero an an area within a single hardware page.  off and size must not  * cover an area beyond a single hardware page.  */
end_comment

begin_function
name|void
name|pmap_zero_page_area
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_offset_t
name|va
init|=
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|off
operator|==
literal|0
operator|&&
name|size
operator|==
name|PAGE_SIZE
condition|)
name|pagezero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|)
expr_stmt|;
else|else
name|bzero
argument_list|(
operator|(
name|char
operator|*
operator|)
name|va
operator|+
name|off
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Copy 1 specified hardware page to another.  */
end_comment

begin_function
name|void
name|pmap_copy_page
parameter_list|(
name|vm_page_t
name|msrc
parameter_list|,
name|vm_page_t
name|mdst
parameter_list|)
block|{
name|vm_offset_t
name|src
init|=
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|msrc
argument_list|)
argument_list|)
decl_stmt|;
name|vm_offset_t
name|dst
init|=
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|mdst
argument_list|)
argument_list|)
decl_stmt|;
name|pagecopy
argument_list|(
operator|(
name|void
operator|*
operator|)
name|src
argument_list|,
operator|(
name|void
operator|*
operator|)
name|dst
argument_list|)
expr_stmt|;
block|}
end_function

begin_decl_stmt
name|int
name|unmapped_buf_allowed
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|pmap_copy_pages
parameter_list|(
name|vm_page_t
name|ma
index|[]
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
name|mb
index|[]
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
block|{
name|void
modifier|*
name|a_cp
decl_stmt|,
modifier|*
name|b_cp
decl_stmt|;
name|vm_page_t
name|pages
index|[
literal|2
index|]
decl_stmt|;
name|vm_offset_t
name|vaddr
index|[
literal|2
index|]
decl_stmt|,
name|a_pg_offset
decl_stmt|,
name|b_pg_offset
decl_stmt|;
name|int
name|cnt
decl_stmt|;
name|boolean_t
name|mapped
decl_stmt|;
while|while
condition|(
name|xfersize
operator|>
literal|0
condition|)
block|{
name|a_pg_offset
operator|=
name|a_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|pages
index|[
literal|0
index|]
operator|=
name|ma
index|[
name|a_offset
operator|>>
name|PAGE_SHIFT
index|]
expr_stmt|;
name|b_pg_offset
operator|=
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|pages
index|[
literal|1
index|]
operator|=
name|mb
index|[
name|b_offset
operator|>>
name|PAGE_SHIFT
index|]
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|xfersize
argument_list|,
name|PAGE_SIZE
operator|-
name|a_pg_offset
argument_list|)
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|cnt
argument_list|,
name|PAGE_SIZE
operator|-
name|b_pg_offset
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|pmap_map_io_transient
argument_list|(
name|pages
argument_list|,
name|vaddr
argument_list|,
literal|2
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|a_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|vaddr
index|[
literal|0
index|]
operator|+
name|a_pg_offset
expr_stmt|;
name|b_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|vaddr
index|[
literal|1
index|]
operator|+
name|b_pg_offset
expr_stmt|;
name|bcopy
argument_list|(
name|a_cp
argument_list|,
name|b_cp
argument_list|,
name|cnt
argument_list|)
expr_stmt|;
if|if
condition|(
name|__predict_false
argument_list|(
name|mapped
argument_list|)
condition|)
name|pmap_unmap_io_transient
argument_list|(
name|pages
argument_list|,
name|vaddr
argument_list|,
literal|2
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|a_offset
operator|+=
name|cnt
expr_stmt|;
name|b_offset
operator|+=
name|cnt
expr_stmt|;
name|xfersize
operator|-=
name|cnt
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Returns true if the pmap's pv is one of the first  * 16 pvs linked to from this page.  This count may  * be changed upwards or downwards in the future; it  * is only necessary that true be returned for a small  * subset of pmaps for proper page aging.  */
end_comment

begin_function
name|boolean_t
name|pmap_page_exists_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|int
name|loops
init|=
literal|0
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_page_exists_quick: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|==
name|pmap
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
name|loops
operator|++
expr_stmt|;
if|if
condition|(
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
if|if
condition|(
operator|!
name|rv
operator|&&
name|loops
operator|<
literal|16
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|==
name|pmap
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
name|loops
operator|++
expr_stmt|;
if|if
condition|(
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
block|}
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_page_wired_mappings:  *  *	Return the number of managed mappings to the given physical page  *	that are wired.  */
end_comment

begin_function
name|int
name|pmap_page_wired_mappings
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|int
name|count
decl_stmt|,
name|md_gen
decl_stmt|,
name|pvh_gen
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|restart
label|:
name|count
operator|=
literal|0
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
block|}
name|pte
operator|=
name|pmap_pte
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_W
operator|)
operator|!=
literal|0
condition|)
name|count
operator|++
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|pvh_gen
operator|=
name|pvh
operator|->
name|pv_gen
expr_stmt|;
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|||
name|pvh_gen
operator|!=
name|pvh
operator|->
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
block|}
name|pte
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_W
operator|)
operator|!=
literal|0
condition|)
name|count
operator|++
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
block|}
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns TRUE if the given page is mapped individually or as part of  * a 2mpage.  Otherwise, returns FALSE.  */
end_comment

begin_function
name|boolean_t
name|pmap_page_is_mapped
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|rv
operator|=
operator|!
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|||
operator|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
operator|!
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
operator|->
name|pv_list
argument_list|)
operator|)
expr_stmt|;
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Destroy all managed, non-wired mappings in the given user-space  * pmap.  This pmap cannot be active on any processor besides the  * caller.  *  * This function cannot be applied to the kernel pmap.  Moreover, it  * is not intended for general use.  It is only to be used during  * process termination.  Consequently, it can be implemented in ways  * that make it faster than pmap_remove().  First, it can more quickly  * destroy mappings by iterating over the pmap's collection of PV  * entries, rather than searching the page table.  Second, it doesn't  * have to test and clear the page table entries atomically, because  * no processor is currently accessing the user address space.  In  * particular, a page table entry's dirty bit won't change state once  * this function starts.  */
end_comment

begin_function
name|void
name|pmap_remove_pages
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|pd_entry_t
name|ptepde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|tpte
decl_stmt|;
name|pt_entry_t
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mpte
decl_stmt|,
name|mt
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|,
modifier|*
name|npc
decl_stmt|;
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|int64_t
name|bit
decl_stmt|;
name|uint64_t
name|inuse
decl_stmt|,
name|bitmask
decl_stmt|;
name|int
name|allfree
decl_stmt|,
name|field
decl_stmt|,
name|freed
decl_stmt|,
name|idx
decl_stmt|;
name|boolean_t
name|superpage
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
comment|/* 	 * Assert that the given pmap is only active on the current 	 * CPU.  Unfortunately, we cannot block another CPU from 	 * activating the pmap while this function is executing. 	 */
name|KASSERT
argument_list|(
name|pmap
operator|==
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
argument_list|,
operator|(
literal|"non-current pmap %p"
operator|,
name|pmap
operator|)
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|INVARIANTS
block|{
name|cpuset_t
name|other_cpus
decl_stmt|;
name|other_cpus
operator|=
name|all_cpus
expr_stmt|;
name|critical_enter
argument_list|()
expr_stmt|;
name|CPU_CLR
argument_list|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|,
operator|&
name|other_cpus
argument_list|)
expr_stmt|;
name|CPU_AND
argument_list|(
operator|&
name|other_cpus
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|critical_exit
argument_list|()
expr_stmt|;
name|KASSERT
argument_list|(
name|CPU_EMPTY
argument_list|(
operator|&
name|other_cpus
argument_list|)
argument_list|,
operator|(
literal|"pmap active %p"
operator|,
name|pmap
operator|)
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|lock
operator|=
name|NULL
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|pc
argument_list|,
argument|&pmap->pm_pvchunk
argument_list|,
argument|pc_list
argument_list|,
argument|npc
argument_list|)
block|{
name|allfree
operator|=
literal|1
expr_stmt|;
name|freed
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
name|inuse
operator|=
operator|~
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&
name|pc_freemask
index|[
name|field
index|]
expr_stmt|;
while|while
condition|(
name|inuse
operator|!=
literal|0
condition|)
block|{
name|bit
operator|=
name|bsfq
argument_list|(
name|inuse
argument_list|)
expr_stmt|;
name|bitmask
operator|=
literal|1UL
operator|<<
name|bit
expr_stmt|;
name|idx
operator|=
name|field
operator|*
literal|64
operator|+
name|bit
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|idx
index|]
expr_stmt|;
name|inuse
operator|&=
operator|~
name|bitmask
expr_stmt|;
name|pte
operator|=
name|pmap_pdpe
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|ptepde
operator|=
operator|*
name|pte
expr_stmt|;
name|pte
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pte
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|tpte
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
operator|(
name|PG_PS
operator||
name|PG_V
operator|)
operator|)
operator|==
name|PG_V
condition|)
block|{
name|superpage
operator|=
name|FALSE
expr_stmt|;
name|ptepde
operator|=
name|tpte
expr_stmt|;
name|pte
operator|=
operator|(
name|pt_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|tpte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|pte
operator|=
operator|&
name|pte
index|[
name|pmap_pte_index
argument_list|(
name|pv
operator|->
name|pv_va
argument_list|)
index|]
expr_stmt|;
name|tpte
operator|=
operator|*
name|pte
expr_stmt|;
block|}
else|else
block|{
comment|/* 					 * Keep track whether 'tpte' is a 					 * superpage explicitly instead of 					 * relying on PG_PS being set. 					 * 					 * This is because PG_PS is numerically 					 * identical to PG_PTE_PAT and thus a 					 * regular page could be mistaken for 					 * a superpage. 					 */
name|superpage
operator|=
name|TRUE
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"bad pte va %lx pte %lx"
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
name|tpte
argument_list|)
expr_stmt|;
block|}
comment|/*  * We cannot remove wired pages from a process' mapping at this time  */
if|if
condition|(
name|tpte
operator|&
name|PG_W
condition|)
block|{
name|allfree
operator|=
literal|0
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|superpage
condition|)
name|pa
operator|=
name|tpte
operator|&
name|PG_PS_FRAME
expr_stmt|;
else|else
name|pa
operator|=
name|tpte
operator|&
name|PG_FRAME
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|phys_addr
operator|==
name|pa
argument_list|,
operator|(
literal|"vm_page_t %p phys_addr mismatch %016jx %016jx"
operator|,
name|m
operator|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|phys_addr
operator|,
operator|(
name|uintmax_t
operator|)
name|tpte
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
operator|||
name|m
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"pmap_remove_pages: bad tpte %#jx"
operator|,
operator|(
name|uintmax_t
operator|)
name|tpte
operator|)
argument_list|)
expr_stmt|;
name|pte_clear
argument_list|(
name|pte
argument_list|)
expr_stmt|;
comment|/* 				 * Update the vm_page_t clean/reference bits. 				 */
if|if
condition|(
operator|(
name|tpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
if|if
condition|(
name|superpage
condition|)
block|{
for|for
control|(
name|mt
operator|=
name|m
init|;
name|mt
operator|<
operator|&
name|m
index|[
name|NBPDR
operator|/
name|PAGE_SIZE
index|]
condition|;
name|mt
operator|++
control|)
name|vm_page_dirty
argument_list|(
name|mt
argument_list|)
expr_stmt|;
block|}
else|else
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|CHANGE_PV_LIST_LOCK_TO_VM_PAGE
argument_list|(
operator|&
name|lock
argument_list|,
name|m
argument_list|)
expr_stmt|;
comment|/* Mark free */
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
name|bitmask
expr_stmt|;
if|if
condition|(
name|superpage
condition|)
block|{
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
name|NBPDR
operator|/
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|tpte
operator|&
name|PG_PS_FRAME
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|pvh
operator|->
name|pv_gen
operator|++
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
block|{
for|for
control|(
name|mt
operator|=
name|m
init|;
name|mt
operator|<
operator|&
name|m
index|[
name|NBPDR
operator|/
name|PAGE_SIZE
index|]
condition|;
name|mt
operator|++
control|)
if|if
condition|(
operator|(
name|mt
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|!=
literal|0
operator|&&
name|TAILQ_EMPTY
argument_list|(
operator|&
name|mt
operator|->
name|md
operator|.
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|mt
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
name|mpte
operator|=
name|pmap_remove_pt_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|->
name|wire_count
operator|==
name|NPTEPG
argument_list|,
operator|(
literal|"pmap_remove_pages: pte page wire count error"
operator|)
argument_list|)
expr_stmt|;
name|mpte
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
name|pmap_add_delayed_free_list
argument_list|(
name|mpte
argument_list|,
operator|&
name|free
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|pmap_resident_count_dec
argument_list|(
name|pmap
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|!=
literal|0
operator|&&
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
block|}
name|pmap_unuse_pt
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
name|ptepde
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
name|freed
operator|++
expr_stmt|;
block|}
block|}
name|PV_STAT
argument_list|(
name|atomic_add_long
argument_list|(
operator|&
name|pv_entry_frees
argument_list|,
name|freed
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_add_int
argument_list|(
operator|&
name|pv_entry_spare
argument_list|,
name|freed
argument_list|)
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|atomic_subtract_long
argument_list|(
operator|&
name|pv_entry_count
argument_list|,
name|freed
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|allfree
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|free_pv_chunk
argument_list|(
name|pc
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|boolean_t
name|pmap_page_test_mappings
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|boolean_t
name|accessed
parameter_list|,
name|boolean_t
name|modified
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|mask
decl_stmt|;
name|pt_entry_t
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|int
name|md_gen
decl_stmt|,
name|pvh_gen
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|restart
label|:
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
block|}
name|pte
operator|=
name|pmap_pte
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|mask
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|modified
condition|)
block|{
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|mask
operator||=
name|PG_RW
operator||
name|PG_M
expr_stmt|;
block|}
if|if
condition|(
name|accessed
condition|)
block|{
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|mask
operator||=
name|PG_V
operator||
name|PG_A
expr_stmt|;
block|}
name|rv
operator|=
operator|(
operator|*
name|pte
operator|&
name|mask
operator|)
operator|==
name|mask
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
condition|)
goto|goto
name|out
goto|;
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|pvh_gen
operator|=
name|pvh
operator|->
name|pv_gen
expr_stmt|;
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_rlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|||
name|pvh_gen
operator|!=
name|pvh
operator|->
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
block|}
name|pte
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|mask
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|modified
condition|)
block|{
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|mask
operator||=
name|PG_RW
operator||
name|PG_M
expr_stmt|;
block|}
if|if
condition|(
name|accessed
condition|)
block|{
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|mask
operator||=
name|PG_V
operator||
name|PG_A
expr_stmt|;
block|}
name|rv
operator|=
operator|(
operator|*
name|pte
operator|&
name|mask
operator|)
operator|==
name|mask
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
condition|)
goto|goto
name|out
goto|;
block|}
block|}
name|out
label|:
name|rw_runlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_modified:  *  *	Return whether or not the specified physical page was modified  *	in any physical maps.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_modified
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_is_modified: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not exclusive busied, then PGA_WRITEABLE cannot be 	 * concurrently set while the object is locked.  Thus, if PGA_WRITEABLE 	 * is clear, no PTEs can have PG_M set. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
return|return
operator|(
name|pmap_page_test_mappings
argument_list|(
name|m
argument_list|,
name|FALSE
argument_list|,
name|TRUE
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_prefaultable:  *  *	Return whether or not the specified virtual address is eligible  *	for prefault.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_prefaultable
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_V
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
name|pde
operator|!=
name|NULL
operator|&&
operator|(
operator|*
name|pde
operator|&
operator|(
name|PG_PS
operator||
name|PG_V
operator|)
operator|)
operator|==
name|PG_V
condition|)
block|{
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|addr
argument_list|)
expr_stmt|;
name|rv
operator|=
operator|(
operator|*
name|pte
operator|&
name|PG_V
operator|)
operator|==
literal|0
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_referenced:  *  *	Return whether or not the specified physical page was referenced  *	in any physical maps.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_referenced
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_is_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|pmap_page_test_mappings
argument_list|(
name|m
argument_list|,
name|TRUE
argument_list|,
name|FALSE
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Clear the write and modified bits in each of the given page's mappings.  */
end_comment

begin_function
name|void
name|pmap_remove_write
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pv_entry_t
name|next_pv
decl_stmt|,
name|pv
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
name|oldpte
decl_stmt|,
modifier|*
name|pte
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|int
name|pvh_gen
decl_stmt|,
name|md_gen
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_write: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not exclusive busied, then PGA_WRITEABLE cannot be 	 * set by another thread while the object is locked.  Thus, 	 * if PGA_WRITEABLE is clear, no page table entries need updating. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pvh
operator|=
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|?
operator|&
name|pv_dummy
else|:
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|retry_pv_loop
label|:
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|,
argument|next_pv
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pvh_gen
operator|=
name|pvh
operator|->
name|pv_gen
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvh_gen
operator|!=
name|pvh
operator|->
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
goto|goto
name|retry_pv_loop
goto|;
block|}
block|}
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_RW
operator|)
operator|!=
literal|0
condition|)
operator|(
name|void
operator|)
name|pmap_demote_pde_locked
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|lock
operator|==
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"inconsistent pv lock %p %p for page %p"
operator|,
name|lock
operator|,
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pvh_gen
operator|=
name|pvh
operator|->
name|pv_gen
expr_stmt|;
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvh_gen
operator|!=
name|pvh
operator|->
name|pv_gen
operator|||
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
goto|goto
name|retry_pv_loop
goto|;
block|}
block|}
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_write: found a 2mpage in page %p's pv list"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|retry
label|:
name|oldpte
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
name|oldpte
operator|&
name|PG_RW
condition|)
block|{
if|if
condition|(
operator|!
name|atomic_cmpset_long
argument_list|(
name|pte
argument_list|,
name|oldpte
argument_list|,
name|oldpte
operator|&
operator|~
operator|(
name|PG_RW
operator||
name|PG_M
operator|)
argument_list|)
condition|)
goto|goto
name|retry
goto|;
if|if
condition|(
operator|(
name|oldpte
operator|&
name|PG_M
operator|)
operator|!=
literal|0
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|pmap_delayed_invl_wait
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|boolean_t
name|safe_to_clear_referenced
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt_entry_t
name|pte
parameter_list|)
block|{
if|if
condition|(
operator|!
name|pmap_emulate_ad_bits
argument_list|(
name|pmap
argument_list|)
condition|)
return|return
operator|(
name|TRUE
operator|)
return|;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_type
operator|==
name|PT_EPT
argument_list|,
operator|(
literal|"invalid pm_type %d"
operator|,
name|pmap
operator|->
name|pm_type
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * XWR = 010 or 110 will cause an unconditional EPT misconfiguration 	 * so we don't let the referenced (aka EPT_PG_READ) bit to be cleared 	 * if the EPT_PG_WRITE bit is set. 	 */
if|if
condition|(
operator|(
name|pte
operator|&
name|EPT_PG_WRITE
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
comment|/* 	 * XWR = 100 is allowed only if the PMAP_SUPPORTS_EXEC_ONLY is set. 	 */
if|if
condition|(
operator|(
name|pte
operator|&
name|EPT_PG_EXECUTE
operator|)
operator|==
literal|0
operator|||
operator|(
operator|(
name|pmap
operator|->
name|pm_flags
operator|&
name|PMAP_SUPPORTS_EXEC_ONLY
operator|)
operator|!=
literal|0
operator|)
condition|)
return|return
operator|(
name|TRUE
operator|)
return|;
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_ts_referenced:  *  *	Return a count of reference bits for a page, clearing those bits.  *	It is not necessary for every reference bit to be cleared, but it  *	is necessary that 0 only be returned when there are truly no  *	reference bits set.  *  *	As an optimization, update the page's dirty field if a modified bit is  *	found while counting reference bits.  This opportunistic update can be  *	performed at low cost and can eliminate the need for some future calls  *	to pmap_is_modified().  However, since this function stops after  *	finding PMAP_TS_REFERENCED_MAX reference bits, it may not detect some  *	dirty pages.  Those dirty pages will only be detected by a future call  *	to pmap_is_modified().  *  *	A DI block is not needed within this function, because  *	invalidations are performed before the PV list lock is  *	released.  */
end_comment

begin_function
name|int
name|pmap_ts_referenced
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|,
name|pvf
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pd_entry_t
name|oldpde
decl_stmt|,
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|int
name|cleared
decl_stmt|,
name|md_gen
decl_stmt|,
name|not_cleared
decl_stmt|,
name|pvh_gen
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|boolean_t
name|demoted
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_ts_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|cleared
operator|=
literal|0
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|lock
operator|=
name|PHYS_TO_PV_LIST_LOCK
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|pvh
operator|=
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|?
operator|&
name|pv_dummy
else|:
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|retry
label|:
name|not_cleared
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|pvf
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
operator|)
operator|==
name|NULL
condition|)
goto|goto
name|small_mappings
goto|;
name|pv
operator|=
name|pvf
expr_stmt|;
do|do
block|{
if|if
condition|(
name|pvf
operator|==
name|NULL
condition|)
name|pvf
operator|=
name|pv
expr_stmt|;
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pvh_gen
operator|=
name|pvh
operator|->
name|pv_gen
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvh_gen
operator|!=
name|pvh
operator|->
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
block|}
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|oldpde
operator|=
operator|*
name|pde
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
comment|/* 			 * Although "oldpde" is mapping a 2MB page, because 			 * this function is called at a 4KB page granularity, 			 * we only update the 4KB page under test. 			 */
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * Since this reference bit is shared by 512 4KB 			 * pages, it should not be cleared every time it is 			 * tested.  Apply a simple "hash" function on the 			 * physical page number, the virtual superpage number, 			 * and the pmap address to select one 4KB page out of 			 * the 512 on which testing the reference bit will 			 * result in clearing that reference bit.  This 			 * function is designed to avoid the selection of the 			 * same 4KB page for every 2MB page mapping. 			 * 			 * On demotion, a mapping that hasn't been referenced 			 * is simply destroyed.  To avoid the possibility of a 			 * subsequent page fault on a demoted wired mapping, 			 * always leave its reference bit set.  Moreover, 			 * since the superpage is wired, the current state of 			 * its reference bit won't affect page replacement. 			 */
if|if
condition|(
operator|(
operator|(
operator|(
name|pa
operator|>>
name|PAGE_SHIFT
operator|)
operator|^
operator|(
name|pv
operator|->
name|pv_va
operator|>>
name|PDRSHIFT
operator|)
operator|^
operator|(
name|uintptr_t
operator|)
name|pmap
operator|)
operator|&
operator|(
name|NPTEPG
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
operator|&&
operator|(
name|oldpde
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|safe_to_clear_referenced
argument_list|(
name|pmap
argument_list|,
name|oldpde
argument_list|)
condition|)
block|{
name|atomic_clear_long
argument_list|(
name|pde
argument_list|,
name|PG_A
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|demoted
operator|=
name|FALSE
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pmap_demote_pde_locked
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
operator|&
name|lock
argument_list|)
condition|)
block|{
comment|/* 					 * Remove the mapping to a single page 					 * so that a subsequent access may 					 * repromote.  Since the underlying 					 * page table page is fully populated, 					 * this removal never frees a page 					 * table page. 					 */
name|demoted
operator|=
name|TRUE
expr_stmt|;
name|va
operator|+=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator|-
operator|(
name|oldpde
operator|&
name|PG_PS_FRAME
operator|)
expr_stmt|;
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pmap_remove_pte
argument_list|(
name|pmap
argument_list|,
name|pte
argument_list|,
name|va
argument_list|,
operator|*
name|pde
argument_list|,
name|NULL
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
else|else
name|demoted
operator|=
name|TRUE
expr_stmt|;
if|if
condition|(
name|demoted
condition|)
block|{
comment|/* 					 * The superpage mapping was removed 					 * entirely and therefore 'pv' is no 					 * longer valid. 					 */
if|if
condition|(
name|pvf
operator|==
name|pv
condition|)
name|pvf
operator|=
name|NULL
expr_stmt|;
name|pv
operator|=
name|NULL
expr_stmt|;
block|}
name|cleared
operator|++
expr_stmt|;
name|KASSERT
argument_list|(
name|lock
operator|==
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"inconsistent pv lock %p %p for page %p"
operator|,
name|lock
operator|,
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
name|not_cleared
operator|++
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Rotate the PV list if it has more than one entry. */
if|if
condition|(
name|pv
operator|!=
name|NULL
operator|&&
name|TAILQ_NEXT
argument_list|(
name|pv
argument_list|,
name|pv_next
argument_list|)
operator|!=
name|NULL
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|pvh
operator|->
name|pv_gen
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|cleared
operator|+
name|not_cleared
operator|>=
name|PMAP_TS_REFERENCED_MAX
condition|)
goto|goto
name|out
goto|;
block|}
do|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
operator|)
operator|!=
name|pvf
condition|)
do|;
name|small_mappings
label|:
if|if
condition|(
operator|(
name|pvf
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|==
name|NULL
condition|)
goto|goto
name|out
goto|;
name|pv
operator|=
name|pvf
expr_stmt|;
do|do
block|{
if|if
condition|(
name|pvf
operator|==
name|NULL
condition|)
name|pvf
operator|=
name|pv
expr_stmt|;
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pvh_gen
operator|=
name|pvh
operator|->
name|pv_gen
expr_stmt|;
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvh_gen
operator|!=
name|pvh
operator|->
name|pv_gen
operator|||
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
block|}
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_ts_referenced: found a 2mpage in page %p's pv list"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|safe_to_clear_referenced
argument_list|(
name|pmap
argument_list|,
operator|*
name|pte
argument_list|)
condition|)
block|{
name|atomic_clear_long
argument_list|(
name|pte
argument_list|,
name|PG_A
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|cleared
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 				 * Wired pages cannot be paged out so 				 * doing accessed bit emulation for 				 * them is wasted effort. We do the 				 * hard work for unwired pages only. 				 */
name|pmap_remove_pte
argument_list|(
name|pmap
argument_list|,
name|pte
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
operator|*
name|pde
argument_list|,
operator|&
name|free
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|cleared
operator|++
expr_stmt|;
if|if
condition|(
name|pvf
operator|==
name|pv
condition|)
name|pvf
operator|=
name|NULL
expr_stmt|;
name|pv
operator|=
name|NULL
expr_stmt|;
name|KASSERT
argument_list|(
name|lock
operator|==
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"inconsistent pv lock %p %p for page %p"
operator|,
name|lock
operator|,
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
name|not_cleared
operator|++
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Rotate the PV list if it has more than one entry. */
if|if
condition|(
name|pv
operator|!=
name|NULL
operator|&&
name|TAILQ_NEXT
argument_list|(
name|pv
argument_list|,
name|pv_next
argument_list|)
operator|!=
name|NULL
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pv_gen
operator|++
expr_stmt|;
block|}
block|}
do|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|!=
name|pvf
operator|&&
name|cleared
operator|+
name|not_cleared
operator|<
name|PMAP_TS_REFERENCED_MAX
condition|)
do|;
name|out
label|:
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
return|return
operator|(
name|cleared
operator|+
name|not_cleared
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Apply the given advice to the specified range of addresses within the  *	given pmap.  Depending on the advice, clear the referenced and/or  *	modified flags in each mapping and set the mapped page's dirty field.  */
end_comment

begin_function
name|void
name|pmap_advise
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|int
name|advice
parameter_list|)
block|{
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|pml4_entry_t
modifier|*
name|pml4e
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|pd_entry_t
name|oldpde
decl_stmt|,
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_A
decl_stmt|,
name|PG_G
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|va_next
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|boolean_t
name|anychanged
decl_stmt|;
if|if
condition|(
name|advice
operator|!=
name|MADV_DONTNEED
operator|&&
name|advice
operator|!=
name|MADV_FREE
condition|)
return|return;
comment|/* 	 * A/D bit emulation requires an alternate code path when clearing 	 * the modified and accessed bits below. Since this function is 	 * advisory in nature we skip it entirely for pmaps that require 	 * A/D bit emulation. 	 */
if|if
condition|(
name|pmap_emulate_ad_bits
argument_list|(
name|pmap
argument_list|)
condition|)
return|return;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_G
operator|=
name|pmap_global_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|anychanged
operator|=
name|FALSE
expr_stmt|;
name|pmap_delayed_invl_started
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|va_next
control|)
block|{
name|pml4e
operator|=
name|pmap_pml4e
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pml4e
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPML4
operator|)
operator|&
operator|~
name|PML4MASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
name|pdpe
operator|=
name|pmap_pml4e_to_pdpe
argument_list|(
name|pml4e
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPDP
operator|)
operator|&
operator|~
name|PDPMASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
continue|continue;
block|}
name|va_next
operator|=
operator|(
name|sva
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|va_next
operator|<
name|sva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|oldpde
operator|=
operator|*
name|pde
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
continue|continue;
elseif|else
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_MANAGED
operator|)
operator|==
literal|0
condition|)
continue|continue;
name|lock
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
operator|!
name|pmap_demote_pde_locked
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|sva
argument_list|,
operator|&
name|lock
argument_list|)
condition|)
block|{
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
comment|/* 				 * The large page mapping was destroyed. 				 */
continue|continue;
block|}
comment|/* 			 * Unless the page mappings are wired, remove the 			 * mapping to a single page so that a subsequent 			 * access may repromote.  Since the underlying page 			 * table page is fully populated, this removal never 			 * frees a page table page. 			 */
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
block|{
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|*
name|pte
operator|&
name|PG_V
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_advise: invalid PTE"
operator|)
argument_list|)
expr_stmt|;
name|pmap_remove_pte
argument_list|(
name|pmap
argument_list|,
name|pte
argument_list|,
name|sva
argument_list|,
operator|*
name|pde
argument_list|,
name|NULL
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
name|anychanged
operator|=
name|TRUE
expr_stmt|;
block|}
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|va_next
operator|>
name|eva
condition|)
name|va_next
operator|=
name|eva
expr_stmt|;
name|va
operator|=
name|va_next
expr_stmt|;
for|for
control|(
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|va_next
condition|;
name|pte
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_MANAGED
operator||
name|PG_V
operator|)
operator|)
operator|!=
operator|(
name|PG_MANAGED
operator||
name|PG_V
operator|)
condition|)
goto|goto
name|maybe_invlrng
goto|;
elseif|else
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
if|if
condition|(
name|advice
operator|==
name|MADV_DONTNEED
condition|)
block|{
comment|/* 					 * Future calls to pmap_is_modified() 					 * can be avoided by making the page 					 * dirty now. 					 */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|atomic_clear_long
argument_list|(
name|pte
argument_list|,
name|PG_M
operator||
name|PG_A
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
name|atomic_clear_long
argument_list|(
name|pte
argument_list|,
name|PG_A
argument_list|)
expr_stmt|;
else|else
goto|goto
name|maybe_invlrng
goto|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_G
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|va
operator|==
name|va_next
condition|)
name|va
operator|=
name|sva
expr_stmt|;
block|}
else|else
name|anychanged
operator|=
name|TRUE
expr_stmt|;
continue|continue;
name|maybe_invlrng
label|:
if|if
condition|(
name|va
operator|!=
name|va_next
condition|)
block|{
name|pmap_invalidate_range
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|va
operator|=
name|va_next
expr_stmt|;
block|}
block|}
if|if
condition|(
name|va
operator|!=
name|va_next
condition|)
name|pmap_invalidate_range
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|sva
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|anychanged
condition|)
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_delayed_invl_finished
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Clear the modify bits on the specified physical page.  */
end_comment

begin_function
name|void
name|pmap_clear_modify
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pv_entry_t
name|next_pv
decl_stmt|,
name|pv
decl_stmt|;
name|pd_entry_t
name|oldpde
decl_stmt|,
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
name|oldpte
decl_stmt|,
modifier|*
name|pte
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|int
name|md_gen
decl_stmt|,
name|pvh_gen
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_clear_modify: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"pmap_clear_modify: page %p is exclusive busied"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not PGA_WRITEABLE, then no PTEs can have PG_M set. 	 * If the object containing the page is locked and the page is not 	 * exclusive busied, then PGA_WRITEABLE cannot be concurrently set. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|pvh
operator|=
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|?
operator|&
name|pv_dummy
else|:
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|lock
operator|=
name|VM_PAGE_TO_PV_LIST_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|restart
label|:
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|,
argument|next_pv
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pvh_gen
operator|=
name|pvh
operator|->
name|pv_gen
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvh_gen
operator|!=
name|pvh
operator|->
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
block|}
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|oldpde
operator|=
operator|*
name|pde
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_RW
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|pmap_demote_pde_locked
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|,
operator|&
name|lock
argument_list|)
condition|)
block|{
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 					 * Write protect the mapping to a 					 * single page so that a subsequent 					 * write access may repromote. 					 */
name|va
operator|+=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator|-
operator|(
name|oldpde
operator|&
name|PG_PS_FRAME
operator|)
expr_stmt|;
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|oldpte
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|oldpte
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
while|while
condition|(
operator|!
name|atomic_cmpset_long
argument_list|(
name|pte
argument_list|,
name|oldpte
argument_list|,
name|oldpte
operator|&
operator|~
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
argument_list|)
condition|)
name|oldpte
operator|=
operator|*
name|pte
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|md_gen
operator|=
name|m
operator|->
name|md
operator|.
name|pv_gen
expr_stmt|;
name|pvh_gen
operator|=
name|pvh
operator|->
name|pv_gen
expr_stmt|;
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvh_gen
operator|!=
name|pvh
operator|->
name|pv_gen
operator|||
name|md_gen
operator|!=
name|m
operator|->
name|md
operator|.
name|pv_gen
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|restart
goto|;
block|}
block|}
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_clear_modify: found"
literal|" a 2mpage in page %p's pv list"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
name|atomic_clear_long
argument_list|(
name|pte
argument_list|,
name|PG_M
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Miscellaneous support routines follow  */
end_comment

begin_comment
comment|/* Adjust the cache mode for a 4KB page mapped via a PTE. */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_pte_attr
parameter_list|(
name|pt_entry_t
modifier|*
name|pte
parameter_list|,
name|int
name|cache_bits
parameter_list|,
name|int
name|mask
parameter_list|)
block|{
name|u_int
name|opte
decl_stmt|,
name|npte
decl_stmt|;
comment|/* 	 * The cache mode bits are all in the low 32-bits of the 	 * PTE, so we can just spin on updating the low 32-bits. 	 */
do|do
block|{
name|opte
operator|=
operator|*
operator|(
name|u_int
operator|*
operator|)
name|pte
expr_stmt|;
name|npte
operator|=
name|opte
operator|&
operator|~
name|mask
expr_stmt|;
name|npte
operator||=
name|cache_bits
expr_stmt|;
block|}
do|while
condition|(
name|npte
operator|!=
name|opte
operator|&&
operator|!
name|atomic_cmpset_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|opte
argument_list|,
name|npte
argument_list|)
condition|)
do|;
block|}
end_function

begin_comment
comment|/* Adjust the cache mode for a 2MB page mapped via a PDE. */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_pde_attr
parameter_list|(
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|int
name|cache_bits
parameter_list|,
name|int
name|mask
parameter_list|)
block|{
name|u_int
name|opde
decl_stmt|,
name|npde
decl_stmt|;
comment|/* 	 * The cache mode bits are all in the low 32-bits of the 	 * PDE, so we can just spin on updating the low 32-bits. 	 */
do|do
block|{
name|opde
operator|=
operator|*
operator|(
name|u_int
operator|*
operator|)
name|pde
expr_stmt|;
name|npde
operator|=
name|opde
operator|&
operator|~
name|mask
expr_stmt|;
name|npde
operator||=
name|cache_bits
expr_stmt|;
block|}
do|while
condition|(
name|npde
operator|!=
name|opde
operator|&&
operator|!
name|atomic_cmpset_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pde
argument_list|,
name|opde
argument_list|,
name|npde
argument_list|)
condition|)
do|;
block|}
end_function

begin_comment
comment|/*  * Map a set of physical memory pages into the kernel virtual  * address space. Return a pointer to where it is mapped. This  * routine is intended to be used for mapping device memory,  * NOT real memory.  */
end_comment

begin_function
name|void
modifier|*
name|pmap_mapdev_attr
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|int
name|mode
parameter_list|)
block|{
name|struct
name|pmap_preinit_mapping
modifier|*
name|ppim
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|offset
decl_stmt|;
name|vm_size_t
name|tmpsize
decl_stmt|;
name|int
name|i
decl_stmt|;
name|offset
operator|=
name|pa
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|offset
operator|+
name|size
argument_list|)
expr_stmt|;
name|pa
operator|=
name|trunc_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pmap_initialized
condition|)
block|{
name|va
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PMAP_PREINIT_MAPPING_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|ppim
operator|=
name|pmap_preinit_mapping
operator|+
name|i
expr_stmt|;
if|if
condition|(
name|ppim
operator|->
name|va
operator|==
literal|0
condition|)
block|{
name|ppim
operator|->
name|pa
operator|=
name|pa
expr_stmt|;
name|ppim
operator|->
name|sz
operator|=
name|size
expr_stmt|;
name|ppim
operator|->
name|mode
operator|=
name|mode
expr_stmt|;
name|ppim
operator|->
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|size
expr_stmt|;
name|va
operator|=
name|ppim
operator|->
name|va
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|va
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: too many preinit mappings"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * If we have a preinit mapping, re-use it. 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PMAP_PREINIT_MAPPING_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|ppim
operator|=
name|pmap_preinit_mapping
operator|+
name|i
expr_stmt|;
if|if
condition|(
name|ppim
operator|->
name|pa
operator|==
name|pa
operator|&&
name|ppim
operator|->
name|sz
operator|==
name|size
operator|&&
name|ppim
operator|->
name|mode
operator|==
name|mode
condition|)
return|return
operator|(
operator|(
name|void
operator|*
operator|)
operator|(
name|ppim
operator|->
name|va
operator|+
name|offset
operator|)
operator|)
return|;
block|}
comment|/* 		 * If the specified range of physical addresses fits within 		 * the direct map window, use the direct map. 		 */
if|if
condition|(
name|pa
operator|<
name|dmaplimit
operator|&&
name|pa
operator|+
name|size
operator|<
name|dmaplimit
condition|)
block|{
name|va
operator|=
name|PHYS_TO_DMAP
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pmap_change_attr
argument_list|(
name|va
argument_list|,
name|size
argument_list|,
name|mode
argument_list|)
condition|)
return|return
operator|(
operator|(
name|void
operator|*
operator|)
operator|(
name|va
operator|+
name|offset
operator|)
operator|)
return|;
block|}
name|va
operator|=
name|kva_alloc
argument_list|(
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|va
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: Couldn't allocate KVA"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|tmpsize
operator|=
literal|0
init|;
name|tmpsize
operator|<
name|size
condition|;
name|tmpsize
operator|+=
name|PAGE_SIZE
control|)
name|pmap_kenter_attr
argument_list|(
name|va
operator|+
name|tmpsize
argument_list|,
name|pa
operator|+
name|tmpsize
argument_list|,
name|mode
argument_list|)
expr_stmt|;
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|,
name|va
operator|+
name|tmpsize
argument_list|)
expr_stmt|;
name|pmap_invalidate_cache_range
argument_list|(
name|va
argument_list|,
name|va
operator|+
name|tmpsize
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
return|return
operator|(
operator|(
name|void
operator|*
operator|)
operator|(
name|va
operator|+
name|offset
operator|)
operator|)
return|;
block|}
end_function

begin_function
name|void
modifier|*
name|pmap_mapdev
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
return|return
operator|(
name|pmap_mapdev_attr
argument_list|(
name|pa
argument_list|,
name|size
argument_list|,
name|PAT_UNCACHEABLE
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
modifier|*
name|pmap_mapbios
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
return|return
operator|(
name|pmap_mapdev_attr
argument_list|(
name|pa
argument_list|,
name|size
argument_list|,
name|PAT_WRITE_BACK
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_unmapdev
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|struct
name|pmap_preinit_mapping
modifier|*
name|ppim
decl_stmt|;
name|vm_offset_t
name|offset
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* If we gave a direct map region in pmap_mapdev, do nothing */
if|if
condition|(
name|va
operator|>=
name|DMAP_MIN_ADDRESS
operator|&&
name|va
operator|<
name|DMAP_MAX_ADDRESS
condition|)
return|return;
name|offset
operator|=
name|va
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|offset
operator|+
name|size
argument_list|)
expr_stmt|;
name|va
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PMAP_PREINIT_MAPPING_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|ppim
operator|=
name|pmap_preinit_mapping
operator|+
name|i
expr_stmt|;
if|if
condition|(
name|ppim
operator|->
name|va
operator|==
name|va
operator|&&
name|ppim
operator|->
name|sz
operator|==
name|size
condition|)
block|{
if|if
condition|(
name|pmap_initialized
condition|)
return|return;
name|ppim
operator|->
name|pa
operator|=
literal|0
expr_stmt|;
name|ppim
operator|->
name|va
operator|=
literal|0
expr_stmt|;
name|ppim
operator|->
name|sz
operator|=
literal|0
expr_stmt|;
name|ppim
operator|->
name|mode
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|va
operator|+
name|size
operator|==
name|virtual_avail
condition|)
name|virtual_avail
operator|=
name|va
expr_stmt|;
return|return;
block|}
block|}
if|if
condition|(
name|pmap_initialized
condition|)
name|kva_free
argument_list|(
name|va
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Tries to demote a 1GB page mapping.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_demote_pdpe
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pdp_entry_t
modifier|*
name|pdpe
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pdp_entry_t
name|newpdpe
decl_stmt|,
name|oldpdpe
decl_stmt|;
name|pd_entry_t
modifier|*
name|firstpde
decl_stmt|,
name|newpde
decl_stmt|,
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_paddr_t
name|pdpgpa
decl_stmt|;
name|vm_page_t
name|pdpg
decl_stmt|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|oldpdpe
operator|=
operator|*
name|pdpe
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|oldpdpe
operator|&
operator|(
name|PG_PS
operator||
name|PG_V
operator|)
operator|)
operator|==
operator|(
name|PG_PS
operator||
name|PG_V
operator|)
argument_list|,
operator|(
literal|"pmap_demote_pdpe: oldpdpe is missing PG_PS and/or PG_V"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pdpg
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|va
operator|>>
name|PDPSHIFT
argument_list|,
name|VM_ALLOC_INTERRUPT
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_demote_pdpe: failure for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
name|pdpgpa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|pdpg
argument_list|)
expr_stmt|;
name|firstpde
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|pdpgpa
argument_list|)
expr_stmt|;
name|newpdpe
operator|=
name|pdpgpa
operator||
name|PG_M
operator||
name|PG_A
operator||
operator|(
name|oldpdpe
operator|&
name|PG_U
operator|)
operator||
name|PG_RW
operator||
name|PG_V
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|oldpdpe
operator|&
name|PG_A
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_demote_pdpe: oldpdpe is missing PG_A"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|oldpdpe
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|!=
name|PG_RW
argument_list|,
operator|(
literal|"pmap_demote_pdpe: oldpdpe is missing PG_M"
operator|)
argument_list|)
expr_stmt|;
name|newpde
operator|=
name|oldpdpe
expr_stmt|;
comment|/* 	 * Initialize the page directory page. 	 */
for|for
control|(
name|pde
operator|=
name|firstpde
init|;
name|pde
operator|<
name|firstpde
operator|+
name|NPDEPG
condition|;
name|pde
operator|++
control|)
block|{
operator|*
name|pde
operator|=
name|newpde
expr_stmt|;
name|newpde
operator|+=
name|NBPDR
expr_stmt|;
block|}
comment|/* 	 * Demote the mapping. 	 */
operator|*
name|pdpe
operator|=
name|newpdpe
expr_stmt|;
comment|/* 	 * Invalidate a stale recursive mapping of the page directory page. 	 */
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|vtopde
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
name|pmap_pdpe_demotions
operator|++
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_demote_pdpe: success for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Sets the memory attribute for the specified page.  */
end_comment

begin_function
name|void
name|pmap_page_set_memattr
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|m
operator|->
name|md
operator|.
name|pat_mode
operator|=
name|ma
expr_stmt|;
comment|/* 	 * If "m" is a normal page, update its direct mapping.  This update 	 * can be relied upon to perform any cache operations that are 	 * required for data coherence. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
name|pmap_change_attr
argument_list|(
name|PHYS_TO_DMAP
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|,
name|PAGE_SIZE
argument_list|,
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|)
condition|)
name|panic
argument_list|(
literal|"memory attribute change on the direct map failed"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Changes the specified virtual address range's memory type to that given by  * the parameter "mode".  The specified virtual address range must be  * completely contained within either the direct map or the kernel map.  If  * the virtual address range is contained within the kernel map, then the  * memory type for each of the corresponding ranges of the direct map is also  * changed.  (The corresponding ranges of the direct map are those ranges that  * map the same physical pages as the specified virtual address range.)  These  * changes to the direct map are necessary because Intel describes the  * behavior of their processors as "undefined" if two or more mappings to the  * same physical page have different memory types.  *  * Returns zero if the change completed successfully, and either EINVAL or  * ENOMEM if the change failed.  Specifically, EINVAL is returned if some part  * of the virtual address range was not mapped, and ENOMEM is returned if  * there was insufficient memory available to complete the change.  In the  * latter case, the memory type may have been changed on some part of the  * virtual address range or the direct map.  */
end_comment

begin_function
name|int
name|pmap_change_attr
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|int
name|mode
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|error
operator|=
name|pmap_change_attr_locked
argument_list|(
name|va
argument_list|,
name|size
argument_list|,
name|mode
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|pmap_change_attr_locked
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|int
name|mode
parameter_list|)
block|{
name|vm_offset_t
name|base
decl_stmt|,
name|offset
decl_stmt|,
name|tmpva
decl_stmt|;
name|vm_paddr_t
name|pa_start
decl_stmt|,
name|pa_end
decl_stmt|,
name|pa_end1
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|int
name|cache_bits_pte
decl_stmt|,
name|cache_bits_pde
decl_stmt|,
name|error
decl_stmt|;
name|boolean_t
name|changed
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|kernel_pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|base
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|offset
operator|=
name|va
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|offset
operator|+
name|size
argument_list|)
expr_stmt|;
comment|/* 	 * Only supported on kernel virtual addresses, including the direct 	 * map but excluding the recursive map. 	 */
if|if
condition|(
name|base
operator|<
name|DMAP_MIN_ADDRESS
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|cache_bits_pde
operator|=
name|pmap_cache_bits
argument_list|(
name|kernel_pmap
argument_list|,
name|mode
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|cache_bits_pte
operator|=
name|pmap_cache_bits
argument_list|(
name|kernel_pmap
argument_list|,
name|mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|changed
operator|=
name|FALSE
expr_stmt|;
comment|/* 	 * Pages that aren't mapped aren't supported.  Also break down 2MB pages 	 * into 4KB pages if required. 	 */
for|for
control|(
name|tmpva
operator|=
name|base
init|;
name|tmpva
operator|<
name|base
operator|+
name|size
condition|;
control|)
block|{
name|pdpe
operator|=
name|pmap_pdpe
argument_list|(
name|kernel_pmap
argument_list|,
name|tmpva
argument_list|)
expr_stmt|;
if|if
condition|(
name|pdpe
operator|==
name|NULL
operator|||
operator|*
name|pdpe
operator|==
literal|0
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
if|if
condition|(
operator|*
name|pdpe
operator|&
name|PG_PS
condition|)
block|{
comment|/* 			 * If the current 1GB page already has the required 			 * memory type, then we need not demote this page. Just 			 * increment tmpva to the next 1GB page frame. 			 */
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|X86_PG_PDE_CACHE
operator|)
operator|==
name|cache_bits_pde
condition|)
block|{
name|tmpva
operator|=
name|trunc_1gpage
argument_list|(
name|tmpva
argument_list|)
operator|+
name|NBPDP
expr_stmt|;
continue|continue;
block|}
comment|/* 			 * If the current offset aligns with a 1GB page frame 			 * and there is at least 1GB left within the range, then 			 * we need not break down this page into 2MB pages. 			 */
if|if
condition|(
operator|(
name|tmpva
operator|&
name|PDPMASK
operator|)
operator|==
literal|0
operator|&&
name|tmpva
operator|+
name|PDPMASK
operator|<
name|base
operator|+
name|size
condition|)
block|{
name|tmpva
operator|+=
name|NBPDP
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|!
name|pmap_demote_pdpe
argument_list|(
name|kernel_pmap
argument_list|,
name|pdpe
argument_list|,
name|tmpva
argument_list|)
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|tmpva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pde
operator|==
literal|0
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
if|if
condition|(
operator|*
name|pde
operator|&
name|PG_PS
condition|)
block|{
comment|/* 			 * If the current 2MB page already has the required 			 * memory type, then we need not demote this page. Just 			 * increment tmpva to the next 2MB page frame. 			 */
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|X86_PG_PDE_CACHE
operator|)
operator|==
name|cache_bits_pde
condition|)
block|{
name|tmpva
operator|=
name|trunc_2mpage
argument_list|(
name|tmpva
argument_list|)
operator|+
name|NBPDR
expr_stmt|;
continue|continue;
block|}
comment|/* 			 * If the current offset aligns with a 2MB page frame 			 * and there is at least 2MB left within the range, then 			 * we need not break down this page into 4KB pages. 			 */
if|if
condition|(
operator|(
name|tmpva
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
operator|&&
name|tmpva
operator|+
name|PDRMASK
operator|<
name|base
operator|+
name|size
condition|)
block|{
name|tmpva
operator|+=
name|NBPDR
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|!
name|pmap_demote_pde
argument_list|(
name|kernel_pmap
argument_list|,
name|pde
argument_list|,
name|tmpva
argument_list|)
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|tmpva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pte
operator|==
literal|0
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|tmpva
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|error
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Ok, all the pages exist, so run through them updating their 	 * cache mode if required. 	 */
name|pa_start
operator|=
name|pa_end
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|tmpva
operator|=
name|base
init|;
name|tmpva
operator|<
name|base
operator|+
name|size
condition|;
control|)
block|{
name|pdpe
operator|=
name|pmap_pdpe
argument_list|(
name|kernel_pmap
argument_list|,
name|tmpva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pdpe
operator|&
name|PG_PS
condition|)
block|{
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|X86_PG_PDE_CACHE
operator|)
operator|!=
name|cache_bits_pde
condition|)
block|{
name|pmap_pde_attr
argument_list|(
name|pdpe
argument_list|,
name|cache_bits_pde
argument_list|,
name|X86_PG_PDE_CACHE
argument_list|)
expr_stmt|;
name|changed
operator|=
name|TRUE
expr_stmt|;
block|}
if|if
condition|(
name|tmpva
operator|>=
name|VM_MIN_KERNEL_ADDRESS
operator|&&
operator|(
operator|*
name|pdpe
operator|&
name|PG_PS_FRAME
operator|)
operator|<
name|dmaplimit
condition|)
block|{
if|if
condition|(
name|pa_start
operator|==
name|pa_end
condition|)
block|{
comment|/* Start physical address run. */
name|pa_start
operator|=
operator|*
name|pdpe
operator|&
name|PG_PS_FRAME
expr_stmt|;
name|pa_end
operator|=
name|pa_start
operator|+
name|NBPDP
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pa_end
operator|==
operator|(
operator|*
name|pdpe
operator|&
name|PG_PS_FRAME
operator|)
condition|)
name|pa_end
operator|+=
name|NBPDP
expr_stmt|;
else|else
block|{
comment|/* Run ended, update direct map. */
name|error
operator|=
name|pmap_change_attr_locked
argument_list|(
name|PHYS_TO_DMAP
argument_list|(
name|pa_start
argument_list|)
argument_list|,
name|pa_end
operator|-
name|pa_start
argument_list|,
name|mode
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
break|break;
comment|/* Start physical address run. */
name|pa_start
operator|=
operator|*
name|pdpe
operator|&
name|PG_PS_FRAME
expr_stmt|;
name|pa_end
operator|=
name|pa_start
operator|+
name|NBPDP
expr_stmt|;
block|}
block|}
name|tmpva
operator|=
name|trunc_1gpage
argument_list|(
name|tmpva
argument_list|)
operator|+
name|NBPDP
expr_stmt|;
continue|continue;
block|}
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|tmpva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pde
operator|&
name|PG_PS
condition|)
block|{
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|X86_PG_PDE_CACHE
operator|)
operator|!=
name|cache_bits_pde
condition|)
block|{
name|pmap_pde_attr
argument_list|(
name|pde
argument_list|,
name|cache_bits_pde
argument_list|,
name|X86_PG_PDE_CACHE
argument_list|)
expr_stmt|;
name|changed
operator|=
name|TRUE
expr_stmt|;
block|}
if|if
condition|(
name|tmpva
operator|>=
name|VM_MIN_KERNEL_ADDRESS
operator|&&
operator|(
operator|*
name|pde
operator|&
name|PG_PS_FRAME
operator|)
operator|<
name|dmaplimit
condition|)
block|{
if|if
condition|(
name|pa_start
operator|==
name|pa_end
condition|)
block|{
comment|/* Start physical address run. */
name|pa_start
operator|=
operator|*
name|pde
operator|&
name|PG_PS_FRAME
expr_stmt|;
name|pa_end
operator|=
name|pa_start
operator|+
name|NBPDR
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pa_end
operator|==
operator|(
operator|*
name|pde
operator|&
name|PG_PS_FRAME
operator|)
condition|)
name|pa_end
operator|+=
name|NBPDR
expr_stmt|;
else|else
block|{
comment|/* Run ended, update direct map. */
name|error
operator|=
name|pmap_change_attr_locked
argument_list|(
name|PHYS_TO_DMAP
argument_list|(
name|pa_start
argument_list|)
argument_list|,
name|pa_end
operator|-
name|pa_start
argument_list|,
name|mode
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
break|break;
comment|/* Start physical address run. */
name|pa_start
operator|=
operator|*
name|pde
operator|&
name|PG_PS_FRAME
expr_stmt|;
name|pa_end
operator|=
name|pa_start
operator|+
name|NBPDR
expr_stmt|;
block|}
block|}
name|tmpva
operator|=
name|trunc_2mpage
argument_list|(
name|tmpva
argument_list|)
operator|+
name|NBPDR
expr_stmt|;
block|}
else|else
block|{
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|tmpva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|X86_PG_PTE_CACHE
operator|)
operator|!=
name|cache_bits_pte
condition|)
block|{
name|pmap_pte_attr
argument_list|(
name|pte
argument_list|,
name|cache_bits_pte
argument_list|,
name|X86_PG_PTE_CACHE
argument_list|)
expr_stmt|;
name|changed
operator|=
name|TRUE
expr_stmt|;
block|}
if|if
condition|(
name|tmpva
operator|>=
name|VM_MIN_KERNEL_ADDRESS
operator|&&
operator|(
operator|*
name|pte
operator|&
name|PG_FRAME
operator|)
operator|<
name|dmaplimit
condition|)
block|{
if|if
condition|(
name|pa_start
operator|==
name|pa_end
condition|)
block|{
comment|/* Start physical address run. */
name|pa_start
operator|=
operator|*
name|pte
operator|&
name|PG_FRAME
expr_stmt|;
name|pa_end
operator|=
name|pa_start
operator|+
name|PAGE_SIZE
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pa_end
operator|==
operator|(
operator|*
name|pte
operator|&
name|PG_FRAME
operator|)
condition|)
name|pa_end
operator|+=
name|PAGE_SIZE
expr_stmt|;
else|else
block|{
comment|/* Run ended, update direct map. */
name|error
operator|=
name|pmap_change_attr_locked
argument_list|(
name|PHYS_TO_DMAP
argument_list|(
name|pa_start
argument_list|)
argument_list|,
name|pa_end
operator|-
name|pa_start
argument_list|,
name|mode
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
break|break;
comment|/* Start physical address run. */
name|pa_start
operator|=
operator|*
name|pte
operator|&
name|PG_FRAME
expr_stmt|;
name|pa_end
operator|=
name|pa_start
operator|+
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
name|tmpva
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
if|if
condition|(
name|error
operator|==
literal|0
operator|&&
name|pa_start
operator|!=
name|pa_end
operator|&&
name|pa_start
operator|<
name|dmaplimit
condition|)
block|{
name|pa_end1
operator|=
name|MIN
argument_list|(
name|pa_end
argument_list|,
name|dmaplimit
argument_list|)
expr_stmt|;
if|if
condition|(
name|pa_start
operator|!=
name|pa_end1
condition|)
name|error
operator|=
name|pmap_change_attr_locked
argument_list|(
name|PHYS_TO_DMAP
argument_list|(
name|pa_start
argument_list|)
argument_list|,
name|pa_end1
operator|-
name|pa_start
argument_list|,
name|mode
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Flush CPU caches if required to make sure any data isn't cached that 	 * shouldn't be, etc. 	 */
if|if
condition|(
name|changed
condition|)
block|{
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|base
argument_list|,
name|tmpva
argument_list|)
expr_stmt|;
name|pmap_invalidate_cache_range
argument_list|(
name|base
argument_list|,
name|tmpva
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Demotes any mapping within the direct map region that covers more than the  * specified range of physical addresses.  This range's size must be a power  * of two and its starting address must be a multiple of its size.  Since the  * demotion does not change any attributes of the mapping, a TLB invalidation  * is not mandatory.  The caller may, however, request a TLB invalidation.  */
end_comment

begin_function
name|void
name|pmap_demote_DMAP
parameter_list|(
name|vm_paddr_t
name|base
parameter_list|,
name|vm_size_t
name|len
parameter_list|,
name|boolean_t
name|invalidate
parameter_list|)
block|{
name|pdp_entry_t
modifier|*
name|pdpe
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|boolean_t
name|changed
decl_stmt|;
if|if
condition|(
name|len
operator|==
literal|0
condition|)
return|return;
name|KASSERT
argument_list|(
name|powerof2
argument_list|(
name|len
argument_list|)
argument_list|,
operator|(
literal|"pmap_demote_DMAP: len is not a power of 2"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|base
operator|&
operator|(
name|len
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_demote_DMAP: base is not a multiple of len"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|len
operator|<
name|NBPDP
operator|&&
name|base
operator|<
name|dmaplimit
condition|)
block|{
name|va
operator|=
name|PHYS_TO_DMAP
argument_list|(
name|base
argument_list|)
expr_stmt|;
name|changed
operator|=
name|FALSE
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|pdpe
operator|=
name|pmap_pdpe
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|X86_PG_V
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_demote_DMAP: invalid PDPE"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdpe
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|pmap_demote_pdpe
argument_list|(
name|kernel_pmap
argument_list|,
name|pdpe
argument_list|,
name|va
argument_list|)
condition|)
name|panic
argument_list|(
literal|"pmap_demote_DMAP: PDPE failed"
argument_list|)
expr_stmt|;
name|changed
operator|=
name|TRUE
expr_stmt|;
block|}
if|if
condition|(
name|len
operator|<
name|NBPDR
condition|)
block|{
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdpe
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|X86_PG_V
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_demote_DMAP: invalid PDE"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|pmap_demote_pde
argument_list|(
name|kernel_pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|)
condition|)
name|panic
argument_list|(
literal|"pmap_demote_DMAP: PDE failed"
argument_list|)
expr_stmt|;
name|changed
operator|=
name|TRUE
expr_stmt|;
block|}
block|}
if|if
condition|(
name|changed
operator|&&
name|invalidate
condition|)
name|pmap_invalidate_page
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * perform the pmap work for mincore  */
end_comment

begin_function
name|int
name|pmap_mincore
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|vm_paddr_t
modifier|*
name|locked_pa
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pdep
decl_stmt|;
name|pt_entry_t
name|pte
decl_stmt|,
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|int
name|val
decl_stmt|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|pdep
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
name|pdep
operator|!=
name|NULL
operator|&&
operator|(
operator|*
name|pdep
operator|&
name|PG_V
operator|)
condition|)
block|{
if|if
condition|(
operator|*
name|pdep
operator|&
name|PG_PS
condition|)
block|{
name|pte
operator|=
operator|*
name|pdep
expr_stmt|;
comment|/* Compute the physical address of the 4KB page. */
name|pa
operator|=
operator|(
operator|(
operator|*
name|pdep
operator|&
name|PG_PS_FRAME
operator|)
operator||
operator|(
name|addr
operator|&
name|PDRMASK
operator|)
operator|)
operator|&
name|PG_FRAME
expr_stmt|;
name|val
operator|=
name|MINCORE_SUPER
expr_stmt|;
block|}
else|else
block|{
name|pte
operator|=
operator|*
name|pmap_pde_to_pte
argument_list|(
name|pdep
argument_list|,
name|addr
argument_list|)
expr_stmt|;
name|pa
operator|=
name|pte
operator|&
name|PG_FRAME
expr_stmt|;
name|val
operator|=
literal|0
expr_stmt|;
block|}
block|}
else|else
block|{
name|pte
operator|=
literal|0
expr_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
name|val
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|pte
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
name|val
operator||=
name|MINCORE_INCORE
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|val
operator||=
name|MINCORE_MODIFIED
operator||
name|MINCORE_MODIFIED_OTHER
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
name|val
operator||=
name|MINCORE_REFERENCED
operator||
name|MINCORE_REFERENCED_OTHER
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|val
operator|&
operator|(
name|MINCORE_MODIFIED_OTHER
operator||
name|MINCORE_REFERENCED_OTHER
operator|)
operator|)
operator|!=
operator|(
name|MINCORE_MODIFIED_OTHER
operator||
name|MINCORE_REFERENCED_OTHER
operator|)
operator|&&
operator|(
name|pte
operator|&
operator|(
name|PG_MANAGED
operator||
name|PG_V
operator|)
operator|)
operator|==
operator|(
name|PG_MANAGED
operator||
name|PG_V
operator|)
condition|)
block|{
comment|/* Ensure that "PHYS_TO_VM_PAGE(pa)->object" doesn't change. */
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|pa
argument_list|,
name|locked_pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
block|}
else|else
name|PA_UNLOCK_COND
argument_list|(
operator|*
name|locked_pa
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|val
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|uint64_t
name|pmap_pcid_alloc
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|u_int
name|cpuid
parameter_list|)
block|{
name|uint32_t
name|gen
decl_stmt|,
name|new_gen
decl_stmt|,
name|pcid_next
decl_stmt|;
name|CRITICAL_ASSERT
argument_list|(
name|curthread
argument_list|)
expr_stmt|;
name|gen
operator|=
name|PCPU_GET
argument_list|(
name|pcid_gen
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_pcid
operator|==
name|PMAP_PCID_KERN
operator|||
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_gen
operator|==
name|gen
condition|)
return|return
operator|(
name|CR3_PCID_SAVE
operator|)
return|;
name|pcid_next
operator|=
name|PCPU_GET
argument_list|(
name|pcid_next
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pcid_next
operator|<=
name|PMAP_PCID_OVERMAX
argument_list|,
operator|(
literal|"cpu %d pcid_next %#x"
operator|,
name|cpuid
operator|,
name|pcid_next
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pcid_next
operator|==
name|PMAP_PCID_OVERMAX
condition|)
block|{
name|new_gen
operator|=
name|gen
operator|+
literal|1
expr_stmt|;
if|if
condition|(
name|new_gen
operator|==
literal|0
condition|)
name|new_gen
operator|=
literal|1
expr_stmt|;
name|PCPU_SET
argument_list|(
name|pcid_gen
argument_list|,
name|new_gen
argument_list|)
expr_stmt|;
name|pcid_next
operator|=
name|PMAP_PCID_KERN
operator|+
literal|1
expr_stmt|;
block|}
else|else
block|{
name|new_gen
operator|=
name|gen
expr_stmt|;
block|}
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_pcid
operator|=
name|pcid_next
expr_stmt|;
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_gen
operator|=
name|new_gen
expr_stmt|;
name|PCPU_SET
argument_list|(
name|pcid_next
argument_list|,
name|pcid_next
operator|+
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_activate_sw
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|oldpmap
decl_stmt|,
name|pmap
decl_stmt|;
name|uint64_t
name|cached
decl_stmt|,
name|cr3
decl_stmt|;
name|register_t
name|rflags
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|;
name|oldpmap
operator|=
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
expr_stmt|;
name|pmap
operator|=
name|vmspace_pmap
argument_list|(
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpmap
operator|==
name|pmap
condition|)
return|return;
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|CPU_SET_ATOMIC
argument_list|(
name|cpuid
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
else|#
directive|else
name|CPU_SET
argument_list|(
name|cpuid
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|cr3
operator|=
name|rcr3
argument_list|()
expr_stmt|;
if|if
condition|(
name|pmap_pcid_enabled
condition|)
block|{
name|cached
operator|=
name|pmap_pcid_alloc
argument_list|(
name|pmap
argument_list|,
name|cpuid
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_pcid
operator|>=
literal|0
operator|&&
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_pcid
operator|<
name|PMAP_PCID_OVERMAX
argument_list|,
operator|(
literal|"pmap %p cpu %d pcid %#x"
operator|,
name|pmap
operator|,
name|cpuid
operator|,
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_pcid
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_pcid
operator|!=
name|PMAP_PCID_KERN
operator|||
name|pmap
operator|==
name|kernel_pmap
argument_list|,
operator|(
literal|"non-kernel pmap thread %p pmap %p cpu %d pcid %#x"
operator|,
name|td
operator|,
name|pmap
operator|,
name|cpuid
operator|,
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_pcid
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * If the INVPCID instruction is not available, 		 * invltlb_pcid_handler() is used for handle 		 * invalidate_all IPI, which checks for curpmap == 		 * smp_tlb_pmap.  Below operations sequence has a 		 * window where %CR3 is loaded with the new pmap's 		 * PML4 address, but curpmap value is not yet updated. 		 * This causes invltlb IPI handler, called between the 		 * updates, to execute as NOP, which leaves stale TLB 		 * entries. 		 * 		 * Note that the most typical use of 		 * pmap_activate_sw(), from the context switch, is 		 * immune to this race, because interrupts are 		 * disabled (while the thread lock is owned), and IPI 		 * happends after curpmap is updated.  Protect other 		 * callers in a similar way, by disabling interrupts 		 * around the %cr3 register reload and curpmap 		 * assignment. 		 */
if|if
condition|(
operator|!
name|invpcid_works
condition|)
name|rflags
operator|=
name|intr_disable
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|cached
operator|||
operator|(
name|cr3
operator|&
operator|~
name|CR3_PCID_MASK
operator|)
operator|!=
name|pmap
operator|->
name|pm_cr3
condition|)
block|{
name|load_cr3
argument_list|(
name|pmap
operator|->
name|pm_cr3
operator||
name|pmap
operator|->
name|pm_pcids
index|[
name|cpuid
index|]
operator|.
name|pm_pcid
operator||
name|cached
argument_list|)
expr_stmt|;
if|if
condition|(
name|cached
condition|)
name|PCPU_INC
argument_list|(
name|pm_save_cnt
argument_list|)
expr_stmt|;
block|}
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|invpcid_works
condition|)
name|intr_restore
argument_list|(
name|rflags
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cr3
operator|!=
name|pmap
operator|->
name|pm_cr3
condition|)
block|{
name|load_cr3
argument_list|(
name|pmap
operator|->
name|pm_cr3
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|SMP
name|CPU_CLR_ATOMIC
argument_list|(
name|cpuid
argument_list|,
operator|&
name|oldpmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
else|#
directive|else
name|CPU_CLR
argument_list|(
name|cpuid
argument_list|,
operator|&
name|oldpmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|pmap_activate
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|critical_enter
argument_list|()
expr_stmt|;
name|pmap_activate_sw
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|critical_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_sync_icache
parameter_list|(
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|sz
parameter_list|)
block|{ }
end_function

begin_comment
comment|/*  *	Increase the starting virtual address of the given mapping if a  *	different alignment might result in more superpage mappings.  */
end_comment

begin_function
name|void
name|pmap_align_superpage
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_ooffset_t
name|offset
parameter_list|,
name|vm_offset_t
modifier|*
name|addr
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|vm_offset_t
name|superpage_offset
decl_stmt|;
if|if
condition|(
name|size
operator|<
name|NBPDR
condition|)
return|return;
if|if
condition|(
name|object
operator|!=
name|NULL
operator|&&
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_COLORED
operator|)
operator|!=
literal|0
condition|)
name|offset
operator|+=
name|ptoa
argument_list|(
name|object
operator|->
name|pg_color
argument_list|)
expr_stmt|;
name|superpage_offset
operator|=
name|offset
operator|&
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|size
operator|-
operator|(
operator|(
name|NBPDR
operator|-
name|superpage_offset
operator|)
operator|&
name|PDRMASK
operator|)
operator|<
name|NBPDR
operator|||
operator|(
operator|*
name|addr
operator|&
name|PDRMASK
operator|)
operator|==
name|superpage_offset
condition|)
return|return;
if|if
condition|(
operator|(
operator|*
name|addr
operator|&
name|PDRMASK
operator|)
operator|<
name|superpage_offset
condition|)
operator|*
name|addr
operator|=
operator|(
operator|*
name|addr
operator|&
operator|~
name|PDRMASK
operator|)
operator|+
name|superpage_offset
expr_stmt|;
else|else
operator|*
name|addr
operator|=
operator|(
operator|(
operator|*
name|addr
operator|+
name|PDRMASK
operator|)
operator|&
operator|~
name|PDRMASK
operator|)
operator|+
name|superpage_offset
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|INVARIANTS
end_ifdef

begin_decl_stmt
specifier|static
name|unsigned
name|long
name|num_dirty_emulations
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|num_dirty_emulations
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|num_dirty_emulations
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|unsigned
name|long
name|num_accessed_emulations
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|num_accessed_emulations
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|num_accessed_emulations
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|unsigned
name|long
name|num_superpage_accessed_emulations
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|num_superpage_accessed_emulations
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|num_superpage_accessed_emulations
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|unsigned
name|long
name|ad_emulation_superpage_promotions
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|ad_emulation_superpage_promotions
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|ad_emulation_superpage_promotions
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* INVARIANTS */
end_comment

begin_function
name|int
name|pmap_emulate_accessed_dirty
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|int
name|ftype
parameter_list|)
block|{
name|int
name|rv
decl_stmt|;
name|struct
name|rwlock
modifier|*
name|lock
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mpte
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_A
decl_stmt|,
name|PG_M
decl_stmt|,
name|PG_RW
decl_stmt|,
name|PG_V
decl_stmt|;
name|KASSERT
argument_list|(
name|ftype
operator|==
name|VM_PROT_READ
operator|||
name|ftype
operator|==
name|VM_PROT_WRITE
argument_list|,
operator|(
literal|"pmap_emulate_accessed_dirty: invalid fault type %d"
operator|,
name|ftype
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pmap_emulate_ad_bits
argument_list|(
name|pmap
argument_list|)
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
name|PG_A
operator|=
name|pmap_accessed_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_M
operator|=
name|pmap_modified_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PG_RW
operator|=
name|pmap_rw_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rv
operator|=
operator|-
literal|1
expr_stmt|;
name|lock
operator|=
name|NULL
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pde
operator|==
name|NULL
operator|||
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
goto|goto
name|done
goto|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|ftype
operator|==
name|VM_PROT_READ
condition|)
block|{
ifdef|#
directive|ifdef
name|INVARIANTS
name|atomic_add_long
argument_list|(
operator|&
name|num_superpage_accessed_emulations
argument_list|,
literal|1
argument_list|)
expr_stmt|;
endif|#
directive|endif
operator|*
name|pde
operator||=
name|PG_A
expr_stmt|;
name|rv
operator|=
literal|0
expr_stmt|;
block|}
goto|goto
name|done
goto|;
block|}
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
goto|goto
name|done
goto|;
if|if
condition|(
name|ftype
operator|==
name|VM_PROT_WRITE
condition|)
block|{
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_RW
operator|)
operator|==
literal|0
condition|)
goto|goto
name|done
goto|;
comment|/* 		 * Set the modified and accessed bits simultaneously. 		 * 		 * Intel EPT PTEs that do software emulation of A/D bits map 		 * PG_A and PG_M to EPT_PG_READ and EPT_PG_WRITE respectively. 		 * An EPT misconfiguration is triggered if the PTE is writable 		 * but not readable (WR=10). This is avoided by setting PG_A 		 * and PG_M simultaneously. 		 */
operator|*
name|pte
operator||=
name|PG_M
operator||
name|PG_A
expr_stmt|;
block|}
else|else
block|{
operator|*
name|pte
operator||=
name|PG_A
expr_stmt|;
block|}
comment|/* try to promote the mapping */
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pde
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
else|else
name|mpte
operator|=
name|NULL
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|mpte
operator|==
name|NULL
operator|||
name|mpte
operator|->
name|wire_count
operator|==
name|NPTEPG
operator|)
operator|&&
name|pmap_ps_enabled
argument_list|(
name|pmap
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
name|vm_reserv_level_iffullpop
argument_list|(
name|m
argument_list|)
operator|==
literal|0
condition|)
block|{
name|pmap_promote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|,
operator|&
name|lock
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|INVARIANTS
name|atomic_add_long
argument_list|(
operator|&
name|ad_emulation_superpage_promotions
argument_list|,
literal|1
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
ifdef|#
directive|ifdef
name|INVARIANTS
if|if
condition|(
name|ftype
operator|==
name|VM_PROT_WRITE
condition|)
name|atomic_add_long
argument_list|(
operator|&
name|num_dirty_emulations
argument_list|,
literal|1
argument_list|)
expr_stmt|;
else|else
name|atomic_add_long
argument_list|(
operator|&
name|num_accessed_emulations
argument_list|,
literal|1
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|rv
operator|=
literal|0
expr_stmt|;
comment|/* success */
name|done
label|:
if|if
condition|(
name|lock
operator|!=
name|NULL
condition|)
name|rw_wunlock
argument_list|(
name|lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_get_mapping
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|uint64_t
modifier|*
name|ptr
parameter_list|,
name|int
modifier|*
name|num
parameter_list|)
block|{
name|pml4_entry_t
modifier|*
name|pml4
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdp
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_V
decl_stmt|;
name|int
name|idx
decl_stmt|;
name|idx
operator|=
literal|0
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pml4
operator|=
name|pmap_pml4e
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|ptr
index|[
name|idx
operator|++
index|]
operator|=
operator|*
name|pml4
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pml4
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
goto|goto
name|done
goto|;
name|pdp
operator|=
name|pmap_pml4e_to_pdpe
argument_list|(
name|pml4
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|ptr
index|[
name|idx
operator|++
index|]
operator|=
operator|*
name|pdp
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdp
operator|&
name|PG_V
operator|)
operator|==
literal|0
operator|||
operator|(
operator|*
name|pdp
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
goto|goto
name|done
goto|;
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdp
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|ptr
index|[
name|idx
operator|++
index|]
operator|=
operator|*
name|pde
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|==
literal|0
operator|||
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
goto|goto
name|done
goto|;
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|ptr
index|[
name|idx
operator|++
index|]
operator|=
operator|*
name|pte
expr_stmt|;
name|done
label|:
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
operator|*
name|num
operator|=
name|idx
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Get the kernel virtual address of a set of physical pages. If there are  * physical addresses not covered by the DMAP perform a transient mapping  * that will be removed when calling pmap_unmap_io_transient.  *  * \param page        The pages the caller wishes to obtain the virtual  *                    address on the kernel memory map.  * \param vaddr       On return contains the kernel virtual memory address  *                    of the pages passed in the page parameter.  * \param count       Number of pages passed in.  * \param can_fault   TRUE if the thread using the mapped pages can take  *                    page faults, FALSE otherwise.  *  * \returns TRUE if the caller must call pmap_unmap_io_transient when  *          finished or FALSE otherwise.  *  */
end_comment

begin_function
name|boolean_t
name|pmap_map_io_transient
parameter_list|(
name|vm_page_t
name|page
index|[]
parameter_list|,
name|vm_offset_t
name|vaddr
index|[]
parameter_list|,
name|int
name|count
parameter_list|,
name|boolean_t
name|can_fault
parameter_list|)
block|{
name|vm_paddr_t
name|paddr
decl_stmt|;
name|boolean_t
name|needs_mapping
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|int
name|cache_bits
decl_stmt|,
name|error
decl_stmt|,
name|i
decl_stmt|;
comment|/* 	 * Allocate any KVA space that we need, this is done in a separate 	 * loop to prevent calling vmem_alloc while pinned. 	 */
name|needs_mapping
operator|=
name|FALSE
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|page
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|__predict_false
argument_list|(
name|paddr
operator|>=
name|dmaplimit
argument_list|)
condition|)
block|{
name|error
operator|=
name|vmem_alloc
argument_list|(
name|kernel_arena
argument_list|,
name|PAGE_SIZE
argument_list|,
name|M_BESTFIT
operator||
name|M_WAITOK
argument_list|,
operator|&
name|vaddr
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|error
operator|==
literal|0
argument_list|,
operator|(
literal|"vmem_alloc failed: %d"
operator|,
name|error
operator|)
argument_list|)
expr_stmt|;
name|needs_mapping
operator|=
name|TRUE
expr_stmt|;
block|}
else|else
block|{
name|vaddr
index|[
name|i
index|]
operator|=
name|PHYS_TO_DMAP
argument_list|(
name|paddr
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* Exit early if everything is covered by the DMAP */
if|if
condition|(
operator|!
name|needs_mapping
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
comment|/* 	 * NB:  The sequence of updating a page table followed by accesses 	 * to the corresponding pages used in the !DMAP case is subject to 	 * the situation described in the "AMD64 Architecture Programmer's 	 * Manual Volume 2: System Programming" rev. 3.23, "7.3.1 Special 	 * Coherency Considerations".  Therefore, issuing the INVLPG right 	 * after modifying the PTE bits is crucial. 	 */
if|if
condition|(
operator|!
name|can_fault
condition|)
name|sched_pin
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|page
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|paddr
operator|>=
name|dmaplimit
condition|)
block|{
if|if
condition|(
name|can_fault
condition|)
block|{
comment|/* 				 * Slow path, since we can get page faults 				 * while mappings are active don't pin the 				 * thread to the CPU and instead add a global 				 * mapping visible to all CPUs. 				 */
name|pmap_qenter
argument_list|(
name|vaddr
index|[
name|i
index|]
argument_list|,
operator|&
name|page
index|[
name|i
index|]
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pte
operator|=
name|vtopte
argument_list|(
name|vaddr
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|cache_bits
operator|=
name|pmap_cache_bits
argument_list|(
name|kernel_pmap
argument_list|,
name|page
index|[
name|i
index|]
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|pte_store
argument_list|(
name|pte
argument_list|,
name|paddr
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|cache_bits
argument_list|)
expr_stmt|;
name|invlpg
argument_list|(
name|vaddr
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
operator|(
name|needs_mapping
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_unmap_io_transient
parameter_list|(
name|vm_page_t
name|page
index|[]
parameter_list|,
name|vm_offset_t
name|vaddr
index|[]
parameter_list|,
name|int
name|count
parameter_list|,
name|boolean_t
name|can_fault
parameter_list|)
block|{
name|vm_paddr_t
name|paddr
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
operator|!
name|can_fault
condition|)
name|sched_unpin
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|page
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|paddr
operator|>=
name|dmaplimit
condition|)
block|{
if|if
condition|(
name|can_fault
condition|)
name|pmap_qremove
argument_list|(
name|vaddr
index|[
name|i
index|]
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vmem_free
argument_list|(
name|kernel_arena
argument_list|,
name|vaddr
index|[
name|i
index|]
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
name|vm_offset_t
name|pmap_quick_enter_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_paddr_t
name|paddr
decl_stmt|;
name|paddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|paddr
operator|<
name|dmaplimit
condition|)
return|return
operator|(
name|PHYS_TO_DMAP
argument_list|(
name|paddr
argument_list|)
operator|)
return|;
name|mtx_lock_spin
argument_list|(
operator|&
name|qframe_mtx
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|*
name|vtopte
argument_list|(
name|qframe
argument_list|)
operator|==
literal|0
argument_list|,
operator|(
literal|"qframe busy"
operator|)
argument_list|)
expr_stmt|;
name|pte_store
argument_list|(
name|vtopte
argument_list|(
name|qframe
argument_list|)
argument_list|,
name|paddr
operator||
name|X86_PG_RW
operator||
name|X86_PG_V
operator||
name|X86_PG_A
operator||
name|X86_PG_M
operator||
name|pmap_cache_bits
argument_list|(
name|kernel_pmap
argument_list|,
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|qframe
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_quick_remove_page
parameter_list|(
name|vm_offset_t
name|addr
parameter_list|)
block|{
if|if
condition|(
name|addr
operator|!=
name|qframe
condition|)
return|return;
name|pte_store
argument_list|(
name|vtopte
argument_list|(
name|qframe
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|invlpg
argument_list|(
name|qframe
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|qframe_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_include
include|#
directive|include
file|"opt_ddb.h"
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_include
include|#
directive|include
file|<sys/kdb.h>
end_include

begin_include
include|#
directive|include
file|<ddb/ddb.h>
end_include

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|pte
argument_list|,
argument|pmap_print_pte
argument_list|)
end_macro

begin_block
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|pml4_entry_t
modifier|*
name|pml4
decl_stmt|;
name|pdp_entry_t
modifier|*
name|pdp
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|PG_V
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
if|if
condition|(
operator|!
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"show pte addr\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|va
operator|=
operator|(
name|vm_offset_t
operator|)
name|addr
expr_stmt|;
if|if
condition|(
name|kdb_thread
operator|!=
name|NULL
condition|)
name|pmap
operator|=
name|vmspace_pmap
argument_list|(
name|kdb_thread
operator|->
name|td_proc
operator|->
name|p_vmspace
argument_list|)
expr_stmt|;
else|else
name|pmap
operator|=
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
expr_stmt|;
name|PG_V
operator|=
name|pmap_valid_bit
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pml4
operator|=
name|pmap_pml4e
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"VA %#016lx pml4e %#016lx"
argument_list|,
name|va
argument_list|,
operator|*
name|pml4
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pml4
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|pdp
operator|=
name|pmap_pml4e_to_pdpe
argument_list|(
name|pml4
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|" pdpe %#016lx"
argument_list|,
operator|*
name|pdp
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pdp
operator|&
name|PG_V
operator|)
operator|==
literal|0
operator|||
operator|(
operator|*
name|pdp
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|pde
operator|=
name|pmap_pdpe_to_pde
argument_list|(
name|pdp
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|" pde %#016lx"
argument_list|,
operator|*
name|pde
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|==
literal|0
operator|||
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|pte
operator|=
name|pmap_pde_to_pte
argument_list|(
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|" pte %#016lx\n"
argument_list|,
operator|*
name|pte
argument_list|)
expr_stmt|;
block|}
end_block

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|phys2dmap
argument_list|,
argument|pmap_phys2dmap
argument_list|)
end_macro

begin_block
block|{
name|vm_paddr_t
name|a
decl_stmt|;
if|if
condition|(
name|have_addr
condition|)
block|{
name|a
operator|=
operator|(
name|vm_paddr_t
operator|)
name|addr
expr_stmt|;
name|db_printf
argument_list|(
literal|"0x%jx\n"
argument_list|,
operator|(
name|uintmax_t
operator|)
name|PHYS_TO_DMAP
argument_list|(
name|a
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|db_printf
argument_list|(
literal|"show phys2dmap addr\n"
argument_list|)
expr_stmt|;
block|}
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

end_unit

