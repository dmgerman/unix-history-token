begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2011 NetApp, Inc.  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY NETAPP, INC ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL NETAPP, INC OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  * $FreeBSD$  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/pcpu.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/pmap.h>
end_include

begin_include
include|#
directive|include
file|<machine/psl.h>
end_include

begin_include
include|#
directive|include
file|<machine/cpufunc.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_include
include|#
directive|include
file|<machine/segments.h>
end_include

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_include
include|#
directive|include
file|<machine/specialreg.h>
end_include

begin_include
include|#
directive|include
file|<machine/vmparam.h>
end_include

begin_include
include|#
directive|include
file|<machine/vmm.h>
end_include

begin_include
include|#
directive|include
file|<machine/vmm_dev.h>
end_include

begin_include
include|#
directive|include
file|"vmm_host.h"
end_include

begin_include
include|#
directive|include
file|"vmm_ioport.h"
end_include

begin_include
include|#
directive|include
file|"vmm_ipi.h"
end_include

begin_include
include|#
directive|include
file|"vmm_msr.h"
end_include

begin_include
include|#
directive|include
file|"vmm_ktr.h"
end_include

begin_include
include|#
directive|include
file|"vmm_stat.h"
end_include

begin_include
include|#
directive|include
file|"vatpic.h"
end_include

begin_include
include|#
directive|include
file|"vlapic.h"
end_include

begin_include
include|#
directive|include
file|"vlapic_priv.h"
end_include

begin_include
include|#
directive|include
file|"vmx_msr.h"
end_include

begin_include
include|#
directive|include
file|"ept.h"
end_include

begin_include
include|#
directive|include
file|"vmx_cpufunc.h"
end_include

begin_include
include|#
directive|include
file|"vmx.h"
end_include

begin_include
include|#
directive|include
file|"x86.h"
end_include

begin_include
include|#
directive|include
file|"vmx_controls.h"
end_include

begin_define
define|#
directive|define
name|PINBASED_CTLS_ONE_SETTING
define|\
value|(PINBASED_EXTINT_EXITING	|				\ 	 PINBASED_NMI_EXITING		|				\ 	 PINBASED_VIRTUAL_NMI)
end_define

begin_define
define|#
directive|define
name|PINBASED_CTLS_ZERO_SETTING
value|0
end_define

begin_define
define|#
directive|define
name|PROCBASED_CTLS_WINDOW_SETTING
define|\
value|(PROCBASED_INT_WINDOW_EXITING	|				\ 	 PROCBASED_NMI_WINDOW_EXITING)
end_define

begin_define
define|#
directive|define
name|PROCBASED_CTLS_ONE_SETTING
define|\
value|(PROCBASED_SECONDARY_CONTROLS	|				\ 	 PROCBASED_IO_EXITING		|				\ 	 PROCBASED_MSR_BITMAPS		|				\ 	 PROCBASED_CTLS_WINDOW_SETTING)
end_define

begin_define
define|#
directive|define
name|PROCBASED_CTLS_ZERO_SETTING
define|\
value|(PROCBASED_CR3_LOAD_EXITING |	\ 	PROCBASED_CR3_STORE_EXITING |	\ 	PROCBASED_IO_BITMAPS)
end_define

begin_define
define|#
directive|define
name|PROCBASED_CTLS2_ONE_SETTING
value|PROCBASED2_ENABLE_EPT
end_define

begin_define
define|#
directive|define
name|PROCBASED_CTLS2_ZERO_SETTING
value|0
end_define

begin_define
define|#
directive|define
name|VM_EXIT_CTLS_ONE_SETTING_NO_PAT
define|\
value|(VM_EXIT_HOST_LMA			|			\ 	VM_EXIT_SAVE_EFER			|			\ 	VM_EXIT_LOAD_EFER)
end_define

begin_define
define|#
directive|define
name|VM_EXIT_CTLS_ONE_SETTING
define|\
value|(VM_EXIT_CTLS_ONE_SETTING_NO_PAT       	|			\ 	VM_EXIT_ACKNOWLEDGE_INTERRUPT		|			\ 	VM_EXIT_SAVE_PAT			|			\ 	VM_EXIT_LOAD_PAT)
end_define

begin_define
define|#
directive|define
name|VM_EXIT_CTLS_ZERO_SETTING
value|VM_EXIT_SAVE_DEBUG_CONTROLS
end_define

begin_define
define|#
directive|define
name|VM_ENTRY_CTLS_ONE_SETTING_NO_PAT
value|VM_ENTRY_LOAD_EFER
end_define

begin_define
define|#
directive|define
name|VM_ENTRY_CTLS_ONE_SETTING
define|\
value|(VM_ENTRY_CTLS_ONE_SETTING_NO_PAT     	|			\ 	VM_ENTRY_LOAD_PAT)
end_define

begin_define
define|#
directive|define
name|VM_ENTRY_CTLS_ZERO_SETTING
define|\
value|(VM_ENTRY_LOAD_DEBUG_CONTROLS		|			\ 	VM_ENTRY_INTO_SMM			|			\ 	VM_ENTRY_DEACTIVATE_DUAL_MONITOR)
end_define

begin_define
define|#
directive|define
name|guest_msr_rw
parameter_list|(
name|vmx
parameter_list|,
name|msr
parameter_list|)
define|\
value|msr_bitmap_change_access((vmx)->msr_bitmap, (msr), MSR_BITMAP_ACCESS_RW)
end_define

begin_define
define|#
directive|define
name|guest_msr_ro
parameter_list|(
name|vmx
parameter_list|,
name|msr
parameter_list|)
define|\
value|msr_bitmap_change_access((vmx)->msr_bitmap, (msr), MSR_BITMAP_ACCESS_READ)
end_define

begin_define
define|#
directive|define
name|HANDLED
value|1
end_define

begin_define
define|#
directive|define
name|UNHANDLED
value|0
end_define

begin_expr_stmt
specifier|static
name|MALLOC_DEFINE
argument_list|(
name|M_VMX
argument_list|,
literal|"vmx"
argument_list|,
literal|"vmx"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
specifier|static
name|MALLOC_DEFINE
argument_list|(
name|M_VLAPIC
argument_list|,
literal|"vlapic"
argument_list|,
literal|"vlapic"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_DECL
argument_list|(
name|_hw_vmm
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_NODE
argument_list|(
name|_hw_vmm
argument_list|,
name|OID_AUTO
argument_list|,
name|vmx
argument_list|,
name|CTLFLAG_RW
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|int
name|vmxon_enabled
index|[
name|MAXCPU
index|]
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|char
name|vmxon_region
index|[
name|MAXCPU
index|]
index|[
name|PAGE_SIZE
index|]
name|__aligned
parameter_list|(
name|PAGE_SIZE
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
specifier|static
name|uint32_t
name|pinbased_ctls
decl_stmt|,
name|procbased_ctls
decl_stmt|,
name|procbased_ctls2
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|uint32_t
name|exit_ctls
decl_stmt|,
name|entry_ctls
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|uint64_t
name|cr0_ones_mask
decl_stmt|,
name|cr0_zeros_mask
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_hw_vmm_vmx
argument_list|,
name|OID_AUTO
argument_list|,
name|cr0_ones_mask
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|cr0_ones_mask
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_hw_vmm_vmx
argument_list|,
name|OID_AUTO
argument_list|,
name|cr0_zeros_mask
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|cr0_zeros_mask
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|uint64_t
name|cr4_ones_mask
decl_stmt|,
name|cr4_zeros_mask
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_hw_vmm_vmx
argument_list|,
name|OID_AUTO
argument_list|,
name|cr4_ones_mask
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|cr4_ones_mask
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_hw_vmm_vmx
argument_list|,
name|OID_AUTO
argument_list|,
name|cr4_zeros_mask
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|cr4_zeros_mask
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|vmx_no_patmsr
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|vmx_initialized
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_hw_vmm_vmx
argument_list|,
name|OID_AUTO
argument_list|,
name|initialized
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|vmx_initialized
argument_list|,
literal|0
argument_list|,
literal|"Intel VMX initialized"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Optional capabilities  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|cap_halt_exit
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|cap_pause_exit
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|cap_unrestricted_guest
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|cap_monitor_trap
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|cap_invpcid
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|virtual_interrupt_delivery
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_hw_vmm_vmx
argument_list|,
name|OID_AUTO
argument_list|,
name|virtual_interrupt_delivery
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|virtual_interrupt_delivery
argument_list|,
literal|0
argument_list|,
literal|"APICv virtual interrupt delivery support"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|posted_interrupts
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_hw_vmm_vmx
argument_list|,
name|OID_AUTO
argument_list|,
name|posted_interrupts
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|posted_interrupts
argument_list|,
literal|0
argument_list|,
literal|"APICv posted interrupt support"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pirvec
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_hw_vmm_vmx
argument_list|,
name|OID_AUTO
argument_list|,
name|posted_interrupt_vector
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pirvec
argument_list|,
literal|0
argument_list|,
literal|"APICv posted interrupt vector"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|unrhdr
modifier|*
name|vpid_unr
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|u_int
name|vpid_alloc_failed
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_UINT
argument_list|(
name|_hw_vmm_vmx
argument_list|,
name|OID_AUTO
argument_list|,
name|vpid_alloc_failed
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|vpid_alloc_failed
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Use the last page below 4GB as the APIC access address. This address is  * occupied by the boot firmware so it is guaranteed that it will not conflict  * with a page in system memory.  */
end_comment

begin_define
define|#
directive|define
name|APIC_ACCESS_ADDRESS
value|0xFFFFF000
end_define

begin_function_decl
specifier|static
name|void
name|vmx_inject_pir
parameter_list|(
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|)
function_decl|;
end_function_decl

begin_ifdef
ifdef|#
directive|ifdef
name|KTR
end_ifdef

begin_function
specifier|static
specifier|const
name|char
modifier|*
name|exit_reason_to_str
parameter_list|(
name|int
name|reason
parameter_list|)
block|{
specifier|static
name|char
name|reasonbuf
index|[
literal|32
index|]
decl_stmt|;
switch|switch
condition|(
name|reason
condition|)
block|{
case|case
name|EXIT_REASON_EXCEPTION
case|:
return|return
literal|"exception"
return|;
case|case
name|EXIT_REASON_EXT_INTR
case|:
return|return
literal|"extint"
return|;
case|case
name|EXIT_REASON_TRIPLE_FAULT
case|:
return|return
literal|"triplefault"
return|;
case|case
name|EXIT_REASON_INIT
case|:
return|return
literal|"init"
return|;
case|case
name|EXIT_REASON_SIPI
case|:
return|return
literal|"sipi"
return|;
case|case
name|EXIT_REASON_IO_SMI
case|:
return|return
literal|"iosmi"
return|;
case|case
name|EXIT_REASON_SMI
case|:
return|return
literal|"smi"
return|;
case|case
name|EXIT_REASON_INTR_WINDOW
case|:
return|return
literal|"intrwindow"
return|;
case|case
name|EXIT_REASON_NMI_WINDOW
case|:
return|return
literal|"nmiwindow"
return|;
case|case
name|EXIT_REASON_TASK_SWITCH
case|:
return|return
literal|"taskswitch"
return|;
case|case
name|EXIT_REASON_CPUID
case|:
return|return
literal|"cpuid"
return|;
case|case
name|EXIT_REASON_GETSEC
case|:
return|return
literal|"getsec"
return|;
case|case
name|EXIT_REASON_HLT
case|:
return|return
literal|"hlt"
return|;
case|case
name|EXIT_REASON_INVD
case|:
return|return
literal|"invd"
return|;
case|case
name|EXIT_REASON_INVLPG
case|:
return|return
literal|"invlpg"
return|;
case|case
name|EXIT_REASON_RDPMC
case|:
return|return
literal|"rdpmc"
return|;
case|case
name|EXIT_REASON_RDTSC
case|:
return|return
literal|"rdtsc"
return|;
case|case
name|EXIT_REASON_RSM
case|:
return|return
literal|"rsm"
return|;
case|case
name|EXIT_REASON_VMCALL
case|:
return|return
literal|"vmcall"
return|;
case|case
name|EXIT_REASON_VMCLEAR
case|:
return|return
literal|"vmclear"
return|;
case|case
name|EXIT_REASON_VMLAUNCH
case|:
return|return
literal|"vmlaunch"
return|;
case|case
name|EXIT_REASON_VMPTRLD
case|:
return|return
literal|"vmptrld"
return|;
case|case
name|EXIT_REASON_VMPTRST
case|:
return|return
literal|"vmptrst"
return|;
case|case
name|EXIT_REASON_VMREAD
case|:
return|return
literal|"vmread"
return|;
case|case
name|EXIT_REASON_VMRESUME
case|:
return|return
literal|"vmresume"
return|;
case|case
name|EXIT_REASON_VMWRITE
case|:
return|return
literal|"vmwrite"
return|;
case|case
name|EXIT_REASON_VMXOFF
case|:
return|return
literal|"vmxoff"
return|;
case|case
name|EXIT_REASON_VMXON
case|:
return|return
literal|"vmxon"
return|;
case|case
name|EXIT_REASON_CR_ACCESS
case|:
return|return
literal|"craccess"
return|;
case|case
name|EXIT_REASON_DR_ACCESS
case|:
return|return
literal|"draccess"
return|;
case|case
name|EXIT_REASON_INOUT
case|:
return|return
literal|"inout"
return|;
case|case
name|EXIT_REASON_RDMSR
case|:
return|return
literal|"rdmsr"
return|;
case|case
name|EXIT_REASON_WRMSR
case|:
return|return
literal|"wrmsr"
return|;
case|case
name|EXIT_REASON_INVAL_VMCS
case|:
return|return
literal|"invalvmcs"
return|;
case|case
name|EXIT_REASON_INVAL_MSR
case|:
return|return
literal|"invalmsr"
return|;
case|case
name|EXIT_REASON_MWAIT
case|:
return|return
literal|"mwait"
return|;
case|case
name|EXIT_REASON_MTF
case|:
return|return
literal|"mtf"
return|;
case|case
name|EXIT_REASON_MONITOR
case|:
return|return
literal|"monitor"
return|;
case|case
name|EXIT_REASON_PAUSE
case|:
return|return
literal|"pause"
return|;
case|case
name|EXIT_REASON_MCE
case|:
return|return
literal|"mce"
return|;
case|case
name|EXIT_REASON_TPR
case|:
return|return
literal|"tpr"
return|;
case|case
name|EXIT_REASON_APIC_ACCESS
case|:
return|return
literal|"apic-access"
return|;
case|case
name|EXIT_REASON_GDTR_IDTR
case|:
return|return
literal|"gdtridtr"
return|;
case|case
name|EXIT_REASON_LDTR_TR
case|:
return|return
literal|"ldtrtr"
return|;
case|case
name|EXIT_REASON_EPT_FAULT
case|:
return|return
literal|"eptfault"
return|;
case|case
name|EXIT_REASON_EPT_MISCONFIG
case|:
return|return
literal|"eptmisconfig"
return|;
case|case
name|EXIT_REASON_INVEPT
case|:
return|return
literal|"invept"
return|;
case|case
name|EXIT_REASON_RDTSCP
case|:
return|return
literal|"rdtscp"
return|;
case|case
name|EXIT_REASON_VMX_PREEMPT
case|:
return|return
literal|"vmxpreempt"
return|;
case|case
name|EXIT_REASON_INVVPID
case|:
return|return
literal|"invvpid"
return|;
case|case
name|EXIT_REASON_WBINVD
case|:
return|return
literal|"wbinvd"
return|;
case|case
name|EXIT_REASON_XSETBV
case|:
return|return
literal|"xsetbv"
return|;
case|case
name|EXIT_REASON_APIC_WRITE
case|:
return|return
literal|"apic-write"
return|;
default|default:
name|snprintf
argument_list|(
name|reasonbuf
argument_list|,
sizeof|sizeof
argument_list|(
name|reasonbuf
argument_list|)
argument_list|,
literal|"%d"
argument_list|,
name|reason
argument_list|)
expr_stmt|;
return|return
operator|(
name|reasonbuf
operator|)
return|;
block|}
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* KTR */
end_comment

begin_function
specifier|static
name|int
name|vmx_allow_x2apic_msrs
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|error
decl_stmt|;
name|error
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Allow readonly access to the following x2APIC MSRs from the guest. 	 */
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_ID
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_VERSION
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_LDR
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_SVR
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|8
condition|;
name|i
operator|++
control|)
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_ISR0
operator|+
name|i
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|8
condition|;
name|i
operator|++
control|)
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_TMR0
operator|+
name|i
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|8
condition|;
name|i
operator|++
control|)
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_IRR0
operator|+
name|i
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_ESR
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_LVT_TIMER
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_LVT_THERMAL
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_LVT_PCINT
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_LVT_LINT0
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_LVT_LINT1
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_LVT_ERROR
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_ICR_TIMER
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_DCR_TIMER
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_ICR
argument_list|)
expr_stmt|;
comment|/* 	 * Allow TPR, EOI and SELF_IPI MSRs to be read and written by the guest. 	 * 	 * These registers get special treatment described in the section 	 * "Virtualizing MSR-Based APIC Accesses". 	 */
name|error
operator|+=
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_TPR
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_EOI
argument_list|)
expr_stmt|;
name|error
operator|+=
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_APIC_SELF_IPI
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
name|u_long
name|vmx_fix_cr0
parameter_list|(
name|u_long
name|cr0
parameter_list|)
block|{
return|return
operator|(
operator|(
name|cr0
operator||
name|cr0_ones_mask
operator|)
operator|&
operator|~
name|cr0_zeros_mask
operator|)
return|;
block|}
end_function

begin_function
name|u_long
name|vmx_fix_cr4
parameter_list|(
name|u_long
name|cr4
parameter_list|)
block|{
return|return
operator|(
operator|(
name|cr4
operator||
name|cr4_ones_mask
operator|)
operator|&
operator|~
name|cr4_zeros_mask
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vpid_free
parameter_list|(
name|int
name|vpid
parameter_list|)
block|{
if|if
condition|(
name|vpid
operator|<
literal|0
operator|||
name|vpid
operator|>
literal|0xffff
condition|)
name|panic
argument_list|(
literal|"vpid_free: invalid vpid %d"
argument_list|,
name|vpid
argument_list|)
expr_stmt|;
comment|/* 	 * VPIDs [0,VM_MAXCPU] are special and are not allocated from 	 * the unit number allocator. 	 */
if|if
condition|(
name|vpid
operator|>
name|VM_MAXCPU
condition|)
name|free_unr
argument_list|(
name|vpid_unr
argument_list|,
name|vpid
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vpid_alloc
parameter_list|(
name|uint16_t
modifier|*
name|vpid
parameter_list|,
name|int
name|num
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|x
decl_stmt|;
if|if
condition|(
name|num
operator|<=
literal|0
operator|||
name|num
operator|>
name|VM_MAXCPU
condition|)
name|panic
argument_list|(
literal|"invalid number of vpids requested: %d"
argument_list|,
name|num
argument_list|)
expr_stmt|;
comment|/* 	 * If the "enable vpid" execution control is not enabled then the 	 * VPID is required to be 0 for all vcpus. 	 */
if|if
condition|(
operator|(
name|procbased_ctls2
operator|&
name|PROCBASED2_ENABLE_VPID
operator|)
operator|==
literal|0
condition|)
block|{
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|num
condition|;
name|i
operator|++
control|)
name|vpid
index|[
name|i
index|]
operator|=
literal|0
expr_stmt|;
return|return;
block|}
comment|/* 	 * Allocate a unique VPID for each vcpu from the unit number allocator. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|num
condition|;
name|i
operator|++
control|)
block|{
name|x
operator|=
name|alloc_unr
argument_list|(
name|vpid_unr
argument_list|)
expr_stmt|;
if|if
condition|(
name|x
operator|==
operator|-
literal|1
condition|)
break|break;
else|else
name|vpid
index|[
name|i
index|]
operator|=
name|x
expr_stmt|;
block|}
if|if
condition|(
name|i
operator|<
name|num
condition|)
block|{
name|atomic_add_int
argument_list|(
operator|&
name|vpid_alloc_failed
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 		 * If the unit number allocator does not have enough unique 		 * VPIDs then we need to allocate from the [1,VM_MAXCPU] range. 		 * 		 * These VPIDs are not be unique across VMs but this does not 		 * affect correctness because the combined mappings are also 		 * tagged with the EP4TA which is unique for each VM. 		 * 		 * It is still sub-optimal because the invvpid will invalidate 		 * combined mappings for a particular VPID across all EP4TAs. 		 */
while|while
condition|(
name|i
operator|--
operator|>
literal|0
condition|)
name|vpid_free
argument_list|(
name|vpid
index|[
name|i
index|]
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|num
condition|;
name|i
operator|++
control|)
name|vpid
index|[
name|i
index|]
operator|=
name|i
operator|+
literal|1
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|vpid_init
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * VPID 0 is required when the "enable VPID" execution control is 	 * disabled. 	 * 	 * VPIDs [1,VM_MAXCPU] are used as the "overflow namespace" when the 	 * unit number allocator does not have sufficient unique VPIDs to 	 * satisfy the allocation. 	 * 	 * The remaining VPIDs are managed by the unit number allocator. 	 */
name|vpid_unr
operator|=
name|new_unrhdr
argument_list|(
name|VM_MAXCPU
operator|+
literal|1
argument_list|,
literal|0xffff
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|msr_save_area_init
parameter_list|(
name|struct
name|msr_entry
modifier|*
name|g_area
parameter_list|,
name|int
modifier|*
name|g_count
parameter_list|)
block|{
name|int
name|cnt
decl_stmt|;
specifier|static
name|struct
name|msr_entry
name|guest_msrs
index|[]
init|=
block|{
block|{
name|MSR_KGSBASE
block|,
literal|0
block|,
literal|0
block|}
block|, 	}
decl_stmt|;
name|cnt
operator|=
sizeof|sizeof
argument_list|(
name|guest_msrs
argument_list|)
operator|/
sizeof|sizeof
argument_list|(
name|guest_msrs
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|cnt
operator|>
name|GUEST_MSR_MAX_ENTRIES
condition|)
name|panic
argument_list|(
literal|"guest msr save area overrun"
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|guest_msrs
argument_list|,
name|g_area
argument_list|,
sizeof|sizeof
argument_list|(
name|guest_msrs
argument_list|)
argument_list|)
expr_stmt|;
operator|*
name|g_count
operator|=
name|cnt
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_disable
parameter_list|(
name|void
modifier|*
name|arg
name|__unused
parameter_list|)
block|{
name|struct
name|invvpid_desc
name|invvpid_desc
init|=
block|{
literal|0
block|}
decl_stmt|;
name|struct
name|invept_desc
name|invept_desc
init|=
block|{
literal|0
block|}
decl_stmt|;
if|if
condition|(
name|vmxon_enabled
index|[
name|curcpu
index|]
condition|)
block|{
comment|/* 		 * See sections 25.3.3.3 and 25.3.3.4 in Intel Vol 3b. 		 * 		 * VMXON or VMXOFF are not required to invalidate any TLB 		 * caching structures. This prevents potential retention of 		 * cached information in the TLB between distinct VMX episodes. 		 */
name|invvpid
argument_list|(
name|INVVPID_TYPE_ALL_CONTEXTS
argument_list|,
name|invvpid_desc
argument_list|)
expr_stmt|;
name|invept
argument_list|(
name|INVEPT_TYPE_ALL_CONTEXTS
argument_list|,
name|invept_desc
argument_list|)
expr_stmt|;
name|vmxoff
argument_list|()
expr_stmt|;
block|}
name|load_cr4
argument_list|(
name|rcr4
argument_list|()
operator|&
operator|~
name|CR4_VMXE
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_cleanup
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|pirvec
operator|!=
literal|0
condition|)
name|vmm_ipi_free
argument_list|(
name|pirvec
argument_list|)
expr_stmt|;
if|if
condition|(
name|vpid_unr
operator|!=
name|NULL
condition|)
block|{
name|delete_unrhdr
argument_list|(
name|vpid_unr
argument_list|)
expr_stmt|;
name|vpid_unr
operator|=
name|NULL
expr_stmt|;
block|}
name|smp_rendezvous
argument_list|(
name|NULL
argument_list|,
name|vmx_disable
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_enable
parameter_list|(
name|void
modifier|*
name|arg
name|__unused
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
name|load_cr4
argument_list|(
name|rcr4
argument_list|()
operator||
name|CR4_VMXE
argument_list|)
expr_stmt|;
operator|*
operator|(
name|uint32_t
operator|*
operator|)
name|vmxon_region
index|[
name|curcpu
index|]
operator|=
name|vmx_revision
argument_list|()
expr_stmt|;
name|error
operator|=
name|vmxon
argument_list|(
name|vmxon_region
index|[
name|curcpu
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|==
literal|0
condition|)
name|vmxon_enabled
index|[
name|curcpu
index|]
operator|=
literal|1
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_restore
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|vmxon_enabled
index|[
name|curcpu
index|]
condition|)
name|vmxon
argument_list|(
name|vmxon_region
index|[
name|curcpu
index|]
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_init
parameter_list|(
name|int
name|ipinum
parameter_list|)
block|{
name|int
name|error
decl_stmt|,
name|use_tpr_shadow
decl_stmt|;
name|uint64_t
name|fixed0
decl_stmt|,
name|fixed1
decl_stmt|,
name|feature_control
decl_stmt|;
name|uint32_t
name|tmp
decl_stmt|,
name|procbased2_vid_bits
decl_stmt|;
comment|/* CPUID.1:ECX[bit 5] must be 1 for processor to support VMX */
if|if
condition|(
operator|!
operator|(
name|cpu_feature2
operator|&
name|CPUID2_VMX
operator|)
condition|)
block|{
name|printf
argument_list|(
literal|"vmx_init: processor does not support VMX operation\n"
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENXIO
operator|)
return|;
block|}
comment|/* 	 * Verify that MSR_IA32_FEATURE_CONTROL lock and VMXON enable bits 	 * are set (bits 0 and 2 respectively). 	 */
name|feature_control
operator|=
name|rdmsr
argument_list|(
name|MSR_IA32_FEATURE_CONTROL
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|feature_control
operator|&
name|IA32_FEATURE_CONTROL_LOCK
operator|)
operator|==
literal|0
operator|||
operator|(
name|feature_control
operator|&
name|IA32_FEATURE_CONTROL_VMX_EN
operator|)
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"vmx_init: VMX operation disabled by BIOS\n"
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENXIO
operator|)
return|;
block|}
comment|/* Check support for primary processor-based VM-execution controls */
name|error
operator|=
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PROCBASED_CTLS
argument_list|,
name|MSR_VMX_TRUE_PROCBASED_CTLS
argument_list|,
name|PROCBASED_CTLS_ONE_SETTING
argument_list|,
name|PROCBASED_CTLS_ZERO_SETTING
argument_list|,
operator|&
name|procbased_ctls
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|printf
argument_list|(
literal|"vmx_init: processor does not support desired primary "
literal|"processor-based controls\n"
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
comment|/* Clear the processor-based ctl bits that are set on demand */
name|procbased_ctls
operator|&=
operator|~
name|PROCBASED_CTLS_WINDOW_SETTING
expr_stmt|;
comment|/* Check support for secondary processor-based VM-execution controls */
name|error
operator|=
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PROCBASED_CTLS2
argument_list|,
name|MSR_VMX_PROCBASED_CTLS2
argument_list|,
name|PROCBASED_CTLS2_ONE_SETTING
argument_list|,
name|PROCBASED_CTLS2_ZERO_SETTING
argument_list|,
operator|&
name|procbased_ctls2
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|printf
argument_list|(
literal|"vmx_init: processor does not support desired secondary "
literal|"processor-based controls\n"
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
comment|/* Check support for VPID */
name|error
operator|=
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PROCBASED_CTLS2
argument_list|,
name|MSR_VMX_PROCBASED_CTLS2
argument_list|,
name|PROCBASED2_ENABLE_VPID
argument_list|,
literal|0
argument_list|,
operator|&
name|tmp
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|==
literal|0
condition|)
name|procbased_ctls2
operator||=
name|PROCBASED2_ENABLE_VPID
expr_stmt|;
comment|/* Check support for pin-based VM-execution controls */
name|error
operator|=
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PINBASED_CTLS
argument_list|,
name|MSR_VMX_TRUE_PINBASED_CTLS
argument_list|,
name|PINBASED_CTLS_ONE_SETTING
argument_list|,
name|PINBASED_CTLS_ZERO_SETTING
argument_list|,
operator|&
name|pinbased_ctls
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|printf
argument_list|(
literal|"vmx_init: processor does not support desired "
literal|"pin-based controls\n"
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
comment|/* Check support for VM-exit controls */
name|error
operator|=
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_EXIT_CTLS
argument_list|,
name|MSR_VMX_TRUE_EXIT_CTLS
argument_list|,
name|VM_EXIT_CTLS_ONE_SETTING
argument_list|,
name|VM_EXIT_CTLS_ZERO_SETTING
argument_list|,
operator|&
name|exit_ctls
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
comment|/* Try again without the PAT MSR bits */
name|error
operator|=
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_EXIT_CTLS
argument_list|,
name|MSR_VMX_TRUE_EXIT_CTLS
argument_list|,
name|VM_EXIT_CTLS_ONE_SETTING_NO_PAT
argument_list|,
name|VM_EXIT_CTLS_ZERO_SETTING
argument_list|,
operator|&
name|exit_ctls
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|printf
argument_list|(
literal|"vmx_init: processor does not support desired "
literal|"exit controls\n"
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
else|else
block|{
if|if
condition|(
name|bootverbose
condition|)
name|printf
argument_list|(
literal|"vmm: PAT MSR access not supported\n"
argument_list|)
expr_stmt|;
name|guest_msr_valid
argument_list|(
name|MSR_PAT
argument_list|)
expr_stmt|;
name|vmx_no_patmsr
operator|=
literal|1
expr_stmt|;
block|}
block|}
comment|/* Check support for VM-entry controls */
if|if
condition|(
operator|!
name|vmx_no_patmsr
condition|)
block|{
name|error
operator|=
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_ENTRY_CTLS
argument_list|,
name|MSR_VMX_TRUE_ENTRY_CTLS
argument_list|,
name|VM_ENTRY_CTLS_ONE_SETTING
argument_list|,
name|VM_ENTRY_CTLS_ZERO_SETTING
argument_list|,
operator|&
name|entry_ctls
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|error
operator|=
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_ENTRY_CTLS
argument_list|,
name|MSR_VMX_TRUE_ENTRY_CTLS
argument_list|,
name|VM_ENTRY_CTLS_ONE_SETTING_NO_PAT
argument_list|,
name|VM_ENTRY_CTLS_ZERO_SETTING
argument_list|,
operator|&
name|entry_ctls
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|error
condition|)
block|{
name|printf
argument_list|(
literal|"vmx_init: processor does not support desired "
literal|"entry controls\n"
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
comment|/* 	 * Check support for optional features by testing them 	 * as individual bits 	 */
name|cap_halt_exit
operator|=
operator|(
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PROCBASED_CTLS
argument_list|,
name|MSR_VMX_TRUE_PROCBASED_CTLS
argument_list|,
name|PROCBASED_HLT_EXITING
argument_list|,
literal|0
argument_list|,
operator|&
name|tmp
argument_list|)
operator|==
literal|0
operator|)
expr_stmt|;
name|cap_monitor_trap
operator|=
operator|(
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PROCBASED_CTLS
argument_list|,
name|MSR_VMX_PROCBASED_CTLS
argument_list|,
name|PROCBASED_MTF
argument_list|,
literal|0
argument_list|,
operator|&
name|tmp
argument_list|)
operator|==
literal|0
operator|)
expr_stmt|;
name|cap_pause_exit
operator|=
operator|(
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PROCBASED_CTLS
argument_list|,
name|MSR_VMX_TRUE_PROCBASED_CTLS
argument_list|,
name|PROCBASED_PAUSE_EXITING
argument_list|,
literal|0
argument_list|,
operator|&
name|tmp
argument_list|)
operator|==
literal|0
operator|)
expr_stmt|;
name|cap_unrestricted_guest
operator|=
operator|(
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PROCBASED_CTLS2
argument_list|,
name|MSR_VMX_PROCBASED_CTLS2
argument_list|,
name|PROCBASED2_UNRESTRICTED_GUEST
argument_list|,
literal|0
argument_list|,
operator|&
name|tmp
argument_list|)
operator|==
literal|0
operator|)
expr_stmt|;
name|cap_invpcid
operator|=
operator|(
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PROCBASED_CTLS2
argument_list|,
name|MSR_VMX_PROCBASED_CTLS2
argument_list|,
name|PROCBASED2_ENABLE_INVPCID
argument_list|,
literal|0
argument_list|,
operator|&
name|tmp
argument_list|)
operator|==
literal|0
operator|)
expr_stmt|;
comment|/* 	 * Check support for virtual interrupt delivery. 	 */
name|procbased2_vid_bits
operator|=
operator|(
name|PROCBASED2_VIRTUALIZE_APIC_ACCESSES
operator||
name|PROCBASED2_VIRTUALIZE_X2APIC_MODE
operator||
name|PROCBASED2_APIC_REGISTER_VIRTUALIZATION
operator||
name|PROCBASED2_VIRTUAL_INTERRUPT_DELIVERY
operator|)
expr_stmt|;
name|use_tpr_shadow
operator|=
operator|(
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PROCBASED_CTLS
argument_list|,
name|MSR_VMX_TRUE_PROCBASED_CTLS
argument_list|,
name|PROCBASED_USE_TPR_SHADOW
argument_list|,
literal|0
argument_list|,
operator|&
name|tmp
argument_list|)
operator|==
literal|0
operator|)
expr_stmt|;
name|error
operator|=
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PROCBASED_CTLS2
argument_list|,
name|MSR_VMX_PROCBASED_CTLS2
argument_list|,
name|procbased2_vid_bits
argument_list|,
literal|0
argument_list|,
operator|&
name|tmp
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|==
literal|0
operator|&&
name|use_tpr_shadow
condition|)
block|{
name|virtual_interrupt_delivery
operator|=
literal|1
expr_stmt|;
name|TUNABLE_INT_FETCH
argument_list|(
literal|"hw.vmm.vmx.use_apic_vid"
argument_list|,
operator|&
name|virtual_interrupt_delivery
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|virtual_interrupt_delivery
condition|)
block|{
name|procbased_ctls
operator||=
name|PROCBASED_USE_TPR_SHADOW
expr_stmt|;
name|procbased_ctls2
operator||=
name|procbased2_vid_bits
expr_stmt|;
name|procbased_ctls2
operator|&=
operator|~
name|PROCBASED2_VIRTUALIZE_X2APIC_MODE
expr_stmt|;
comment|/* 		 * Check for Posted Interrupts only if Virtual Interrupt 		 * Delivery is enabled. 		 */
name|error
operator|=
name|vmx_set_ctlreg
argument_list|(
name|MSR_VMX_PINBASED_CTLS
argument_list|,
name|MSR_VMX_TRUE_PINBASED_CTLS
argument_list|,
name|PINBASED_POSTED_INTERRUPT
argument_list|,
literal|0
argument_list|,
operator|&
name|tmp
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|==
literal|0
condition|)
block|{
name|pirvec
operator|=
name|vmm_ipi_alloc
argument_list|()
expr_stmt|;
if|if
condition|(
name|pirvec
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|bootverbose
condition|)
block|{
name|printf
argument_list|(
literal|"vmx_init: unable to allocate "
literal|"posted interrupt vector\n"
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|posted_interrupts
operator|=
literal|1
expr_stmt|;
name|TUNABLE_INT_FETCH
argument_list|(
literal|"hw.vmm.vmx.use_apic_pir"
argument_list|,
operator|&
name|posted_interrupts
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|posted_interrupts
condition|)
name|pinbased_ctls
operator||=
name|PINBASED_POSTED_INTERRUPT
expr_stmt|;
comment|/* Initialize EPT */
name|error
operator|=
name|ept_init
argument_list|(
name|ipinum
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|printf
argument_list|(
literal|"vmx_init: ept initialization failed (%d)\n"
argument_list|,
name|error
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
comment|/* 	 * Stash the cr0 and cr4 bits that must be fixed to 0 or 1 	 */
name|fixed0
operator|=
name|rdmsr
argument_list|(
name|MSR_VMX_CR0_FIXED0
argument_list|)
expr_stmt|;
name|fixed1
operator|=
name|rdmsr
argument_list|(
name|MSR_VMX_CR0_FIXED1
argument_list|)
expr_stmt|;
name|cr0_ones_mask
operator|=
name|fixed0
operator|&
name|fixed1
expr_stmt|;
name|cr0_zeros_mask
operator|=
operator|~
name|fixed0
operator|&
operator|~
name|fixed1
expr_stmt|;
comment|/* 	 * CR0_PE and CR0_PG can be set to zero in VMX non-root operation 	 * if unrestricted guest execution is allowed. 	 */
if|if
condition|(
name|cap_unrestricted_guest
condition|)
name|cr0_ones_mask
operator|&=
operator|~
operator|(
name|CR0_PG
operator||
name|CR0_PE
operator|)
expr_stmt|;
comment|/* 	 * Do not allow the guest to set CR0_NW or CR0_CD. 	 */
name|cr0_zeros_mask
operator||=
operator|(
name|CR0_NW
operator||
name|CR0_CD
operator|)
expr_stmt|;
name|fixed0
operator|=
name|rdmsr
argument_list|(
name|MSR_VMX_CR4_FIXED0
argument_list|)
expr_stmt|;
name|fixed1
operator|=
name|rdmsr
argument_list|(
name|MSR_VMX_CR4_FIXED1
argument_list|)
expr_stmt|;
name|cr4_ones_mask
operator|=
name|fixed0
operator|&
name|fixed1
expr_stmt|;
name|cr4_zeros_mask
operator|=
operator|~
name|fixed0
operator|&
operator|~
name|fixed1
expr_stmt|;
name|vpid_init
argument_list|()
expr_stmt|;
comment|/* enable VMX operation */
name|smp_rendezvous
argument_list|(
name|NULL
argument_list|,
name|vmx_enable
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|vmx_initialized
operator|=
literal|1
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_trigger_hostintr
parameter_list|(
name|int
name|vector
parameter_list|)
block|{
name|uintptr_t
name|func
decl_stmt|;
name|struct
name|gate_descriptor
modifier|*
name|gd
decl_stmt|;
name|gd
operator|=
operator|&
name|idt
index|[
name|vector
index|]
expr_stmt|;
name|KASSERT
argument_list|(
name|vector
operator|>=
literal|32
operator|&&
name|vector
operator|<=
literal|255
argument_list|,
operator|(
literal|"vmx_trigger_hostintr: "
literal|"invalid vector %d"
operator|,
name|vector
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|gd
operator|->
name|gd_p
operator|==
literal|1
argument_list|,
operator|(
literal|"gate descriptor for vector %d not present"
operator|,
name|vector
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|gd
operator|->
name|gd_type
operator|==
name|SDT_SYSIGT
argument_list|,
operator|(
literal|"gate descriptor for vector %d "
literal|"has invalid type %d"
operator|,
name|vector
operator|,
name|gd
operator|->
name|gd_type
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|gd
operator|->
name|gd_dpl
operator|==
name|SEL_KPL
argument_list|,
operator|(
literal|"gate descriptor for vector %d "
literal|"has invalid dpl %d"
operator|,
name|vector
operator|,
name|gd
operator|->
name|gd_dpl
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|gd
operator|->
name|gd_selector
operator|==
name|GSEL
argument_list|(
name|GCODE_SEL
argument_list|,
name|SEL_KPL
argument_list|)
argument_list|,
operator|(
literal|"gate descriptor "
literal|"for vector %d has invalid selector %d"
operator|,
name|vector
operator|,
name|gd
operator|->
name|gd_selector
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|gd
operator|->
name|gd_ist
operator|==
literal|0
argument_list|,
operator|(
literal|"gate descriptor for vector %d has invalid "
literal|"IST %d"
operator|,
name|vector
operator|,
name|gd
operator|->
name|gd_ist
operator|)
argument_list|)
expr_stmt|;
name|func
operator|=
operator|(
operator|(
name|long
operator|)
name|gd
operator|->
name|gd_hioffset
operator|<<
literal|16
operator||
name|gd
operator|->
name|gd_looffset
operator|)
expr_stmt|;
name|vmx_call_isr
argument_list|(
name|func
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_setup_cr_shadow
parameter_list|(
name|int
name|which
parameter_list|,
name|struct
name|vmcs
modifier|*
name|vmcs
parameter_list|,
name|uint32_t
name|initial
parameter_list|)
block|{
name|int
name|error
decl_stmt|,
name|mask_ident
decl_stmt|,
name|shadow_ident
decl_stmt|;
name|uint64_t
name|mask_value
decl_stmt|;
if|if
condition|(
name|which
operator|!=
literal|0
operator|&&
name|which
operator|!=
literal|4
condition|)
name|panic
argument_list|(
literal|"vmx_setup_cr_shadow: unknown cr%d"
argument_list|,
name|which
argument_list|)
expr_stmt|;
if|if
condition|(
name|which
operator|==
literal|0
condition|)
block|{
name|mask_ident
operator|=
name|VMCS_CR0_MASK
expr_stmt|;
name|mask_value
operator|=
name|cr0_ones_mask
operator||
name|cr0_zeros_mask
expr_stmt|;
name|shadow_ident
operator|=
name|VMCS_CR0_SHADOW
expr_stmt|;
block|}
else|else
block|{
name|mask_ident
operator|=
name|VMCS_CR4_MASK
expr_stmt|;
name|mask_value
operator|=
name|cr4_ones_mask
operator||
name|cr4_zeros_mask
expr_stmt|;
name|shadow_ident
operator|=
name|VMCS_CR4_SHADOW
expr_stmt|;
block|}
name|error
operator|=
name|vmcs_setreg
argument_list|(
name|vmcs
argument_list|,
literal|0
argument_list|,
name|VMCS_IDENT
argument_list|(
name|mask_ident
argument_list|)
argument_list|,
name|mask_value
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
return|return
operator|(
name|error
operator|)
return|;
name|error
operator|=
name|vmcs_setreg
argument_list|(
name|vmcs
argument_list|,
literal|0
argument_list|,
name|VMCS_IDENT
argument_list|(
name|shadow_ident
argument_list|)
argument_list|,
name|initial
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
return|return
operator|(
name|error
operator|)
return|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|vmx_setup_cr0_shadow
parameter_list|(
name|vmcs
parameter_list|,
name|init
parameter_list|)
value|vmx_setup_cr_shadow(0, (vmcs), (init))
end_define

begin_define
define|#
directive|define
name|vmx_setup_cr4_shadow
parameter_list|(
name|vmcs
parameter_list|,
name|init
parameter_list|)
value|vmx_setup_cr_shadow(4, (vmcs), (init))
end_define

begin_function
specifier|static
name|void
modifier|*
name|vmx_vminit
parameter_list|(
name|struct
name|vm
modifier|*
name|vm
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|uint16_t
name|vpid
index|[
name|VM_MAXCPU
index|]
decl_stmt|;
name|int
name|i
decl_stmt|,
name|error
decl_stmt|,
name|guest_msr_count
decl_stmt|;
name|struct
name|vmx
modifier|*
name|vmx
decl_stmt|;
name|struct
name|vmcs
modifier|*
name|vmcs
decl_stmt|;
name|vmx
operator|=
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|vmx
argument_list|)
argument_list|,
name|M_VMX
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|uintptr_t
operator|)
name|vmx
operator|&
name|PAGE_MASK
condition|)
block|{
name|panic
argument_list|(
literal|"malloc of struct vmx not aligned on %d byte boundary"
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
name|vmx
operator|->
name|vm
operator|=
name|vm
expr_stmt|;
name|vmx
operator|->
name|eptp
operator|=
name|eptp
argument_list|(
name|vtophys
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pmap
operator|->
name|pm_pml4
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Clean up EPTP-tagged guest physical and combined mappings 	 * 	 * VMX transitions are not required to invalidate any guest physical 	 * mappings. So, it may be possible for stale guest physical mappings 	 * to be present in the processor TLBs. 	 * 	 * Combined mappings for this EP4TA are also invalidated for all VPIDs. 	 */
name|ept_invalidate_mappings
argument_list|(
name|vmx
operator|->
name|eptp
argument_list|)
expr_stmt|;
name|msr_bitmap_initialize
argument_list|(
name|vmx
operator|->
name|msr_bitmap
argument_list|)
expr_stmt|;
comment|/* 	 * It is safe to allow direct access to MSR_GSBASE and MSR_FSBASE. 	 * The guest FSBASE and GSBASE are saved and restored during 	 * vm-exit and vm-entry respectively. The host FSBASE and GSBASE are 	 * always restored from the vmcs host state area on vm-exit. 	 * 	 * The SYSENTER_CS/ESP/EIP MSRs are identical to FS/GSBASE in 	 * how they are saved/restored so can be directly accessed by the 	 * guest. 	 * 	 * Guest KGSBASE is saved and restored in the guest MSR save area. 	 * Host KGSBASE is restored before returning to userland from the pcb. 	 * There will be a window of time when we are executing in the host 	 * kernel context with a value of KGSBASE from the guest. This is ok 	 * because the value of KGSBASE is inconsequential in kernel context. 	 * 	 * MSR_EFER is saved and restored in the guest VMCS area on a 	 * VM exit and entry respectively. It is also restored from the 	 * host VMCS area on a VM exit. 	 * 	 * The TSC MSR is exposed read-only. Writes are disallowed as that 	 * will impact the host TSC. 	 * XXX Writes would be implemented with a wrmsr trap, and 	 * then modifying the TSC offset in the VMCS. 	 */
if|if
condition|(
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_GSBASE
argument_list|)
operator|||
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_FSBASE
argument_list|)
operator|||
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_SYSENTER_CS_MSR
argument_list|)
operator|||
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_SYSENTER_ESP_MSR
argument_list|)
operator|||
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_SYSENTER_EIP_MSR
argument_list|)
operator|||
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_KGSBASE
argument_list|)
operator|||
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_EFER
argument_list|)
operator|||
name|guest_msr_ro
argument_list|(
name|vmx
argument_list|,
name|MSR_TSC
argument_list|)
condition|)
name|panic
argument_list|(
literal|"vmx_vminit: error setting guest msr access"
argument_list|)
expr_stmt|;
comment|/* 	 * MSR_PAT is saved and restored in the guest VMCS are on a VM exit 	 * and entry respectively. It is also restored from the host VMCS 	 * area on a VM exit. However, if running on a system with no 	 * MSR_PAT save/restore support, leave access disabled so accesses 	 * will be trapped. 	 */
if|if
condition|(
operator|!
name|vmx_no_patmsr
operator|&&
name|guest_msr_rw
argument_list|(
name|vmx
argument_list|,
name|MSR_PAT
argument_list|)
condition|)
name|panic
argument_list|(
literal|"vmx_vminit: error setting guest pat msr access"
argument_list|)
expr_stmt|;
name|vpid_alloc
argument_list|(
name|vpid
argument_list|,
name|VM_MAXCPU
argument_list|)
expr_stmt|;
if|if
condition|(
name|virtual_interrupt_delivery
condition|)
block|{
name|error
operator|=
name|vm_map_mmio
argument_list|(
name|vm
argument_list|,
name|DEFAULT_APIC_BASE
argument_list|,
name|PAGE_SIZE
argument_list|,
name|APIC_ACCESS_ADDRESS
argument_list|)
expr_stmt|;
comment|/* XXX this should really return an error to the caller */
name|KASSERT
argument_list|(
name|error
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_map_mmio(apicbase) error %d"
operator|,
name|error
operator|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|VM_MAXCPU
condition|;
name|i
operator|++
control|)
block|{
name|vmcs
operator|=
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|i
index|]
expr_stmt|;
name|vmcs
operator|->
name|identifier
operator|=
name|vmx_revision
argument_list|()
expr_stmt|;
name|error
operator|=
name|vmclear
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"vmx_vminit: vmclear error %d on vcpu %d\n"
argument_list|,
name|error
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
name|error
operator|=
name|vmcs_init
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|error
operator|==
literal|0
argument_list|,
operator|(
literal|"vmcs_init error %d"
operator|,
name|error
operator|)
argument_list|)
expr_stmt|;
name|VMPTRLD
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
name|error
operator|=
literal|0
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_HOST_RSP
argument_list|,
operator|(
name|u_long
operator|)
operator|&
name|vmx
operator|->
name|ctx
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_EPTP
argument_list|,
name|vmx
operator|->
name|eptp
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_PIN_BASED_CTLS
argument_list|,
name|pinbased_ctls
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_PRI_PROC_BASED_CTLS
argument_list|,
name|procbased_ctls
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_SEC_PROC_BASED_CTLS
argument_list|,
name|procbased_ctls2
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_EXIT_CTLS
argument_list|,
name|exit_ctls
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_ENTRY_CTLS
argument_list|,
name|entry_ctls
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_MSR_BITMAP
argument_list|,
name|vtophys
argument_list|(
name|vmx
operator|->
name|msr_bitmap
argument_list|)
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_VPID
argument_list|,
name|vpid
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|virtual_interrupt_delivery
condition|)
block|{
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_APIC_ACCESS
argument_list|,
name|APIC_ACCESS_ADDRESS
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_VIRTUAL_APIC
argument_list|,
name|vtophys
argument_list|(
operator|&
name|vmx
operator|->
name|apic_page
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_EOI_EXIT0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_EOI_EXIT1
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_EOI_EXIT2
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_EOI_EXIT3
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|posted_interrupts
condition|)
block|{
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_PIR_VECTOR
argument_list|,
name|pirvec
argument_list|)
expr_stmt|;
name|error
operator|+=
name|vmwrite
argument_list|(
name|VMCS_PIR_DESC
argument_list|,
name|vtophys
argument_list|(
operator|&
name|vmx
operator|->
name|pir_desc
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|VMCLEAR
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|error
operator|==
literal|0
argument_list|,
operator|(
literal|"vmx_vminit: error customizing the vmcs"
operator|)
argument_list|)
expr_stmt|;
name|vmx
operator|->
name|cap
index|[
name|i
index|]
operator|.
name|set
operator|=
literal|0
expr_stmt|;
name|vmx
operator|->
name|cap
index|[
name|i
index|]
operator|.
name|proc_ctls
operator|=
name|procbased_ctls
expr_stmt|;
name|vmx
operator|->
name|cap
index|[
name|i
index|]
operator|.
name|proc_ctls2
operator|=
name|procbased_ctls2
expr_stmt|;
name|vmx
operator|->
name|state
index|[
name|i
index|]
operator|.
name|lastcpu
operator|=
operator|-
literal|1
expr_stmt|;
name|vmx
operator|->
name|state
index|[
name|i
index|]
operator|.
name|vpid
operator|=
name|vpid
index|[
name|i
index|]
expr_stmt|;
name|msr_save_area_init
argument_list|(
name|vmx
operator|->
name|guest_msrs
index|[
name|i
index|]
argument_list|,
operator|&
name|guest_msr_count
argument_list|)
expr_stmt|;
name|error
operator|=
name|vmcs_set_msr_save
argument_list|(
name|vmcs
argument_list|,
name|vtophys
argument_list|(
name|vmx
operator|->
name|guest_msrs
index|[
name|i
index|]
argument_list|)
argument_list|,
name|guest_msr_count
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vmcs_set_msr_save error %d"
argument_list|,
name|error
argument_list|)
expr_stmt|;
comment|/* 		 * Set up the CR0/4 shadows, and init the read shadow 		 * to the power-on register value from the Intel Sys Arch. 		 *  CR0 - 0x60000010 		 *  CR4 - 0 		 */
name|error
operator|=
name|vmx_setup_cr0_shadow
argument_list|(
name|vmcs
argument_list|,
literal|0x60000010
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vmx_setup_cr0_shadow %d"
argument_list|,
name|error
argument_list|)
expr_stmt|;
name|error
operator|=
name|vmx_setup_cr4_shadow
argument_list|(
name|vmcs
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vmx_setup_cr4_shadow %d"
argument_list|,
name|error
argument_list|)
expr_stmt|;
name|vmx
operator|->
name|ctx
index|[
name|i
index|]
operator|.
name|pmap
operator|=
name|pmap
expr_stmt|;
block|}
return|return
operator|(
name|vmx
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_handle_cpuid
parameter_list|(
name|struct
name|vm
modifier|*
name|vm
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|struct
name|vmxctx
modifier|*
name|vmxctx
parameter_list|)
block|{
name|int
name|handled
decl_stmt|,
name|func
decl_stmt|;
name|func
operator|=
name|vmxctx
operator|->
name|guest_rax
expr_stmt|;
name|handled
operator|=
name|x86_emulate_cpuid
argument_list|(
name|vm
argument_list|,
name|vcpu
argument_list|,
operator|(
name|uint32_t
operator|*
operator|)
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rax
operator|)
argument_list|,
operator|(
name|uint32_t
operator|*
operator|)
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rbx
operator|)
argument_list|,
operator|(
name|uint32_t
operator|*
operator|)
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rcx
operator|)
argument_list|,
operator|(
name|uint32_t
operator|*
operator|)
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rdx
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|handled
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|vmx_run_trace
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|KTR
name|VCPU_CTR1
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Resume execution at %#lx"
argument_list|,
name|vmcs_guest_rip
argument_list|()
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|vmx_exit_trace
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|uint64_t
name|rip
parameter_list|,
name|uint32_t
name|exit_reason
parameter_list|,
name|int
name|handled
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|KTR
name|VCPU_CTR3
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"%s %s vmexit at 0x%0lx"
argument_list|,
name|handled
condition|?
literal|"handled"
else|:
literal|"unhandled"
argument_list|,
name|exit_reason_to_str
argument_list|(
name|exit_reason
argument_list|)
argument_list|,
name|rip
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|vmx_astpending_trace
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|uint64_t
name|rip
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|KTR
name|VCPU_CTR1
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"astpending vmexit at 0x%0lx"
argument_list|,
name|rip
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_expr_stmt
specifier|static
name|VMM_STAT_INTEL
argument_list|(
name|VCPU_INVVPID_SAVED
argument_list|,
literal|"Number of vpid invalidations saved"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|void
name|vmx_set_pcpu_defaults
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|struct
name|vmxstate
modifier|*
name|vmxstate
decl_stmt|;
name|struct
name|invvpid_desc
name|invvpid_desc
decl_stmt|;
name|vmxstate
operator|=
operator|&
name|vmx
operator|->
name|state
index|[
name|vcpu
index|]
expr_stmt|;
if|if
condition|(
name|vmxstate
operator|->
name|lastcpu
operator|==
name|curcpu
condition|)
return|return;
name|vmxstate
operator|->
name|lastcpu
operator|=
name|curcpu
expr_stmt|;
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VCPU_MIGRATIONS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_HOST_TR_BASE
argument_list|,
name|vmm_get_host_trbase
argument_list|()
argument_list|)
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_HOST_GDTR_BASE
argument_list|,
name|vmm_get_host_gdtrbase
argument_list|()
argument_list|)
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_HOST_GS_BASE
argument_list|,
name|vmm_get_host_gsbase
argument_list|()
argument_list|)
expr_stmt|;
comment|/* 	 * If we are using VPIDs then invalidate all mappings tagged with 'vpid' 	 * 	 * We do this because this vcpu was executing on a different host 	 * cpu when it last ran. We do not track whether it invalidated 	 * mappings associated with its 'vpid' during that run. So we must 	 * assume that the mappings associated with 'vpid' on 'curcpu' are 	 * stale and invalidate them. 	 * 	 * Note that we incur this penalty only when the scheduler chooses to 	 * move the thread associated with this vcpu between host cpus. 	 * 	 * Note also that this will invalidate mappings tagged with 'vpid' 	 * for "all" EP4TAs. 	 */
if|if
condition|(
name|vmxstate
operator|->
name|vpid
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|pmap
operator|->
name|pm_eptgen
operator|==
name|vmx
operator|->
name|eptgen
index|[
name|curcpu
index|]
condition|)
block|{
name|invvpid_desc
operator|.
name|_res1
operator|=
literal|0
expr_stmt|;
name|invvpid_desc
operator|.
name|_res2
operator|=
literal|0
expr_stmt|;
name|invvpid_desc
operator|.
name|vpid
operator|=
name|vmxstate
operator|->
name|vpid
expr_stmt|;
name|invvpid_desc
operator|.
name|linear_addr
operator|=
literal|0
expr_stmt|;
name|invvpid
argument_list|(
name|INVVPID_TYPE_SINGLE_CONTEXT
argument_list|,
name|invvpid_desc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * The invvpid can be skipped if an invept is going to 			 * be performed before entering the guest. The invept 			 * will invalidate combined mappings tagged with 			 * 'vmx->eptp' for all vpids. 			 */
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VCPU_INVVPID_SAVED
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * We depend on 'procbased_ctls' to have the Interrupt Window Exiting bit set.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
operator|(
name|PROCBASED_CTLS_ONE_SETTING
operator|&
name|PROCBASED_INT_WINDOW_EXITING
operator|)
operator|!=
literal|0
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|void
name|__inline
name|vmx_set_int_window_exiting
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|)
block|{
if|if
condition|(
operator|(
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator|&
name|PROCBASED_INT_WINDOW_EXITING
operator|)
operator|==
literal|0
condition|)
block|{
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator||=
name|PROCBASED_INT_WINDOW_EXITING
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_PRI_PROC_BASED_CTLS
argument_list|,
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
argument_list|)
expr_stmt|;
name|VCPU_CTR0
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Enabling interrupt window exiting"
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|__inline
name|vmx_clear_int_window_exiting
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator|&
name|PROCBASED_INT_WINDOW_EXITING
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"intr_window_exiting not set: %#x"
operator|,
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator|)
argument_list|)
expr_stmt|;
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator|&=
operator|~
name|PROCBASED_INT_WINDOW_EXITING
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_PRI_PROC_BASED_CTLS
argument_list|,
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
argument_list|)
expr_stmt|;
name|VCPU_CTR0
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Disabling interrupt window exiting"
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|__inline
name|vmx_set_nmi_window_exiting
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|)
block|{
if|if
condition|(
operator|(
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator|&
name|PROCBASED_NMI_WINDOW_EXITING
operator|)
operator|==
literal|0
condition|)
block|{
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator||=
name|PROCBASED_NMI_WINDOW_EXITING
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_PRI_PROC_BASED_CTLS
argument_list|,
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
argument_list|)
expr_stmt|;
name|VCPU_CTR0
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Enabling NMI window exiting"
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|__inline
name|vmx_clear_nmi_window_exiting
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator|&
name|PROCBASED_NMI_WINDOW_EXITING
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"nmi_window_exiting not set %#x"
operator|,
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator|)
argument_list|)
expr_stmt|;
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator|&=
operator|~
name|PROCBASED_NMI_WINDOW_EXITING
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_PRI_PROC_BASED_CTLS
argument_list|,
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
argument_list|)
expr_stmt|;
name|VCPU_CTR0
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Disabling NMI window exiting"
argument_list|)
expr_stmt|;
block|}
end_function

begin_define
define|#
directive|define
name|NMI_BLOCKING
value|(VMCS_INTERRUPTIBILITY_NMI_BLOCKING |		\ 			 VMCS_INTERRUPTIBILITY_MOVSS_BLOCKING)
end_define

begin_define
define|#
directive|define
name|HWINTR_BLOCKING
value|(VMCS_INTERRUPTIBILITY_STI_BLOCKING |		\ 			 VMCS_INTERRUPTIBILITY_MOVSS_BLOCKING)
end_define

begin_function
specifier|static
name|void
name|vmx_inject_nmi
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|)
block|{
name|uint32_t
name|gi
decl_stmt|,
name|info
decl_stmt|;
name|gi
operator|=
name|vmcs_read
argument_list|(
name|VMCS_GUEST_INTERRUPTIBILITY
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|gi
operator|&
name|NMI_BLOCKING
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vmx_inject_nmi: invalid guest "
literal|"interruptibility-state %#x"
operator|,
name|gi
operator|)
argument_list|)
expr_stmt|;
name|info
operator|=
name|vmcs_read
argument_list|(
name|VMCS_ENTRY_INTR_INFO
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|info
operator|&
name|VMCS_INTR_VALID
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vmx_inject_nmi: invalid "
literal|"VM-entry interruption information %#x"
operator|,
name|info
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Inject the virtual NMI. The vector must be the NMI IDT entry 	 * or the VMCS entry check will fail. 	 */
name|info
operator|=
name|IDT_NMI
operator||
name|VMCS_INTR_T_NMI
operator||
name|VMCS_INTR_VALID
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_ENTRY_INTR_INFO
argument_list|,
name|info
argument_list|)
expr_stmt|;
name|VCPU_CTR0
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Injecting vNMI"
argument_list|)
expr_stmt|;
comment|/* Clear the request */
name|vm_nmi_clear
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_inject_interrupts
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|)
block|{
name|struct
name|vm_exception
name|exc
decl_stmt|;
name|int
name|vector
decl_stmt|,
name|need_nmi_exiting
decl_stmt|,
name|extint_pending
decl_stmt|;
name|uint64_t
name|rflags
decl_stmt|;
name|uint32_t
name|gi
decl_stmt|,
name|info
decl_stmt|;
if|if
condition|(
name|vm_exception_pending
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
operator|&
name|exc
argument_list|)
condition|)
block|{
name|KASSERT
argument_list|(
name|exc
operator|.
name|vector
operator|>=
literal|0
operator|&&
name|exc
operator|.
name|vector
operator|<
literal|32
argument_list|,
operator|(
literal|"%s: invalid exception vector %d"
operator|,
name|__func__
operator|,
name|exc
operator|.
name|vector
operator|)
argument_list|)
expr_stmt|;
name|info
operator|=
name|vmcs_read
argument_list|(
name|VMCS_ENTRY_INTR_INFO
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|info
operator|&
name|VMCS_INTR_VALID
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: cannot inject "
literal|"pending exception %d: %#x"
operator|,
name|__func__
operator|,
name|exc
operator|.
name|vector
operator|,
name|info
operator|)
argument_list|)
expr_stmt|;
name|info
operator|=
name|exc
operator|.
name|vector
operator||
name|VMCS_INTR_T_HWEXCEPTION
operator||
name|VMCS_INTR_VALID
expr_stmt|;
if|if
condition|(
name|exc
operator|.
name|error_code_valid
condition|)
block|{
name|info
operator||=
name|VMCS_INTR_DEL_ERRCODE
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_ENTRY_EXCEPTION_ERROR
argument_list|,
name|exc
operator|.
name|error_code
argument_list|)
expr_stmt|;
block|}
name|vmcs_write
argument_list|(
name|VMCS_ENTRY_INTR_INFO
argument_list|,
name|info
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|vm_nmi_pending
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
condition|)
block|{
comment|/* 		 * If there are no conditions blocking NMI injection then 		 * inject it directly here otherwise enable "NMI window 		 * exiting" to inject it as soon as we can. 		 * 		 * We also check for STI_BLOCKING because some implementations 		 * don't allow NMI injection in this case. If we are running 		 * on a processor that doesn't have this restriction it will 		 * immediately exit and the NMI will be injected in the 		 * "NMI window exiting" handler. 		 */
name|need_nmi_exiting
operator|=
literal|1
expr_stmt|;
name|gi
operator|=
name|vmcs_read
argument_list|(
name|VMCS_GUEST_INTERRUPTIBILITY
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|gi
operator|&
operator|(
name|HWINTR_BLOCKING
operator||
name|NMI_BLOCKING
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|info
operator|=
name|vmcs_read
argument_list|(
name|VMCS_ENTRY_INTR_INFO
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|info
operator|&
name|VMCS_INTR_VALID
operator|)
operator|==
literal|0
condition|)
block|{
name|vmx_inject_nmi
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
name|need_nmi_exiting
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
name|VCPU_CTR1
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Cannot inject NMI "
literal|"due to VM-entry intr info %#x"
argument_list|,
name|info
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|VCPU_CTR1
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Cannot inject NMI due to "
literal|"Guest Interruptibility-state %#x"
argument_list|,
name|gi
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|need_nmi_exiting
condition|)
name|vmx_set_nmi_window_exiting
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
block|}
name|extint_pending
operator|=
name|vm_extint_pending
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|extint_pending
operator|&&
name|virtual_interrupt_delivery
condition|)
block|{
name|vmx_inject_pir
argument_list|(
name|vlapic
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * If interrupt-window exiting is already in effect then don't bother 	 * checking for pending interrupts. This is just an optimization and 	 * not needed for correctness. 	 */
if|if
condition|(
operator|(
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
operator|&
name|PROCBASED_INT_WINDOW_EXITING
operator|)
operator|!=
literal|0
condition|)
block|{
name|VCPU_CTR0
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Skip interrupt injection due to "
literal|"pending int_window_exiting"
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|!
name|extint_pending
condition|)
block|{
comment|/* Ask the local apic for a vector to inject */
if|if
condition|(
operator|!
name|vlapic_pending_intr
argument_list|(
name|vlapic
argument_list|,
operator|&
name|vector
argument_list|)
condition|)
return|return;
block|}
else|else
block|{
comment|/* Ask the legacy pic for a vector to inject */
name|vatpic_pending_intr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
operator|&
name|vector
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|vector
operator|>=
literal|32
operator|&&
name|vector
operator|<=
literal|255
argument_list|,
operator|(
literal|"invalid vector %d"
operator|,
name|vector
operator|)
argument_list|)
expr_stmt|;
comment|/* Check RFLAGS.IF and the interruptibility state of the guest */
name|rflags
operator|=
name|vmcs_read
argument_list|(
name|VMCS_GUEST_RFLAGS
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|rflags
operator|&
name|PSL_I
operator|)
operator|==
literal|0
condition|)
block|{
name|VCPU_CTR2
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Cannot inject vector %d due to "
literal|"rflags %#lx"
argument_list|,
name|vector
argument_list|,
name|rflags
argument_list|)
expr_stmt|;
goto|goto
name|cantinject
goto|;
block|}
name|gi
operator|=
name|vmcs_read
argument_list|(
name|VMCS_GUEST_INTERRUPTIBILITY
argument_list|)
expr_stmt|;
if|if
condition|(
name|gi
operator|&
name|HWINTR_BLOCKING
condition|)
block|{
name|VCPU_CTR2
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Cannot inject vector %d due to "
literal|"Guest Interruptibility-state %#x"
argument_list|,
name|vector
argument_list|,
name|gi
argument_list|)
expr_stmt|;
goto|goto
name|cantinject
goto|;
block|}
name|info
operator|=
name|vmcs_read
argument_list|(
name|VMCS_ENTRY_INTR_INFO
argument_list|)
expr_stmt|;
if|if
condition|(
name|info
operator|&
name|VMCS_INTR_VALID
condition|)
block|{
comment|/* 		 * This is expected and could happen for multiple reasons: 		 * - A vectoring VM-entry was aborted due to astpending 		 * - A VM-exit happened during event injection. 		 * - An exception was injected above. 		 * - An NMI was injected above or after "NMI window exiting" 		 */
name|VCPU_CTR2
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Cannot inject vector %d due to "
literal|"VM-entry intr info %#x"
argument_list|,
name|vector
argument_list|,
name|info
argument_list|)
expr_stmt|;
goto|goto
name|cantinject
goto|;
block|}
comment|/* Inject the interrupt */
name|info
operator|=
name|VMCS_INTR_T_HWINTR
operator||
name|VMCS_INTR_VALID
expr_stmt|;
name|info
operator||=
name|vector
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_ENTRY_INTR_INFO
argument_list|,
name|info
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|extint_pending
condition|)
block|{
comment|/* Update the Local APIC ISR */
name|vlapic_intr_accepted
argument_list|(
name|vlapic
argument_list|,
name|vector
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|vm_extint_clear
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
name|vatpic_intr_accepted
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vector
argument_list|)
expr_stmt|;
comment|/* 		 * After we accepted the current ExtINT the PIC may 		 * have posted another one.  If that is the case, set 		 * the Interrupt Window Exiting execution control so 		 * we can inject that one too. 		 */
if|if
condition|(
name|vm_extint_pending
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
condition|)
name|vmx_set_int_window_exiting
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
block|}
name|VCPU_CTR1
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"Injecting hwintr at vector %d"
argument_list|,
name|vector
argument_list|)
expr_stmt|;
return|return;
name|cantinject
label|:
comment|/* 	 * Set the Interrupt Window Exiting execution control so we can inject 	 * the interrupt as soon as blocking condition goes away. 	 */
name|vmx_set_int_window_exiting
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * If the Virtual NMIs execution control is '1' then the logical processor  * tracks virtual-NMI blocking in the Guest Interruptibility-state field of  * the VMCS. An IRET instruction in VMX non-root operation will remove any  * virtual-NMI blocking.  *  * This unblocking occurs even if the IRET causes a fault. In this case the  * hypervisor needs to restore virtual-NMI blocking before resuming the guest.  */
end_comment

begin_function
specifier|static
name|void
name|vmx_restore_nmi_blocking
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpuid
parameter_list|)
block|{
name|uint32_t
name|gi
decl_stmt|;
name|VCPU_CTR0
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpuid
argument_list|,
literal|"Restore Virtual-NMI blocking"
argument_list|)
expr_stmt|;
name|gi
operator|=
name|vmcs_read
argument_list|(
name|VMCS_GUEST_INTERRUPTIBILITY
argument_list|)
expr_stmt|;
name|gi
operator||=
name|VMCS_INTERRUPTIBILITY_NMI_BLOCKING
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_GUEST_INTERRUPTIBILITY
argument_list|,
name|gi
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_clear_nmi_blocking
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpuid
parameter_list|)
block|{
name|uint32_t
name|gi
decl_stmt|;
name|VCPU_CTR0
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpuid
argument_list|,
literal|"Clear Virtual-NMI blocking"
argument_list|)
expr_stmt|;
name|gi
operator|=
name|vmcs_read
argument_list|(
name|VMCS_GUEST_INTERRUPTIBILITY
argument_list|)
expr_stmt|;
name|gi
operator|&=
operator|~
name|VMCS_INTERRUPTIBILITY_NMI_BLOCKING
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_GUEST_INTERRUPTIBILITY
argument_list|,
name|gi
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_emulate_xsetbv
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|struct
name|vm_exit
modifier|*
name|vmexit
parameter_list|)
block|{
name|struct
name|vmxctx
modifier|*
name|vmxctx
decl_stmt|;
name|uint64_t
name|xcrval
decl_stmt|;
specifier|const
name|struct
name|xsave_limits
modifier|*
name|limits
decl_stmt|;
name|vmxctx
operator|=
operator|&
name|vmx
operator|->
name|ctx
index|[
name|vcpu
index|]
expr_stmt|;
name|limits
operator|=
name|vmm_get_xsave_limits
argument_list|()
expr_stmt|;
comment|/* 	 * Note that the processor raises a GP# fault on its own if 	 * xsetbv is executed for CPL != 0, so we do not have to 	 * emulate that fault here. 	 */
comment|/* Only xcr0 is supported. */
if|if
condition|(
name|vmxctx
operator|->
name|guest_rcx
operator|!=
literal|0
condition|)
block|{
name|vm_inject_gp
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
return|return
operator|(
name|HANDLED
operator|)
return|;
block|}
comment|/* We only handle xcr0 if both the host and guest have XSAVE enabled. */
if|if
condition|(
operator|!
name|limits
operator|->
name|xsave_enabled
operator|||
operator|!
operator|(
name|vmcs_read
argument_list|(
name|VMCS_GUEST_CR4
argument_list|)
operator|&
name|CR4_XSAVE
operator|)
condition|)
block|{
name|vm_inject_ud
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
return|return
operator|(
name|HANDLED
operator|)
return|;
block|}
name|xcrval
operator|=
name|vmxctx
operator|->
name|guest_rdx
operator|<<
literal|32
operator||
operator|(
name|vmxctx
operator|->
name|guest_rax
operator|&
literal|0xffffffff
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|xcrval
operator|&
operator|~
name|limits
operator|->
name|xcr0_allowed
operator|)
operator|!=
literal|0
condition|)
block|{
name|vm_inject_gp
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
return|return
operator|(
name|HANDLED
operator|)
return|;
block|}
if|if
condition|(
operator|!
operator|(
name|xcrval
operator|&
name|XFEATURE_ENABLED_X87
operator|)
condition|)
block|{
name|vm_inject_gp
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
return|return
operator|(
name|HANDLED
operator|)
return|;
block|}
if|if
condition|(
operator|(
name|xcrval
operator|&
operator|(
name|XFEATURE_ENABLED_AVX
operator||
name|XFEATURE_ENABLED_SSE
operator|)
operator|)
operator|==
name|XFEATURE_ENABLED_AVX
condition|)
block|{
name|vm_inject_gp
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
return|return
operator|(
name|HANDLED
operator|)
return|;
block|}
comment|/* 	 * This runs "inside" vmrun() with the guest's FPU state, so 	 * modifying xcr0 directly modifies the guest's xcr0, not the 	 * host's. 	 */
name|load_xcr
argument_list|(
literal|0
argument_list|,
name|xcrval
argument_list|)
expr_stmt|;
return|return
operator|(
name|HANDLED
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_emulate_cr_access
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|uint64_t
name|exitqual
parameter_list|)
block|{
name|int
name|cr
decl_stmt|,
name|vmcs_guest_cr
decl_stmt|,
name|vmcs_shadow_cr
decl_stmt|;
name|uint64_t
name|crval
decl_stmt|,
name|regval
decl_stmt|,
name|ones_mask
decl_stmt|,
name|zeros_mask
decl_stmt|;
specifier|const
name|struct
name|vmxctx
modifier|*
name|vmxctx
decl_stmt|;
comment|/* We only handle mov to %cr0 or %cr4 at this time */
if|if
condition|(
operator|(
name|exitqual
operator|&
literal|0xf0
operator|)
operator|!=
literal|0x00
condition|)
return|return
operator|(
name|UNHANDLED
operator|)
return|;
name|cr
operator|=
name|exitqual
operator|&
literal|0xf
expr_stmt|;
if|if
condition|(
name|cr
operator|!=
literal|0
operator|&&
name|cr
operator|!=
literal|4
condition|)
return|return
operator|(
name|UNHANDLED
operator|)
return|;
name|regval
operator|=
literal|0
expr_stmt|;
comment|/* silence gcc */
name|vmxctx
operator|=
operator|&
name|vmx
operator|->
name|ctx
index|[
name|vcpu
index|]
expr_stmt|;
comment|/* 	 * We must use vmcs_write() directly here because vmcs_setreg() will 	 * call vmclear(vmcs) as a side-effect which we certainly don't want. 	 */
switch|switch
condition|(
operator|(
name|exitqual
operator|>>
literal|8
operator|)
operator|&
literal|0xf
condition|)
block|{
case|case
literal|0
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_rax
expr_stmt|;
break|break;
case|case
literal|1
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_rcx
expr_stmt|;
break|break;
case|case
literal|2
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_rdx
expr_stmt|;
break|break;
case|case
literal|3
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_rbx
expr_stmt|;
break|break;
case|case
literal|4
case|:
name|regval
operator|=
name|vmcs_read
argument_list|(
name|VMCS_GUEST_RSP
argument_list|)
expr_stmt|;
break|break;
case|case
literal|5
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_rbp
expr_stmt|;
break|break;
case|case
literal|6
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_rsi
expr_stmt|;
break|break;
case|case
literal|7
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_rdi
expr_stmt|;
break|break;
case|case
literal|8
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_r8
expr_stmt|;
break|break;
case|case
literal|9
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_r9
expr_stmt|;
break|break;
case|case
literal|10
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_r10
expr_stmt|;
break|break;
case|case
literal|11
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_r11
expr_stmt|;
break|break;
case|case
literal|12
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_r12
expr_stmt|;
break|break;
case|case
literal|13
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_r13
expr_stmt|;
break|break;
case|case
literal|14
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_r14
expr_stmt|;
break|break;
case|case
literal|15
case|:
name|regval
operator|=
name|vmxctx
operator|->
name|guest_r15
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|cr
operator|==
literal|0
condition|)
block|{
name|ones_mask
operator|=
name|cr0_ones_mask
expr_stmt|;
name|zeros_mask
operator|=
name|cr0_zeros_mask
expr_stmt|;
name|vmcs_guest_cr
operator|=
name|VMCS_GUEST_CR0
expr_stmt|;
name|vmcs_shadow_cr
operator|=
name|VMCS_CR0_SHADOW
expr_stmt|;
block|}
else|else
block|{
name|ones_mask
operator|=
name|cr4_ones_mask
expr_stmt|;
name|zeros_mask
operator|=
name|cr4_zeros_mask
expr_stmt|;
name|vmcs_guest_cr
operator|=
name|VMCS_GUEST_CR4
expr_stmt|;
name|vmcs_shadow_cr
operator|=
name|VMCS_CR4_SHADOW
expr_stmt|;
block|}
name|vmcs_write
argument_list|(
name|vmcs_shadow_cr
argument_list|,
name|regval
argument_list|)
expr_stmt|;
name|crval
operator|=
name|regval
operator||
name|ones_mask
expr_stmt|;
name|crval
operator|&=
operator|~
name|zeros_mask
expr_stmt|;
name|vmcs_write
argument_list|(
name|vmcs_guest_cr
argument_list|,
name|crval
argument_list|)
expr_stmt|;
if|if
condition|(
name|cr
operator|==
literal|0
operator|&&
name|regval
operator|&
name|CR0_PG
condition|)
block|{
name|uint64_t
name|efer
decl_stmt|,
name|entry_ctls
decl_stmt|;
comment|/* 		 * If CR0.PG is 1 and EFER.LME is 1 then EFER.LMA and 		 * the "IA-32e mode guest" bit in VM-entry control must be 		 * equal. 		 */
name|efer
operator|=
name|vmcs_read
argument_list|(
name|VMCS_GUEST_IA32_EFER
argument_list|)
expr_stmt|;
if|if
condition|(
name|efer
operator|&
name|EFER_LME
condition|)
block|{
name|efer
operator||=
name|EFER_LMA
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_GUEST_IA32_EFER
argument_list|,
name|efer
argument_list|)
expr_stmt|;
name|entry_ctls
operator|=
name|vmcs_read
argument_list|(
name|VMCS_ENTRY_CTLS
argument_list|)
expr_stmt|;
name|entry_ctls
operator||=
name|VM_ENTRY_GUEST_LMA
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_ENTRY_CTLS
argument_list|,
name|entry_ctls
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|(
name|HANDLED
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|enum
name|vie_cpu_mode
name|vmx_cpu_mode
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|vmcs_read
argument_list|(
name|VMCS_GUEST_IA32_EFER
argument_list|)
operator|&
name|EFER_LMA
condition|)
return|return
operator|(
name|CPU_MODE_64BIT
operator|)
return|;
else|else
return|return
operator|(
name|CPU_MODE_COMPATIBILITY
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|enum
name|vie_paging_mode
name|vmx_paging_mode
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|vmcs_read
argument_list|(
name|VMCS_GUEST_CR0
argument_list|)
operator|&
name|CR0_PG
operator|)
condition|)
return|return
operator|(
name|PAGING_MODE_FLAT
operator|)
return|;
if|if
condition|(
operator|!
operator|(
name|vmcs_read
argument_list|(
name|VMCS_GUEST_CR4
argument_list|)
operator|&
name|CR4_PAE
operator|)
condition|)
return|return
operator|(
name|PAGING_MODE_32
operator|)
return|;
if|if
condition|(
name|vmcs_read
argument_list|(
name|VMCS_GUEST_IA32_EFER
argument_list|)
operator|&
name|EFER_LME
condition|)
return|return
operator|(
name|PAGING_MODE_64
operator|)
return|;
else|else
return|return
operator|(
name|PAGING_MODE_PAE
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|ept_fault_type
parameter_list|(
name|uint64_t
name|ept_qual
parameter_list|)
block|{
name|int
name|fault_type
decl_stmt|;
if|if
condition|(
name|ept_qual
operator|&
name|EPT_VIOLATION_DATA_WRITE
condition|)
name|fault_type
operator|=
name|VM_PROT_WRITE
expr_stmt|;
elseif|else
if|if
condition|(
name|ept_qual
operator|&
name|EPT_VIOLATION_INST_FETCH
condition|)
name|fault_type
operator|=
name|VM_PROT_EXECUTE
expr_stmt|;
else|else
name|fault_type
operator|=
name|VM_PROT_READ
expr_stmt|;
return|return
operator|(
name|fault_type
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|boolean_t
name|ept_emulation_fault
parameter_list|(
name|uint64_t
name|ept_qual
parameter_list|)
block|{
name|int
name|read
decl_stmt|,
name|write
decl_stmt|;
comment|/* EPT fault on an instruction fetch doesn't make sense here */
if|if
condition|(
name|ept_qual
operator|&
name|EPT_VIOLATION_INST_FETCH
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
comment|/* EPT fault must be a read fault or a write fault */
name|read
operator|=
name|ept_qual
operator|&
name|EPT_VIOLATION_DATA_READ
condition|?
literal|1
else|:
literal|0
expr_stmt|;
name|write
operator|=
name|ept_qual
operator|&
name|EPT_VIOLATION_DATA_WRITE
condition|?
literal|1
else|:
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|read
operator||
name|write
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
comment|/* 	 * The EPT violation must have been caused by accessing a 	 * guest-physical address that is a translation of a guest-linear 	 * address. 	 */
if|if
condition|(
operator|(
name|ept_qual
operator|&
name|EPT_VIOLATION_GLA_VALID
operator|)
operator|==
literal|0
operator|||
operator|(
name|ept_qual
operator|&
name|EPT_VIOLATION_XLAT_VALID
operator|)
operator|==
literal|0
condition|)
block|{
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|apic_access_virtualization
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpuid
parameter_list|)
block|{
name|uint32_t
name|proc_ctls2
decl_stmt|;
name|proc_ctls2
operator|=
name|vmx
operator|->
name|cap
index|[
name|vcpuid
index|]
operator|.
name|proc_ctls2
expr_stmt|;
return|return
operator|(
operator|(
name|proc_ctls2
operator|&
name|PROCBASED2_VIRTUALIZE_APIC_ACCESSES
operator|)
condition|?
literal|1
else|:
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|x2apic_virtualization
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpuid
parameter_list|)
block|{
name|uint32_t
name|proc_ctls2
decl_stmt|;
name|proc_ctls2
operator|=
name|vmx
operator|->
name|cap
index|[
name|vcpuid
index|]
operator|.
name|proc_ctls2
expr_stmt|;
return|return
operator|(
operator|(
name|proc_ctls2
operator|&
name|PROCBASED2_VIRTUALIZE_X2APIC_MODE
operator|)
condition|?
literal|1
else|:
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_handle_apic_write
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpuid
parameter_list|,
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|,
name|uint64_t
name|qual
parameter_list|)
block|{
name|int
name|error
decl_stmt|,
name|handled
decl_stmt|,
name|offset
decl_stmt|;
name|uint32_t
modifier|*
name|apic_regs
decl_stmt|,
name|vector
decl_stmt|;
name|bool
name|retu
decl_stmt|;
name|handled
operator|=
name|HANDLED
expr_stmt|;
name|offset
operator|=
name|APIC_WRITE_OFFSET
argument_list|(
name|qual
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|apic_access_virtualization
argument_list|(
name|vmx
argument_list|,
name|vcpuid
argument_list|)
condition|)
block|{
comment|/* 		 * In general there should not be any APIC write VM-exits 		 * unless APIC-access virtualization is enabled. 		 * 		 * However self-IPI virtualization can legitimately trigger 		 * an APIC-write VM-exit so treat it specially. 		 */
if|if
condition|(
name|x2apic_virtualization
argument_list|(
name|vmx
argument_list|,
name|vcpuid
argument_list|)
operator|&&
name|offset
operator|==
name|APIC_OFFSET_SELF_IPI
condition|)
block|{
name|apic_regs
operator|=
operator|(
name|uint32_t
operator|*
operator|)
operator|(
name|vlapic
operator|->
name|apic_page
operator|)
expr_stmt|;
name|vector
operator|=
name|apic_regs
index|[
name|APIC_OFFSET_SELF_IPI
operator|/
literal|4
index|]
expr_stmt|;
name|vlapic_self_ipi_handler
argument_list|(
name|vlapic
argument_list|,
name|vector
argument_list|)
expr_stmt|;
return|return
operator|(
name|HANDLED
operator|)
return|;
block|}
else|else
return|return
operator|(
name|UNHANDLED
operator|)
return|;
block|}
switch|switch
condition|(
name|offset
condition|)
block|{
case|case
name|APIC_OFFSET_ID
case|:
name|vlapic_id_write_handler
argument_list|(
name|vlapic
argument_list|)
expr_stmt|;
break|break;
case|case
name|APIC_OFFSET_LDR
case|:
name|vlapic_ldr_write_handler
argument_list|(
name|vlapic
argument_list|)
expr_stmt|;
break|break;
case|case
name|APIC_OFFSET_DFR
case|:
name|vlapic_dfr_write_handler
argument_list|(
name|vlapic
argument_list|)
expr_stmt|;
break|break;
case|case
name|APIC_OFFSET_SVR
case|:
name|vlapic_svr_write_handler
argument_list|(
name|vlapic
argument_list|)
expr_stmt|;
break|break;
case|case
name|APIC_OFFSET_ESR
case|:
name|vlapic_esr_write_handler
argument_list|(
name|vlapic
argument_list|)
expr_stmt|;
break|break;
case|case
name|APIC_OFFSET_ICR_LOW
case|:
name|retu
operator|=
name|false
expr_stmt|;
name|error
operator|=
name|vlapic_icrlo_write_handler
argument_list|(
name|vlapic
argument_list|,
operator|&
name|retu
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
operator|||
name|retu
condition|)
name|handled
operator|=
name|UNHANDLED
expr_stmt|;
break|break;
case|case
name|APIC_OFFSET_CMCI_LVT
case|:
case|case
name|APIC_OFFSET_TIMER_LVT
operator|...
name|APIC_OFFSET_ERROR_LVT
case|:
name|vlapic_lvt_write_handler
argument_list|(
name|vlapic
argument_list|,
name|offset
argument_list|)
expr_stmt|;
break|break;
case|case
name|APIC_OFFSET_TIMER_ICR
case|:
name|vlapic_icrtmr_write_handler
argument_list|(
name|vlapic
argument_list|)
expr_stmt|;
break|break;
case|case
name|APIC_OFFSET_TIMER_DCR
case|:
name|vlapic_dcr_write_handler
argument_list|(
name|vlapic
argument_list|)
expr_stmt|;
break|break;
default|default:
name|handled
operator|=
name|UNHANDLED
expr_stmt|;
break|break;
block|}
return|return
operator|(
name|handled
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|bool
name|apic_access_fault
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpuid
parameter_list|,
name|uint64_t
name|gpa
parameter_list|)
block|{
if|if
condition|(
name|apic_access_virtualization
argument_list|(
name|vmx
argument_list|,
name|vcpuid
argument_list|)
operator|&&
operator|(
name|gpa
operator|>=
name|DEFAULT_APIC_BASE
operator|&&
name|gpa
operator|<
name|DEFAULT_APIC_BASE
operator|+
name|PAGE_SIZE
operator|)
condition|)
return|return
operator|(
name|true
operator|)
return|;
else|else
return|return
operator|(
name|false
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_handle_apic_access
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpuid
parameter_list|,
name|struct
name|vm_exit
modifier|*
name|vmexit
parameter_list|)
block|{
name|uint64_t
name|qual
decl_stmt|;
name|int
name|access_type
decl_stmt|,
name|offset
decl_stmt|,
name|allowed
decl_stmt|;
if|if
condition|(
operator|!
name|apic_access_virtualization
argument_list|(
name|vmx
argument_list|,
name|vcpuid
argument_list|)
condition|)
return|return
operator|(
name|UNHANDLED
operator|)
return|;
name|qual
operator|=
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|exit_qualification
expr_stmt|;
name|access_type
operator|=
name|APIC_ACCESS_TYPE
argument_list|(
name|qual
argument_list|)
expr_stmt|;
name|offset
operator|=
name|APIC_ACCESS_OFFSET
argument_list|(
name|qual
argument_list|)
expr_stmt|;
name|allowed
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|access_type
operator|==
literal|0
condition|)
block|{
comment|/* 		 * Read data access to the following registers is expected. 		 */
switch|switch
condition|(
name|offset
condition|)
block|{
case|case
name|APIC_OFFSET_APR
case|:
case|case
name|APIC_OFFSET_PPR
case|:
case|case
name|APIC_OFFSET_RRR
case|:
case|case
name|APIC_OFFSET_CMCI_LVT
case|:
case|case
name|APIC_OFFSET_TIMER_CCR
case|:
name|allowed
operator|=
literal|1
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
elseif|else
if|if
condition|(
name|access_type
operator|==
literal|1
condition|)
block|{
comment|/* 		 * Write data access to the following registers is expected. 		 */
switch|switch
condition|(
name|offset
condition|)
block|{
case|case
name|APIC_OFFSET_VER
case|:
case|case
name|APIC_OFFSET_APR
case|:
case|case
name|APIC_OFFSET_PPR
case|:
case|case
name|APIC_OFFSET_RRR
case|:
case|case
name|APIC_OFFSET_ISR0
operator|...
name|APIC_OFFSET_ISR7
case|:
case|case
name|APIC_OFFSET_TMR0
operator|...
name|APIC_OFFSET_TMR7
case|:
case|case
name|APIC_OFFSET_IRR0
operator|...
name|APIC_OFFSET_IRR7
case|:
case|case
name|APIC_OFFSET_CMCI_LVT
case|:
case|case
name|APIC_OFFSET_TIMER_CCR
case|:
name|allowed
operator|=
literal|1
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
if|if
condition|(
name|allowed
condition|)
block|{
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_INST_EMUL
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inst_emul
operator|.
name|gpa
operator|=
name|DEFAULT_APIC_BASE
operator|+
name|offset
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inst_emul
operator|.
name|gla
operator|=
name|VIE_INVALID_GLA
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inst_emul
operator|.
name|cr3
operator|=
name|vmcs_guest_cr3
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inst_emul
operator|.
name|cpu_mode
operator|=
name|vmx_cpu_mode
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inst_emul
operator|.
name|paging_mode
operator|=
name|vmx_paging_mode
argument_list|()
expr_stmt|;
block|}
comment|/* 	 * Regardless of whether the APIC-access is allowed this handler 	 * always returns UNHANDLED: 	 * - if the access is allowed then it is handled by emulating the 	 *   instruction that caused the VM-exit (outside the critical section) 	 * - if the access is not allowed then it will be converted to an 	 *   exitcode of VM_EXITCODE_VMX and will be dealt with in userland. 	 */
return|return
operator|(
name|UNHANDLED
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_exit_process
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|struct
name|vm_exit
modifier|*
name|vmexit
parameter_list|)
block|{
name|int
name|error
decl_stmt|,
name|handled
decl_stmt|;
name|struct
name|vmxctx
modifier|*
name|vmxctx
decl_stmt|;
name|struct
name|vlapic
modifier|*
name|vlapic
decl_stmt|;
name|uint32_t
name|eax
decl_stmt|,
name|ecx
decl_stmt|,
name|edx
decl_stmt|,
name|idtvec_info
decl_stmt|,
name|idtvec_err
decl_stmt|,
name|intr_info
decl_stmt|,
name|reason
decl_stmt|;
name|uint64_t
name|qual
decl_stmt|,
name|gpa
decl_stmt|;
name|bool
name|retu
decl_stmt|;
name|CTASSERT
argument_list|(
operator|(
name|PINBASED_CTLS_ONE_SETTING
operator|&
name|PINBASED_VIRTUAL_NMI
operator|)
operator|!=
literal|0
argument_list|)
expr_stmt|;
name|CTASSERT
argument_list|(
operator|(
name|PINBASED_CTLS_ONE_SETTING
operator|&
name|PINBASED_NMI_EXITING
operator|)
operator|!=
literal|0
argument_list|)
expr_stmt|;
name|handled
operator|=
name|UNHANDLED
expr_stmt|;
name|vmxctx
operator|=
operator|&
name|vmx
operator|->
name|ctx
index|[
name|vcpu
index|]
expr_stmt|;
name|qual
operator|=
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|exit_qualification
expr_stmt|;
name|reason
operator|=
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|exit_reason
expr_stmt|;
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_BOGUS
expr_stmt|;
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_COUNT
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * VM exits that could be triggered during event injection on the 	 * previous VM entry need to be handled specially by re-injecting 	 * the event. 	 * 	 * See "Information for VM Exits During Event Delivery" in Intel SDM 	 * for details. 	 */
switch|switch
condition|(
name|reason
condition|)
block|{
case|case
name|EXIT_REASON_EPT_FAULT
case|:
case|case
name|EXIT_REASON_EPT_MISCONFIG
case|:
case|case
name|EXIT_REASON_APIC_ACCESS
case|:
case|case
name|EXIT_REASON_TASK_SWITCH
case|:
case|case
name|EXIT_REASON_EXCEPTION
case|:
name|idtvec_info
operator|=
name|vmcs_idt_vectoring_info
argument_list|()
expr_stmt|;
if|if
condition|(
name|idtvec_info
operator|&
name|VMCS_IDT_VEC_VALID
condition|)
block|{
name|idtvec_info
operator|&=
operator|~
operator|(
literal|1
operator|<<
literal|12
operator|)
expr_stmt|;
comment|/* clear undefined bit */
name|vmcs_write
argument_list|(
name|VMCS_ENTRY_INTR_INFO
argument_list|,
name|idtvec_info
argument_list|)
expr_stmt|;
if|if
condition|(
name|idtvec_info
operator|&
name|VMCS_IDT_VEC_ERRCODE_VALID
condition|)
block|{
name|idtvec_err
operator|=
name|vmcs_idt_vectoring_err
argument_list|()
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_ENTRY_EXCEPTION_ERROR
argument_list|,
name|idtvec_err
argument_list|)
expr_stmt|;
block|}
comment|/* 			 * If 'virtual NMIs' are being used and the VM-exit 			 * happened while injecting an NMI during the previous 			 * VM-entry, then clear "blocking by NMI" in the Guest 			 * Interruptibility-state. 			 */
if|if
condition|(
operator|(
name|idtvec_info
operator|&
name|VMCS_INTR_T_MASK
operator|)
operator|==
name|VMCS_INTR_T_NMI
condition|)
block|{
name|vmx_clear_nmi_blocking
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
block|}
name|vmcs_write
argument_list|(
name|VMCS_ENTRY_INST_LENGTH
argument_list|,
name|vmexit
operator|->
name|inst_length
argument_list|)
expr_stmt|;
block|}
default|default:
name|idtvec_info
operator|=
literal|0
expr_stmt|;
break|break;
block|}
switch|switch
condition|(
name|reason
condition|)
block|{
case|case
name|EXIT_REASON_CR_ACCESS
case|:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_CR_ACCESS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|handled
operator|=
name|vmx_emulate_cr_access
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|qual
argument_list|)
expr_stmt|;
break|break;
case|case
name|EXIT_REASON_RDMSR
case|:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_RDMSR
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|retu
operator|=
name|false
expr_stmt|;
name|ecx
operator|=
name|vmxctx
operator|->
name|guest_rcx
expr_stmt|;
name|error
operator|=
name|emulate_rdmsr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|ecx
argument_list|,
operator|&
name|retu
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_RDMSR
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|msr
operator|.
name|code
operator|=
name|ecx
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|retu
condition|)
block|{
name|handled
operator|=
name|HANDLED
expr_stmt|;
block|}
else|else
block|{
comment|/* Return to userspace with a valid exitcode */
name|KASSERT
argument_list|(
name|vmexit
operator|->
name|exitcode
operator|!=
name|VM_EXITCODE_BOGUS
argument_list|,
operator|(
literal|"emulate_wrmsr retu with bogus exitcode"
operator|)
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|EXIT_REASON_WRMSR
case|:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_WRMSR
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|retu
operator|=
name|false
expr_stmt|;
name|eax
operator|=
name|vmxctx
operator|->
name|guest_rax
expr_stmt|;
name|ecx
operator|=
name|vmxctx
operator|->
name|guest_rcx
expr_stmt|;
name|edx
operator|=
name|vmxctx
operator|->
name|guest_rdx
expr_stmt|;
name|error
operator|=
name|emulate_wrmsr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|ecx
argument_list|,
operator|(
name|uint64_t
operator|)
name|edx
operator|<<
literal|32
operator||
name|eax
argument_list|,
operator|&
name|retu
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_WRMSR
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|msr
operator|.
name|code
operator|=
name|ecx
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|msr
operator|.
name|wval
operator|=
operator|(
name|uint64_t
operator|)
name|edx
operator|<<
literal|32
operator||
name|eax
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|retu
condition|)
block|{
name|handled
operator|=
name|HANDLED
expr_stmt|;
block|}
else|else
block|{
comment|/* Return to userspace with a valid exitcode */
name|KASSERT
argument_list|(
name|vmexit
operator|->
name|exitcode
operator|!=
name|VM_EXITCODE_BOGUS
argument_list|,
operator|(
literal|"emulate_wrmsr retu with bogus exitcode"
operator|)
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|EXIT_REASON_HLT
case|:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_HLT
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_HLT
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|hlt
operator|.
name|rflags
operator|=
name|vmcs_read
argument_list|(
name|VMCS_GUEST_RFLAGS
argument_list|)
expr_stmt|;
break|break;
case|case
name|EXIT_REASON_MTF
case|:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_MTRAP
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_MTRAP
expr_stmt|;
break|break;
case|case
name|EXIT_REASON_PAUSE
case|:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_PAUSE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_PAUSE
expr_stmt|;
break|break;
case|case
name|EXIT_REASON_INTR_WINDOW
case|:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_INTR_WINDOW
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vmx_clear_int_window_exiting
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
case|case
name|EXIT_REASON_EXT_INTR
case|:
comment|/* 		 * External interrupts serve only to cause VM exits and allow 		 * the host interrupt handler to run. 		 * 		 * If this external interrupt triggers a virtual interrupt 		 * to a VM, then that state will be recorded by the 		 * host interrupt handler in the VM's softc. We will inject 		 * this virtual interrupt during the subsequent VM enter. 		 */
name|intr_info
operator|=
name|vmcs_read
argument_list|(
name|VMCS_EXIT_INTR_INFO
argument_list|)
expr_stmt|;
comment|/* 		 * XXX: Ignore this exit if VMCS_INTR_VALID is not set. 		 * This appears to be a bug in VMware Fusion? 		 */
if|if
condition|(
operator|!
operator|(
name|intr_info
operator|&
name|VMCS_INTR_VALID
operator|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|KASSERT
argument_list|(
operator|(
name|intr_info
operator|&
name|VMCS_INTR_VALID
operator|)
operator|!=
literal|0
operator|&&
operator|(
name|intr_info
operator|&
name|VMCS_INTR_T_MASK
operator|)
operator|==
name|VMCS_INTR_T_HWINTR
argument_list|,
operator|(
literal|"VM exit interruption info invalid: %#x"
operator|,
name|intr_info
operator|)
argument_list|)
expr_stmt|;
name|vmx_trigger_hostintr
argument_list|(
name|intr_info
operator|&
literal|0xff
argument_list|)
expr_stmt|;
comment|/* 		 * This is special. We want to treat this as an 'handled' 		 * VM-exit but not increment the instruction pointer. 		 */
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_EXTINT
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
case|case
name|EXIT_REASON_NMI_WINDOW
case|:
comment|/* Exit to allow the pending virtual NMI to be injected */
if|if
condition|(
name|vm_nmi_pending
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
condition|)
name|vmx_inject_nmi
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
name|vmx_clear_nmi_window_exiting
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_NMI_WINDOW
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
case|case
name|EXIT_REASON_INOUT
case|:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_INOUT
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_INOUT
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inout
operator|.
name|bytes
operator|=
operator|(
name|qual
operator|&
literal|0x7
operator|)
operator|+
literal|1
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inout
operator|.
name|in
operator|=
operator|(
name|qual
operator|&
literal|0x8
operator|)
condition|?
literal|1
else|:
literal|0
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inout
operator|.
name|string
operator|=
operator|(
name|qual
operator|&
literal|0x10
operator|)
condition|?
literal|1
else|:
literal|0
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inout
operator|.
name|rep
operator|=
operator|(
name|qual
operator|&
literal|0x20
operator|)
condition|?
literal|1
else|:
literal|0
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inout
operator|.
name|port
operator|=
call|(
name|uint16_t
call|)
argument_list|(
name|qual
operator|>>
literal|16
argument_list|)
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inout
operator|.
name|eax
operator|=
call|(
name|uint32_t
call|)
argument_list|(
name|vmxctx
operator|->
name|guest_rax
argument_list|)
expr_stmt|;
name|error
operator|=
name|emulate_ioport
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|vmexit
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|==
literal|0
condition|)
block|{
name|handled
operator|=
literal|1
expr_stmt|;
name|vmxctx
operator|->
name|guest_rax
operator|=
name|vmexit
operator|->
name|u
operator|.
name|inout
operator|.
name|eax
expr_stmt|;
block|}
break|break;
case|case
name|EXIT_REASON_CPUID
case|:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_CPUID
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|handled
operator|=
name|vmx_handle_cpuid
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|vmxctx
argument_list|)
expr_stmt|;
break|break;
case|case
name|EXIT_REASON_EXCEPTION
case|:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_EXCEPTION
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|intr_info
operator|=
name|vmcs_read
argument_list|(
name|VMCS_EXIT_INTR_INFO
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|intr_info
operator|&
name|VMCS_INTR_VALID
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"VM exit interruption info invalid: %#x"
operator|,
name|intr_info
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * If Virtual NMIs control is 1 and the VM-exit is due to a 		 * fault encountered during the execution of IRET then we must 		 * restore the state of "virtual-NMI blocking" before resuming 		 * the guest. 		 * 		 * See "Resuming Guest Software after Handling an Exception". 		 */
if|if
condition|(
operator|(
name|idtvec_info
operator|&
name|VMCS_IDT_VEC_VALID
operator|)
operator|==
literal|0
operator|&&
operator|(
name|intr_info
operator|&
literal|0xff
operator|)
operator|!=
name|IDT_DF
operator|&&
operator|(
name|intr_info
operator|&
name|EXIT_QUAL_NMIUDTI
operator|)
operator|!=
literal|0
condition|)
name|vmx_restore_nmi_blocking
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
comment|/* 		 * The NMI has already been handled in vmx_exit_handle_nmi(). 		 */
if|if
condition|(
operator|(
name|intr_info
operator|&
name|VMCS_INTR_T_MASK
operator|)
operator|==
name|VMCS_INTR_T_NMI
condition|)
return|return
operator|(
literal|1
operator|)
return|;
break|break;
case|case
name|EXIT_REASON_EPT_FAULT
case|:
comment|/* 		 * If 'gpa' lies within the address space allocated to 		 * memory then this must be a nested page fault otherwise 		 * this must be an instruction that accesses MMIO space. 		 */
name|gpa
operator|=
name|vmcs_gpa
argument_list|()
expr_stmt|;
if|if
condition|(
name|vm_mem_allocated
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|gpa
argument_list|)
operator|||
name|apic_access_fault
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|gpa
argument_list|)
condition|)
block|{
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_PAGING
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|paging
operator|.
name|gpa
operator|=
name|gpa
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|paging
operator|.
name|fault_type
operator|=
name|ept_fault_type
argument_list|(
name|qual
argument_list|)
expr_stmt|;
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_NESTED_FAULT
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ept_emulation_fault
argument_list|(
name|qual
argument_list|)
condition|)
block|{
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_INST_EMUL
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inst_emul
operator|.
name|gpa
operator|=
name|gpa
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inst_emul
operator|.
name|gla
operator|=
name|vmcs_gla
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inst_emul
operator|.
name|cr3
operator|=
name|vmcs_guest_cr3
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inst_emul
operator|.
name|cpu_mode
operator|=
name|vmx_cpu_mode
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|inst_emul
operator|.
name|paging_mode
operator|=
name|vmx_paging_mode
argument_list|()
expr_stmt|;
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_INST_EMUL
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * If Virtual NMIs control is 1 and the VM-exit is due to an 		 * EPT fault during the execution of IRET then we must restore 		 * the state of "virtual-NMI blocking" before resuming. 		 * 		 * See description of "NMI unblocking due to IRET" in 		 * "Exit Qualification for EPT Violations". 		 */
if|if
condition|(
operator|(
name|idtvec_info
operator|&
name|VMCS_IDT_VEC_VALID
operator|)
operator|==
literal|0
operator|&&
operator|(
name|qual
operator|&
name|EXIT_QUAL_NMIUDTI
operator|)
operator|!=
literal|0
condition|)
name|vmx_restore_nmi_blocking
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
break|break;
case|case
name|EXIT_REASON_VIRTUALIZED_EOI
case|:
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_IOAPIC_EOI
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|ioapic_eoi
operator|.
name|vector
operator|=
name|qual
operator|&
literal|0xFF
expr_stmt|;
name|vmexit
operator|->
name|inst_length
operator|=
literal|0
expr_stmt|;
comment|/* trap-like */
break|break;
case|case
name|EXIT_REASON_APIC_ACCESS
case|:
name|handled
operator|=
name|vmx_handle_apic_access
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|vmexit
argument_list|)
expr_stmt|;
break|break;
case|case
name|EXIT_REASON_APIC_WRITE
case|:
comment|/* 		 * APIC-write VM exit is trap-like so the %rip is already 		 * pointing to the next instruction. 		 */
name|vmexit
operator|->
name|inst_length
operator|=
literal|0
expr_stmt|;
name|vlapic
operator|=
name|vm_lapic
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
name|handled
operator|=
name|vmx_handle_apic_write
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|vlapic
argument_list|,
name|qual
argument_list|)
expr_stmt|;
break|break;
case|case
name|EXIT_REASON_XSETBV
case|:
name|handled
operator|=
name|vmx_emulate_xsetbv
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|vmexit
argument_list|)
expr_stmt|;
break|break;
default|default:
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_UNKNOWN
argument_list|,
literal|1
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|handled
condition|)
block|{
comment|/* 		 * It is possible that control is returned to userland 		 * even though we were able to handle the VM exit in the 		 * kernel. 		 * 		 * In such a case we want to make sure that the userland 		 * restarts guest execution at the instruction *after* 		 * the one we just processed. Therefore we update the 		 * guest rip in the VMCS and in 'vmexit'. 		 */
name|vmexit
operator|->
name|rip
operator|+=
name|vmexit
operator|->
name|inst_length
expr_stmt|;
name|vmexit
operator|->
name|inst_length
operator|=
literal|0
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_GUEST_RIP
argument_list|,
name|vmexit
operator|->
name|rip
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|vmexit
operator|->
name|exitcode
operator|==
name|VM_EXITCODE_BOGUS
condition|)
block|{
comment|/* 			 * If this VM exit was not claimed by anybody then 			 * treat it as a generic VMX exit. 			 */
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_VMX
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|status
operator|=
name|VM_SUCCESS
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|inst_type
operator|=
literal|0
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|inst_error
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * The exitcode and collateral have been populated. 			 * The VM exit will be processed further in userland. 			 */
block|}
block|}
return|return
operator|(
name|handled
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|vmx_exit_astpending
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|struct
name|vm_exit
modifier|*
name|vmexit
parameter_list|)
block|{
name|vmexit
operator|->
name|rip
operator|=
name|vmcs_guest_rip
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|inst_length
operator|=
literal|0
expr_stmt|;
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_BOGUS
expr_stmt|;
name|vmx_astpending_trace
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|vmexit
operator|->
name|rip
argument_list|)
expr_stmt|;
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_ASTPENDING
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|HANDLED
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|vmx_exit_rendezvous
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|struct
name|vm_exit
modifier|*
name|vmexit
parameter_list|)
block|{
name|vmexit
operator|->
name|rip
operator|=
name|vmcs_guest_rip
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|inst_length
operator|=
literal|0
expr_stmt|;
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_RENDEZVOUS
expr_stmt|;
name|vmm_stat_incr
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_RENDEZVOUS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|UNHANDLED
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|vmx_exit_inst_error
parameter_list|(
name|struct
name|vmxctx
modifier|*
name|vmxctx
parameter_list|,
name|int
name|rc
parameter_list|,
name|struct
name|vm_exit
modifier|*
name|vmexit
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|vmxctx
operator|->
name|inst_fail_status
operator|!=
name|VM_SUCCESS
argument_list|,
operator|(
literal|"vmx_exit_inst_error: invalid inst_fail_status %d"
operator|,
name|vmxctx
operator|->
name|inst_fail_status
operator|)
argument_list|)
expr_stmt|;
name|vmexit
operator|->
name|inst_length
operator|=
literal|0
expr_stmt|;
name|vmexit
operator|->
name|exitcode
operator|=
name|VM_EXITCODE_VMX
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|status
operator|=
name|vmxctx
operator|->
name|inst_fail_status
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|inst_error
operator|=
name|vmcs_instruction_error
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|exit_reason
operator|=
operator|~
literal|0
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|exit_qualification
operator|=
operator|~
literal|0
expr_stmt|;
switch|switch
condition|(
name|rc
condition|)
block|{
case|case
name|VMX_VMRESUME_ERROR
case|:
case|case
name|VMX_VMLAUNCH_ERROR
case|:
case|case
name|VMX_INVEPT_ERROR
case|:
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|inst_type
operator|=
name|rc
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"vm_exit_inst_error: vmx_enter_guest returned %d"
argument_list|,
name|rc
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|UNHANDLED
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * If the NMI-exiting VM execution control is set to '1' then an NMI in  * non-root operation causes a VM-exit. NMI blocking is in effect so it is  * sufficient to simply vector to the NMI handler via a software interrupt.  * However, this must be done before maskable interrupts are enabled  * otherwise the "iret" issued by an interrupt handler will incorrectly  * clear NMI blocking.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|vmx_exit_handle_nmi
parameter_list|(
name|struct
name|vmx
modifier|*
name|vmx
parameter_list|,
name|int
name|vcpuid
parameter_list|,
name|struct
name|vm_exit
modifier|*
name|vmexit
parameter_list|)
block|{
name|uint32_t
name|intr_info
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|read_rflags
argument_list|()
operator|&
name|PSL_I
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"interrupts enabled"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|exit_reason
operator|!=
name|EXIT_REASON_EXCEPTION
condition|)
return|return;
name|intr_info
operator|=
name|vmcs_read
argument_list|(
name|VMCS_EXIT_INTR_INFO
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|intr_info
operator|&
name|VMCS_INTR_VALID
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"VM exit interruption info invalid: %#x"
operator|,
name|intr_info
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|intr_info
operator|&
name|VMCS_INTR_T_MASK
operator|)
operator|==
name|VMCS_INTR_T_NMI
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|intr_info
operator|&
literal|0xff
operator|)
operator|==
name|IDT_NMI
argument_list|,
operator|(
literal|"VM exit due "
literal|"to NMI has invalid vector: %#x"
operator|,
name|intr_info
operator|)
argument_list|)
expr_stmt|;
name|VCPU_CTR0
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpuid
argument_list|,
literal|"Vectoring to NMI handler"
argument_list|)
expr_stmt|;
asm|__asm __volatile("int $2");
block|}
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_run
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|register_t
name|startrip
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|void
modifier|*
name|rendezvous_cookie
parameter_list|,
name|void
modifier|*
name|suspend_cookie
parameter_list|)
block|{
name|int
name|rc
decl_stmt|,
name|handled
decl_stmt|,
name|launched
decl_stmt|;
name|struct
name|vmx
modifier|*
name|vmx
decl_stmt|;
name|struct
name|vm
modifier|*
name|vm
decl_stmt|;
name|struct
name|vmxctx
modifier|*
name|vmxctx
decl_stmt|;
name|struct
name|vmcs
modifier|*
name|vmcs
decl_stmt|;
name|struct
name|vm_exit
modifier|*
name|vmexit
decl_stmt|;
name|struct
name|vlapic
modifier|*
name|vlapic
decl_stmt|;
name|uint64_t
name|rip
decl_stmt|;
name|uint32_t
name|exit_reason
decl_stmt|;
name|vmx
operator|=
name|arg
expr_stmt|;
name|vm
operator|=
name|vmx
operator|->
name|vm
expr_stmt|;
name|vmcs
operator|=
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vcpu
index|]
expr_stmt|;
name|vmxctx
operator|=
operator|&
name|vmx
operator|->
name|ctx
index|[
name|vcpu
index|]
expr_stmt|;
name|vlapic
operator|=
name|vm_lapic
argument_list|(
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
name|vmexit
operator|=
name|vm_exitinfo
argument_list|(
name|vm
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
name|launched
operator|=
literal|0
expr_stmt|;
name|KASSERT
argument_list|(
name|vmxctx
operator|->
name|pmap
operator|==
name|pmap
argument_list|,
operator|(
literal|"pmap %p different than ctx pmap %p"
operator|,
name|pmap
operator|,
name|vmxctx
operator|->
name|pmap
operator|)
argument_list|)
expr_stmt|;
name|VMPTRLD
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
comment|/* 	 * XXX 	 * We do this every time because we may setup the virtual machine 	 * from a different process than the one that actually runs it. 	 * 	 * If the life of a virtual machine was spent entirely in the context 	 * of a single process we could do this once in vmx_vminit(). 	 */
name|vmcs_write
argument_list|(
name|VMCS_HOST_CR3
argument_list|,
name|rcr3
argument_list|()
argument_list|)
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_GUEST_RIP
argument_list|,
name|startrip
argument_list|)
expr_stmt|;
name|vmx_set_pcpu_defaults
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
do|do
block|{
comment|/* 		 * Interrupts are disabled from this point on until the 		 * guest starts executing. This is done for the following 		 * reasons: 		 * 		 * If an AST is asserted on this thread after the check below, 		 * then the IPI_AST notification will not be lost, because it 		 * will cause a VM exit due to external interrupt as soon as 		 * the guest state is loaded. 		 * 		 * A posted interrupt after 'vmx_inject_interrupts()' will 		 * not be "lost" because it will be held pending in the host 		 * APIC because interrupts are disabled. The pending interrupt 		 * will be recognized as soon as the guest state is loaded. 		 * 		 * The same reasoning applies to the IPI generated by 		 * pmap_invalidate_ept(). 		 */
name|disable_intr
argument_list|()
expr_stmt|;
if|if
condition|(
name|vcpu_suspended
argument_list|(
name|suspend_cookie
argument_list|)
condition|)
block|{
name|enable_intr
argument_list|()
expr_stmt|;
name|vm_exit_suspended
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
name|vmcs_guest_rip
argument_list|()
argument_list|)
expr_stmt|;
name|handled
operator|=
name|UNHANDLED
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|vcpu_rendezvous_pending
argument_list|(
name|rendezvous_cookie
argument_list|)
condition|)
block|{
name|enable_intr
argument_list|()
expr_stmt|;
name|handled
operator|=
name|vmx_exit_rendezvous
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|vmexit
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|curthread
operator|->
name|td_flags
operator|&
operator|(
name|TDF_ASTPENDING
operator||
name|TDF_NEEDRESCHED
operator|)
condition|)
block|{
name|enable_intr
argument_list|()
expr_stmt|;
name|handled
operator|=
name|vmx_exit_astpending
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|vmexit
argument_list|)
expr_stmt|;
break|break;
block|}
name|vmx_inject_interrupts
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|vlapic
argument_list|)
expr_stmt|;
name|vmx_run_trace
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
name|rc
operator|=
name|vmx_enter_guest
argument_list|(
name|vmxctx
argument_list|,
name|vmx
argument_list|,
name|launched
argument_list|)
expr_stmt|;
comment|/* Collect some information for VM exit processing */
name|vmexit
operator|->
name|rip
operator|=
name|rip
operator|=
name|vmcs_guest_rip
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|inst_length
operator|=
name|vmexit_instruction_length
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|exit_reason
operator|=
name|exit_reason
operator|=
name|vmcs_exit_reason
argument_list|()
expr_stmt|;
name|vmexit
operator|->
name|u
operator|.
name|vmx
operator|.
name|exit_qualification
operator|=
name|vmcs_exit_qualification
argument_list|()
expr_stmt|;
if|if
condition|(
name|rc
operator|==
name|VMX_GUEST_VMEXIT
condition|)
block|{
name|vmx_exit_handle_nmi
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|vmexit
argument_list|)
expr_stmt|;
name|enable_intr
argument_list|()
expr_stmt|;
name|handled
operator|=
name|vmx_exit_process
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|vmexit
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|enable_intr
argument_list|()
expr_stmt|;
name|handled
operator|=
name|vmx_exit_inst_error
argument_list|(
name|vmxctx
argument_list|,
name|rc
argument_list|,
name|vmexit
argument_list|)
expr_stmt|;
block|}
name|launched
operator|=
literal|1
expr_stmt|;
name|vmx_exit_trace
argument_list|(
name|vmx
argument_list|,
name|vcpu
argument_list|,
name|rip
argument_list|,
name|exit_reason
argument_list|,
name|handled
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|handled
condition|)
do|;
comment|/* 	 * If a VM exit has been handled then the exitcode must be BOGUS 	 * If a VM exit is not handled then the exitcode must not be BOGUS 	 */
if|if
condition|(
operator|(
name|handled
operator|&&
name|vmexit
operator|->
name|exitcode
operator|!=
name|VM_EXITCODE_BOGUS
operator|)
operator|||
operator|(
operator|!
name|handled
operator|&&
name|vmexit
operator|->
name|exitcode
operator|==
name|VM_EXITCODE_BOGUS
operator|)
condition|)
block|{
name|panic
argument_list|(
literal|"Mismatch between handled (%d) and exitcode (%d)"
argument_list|,
name|handled
argument_list|,
name|vmexit
operator|->
name|exitcode
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|handled
condition|)
name|vmm_stat_incr
argument_list|(
name|vm
argument_list|,
name|vcpu
argument_list|,
name|VMEXIT_USERSPACE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|VCPU_CTR1
argument_list|(
name|vm
argument_list|,
name|vcpu
argument_list|,
literal|"returning from vmx_run: exitcode %d"
argument_list|,
name|vmexit
operator|->
name|exitcode
argument_list|)
expr_stmt|;
name|VMCLEAR
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_vmcleanup
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|struct
name|vmx
modifier|*
name|vmx
init|=
name|arg
decl_stmt|;
if|if
condition|(
name|apic_access_virtualization
argument_list|(
name|vmx
argument_list|,
literal|0
argument_list|)
condition|)
name|vm_unmap_mmio
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|DEFAULT_APIC_BASE
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|VM_MAXCPU
condition|;
name|i
operator|++
control|)
name|vpid_free
argument_list|(
name|vmx
operator|->
name|state
index|[
name|i
index|]
operator|.
name|vpid
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|vmx
argument_list|,
name|M_VMX
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_function
specifier|static
name|register_t
modifier|*
name|vmxctx_regptr
parameter_list|(
name|struct
name|vmxctx
modifier|*
name|vmxctx
parameter_list|,
name|int
name|reg
parameter_list|)
block|{
switch|switch
condition|(
name|reg
condition|)
block|{
case|case
name|VM_REG_GUEST_RAX
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rax
operator|)
return|;
case|case
name|VM_REG_GUEST_RBX
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rbx
operator|)
return|;
case|case
name|VM_REG_GUEST_RCX
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rcx
operator|)
return|;
case|case
name|VM_REG_GUEST_RDX
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rdx
operator|)
return|;
case|case
name|VM_REG_GUEST_RSI
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rsi
operator|)
return|;
case|case
name|VM_REG_GUEST_RDI
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rdi
operator|)
return|;
case|case
name|VM_REG_GUEST_RBP
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_rbp
operator|)
return|;
case|case
name|VM_REG_GUEST_R8
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_r8
operator|)
return|;
case|case
name|VM_REG_GUEST_R9
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_r9
operator|)
return|;
case|case
name|VM_REG_GUEST_R10
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_r10
operator|)
return|;
case|case
name|VM_REG_GUEST_R11
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_r11
operator|)
return|;
case|case
name|VM_REG_GUEST_R12
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_r12
operator|)
return|;
case|case
name|VM_REG_GUEST_R13
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_r13
operator|)
return|;
case|case
name|VM_REG_GUEST_R14
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_r14
operator|)
return|;
case|case
name|VM_REG_GUEST_R15
case|:
return|return
operator|(
operator|&
name|vmxctx
operator|->
name|guest_r15
operator|)
return|;
default|default:
break|break;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmxctx_getreg
parameter_list|(
name|struct
name|vmxctx
modifier|*
name|vmxctx
parameter_list|,
name|int
name|reg
parameter_list|,
name|uint64_t
modifier|*
name|retval
parameter_list|)
block|{
name|register_t
modifier|*
name|regp
decl_stmt|;
if|if
condition|(
operator|(
name|regp
operator|=
name|vmxctx_regptr
argument_list|(
name|vmxctx
argument_list|,
name|reg
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
operator|*
name|retval
operator|=
operator|*
name|regp
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
else|else
return|return
operator|(
name|EINVAL
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmxctx_setreg
parameter_list|(
name|struct
name|vmxctx
modifier|*
name|vmxctx
parameter_list|,
name|int
name|reg
parameter_list|,
name|uint64_t
name|val
parameter_list|)
block|{
name|register_t
modifier|*
name|regp
decl_stmt|;
if|if
condition|(
operator|(
name|regp
operator|=
name|vmxctx_regptr
argument_list|(
name|vmxctx
argument_list|,
name|reg
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
operator|*
name|regp
operator|=
name|val
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
else|else
return|return
operator|(
name|EINVAL
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_shadow_reg
parameter_list|(
name|int
name|reg
parameter_list|)
block|{
name|int
name|shreg
decl_stmt|;
name|shreg
operator|=
operator|-
literal|1
expr_stmt|;
switch|switch
condition|(
name|reg
condition|)
block|{
case|case
name|VM_REG_GUEST_CR0
case|:
name|shreg
operator|=
name|VMCS_CR0_SHADOW
expr_stmt|;
break|break;
case|case
name|VM_REG_GUEST_CR4
case|:
name|shreg
operator|=
name|VMCS_CR4_SHADOW
expr_stmt|;
break|break;
default|default:
break|break;
block|}
return|return
operator|(
name|shreg
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_getreg
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|int
name|reg
parameter_list|,
name|uint64_t
modifier|*
name|retval
parameter_list|)
block|{
name|int
name|running
decl_stmt|,
name|hostcpu
decl_stmt|;
name|struct
name|vmx
modifier|*
name|vmx
init|=
name|arg
decl_stmt|;
name|running
operator|=
name|vcpu_is_running
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
operator|&
name|hostcpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|running
operator|&&
name|hostcpu
operator|!=
name|curcpu
condition|)
name|panic
argument_list|(
literal|"vmx_getreg: %s%d is running"
argument_list|,
name|vm_name
argument_list|(
name|vmx
operator|->
name|vm
argument_list|)
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|vmxctx_getreg
argument_list|(
operator|&
name|vmx
operator|->
name|ctx
index|[
name|vcpu
index|]
argument_list|,
name|reg
argument_list|,
name|retval
argument_list|)
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
return|return
operator|(
name|vmcs_getreg
argument_list|(
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vcpu
index|]
argument_list|,
name|running
argument_list|,
name|reg
argument_list|,
name|retval
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_setreg
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|int
name|reg
parameter_list|,
name|uint64_t
name|val
parameter_list|)
block|{
name|int
name|error
decl_stmt|,
name|hostcpu
decl_stmt|,
name|running
decl_stmt|,
name|shadow
decl_stmt|;
name|uint64_t
name|ctls
decl_stmt|;
name|struct
name|vmx
modifier|*
name|vmx
init|=
name|arg
decl_stmt|;
name|running
operator|=
name|vcpu_is_running
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|vcpu
argument_list|,
operator|&
name|hostcpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|running
operator|&&
name|hostcpu
operator|!=
name|curcpu
condition|)
name|panic
argument_list|(
literal|"vmx_setreg: %s%d is running"
argument_list|,
name|vm_name
argument_list|(
name|vmx
operator|->
name|vm
argument_list|)
argument_list|,
name|vcpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|vmxctx_setreg
argument_list|(
operator|&
name|vmx
operator|->
name|ctx
index|[
name|vcpu
index|]
argument_list|,
name|reg
argument_list|,
name|val
argument_list|)
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|error
operator|=
name|vmcs_setreg
argument_list|(
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vcpu
index|]
argument_list|,
name|running
argument_list|,
name|reg
argument_list|,
name|val
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|==
literal|0
condition|)
block|{
comment|/* 		 * If the "load EFER" VM-entry control is 1 then the 		 * value of EFER.LMA must be identical to "IA-32e mode guest" 		 * bit in the VM-entry control. 		 */
if|if
condition|(
operator|(
name|entry_ctls
operator|&
name|VM_ENTRY_LOAD_EFER
operator|)
operator|!=
literal|0
operator|&&
operator|(
name|reg
operator|==
name|VM_REG_GUEST_EFER
operator|)
condition|)
block|{
name|vmcs_getreg
argument_list|(
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vcpu
index|]
argument_list|,
name|running
argument_list|,
name|VMCS_IDENT
argument_list|(
name|VMCS_ENTRY_CTLS
argument_list|)
argument_list|,
operator|&
name|ctls
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|&
name|EFER_LMA
condition|)
name|ctls
operator||=
name|VM_ENTRY_GUEST_LMA
expr_stmt|;
else|else
name|ctls
operator|&=
operator|~
name|VM_ENTRY_GUEST_LMA
expr_stmt|;
name|vmcs_setreg
argument_list|(
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vcpu
index|]
argument_list|,
name|running
argument_list|,
name|VMCS_IDENT
argument_list|(
name|VMCS_ENTRY_CTLS
argument_list|)
argument_list|,
name|ctls
argument_list|)
expr_stmt|;
block|}
name|shadow
operator|=
name|vmx_shadow_reg
argument_list|(
name|reg
argument_list|)
expr_stmt|;
if|if
condition|(
name|shadow
operator|>
literal|0
condition|)
block|{
comment|/* 			 * Store the unmodified value in the shadow 			 */
name|error
operator|=
name|vmcs_setreg
argument_list|(
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vcpu
index|]
argument_list|,
name|running
argument_list|,
name|VMCS_IDENT
argument_list|(
name|shadow
argument_list|)
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_getdesc
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|int
name|reg
parameter_list|,
name|struct
name|seg_desc
modifier|*
name|desc
parameter_list|)
block|{
name|struct
name|vmx
modifier|*
name|vmx
init|=
name|arg
decl_stmt|;
return|return
operator|(
name|vmcs_getdesc
argument_list|(
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vcpu
index|]
argument_list|,
name|reg
argument_list|,
name|desc
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_setdesc
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|int
name|reg
parameter_list|,
name|struct
name|seg_desc
modifier|*
name|desc
parameter_list|)
block|{
name|struct
name|vmx
modifier|*
name|vmx
init|=
name|arg
decl_stmt|;
return|return
operator|(
name|vmcs_setdesc
argument_list|(
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vcpu
index|]
argument_list|,
name|reg
argument_list|,
name|desc
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_getcap
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|int
name|type
parameter_list|,
name|int
modifier|*
name|retval
parameter_list|)
block|{
name|struct
name|vmx
modifier|*
name|vmx
init|=
name|arg
decl_stmt|;
name|int
name|vcap
decl_stmt|;
name|int
name|ret
decl_stmt|;
name|ret
operator|=
name|ENOENT
expr_stmt|;
name|vcap
operator|=
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|set
expr_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|VM_CAP_HALT_EXIT
case|:
if|if
condition|(
name|cap_halt_exit
condition|)
name|ret
operator|=
literal|0
expr_stmt|;
break|break;
case|case
name|VM_CAP_PAUSE_EXIT
case|:
if|if
condition|(
name|cap_pause_exit
condition|)
name|ret
operator|=
literal|0
expr_stmt|;
break|break;
case|case
name|VM_CAP_MTRAP_EXIT
case|:
if|if
condition|(
name|cap_monitor_trap
condition|)
name|ret
operator|=
literal|0
expr_stmt|;
break|break;
case|case
name|VM_CAP_UNRESTRICTED_GUEST
case|:
if|if
condition|(
name|cap_unrestricted_guest
condition|)
name|ret
operator|=
literal|0
expr_stmt|;
break|break;
case|case
name|VM_CAP_ENABLE_INVPCID
case|:
if|if
condition|(
name|cap_invpcid
condition|)
name|ret
operator|=
literal|0
expr_stmt|;
break|break;
default|default:
break|break;
block|}
if|if
condition|(
name|ret
operator|==
literal|0
condition|)
operator|*
name|retval
operator|=
operator|(
name|vcap
operator|&
operator|(
literal|1
operator|<<
name|type
operator|)
operator|)
condition|?
literal|1
else|:
literal|0
expr_stmt|;
return|return
operator|(
name|ret
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_setcap
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|int
name|vcpu
parameter_list|,
name|int
name|type
parameter_list|,
name|int
name|val
parameter_list|)
block|{
name|struct
name|vmx
modifier|*
name|vmx
init|=
name|arg
decl_stmt|;
name|struct
name|vmcs
modifier|*
name|vmcs
init|=
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vcpu
index|]
decl_stmt|;
name|uint32_t
name|baseval
decl_stmt|;
name|uint32_t
modifier|*
name|pptr
decl_stmt|;
name|int
name|error
decl_stmt|;
name|int
name|flag
decl_stmt|;
name|int
name|reg
decl_stmt|;
name|int
name|retval
decl_stmt|;
name|retval
operator|=
name|ENOENT
expr_stmt|;
name|pptr
operator|=
name|NULL
expr_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|VM_CAP_HALT_EXIT
case|:
if|if
condition|(
name|cap_halt_exit
condition|)
block|{
name|retval
operator|=
literal|0
expr_stmt|;
name|pptr
operator|=
operator|&
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
expr_stmt|;
name|baseval
operator|=
operator|*
name|pptr
expr_stmt|;
name|flag
operator|=
name|PROCBASED_HLT_EXITING
expr_stmt|;
name|reg
operator|=
name|VMCS_PRI_PROC_BASED_CTLS
expr_stmt|;
block|}
break|break;
case|case
name|VM_CAP_MTRAP_EXIT
case|:
if|if
condition|(
name|cap_monitor_trap
condition|)
block|{
name|retval
operator|=
literal|0
expr_stmt|;
name|pptr
operator|=
operator|&
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
expr_stmt|;
name|baseval
operator|=
operator|*
name|pptr
expr_stmt|;
name|flag
operator|=
name|PROCBASED_MTF
expr_stmt|;
name|reg
operator|=
name|VMCS_PRI_PROC_BASED_CTLS
expr_stmt|;
block|}
break|break;
case|case
name|VM_CAP_PAUSE_EXIT
case|:
if|if
condition|(
name|cap_pause_exit
condition|)
block|{
name|retval
operator|=
literal|0
expr_stmt|;
name|pptr
operator|=
operator|&
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls
expr_stmt|;
name|baseval
operator|=
operator|*
name|pptr
expr_stmt|;
name|flag
operator|=
name|PROCBASED_PAUSE_EXITING
expr_stmt|;
name|reg
operator|=
name|VMCS_PRI_PROC_BASED_CTLS
expr_stmt|;
block|}
break|break;
case|case
name|VM_CAP_UNRESTRICTED_GUEST
case|:
if|if
condition|(
name|cap_unrestricted_guest
condition|)
block|{
name|retval
operator|=
literal|0
expr_stmt|;
name|pptr
operator|=
operator|&
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls2
expr_stmt|;
name|baseval
operator|=
operator|*
name|pptr
expr_stmt|;
name|flag
operator|=
name|PROCBASED2_UNRESTRICTED_GUEST
expr_stmt|;
name|reg
operator|=
name|VMCS_SEC_PROC_BASED_CTLS
expr_stmt|;
block|}
break|break;
case|case
name|VM_CAP_ENABLE_INVPCID
case|:
if|if
condition|(
name|cap_invpcid
condition|)
block|{
name|retval
operator|=
literal|0
expr_stmt|;
name|pptr
operator|=
operator|&
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|proc_ctls2
expr_stmt|;
name|baseval
operator|=
operator|*
name|pptr
expr_stmt|;
name|flag
operator|=
name|PROCBASED2_ENABLE_INVPCID
expr_stmt|;
name|reg
operator|=
name|VMCS_SEC_PROC_BASED_CTLS
expr_stmt|;
block|}
break|break;
default|default:
break|break;
block|}
if|if
condition|(
name|retval
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|val
condition|)
block|{
name|baseval
operator||=
name|flag
expr_stmt|;
block|}
else|else
block|{
name|baseval
operator|&=
operator|~
name|flag
expr_stmt|;
block|}
name|VMPTRLD
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
name|error
operator|=
name|vmwrite
argument_list|(
name|reg
argument_list|,
name|baseval
argument_list|)
expr_stmt|;
name|VMCLEAR
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|retval
operator|=
name|error
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * Update optional stored flags, and record 			 * setting 			 */
if|if
condition|(
name|pptr
operator|!=
name|NULL
condition|)
block|{
operator|*
name|pptr
operator|=
name|baseval
expr_stmt|;
block|}
if|if
condition|(
name|val
condition|)
block|{
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|set
operator||=
operator|(
literal|1
operator|<<
name|type
operator|)
expr_stmt|;
block|}
else|else
block|{
name|vmx
operator|->
name|cap
index|[
name|vcpu
index|]
operator|.
name|set
operator|&=
operator|~
operator|(
literal|1
operator|<<
name|type
operator|)
expr_stmt|;
block|}
block|}
block|}
return|return
operator|(
name|retval
operator|)
return|;
block|}
end_function

begin_struct
struct|struct
name|vlapic_vtx
block|{
name|struct
name|vlapic
name|vlapic
decl_stmt|;
name|struct
name|pir_desc
modifier|*
name|pir_desc
decl_stmt|;
name|struct
name|vmx
modifier|*
name|vmx
decl_stmt|;
block|}
struct|;
end_struct

begin_define
define|#
directive|define
name|VMX_CTR_PIR
parameter_list|(
name|vm
parameter_list|,
name|vcpuid
parameter_list|,
name|pir_desc
parameter_list|,
name|notify
parameter_list|,
name|vector
parameter_list|,
name|level
parameter_list|,
name|msg
parameter_list|)
define|\
value|do {									\ 	VCPU_CTR2(vm, vcpuid, msg " assert %s-triggered vector %d",	\ 	    level ? "level" : "edge", vector);				\ 	VCPU_CTR1(vm, vcpuid, msg " pir0 0x%016lx", pir_desc->pir[0]);	\ 	VCPU_CTR1(vm, vcpuid, msg " pir1 0x%016lx", pir_desc->pir[1]);	\ 	VCPU_CTR1(vm, vcpuid, msg " pir2 0x%016lx", pir_desc->pir[2]);	\ 	VCPU_CTR1(vm, vcpuid, msg " pir3 0x%016lx", pir_desc->pir[3]);	\ 	VCPU_CTR1(vm, vcpuid, msg " notify: %s", notify ? "yes" : "no");\ } while (0)
end_define

begin_comment
comment|/*  * vlapic->ops handlers that utilize the APICv hardware assist described in  * Chapter 29 of the Intel SDM.  */
end_comment

begin_function
specifier|static
name|int
name|vmx_set_intr_ready
parameter_list|(
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|,
name|int
name|vector
parameter_list|,
name|bool
name|level
parameter_list|)
block|{
name|struct
name|vlapic_vtx
modifier|*
name|vlapic_vtx
decl_stmt|;
name|struct
name|pir_desc
modifier|*
name|pir_desc
decl_stmt|;
name|uint64_t
name|mask
decl_stmt|;
name|int
name|idx
decl_stmt|,
name|notify
decl_stmt|;
name|vlapic_vtx
operator|=
operator|(
expr|struct
name|vlapic_vtx
operator|*
operator|)
name|vlapic
expr_stmt|;
name|pir_desc
operator|=
name|vlapic_vtx
operator|->
name|pir_desc
expr_stmt|;
comment|/* 	 * Keep track of interrupt requests in the PIR descriptor. This is 	 * because the virtual APIC page pointed to by the VMCS cannot be 	 * modified if the vcpu is running. 	 */
name|idx
operator|=
name|vector
operator|/
literal|64
expr_stmt|;
name|mask
operator|=
literal|1UL
operator|<<
operator|(
name|vector
operator|%
literal|64
operator|)
expr_stmt|;
name|atomic_set_long
argument_list|(
operator|&
name|pir_desc
operator|->
name|pir
index|[
name|idx
index|]
argument_list|,
name|mask
argument_list|)
expr_stmt|;
name|notify
operator|=
name|atomic_cmpset_long
argument_list|(
operator|&
name|pir_desc
operator|->
name|pending
argument_list|,
literal|0
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|VMX_CTR_PIR
argument_list|(
name|vlapic
operator|->
name|vm
argument_list|,
name|vlapic
operator|->
name|vcpuid
argument_list|,
name|pir_desc
argument_list|,
name|notify
argument_list|,
name|vector
argument_list|,
name|level
argument_list|,
literal|"vmx_set_intr_ready"
argument_list|)
expr_stmt|;
return|return
operator|(
name|notify
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vmx_pending_intr
parameter_list|(
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|,
name|int
modifier|*
name|vecptr
parameter_list|)
block|{
name|struct
name|vlapic_vtx
modifier|*
name|vlapic_vtx
decl_stmt|;
name|struct
name|pir_desc
modifier|*
name|pir_desc
decl_stmt|;
name|struct
name|LAPIC
modifier|*
name|lapic
decl_stmt|;
name|uint64_t
name|pending
decl_stmt|,
name|pirval
decl_stmt|;
name|uint32_t
name|ppr
decl_stmt|,
name|vpr
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * This function is only expected to be called from the 'HLT' exit 	 * handler which does not care about the vector that is pending. 	 */
name|KASSERT
argument_list|(
name|vecptr
operator|==
name|NULL
argument_list|,
operator|(
literal|"vmx_pending_intr: vecptr must be NULL"
operator|)
argument_list|)
expr_stmt|;
name|vlapic_vtx
operator|=
operator|(
expr|struct
name|vlapic_vtx
operator|*
operator|)
name|vlapic
expr_stmt|;
name|pir_desc
operator|=
name|vlapic_vtx
operator|->
name|pir_desc
expr_stmt|;
name|pending
operator|=
name|atomic_load_acq_long
argument_list|(
operator|&
name|pir_desc
operator|->
name|pending
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|pending
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* common case */
comment|/* 	 * If there is an interrupt pending then it will be recognized only 	 * if its priority is greater than the processor priority. 	 * 	 * Special case: if the processor priority is zero then any pending 	 * interrupt will be recognized. 	 */
name|lapic
operator|=
name|vlapic
operator|->
name|apic_page
expr_stmt|;
name|ppr
operator|=
name|lapic
operator|->
name|ppr
operator|&
literal|0xf0
expr_stmt|;
if|if
condition|(
name|ppr
operator|==
literal|0
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|VCPU_CTR1
argument_list|(
name|vlapic
operator|->
name|vm
argument_list|,
name|vlapic
operator|->
name|vcpuid
argument_list|,
literal|"HLT with non-zero PPR %d"
argument_list|,
name|lapic
operator|->
name|ppr
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|3
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|pirval
operator|=
name|pir_desc
operator|->
name|pir
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|pirval
operator|!=
literal|0
condition|)
block|{
name|vpr
operator|=
operator|(
name|i
operator|*
literal|64
operator|+
name|flsl
argument_list|(
name|pirval
argument_list|)
operator|-
literal|1
operator|)
operator|&
literal|0xf0
expr_stmt|;
return|return
operator|(
name|vpr
operator|>
name|ppr
operator|)
return|;
block|}
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_intr_accepted
parameter_list|(
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|,
name|int
name|vector
parameter_list|)
block|{
name|panic
argument_list|(
literal|"vmx_intr_accepted: not expected to be called"
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_set_tmr
parameter_list|(
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|,
name|int
name|vector
parameter_list|,
name|bool
name|level
parameter_list|)
block|{
name|struct
name|vlapic_vtx
modifier|*
name|vlapic_vtx
decl_stmt|;
name|struct
name|vmx
modifier|*
name|vmx
decl_stmt|;
name|struct
name|vmcs
modifier|*
name|vmcs
decl_stmt|;
name|uint64_t
name|mask
decl_stmt|,
name|val
decl_stmt|;
name|KASSERT
argument_list|(
name|vector
operator|>=
literal|0
operator|&&
name|vector
operator|<=
literal|255
argument_list|,
operator|(
literal|"invalid vector %d"
operator|,
name|vector
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|vcpu_is_running
argument_list|(
name|vlapic
operator|->
name|vm
argument_list|,
name|vlapic
operator|->
name|vcpuid
argument_list|,
name|NULL
argument_list|)
argument_list|,
operator|(
literal|"vmx_set_tmr: vcpu cannot be running"
operator|)
argument_list|)
expr_stmt|;
name|vlapic_vtx
operator|=
operator|(
expr|struct
name|vlapic_vtx
operator|*
operator|)
name|vlapic
expr_stmt|;
name|vmx
operator|=
name|vlapic_vtx
operator|->
name|vmx
expr_stmt|;
name|vmcs
operator|=
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vlapic
operator|->
name|vcpuid
index|]
expr_stmt|;
name|mask
operator|=
literal|1UL
operator|<<
operator|(
name|vector
operator|%
literal|64
operator|)
expr_stmt|;
name|VMPTRLD
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
name|val
operator|=
name|vmcs_read
argument_list|(
name|VMCS_EOI_EXIT
argument_list|(
name|vector
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|level
condition|)
name|val
operator||=
name|mask
expr_stmt|;
else|else
name|val
operator|&=
operator|~
name|mask
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_EOI_EXIT
argument_list|(
name|vector
argument_list|)
argument_list|,
name|val
argument_list|)
expr_stmt|;
name|VMCLEAR
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_enable_x2apic_mode
parameter_list|(
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|)
block|{
name|struct
name|vmx
modifier|*
name|vmx
decl_stmt|;
name|struct
name|vmcs
modifier|*
name|vmcs
decl_stmt|;
name|uint32_t
name|proc_ctls2
decl_stmt|;
name|int
name|vcpuid
decl_stmt|,
name|error
decl_stmt|;
name|vcpuid
operator|=
name|vlapic
operator|->
name|vcpuid
expr_stmt|;
name|vmx
operator|=
operator|(
operator|(
expr|struct
name|vlapic_vtx
operator|*
operator|)
name|vlapic
operator|)
operator|->
name|vmx
expr_stmt|;
name|vmcs
operator|=
operator|&
name|vmx
operator|->
name|vmcs
index|[
name|vcpuid
index|]
expr_stmt|;
name|proc_ctls2
operator|=
name|vmx
operator|->
name|cap
index|[
name|vcpuid
index|]
operator|.
name|proc_ctls2
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|proc_ctls2
operator|&
name|PROCBASED2_VIRTUALIZE_APIC_ACCESSES
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"%s: invalid proc_ctls2 %#x"
operator|,
name|__func__
operator|,
name|proc_ctls2
operator|)
argument_list|)
expr_stmt|;
name|proc_ctls2
operator|&=
operator|~
name|PROCBASED2_VIRTUALIZE_APIC_ACCESSES
expr_stmt|;
name|proc_ctls2
operator||=
name|PROCBASED2_VIRTUALIZE_X2APIC_MODE
expr_stmt|;
name|vmx
operator|->
name|cap
index|[
name|vcpuid
index|]
operator|.
name|proc_ctls2
operator|=
name|proc_ctls2
expr_stmt|;
name|VMPTRLD
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
name|vmcs_write
argument_list|(
name|VMCS_SEC_PROC_BASED_CTLS
argument_list|,
name|proc_ctls2
argument_list|)
expr_stmt|;
name|VMCLEAR
argument_list|(
name|vmcs
argument_list|)
expr_stmt|;
if|if
condition|(
name|vlapic
operator|->
name|vcpuid
operator|==
literal|0
condition|)
block|{
comment|/* 		 * The nested page table mappings are shared by all vcpus 		 * so unmap the APIC access page just once. 		 */
name|error
operator|=
name|vm_unmap_mmio
argument_list|(
name|vmx
operator|->
name|vm
argument_list|,
name|DEFAULT_APIC_BASE
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|error
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: vm_unmap_mmio error %d"
operator|,
name|__func__
operator|,
name|error
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * The MSR bitmap is shared by all vcpus so modify it only 		 * once in the context of vcpu 0. 		 */
name|error
operator|=
name|vmx_allow_x2apic_msrs
argument_list|(
name|vmx
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|error
operator|==
literal|0
argument_list|,
operator|(
literal|"%s: vmx_allow_x2apic_msrs error %d"
operator|,
name|__func__
operator|,
name|error
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_post_intr
parameter_list|(
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|,
name|int
name|hostcpu
parameter_list|)
block|{
name|ipi_cpu
argument_list|(
name|hostcpu
argument_list|,
name|pirvec
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Transfer the pending interrupts in the PIR descriptor to the IRR  * in the virtual APIC page.  */
end_comment

begin_function
specifier|static
name|void
name|vmx_inject_pir
parameter_list|(
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|)
block|{
name|struct
name|vlapic_vtx
modifier|*
name|vlapic_vtx
decl_stmt|;
name|struct
name|pir_desc
modifier|*
name|pir_desc
decl_stmt|;
name|struct
name|LAPIC
modifier|*
name|lapic
decl_stmt|;
name|uint64_t
name|val
decl_stmt|,
name|pirval
decl_stmt|;
name|int
name|rvi
decl_stmt|,
name|pirbase
init|=
operator|-
literal|1
decl_stmt|;
name|uint16_t
name|intr_status_old
decl_stmt|,
name|intr_status_new
decl_stmt|;
name|vlapic_vtx
operator|=
operator|(
expr|struct
name|vlapic_vtx
operator|*
operator|)
name|vlapic
expr_stmt|;
name|pir_desc
operator|=
name|vlapic_vtx
operator|->
name|pir_desc
expr_stmt|;
if|if
condition|(
name|atomic_cmpset_long
argument_list|(
operator|&
name|pir_desc
operator|->
name|pending
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|)
operator|==
literal|0
condition|)
block|{
name|VCPU_CTR0
argument_list|(
name|vlapic
operator|->
name|vm
argument_list|,
name|vlapic
operator|->
name|vcpuid
argument_list|,
literal|"vmx_inject_pir: "
literal|"no posted interrupt pending"
argument_list|)
expr_stmt|;
return|return;
block|}
name|pirval
operator|=
literal|0
expr_stmt|;
name|pirbase
operator|=
operator|-
literal|1
expr_stmt|;
name|lapic
operator|=
name|vlapic
operator|->
name|apic_page
expr_stmt|;
name|val
operator|=
name|atomic_readandclear_long
argument_list|(
operator|&
name|pir_desc
operator|->
name|pir
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|!=
literal|0
condition|)
block|{
name|lapic
operator|->
name|irr0
operator||=
name|val
expr_stmt|;
name|lapic
operator|->
name|irr1
operator||=
name|val
operator|>>
literal|32
expr_stmt|;
name|pirbase
operator|=
literal|0
expr_stmt|;
name|pirval
operator|=
name|val
expr_stmt|;
block|}
name|val
operator|=
name|atomic_readandclear_long
argument_list|(
operator|&
name|pir_desc
operator|->
name|pir
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|!=
literal|0
condition|)
block|{
name|lapic
operator|->
name|irr2
operator||=
name|val
expr_stmt|;
name|lapic
operator|->
name|irr3
operator||=
name|val
operator|>>
literal|32
expr_stmt|;
name|pirbase
operator|=
literal|64
expr_stmt|;
name|pirval
operator|=
name|val
expr_stmt|;
block|}
name|val
operator|=
name|atomic_readandclear_long
argument_list|(
operator|&
name|pir_desc
operator|->
name|pir
index|[
literal|2
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|!=
literal|0
condition|)
block|{
name|lapic
operator|->
name|irr4
operator||=
name|val
expr_stmt|;
name|lapic
operator|->
name|irr5
operator||=
name|val
operator|>>
literal|32
expr_stmt|;
name|pirbase
operator|=
literal|128
expr_stmt|;
name|pirval
operator|=
name|val
expr_stmt|;
block|}
name|val
operator|=
name|atomic_readandclear_long
argument_list|(
operator|&
name|pir_desc
operator|->
name|pir
index|[
literal|3
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|val
operator|!=
literal|0
condition|)
block|{
name|lapic
operator|->
name|irr6
operator||=
name|val
expr_stmt|;
name|lapic
operator|->
name|irr7
operator||=
name|val
operator|>>
literal|32
expr_stmt|;
name|pirbase
operator|=
literal|192
expr_stmt|;
name|pirval
operator|=
name|val
expr_stmt|;
block|}
name|VLAPIC_CTR_IRR
argument_list|(
name|vlapic
argument_list|,
literal|"vmx_inject_pir"
argument_list|)
expr_stmt|;
comment|/* 	 * Update RVI so the processor can evaluate pending virtual 	 * interrupts on VM-entry. 	 * 	 * It is possible for pirval to be 0 here, even though the 	 * pending bit has been set. The scenario is: 	 * CPU-Y is sending a posted interrupt to CPU-X, which 	 * is running a guest and processing posted interrupts in h/w. 	 * CPU-X will eventually exit and the state seen in s/w is 	 * the pending bit set, but no PIR bits set. 	 * 	 *      CPU-X                      CPU-Y 	 *   (vm running)                (host running) 	 *   rx posted interrupt 	 *   CLEAR pending bit 	 *				 SET PIR bit 	 *   READ/CLEAR PIR bits 	 *				 SET pending bit 	 *   (vm exit) 	 *   pending bit set, PIR 0 	 */
if|if
condition|(
name|pirval
operator|!=
literal|0
condition|)
block|{
name|rvi
operator|=
name|pirbase
operator|+
name|flsl
argument_list|(
name|pirval
argument_list|)
operator|-
literal|1
expr_stmt|;
name|intr_status_old
operator|=
name|vmcs_read
argument_list|(
name|VMCS_GUEST_INTR_STATUS
argument_list|)
expr_stmt|;
name|intr_status_new
operator|=
operator|(
name|intr_status_old
operator|&
literal|0xFF00
operator|)
operator||
name|rvi
expr_stmt|;
if|if
condition|(
name|intr_status_new
operator|>
name|intr_status_old
condition|)
block|{
name|vmcs_write
argument_list|(
name|VMCS_GUEST_INTR_STATUS
argument_list|,
name|intr_status_new
argument_list|)
expr_stmt|;
name|VCPU_CTR2
argument_list|(
name|vlapic
operator|->
name|vm
argument_list|,
name|vlapic
operator|->
name|vcpuid
argument_list|,
literal|"vmx_inject_pir: "
literal|"guest_intr_status changed from 0x%04x to 0x%04x"
argument_list|,
name|intr_status_old
argument_list|,
name|intr_status_new
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
specifier|static
name|struct
name|vlapic
modifier|*
name|vmx_vlapic_init
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|int
name|vcpuid
parameter_list|)
block|{
name|struct
name|vmx
modifier|*
name|vmx
decl_stmt|;
name|struct
name|vlapic
modifier|*
name|vlapic
decl_stmt|;
name|struct
name|vlapic_vtx
modifier|*
name|vlapic_vtx
decl_stmt|;
name|vmx
operator|=
name|arg
expr_stmt|;
name|vlapic
operator|=
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|vlapic_vtx
argument_list|)
argument_list|,
name|M_VLAPIC
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
name|vlapic
operator|->
name|vm
operator|=
name|vmx
operator|->
name|vm
expr_stmt|;
name|vlapic
operator|->
name|vcpuid
operator|=
name|vcpuid
expr_stmt|;
name|vlapic
operator|->
name|apic_page
operator|=
operator|(
expr|struct
name|LAPIC
operator|*
operator|)
operator|&
name|vmx
operator|->
name|apic_page
index|[
name|vcpuid
index|]
expr_stmt|;
name|vlapic_vtx
operator|=
operator|(
expr|struct
name|vlapic_vtx
operator|*
operator|)
name|vlapic
expr_stmt|;
name|vlapic_vtx
operator|->
name|pir_desc
operator|=
operator|&
name|vmx
operator|->
name|pir_desc
index|[
name|vcpuid
index|]
expr_stmt|;
name|vlapic_vtx
operator|->
name|vmx
operator|=
name|vmx
expr_stmt|;
if|if
condition|(
name|virtual_interrupt_delivery
condition|)
block|{
name|vlapic
operator|->
name|ops
operator|.
name|set_intr_ready
operator|=
name|vmx_set_intr_ready
expr_stmt|;
name|vlapic
operator|->
name|ops
operator|.
name|pending_intr
operator|=
name|vmx_pending_intr
expr_stmt|;
name|vlapic
operator|->
name|ops
operator|.
name|intr_accepted
operator|=
name|vmx_intr_accepted
expr_stmt|;
name|vlapic
operator|->
name|ops
operator|.
name|set_tmr
operator|=
name|vmx_set_tmr
expr_stmt|;
name|vlapic
operator|->
name|ops
operator|.
name|enable_x2apic_mode
operator|=
name|vmx_enable_x2apic_mode
expr_stmt|;
block|}
if|if
condition|(
name|posted_interrupts
condition|)
name|vlapic
operator|->
name|ops
operator|.
name|post_intr
operator|=
name|vmx_post_intr
expr_stmt|;
name|vlapic_init
argument_list|(
name|vlapic
argument_list|)
expr_stmt|;
return|return
operator|(
name|vlapic
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vmx_vlapic_cleanup
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|,
name|struct
name|vlapic
modifier|*
name|vlapic
parameter_list|)
block|{
name|vlapic_cleanup
argument_list|(
name|vlapic
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|vlapic
argument_list|,
name|M_VLAPIC
argument_list|)
expr_stmt|;
block|}
end_function

begin_decl_stmt
name|struct
name|vmm_ops
name|vmm_ops_intel
init|=
block|{
name|vmx_init
block|,
name|vmx_cleanup
block|,
name|vmx_restore
block|,
name|vmx_vminit
block|,
name|vmx_run
block|,
name|vmx_vmcleanup
block|,
name|vmx_getreg
block|,
name|vmx_setreg
block|,
name|vmx_getdesc
block|,
name|vmx_setdesc
block|,
name|vmx_getcap
block|,
name|vmx_setcap
block|,
name|ept_vmspace_alloc
block|,
name|ept_vmspace_free
block|,
name|vmx_vlapic_init
block|,
name|vmx_vlapic_cleanup
block|, }
decl_stmt|;
end_decl_stmt

end_unit

