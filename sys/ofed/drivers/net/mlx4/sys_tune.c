begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * Copyright (c) 2010 Mellanox Technologies. All rights reserved.  *  * This software is available to you under a choice of one of two  * licenses.  You may choose to be licensed under the terms of the GNU  * General Public License (GPL) Version 2, available from the file  * COPYING in the main directory of this source tree, or the  * OpenIB.org BSD license below:  *  *     Redistribution and use in source and binary forms, with or  *     without modification, are permitted provided that the following  *     conditions are met:  *  *      - Redistributions of source code must retain the above  *        copyright notice, this list of conditions and the following  *        disclaimer.  *  *      - Redistributions in binary form must reproduce the above  *        copyright notice, this list of conditions and the following  *        disclaimer in the documentation and/or other materials  *        provided with the distribution.  *  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF  * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND  * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS  * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN  * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE  * SOFTWARE.  *  */
end_comment

begin_include
include|#
directive|include
file|<linux/sched.h>
end_include

begin_include
include|#
directive|include
file|<linux/mutex.h>
end_include

begin_include
include|#
directive|include
file|<asm/atomic.h>
end_include

begin_include
include|#
directive|include
file|"mlx4.h"
end_include

begin_if
if|#
directive|if
name|defined
argument_list|(
name|CONFIG_X86
argument_list|)
operator|&&
name|defined
argument_list|(
name|CONFIG_APM_MODULE
argument_list|)
end_if

begin_comment
comment|/* Each CPU is put into a group.  In most cases, the group number is  * equal to the CPU number of one of the CPUs in the group.  The  * exception is group NR_CPUS which is the default group.  This is  * protected by sys_tune_startup_mutex. */
end_comment

begin_expr_stmt
name|DEFINE_PER_CPU
argument_list|(
name|int
argument_list|,
name|idle_cpu_group
argument_list|)
operator|=
name|NR_CPUS
expr_stmt|;
end_expr_stmt

begin_comment
comment|/* For each group, a count of the number of CPUs in the group which  * are known to be busy.  A busy CPU might be running the busy loop  * below or general kernel code.  The count is decremented on entry to  * the old pm_idle handler and incremented on exit.  The aim is to  * avoid the count going to zero or negative.  This situation can  * occur temporarily during module unload or CPU hot-plug but  * normality will be restored when the affected CPUs next exit the  * idle loop. */
end_comment

begin_decl_stmt
specifier|static
name|atomic_t
name|busy_cpu_count
index|[
name|NR_CPUS
operator|+
literal|1
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* A workqueue item to be executed to cause the CPU to exit from the  * idle loop. */
end_comment

begin_expr_stmt
name|DEFINE_PER_CPU
argument_list|(
expr|struct
name|work_struct
argument_list|,
name|sys_tune_cpu_work
argument_list|)
expr_stmt|;
end_expr_stmt

begin_define
define|#
directive|define
name|sys_tune_set_state
parameter_list|(
name|CPU
parameter_list|,
name|STATE
parameter_list|)
define|\
value|do { } while(0)
end_define

begin_comment
comment|/* A mutex to protect most of the module datastructures. */
end_comment

begin_expr_stmt
specifier|static
name|DEFINE_MUTEX
argument_list|(
name|sys_tune_startup_mutex
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/* The old pm_idle handler. */
end_comment

begin_function_decl
specifier|static
name|void
function_decl|(
modifier|*
name|old_pm_idle
function_decl|)
parameter_list|(
name|void
parameter_list|)
init|=
name|NULL
function_decl|;
end_function_decl

begin_function
specifier|static
name|void
name|sys_tune_pm_idle
parameter_list|(
name|void
parameter_list|)
block|{
name|atomic_t
modifier|*
name|busy_cpus_ptr
decl_stmt|;
name|int
name|busy_cpus
decl_stmt|;
name|int
name|cpu
init|=
name|smp_processor_id
argument_list|()
decl_stmt|;
name|busy_cpus_ptr
operator|=
operator|&
operator|(
name|busy_cpu_count
index|[
name|per_cpu
argument_list|(
name|idle_cpu_group
argument_list|,
name|cpu
argument_list|)
index|]
operator|)
expr_stmt|;
name|sys_tune_set_state
argument_list|(
name|cpu
argument_list|,
literal|2
argument_list|)
expr_stmt|;
name|local_irq_enable
argument_list|()
expr_stmt|;
while|while
condition|(
operator|!
name|need_resched
argument_list|()
condition|)
block|{
name|busy_cpus
operator|=
name|atomic_read
argument_list|(
name|busy_cpus_ptr
argument_list|)
expr_stmt|;
comment|/* If other CPUs in this group are busy then let this 		 * CPU go idle.  We mustn't let the number of busy 		 * CPUs drop below 1. */
if|if
condition|(
name|busy_cpus
operator|>
literal|1
operator|&&
name|old_pm_idle
operator|!=
name|NULL
operator|&&
operator|(
name|atomic_cmpxchg
argument_list|(
name|busy_cpus_ptr
argument_list|,
name|busy_cpus
argument_list|,
name|busy_cpus
operator|-
literal|1
argument_list|)
operator|==
name|busy_cpus
operator|)
condition|)
block|{
name|local_irq_disable
argument_list|()
expr_stmt|;
name|sys_tune_set_state
argument_list|(
name|cpu
argument_list|,
literal|3
argument_list|)
expr_stmt|;
comment|/* This check might not be necessary, but it 			 * seems safest to include it because there 			 * might be a kernel version which requires 			 * it. */
if|if
condition|(
name|need_resched
argument_list|()
condition|)
name|local_irq_enable
argument_list|()
expr_stmt|;
else|else
name|old_pm_idle
argument_list|()
expr_stmt|;
comment|/* This CPU is busy again. */
name|sys_tune_set_state
argument_list|(
name|cpu
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|atomic_add
argument_list|(
literal|1
argument_list|,
name|busy_cpus_ptr
argument_list|)
expr_stmt|;
return|return;
block|}
name|cpu_relax
argument_list|()
expr_stmt|;
block|}
name|sys_tune_set_state
argument_list|(
name|cpu
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|sys_tune_work_func
parameter_list|(
name|struct
name|work_struct
modifier|*
name|work
parameter_list|)
block|{
comment|/* Do nothing.  Since this function is running in process 	 * context, the idle thread isn't running on this CPU. */
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|CONFIG_SMP
end_ifdef

begin_function
specifier|static
name|void
name|sys_tune_smp_call
parameter_list|(
name|void
modifier|*
name|info
parameter_list|)
block|{
name|schedule_work
argument_list|(
operator|&
name|get_cpu_var
argument_list|(
name|sys_tune_cpu_work
argument_list|)
argument_list|)
expr_stmt|;
name|put_cpu_var
argument_list|(
name|sys_tune_cpu_work
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|CONFIG_SMP
end_ifdef

begin_function
specifier|static
name|void
name|sys_tune_refresh
parameter_list|(
name|void
parameter_list|)
block|{
if|#
directive|if
name|LINUX_VERSION_CODE
operator|<
name|KERNEL_VERSION
argument_list|(
literal|2
operator|,
literal|6
operator|,
literal|26
argument_list|)
name|on_each_cpu
argument_list|(
operator|&
name|sys_tune_smp_call
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
literal|1
argument_list|)
expr_stmt|;
else|#
directive|else
name|on_each_cpu
argument_list|(
operator|&
name|sys_tune_smp_call
argument_list|,
name|NULL
argument_list|,
literal|1
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_else
else|#
directive|else
end_else

begin_function
specifier|static
name|void
name|sys_tune_refresh
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* The current thread is executing on the one and only CPU so 	 * the idle thread isn't running. */
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|int
name|sys_tune_cpu_group
parameter_list|(
name|int
name|cpu
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|CONFIG_SMP
specifier|const
name|cpumask_t
modifier|*
name|mask
decl_stmt|;
name|int
name|other_cpu
decl_stmt|;
name|int
name|group
decl_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|topology_thread_cpumask
argument_list|)
operator|&&
name|defined
argument_list|(
name|ST_HAVE_EXPORTED_CPU_SIBLING_MAP
argument_list|)
comment|/* Keep one hyperthread busy per core. */
name|mask
operator|=
name|topology_thread_cpumask
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
else|#
directive|else
return|return
name|cpu
return|;
endif|#
directive|endif
name|for_each_cpu_mask
argument_list|(
argument|cpu
argument_list|,
argument|*(mask)
argument_list|)
block|{
name|group
operator|=
name|per_cpu
argument_list|(
name|idle_cpu_group
argument_list|,
name|other_cpu
argument_list|)
expr_stmt|;
if|if
condition|(
name|group
operator|!=
name|NR_CPUS
condition|)
return|return
name|group
return|;
block|}
endif|#
directive|endif
return|return
name|cpu
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|sys_tune_add_cpu
parameter_list|(
name|int
name|cpu
parameter_list|)
block|{
name|int
name|group
decl_stmt|;
comment|/* Do nothing if this CPU has already been added. */
if|if
condition|(
name|per_cpu
argument_list|(
name|idle_cpu_group
argument_list|,
name|cpu
argument_list|)
operator|!=
name|NR_CPUS
condition|)
return|return;
name|group
operator|=
name|sys_tune_cpu_group
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|per_cpu
argument_list|(
name|idle_cpu_group
argument_list|,
name|cpu
argument_list|)
operator|=
name|group
expr_stmt|;
name|atomic_inc
argument_list|(
operator|&
operator|(
name|busy_cpu_count
index|[
name|group
index|]
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|sys_tune_del_cpu
parameter_list|(
name|int
name|cpu
parameter_list|)
block|{
name|int
name|group
decl_stmt|;
if|if
condition|(
name|per_cpu
argument_list|(
name|idle_cpu_group
argument_list|,
name|cpu
argument_list|)
operator|==
name|NR_CPUS
condition|)
return|return;
name|group
operator|=
name|per_cpu
argument_list|(
name|idle_cpu_group
argument_list|,
name|cpu
argument_list|)
expr_stmt|;
comment|/* If the CPU was busy, this can cause the count to drop to 	 * zero.  To rectify this, we need to cause one of the other 	 * CPUs in the group to exit the idle loop.  If the CPU was 	 * not busy then this causes the contribution for this CPU to 	 * go to -1 which can cause the overall count to drop to zero 	 * or go negative.  To rectify this situation we need to cause 	 * this CPU to exit the idle loop. */
name|atomic_dec
argument_list|(
operator|&
operator|(
name|busy_cpu_count
index|[
name|group
index|]
operator|)
argument_list|)
expr_stmt|;
name|per_cpu
argument_list|(
name|idle_cpu_group
argument_list|,
name|cpu
argument_list|)
operator|=
name|NR_CPUS
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|sys_tune_cpu_notify
parameter_list|(
name|struct
name|notifier_block
modifier|*
name|self
parameter_list|,
name|unsigned
name|long
name|action
parameter_list|,
name|void
modifier|*
name|hcpu
parameter_list|)
block|{
name|int
name|cpu
init|=
operator|(
name|long
operator|)
name|hcpu
decl_stmt|;
switch|switch
condition|(
name|action
condition|)
block|{
ifdef|#
directive|ifdef
name|CPU_ONLINE_FROZEN
case|case
name|CPU_ONLINE_FROZEN
case|:
endif|#
directive|endif
case|case
name|CPU_ONLINE
case|:
name|mutex_lock
argument_list|(
operator|&
name|sys_tune_startup_mutex
argument_list|)
expr_stmt|;
name|sys_tune_add_cpu
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|mutex_unlock
argument_list|(
operator|&
name|sys_tune_startup_mutex
argument_list|)
expr_stmt|;
comment|/* The CPU might have already entered the idle loop in 		 * the wrong group.  Make sure it exits the idle loop 		 * so that it picks up the correct group. */
name|sys_tune_refresh
argument_list|()
expr_stmt|;
break|break;
ifdef|#
directive|ifdef
name|CPU_DEAD_FROZEN
case|case
name|CPU_DEAD_FROZEN
case|:
endif|#
directive|endif
case|case
name|CPU_DEAD
case|:
name|mutex_lock
argument_list|(
operator|&
name|sys_tune_startup_mutex
argument_list|)
expr_stmt|;
name|sys_tune_del_cpu
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|mutex_unlock
argument_list|(
operator|&
name|sys_tune_startup_mutex
argument_list|)
expr_stmt|;
comment|/* The deleted CPU may have been the only busy CPU in 		 * the group.  Make sure one of the other CPUs in the 		 * group exits the idle loop. */
name|sys_tune_refresh
argument_list|()
expr_stmt|;
break|break;
block|}
return|return
name|NOTIFY_OK
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|struct
name|notifier_block
name|sys_tune_cpu_nb
init|=
block|{
operator|.
name|notifier_call
operator|=
name|sys_tune_cpu_notify
block|, }
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|void
name|sys_tune_ensure_init
parameter_list|(
name|void
parameter_list|)
block|{
name|BUG_ON
argument_list|(
name|old_pm_idle
operator|!=
name|NULL
argument_list|)
expr_stmt|;
comment|/* Atomically update pm_idle to&sys_tune_pm_idle.  The old value 	 * is stored in old_pm_idle before installing the new 	 * handler. */
do|do
block|{
name|old_pm_idle
operator|=
name|pm_idle
expr_stmt|;
block|}
do|while
condition|(
name|cmpxchg
argument_list|(
operator|&
name|pm_idle
argument_list|,
name|old_pm_idle
argument_list|,
operator|&
name|sys_tune_pm_idle
argument_list|)
operator|!=
name|old_pm_idle
condition|)
do|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
name|void
name|sys_tune_fini
parameter_list|(
name|void
parameter_list|)
block|{
if|#
directive|if
name|defined
argument_list|(
name|CONFIG_X86
argument_list|)
operator|&&
name|defined
argument_list|(
name|CONFIG_APM_MODULE
argument_list|)
name|void
function_decl|(
modifier|*
name|old
function_decl|)
parameter_list|(
name|void
parameter_list|)
function_decl|;
name|int
name|cpu
decl_stmt|;
name|unregister_cpu_notifier
argument_list|(
operator|&
name|sys_tune_cpu_nb
argument_list|)
expr_stmt|;
name|mutex_lock
argument_list|(
operator|&
name|sys_tune_startup_mutex
argument_list|)
expr_stmt|;
name|old
operator|=
name|cmpxchg
argument_list|(
operator|&
name|pm_idle
argument_list|,
operator|&
name|sys_tune_pm_idle
argument_list|,
name|old_pm_idle
argument_list|)
expr_stmt|;
name|for_each_online_cpu
argument_list|(
argument|cpu
argument_list|)
name|sys_tune_del_cpu
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|mutex_unlock
argument_list|(
operator|&
name|sys_tune_startup_mutex
argument_list|)
expr_stmt|;
comment|/* Our handler may still be executing on other CPUs. 	 * Schedule this thread on all CPUs to make sure all 	 * idle threads get interrupted. */
name|sys_tune_refresh
argument_list|()
expr_stmt|;
comment|/* Make sure the work item has finished executing on all CPUs. 	 * This in turn ensures that all idle threads have been 	 * interrupted. */
name|flush_scheduled_work
argument_list|()
expr_stmt|;
endif|#
directive|endif
comment|/* CONFIG_X86 */
block|}
end_function

begin_function
name|void
name|sys_tune_init
parameter_list|(
name|void
parameter_list|)
block|{
if|#
directive|if
name|defined
argument_list|(
name|CONFIG_X86
argument_list|)
operator|&&
name|defined
argument_list|(
name|CONFIG_APM_MODULE
argument_list|)
name|int
name|cpu
decl_stmt|;
name|for_each_possible_cpu
argument_list|(
argument|cpu
argument_list|)
block|{
name|INIT_WORK
argument_list|(
operator|&
name|per_cpu
argument_list|(
name|sys_tune_cpu_work
argument_list|,
name|cpu
argument_list|)
argument_list|,
name|sys_tune_work_func
argument_list|)
expr_stmt|;
block|}
comment|/* Start by registering the handler to ensure we don't miss 	 * any updates. */
name|register_cpu_notifier
argument_list|(
operator|&
name|sys_tune_cpu_nb
argument_list|)
expr_stmt|;
name|mutex_lock
argument_list|(
operator|&
name|sys_tune_startup_mutex
argument_list|)
expr_stmt|;
name|for_each_online_cpu
argument_list|(
argument|cpu
argument_list|)
name|sys_tune_add_cpu
argument_list|(
name|cpu
argument_list|)
expr_stmt|;
name|sys_tune_ensure_init
argument_list|()
expr_stmt|;
name|mutex_unlock
argument_list|(
operator|&
name|sys_tune_startup_mutex
argument_list|)
expr_stmt|;
comment|/* Ensure our idle handler starts to run. */
name|sys_tune_refresh
argument_list|()
expr_stmt|;
endif|#
directive|endif
block|}
end_function

end_unit

