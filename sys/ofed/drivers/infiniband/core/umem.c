begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * Copyright (c) 2005 Topspin Communications.  All rights reserved.  * Copyright (c) 2005 Cisco Systems.  All rights reserved.  * Copyright (c) 2005 Mellanox Technologies. All rights reserved.  *  * This software is available to you under a choice of one of two  * licenses.  You may choose to be licensed under the terms of the GNU  * General Public License (GPL) Version 2, available from the file  * COPYING in the main directory of this source tree, or the  * OpenIB.org BSD license below:  *  *     Redistribution and use in source and binary forms, with or  *     without modification, are permitted provided that the following  *     conditions are met:  *  *      - Redistributions of source code must retain the above  *        copyright notice, this list of conditions and the following  *        disclaimer.  *  *      - Redistributions in binary form must reproduce the above  *        copyright notice, this list of conditions and the following  *        disclaimer in the documentation and/or other materials  *        provided with the distribution.  *  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF  * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND  * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS  * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN  * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE  * SOFTWARE.  */
end_comment

begin_define
define|#
directive|define
name|LINUXKPI_PARAM_PREFIX
value|ibcore_
end_define

begin_include
include|#
directive|include
file|<linux/mm.h>
end_include

begin_include
include|#
directive|include
file|<linux/dma-mapping.h>
end_include

begin_include
include|#
directive|include
file|<linux/sched.h>
end_include

begin_include
include|#
directive|include
file|<linux/dma-attrs.h>
end_include

begin_include
include|#
directive|include
file|<linux/slab.h>
end_include

begin_include
include|#
directive|include
file|<linux/module.h>
end_include

begin_include
include|#
directive|include
file|<sys/priv.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|"uverbs.h"
end_include

begin_define
define|#
directive|define
name|IB_UMEM_MAX_PAGE_CHUNK
value|(PAGE_SIZE / sizeof (struct page *))
end_define

begin_decl_stmt
specifier|static
name|int
name|allow_weak_ordering
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|module_param_named
argument_list|(
name|weak_ordering
argument_list|,
name|allow_weak_ordering
argument_list|,
name|int
argument_list|,
literal|0444
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|MODULE_PARM_DESC
argument_list|(
name|weak_ordering
argument_list|,
literal|"Allow weak ordering for data registered memory"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|struct
name|ib_umem
modifier|*
name|peer_umem_get
parameter_list|(
name|struct
name|ib_peer_memory_client
modifier|*
name|ib_peer_mem
parameter_list|,
name|struct
name|ib_umem
modifier|*
name|umem
parameter_list|,
name|unsigned
name|long
name|addr
parameter_list|,
name|int
name|dmasync
parameter_list|,
name|int
name|invalidation_supported
parameter_list|)
block|{
name|int
name|ret
decl_stmt|;
specifier|const
name|struct
name|peer_memory_client
modifier|*
name|peer_mem
init|=
name|ib_peer_mem
operator|->
name|peer_mem
decl_stmt|;
name|struct
name|invalidation_ctx
modifier|*
name|invalidation_ctx
init|=
name|NULL
decl_stmt|;
name|umem
operator|->
name|ib_peer_mem
operator|=
name|ib_peer_mem
expr_stmt|;
if|if
condition|(
name|invalidation_supported
condition|)
block|{
name|invalidation_ctx
operator|=
name|kzalloc
argument_list|(
sizeof|sizeof
argument_list|(
operator|*
name|invalidation_ctx
argument_list|)
argument_list|,
name|GFP_KERNEL
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|invalidation_ctx
condition|)
block|{
name|ret
operator|=
operator|-
name|ENOMEM
expr_stmt|;
goto|goto
name|out
goto|;
block|}
name|umem
operator|->
name|invalidation_ctx
operator|=
name|invalidation_ctx
expr_stmt|;
name|invalidation_ctx
operator|->
name|umem
operator|=
name|umem
expr_stmt|;
name|mutex_lock
argument_list|(
operator|&
name|ib_peer_mem
operator|->
name|lock
argument_list|)
expr_stmt|;
name|invalidation_ctx
operator|->
name|context_ticket
operator|=
name|ib_peer_insert_context
argument_list|(
name|ib_peer_mem
argument_list|,
name|invalidation_ctx
argument_list|)
expr_stmt|;
comment|/* unlock before calling get pages to prevent a dead-lock from the callback */
name|mutex_unlock
argument_list|(
operator|&
name|ib_peer_mem
operator|->
name|lock
argument_list|)
expr_stmt|;
block|}
name|ret
operator|=
name|peer_mem
operator|->
name|get_pages
argument_list|(
name|addr
argument_list|,
name|umem
operator|->
name|length
argument_list|,
name|umem
operator|->
name|writable
argument_list|,
literal|1
argument_list|,
operator|&
name|umem
operator|->
name|sg_head
argument_list|,
name|umem
operator|->
name|peer_mem_client_context
argument_list|,
name|invalidation_ctx
condition|?
operator|(
name|void
operator|*
operator|)
name|invalidation_ctx
operator|->
name|context_ticket
else|:
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|invalidation_ctx
condition|)
block|{
comment|/* taking the lock back, checking that wasn't invalidated at that time */
name|mutex_lock
argument_list|(
operator|&
name|ib_peer_mem
operator|->
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|invalidation_ctx
operator|->
name|peer_invalidated
condition|)
block|{
name|printk
argument_list|(
name|KERN_ERR
literal|"peer_umem_get: pages were invalidated by peer\n"
argument_list|)
expr_stmt|;
name|ret
operator|=
operator|-
name|EINVAL
expr_stmt|;
block|}
block|}
if|if
condition|(
name|ret
condition|)
goto|goto
name|out
goto|;
name|umem
operator|->
name|page_size
operator|=
name|peer_mem
operator|->
name|get_page_size
argument_list|(
name|umem
operator|->
name|peer_mem_client_context
argument_list|)
expr_stmt|;
if|if
condition|(
name|umem
operator|->
name|page_size
operator|<=
literal|0
condition|)
goto|goto
name|put_pages
goto|;
name|umem
operator|->
name|offset
operator|=
name|addr
operator|&
operator|(
operator|(
name|unsigned
name|long
operator|)
name|umem
operator|->
name|page_size
operator|-
literal|1
operator|)
expr_stmt|;
name|ret
operator|=
name|peer_mem
operator|->
name|dma_map
argument_list|(
operator|&
name|umem
operator|->
name|sg_head
argument_list|,
name|umem
operator|->
name|peer_mem_client_context
argument_list|,
name|umem
operator|->
name|context
operator|->
name|device
operator|->
name|dma_device
argument_list|,
name|dmasync
argument_list|,
operator|&
name|umem
operator|->
name|nmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|ret
condition|)
goto|goto
name|put_pages
goto|;
name|ib_peer_mem
operator|->
name|stats
operator|.
name|num_reg_pages
operator|+=
name|umem
operator|->
name|nmap
operator|*
operator|(
name|umem
operator|->
name|page_size
operator|>>
name|PAGE_SHIFT
operator|)
expr_stmt|;
name|ib_peer_mem
operator|->
name|stats
operator|.
name|num_alloc_mrs
operator|+=
literal|1
expr_stmt|;
return|return
name|umem
return|;
name|put_pages
label|:
name|peer_mem
operator|->
name|put_pages
argument_list|(
name|umem
operator|->
name|peer_mem_client_context
argument_list|,
operator|&
name|umem
operator|->
name|sg_head
argument_list|)
expr_stmt|;
name|out
label|:
if|if
condition|(
name|invalidation_ctx
condition|)
block|{
name|ib_peer_remove_context
argument_list|(
name|ib_peer_mem
argument_list|,
name|invalidation_ctx
operator|->
name|context_ticket
argument_list|)
expr_stmt|;
name|mutex_unlock
argument_list|(
operator|&
name|umem
operator|->
name|ib_peer_mem
operator|->
name|lock
argument_list|)
expr_stmt|;
name|kfree
argument_list|(
name|invalidation_ctx
argument_list|)
expr_stmt|;
block|}
name|ib_put_peer_client
argument_list|(
name|ib_peer_mem
argument_list|,
name|umem
operator|->
name|peer_mem_client_context
argument_list|,
name|umem
operator|->
name|peer_mem_srcu_key
argument_list|)
expr_stmt|;
name|kfree
argument_list|(
name|umem
argument_list|)
expr_stmt|;
return|return
name|ERR_PTR
argument_list|(
name|ret
argument_list|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|peer_umem_release
parameter_list|(
name|struct
name|ib_umem
modifier|*
name|umem
parameter_list|)
block|{
name|struct
name|ib_peer_memory_client
modifier|*
name|ib_peer_mem
init|=
name|umem
operator|->
name|ib_peer_mem
decl_stmt|;
specifier|const
name|struct
name|peer_memory_client
modifier|*
name|peer_mem
init|=
name|ib_peer_mem
operator|->
name|peer_mem
decl_stmt|;
name|struct
name|invalidation_ctx
modifier|*
name|invalidation_ctx
init|=
name|umem
operator|->
name|invalidation_ctx
decl_stmt|;
if|if
condition|(
name|invalidation_ctx
condition|)
block|{
name|int
name|peer_callback
decl_stmt|;
name|int
name|inflight_invalidation
decl_stmt|;
comment|/* If we are not under peer callback we must take the lock before removing 		  * core ticket from the tree and releasing its umem. 		  * It will let any inflight callbacks to be ended safely. 		  * If we are under peer callback or under error flow of reg_mr so that context 		  * wasn't activated yet lock was already taken. 		*/
if|if
condition|(
name|invalidation_ctx
operator|->
name|func
operator|&&
operator|!
name|invalidation_ctx
operator|->
name|peer_callback
condition|)
name|mutex_lock
argument_list|(
operator|&
name|ib_peer_mem
operator|->
name|lock
argument_list|)
expr_stmt|;
name|ib_peer_remove_context
argument_list|(
name|ib_peer_mem
argument_list|,
name|invalidation_ctx
operator|->
name|context_ticket
argument_list|)
expr_stmt|;
comment|/* make sure to check inflight flag after took the lock and remove from tree. 		  * in addition, from that point using local variables for peer_callback and 		  * inflight_invalidation as after the complete invalidation_ctx can't be accessed 		  * any more as it may be freed by the callback. 		*/
name|peer_callback
operator|=
name|invalidation_ctx
operator|->
name|peer_callback
expr_stmt|;
name|inflight_invalidation
operator|=
name|invalidation_ctx
operator|->
name|inflight_invalidation
expr_stmt|;
if|if
condition|(
name|inflight_invalidation
condition|)
name|complete
argument_list|(
operator|&
name|invalidation_ctx
operator|->
name|comp
argument_list|)
expr_stmt|;
comment|/* On peer callback lock is handled externally */
if|if
condition|(
operator|!
name|peer_callback
condition|)
comment|/* unlocking before put_pages */
name|mutex_unlock
argument_list|(
operator|&
name|ib_peer_mem
operator|->
name|lock
argument_list|)
expr_stmt|;
comment|/* in case under callback context or callback is pending let it free the invalidation context */
if|if
condition|(
operator|!
name|peer_callback
operator|&&
operator|!
name|inflight_invalidation
condition|)
name|kfree
argument_list|(
name|invalidation_ctx
argument_list|)
expr_stmt|;
block|}
name|peer_mem
operator|->
name|dma_unmap
argument_list|(
operator|&
name|umem
operator|->
name|sg_head
argument_list|,
name|umem
operator|->
name|peer_mem_client_context
argument_list|,
name|umem
operator|->
name|context
operator|->
name|device
operator|->
name|dma_device
argument_list|)
expr_stmt|;
name|peer_mem
operator|->
name|put_pages
argument_list|(
operator|&
name|umem
operator|->
name|sg_head
argument_list|,
name|umem
operator|->
name|peer_mem_client_context
argument_list|)
expr_stmt|;
name|ib_peer_mem
operator|->
name|stats
operator|.
name|num_dereg_pages
operator|+=
name|umem
operator|->
name|nmap
operator|*
operator|(
name|umem
operator|->
name|page_size
operator|>>
name|PAGE_SHIFT
operator|)
expr_stmt|;
name|ib_peer_mem
operator|->
name|stats
operator|.
name|num_dealloc_mrs
operator|+=
literal|1
expr_stmt|;
name|ib_put_peer_client
argument_list|(
name|ib_peer_mem
argument_list|,
name|umem
operator|->
name|peer_mem_client_context
argument_list|,
name|umem
operator|->
name|peer_mem_srcu_key
argument_list|)
expr_stmt|;
name|kfree
argument_list|(
name|umem
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_function
specifier|static
name|void
name|__ib_umem_release
parameter_list|(
name|struct
name|ib_device
modifier|*
name|dev
parameter_list|,
name|struct
name|ib_umem
modifier|*
name|umem
parameter_list|,
name|int
name|dirty
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|struct
name|scatterlist
modifier|*
name|sg
decl_stmt|;
name|struct
name|page
modifier|*
name|page
decl_stmt|;
name|int
name|i
decl_stmt|;
name|object
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|umem
operator|->
name|nmap
operator|>
literal|0
condition|)
name|ib_dma_unmap_sg
argument_list|(
name|dev
argument_list|,
name|umem
operator|->
name|sg_head
operator|.
name|sgl
argument_list|,
name|umem
operator|->
name|nmap
argument_list|,
name|DMA_BIDIRECTIONAL
argument_list|)
expr_stmt|;
name|for_each_sg
argument_list|(
argument|umem->sg_head.sgl
argument_list|,
argument|sg
argument_list|,
argument|umem->npages
argument_list|,
argument|i
argument_list|)
block|{
name|page
operator|=
name|sg_page
argument_list|(
name|sg
argument_list|)
expr_stmt|;
if|if
condition|(
name|umem
operator|->
name|writable
operator|&&
name|dirty
condition|)
block|{
if|if
condition|(
name|object
operator|&&
name|object
operator|!=
name|page
operator|->
name|object
condition|)
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|page
operator|->
name|object
condition|)
block|{
name|object
operator|=
name|page
operator|->
name|object
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
name|vm_page_dirty
argument_list|(
name|page
argument_list|)
expr_stmt|;
block|}
block|}
name|sg_free_table
argument_list|(
operator|&
name|umem
operator|->
name|sg_head
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
condition|)
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|ib_umem_activate_invalidation_notifier
parameter_list|(
name|struct
name|ib_umem
modifier|*
name|umem
parameter_list|,
name|umem_invalidate_func_t
name|func
parameter_list|,
name|void
modifier|*
name|cookie
parameter_list|)
block|{
name|struct
name|invalidation_ctx
modifier|*
name|invalidation_ctx
init|=
name|umem
operator|->
name|invalidation_ctx
decl_stmt|;
name|invalidation_ctx
operator|->
name|func
operator|=
name|func
expr_stmt|;
name|invalidation_ctx
operator|->
name|cookie
operator|=
name|cookie
expr_stmt|;
comment|/* from that point any pending invalidations can be called */
name|mutex_unlock
argument_list|(
operator|&
name|umem
operator|->
name|ib_peer_mem
operator|->
name|lock
argument_list|)
expr_stmt|;
return|return;
block|}
end_function

begin_expr_stmt
name|EXPORT_SYMBOL
argument_list|(
name|ib_umem_activate_invalidation_notifier
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/**  * ib_umem_get - Pin and DMA map userspace memory.  * @context: userspace context to pin memory for  * @addr: userspace virtual address to start at  * @size: length of region to pin  * @access: IB_ACCESS_xxx flags for memory being pinned  * @dmasync: flush in-flight DMA when the memory region is written  */
end_comment

begin_function
name|struct
name|ib_umem
modifier|*
name|ib_umem_get_ex
parameter_list|(
name|struct
name|ib_ucontext
modifier|*
name|context
parameter_list|,
name|unsigned
name|long
name|addr
parameter_list|,
name|size_t
name|size
parameter_list|,
name|int
name|access
parameter_list|,
name|int
name|dmasync
parameter_list|,
name|int
name|invalidation_supported
parameter_list|)
block|{
name|struct
name|ib_umem
modifier|*
name|umem
decl_stmt|;
name|struct
name|proc
modifier|*
name|proc
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|vm_offset_t
name|end
decl_stmt|,
name|last
decl_stmt|,
name|start
decl_stmt|;
name|vm_size_t
name|npages
decl_stmt|;
name|int
name|error
decl_stmt|;
name|int
name|ret
decl_stmt|;
name|int
name|ents
decl_stmt|;
name|int
name|i
decl_stmt|;
name|DEFINE_DMA_ATTRS
argument_list|(
name|attrs
argument_list|)
expr_stmt|;
name|struct
name|scatterlist
modifier|*
name|sg
decl_stmt|,
modifier|*
name|sg_list_start
decl_stmt|;
name|int
name|need_release
init|=
literal|0
decl_stmt|;
name|error
operator|=
name|priv_check
argument_list|(
name|curthread
argument_list|,
name|PRIV_VM_MLOCK
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
return|return
name|ERR_PTR
argument_list|(
operator|-
name|error
argument_list|)
return|;
name|last
operator|=
name|addr
operator|+
name|size
expr_stmt|;
name|start
operator|=
name|addr
operator|&
name|PAGE_MASK
expr_stmt|;
comment|/* Use the linux PAGE_MASK definition. */
name|end
operator|=
name|roundup2
argument_list|(
name|last
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
comment|/* Use PAGE_MASK safe operation. */
if|if
condition|(
name|last
operator|<
name|addr
operator|||
name|end
operator|<
name|addr
condition|)
return|return
name|ERR_PTR
argument_list|(
operator|-
name|EINVAL
argument_list|)
return|;
name|npages
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
if|if
condition|(
name|npages
operator|>
name|vm_page_max_wired
condition|)
return|return
name|ERR_PTR
argument_list|(
operator|-
name|ENOMEM
argument_list|)
return|;
name|umem
operator|=
name|kzalloc
argument_list|(
sizeof|sizeof
expr|*
name|umem
argument_list|,
name|GFP_KERNEL
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|umem
condition|)
return|return
name|ERR_PTR
argument_list|(
operator|-
name|ENOMEM
argument_list|)
return|;
name|proc
operator|=
name|curthread
operator|->
name|td_proc
expr_stmt|;
name|PROC_LOCK
argument_list|(
name|proc
argument_list|)
expr_stmt|;
if|if
condition|(
name|ptoa
argument_list|(
name|npages
operator|+
name|pmap_wired_count
argument_list|(
name|vm_map_pmap
argument_list|(
operator|&
name|proc
operator|->
name|p_vmspace
operator|->
name|vm_map
argument_list|)
argument_list|)
argument_list|)
operator|>
name|lim_cur_proc
argument_list|(
name|proc
argument_list|,
name|RLIMIT_MEMLOCK
argument_list|)
condition|)
block|{
name|PROC_UNLOCK
argument_list|(
name|proc
argument_list|)
expr_stmt|;
name|kfree
argument_list|(
name|umem
argument_list|)
expr_stmt|;
return|return
name|ERR_PTR
argument_list|(
operator|-
name|ENOMEM
argument_list|)
return|;
block|}
name|PROC_UNLOCK
argument_list|(
name|proc
argument_list|)
expr_stmt|;
if|if
condition|(
name|npages
operator|+
name|vm_cnt
operator|.
name|v_wire_count
operator|>
name|vm_page_max_wired
condition|)
block|{
name|kfree
argument_list|(
name|umem
argument_list|)
expr_stmt|;
return|return
name|ERR_PTR
argument_list|(
operator|-
name|EAGAIN
argument_list|)
return|;
block|}
name|error
operator|=
name|vm_map_wire
argument_list|(
operator|&
name|proc
operator|->
name|p_vmspace
operator|->
name|vm_map
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
name|VM_MAP_WIRE_USER
operator||
name|VM_MAP_WIRE_NOHOLES
operator||
operator|(
name|umem
operator|->
name|writable
condition|?
name|VM_MAP_WIRE_WRITE
else|:
literal|0
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
name|KERN_SUCCESS
condition|)
block|{
name|kfree
argument_list|(
name|umem
argument_list|)
expr_stmt|;
return|return
name|ERR_PTR
argument_list|(
operator|-
name|ENOMEM
argument_list|)
return|;
block|}
name|umem
operator|->
name|context
operator|=
name|context
expr_stmt|;
name|umem
operator|->
name|length
operator|=
name|size
expr_stmt|;
name|umem
operator|->
name|offset
operator|=
name|addr
operator|&
operator|~
name|PAGE_MASK
expr_stmt|;
name|umem
operator|->
name|page_size
operator|=
name|PAGE_SIZE
expr_stmt|;
name|umem
operator|->
name|start
operator|=
name|addr
expr_stmt|;
comment|/* 	 * We ask for writable memory if any access flags other than 	 * "remote read" are set.  "Local write" and "remote write" 	 * obviously require write access.  "Remote atomic" can do 	 * things like fetch and add, which will modify memory, and 	 * "MW bind" can change permissions by binding a window. 	 */
name|umem
operator|->
name|writable
operator|=
operator|!
operator|!
operator|(
name|access
operator|&
operator|~
name|IB_ACCESS_REMOTE_READ
operator|)
expr_stmt|;
if|if
condition|(
name|invalidation_supported
operator|||
name|context
operator|->
name|peer_mem_private_data
condition|)
block|{
name|struct
name|ib_peer_memory_client
modifier|*
name|peer_mem_client
decl_stmt|;
name|peer_mem_client
operator|=
name|ib_get_peer_client
argument_list|(
name|context
argument_list|,
name|addr
argument_list|,
name|size
argument_list|,
operator|&
name|umem
operator|->
name|peer_mem_client_context
argument_list|,
operator|&
name|umem
operator|->
name|peer_mem_srcu_key
argument_list|)
expr_stmt|;
if|if
condition|(
name|peer_mem_client
condition|)
return|return
name|peer_umem_get
argument_list|(
name|peer_mem_client
argument_list|,
name|umem
argument_list|,
name|addr
argument_list|,
name|dmasync
argument_list|,
name|invalidation_supported
argument_list|)
return|;
block|}
name|umem
operator|->
name|hugetlb
operator|=
literal|0
expr_stmt|;
name|pmap
operator|=
name|vm_map_pmap
argument_list|(
operator|&
name|proc
operator|->
name|p_vmspace
operator|->
name|vm_map
argument_list|)
expr_stmt|;
if|if
condition|(
name|npages
operator|==
literal|0
condition|)
block|{
name|ret
operator|=
operator|-
name|EINVAL
expr_stmt|;
goto|goto
name|out
goto|;
block|}
name|ret
operator|=
name|sg_alloc_table
argument_list|(
operator|&
name|umem
operator|->
name|sg_head
argument_list|,
name|npages
argument_list|,
name|GFP_KERNEL
argument_list|)
expr_stmt|;
if|if
condition|(
name|ret
condition|)
goto|goto
name|out
goto|;
name|need_release
operator|=
literal|1
expr_stmt|;
name|sg_list_start
operator|=
name|umem
operator|->
name|sg_head
operator|.
name|sgl
expr_stmt|;
while|while
condition|(
name|npages
condition|)
block|{
name|ents
operator|=
name|min_t
argument_list|(
name|int
argument_list|,
name|npages
argument_list|,
name|IB_UMEM_MAX_PAGE_CHUNK
argument_list|)
expr_stmt|;
name|umem
operator|->
name|npages
operator|+=
name|ents
expr_stmt|;
name|for_each_sg
argument_list|(
argument|sg_list_start
argument_list|,
argument|sg
argument_list|,
argument|ents
argument_list|,
argument|i
argument_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|pa
operator|=
name|pmap_extract
argument_list|(
name|pmap
argument_list|,
name|start
argument_list|)
expr_stmt|;
if|if
condition|(
name|pa
operator|==
literal|0
condition|)
block|{
name|ret
operator|=
operator|-
name|ENOMEM
expr_stmt|;
goto|goto
name|out
goto|;
block|}
name|sg_set_page
argument_list|(
name|sg
argument_list|,
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
argument_list|,
name|PAGE_SIZE
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|npages
operator|--
expr_stmt|;
name|start
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* preparing for next loop */
name|sg_list_start
operator|=
name|sg
expr_stmt|;
block|}
name|umem
operator|->
name|nmap
operator|=
name|ib_dma_map_sg_attrs
argument_list|(
name|context
operator|->
name|device
argument_list|,
name|umem
operator|->
name|sg_head
operator|.
name|sgl
argument_list|,
name|umem
operator|->
name|npages
argument_list|,
name|DMA_BIDIRECTIONAL
argument_list|,
operator|&
name|attrs
argument_list|)
expr_stmt|;
if|if
condition|(
name|umem
operator|->
name|nmap
operator|!=
name|umem
operator|->
name|npages
condition|)
block|{
name|ret
operator|=
operator|-
name|ENOMEM
expr_stmt|;
goto|goto
name|out
goto|;
block|}
name|out
label|:
if|if
condition|(
name|ret
operator|<
literal|0
condition|)
block|{
if|if
condition|(
name|need_release
condition|)
name|__ib_umem_release
argument_list|(
name|context
operator|->
name|device
argument_list|,
name|umem
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|kfree
argument_list|(
name|umem
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
operator|<
literal|0
condition|?
name|ERR_PTR
argument_list|(
name|ret
argument_list|)
else|:
name|umem
return|;
block|}
end_function

begin_expr_stmt
name|EXPORT_SYMBOL
argument_list|(
name|ib_umem_get_ex
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
name|struct
name|ib_umem
modifier|*
name|ib_umem_get
parameter_list|(
name|struct
name|ib_ucontext
modifier|*
name|context
parameter_list|,
name|unsigned
name|long
name|addr
parameter_list|,
name|size_t
name|size
parameter_list|,
name|int
name|access
parameter_list|,
name|int
name|dmasync
parameter_list|)
block|{
return|return
name|ib_umem_get_ex
argument_list|(
name|context
argument_list|,
name|addr
argument_list|,
name|size
argument_list|,
name|access
argument_list|,
name|dmasync
argument_list|,
literal|0
argument_list|)
return|;
block|}
end_function

begin_expr_stmt
name|EXPORT_SYMBOL
argument_list|(
name|ib_umem_get
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/**  * ib_umem_release - release memory pinned with ib_umem_get  * @umem: umem struct to release  */
end_comment

begin_function
name|void
name|ib_umem_release
parameter_list|(
name|struct
name|ib_umem
modifier|*
name|umem
parameter_list|)
block|{
name|vm_offset_t
name|addr
decl_stmt|,
name|end
decl_stmt|,
name|last
decl_stmt|,
name|start
decl_stmt|;
name|vm_size_t
name|size
decl_stmt|;
name|int
name|error
decl_stmt|;
if|if
condition|(
name|umem
operator|->
name|ib_peer_mem
condition|)
block|{
name|peer_umem_release
argument_list|(
name|umem
argument_list|)
expr_stmt|;
return|return;
block|}
name|__ib_umem_release
argument_list|(
name|umem
operator|->
name|context
operator|->
name|device
argument_list|,
name|umem
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|umem
operator|->
name|context
operator|->
name|closing
condition|)
block|{
name|kfree
argument_list|(
name|umem
argument_list|)
expr_stmt|;
return|return;
block|}
name|error
operator|=
name|priv_check
argument_list|(
name|curthread
argument_list|,
name|PRIV_VM_MUNLOCK
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
return|return;
name|addr
operator|=
name|umem
operator|->
name|start
expr_stmt|;
name|size
operator|=
name|umem
operator|->
name|length
expr_stmt|;
name|last
operator|=
name|addr
operator|+
name|size
expr_stmt|;
name|start
operator|=
name|addr
operator|&
name|PAGE_MASK
expr_stmt|;
comment|/* Use the linux PAGE_MASK definition. */
name|end
operator|=
name|roundup2
argument_list|(
name|last
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
comment|/* Use PAGE_MASK safe operation. */
name|vm_map_unwire
argument_list|(
operator|&
name|curthread
operator|->
name|td_proc
operator|->
name|p_vmspace
operator|->
name|vm_map
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
name|VM_MAP_WIRE_USER
operator||
name|VM_MAP_WIRE_NOHOLES
argument_list|)
expr_stmt|;
name|kfree
argument_list|(
name|umem
argument_list|)
expr_stmt|;
block|}
end_function

begin_expr_stmt
name|EXPORT_SYMBOL
argument_list|(
name|ib_umem_release
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
name|int
name|ib_umem_page_count
parameter_list|(
name|struct
name|ib_umem
modifier|*
name|umem
parameter_list|)
block|{
name|int
name|shift
decl_stmt|;
name|int
name|i
decl_stmt|;
name|int
name|n
decl_stmt|;
name|struct
name|scatterlist
modifier|*
name|sg
decl_stmt|;
name|shift
operator|=
name|ilog2
argument_list|(
name|umem
operator|->
name|page_size
argument_list|)
expr_stmt|;
name|n
operator|=
literal|0
expr_stmt|;
name|for_each_sg
argument_list|(
argument|umem->sg_head.sgl
argument_list|,
argument|sg
argument_list|,
argument|umem->nmap
argument_list|,
argument|i
argument_list|)
name|n
operator|+=
name|sg_dma_len
argument_list|(
name|sg
argument_list|)
operator|>>
name|shift
expr_stmt|;
return|return
name|n
return|;
block|}
end_function

begin_expr_stmt
name|EXPORT_SYMBOL
argument_list|(
name|ib_umem_page_count
argument_list|)
expr_stmt|;
end_expr_stmt

end_unit

