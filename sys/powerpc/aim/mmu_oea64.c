begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2001 The NetBSD Foundation, Inc.  * All rights reserved.  *  * This code is derived from software contributed to The NetBSD Foundation  * by Matt Thomas<matt@3am-software.com> of Allegro Networks, Inc.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. All advertising materials mentioning features or use of this software  *    must display the following acknowledgement:  *        This product includes software developed by the NetBSD  *        Foundation, Inc. and its contributors.  * 4. Neither the name of The NetBSD Foundation nor the names of its  *    contributors may be used to endorse or promote products derived  *    from this software without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS  * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED  * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS  * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS  * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN  * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)  * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE  * POSSIBILITY OF SUCH DAMAGE.  */
end_comment

begin_comment
comment|/*-  * Copyright (C) 1995, 1996 Wolfgang Solfrank.  * Copyright (C) 1995, 1996 TooLs GmbH.  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. All advertising materials mentioning features or use of this software  *    must display the following acknowledgement:  *	This product includes software developed by TooLs GmbH.  * 4. The name of TooLs GmbH may not be used to endorse or promote products  *    derived from this software without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY TOOLS GMBH ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  * IN NO EVENT SHALL TOOLS GMBH BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,  * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;  * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,  * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR  * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF  * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  *  * $NetBSD: pmap.c,v 1.28 2000/03/26 20:42:36 kleink Exp $  */
end_comment

begin_comment
comment|/*-  * Copyright (C) 2001 Benno Rice.  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY Benno Rice ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  * IN NO EVENT SHALL TOOLS GMBH BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,  * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;  * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,  * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR  * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF  * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Manages physical address maps.  *  * In addition to hardware address maps, this module is called upon to  * provide software-use-only maps which may or may not be stored in the  * same form as hardware maps.  These pseudo-maps are used to store  * intermediate results from copy operations to and from address spaces.  *  * Since the information managed by this module is also stored by the  * logical address mapping module, this module may throw away valid virtual  * to physical mappings at almost any time.  However, invalidations of  * mappings must be done as requested.  *  * In order to cope with hardware architectures which make virtual to  * physical map invalidates expensive, this module may delay invalidate  * reduced protection operations until such time as they are actually  * necessary.  This module is given full information as to which processors  * are currently using which maps, and to when physical maps must be made  * correct.  */
end_comment

begin_include
include|#
directive|include
file|"opt_kstack_pages.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/msgbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/kdb.h>
end_include

begin_include
include|#
directive|include
file|<dev/ofw/openfirm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/platform.h>
end_include

begin_include
include|#
directive|include
file|<machine/frame.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_include
include|#
directive|include
file|<machine/psl.h>
end_include

begin_include
include|#
directive|include
file|<machine/bat.h>
end_include

begin_include
include|#
directive|include
file|<machine/pte.h>
end_include

begin_include
include|#
directive|include
file|<machine/sr.h>
end_include

begin_include
include|#
directive|include
file|<machine/trap.h>
end_include

begin_include
include|#
directive|include
file|<machine/mmuvar.h>
end_include

begin_include
include|#
directive|include
file|"mmu_if.h"
end_include

begin_define
define|#
directive|define
name|MOEA_DEBUG
end_define

begin_define
define|#
directive|define
name|TODO
value|panic("%s: not implemented", __func__);
end_define

begin_function
specifier|static
name|__inline
name|u_int32_t
name|cntlzw
parameter_list|(
specifier|volatile
name|u_int32_t
name|a
parameter_list|)
block|{
name|u_int32_t
name|b
decl_stmt|;
asm|__asm ("cntlzw %0, %1" : "=r"(b) : "r"(a));
return|return
name|b
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|uint64_t
name|va_to_vsid
parameter_list|(
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
return|return
operator|(
operator|(
name|pm
operator|->
name|pm_sr
index|[
operator|(
name|uintptr_t
operator|)
name|va
operator|>>
name|ADDR_SR_SHFT
index|]
operator|)
operator|&
name|SR_VSID_MASK
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|TLBSYNC
parameter_list|()
value|__asm __volatile("tlbsync; ptesync");
end_define

begin_define
define|#
directive|define
name|SYNC
parameter_list|()
value|__asm __volatile("sync");
end_define

begin_define
define|#
directive|define
name|EIEIO
parameter_list|()
value|__asm __volatile("eieio");
end_define

begin_comment
comment|/*  * The tlbie instruction must be executed in 64-bit mode  * so we have to twiddle MSR[SF] around every invocation.  * Just to add to the fun, exceptions must be off as well  * so that we can't trap in 64-bit mode. What a pain.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|TLBIE
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|register_t
name|msr
decl_stmt|;
name|register_t
name|scratch
decl_stmt|;
name|uint64_t
name|vpn
decl_stmt|;
name|register_t
name|vpn_hi
decl_stmt|,
name|vpn_lo
decl_stmt|;
if|#
directive|if
literal|1
comment|/* 	 * CPU documentation says that tlbie takes the VPN, not the 	 * VA. I think the code below does this correctly. We will see. 	 */
name|vpn
operator|=
call|(
name|uint64_t
call|)
argument_list|(
name|va
operator|&
name|ADDR_PIDX
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|NULL
condition|)
name|vpn
operator||=
operator|(
name|va_to_vsid
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
operator|<<
literal|28
operator|)
expr_stmt|;
else|#
directive|else
name|vpn
operator|=
name|va
expr_stmt|;
endif|#
directive|endif
name|vpn_hi
operator|=
call|(
name|uint32_t
call|)
argument_list|(
name|vpn
operator|>>
literal|32
argument_list|)
expr_stmt|;
name|vpn_lo
operator|=
operator|(
name|uint32_t
operator|)
name|vpn
expr_stmt|;
asm|__asm __volatile("\ 	    mfmsr %0; \ 	    clrldi %1,%0,49; \ 	    insrdi %1,1,1,0; \ 	    mtmsrd %1; \ 	    ptesync; \ 	    \ 	    sld %1,%2,%4; \ 	    or %1,%1,%3; \ 	    tlbie %1; \ 	    \ 	    mtmsrd %0; \ 	    eieio; \ 	    tlbsync; \ 	    ptesync;"
block|:
literal|"=r"
operator|(
name|msr
operator|)
operator|,
literal|"=r"
operator|(
name|scratch
operator|)
operator|:
literal|"r"
operator|(
name|vpn_hi
operator|)
operator|,
literal|"r"
operator|(
name|vpn_lo
operator|)
operator|,
literal|"r"
operator|(
literal|32
operator|)
block|)
function|;
end_function

begin_define
unit|}
define|#
directive|define
name|DISABLE_TRANS
parameter_list|(
name|msr
parameter_list|)
value|msr = mfmsr(); mtmsr(msr& ~PSL_DR); isync()
end_define

begin_define
define|#
directive|define
name|ENABLE_TRANS
parameter_list|(
name|msr
parameter_list|)
value|mtmsr(msr); isync()
end_define

begin_define
define|#
directive|define
name|VSID_MAKE
parameter_list|(
name|sr
parameter_list|,
name|hash
parameter_list|)
value|((sr) | (((hash)& 0xfffff)<< 4))
end_define

begin_define
define|#
directive|define
name|VSID_TO_SR
parameter_list|(
name|vsid
parameter_list|)
value|((vsid)& 0xf)
end_define

begin_define
define|#
directive|define
name|VSID_TO_HASH
parameter_list|(
name|vsid
parameter_list|)
value|(((vsid)>> 4)& 0xfffff)
end_define

begin_define
define|#
directive|define
name|PVO_PTEGIDX_MASK
value|0x007
end_define

begin_comment
comment|/* which PTEG slot */
end_comment

begin_define
define|#
directive|define
name|PVO_PTEGIDX_VALID
value|0x008
end_define

begin_comment
comment|/* slot is valid */
end_comment

begin_define
define|#
directive|define
name|PVO_WIRED
value|0x010
end_define

begin_comment
comment|/* PVO entry is wired */
end_comment

begin_define
define|#
directive|define
name|PVO_MANAGED
value|0x020
end_define

begin_comment
comment|/* PVO entry is managed */
end_comment

begin_define
define|#
directive|define
name|PVO_BOOTSTRAP
value|0x080
end_define

begin_comment
comment|/* PVO entry allocated during 						   bootstrap */
end_comment

begin_define
define|#
directive|define
name|PVO_FAKE
value|0x100
end_define

begin_comment
comment|/* fictitious phys page */
end_comment

begin_define
define|#
directive|define
name|PVO_VADDR
parameter_list|(
name|pvo
parameter_list|)
value|((pvo)->pvo_vaddr& ~ADDR_POFF)
end_define

begin_define
define|#
directive|define
name|PVO_ISFAKE
parameter_list|(
name|pvo
parameter_list|)
value|((pvo)->pvo_vaddr& PVO_FAKE)
end_define

begin_define
define|#
directive|define
name|PVO_PTEGIDX_GET
parameter_list|(
name|pvo
parameter_list|)
value|((pvo)->pvo_vaddr& PVO_PTEGIDX_MASK)
end_define

begin_define
define|#
directive|define
name|PVO_PTEGIDX_ISSET
parameter_list|(
name|pvo
parameter_list|)
value|((pvo)->pvo_vaddr& PVO_PTEGIDX_VALID)
end_define

begin_define
define|#
directive|define
name|PVO_PTEGIDX_CLR
parameter_list|(
name|pvo
parameter_list|)
define|\
value|((void)((pvo)->pvo_vaddr&= ~(PVO_PTEGIDX_VALID|PVO_PTEGIDX_MASK)))
end_define

begin_define
define|#
directive|define
name|PVO_PTEGIDX_SET
parameter_list|(
name|pvo
parameter_list|,
name|i
parameter_list|)
define|\
value|((void)((pvo)->pvo_vaddr |= (i)|PVO_PTEGIDX_VALID))
end_define

begin_define
define|#
directive|define
name|MOEA_PVO_CHECK
parameter_list|(
name|pvo
parameter_list|)
end_define

begin_define
define|#
directive|define
name|LOCK_TABLE
parameter_list|()
value|mtx_lock(&moea64_table_mutex)
end_define

begin_define
define|#
directive|define
name|UNLOCK_TABLE
parameter_list|()
value|mtx_unlock(&moea64_table_mutex);
end_define

begin_define
define|#
directive|define
name|ASSERT_TABLE_LOCK
parameter_list|()
value|mtx_assert(&moea64_table_mutex, MA_OWNED)
end_define

begin_macro
unit|struct
name|ofw_map
end_macro

begin_block
block|{
name|vm_offset_t
name|om_va
decl_stmt|;
name|vm_size_t
name|om_len
decl_stmt|;
name|vm_offset_t
name|om_pa_hi
decl_stmt|;
name|vm_offset_t
name|om_pa_lo
decl_stmt|;
name|u_int
name|om_mode
decl_stmt|;
block|}
end_block

begin_empty_stmt
empty_stmt|;
end_empty_stmt

begin_comment
comment|/*  * Map of physical memory regions.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mem_region
modifier|*
name|regions
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mem_region
modifier|*
name|pregions
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|u_int
name|phys_avail_count
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|int
name|regions_sz
decl_stmt|,
name|pregions_sz
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|int
name|ofw_real_mode
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|ofw_map
name|translations
index|[
literal|64
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|struct
name|pmap
name|ofw_pmap
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|extern
name|void
name|bs_remap_earlyboot
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Lock for the pteg and pvo tables.  */
end_comment

begin_decl_stmt
name|struct
name|mtx
name|moea64_table_mutex
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * PTEG data.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|lpteg
modifier|*
name|moea64_pteg_table
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pteg_count
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pteg_mask
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * PVO data.  */
end_comment

begin_decl_stmt
name|struct
name|pvo_head
modifier|*
name|moea64_pvo_table
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* pvo entries by pteg index */
end_comment

begin_comment
comment|/* lists of unmanaged pages */
end_comment

begin_decl_stmt
name|struct
name|pvo_head
name|moea64_pvo_kunmanaged
init|=
name|LIST_HEAD_INITIALIZER
argument_list|(
name|moea64_pvo_kunmanaged
argument_list|)
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|pvo_head
name|moea64_pvo_unmanaged
init|=
name|LIST_HEAD_INITIALIZER
argument_list|(
name|moea64_pvo_unmanaged
argument_list|)
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uma_zone_t
name|moea64_upvo_zone
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* zone for pvo entries for unmanaged pages */
end_comment

begin_decl_stmt
name|uma_zone_t
name|moea64_mpvo_zone
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* zone for pvo entries for managed pages */
end_comment

begin_decl_stmt
name|vm_offset_t
name|pvo_allocator_start
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|pvo_allocator_end
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|BPVO_POOL_SIZE
value|327680
end_define

begin_decl_stmt
specifier|static
name|struct
name|pvo_entry
modifier|*
name|moea64_bpvo_pool
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|moea64_bpvo_pool_index
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|VSID_NBPW
value|(sizeof(u_int32_t) * 8)
end_define

begin_decl_stmt
specifier|static
name|u_int
name|moea64_vsid_bitmap
index|[
name|NPMAPS
operator|/
name|VSID_NBPW
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|boolean_t
name|moea64_initialized
init|=
name|FALSE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Statistics.  */
end_comment

begin_decl_stmt
name|u_int
name|moea64_pte_valid
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pte_overflow
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pvo_entries
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pvo_enter_calls
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pvo_remove_calls
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pte_valid
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pte_valid
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pte_overflow
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pte_overflow
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pvo_entries
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pvo_entries
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pvo_enter_calls
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pvo_enter_calls
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pvo_remove_calls
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pvo_remove_calls
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|vm_offset_t
name|moea64_scratchpage_va
index|[
literal|2
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|pvo_entry
modifier|*
name|moea64_scratchpage_pvo
index|[
literal|2
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|lpte
modifier|*
name|moea64_scratchpage_pte
index|[
literal|2
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mtx
name|moea64_scratchpage_mtx
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Allocate physical memory for use in moea64_bootstrap.  */
end_comment

begin_function_decl
specifier|static
name|vm_offset_t
name|moea64_bootstrap_alloc
parameter_list|(
name|vm_size_t
parameter_list|,
name|u_int
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * PTE calls.  */
end_comment

begin_function_decl
specifier|static
name|int
name|moea64_pte_insert
parameter_list|(
name|u_int
parameter_list|,
name|struct
name|lpte
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * PVO calls.  */
end_comment

begin_function_decl
specifier|static
name|int
name|moea64_pvo_enter
parameter_list|(
name|pmap_t
parameter_list|,
name|uma_zone_t
parameter_list|,
name|struct
name|pvo_head
modifier|*
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|uint64_t
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_pvo_remove
parameter_list|(
name|struct
name|pvo_entry
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|pvo_entry
modifier|*
name|moea64_pvo_find_va
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|int
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|lpte
modifier|*
name|moea64_pvo_to_pte
parameter_list|(
specifier|const
name|struct
name|pvo_entry
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Utility routines.  */
end_comment

begin_function_decl
specifier|static
name|void
name|moea64_bridge_bootstrap
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|vm_offset_t
name|kernelstart
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_bridge_cpu_bootstrap
parameter_list|(
name|mmu_t
parameter_list|,
name|int
name|ap
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_enter_locked
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|,
name|boolean_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|moea64_query_bit
parameter_list|(
name|vm_page_t
parameter_list|,
name|u_int64_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|u_int
name|moea64_clear_bit
parameter_list|(
name|vm_page_t
parameter_list|,
name|u_int64_t
parameter_list|,
name|u_int64_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_kremove
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_syncicache
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tlbia
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Kernel MMU interface  */
end_comment

begin_function_decl
name|void
name|moea64_change_wiring
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|boolean_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_clear_modify
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_clear_reference
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_copy_page
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_enter
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|,
name|boolean_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_enter_object
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_enter_quick
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_paddr_t
name|moea64_extract
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_page_t
name|moea64_extract_and_hold
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_init
parameter_list|(
name|mmu_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_is_modified
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_ts_referenced
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_offset_t
name|moea64_map
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
modifier|*
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_page_exists_quick
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|int
name|moea64_page_wired_mappings
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_pinit
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_pinit0
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_protect
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_qenter
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_qremove
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_release
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove_all
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove_write
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_zero_page
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_zero_page_area
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_zero_page_idle
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_activate
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_deactivate
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
modifier|*
name|moea64_mapdev
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_unmapdev
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_offset_t
name|moea64_kextract
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_kenter
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_dev_direct_mapped
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_page_executable
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
specifier|static
name|mmu_method_t
name|moea64_bridge_methods
index|[]
init|=
block|{
name|MMUMETHOD
argument_list|(
name|mmu_change_wiring
argument_list|,
name|moea64_change_wiring
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_clear_modify
argument_list|,
name|moea64_clear_modify
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_clear_reference
argument_list|,
name|moea64_clear_reference
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_copy_page
argument_list|,
name|moea64_copy_page
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter
argument_list|,
name|moea64_enter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter_object
argument_list|,
name|moea64_enter_object
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter_quick
argument_list|,
name|moea64_enter_quick
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_extract
argument_list|,
name|moea64_extract
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_extract_and_hold
argument_list|,
name|moea64_extract_and_hold
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_init
argument_list|,
name|moea64_init
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_is_modified
argument_list|,
name|moea64_is_modified
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_ts_referenced
argument_list|,
name|moea64_ts_referenced
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_map
argument_list|,
name|moea64_map
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_exists_quick
argument_list|,
name|moea64_page_exists_quick
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_wired_mappings
argument_list|,
name|moea64_page_wired_mappings
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_pinit
argument_list|,
name|moea64_pinit
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_pinit0
argument_list|,
name|moea64_pinit0
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_protect
argument_list|,
name|moea64_protect
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_qenter
argument_list|,
name|moea64_qenter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_qremove
argument_list|,
name|moea64_qremove
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_release
argument_list|,
name|moea64_release
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove
argument_list|,
name|moea64_remove
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove_all
argument_list|,
name|moea64_remove_all
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove_write
argument_list|,
name|moea64_remove_write
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page
argument_list|,
name|moea64_zero_page
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page_area
argument_list|,
name|moea64_zero_page_area
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page_idle
argument_list|,
name|moea64_zero_page_idle
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_activate
argument_list|,
name|moea64_activate
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_deactivate
argument_list|,
name|moea64_deactivate
argument_list|)
block|,
comment|/* Internal interfaces */
name|MMUMETHOD
argument_list|(
name|mmu_bootstrap
argument_list|,
name|moea64_bridge_bootstrap
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_cpu_bootstrap
argument_list|,
name|moea64_bridge_cpu_bootstrap
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_mapdev
argument_list|,
name|moea64_mapdev
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_unmapdev
argument_list|,
name|moea64_unmapdev
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_kextract
argument_list|,
name|moea64_kextract
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_kenter
argument_list|,
name|moea64_kenter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_dev_direct_mapped
argument_list|,
name|moea64_dev_direct_mapped
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_executable
argument_list|,
name|moea64_page_executable
argument_list|)
block|,
block|{
literal|0
block|,
literal|0
block|}
block|}
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|mmu_def_t
name|oea64_bridge_mmu
init|=
block|{
name|MMU_TYPE_G5
block|,
name|moea64_bridge_methods
block|,
literal|0
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|MMU_DEF
argument_list|(
name|oea64_bridge_mmu
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|__inline
name|u_int
name|va_to_pteg
parameter_list|(
name|uint64_t
name|vsid
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|u_int
name|hash
decl_stmt|;
name|hash
operator|=
name|vsid
operator|^
operator|(
operator|(
operator|(
name|uint64_t
operator|)
name|addr
operator|&
name|ADDR_PIDX
operator|)
operator|>>
name|ADDR_PIDX_SHFT
operator|)
expr_stmt|;
return|return
operator|(
name|hash
operator|&
name|moea64_pteg_mask
operator|)
return|;
block|}
end_function

begin_expr_stmt
specifier|static
name|__inline
expr|struct
name|pvo_head
operator|*
name|pa_to_pvoh
argument_list|(
argument|vm_offset_t pa
argument_list|,
argument|vm_page_t *pg_p
argument_list|)
block|{ 	struct
name|vm_page
operator|*
name|pg
block|;
name|pg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
block|;
if|if
condition|(
name|pg_p
operator|!=
name|NULL
condition|)
operator|*
name|pg_p
operator|=
name|pg
expr_stmt|;
end_expr_stmt

begin_if
if|if
condition|(
name|pg
operator|==
name|NULL
condition|)
return|return
operator|(
operator|&
name|moea64_pvo_unmanaged
operator|)
return|;
end_if

begin_return
return|return
operator|(
operator|&
name|pg
operator|->
name|md
operator|.
name|mdpg_pvoh
operator|)
return|;
end_return

begin_function
unit|}  static
name|__inline
name|struct
name|pvo_head
modifier|*
name|vm_page_to_pvoh
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
return|return
operator|(
operator|&
name|m
operator|->
name|md
operator|.
name|mdpg_pvoh
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|moea64_attr_clear
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|u_int64_t
name|ptebit
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|mdpg_attrs
operator|&=
operator|~
name|ptebit
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|u_int64_t
name|moea64_attr_fetch
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
return|return
operator|(
name|m
operator|->
name|md
operator|.
name|mdpg_attrs
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|moea64_attr_save
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|u_int64_t
name|ptebit
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|mdpg_attrs
operator||=
name|ptebit
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|moea64_pte_compare
parameter_list|(
specifier|const
name|struct
name|lpte
modifier|*
name|pt
parameter_list|,
specifier|const
name|struct
name|lpte
modifier|*
name|pvo_pt
parameter_list|)
block|{
if|if
condition|(
name|pt
operator|->
name|pte_hi
operator|==
name|pvo_pt
operator|->
name|pte_hi
condition|)
return|return
operator|(
literal|1
operator|)
return|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|moea64_pte_match
parameter_list|(
name|struct
name|lpte
modifier|*
name|pt
parameter_list|,
name|uint64_t
name|vsid
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|int
name|which
parameter_list|)
block|{
return|return
operator|(
name|pt
operator|->
name|pte_hi
operator|&
operator|~
name|LPTE_VALID
operator|)
operator|==
operator|(
operator|(
name|vsid
operator|<<
name|LPTE_VSID_SHIFT
operator|)
operator||
operator|(
call|(
name|uint64_t
call|)
argument_list|(
name|va
operator|>>
name|ADDR_API_SHFT64
argument_list|)
operator|&
name|LPTE_API
operator|)
operator||
name|which
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|moea64_pte_create
parameter_list|(
name|struct
name|lpte
modifier|*
name|pt
parameter_list|,
name|uint64_t
name|vsid
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|uint64_t
name|pte_lo
parameter_list|)
block|{
name|ASSERT_TABLE_LOCK
argument_list|()
expr_stmt|;
comment|/* 	 * Construct a PTE.  Default to IMB initially.  Valid bit only gets 	 * set when the real pte is set in memory. 	 * 	 * Note: Don't set the valid bit for correct operation of tlb update. 	 */
name|pt
operator|->
name|pte_hi
operator|=
operator|(
name|vsid
operator|<<
name|LPTE_VSID_SHIFT
operator|)
operator||
operator|(
operator|(
call|(
name|uint64_t
call|)
argument_list|(
name|va
operator|&
name|ADDR_PIDX
argument_list|)
operator|>>
name|ADDR_API_SHFT64
operator|)
operator|&
name|LPTE_API
operator|)
expr_stmt|;
name|pt
operator|->
name|pte_lo
operator|=
name|pte_lo
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|moea64_pte_synch
parameter_list|(
name|struct
name|lpte
modifier|*
name|pt
parameter_list|,
name|struct
name|lpte
modifier|*
name|pvo_pt
parameter_list|)
block|{
name|ASSERT_TABLE_LOCK
argument_list|()
expr_stmt|;
name|pvo_pt
operator|->
name|pte_lo
operator||=
name|pt
operator|->
name|pte_lo
operator|&
operator|(
name|LPTE_REF
operator||
name|LPTE_CHG
operator|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|moea64_pte_clear
parameter_list|(
name|struct
name|lpte
modifier|*
name|pt
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|u_int64_t
name|ptebit
parameter_list|)
block|{
name|ASSERT_TABLE_LOCK
argument_list|()
expr_stmt|;
comment|/* 	 * As shown in Section 7.6.3.2.3 	 */
name|pt
operator|->
name|pte_lo
operator|&=
operator|~
name|ptebit
expr_stmt|;
name|TLBIE
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|moea64_pte_set
parameter_list|(
name|struct
name|lpte
modifier|*
name|pt
parameter_list|,
name|struct
name|lpte
modifier|*
name|pvo_pt
parameter_list|)
block|{
name|ASSERT_TABLE_LOCK
argument_list|()
expr_stmt|;
name|pvo_pt
operator|->
name|pte_hi
operator||=
name|LPTE_VALID
expr_stmt|;
comment|/* 	 * Update the PTE as defined in section 7.6.3.1. 	 * Note that the REF/CHG bits are from pvo_pt and thus should have 	 * been saved so this routine can restore them (if desired). 	 */
name|pt
operator|->
name|pte_lo
operator|=
name|pvo_pt
operator|->
name|pte_lo
expr_stmt|;
name|EIEIO
argument_list|()
expr_stmt|;
name|pt
operator|->
name|pte_hi
operator|=
name|pvo_pt
operator|->
name|pte_hi
expr_stmt|;
name|SYNC
argument_list|()
expr_stmt|;
name|moea64_pte_valid
operator|++
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|moea64_pte_unset
parameter_list|(
name|struct
name|lpte
modifier|*
name|pt
parameter_list|,
name|struct
name|lpte
modifier|*
name|pvo_pt
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|ASSERT_TABLE_LOCK
argument_list|()
expr_stmt|;
name|pvo_pt
operator|->
name|pte_hi
operator|&=
operator|~
name|LPTE_VALID
expr_stmt|;
comment|/* 	 * Force the reg& chg bits back into the PTEs. 	 */
name|SYNC
argument_list|()
expr_stmt|;
comment|/* 	 * Invalidate the pte. 	 */
name|pt
operator|->
name|pte_hi
operator|&=
operator|~
name|LPTE_VALID
expr_stmt|;
name|TLBIE
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * Save the reg& chg bits. 	 */
name|moea64_pte_synch
argument_list|(
name|pt
argument_list|,
name|pvo_pt
argument_list|)
expr_stmt|;
name|moea64_pte_valid
operator|--
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|moea64_pte_change
parameter_list|(
name|struct
name|lpte
modifier|*
name|pt
parameter_list|,
name|struct
name|lpte
modifier|*
name|pvo_pt
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
comment|/* 	 * Invalidate the PTE 	 */
name|moea64_pte_unset
argument_list|(
name|pt
argument_list|,
name|pvo_pt
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|moea64_pte_set
argument_list|(
name|pt
argument_list|,
name|pvo_pt
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|uint64_t
name|moea64_calc_wimg
parameter_list|(
name|vm_offset_t
name|pa
parameter_list|)
block|{
name|uint64_t
name|pte_lo
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * Assume the page is cache inhibited and access is guarded unless 	 * it's in our available memory array. 	 */
name|pte_lo
operator|=
name|LPTE_I
operator||
name|LPTE_G
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pregions_sz
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|pa
operator|>=
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
operator|)
operator|&&
operator|(
name|pa
operator|<
operator|(
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|pregions
index|[
name|i
index|]
operator|.
name|mr_size
operator|)
operator|)
condition|)
block|{
name|pte_lo
operator|&=
operator|~
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator|)
expr_stmt|;
name|pte_lo
operator||=
name|LPTE_M
expr_stmt|;
break|break;
block|}
block|}
return|return
name|pte_lo
return|;
block|}
end_function

begin_comment
comment|/*  * Quick sort callout for comparing memory regions.  */
end_comment

begin_function_decl
specifier|static
name|int
name|mr_cmp
parameter_list|(
specifier|const
name|void
modifier|*
name|a
parameter_list|,
specifier|const
name|void
modifier|*
name|b
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|om_cmp
parameter_list|(
specifier|const
name|void
modifier|*
name|a
parameter_list|,
specifier|const
name|void
modifier|*
name|b
parameter_list|)
function_decl|;
end_function_decl

begin_function
specifier|static
name|int
name|mr_cmp
parameter_list|(
specifier|const
name|void
modifier|*
name|a
parameter_list|,
specifier|const
name|void
modifier|*
name|b
parameter_list|)
block|{
specifier|const
name|struct
name|mem_region
modifier|*
name|regiona
decl_stmt|;
specifier|const
name|struct
name|mem_region
modifier|*
name|regionb
decl_stmt|;
name|regiona
operator|=
name|a
expr_stmt|;
name|regionb
operator|=
name|b
expr_stmt|;
if|if
condition|(
name|regiona
operator|->
name|mr_start
operator|<
name|regionb
operator|->
name|mr_start
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
elseif|else
if|if
condition|(
name|regiona
operator|->
name|mr_start
operator|>
name|regionb
operator|->
name|mr_start
condition|)
return|return
operator|(
literal|1
operator|)
return|;
else|else
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|om_cmp
parameter_list|(
specifier|const
name|void
modifier|*
name|a
parameter_list|,
specifier|const
name|void
modifier|*
name|b
parameter_list|)
block|{
specifier|const
name|struct
name|ofw_map
modifier|*
name|mapa
decl_stmt|;
specifier|const
name|struct
name|ofw_map
modifier|*
name|mapb
decl_stmt|;
name|mapa
operator|=
name|a
expr_stmt|;
name|mapb
operator|=
name|b
expr_stmt|;
if|if
condition|(
name|mapa
operator|->
name|om_pa_hi
operator|<
name|mapb
operator|->
name|om_pa_hi
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
elseif|else
if|if
condition|(
name|mapa
operator|->
name|om_pa_hi
operator|>
name|mapb
operator|->
name|om_pa_hi
condition|)
return|return
operator|(
literal|1
operator|)
return|;
elseif|else
if|if
condition|(
name|mapa
operator|->
name|om_pa_lo
operator|<
name|mapb
operator|->
name|om_pa_lo
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
elseif|else
if|if
condition|(
name|mapa
operator|->
name|om_pa_lo
operator|>
name|mapb
operator|->
name|om_pa_lo
condition|)
return|return
operator|(
literal|1
operator|)
return|;
else|else
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_bridge_cpu_bootstrap
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|int
name|ap
parameter_list|)
block|{
name|int
name|i
init|=
literal|0
decl_stmt|;
comment|/* 	 * Initialize segment registers and MMU 	 */
name|mtmsr
argument_list|(
name|mfmsr
argument_list|()
operator|&
operator|~
name|PSL_DR
operator|&
operator|~
name|PSL_IR
argument_list|)
expr_stmt|;
name|isync
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|16
condition|;
name|i
operator|++
control|)
block|{
name|mtsrin
argument_list|(
name|i
operator|<<
name|ADDR_SR_SHFT
argument_list|,
name|kernel_pmap
operator|->
name|pm_sr
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
asm|__asm __volatile ("sync; mtsdr1 %0; isync"
operator|::
literal|"r"
operator|(
operator|(
name|u_int
operator|)
name|moea64_pteg_table
operator||
operator|(
literal|32
operator|-
name|cntlzw
argument_list|(
name|moea64_pteg_mask
operator|>>
literal|11
argument_list|)
operator|)
operator|)
block|)
function|;
end_function

begin_expr_stmt
name|tlbia
argument_list|()
expr_stmt|;
end_expr_stmt

begin_function
unit|}  static
name|void
name|moea64_bridge_bootstrap
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|vm_offset_t
name|kernelstart
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
block|{
name|ihandle_t
name|mmui
decl_stmt|;
name|phandle_t
name|chosen
decl_stmt|;
name|phandle_t
name|mmu
decl_stmt|;
name|int
name|sz
decl_stmt|;
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
name|int
name|ofw_mappings
decl_stmt|;
name|vm_size_t
name|size
decl_stmt|,
name|physsz
decl_stmt|,
name|hwphyssz
decl_stmt|;
name|vm_offset_t
name|pa
decl_stmt|,
name|va
decl_stmt|,
name|off
decl_stmt|;
name|uint32_t
name|msr
decl_stmt|;
name|void
modifier|*
name|dpcpu
decl_stmt|;
comment|/* We don't have a direct map since there is no BAT */
name|hw_direct_map
operator|=
literal|0
expr_stmt|;
comment|/* Make sure battable is zero, since we have no BAT */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|16
condition|;
name|i
operator|++
control|)
block|{
name|battable
index|[
name|i
index|]
operator|.
name|batu
operator|=
literal|0
expr_stmt|;
name|battable
index|[
name|i
index|]
operator|.
name|batl
operator|=
literal|0
expr_stmt|;
block|}
comment|/* Get physical memory regions from firmware */
name|mem_regions
argument_list|(
operator|&
name|pregions
argument_list|,
operator|&
name|pregions_sz
argument_list|,
operator|&
name|regions
argument_list|,
operator|&
name|regions_sz
argument_list|)
expr_stmt|;
name|CTR0
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_bootstrap: physical memory"
argument_list|)
expr_stmt|;
name|qsort
argument_list|(
name|pregions
argument_list|,
name|pregions_sz
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|pregions
argument_list|)
argument_list|,
name|mr_cmp
argument_list|)
expr_stmt|;
if|if
condition|(
sizeof|sizeof
argument_list|(
name|phys_avail
argument_list|)
operator|/
sizeof|sizeof
argument_list|(
name|phys_avail
index|[
literal|0
index|]
argument_list|)
operator|<
name|regions_sz
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: phys_avail too small"
argument_list|)
expr_stmt|;
name|qsort
argument_list|(
name|regions
argument_list|,
name|regions_sz
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|regions
argument_list|)
argument_list|,
name|mr_cmp
argument_list|)
expr_stmt|;
name|phys_avail_count
operator|=
literal|0
expr_stmt|;
name|physsz
operator|=
literal|0
expr_stmt|;
name|hwphyssz
operator|=
literal|0
expr_stmt|;
name|TUNABLE_ULONG_FETCH
argument_list|(
literal|"hw.physmem"
argument_list|,
operator|(
name|u_long
operator|*
operator|)
operator|&
name|hwphyssz
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
operator|,
name|j
operator|=
literal|0
init|;
name|i
operator|<
name|regions_sz
condition|;
name|i
operator|++
operator|,
name|j
operator|+=
literal|2
control|)
block|{
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"region: %#x - %#x (%#x)"
argument_list|,
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
argument_list|,
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
argument_list|,
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
argument_list|)
expr_stmt|;
if|if
condition|(
name|hwphyssz
operator|!=
literal|0
operator|&&
operator|(
name|physsz
operator|+
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
operator|)
operator|>=
name|hwphyssz
condition|)
block|{
if|if
condition|(
name|physsz
operator|<
name|hwphyssz
condition|)
block|{
name|phys_avail
index|[
name|j
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|hwphyssz
operator|-
name|physsz
expr_stmt|;
name|physsz
operator|=
name|hwphyssz
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
break|break;
block|}
name|phys_avail
index|[
name|j
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
name|physsz
operator|+=
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
expr_stmt|;
block|}
name|physmem
operator|=
name|btoc
argument_list|(
name|physsz
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate PTEG table. 	 */
ifdef|#
directive|ifdef
name|PTEGCOUNT
name|moea64_pteg_count
operator|=
name|PTEGCOUNT
expr_stmt|;
else|#
directive|else
name|moea64_pteg_count
operator|=
literal|0x1000
expr_stmt|;
while|while
condition|(
name|moea64_pteg_count
operator|<
name|physmem
condition|)
name|moea64_pteg_count
operator|<<=
literal|1
expr_stmt|;
name|moea64_pteg_count
operator|>>=
literal|1
expr_stmt|;
endif|#
directive|endif
comment|/* PTEGCOUNT */
name|size
operator|=
name|moea64_pteg_count
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|lpteg
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_bootstrap: %d PTEGs, %d bytes"
argument_list|,
name|moea64_pteg_count
argument_list|,
name|size
argument_list|)
expr_stmt|;
comment|/* 	 * We now need to allocate memory. This memory, to be allocated, 	 * has to reside in a page table. The page table we are about to 	 * allocate. We don't have BAT. So drop to data real mode for a minute 	 * as a measure of last resort. We do this a couple times. 	 */
name|moea64_pteg_table
operator|=
operator|(
expr|struct
name|lpteg
operator|*
operator|)
name|moea64_bootstrap_alloc
argument_list|(
name|size
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|DISABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|moea64_pteg_table
argument_list|,
name|moea64_pteg_count
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|lpteg
argument_list|)
argument_list|)
expr_stmt|;
name|ENABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
name|moea64_pteg_mask
operator|=
name|moea64_pteg_count
operator|-
literal|1
expr_stmt|;
name|CTR1
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_bootstrap: PTEG table at %p"
argument_list|,
name|moea64_pteg_table
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate pv/overflow lists. 	 */
name|size
operator|=
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_head
argument_list|)
operator|*
name|moea64_pteg_count
expr_stmt|;
name|moea64_pvo_table
operator|=
operator|(
expr|struct
name|pvo_head
operator|*
operator|)
name|moea64_bootstrap_alloc
argument_list|(
name|size
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|CTR1
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_bootstrap: PVO table at %p"
argument_list|,
name|moea64_pvo_table
argument_list|)
expr_stmt|;
name|DISABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|moea64_pteg_count
condition|;
name|i
operator|++
control|)
name|LIST_INIT
argument_list|(
operator|&
name|moea64_pvo_table
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|ENABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the lock that synchronizes access to the pteg and pvo 	 * tables. 	 */
name|mtx_init
argument_list|(
operator|&
name|moea64_table_mutex
argument_list|,
literal|"pmap table"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
operator||
name|MTX_RECURSE
argument_list|)
expr_stmt|;
comment|/* 	 * Initialise the unmanaged pvo pool. 	 */
name|moea64_bpvo_pool
operator|=
operator|(
expr|struct
name|pvo_entry
operator|*
operator|)
name|moea64_bootstrap_alloc
argument_list|(
name|BPVO_POOL_SIZE
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|moea64_bpvo_pool_index
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Make sure kernel vsid is allocated as well as VSID 0. 	 */
name|moea64_vsid_bitmap
index|[
operator|(
name|KERNEL_VSIDBITS
operator|&
operator|(
name|NPMAPS
operator|-
literal|1
operator|)
operator|)
operator|/
name|VSID_NBPW
index|]
operator||=
literal|1
operator|<<
operator|(
name|KERNEL_VSIDBITS
operator|%
name|VSID_NBPW
operator|)
expr_stmt|;
name|moea64_vsid_bitmap
index|[
literal|0
index|]
operator||=
literal|1
expr_stmt|;
comment|/* 	 * Initialize the kernel pmap (which is statically allocated). 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|16
condition|;
name|i
operator|++
control|)
name|kernel_pmap
operator|->
name|pm_sr
index|[
name|i
index|]
operator|=
name|EMPTY_SEGMENT
operator|+
name|i
expr_stmt|;
name|kernel_pmap
operator|->
name|pmap_phys
operator|=
name|kernel_pmap
expr_stmt|;
name|kernel_pmap
operator|->
name|pm_active
operator|=
operator|~
literal|0
expr_stmt|;
name|PMAP_LOCK_INIT
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Now map in all the other buffers we allocated earlier 	 */
name|DISABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
name|size
operator|=
name|moea64_pteg_count
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|lpteg
argument_list|)
expr_stmt|;
name|off
operator|=
call|(
name|vm_offset_t
call|)
argument_list|(
name|moea64_pteg_table
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|off
init|;
name|pa
operator|<
name|off
operator|+
name|size
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|size
operator|=
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_head
argument_list|)
operator|*
name|moea64_pteg_count
expr_stmt|;
name|off
operator|=
call|(
name|vm_offset_t
call|)
argument_list|(
name|moea64_pvo_table
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|off
init|;
name|pa
operator|<
name|off
operator|+
name|size
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|size
operator|=
name|BPVO_POOL_SIZE
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
expr_stmt|;
name|off
operator|=
call|(
name|vm_offset_t
call|)
argument_list|(
name|moea64_bpvo_pool
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|off
init|;
name|pa
operator|<
name|off
operator|+
name|size
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|ENABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
comment|/* 	 * Map certain important things, like ourselves and the exception 	 * vectors 	 */
name|DISABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|kernelstart
operator|&
operator|~
name|PAGE_MASK
init|;
name|pa
operator|<
name|kernelend
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|EXC_RSVD
init|;
name|pa
operator|<
name|EXC_LAST
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|ENABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|ofw_real_mode
condition|)
block|{
comment|/* 	     * Set up the Open Firmware pmap and add its mappings. 	     */
name|moea64_pinit
argument_list|(
name|mmup
argument_list|,
operator|&
name|ofw_pmap
argument_list|)
expr_stmt|;
name|ofw_pmap
operator|.
name|pm_sr
index|[
name|KERNEL_SR
index|]
operator|=
name|kernel_pmap
operator|->
name|pm_sr
index|[
name|KERNEL_SR
index|]
expr_stmt|;
name|ofw_pmap
operator|.
name|pm_sr
index|[
name|KERNEL2_SR
index|]
operator|=
name|kernel_pmap
operator|->
name|pm_sr
index|[
name|KERNEL2_SR
index|]
expr_stmt|;
if|if
condition|(
operator|(
name|chosen
operator|=
name|OF_finddevice
argument_list|(
literal|"/chosen"
argument_list|)
operator|)
operator|==
operator|-
literal|1
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: can't find /chosen"
argument_list|)
expr_stmt|;
name|OF_getprop
argument_list|(
name|chosen
argument_list|,
literal|"mmu"
argument_list|,
operator|&
name|mmui
argument_list|,
literal|4
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|mmu
operator|=
name|OF_instance_to_package
argument_list|(
name|mmui
argument_list|)
operator|)
operator|==
operator|-
literal|1
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: can't get mmu package"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|sz
operator|=
name|OF_getproplen
argument_list|(
name|mmu
argument_list|,
literal|"translations"
argument_list|)
operator|)
operator|==
operator|-
literal|1
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: can't get ofw translation count"
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
name|translations
argument_list|,
name|sz
argument_list|)
expr_stmt|;
if|if
condition|(
name|OF_getprop
argument_list|(
name|mmu
argument_list|,
literal|"translations"
argument_list|,
name|translations
argument_list|,
name|sz
argument_list|)
operator|==
operator|-
literal|1
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: can't get ofw translations"
argument_list|)
expr_stmt|;
name|CTR0
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_bootstrap: translations"
argument_list|)
expr_stmt|;
name|sz
operator|/=
sizeof|sizeof
argument_list|(
operator|*
name|translations
argument_list|)
expr_stmt|;
name|qsort
argument_list|(
name|translations
argument_list|,
name|sz
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|translations
argument_list|)
argument_list|,
name|om_cmp
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
operator|,
name|ofw_mappings
operator|=
literal|0
init|;
name|i
operator|<
name|sz
condition|;
name|i
operator|++
control|)
block|{
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"translation: pa=%#x va=%#x len=%#x"
argument_list|,
call|(
name|uint32_t
call|)
argument_list|(
name|translations
index|[
name|i
index|]
operator|.
name|om_pa_lo
argument_list|)
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_va
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_len
argument_list|)
expr_stmt|;
if|if
condition|(
name|translations
index|[
name|i
index|]
operator|.
name|om_pa_lo
operator|%
name|PAGE_SIZE
condition|)
name|panic
argument_list|(
literal|"OFW translation not page-aligned!"
argument_list|)
expr_stmt|;
if|if
condition|(
name|translations
index|[
name|i
index|]
operator|.
name|om_pa_hi
condition|)
name|panic
argument_list|(
literal|"OFW translations above 32-bit boundary!"
argument_list|)
expr_stmt|;
comment|/* Now enter the pages for this mapping */
comment|/* 		 * Lock the ofw pmap. pmap_kenter(), which we use for the 		 * pages the kernel also needs, does its own locking. 		 */
name|PMAP_LOCK
argument_list|(
operator|&
name|ofw_pmap
argument_list|)
expr_stmt|;
name|DISABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
for|for
control|(
name|off
operator|=
literal|0
init|;
name|off
operator|<
name|translations
index|[
name|i
index|]
operator|.
name|om_len
condition|;
name|off
operator|+=
name|PAGE_SIZE
control|)
block|{
name|struct
name|vm_page
name|m
decl_stmt|;
comment|/* Map low memory mappings into the kernel pmap, too. 			 * These are typically mappings made by the loader, 			 * so we need them if we want to keep executing. */
if|if
condition|(
name|translations
index|[
name|i
index|]
operator|.
name|om_va
operator|+
name|off
operator|<
name|SEGMENT_LENGTH
condition|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_va
operator|+
name|off
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_va
operator|+
name|off
argument_list|)
expr_stmt|;
name|m
operator|.
name|phys_addr
operator|=
name|translations
index|[
name|i
index|]
operator|.
name|om_pa_lo
operator|+
name|off
expr_stmt|;
name|moea64_enter_locked
argument_list|(
operator|&
name|ofw_pmap
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_va
operator|+
name|off
argument_list|,
operator|&
name|m
argument_list|,
name|VM_PROT_ALL
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|ofw_mappings
operator|++
expr_stmt|;
block|}
name|ENABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
operator|&
name|ofw_pmap
argument_list|)
expr_stmt|;
block|}
block|}
ifdef|#
directive|ifdef
name|SMP
name|TLBSYNC
argument_list|()
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Calculate the last available physical address. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|2
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
empty_stmt|;
name|Maxmem
operator|=
name|powerpc_btop
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize MMU and remap early physical mappings 	 */
name|moea64_bridge_cpu_bootstrap
argument_list|(
name|mmup
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|mtmsr
argument_list|(
name|mfmsr
argument_list|()
operator||
name|PSL_DR
operator||
name|PSL_IR
argument_list|)
expr_stmt|;
name|isync
argument_list|()
expr_stmt|;
name|pmap_bootstrapped
operator|++
expr_stmt|;
name|bs_remap_earlyboot
argument_list|()
expr_stmt|;
comment|/* 	 * Set the start and end of kva. 	 */
name|virtual_avail
operator|=
name|VM_MIN_KERNEL_ADDRESS
expr_stmt|;
name|virtual_end
operator|=
name|VM_MAX_KERNEL_ADDRESS
expr_stmt|;
comment|/* 	 * Allocate some stupid buffer regions. 	 */
name|pvo_allocator_start
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|SEGMENT_LENGTH
operator|/
literal|4
expr_stmt|;
name|pvo_allocator_end
operator|=
name|virtual_avail
expr_stmt|;
comment|/* 	 * Allocate some things for page zeroing 	 */
name|mtx_init
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|,
literal|"pvo zero page"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|2
condition|;
name|i
operator|++
control|)
block|{
name|moea64_scratchpage_va
index|[
name|i
index|]
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|moea64_scratchpage_va
index|[
name|i
index|]
argument_list|,
name|kernelstart
argument_list|)
expr_stmt|;
name|LOCK_TABLE
argument_list|()
expr_stmt|;
name|moea64_scratchpage_pvo
index|[
name|i
index|]
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|moea64_scratchpage_va
index|[
name|i
index|]
argument_list|,
operator|&
name|j
argument_list|)
expr_stmt|;
name|moea64_scratchpage_pte
index|[
name|i
index|]
operator|=
name|moea64_pvo_to_pte
argument_list|(
name|moea64_scratchpage_pvo
index|[
name|i
index|]
argument_list|,
name|j
argument_list|)
expr_stmt|;
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
block|}
comment|/* 	 * Allocate a kernel stack with a guard page for thread0 and map it 	 * into the kernel page map. 	 */
name|pa
operator|=
name|moea64_bootstrap_alloc
argument_list|(
name|KSTACK_PAGES
operator|*
name|PAGE_SIZE
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|va
operator|=
name|virtual_avail
operator|+
name|KSTACK_GUARD_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
name|virtual_avail
operator|=
name|va
operator|+
name|KSTACK_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea_bootstrap: kstack0 at %#x (%#x)"
argument_list|,
name|pa
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|thread0
operator|.
name|td_kstack
operator|=
name|va
expr_stmt|;
name|thread0
operator|.
name|td_kstack_pages
operator|=
name|KSTACK_PAGES
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|KSTACK_PAGES
condition|;
name|i
operator|++
control|)
block|{
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
empty_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* 	 * Allocate virtual address space for the message buffer. 	 */
name|pa
operator|=
name|msgbuf_phys
operator|=
name|moea64_bootstrap_alloc
argument_list|(
name|MSGBUF_SIZE
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|msgbufp
operator|=
operator|(
expr|struct
name|msgbuf
operator|*
operator|)
name|virtual_avail
expr_stmt|;
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|round_page
argument_list|(
name|MSGBUF_SIZE
argument_list|)
expr_stmt|;
while|while
condition|(
name|va
operator|<
name|virtual_avail
condition|)
block|{
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
empty_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* 	 * Allocate virtual address space for the dynamic percpu area. 	 */
name|pa
operator|=
name|moea64_bootstrap_alloc
argument_list|(
name|DPCPU_SIZE
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|dpcpu
operator|=
operator|(
name|void
operator|*
operator|)
name|virtual_avail
expr_stmt|;
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|DPCPU_SIZE
expr_stmt|;
while|while
condition|(
name|va
operator|<
name|virtual_avail
condition|)
block|{
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
empty_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|dpcpu_init
argument_list|(
name|dpcpu
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Activate a user pmap.  The pmap must be activated before it's address  * space can be accessed in any way.  */
end_comment

begin_function
name|void
name|moea64_activate
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|pm
decl_stmt|,
name|pmr
decl_stmt|;
comment|/* 	 * Load all the data we need up front to encourage the compiler to 	 * not issue any loads while we have interrupts disabled below. 	 */
name|pm
operator|=
operator|&
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
expr_stmt|;
name|pmr
operator|=
name|pm
operator|->
name|pmap_phys
expr_stmt|;
name|pm
operator|->
name|pm_active
operator||=
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pmr
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_deactivate
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|pm
decl_stmt|;
name|pm
operator|=
operator|&
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
expr_stmt|;
name|pm
operator|->
name|pm_active
operator|&=
operator|~
operator|(
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
operator|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_change_wiring
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|boolean_t
name|wired
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pm
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|wired
condition|)
block|{
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
operator|)
operator|==
literal|0
condition|)
name|pm
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_WIRED
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
operator|)
operator|!=
literal|0
condition|)
name|pm
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator|&=
operator|~
name|PVO_WIRED
expr_stmt|;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Zero a page of physical memory by temporarily mapping it into the tlb.  */
end_comment

begin_function
name|void
name|moea64_zero_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|moea64_zero_page_area
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
literal|0
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This goes through and sets the physical address of our  * special scratch PTE to the PA we want to zero or copy. Because  * of locking issues (this can get called in pvo_enter() by  * the UMA allocator), we can't use most other utility functions here  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|moea64_set_scratchpage_pa
parameter_list|(
name|int
name|which
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|)
block|{
name|moea64_scratchpage_pvo
index|[
name|which
index|]
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|(
operator|~
name|LPTE_WIMG
operator|&
operator|~
name|LPTE_RPGN
operator|)
expr_stmt|;
name|moea64_scratchpage_pvo
index|[
name|which
index|]
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator||=
name|moea64_calc_wimg
argument_list|(
name|pa
argument_list|)
operator||
operator|(
name|uint64_t
operator|)
name|pa
expr_stmt|;
name|moea64_scratchpage_pte
index|[
name|which
index|]
operator|->
name|pte_hi
operator|&=
operator|~
name|LPTE_VALID
expr_stmt|;
name|TLBIE
argument_list|(
name|kernel_pmap
argument_list|,
name|moea64_scratchpage_va
index|[
name|which
index|]
argument_list|)
expr_stmt|;
name|moea64_scratchpage_pte
index|[
name|which
index|]
operator|->
name|pte_lo
operator|=
name|moea64_scratchpage_pvo
index|[
name|which
index|]
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
expr_stmt|;
name|EIEIO
argument_list|()
expr_stmt|;
name|moea64_scratchpage_pte
index|[
name|which
index|]
operator|->
name|pte_hi
operator||=
name|LPTE_VALID
expr_stmt|;
name|TLBIE
argument_list|(
name|kernel_pmap
argument_list|,
name|moea64_scratchpage_va
index|[
name|which
index|]
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_copy_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|msrc
parameter_list|,
name|vm_page_t
name|mdst
parameter_list|)
block|{
name|vm_offset_t
name|dst
decl_stmt|;
name|vm_offset_t
name|src
decl_stmt|;
name|dst
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|mdst
argument_list|)
expr_stmt|;
name|src
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|msrc
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
literal|0
argument_list|,
name|src
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
literal|1
argument_list|,
name|dst
argument_list|)
expr_stmt|;
name|kcopy
argument_list|(
operator|(
name|void
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|0
index|]
argument_list|,
operator|(
name|void
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|1
index|]
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|1
index|]
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_zero_page_area
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_offset_t
name|pa
init|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|moea64_initialized
condition|)
name|panic
argument_list|(
literal|"moea64_zero_page: can't zero pa %#x"
argument_list|,
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|+
name|off
operator|>
name|PAGE_SIZE
condition|)
name|panic
argument_list|(
literal|"moea64_zero_page: size + off> PAGE_SIZE"
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
literal|0
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|moea64_scratchpage_va
index|[
literal|0
index|]
operator|+
name|off
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|0
index|]
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_zero_page_idle
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|moea64_zero_page
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map the given physical page at the specified virtual address in the  * target pmap with the protection requested.  If specified the page  * will be wired down.  */
end_comment

begin_function
name|void
name|moea64_enter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|boolean_t
name|wired
parameter_list|)
block|{
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|moea64_enter_locked
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map the given physical page at the specified virtual address in the  * target pmap with the protection requested.  If specified the page  * will be wired down.  *  * The page queues and pmap must be locked.  */
end_comment

begin_function
specifier|static
name|void
name|moea64_enter_locked
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|boolean_t
name|wired
parameter_list|)
block|{
name|struct
name|pvo_head
modifier|*
name|pvo_head
decl_stmt|;
name|uma_zone_t
name|zone
decl_stmt|;
name|vm_page_t
name|pg
decl_stmt|;
name|uint64_t
name|pte_lo
decl_stmt|;
name|u_int
name|pvo_flags
decl_stmt|;
name|int
name|error
decl_stmt|;
if|if
condition|(
operator|!
name|moea64_initialized
condition|)
block|{
name|pvo_head
operator|=
operator|&
name|moea64_pvo_kunmanaged
expr_stmt|;
name|pg
operator|=
name|NULL
expr_stmt|;
name|zone
operator|=
name|moea64_upvo_zone
expr_stmt|;
name|pvo_flags
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
name|pvo_head
operator|=
name|vm_page_to_pvoh
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pg
operator|=
name|m
expr_stmt|;
name|zone
operator|=
name|moea64_mpvo_zone
expr_stmt|;
name|pvo_flags
operator|=
name|PVO_MANAGED
expr_stmt|;
block|}
if|if
condition|(
name|pmap_bootstrapped
condition|)
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* XXX change the pvo head for fake pages */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
name|PG_FICTITIOUS
condition|)
block|{
name|pvo_flags
operator|&=
operator|~
name|PVO_MANAGED
expr_stmt|;
name|pvo_head
operator|=
operator|&
name|moea64_pvo_kunmanaged
expr_stmt|;
name|zone
operator|=
name|moea64_upvo_zone
expr_stmt|;
block|}
name|pte_lo
operator|=
name|moea64_calc_wimg
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
block|{
name|pte_lo
operator||=
name|LPTE_BW
expr_stmt|;
if|if
condition|(
name|pmap_bootstrapped
condition|)
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_WRITEABLE
argument_list|)
expr_stmt|;
block|}
else|else
name|pte_lo
operator||=
name|LPTE_BR
expr_stmt|;
if|if
condition|(
name|prot
operator|&
name|VM_PROT_EXECUTE
condition|)
name|pvo_flags
operator||=
name|VM_PROT_EXECUTE
expr_stmt|;
if|if
condition|(
name|wired
condition|)
name|pvo_flags
operator||=
name|PVO_WIRED
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
name|pvo_flags
operator||=
name|PVO_FAKE
expr_stmt|;
name|error
operator|=
name|moea64_pvo_enter
argument_list|(
name|pmap
argument_list|,
name|zone
argument_list|,
name|pvo_head
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|pte_lo
argument_list|,
name|pvo_flags
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|TLBIE
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * Flush the page from the instruction cache if this page is 	 * mapped executable and cacheable. 	 */
if|if
condition|(
operator|(
name|pte_lo
operator|&
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator||
name|LPTE_NOEXEC
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|moea64_syncicache
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_syncicache
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|)
block|{
comment|/* 	 * This is much trickier than on older systems because 	 * we can't sync the icache on physical addresses directly 	 * without a direct map. Instead we check a couple of cases 	 * where the memory is already mapped in and, failing that, 	 * use the same trick we use for page zeroing to create 	 * a temporary mapping for this physical address. 	 */
if|if
condition|(
operator|!
name|pmap_bootstrapped
condition|)
block|{
comment|/* 		 * If PMAP is not bootstrapped, we are likely to be 		 * in real mode. 		 */
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|pa
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Use the scratch page to set up a temp mapping */
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
literal|1
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|1
index|]
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Maps a sequence of resident pages belonging to the same object.  * The sequence begins with the given page m_start.  This page is  * mapped at the given virtual address start.  Each subsequent page is  * mapped at a virtual address that is offset from start by the same  * amount as the page is offset from m_start within the object.  The  * last page in the sequence is the page with the largest offset from  * m_start that can be mapped at a virtual address less than the given  * virtual address end.  Not every virtual page between start and end  * is mapped; only those for which a resident page exists with the  * corresponding offset from m_start are mapped.  */
end_comment

begin_function
name|void
name|moea64_enter_object
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|start
parameter_list|,
name|vm_offset_t
name|end
parameter_list|,
name|vm_page_t
name|m_start
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_pindex_t
name|diff
decl_stmt|,
name|psize
decl_stmt|;
name|psize
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|m
operator|=
name|m_start
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
while|while
condition|(
name|m
operator|!=
name|NULL
operator|&&
operator|(
name|diff
operator|=
name|m
operator|->
name|pindex
operator|-
name|m_start
operator|->
name|pindex
operator|)
operator|<
name|psize
condition|)
block|{
name|moea64_enter_locked
argument_list|(
name|pm
argument_list|,
name|start
operator|+
name|ptoa
argument_list|(
name|diff
argument_list|)
argument_list|,
name|m
argument_list|,
name|prot
operator|&
operator|(
name|VM_PROT_READ
operator||
name|VM_PROT_EXECUTE
operator|)
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|m
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_enter_quick
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|moea64_enter_locked
argument_list|(
name|pm
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
operator|&
operator|(
name|VM_PROT_READ
operator||
name|VM_PROT_EXECUTE
operator|)
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|vm_paddr_t
name|moea64_extract
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pm
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|==
name|NULL
condition|)
name|pa
operator|=
literal|0
expr_stmt|;
else|else
name|pa
operator|=
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
operator|)
operator||
operator|(
name|va
operator|&
name|ADDR_POFF
operator|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Atomically extract and hold the physical page with the given  * pmap and virtual address pair if that mapping permits the given  * protection.  */
end_comment

begin_function
name|vm_page_t
name|moea64_extract_and_hold
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pmap
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&
name|LPTE_VALID
operator|)
operator|&&
operator|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_PP
operator|)
operator|==
name|LPTE_RW
operator|||
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
operator|)
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
modifier|*
name|moea64_uma_page_alloc
parameter_list|(
name|uma_zone_t
name|zone
parameter_list|,
name|int
name|bytes
parameter_list|,
name|u_int8_t
modifier|*
name|flags
parameter_list|,
name|int
name|wait
parameter_list|)
block|{
comment|/* 	 * This entire routine is a horrible hack to avoid bothering kmem 	 * for new KVA addresses. Because this can get called from inside 	 * kmem allocation routines, calling kmem for a new address here 	 * can lead to multiply locking non-recursive mutexes. 	 */
specifier|static
name|vm_pindex_t
name|color
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|pflags
decl_stmt|,
name|needed_lock
decl_stmt|;
operator|*
name|flags
operator|=
name|UMA_SLAB_PRIV
expr_stmt|;
name|needed_lock
operator|=
operator|!
name|PMAP_LOCKED
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|needed_lock
condition|)
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|wait
operator|&
operator|(
name|M_NOWAIT
operator||
name|M_USE_RESERVE
operator|)
operator|)
operator|==
name|M_NOWAIT
condition|)
name|pflags
operator|=
name|VM_ALLOC_INTERRUPT
operator||
name|VM_ALLOC_WIRED
expr_stmt|;
else|else
name|pflags
operator|=
name|VM_ALLOC_SYSTEM
operator||
name|VM_ALLOC_WIRED
expr_stmt|;
if|if
condition|(
name|wait
operator|&
name|M_ZERO
condition|)
name|pflags
operator||=
name|VM_ALLOC_ZERO
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|color
operator|++
argument_list|,
name|pflags
operator||
name|VM_ALLOC_NOOBJ
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|wait
operator|&
name|M_NOWAIT
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|VM_WAIT
expr_stmt|;
block|}
else|else
break|break;
block|}
name|va
operator|=
name|pvo_allocator_start
expr_stmt|;
name|pvo_allocator_start
operator|+=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
name|pvo_allocator_start
operator|>=
name|pvo_allocator_end
condition|)
name|panic
argument_list|(
literal|"Ran out of PVO allocator buffer space!"
argument_list|)
expr_stmt|;
comment|/* Now call pvo_enter in recursive mode */
name|moea64_pvo_enter
argument_list|(
name|kernel_pmap
argument_list|,
name|moea64_upvo_zone
argument_list|,
operator|&
name|moea64_pvo_kunmanaged
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|LPTE_M
argument_list|,
name|PVO_WIRED
operator||
name|PVO_BOOTSTRAP
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|TLBIE
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|needed_lock
condition|)
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|wait
operator|&
name|M_ZERO
operator|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
return|return
operator|(
name|void
operator|*
operator|)
name|va
return|;
block|}
end_function

begin_function
name|void
name|moea64_init
parameter_list|(
name|mmu_t
name|mmu
parameter_list|)
block|{
name|CTR0
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_init"
argument_list|)
expr_stmt|;
name|moea64_upvo_zone
operator|=
name|uma_zcreate
argument_list|(
literal|"UPVO entry"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|UMA_ALIGN_PTR
argument_list|,
name|UMA_ZONE_VM
operator||
name|UMA_ZONE_NOFREE
argument_list|)
expr_stmt|;
name|moea64_mpvo_zone
operator|=
name|uma_zcreate
argument_list|(
literal|"MPVO entry"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|UMA_ALIGN_PTR
argument_list|,
name|UMA_ZONE_VM
operator||
name|UMA_ZONE_NOFREE
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|hw_direct_map
condition|)
block|{
name|uma_zone_set_allocf
argument_list|(
name|moea64_upvo_zone
argument_list|,
name|moea64_uma_page_alloc
argument_list|)
expr_stmt|;
name|uma_zone_set_allocf
argument_list|(
name|moea64_mpvo_zone
argument_list|,
name|moea64_uma_page_alloc
argument_list|)
expr_stmt|;
block|}
name|moea64_initialized
operator|=
name|TRUE
expr_stmt|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_is_modified
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
return|return
operator|(
name|moea64_query_bit
argument_list|(
name|m
argument_list|,
name|LPTE_CHG
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|moea64_clear_reference
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|!=
literal|0
condition|)
return|return;
name|moea64_clear_bit
argument_list|(
name|m
argument_list|,
name|LPTE_REF
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_clear_modify
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|!=
literal|0
condition|)
return|return;
name|moea64_clear_bit
argument_list|(
name|m
argument_list|,
name|LPTE_CHG
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Clear the write and modified bits in each of the given page's mappings.  */
end_comment

begin_function
name|void
name|moea64_remove_write
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|struct
name|lpte
modifier|*
name|pt
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|uint64_t
name|lo
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|!=
literal|0
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|lo
operator|=
name|moea64_attr_fetch
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|SYNC
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|pmap
operator|=
name|pvo
operator|->
name|pvo_pmap
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_PP
operator|)
operator|!=
name|LPTE_BR
condition|)
block|{
name|LOCK_TABLE
argument_list|()
expr_stmt|;
name|pt
operator|=
name|moea64_pvo_to_pte
argument_list|(
name|pvo
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|LPTE_PP
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator||=
name|LPTE_BR
expr_stmt|;
if|if
condition|(
name|pt
operator|!=
name|NULL
condition|)
block|{
name|moea64_pte_synch
argument_list|(
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|)
expr_stmt|;
name|lo
operator||=
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|LPTE_CHG
expr_stmt|;
name|moea64_pte_change
argument_list|(
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|pvo
operator|->
name|pvo_pmap
argument_list|,
name|pvo
operator|->
name|pvo_vaddr
argument_list|)
expr_stmt|;
block|}
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|lo
operator|&
name|LPTE_CHG
operator|)
operator|!=
literal|0
condition|)
block|{
name|moea64_attr_clear
argument_list|(
name|m
argument_list|,
name|LPTE_CHG
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WRITEABLE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	moea64_ts_referenced:  *  *	Return a count of reference bits for a page, clearing those bits.  *	It is not necessary for every reference bit to be cleared, but it  *	is necessary that 0 only be returned when there are truly no  *	reference bits set.  *  *	XXX: The exact number of bits to check and clear is a matter that  *	should be tested and standardized at some point in the future for  *	optimal aging of shared pages.  */
end_comment

begin_function
name|boolean_t
name|moea64_ts_referenced
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|count
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|count
operator|=
name|moea64_clear_bit
argument_list|(
name|m
argument_list|,
name|LPTE_REF
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Map a wired page into kernel virtual address space.  */
end_comment

begin_function
name|void
name|moea64_kenter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|)
block|{
name|uint64_t
name|pte_lo
decl_stmt|;
name|int
name|error
decl_stmt|;
if|if
condition|(
operator|!
name|pmap_bootstrapped
condition|)
block|{
if|if
condition|(
name|va
operator|>=
name|VM_MIN_KERNEL_ADDRESS
operator|&&
name|va
operator|<
name|VM_MAX_KERNEL_ADDRESS
condition|)
name|panic
argument_list|(
literal|"Trying to enter an address in KVA -- %#x!\n"
argument_list|,
name|pa
argument_list|)
expr_stmt|;
block|}
name|pte_lo
operator|=
name|moea64_calc_wimg
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|error
operator|=
name|moea64_pvo_enter
argument_list|(
name|kernel_pmap
argument_list|,
name|moea64_upvo_zone
argument_list|,
operator|&
name|moea64_pvo_kunmanaged
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|pte_lo
argument_list|,
name|PVO_WIRED
operator||
name|VM_PROT_EXECUTE
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|TLBIE
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
operator|&&
name|error
operator|!=
name|ENOENT
condition|)
name|panic
argument_list|(
literal|"moea64_kenter: failed to enter va %#x pa %#x: %d"
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|error
argument_list|)
expr_stmt|;
comment|/* 	 * Flush the memory from the instruction cache. 	 */
if|if
condition|(
operator|(
name|pte_lo
operator|&
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Extract the physical page address associated with the given kernel virtual  * address.  */
end_comment

begin_function
name|vm_offset_t
name|moea64_kextract
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pvo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"moea64_kextract: no addr found"
operator|)
argument_list|)
expr_stmt|;
name|pa
operator|=
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
operator|)
operator||
operator|(
name|va
operator|&
name|ADDR_POFF
operator|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Remove a wired page from kernel virtual address space.  */
end_comment

begin_function
name|void
name|moea64_kremove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|moea64_remove
argument_list|(
name|mmu
argument_list|,
name|kernel_pmap
argument_list|,
name|va
argument_list|,
name|va
operator|+
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map a range of physical addresses into kernel virtual address space.  *  * The value passed in *virt is a suggested virtual address for the mapping.  * Architectures which can support a direct-mapped physical to virtual region  * can return the appropriate address within that region, leaving '*virt'  * unchanged.  We cannot and therefore do not; *virt is updated with the  * first usable address after the mapped region.  */
end_comment

begin_function
name|vm_offset_t
name|moea64_map
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
modifier|*
name|virt
parameter_list|,
name|vm_offset_t
name|pa_start
parameter_list|,
name|vm_offset_t
name|pa_end
parameter_list|,
name|int
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|sva
decl_stmt|,
name|va
decl_stmt|;
name|sva
operator|=
operator|*
name|virt
expr_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
for|for
control|(
init|;
name|pa_start
operator|<
name|pa_end
condition|;
name|pa_start
operator|+=
name|PAGE_SIZE
operator|,
name|va
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|pa_start
argument_list|)
expr_stmt|;
operator|*
name|virt
operator|=
name|va
expr_stmt|;
return|return
operator|(
name|sva
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns true if the pmap's pv is one of the first  * 16 pvs linked to from this page.  This count may  * be changed upwards or downwards in the future; it  * is only necessary that true be returned for a small  * subset of pmaps for proper page aging.  */
end_comment

begin_function
name|boolean_t
name|moea64_page_exists_quick
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|loops
decl_stmt|;
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
if|if
condition|(
operator|!
name|moea64_initialized
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
condition|)
return|return
name|FALSE
return|;
name|loops
operator|=
literal|0
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|pmap
condition|)
return|return
operator|(
name|TRUE
operator|)
return|;
if|if
condition|(
operator|++
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return the number of managed mappings to the given physical page  * that are wired.  */
end_comment

begin_function
name|int
name|moea64_page_wired_mappings
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|int
name|count
decl_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|!
name|moea64_initialized
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|count
operator|)
return|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
operator|)
operator|!=
literal|0
condition|)
name|count
operator|++
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|u_int
name|moea64_vsidcontext
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|moea64_pinit
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|mask
decl_stmt|;
name|u_int
name|entropy
decl_stmt|;
name|PMAP_LOCK_INIT
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|entropy
operator|=
literal|0
expr_stmt|;
asm|__asm __volatile("mftb %0" : "=r"(entropy));
if|if
condition|(
name|pmap_bootstrapped
condition|)
name|pmap
operator|->
name|pmap_phys
operator|=
operator|(
name|pmap_t
operator|)
name|moea64_kextract
argument_list|(
name|mmu
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|pmap
argument_list|)
expr_stmt|;
else|else
name|pmap
operator|->
name|pmap_phys
operator|=
name|pmap
expr_stmt|;
comment|/* 	 * Allocate some segment registers for this pmap. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPMAPS
condition|;
name|i
operator|+=
name|VSID_NBPW
control|)
block|{
name|u_int
name|hash
decl_stmt|,
name|n
decl_stmt|;
comment|/* 		 * Create a new value by mutiplying by a prime and adding in 		 * entropy from the timebase register.  This is to make the 		 * VSID more random so that the PT hash function collides 		 * less often.  (Note that the prime casues gcc to do shifts 		 * instead of a multiply.) 		 */
name|moea64_vsidcontext
operator|=
operator|(
name|moea64_vsidcontext
operator|*
literal|0x1105
operator|)
operator|+
name|entropy
expr_stmt|;
name|hash
operator|=
name|moea64_vsidcontext
operator|&
operator|(
name|NPMAPS
operator|-
literal|1
operator|)
expr_stmt|;
if|if
condition|(
name|hash
operator|==
literal|0
condition|)
comment|/* 0 is special, avoid it */
continue|continue;
name|n
operator|=
name|hash
operator|>>
literal|5
expr_stmt|;
name|mask
operator|=
literal|1
operator|<<
operator|(
name|hash
operator|&
operator|(
name|VSID_NBPW
operator|-
literal|1
operator|)
operator|)
expr_stmt|;
name|hash
operator|=
operator|(
name|moea64_vsidcontext
operator|&
literal|0xfffff
operator|)
expr_stmt|;
if|if
condition|(
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator|&
name|mask
condition|)
block|{
comment|/* collision? */
comment|/* anything free in this bucket? */
if|if
condition|(
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator|==
literal|0xffffffff
condition|)
block|{
name|entropy
operator|=
operator|(
name|moea64_vsidcontext
operator|>>
literal|20
operator|)
expr_stmt|;
continue|continue;
block|}
name|i
operator|=
name|ffs
argument_list|(
operator|~
name|moea64_vsid_bitmap
index|[
name|i
index|]
argument_list|)
operator|-
literal|1
expr_stmt|;
name|mask
operator|=
literal|1
operator|<<
name|i
expr_stmt|;
name|hash
operator|&=
literal|0xfffff
operator|&
operator|~
operator|(
name|VSID_NBPW
operator|-
literal|1
operator|)
expr_stmt|;
name|hash
operator||=
name|i
expr_stmt|;
block|}
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator||=
name|mask
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|16
condition|;
name|i
operator|++
control|)
block|{
name|pmap
operator|->
name|pm_sr
index|[
name|i
index|]
operator|=
name|VSID_MAKE
argument_list|(
name|i
argument_list|,
name|hash
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
name|panic
argument_list|(
literal|"moea64_pinit: out of segments"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Initialize the pmap associated with process 0.  */
end_comment

begin_function
name|void
name|moea64_pinit0
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|)
block|{
name|moea64_pinit
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pm
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
argument_list|(
name|pm
operator|->
name|pm_stats
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Set the physical protection on the specified range of this map as requested.  */
end_comment

begin_function
name|void
name|moea64_protect
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|struct
name|lpte
modifier|*
name|pt
decl_stmt|;
name|int
name|pteidx
decl_stmt|;
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_protect: pm=%p sva=%#x eva=%#x prot=%#x"
argument_list|,
name|pm
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|,
name|prot
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pm
operator|==
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
operator|||
name|pm
operator|==
name|kernel_pmap
argument_list|,
operator|(
literal|"moea64_protect: non current pmap"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_READ
operator|)
operator|==
name|VM_PROT_NONE
condition|)
block|{
name|moea64_remove
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
return|return;
block|}
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pm
argument_list|,
name|sva
argument_list|,
operator|&
name|pteidx
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|==
name|NULL
condition|)
continue|continue;
comment|/* 		 * Grab the PTE pointer before we diddle with the cached PTE 		 * copy. 		 */
name|LOCK_TABLE
argument_list|()
expr_stmt|;
name|pt
operator|=
name|moea64_pvo_to_pte
argument_list|(
name|pvo
argument_list|,
name|pteidx
argument_list|)
expr_stmt|;
comment|/* 		 * Change the protection of the page. 		 */
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|LPTE_PP
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator||=
name|LPTE_BR
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|LPTE_NOEXEC
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator||=
name|LPTE_NOEXEC
expr_stmt|;
comment|/* 		 * If the PVO is in the page table, update that pte as well. 		 */
if|if
condition|(
name|pt
operator|!=
name|NULL
condition|)
block|{
name|moea64_pte_change
argument_list|(
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|pvo
operator|->
name|pvo_pmap
argument_list|,
name|pvo
operator|->
name|pvo_vaddr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator||
name|LPTE_NOEXEC
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|moea64_syncicache
argument_list|(
name|pm
argument_list|,
name|sva
argument_list|,
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
block|}
block|}
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map a list of wired pages into kernel virtual address space.  This is  * intended for temporary mappings which do not need page modification or  * references recorded.  Existing mappings in the region are overwritten.  */
end_comment

begin_function
name|void
name|moea64_qenter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
modifier|*
name|m
parameter_list|,
name|int
name|count
parameter_list|)
block|{
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|moea64_kenter
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
operator|*
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|m
operator|++
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Remove page mappings from kernel virtual address space.  Intended for  * temporary mappings entered by moea64_qenter.  */
end_comment

begin_function
name|void
name|moea64_qremove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|int
name|count
parameter_list|)
block|{
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|moea64_kremove
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|moea64_release
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|int
name|idx
decl_stmt|,
name|mask
decl_stmt|;
comment|/* 	 * Free segment register's VSID 	 */
if|if
condition|(
name|pmap
operator|->
name|pm_sr
index|[
literal|0
index|]
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"moea64_release"
argument_list|)
expr_stmt|;
name|idx
operator|=
name|VSID_TO_HASH
argument_list|(
name|pmap
operator|->
name|pm_sr
index|[
literal|0
index|]
argument_list|)
operator|&
operator|(
name|NPMAPS
operator|-
literal|1
operator|)
expr_stmt|;
name|mask
operator|=
literal|1
operator|<<
operator|(
name|idx
operator|%
name|VSID_NBPW
operator|)
expr_stmt|;
name|idx
operator|/=
name|VSID_NBPW
expr_stmt|;
name|moea64_vsid_bitmap
index|[
name|idx
index|]
operator|&=
operator|~
name|mask
expr_stmt|;
name|PMAP_LOCK_DESTROY
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove the given range of addresses from the specified map.  */
end_comment

begin_function
name|void
name|moea64_remove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|int
name|pteidx
decl_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pm
argument_list|,
name|sva
argument_list|,
operator|&
name|pteidx
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
condition|)
block|{
name|moea64_pvo_remove
argument_list|(
name|pvo
argument_list|,
name|pteidx
argument_list|)
expr_stmt|;
block|}
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove physical page from all pmaps in which it resides. moea64_pvo_remove()  * will reflect changes in pte's back to the vm_page.  */
end_comment

begin_function
name|void
name|moea64_remove_all
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pvo_head
modifier|*
name|pvo_head
decl_stmt|;
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|next_pvo
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pvo_head
operator|=
name|vm_page_to_pvoh
argument_list|(
name|m
argument_list|)
expr_stmt|;
for|for
control|(
name|pvo
operator|=
name|LIST_FIRST
argument_list|(
name|pvo_head
argument_list|)
init|;
name|pvo
operator|!=
name|NULL
condition|;
name|pvo
operator|=
name|next_pvo
control|)
block|{
name|next_pvo
operator|=
name|LIST_NEXT
argument_list|(
name|pvo
argument_list|,
name|pvo_vlink
argument_list|)
expr_stmt|;
name|MOEA_PVO_CHECK
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
comment|/* sanity check */
name|pmap
operator|=
name|pvo
operator|->
name|pvo_pmap
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|moea64_pvo_remove
argument_list|(
name|pvo
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WRITEABLE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Allocate a physical page of memory directly from the phys_avail map.  * Can only be called from moea64_bootstrap before avail start and end are  * calculated.  */
end_comment

begin_function
specifier|static
name|vm_offset_t
name|moea64_bootstrap_alloc
parameter_list|(
name|vm_size_t
name|size
parameter_list|,
name|u_int
name|align
parameter_list|)
block|{
name|vm_offset_t
name|s
decl_stmt|,
name|e
decl_stmt|;
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|size
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
block|{
if|if
condition|(
name|align
operator|!=
literal|0
condition|)
name|s
operator|=
operator|(
name|phys_avail
index|[
name|i
index|]
operator|+
name|align
operator|-
literal|1
operator|)
operator|&
operator|~
operator|(
name|align
operator|-
literal|1
operator|)
expr_stmt|;
else|else
name|s
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
name|e
operator|=
name|s
operator|+
name|size
expr_stmt|;
if|if
condition|(
name|s
operator|<
name|phys_avail
index|[
name|i
index|]
operator|||
name|e
operator|>
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|)
continue|continue;
if|if
condition|(
name|s
operator|==
name|phys_avail
index|[
name|i
index|]
condition|)
block|{
name|phys_avail
index|[
name|i
index|]
operator|+=
name|size
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|e
operator|==
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|)
block|{
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-=
name|size
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|j
operator|=
name|phys_avail_count
operator|*
literal|2
init|;
name|j
operator|>
name|i
condition|;
name|j
operator|-=
literal|2
control|)
block|{
name|phys_avail
index|[
name|j
index|]
operator|=
name|phys_avail
index|[
name|j
operator|-
literal|2
index|]
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|phys_avail
index|[
name|j
operator|-
literal|1
index|]
expr_stmt|;
block|}
name|phys_avail
index|[
name|i
operator|+
literal|3
index|]
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|=
name|s
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|2
index|]
operator|=
name|e
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
return|return
operator|(
name|s
operator|)
return|;
block|}
name|panic
argument_list|(
literal|"moea64_bootstrap_alloc: could not allocate memory"
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|tlbia
parameter_list|(
name|void
parameter_list|)
block|{
name|vm_offset_t
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|0xFF000
condition|;
name|i
operator|+=
literal|0x00001000
control|)
name|TLBIE
argument_list|(
name|NULL
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|moea64_pvo_enter
parameter_list|(
name|pmap_t
name|pm
parameter_list|,
name|uma_zone_t
name|zone
parameter_list|,
name|struct
name|pvo_head
modifier|*
name|pvo_head
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|uint64_t
name|pte_lo
parameter_list|,
name|int
name|flags
parameter_list|,
name|int
name|recurse
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|uint64_t
name|vsid
decl_stmt|;
name|int
name|first
decl_stmt|;
name|u_int
name|ptegidx
decl_stmt|;
name|int
name|i
decl_stmt|;
name|int
name|bootstrap
decl_stmt|;
comment|/* 	 * One nasty thing that can happen here is that the UMA calls to 	 * allocate new PVOs need to map more memory, which calls pvo_enter(), 	 * which calls UMA... 	 * 	 * We break the loop by detecting recursion and allocating out of 	 * the bootstrap pool. 	 */
name|moea64_pvo_enter_calls
operator|++
expr_stmt|;
name|first
operator|=
literal|0
expr_stmt|;
name|bootstrap
operator|=
operator|(
name|flags
operator|&
name|PVO_BOOTSTRAP
operator|)
expr_stmt|;
if|if
condition|(
operator|!
name|moea64_initialized
condition|)
name|bootstrap
operator|=
literal|1
expr_stmt|;
comment|/* 	 * Compute the PTE Group index. 	 */
name|va
operator|&=
operator|~
name|ADDR_POFF
expr_stmt|;
name|vsid
operator|=
name|va_to_vsid
argument_list|(
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|ptegidx
operator|=
name|va_to_pteg
argument_list|(
name|vsid
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * Remove any existing mapping for this page.  Reuse the pvo entry if 	 * there is a mapping. 	 */
if|if
condition|(
operator|!
name|recurse
condition|)
name|LOCK_TABLE
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|&moea64_pvo_table[ptegidx]
argument_list|,
argument|pvo_olink
argument_list|)
block|{
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|pm
operator|&&
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|==
name|va
condition|)
block|{
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
operator|)
operator|==
name|pa
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_PP
operator|)
operator|==
operator|(
name|pte_lo
operator|&
name|LPTE_PP
operator|)
condition|)
block|{
if|if
condition|(
operator|!
name|recurse
condition|)
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|moea64_pvo_remove
argument_list|(
name|pvo
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
comment|/* 	 * If we aren't overwriting a mapping, try to allocate. 	 */
if|if
condition|(
name|bootstrap
condition|)
block|{
if|if
condition|(
name|moea64_bpvo_pool_index
operator|>=
name|BPVO_POOL_SIZE
condition|)
block|{
name|panic
argument_list|(
literal|"moea64_enter: bpvo pool exhausted, %d, %d, %d"
argument_list|,
name|moea64_bpvo_pool_index
argument_list|,
name|BPVO_POOL_SIZE
argument_list|,
name|BPVO_POOL_SIZE
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|pvo
operator|=
operator|&
name|moea64_bpvo_pool
index|[
name|moea64_bpvo_pool_index
index|]
expr_stmt|;
name|moea64_bpvo_pool_index
operator|++
expr_stmt|;
name|bootstrap
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|pvo
operator|=
name|uma_zalloc
argument_list|(
name|zone
argument_list|,
name|M_NOWAIT
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pvo
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
operator|!
name|recurse
condition|)
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
name|moea64_pvo_entries
operator|++
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator|=
name|va
expr_stmt|;
name|pvo
operator|->
name|pvo_pmap
operator|=
name|pm
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|moea64_pvo_table
index|[
name|ptegidx
index|]
argument_list|,
name|pvo
argument_list|,
name|pvo_olink
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator|&=
operator|~
name|ADDR_POFF
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|flags
operator|&
name|VM_PROT_EXECUTE
operator|)
condition|)
name|pte_lo
operator||=
name|LPTE_NOEXEC
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|PVO_WIRED
condition|)
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_WIRED
expr_stmt|;
if|if
condition|(
name|pvo_head
operator|!=
operator|&
name|moea64_pvo_kunmanaged
condition|)
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_MANAGED
expr_stmt|;
if|if
condition|(
name|bootstrap
condition|)
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_BOOTSTRAP
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|PVO_FAKE
condition|)
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_FAKE
expr_stmt|;
name|moea64_pte_create
argument_list|(
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|vsid
argument_list|,
name|va
argument_list|,
call|(
name|uint64_t
call|)
argument_list|(
name|pa
argument_list|)
operator||
name|pte_lo
argument_list|)
expr_stmt|;
comment|/* 	 * Remember if the list was empty and therefore will be the first 	 * item. 	 */
if|if
condition|(
name|LIST_FIRST
argument_list|(
name|pvo_head
argument_list|)
operator|==
name|NULL
condition|)
name|first
operator|=
literal|1
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
name|pvo_head
argument_list|,
name|pvo
argument_list|,
name|pvo_vlink
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|PVO_WIRED
condition|)
name|pm
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
name|pm
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
comment|/* 	 * We hope this succeeds but it isn't required. 	 */
name|i
operator|=
name|moea64_pte_insert
argument_list|(
name|ptegidx
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|>=
literal|0
condition|)
block|{
name|PVO_PTEGIDX_SET
argument_list|(
name|pvo
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|panic
argument_list|(
literal|"moea64_pvo_enter: overflow"
argument_list|)
expr_stmt|;
name|moea64_pte_overflow
operator|++
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|recurse
condition|)
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
return|return
operator|(
name|first
condition|?
name|ENOENT
else|:
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_pvo_remove
parameter_list|(
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|,
name|int
name|pteidx
parameter_list|)
block|{
name|struct
name|lpte
modifier|*
name|pt
decl_stmt|;
comment|/* 	 * If there is an active pte entry, we need to deactivate it (and 	 * save the ref& cfg bits). 	 */
name|LOCK_TABLE
argument_list|()
expr_stmt|;
name|pt
operator|=
name|moea64_pvo_to_pte
argument_list|(
name|pvo
argument_list|,
name|pteidx
argument_list|)
expr_stmt|;
if|if
condition|(
name|pt
operator|!=
name|NULL
condition|)
block|{
name|moea64_pte_unset
argument_list|(
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|pvo
operator|->
name|pvo_pmap
argument_list|,
name|pvo
operator|->
name|pvo_vaddr
argument_list|)
expr_stmt|;
name|PVO_PTEGIDX_CLR
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|moea64_pte_overflow
operator|--
expr_stmt|;
block|}
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
comment|/* 	 * Update our statistics. 	 */
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|PVO_WIRED
condition|)
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
comment|/* 	 * Save the REF/CHG bits into their cache if the page is managed. 	 */
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
operator|(
name|PVO_MANAGED
operator||
name|PVO_FAKE
operator|)
operator|)
operator|==
name|PVO_MANAGED
condition|)
block|{
name|struct
name|vm_page
modifier|*
name|pg
decl_stmt|;
name|pg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
if|if
condition|(
name|pg
operator|!=
name|NULL
condition|)
block|{
name|moea64_attr_save
argument_list|(
name|pg
argument_list|,
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
operator|(
name|LPTE_REF
operator||
name|LPTE_CHG
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * Remove this PVO from the PV list. 	 */
name|LIST_REMOVE
argument_list|(
name|pvo
argument_list|,
name|pvo_vlink
argument_list|)
expr_stmt|;
comment|/* 	 * Remove this from the overflow list and return it to the pool 	 * if we aren't going to reuse it. 	 */
name|LIST_REMOVE
argument_list|(
name|pvo
argument_list|,
name|pvo_olink
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_BOOTSTRAP
operator|)
condition|)
name|uma_zfree
argument_list|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_MANAGED
condition|?
name|moea64_mpvo_zone
else|:
name|moea64_upvo_zone
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|moea64_pvo_entries
operator|--
expr_stmt|;
name|moea64_pvo_remove_calls
operator|++
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|moea64_pvo_pte_index
parameter_list|(
specifier|const
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|,
name|int
name|ptegidx
parameter_list|)
block|{
name|int
name|pteidx
decl_stmt|;
comment|/* 	 * We can find the actual pte entry without searching by grabbing 	 * the PTEG index from 3 unused bits in pte_lo[11:9] and by 	 * noticing the HID bit. 	 */
name|pteidx
operator|=
name|ptegidx
operator|*
literal|8
operator|+
name|PVO_PTEGIDX_GET
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&
name|LPTE_HID
condition|)
name|pteidx
operator|^=
name|moea64_pteg_mask
operator|*
literal|8
expr_stmt|;
return|return
operator|(
name|pteidx
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|struct
name|pvo_entry
modifier|*
name|moea64_pvo_find_va
parameter_list|(
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|int
modifier|*
name|pteidx_p
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|int
name|ptegidx
decl_stmt|;
name|uint64_t
name|vsid
decl_stmt|;
name|va
operator|&=
operator|~
name|ADDR_POFF
expr_stmt|;
name|vsid
operator|=
name|va_to_vsid
argument_list|(
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|ptegidx
operator|=
name|va_to_pteg
argument_list|(
name|vsid
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|LOCK_TABLE
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|&moea64_pvo_table[ptegidx]
argument_list|,
argument|pvo_olink
argument_list|)
block|{
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|pm
operator|&&
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|==
name|va
condition|)
block|{
if|if
condition|(
name|pteidx_p
condition|)
operator|*
name|pteidx_p
operator|=
name|moea64_pvo_pte_index
argument_list|(
name|pvo
argument_list|,
name|ptegidx
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
return|return
operator|(
name|pvo
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|struct
name|lpte
modifier|*
name|moea64_pvo_to_pte
parameter_list|(
specifier|const
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|,
name|int
name|pteidx
parameter_list|)
block|{
name|struct
name|lpte
modifier|*
name|pt
decl_stmt|;
comment|/* 	 * If we haven't been supplied the ptegidx, calculate it. 	 */
if|if
condition|(
name|pteidx
operator|==
operator|-
literal|1
condition|)
block|{
name|int
name|ptegidx
decl_stmt|;
name|uint64_t
name|vsid
decl_stmt|;
name|vsid
operator|=
name|va_to_vsid
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|,
name|pvo
operator|->
name|pvo_vaddr
argument_list|)
expr_stmt|;
name|ptegidx
operator|=
name|va_to_pteg
argument_list|(
name|vsid
argument_list|,
name|pvo
operator|->
name|pvo_vaddr
argument_list|)
expr_stmt|;
name|pteidx
operator|=
name|moea64_pvo_pte_index
argument_list|(
name|pvo
argument_list|,
name|ptegidx
argument_list|)
expr_stmt|;
block|}
name|pt
operator|=
operator|&
name|moea64_pteg_table
index|[
name|pteidx
operator|>>
literal|3
index|]
operator|.
name|pt
index|[
name|pteidx
operator|&
literal|7
index|]
expr_stmt|;
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&
name|LPTE_VALID
operator|)
operator|&&
operator|!
name|PVO_PTEGIDX_ISSET
argument_list|(
name|pvo
argument_list|)
condition|)
block|{
name|panic
argument_list|(
literal|"moea64_pvo_to_pte: pvo %p has valid pte in pvo but no "
literal|"valid pte index"
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&
name|LPTE_VALID
operator|)
operator|==
literal|0
operator|&&
name|PVO_PTEGIDX_ISSET
argument_list|(
name|pvo
argument_list|)
condition|)
block|{
name|panic
argument_list|(
literal|"moea64_pvo_to_pte: pvo %p has valid pte index in pvo "
literal|"pvo but no valid pte"
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|pt
operator|->
name|pte_hi
operator|^
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&
operator|~
name|LPTE_VALID
operator|)
operator|)
operator|==
name|LPTE_VALID
condition|)
block|{
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&
name|LPTE_VALID
operator|)
operator|==
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"moea64_pvo_to_pte: pvo %p has valid pte in "
literal|"moea64_pteg_table %p but invalid in pvo"
argument_list|,
name|pvo
argument_list|,
name|pt
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
operator|(
name|pt
operator|->
name|pte_lo
operator|^
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|)
operator|&
operator|~
operator|(
name|LPTE_CHG
operator||
name|LPTE_REF
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"moea64_pvo_to_pte: pvo %p pte does not match "
literal|"pte %p in moea64_pteg_table difference is %#x"
argument_list|,
name|pvo
argument_list|,
name|pt
argument_list|,
call|(
name|uint32_t
call|)
argument_list|(
name|pt
operator|->
name|pte_lo
operator|^
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|ASSERT_TABLE_LOCK
argument_list|()
expr_stmt|;
return|return
operator|(
name|pt
operator|)
return|;
block|}
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&
name|LPTE_VALID
condition|)
block|{
name|panic
argument_list|(
literal|"moea64_pvo_to_pte: pvo %p has invalid pte %p in "
literal|"moea64_pteg_table but valid in pvo"
argument_list|,
name|pvo
argument_list|,
name|pt
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|moea64_pte_insert
parameter_list|(
name|u_int
name|ptegidx
parameter_list|,
name|struct
name|lpte
modifier|*
name|pvo_pt
parameter_list|)
block|{
name|struct
name|lpte
modifier|*
name|pt
decl_stmt|;
name|int
name|i
decl_stmt|;
name|ASSERT_TABLE_LOCK
argument_list|()
expr_stmt|;
comment|/* 	 * First try primary hash. 	 */
for|for
control|(
name|pt
operator|=
name|moea64_pteg_table
index|[
name|ptegidx
index|]
operator|.
name|pt
operator|,
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|8
condition|;
name|i
operator|++
operator|,
name|pt
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|pt
operator|->
name|pte_hi
operator|&
name|LPTE_VALID
operator|)
operator|==
literal|0
condition|)
block|{
name|pvo_pt
operator|->
name|pte_hi
operator|&=
operator|~
name|LPTE_HID
expr_stmt|;
name|moea64_pte_set
argument_list|(
name|pt
argument_list|,
name|pvo_pt
argument_list|)
expr_stmt|;
return|return
operator|(
name|i
operator|)
return|;
block|}
block|}
comment|/* 	 * Now try secondary hash. 	 */
name|ptegidx
operator|^=
name|moea64_pteg_mask
expr_stmt|;
for|for
control|(
name|pt
operator|=
name|moea64_pteg_table
index|[
name|ptegidx
index|]
operator|.
name|pt
operator|,
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|8
condition|;
name|i
operator|++
operator|,
name|pt
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|pt
operator|->
name|pte_hi
operator|&
name|LPTE_VALID
operator|)
operator|==
literal|0
condition|)
block|{
name|pvo_pt
operator|->
name|pte_hi
operator||=
name|LPTE_HID
expr_stmt|;
name|moea64_pte_set
argument_list|(
name|pt
argument_list|,
name|pvo_pt
argument_list|)
expr_stmt|;
return|return
operator|(
name|i
operator|)
return|;
block|}
block|}
name|panic
argument_list|(
literal|"moea64_pte_insert: overflow"
argument_list|)
expr_stmt|;
return|return
operator|(
operator|-
literal|1
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|boolean_t
name|moea64_query_bit
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|u_int64_t
name|ptebit
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|struct
name|lpte
modifier|*
name|pt
decl_stmt|;
if|#
directive|if
literal|0
block|if (moea64_attr_fetch(m)& ptebit) 		return (TRUE);
endif|#
directive|endif
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|MOEA_PVO_CHECK
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
comment|/* sanity check */
comment|/* 		 * See if we saved the bit off.  If so, cache it and return 		 * success. 		 */
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|ptebit
condition|)
block|{
name|moea64_attr_save
argument_list|(
name|m
argument_list|,
name|ptebit
argument_list|)
expr_stmt|;
name|MOEA_PVO_CHECK
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
comment|/* sanity check */
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
block|}
comment|/* 	 * No luck, now go through the hard part of looking at the PTEs 	 * themselves.  Sync so that any pending REF/CHG bits are flushed to 	 * the PTEs. 	 */
name|SYNC
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|MOEA_PVO_CHECK
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
comment|/* sanity check */
comment|/* 		 * See if this pvo has a valid PTE.  if so, fetch the 		 * REF/CHG bits from the valid PTE.  If the appropriate 		 * ptebit is set, cache it and return success. 		 */
name|LOCK_TABLE
argument_list|()
expr_stmt|;
name|pt
operator|=
name|moea64_pvo_to_pte
argument_list|(
name|pvo
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|pt
operator|!=
name|NULL
condition|)
block|{
name|moea64_pte_synch
argument_list|(
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|ptebit
condition|)
block|{
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
name|moea64_attr_save
argument_list|(
name|m
argument_list|,
name|ptebit
argument_list|)
expr_stmt|;
name|MOEA_PVO_CHECK
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
comment|/* sanity check */
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
block|}
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
block|}
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|u_int
name|moea64_clear_bit
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|u_int64_t
name|ptebit
parameter_list|,
name|u_int64_t
modifier|*
name|origbit
parameter_list|)
block|{
name|u_int
name|count
decl_stmt|;
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|struct
name|lpte
modifier|*
name|pt
decl_stmt|;
name|uint64_t
name|rv
decl_stmt|;
comment|/* 	 * Clear the cached value. 	 */
name|rv
operator|=
name|moea64_attr_fetch
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|moea64_attr_clear
argument_list|(
name|m
argument_list|,
name|ptebit
argument_list|)
expr_stmt|;
comment|/* 	 * Sync so that any pending REF/CHG bits are flushed to the PTEs (so 	 * we can reset the right ones).  note that since the pvo entries and 	 * list heads are accessed via BAT0 and are never placed in the page 	 * table, we don't have to worry about further accesses setting the 	 * REF/CHG bits. 	 */
name|SYNC
argument_list|()
expr_stmt|;
comment|/* 	 * For each pvo entry, clear the pvo's ptebit.  If this pvo has a 	 * valid pte clear the ptebit from the valid pte. 	 */
name|count
operator|=
literal|0
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|MOEA_PVO_CHECK
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
comment|/* sanity check */
name|LOCK_TABLE
argument_list|()
expr_stmt|;
name|pt
operator|=
name|moea64_pvo_to_pte
argument_list|(
name|pvo
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|pt
operator|!=
name|NULL
condition|)
block|{
name|moea64_pte_synch
argument_list|(
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|ptebit
condition|)
block|{
name|count
operator|++
expr_stmt|;
name|moea64_pte_clear
argument_list|(
name|pt
argument_list|,
name|pvo
operator|->
name|pvo_pmap
argument_list|,
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
argument_list|,
name|ptebit
argument_list|)
expr_stmt|;
block|}
block|}
name|UNLOCK_TABLE
argument_list|()
expr_stmt|;
name|rv
operator||=
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|ptebit
expr_stmt|;
name|MOEA_PVO_CHECK
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
comment|/* sanity check */
block|}
if|if
condition|(
name|origbit
operator|!=
name|NULL
condition|)
block|{
operator|*
name|origbit
operator|=
name|rv
expr_stmt|;
block|}
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_dev_direct_mapped
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
return|return
operator|(
name|EFAULT
operator|)
return|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_page_executable
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|pg
parameter_list|)
block|{
return|return
operator|(
operator|!
name|moea64_query_bit
argument_list|(
name|pg
argument_list|,
name|LPTE_NOEXEC
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Map a set of physical memory pages into the kernel virtual  * address space. Return a pointer to where it is mapped. This  * routine is intended to be used for mapping device memory,  * NOT real memory.  */
end_comment

begin_function
name|void
modifier|*
name|moea64_mapdev
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|,
name|tmpva
decl_stmt|,
name|ppa
decl_stmt|,
name|offset
decl_stmt|;
name|ppa
operator|=
name|trunc_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|offset
operator|=
name|pa
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|roundup
argument_list|(
name|offset
operator|+
name|size
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|va
operator|=
name|kmem_alloc_nofault
argument_list|(
name|kernel_map
argument_list|,
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|va
condition|)
name|panic
argument_list|(
literal|"moea64_mapdev: Couldn't alloc kernel virtual memory"
argument_list|)
expr_stmt|;
for|for
control|(
name|tmpva
operator|=
name|va
init|;
name|size
operator|>
literal|0
condition|;
control|)
block|{
name|moea64_kenter
argument_list|(
name|mmu
argument_list|,
name|tmpva
argument_list|,
name|ppa
argument_list|)
expr_stmt|;
name|size
operator|-=
name|PAGE_SIZE
expr_stmt|;
name|tmpva
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|ppa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
return|return
operator|(
operator|(
name|void
operator|*
operator|)
operator|(
name|va
operator|+
name|offset
operator|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|moea64_unmapdev
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|vm_offset_t
name|base
decl_stmt|,
name|offset
decl_stmt|;
name|base
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|offset
operator|=
name|va
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|roundup
argument_list|(
name|offset
operator|+
name|size
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|kernel_map
argument_list|,
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

end_unit

