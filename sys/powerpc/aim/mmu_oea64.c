begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2001 The NetBSD Foundation, Inc.  * All rights reserved.  *  * This code is derived from software contributed to The NetBSD Foundation  * by Matt Thomas<matt@3am-software.com> of Allegro Networks, Inc.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. All advertising materials mentioning features or use of this software  *    must display the following acknowledgement:  *        This product includes software developed by the NetBSD  *        Foundation, Inc. and its contributors.  * 4. Neither the name of The NetBSD Foundation nor the names of its  *    contributors may be used to endorse or promote products derived  *    from this software without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS  * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED  * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS  * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS  * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN  * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)  * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE  * POSSIBILITY OF SUCH DAMAGE.  */
end_comment

begin_comment
comment|/*-  * Copyright (C) 1995, 1996 Wolfgang Solfrank.  * Copyright (C) 1995, 1996 TooLs GmbH.  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. All advertising materials mentioning features or use of this software  *    must display the following acknowledgement:  *	This product includes software developed by TooLs GmbH.  * 4. The name of TooLs GmbH may not be used to endorse or promote products  *    derived from this software without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY TOOLS GMBH ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  * IN NO EVENT SHALL TOOLS GMBH BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,  * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;  * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,  * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR  * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF  * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  *  * $NetBSD: pmap.c,v 1.28 2000/03/26 20:42:36 kleink Exp $  */
end_comment

begin_comment
comment|/*-  * Copyright (C) 2001 Benno Rice.  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY Benno Rice ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  * IN NO EVENT SHALL TOOLS GMBH BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,  * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;  * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,  * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR  * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF  * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Manages physical address maps.  *  * Since the information managed by this module is also stored by the  * logical address mapping module, this module may throw away valid virtual  * to physical mappings at almost any time.  However, invalidations of  * mappings must be done as requested.  *  * In order to cope with hardware architectures which make virtual to  * physical map invalidates expensive, this module may delay invalidate  * reduced protection operations until such time as they are actually  * necessary.  This module is given full information as to which processors  * are currently using which maps, and to when physical maps must be made  * correct.  */
end_comment

begin_include
include|#
directive|include
file|"opt_compat.h"
end_include

begin_include
include|#
directive|include
file|"opt_kstack_pages.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/queue.h>
end_include

begin_include
include|#
directive|include
file|<sys/cpuset.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/msgbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/kdb.h>
end_include

begin_include
include|#
directive|include
file|<dev/ofw/openfirm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<machine/_inttypes.h>
end_include

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/platform.h>
end_include

begin_include
include|#
directive|include
file|<machine/frame.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_include
include|#
directive|include
file|<machine/psl.h>
end_include

begin_include
include|#
directive|include
file|<machine/bat.h>
end_include

begin_include
include|#
directive|include
file|<machine/hid.h>
end_include

begin_include
include|#
directive|include
file|<machine/pte.h>
end_include

begin_include
include|#
directive|include
file|<machine/sr.h>
end_include

begin_include
include|#
directive|include
file|<machine/trap.h>
end_include

begin_include
include|#
directive|include
file|<machine/mmuvar.h>
end_include

begin_include
include|#
directive|include
file|"mmu_oea64.h"
end_include

begin_include
include|#
directive|include
file|"mmu_if.h"
end_include

begin_include
include|#
directive|include
file|"moea64_if.h"
end_include

begin_function_decl
name|void
name|moea64_release_vsid
parameter_list|(
name|uint64_t
name|vsid
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|uintptr_t
name|moea64_get_unique_vsid
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_define
define|#
directive|define
name|DISABLE_TRANS
parameter_list|(
name|msr
parameter_list|)
value|msr = mfmsr(); mtmsr(msr& ~PSL_DR)
end_define

begin_define
define|#
directive|define
name|ENABLE_TRANS
parameter_list|(
name|msr
parameter_list|)
value|mtmsr(msr)
end_define

begin_define
define|#
directive|define
name|VSID_MAKE
parameter_list|(
name|sr
parameter_list|,
name|hash
parameter_list|)
value|((sr) | (((hash)& 0xfffff)<< 4))
end_define

begin_define
define|#
directive|define
name|VSID_TO_HASH
parameter_list|(
name|vsid
parameter_list|)
value|(((vsid)>> 4)& 0xfffff)
end_define

begin_define
define|#
directive|define
name|VSID_HASH_MASK
value|0x0000007fffffffffULL
end_define

begin_comment
comment|/*  * Locking semantics:  * -- Read lock: if no modifications are being made to either the PVO lists  *    or page table or if any modifications being made result in internal  *    changes (e.g. wiring, protection) such that the existence of the PVOs  *    is unchanged and they remain associated with the same pmap (in which  *    case the changes should be protected by the pmap lock)  * -- Write lock: required if PTEs/PVOs are being inserted or removed.  */
end_comment

begin_define
define|#
directive|define
name|LOCK_TABLE_RD
parameter_list|()
value|rw_rlock(&moea64_table_lock)
end_define

begin_define
define|#
directive|define
name|UNLOCK_TABLE_RD
parameter_list|()
value|rw_runlock(&moea64_table_lock)
end_define

begin_define
define|#
directive|define
name|LOCK_TABLE_WR
parameter_list|()
value|rw_wlock(&moea64_table_lock)
end_define

begin_define
define|#
directive|define
name|UNLOCK_TABLE_WR
parameter_list|()
value|rw_wunlock(&moea64_table_lock)
end_define

begin_struct
struct|struct
name|ofw_map
block|{
name|cell_t
name|om_va
decl_stmt|;
name|cell_t
name|om_len
decl_stmt|;
name|cell_t
name|om_pa_hi
decl_stmt|;
name|cell_t
name|om_pa_lo
decl_stmt|;
name|cell_t
name|om_mode
decl_stmt|;
block|}
struct|;
end_struct

begin_comment
comment|/*  * Map of physical memory regions.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mem_region
modifier|*
name|regions
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mem_region
modifier|*
name|pregions
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|u_int
name|phys_avail_count
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|regions_sz
decl_stmt|,
name|pregions_sz
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|extern
name|void
name|bs_remap_earlyboot
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Lock for the pteg and pvo tables.  */
end_comment

begin_decl_stmt
name|struct
name|rwlock
name|moea64_table_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mtx
name|moea64_slb_mutex
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * PTEG data.  */
end_comment

begin_decl_stmt
name|u_int
name|moea64_pteg_count
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pteg_mask
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * PVO data.  */
end_comment

begin_decl_stmt
name|struct
name|pvo_head
modifier|*
name|moea64_pvo_table
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* pvo entries by pteg index */
end_comment

begin_decl_stmt
name|uma_zone_t
name|moea64_upvo_zone
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* zone for pvo entries for unmanaged pages */
end_comment

begin_decl_stmt
name|uma_zone_t
name|moea64_mpvo_zone
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* zone for pvo entries for managed pages */
end_comment

begin_define
define|#
directive|define
name|BPVO_POOL_SIZE
value|327680
end_define

begin_decl_stmt
specifier|static
name|struct
name|pvo_entry
modifier|*
name|moea64_bpvo_pool
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|moea64_bpvo_pool_index
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|VSID_NBPW
value|(sizeof(u_int32_t) * 8)
end_define

begin_ifdef
ifdef|#
directive|ifdef
name|__powerpc64__
end_ifdef

begin_define
define|#
directive|define
name|NVSIDS
value|(NPMAPS * 16)
end_define

begin_define
define|#
directive|define
name|VSID_HASHMASK
value|0xffffffffUL
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|NVSIDS
value|NPMAPS
end_define

begin_define
define|#
directive|define
name|VSID_HASHMASK
value|0xfffffUL
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|u_int
name|moea64_vsid_bitmap
index|[
name|NVSIDS
operator|/
name|VSID_NBPW
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|boolean_t
name|moea64_initialized
init|=
name|FALSE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Statistics.  */
end_comment

begin_decl_stmt
name|u_int
name|moea64_pte_valid
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pte_overflow
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pvo_entries
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pvo_enter_calls
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pvo_remove_calls
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pte_valid
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pte_valid
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pte_overflow
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pte_overflow
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pvo_entries
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pvo_entries
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pvo_enter_calls
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pvo_enter_calls
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pvo_remove_calls
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pvo_remove_calls
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|vm_offset_t
name|moea64_scratchpage_va
index|[
literal|2
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|pvo_entry
modifier|*
name|moea64_scratchpage_pvo
index|[
literal|2
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uintptr_t
name|moea64_scratchpage_pte
index|[
literal|2
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mtx
name|moea64_scratchpage_mtx
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|moea64_large_page_mask
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|moea64_large_page_size
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|moea64_large_page_shift
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * PVO calls.  */
end_comment

begin_function_decl
specifier|static
name|int
name|moea64_pvo_enter
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|uma_zone_t
parameter_list|,
name|struct
name|pvo_head
modifier|*
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|uint64_t
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_pvo_remove
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|pvo_entry
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|pvo_entry
modifier|*
name|moea64_pvo_find_va
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Utility routines.  */
end_comment

begin_function_decl
specifier|static
name|boolean_t
name|moea64_query_bit
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|u_int64_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|u_int
name|moea64_clear_bit
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|u_int64_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_kremove
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_syncicache
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|vm_size_t
name|sz
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Kernel MMU interface  */
end_comment

begin_function_decl
name|void
name|moea64_change_wiring
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|boolean_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_clear_modify
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_clear_reference
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_copy_page
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_copy_pages
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
modifier|*
name|mb
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_enter
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|,
name|boolean_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_enter_object
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_enter_quick
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_paddr_t
name|moea64_extract
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_page_t
name|moea64_extract_and_hold
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_init
parameter_list|(
name|mmu_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_is_modified
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_is_prefaultable
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_is_referenced
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|int
name|moea64_ts_referenced
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_offset_t
name|moea64_map
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
modifier|*
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_page_exists_quick
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|int
name|moea64_page_wired_mappings
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_pinit
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_pinit0
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_protect
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_qenter
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_qremove
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_release
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove_pages
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove_all
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove_write
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_zero_page
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_zero_page_area
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_zero_page_idle
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_activate
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_deactivate
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
modifier|*
name|moea64_mapdev
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
modifier|*
name|moea64_mapdev_attr
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|,
name|vm_memattr_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_unmapdev
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_paddr_t
name|moea64_kextract
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_page_set_memattr
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_kenter_attr
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_kenter
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_paddr_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_dev_direct_mapped
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_sync_icache
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
specifier|static
name|mmu_method_t
name|moea64_methods
index|[]
init|=
block|{
name|MMUMETHOD
argument_list|(
name|mmu_change_wiring
argument_list|,
name|moea64_change_wiring
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_clear_modify
argument_list|,
name|moea64_clear_modify
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_clear_reference
argument_list|,
name|moea64_clear_reference
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_copy_page
argument_list|,
name|moea64_copy_page
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_copy_pages
argument_list|,
name|moea64_copy_pages
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter
argument_list|,
name|moea64_enter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter_object
argument_list|,
name|moea64_enter_object
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter_quick
argument_list|,
name|moea64_enter_quick
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_extract
argument_list|,
name|moea64_extract
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_extract_and_hold
argument_list|,
name|moea64_extract_and_hold
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_init
argument_list|,
name|moea64_init
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_is_modified
argument_list|,
name|moea64_is_modified
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_is_prefaultable
argument_list|,
name|moea64_is_prefaultable
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_is_referenced
argument_list|,
name|moea64_is_referenced
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_ts_referenced
argument_list|,
name|moea64_ts_referenced
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_map
argument_list|,
name|moea64_map
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_exists_quick
argument_list|,
name|moea64_page_exists_quick
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_wired_mappings
argument_list|,
name|moea64_page_wired_mappings
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_pinit
argument_list|,
name|moea64_pinit
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_pinit0
argument_list|,
name|moea64_pinit0
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_protect
argument_list|,
name|moea64_protect
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_qenter
argument_list|,
name|moea64_qenter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_qremove
argument_list|,
name|moea64_qremove
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_release
argument_list|,
name|moea64_release
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove
argument_list|,
name|moea64_remove
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove_pages
argument_list|,
name|moea64_remove_pages
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove_all
argument_list|,
name|moea64_remove_all
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove_write
argument_list|,
name|moea64_remove_write
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_sync_icache
argument_list|,
name|moea64_sync_icache
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page
argument_list|,
name|moea64_zero_page
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page_area
argument_list|,
name|moea64_zero_page_area
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page_idle
argument_list|,
name|moea64_zero_page_idle
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_activate
argument_list|,
name|moea64_activate
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_deactivate
argument_list|,
name|moea64_deactivate
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_set_memattr
argument_list|,
name|moea64_page_set_memattr
argument_list|)
block|,
comment|/* Internal interfaces */
name|MMUMETHOD
argument_list|(
name|mmu_mapdev
argument_list|,
name|moea64_mapdev
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_mapdev_attr
argument_list|,
name|moea64_mapdev_attr
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_unmapdev
argument_list|,
name|moea64_unmapdev
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_kextract
argument_list|,
name|moea64_kextract
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_kenter
argument_list|,
name|moea64_kenter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_kenter_attr
argument_list|,
name|moea64_kenter_attr
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_dev_direct_mapped
argument_list|,
name|moea64_dev_direct_mapped
argument_list|)
block|,
block|{
literal|0
block|,
literal|0
block|}
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|MMU_DEF
argument_list|(
name|oea64_mmu
argument_list|,
literal|"mmu_oea64_base"
argument_list|,
name|moea64_methods
argument_list|,
literal|0
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|__inline
name|u_int
name|va_to_pteg
parameter_list|(
name|uint64_t
name|vsid
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|int
name|large
parameter_list|)
block|{
name|uint64_t
name|hash
decl_stmt|;
name|int
name|shift
decl_stmt|;
name|shift
operator|=
name|large
condition|?
name|moea64_large_page_shift
else|:
name|ADDR_PIDX_SHFT
expr_stmt|;
name|hash
operator|=
operator|(
name|vsid
operator|&
name|VSID_HASH_MASK
operator|)
operator|^
operator|(
operator|(
operator|(
name|uint64_t
operator|)
name|addr
operator|&
name|ADDR_PIDX
operator|)
operator|>>
name|shift
operator|)
expr_stmt|;
return|return
operator|(
name|hash
operator|&
name|moea64_pteg_mask
operator|)
return|;
block|}
end_function

begin_expr_stmt
specifier|static
name|__inline
expr|struct
name|pvo_head
operator|*
name|vm_page_to_pvoh
argument_list|(
argument|vm_page_t m
argument_list|)
block|{
return|return
operator|(
operator|&
name|m
operator|->
name|md
operator|.
name|mdpg_pvoh
operator|)
return|;
block|}
end_expr_stmt

begin_function
specifier|static
name|__inline
name|void
name|moea64_pte_create
parameter_list|(
name|struct
name|lpte
modifier|*
name|pt
parameter_list|,
name|uint64_t
name|vsid
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|uint64_t
name|pte_lo
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
comment|/* 	 * Construct a PTE.  Default to IMB initially.  Valid bit only gets 	 * set when the real pte is set in memory. 	 * 	 * Note: Don't set the valid bit for correct operation of tlb update. 	 */
name|pt
operator|->
name|pte_hi
operator|=
operator|(
name|vsid
operator|<<
name|LPTE_VSID_SHIFT
operator|)
operator||
operator|(
operator|(
call|(
name|uint64_t
call|)
argument_list|(
name|va
operator|&
name|ADDR_PIDX
argument_list|)
operator|>>
name|ADDR_API_SHFT64
operator|)
operator|&
name|LPTE_API
operator|)
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|PVO_LARGE
condition|)
name|pt
operator|->
name|pte_hi
operator||=
name|LPTE_BIG
expr_stmt|;
name|pt
operator|->
name|pte_lo
operator|=
name|pte_lo
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|uint64_t
name|moea64_calc_wimg
parameter_list|(
name|vm_offset_t
name|pa
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|uint64_t
name|pte_lo
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
name|ma
operator|!=
name|VM_MEMATTR_DEFAULT
condition|)
block|{
switch|switch
condition|(
name|ma
condition|)
block|{
case|case
name|VM_MEMATTR_UNCACHEABLE
case|:
return|return
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator|)
return|;
case|case
name|VM_MEMATTR_WRITE_COMBINING
case|:
case|case
name|VM_MEMATTR_WRITE_BACK
case|:
case|case
name|VM_MEMATTR_PREFETCHABLE
case|:
return|return
operator|(
name|LPTE_I
operator|)
return|;
case|case
name|VM_MEMATTR_WRITE_THROUGH
case|:
return|return
operator|(
name|LPTE_W
operator||
name|LPTE_M
operator|)
return|;
block|}
block|}
comment|/* 	 * Assume the page is cache inhibited and access is guarded unless 	 * it's in our available memory array. 	 */
name|pte_lo
operator|=
name|LPTE_I
operator||
name|LPTE_G
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pregions_sz
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|pa
operator|>=
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
operator|)
operator|&&
operator|(
name|pa
operator|<
operator|(
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|pregions
index|[
name|i
index|]
operator|.
name|mr_size
operator|)
operator|)
condition|)
block|{
name|pte_lo
operator|&=
operator|~
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator|)
expr_stmt|;
name|pte_lo
operator||=
name|LPTE_M
expr_stmt|;
break|break;
block|}
block|}
return|return
name|pte_lo
return|;
block|}
end_function

begin_comment
comment|/*  * Quick sort callout for comparing memory regions.  */
end_comment

begin_function_decl
specifier|static
name|int
name|om_cmp
parameter_list|(
specifier|const
name|void
modifier|*
name|a
parameter_list|,
specifier|const
name|void
modifier|*
name|b
parameter_list|)
function_decl|;
end_function_decl

begin_function
specifier|static
name|int
name|om_cmp
parameter_list|(
specifier|const
name|void
modifier|*
name|a
parameter_list|,
specifier|const
name|void
modifier|*
name|b
parameter_list|)
block|{
specifier|const
name|struct
name|ofw_map
modifier|*
name|mapa
decl_stmt|;
specifier|const
name|struct
name|ofw_map
modifier|*
name|mapb
decl_stmt|;
name|mapa
operator|=
name|a
expr_stmt|;
name|mapb
operator|=
name|b
expr_stmt|;
if|if
condition|(
name|mapa
operator|->
name|om_pa_hi
operator|<
name|mapb
operator|->
name|om_pa_hi
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
elseif|else
if|if
condition|(
name|mapa
operator|->
name|om_pa_hi
operator|>
name|mapb
operator|->
name|om_pa_hi
condition|)
return|return
operator|(
literal|1
operator|)
return|;
elseif|else
if|if
condition|(
name|mapa
operator|->
name|om_pa_lo
operator|<
name|mapb
operator|->
name|om_pa_lo
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
elseif|else
if|if
condition|(
name|mapa
operator|->
name|om_pa_lo
operator|>
name|mapb
operator|->
name|om_pa_lo
condition|)
return|return
operator|(
literal|1
operator|)
return|;
else|else
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_add_ofw_mappings
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|phandle_t
name|mmu
parameter_list|,
name|size_t
name|sz
parameter_list|)
block|{
name|struct
name|ofw_map
name|translations
index|[
name|sz
operator|/
sizeof|sizeof
argument_list|(
expr|struct
name|ofw_map
argument_list|)
index|]
decl_stmt|;
name|register_t
name|msr
decl_stmt|;
name|vm_offset_t
name|off
decl_stmt|;
name|vm_paddr_t
name|pa_base
decl_stmt|;
name|int
name|i
decl_stmt|;
name|bzero
argument_list|(
name|translations
argument_list|,
name|sz
argument_list|)
expr_stmt|;
if|if
condition|(
name|OF_getprop
argument_list|(
name|mmu
argument_list|,
literal|"translations"
argument_list|,
name|translations
argument_list|,
name|sz
argument_list|)
operator|==
operator|-
literal|1
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: can't get ofw translations"
argument_list|)
expr_stmt|;
name|CTR0
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_add_ofw_mappings: translations"
argument_list|)
expr_stmt|;
name|sz
operator|/=
sizeof|sizeof
argument_list|(
operator|*
name|translations
argument_list|)
expr_stmt|;
name|qsort
argument_list|(
name|translations
argument_list|,
name|sz
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|translations
argument_list|)
argument_list|,
name|om_cmp
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|sz
condition|;
name|i
operator|++
control|)
block|{
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"translation: pa=%#x va=%#x len=%#x"
argument_list|,
call|(
name|uint32_t
call|)
argument_list|(
name|translations
index|[
name|i
index|]
operator|.
name|om_pa_lo
argument_list|)
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_va
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_len
argument_list|)
expr_stmt|;
if|if
condition|(
name|translations
index|[
name|i
index|]
operator|.
name|om_pa_lo
operator|%
name|PAGE_SIZE
condition|)
name|panic
argument_list|(
literal|"OFW translation not page-aligned!"
argument_list|)
expr_stmt|;
name|pa_base
operator|=
name|translations
index|[
name|i
index|]
operator|.
name|om_pa_lo
expr_stmt|;
ifdef|#
directive|ifdef
name|__powerpc64__
name|pa_base
operator|+=
operator|(
name|vm_offset_t
operator|)
name|translations
index|[
name|i
index|]
operator|.
name|om_pa_hi
operator|<<
literal|32
expr_stmt|;
else|#
directive|else
if|if
condition|(
name|translations
index|[
name|i
index|]
operator|.
name|om_pa_hi
condition|)
name|panic
argument_list|(
literal|"OFW translations above 32-bit boundary!"
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* Now enter the pages for this mapping */
name|DISABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
for|for
control|(
name|off
operator|=
literal|0
init|;
name|off
operator|<
name|translations
index|[
name|i
index|]
operator|.
name|om_len
condition|;
name|off
operator|+=
name|PAGE_SIZE
control|)
block|{
if|if
condition|(
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_va
operator|+
name|off
argument_list|)
operator|!=
name|NULL
condition|)
continue|continue;
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_va
operator|+
name|off
argument_list|,
name|pa_base
operator|+
name|off
argument_list|)
expr_stmt|;
block|}
name|ENABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|__powerpc64__
end_ifdef

begin_function
specifier|static
name|void
name|moea64_probe_large_page
parameter_list|(
name|void
parameter_list|)
block|{
name|uint16_t
name|pvr
init|=
name|mfpvr
argument_list|()
operator|>>
literal|16
decl_stmt|;
switch|switch
condition|(
name|pvr
condition|)
block|{
case|case
name|IBM970
case|:
case|case
name|IBM970FX
case|:
case|case
name|IBM970MP
case|:
name|powerpc_sync
argument_list|()
expr_stmt|;
name|isync
argument_list|()
expr_stmt|;
name|mtspr
argument_list|(
name|SPR_HID4
argument_list|,
name|mfspr
argument_list|(
name|SPR_HID4
argument_list|)
operator|&
operator|~
name|HID4_970_DISABLE_LG_PG
argument_list|)
expr_stmt|;
name|powerpc_sync
argument_list|()
expr_stmt|;
name|isync
argument_list|()
expr_stmt|;
comment|/* FALLTHROUGH */
case|case
name|IBMCELLBE
case|:
name|moea64_large_page_size
operator|=
literal|0x1000000
expr_stmt|;
comment|/* 16 MB */
name|moea64_large_page_shift
operator|=
literal|24
expr_stmt|;
break|break;
default|default:
name|moea64_large_page_size
operator|=
literal|0
expr_stmt|;
block|}
name|moea64_large_page_mask
operator|=
name|moea64_large_page_size
operator|-
literal|1
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_bootstrap_slb_prefault
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|int
name|large
parameter_list|)
block|{
name|struct
name|slb
modifier|*
name|cache
decl_stmt|;
name|struct
name|slb
name|entry
decl_stmt|;
name|uint64_t
name|esid
decl_stmt|,
name|slbe
decl_stmt|;
name|uint64_t
name|i
decl_stmt|;
name|cache
operator|=
name|PCPU_GET
argument_list|(
name|slb
argument_list|)
expr_stmt|;
name|esid
operator|=
name|va
operator|>>
name|ADDR_SR_SHFT
expr_stmt|;
name|slbe
operator|=
operator|(
name|esid
operator|<<
name|SLBE_ESID_SHIFT
operator|)
operator||
name|SLBE_VALID
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|64
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|cache
index|[
name|i
index|]
operator|.
name|slbe
operator|==
operator|(
name|slbe
operator||
name|i
operator|)
condition|)
return|return;
block|}
name|entry
operator|.
name|slbe
operator|=
name|slbe
expr_stmt|;
name|entry
operator|.
name|slbv
operator|=
name|KERNEL_VSID
argument_list|(
name|esid
argument_list|)
operator|<<
name|SLBV_VSID_SHIFT
expr_stmt|;
if|if
condition|(
name|large
condition|)
name|entry
operator|.
name|slbv
operator||=
name|SLBV_L
expr_stmt|;
name|slb_insert_kernel
argument_list|(
name|entry
operator|.
name|slbe
argument_list|,
name|entry
operator|.
name|slbv
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|void
name|moea64_setup_direct_map
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|vm_offset_t
name|kernelstart
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
block|{
name|register_t
name|msr
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_offset_t
name|size
decl_stmt|,
name|off
decl_stmt|;
name|uint64_t
name|pte_lo
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
name|moea64_large_page_size
operator|==
literal|0
condition|)
name|hw_direct_map
operator|=
literal|0
expr_stmt|;
name|DISABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
if|if
condition|(
name|hw_direct_map
condition|)
block|{
name|LOCK_TABLE_WR
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pregions_sz
condition|;
name|i
operator|++
control|)
block|{
for|for
control|(
name|pa
operator|=
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
init|;
name|pa
operator|<
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|pregions
index|[
name|i
index|]
operator|.
name|mr_size
condition|;
name|pa
operator|+=
name|moea64_large_page_size
control|)
block|{
name|pte_lo
operator|=
name|LPTE_M
expr_stmt|;
comment|/* 			 * Set memory access as guarded if prefetch within 			 * the page could exit the available physmem area. 			 */
if|if
condition|(
name|pa
operator|&
name|moea64_large_page_mask
condition|)
block|{
name|pa
operator|&=
name|moea64_large_page_mask
expr_stmt|;
name|pte_lo
operator||=
name|LPTE_G
expr_stmt|;
block|}
if|if
condition|(
name|pa
operator|+
name|moea64_large_page_size
operator|>
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|pregions
index|[
name|i
index|]
operator|.
name|mr_size
condition|)
name|pte_lo
operator||=
name|LPTE_G
expr_stmt|;
name|moea64_pvo_enter
argument_list|(
name|mmup
argument_list|,
name|kernel_pmap
argument_list|,
name|moea64_upvo_zone
argument_list|,
name|NULL
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|,
name|pte_lo
argument_list|,
name|PVO_WIRED
operator||
name|PVO_LARGE
argument_list|)
expr_stmt|;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|UNLOCK_TABLE_WR
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|size
operator|=
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_head
argument_list|)
operator|*
name|moea64_pteg_count
expr_stmt|;
name|off
operator|=
call|(
name|vm_offset_t
call|)
argument_list|(
name|moea64_pvo_table
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|off
init|;
name|pa
operator|<
name|off
operator|+
name|size
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|size
operator|=
name|BPVO_POOL_SIZE
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
expr_stmt|;
name|off
operator|=
call|(
name|vm_offset_t
call|)
argument_list|(
name|moea64_bpvo_pool
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|off
init|;
name|pa
operator|<
name|off
operator|+
name|size
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|)
expr_stmt|;
comment|/* 		 * Map certain important things, like ourselves. 		 * 		 * NOTE: We do not map the exception vector space. That code is 		 * used only in real mode, and leaving it unmapped allows us to 		 * catch NULL pointer deferences, instead of making NULL a valid 		 * address. 		 */
for|for
control|(
name|pa
operator|=
name|kernelstart
operator|&
operator|~
name|PAGE_MASK
init|;
name|pa
operator|<
name|kernelend
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|)
expr_stmt|;
block|}
name|ENABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
comment|/* 	 * Allow user to override unmapped_buf_allowed for testing. 	 * XXXKIB Only direct map implementation was tested. 	 */
if|if
condition|(
operator|!
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vfs.unmapped_buf_allowed"
argument_list|,
operator|&
name|unmapped_buf_allowed
argument_list|)
condition|)
name|unmapped_buf_allowed
operator|=
name|hw_direct_map
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_early_bootstrap
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|vm_offset_t
name|kernelstart
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
name|vm_size_t
name|physsz
decl_stmt|,
name|hwphyssz
decl_stmt|;
ifndef|#
directive|ifndef
name|__powerpc64__
comment|/* We don't have a direct map since there is no BAT */
name|hw_direct_map
operator|=
literal|0
expr_stmt|;
comment|/* Make sure battable is zero, since we have no BAT */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|16
condition|;
name|i
operator|++
control|)
block|{
name|battable
index|[
name|i
index|]
operator|.
name|batu
operator|=
literal|0
expr_stmt|;
name|battable
index|[
name|i
index|]
operator|.
name|batl
operator|=
literal|0
expr_stmt|;
block|}
else|#
directive|else
name|moea64_probe_large_page
argument_list|()
expr_stmt|;
comment|/* Use a direct map if we have large page support */
if|if
condition|(
name|moea64_large_page_size
operator|>
literal|0
condition|)
name|hw_direct_map
operator|=
literal|1
expr_stmt|;
else|else
name|hw_direct_map
operator|=
literal|0
expr_stmt|;
endif|#
directive|endif
comment|/* Get physical memory regions from firmware */
name|mem_regions
argument_list|(
operator|&
name|pregions
argument_list|,
operator|&
name|pregions_sz
argument_list|,
operator|&
name|regions
argument_list|,
operator|&
name|regions_sz
argument_list|)
expr_stmt|;
name|CTR0
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_bootstrap: physical memory"
argument_list|)
expr_stmt|;
if|if
condition|(
sizeof|sizeof
argument_list|(
name|phys_avail
argument_list|)
operator|/
sizeof|sizeof
argument_list|(
name|phys_avail
index|[
literal|0
index|]
argument_list|)
operator|<
name|regions_sz
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: phys_avail too small"
argument_list|)
expr_stmt|;
name|phys_avail_count
operator|=
literal|0
expr_stmt|;
name|physsz
operator|=
literal|0
expr_stmt|;
name|hwphyssz
operator|=
literal|0
expr_stmt|;
name|TUNABLE_ULONG_FETCH
argument_list|(
literal|"hw.physmem"
argument_list|,
operator|(
name|u_long
operator|*
operator|)
operator|&
name|hwphyssz
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
operator|,
name|j
operator|=
literal|0
init|;
name|i
operator|<
name|regions_sz
condition|;
name|i
operator|++
operator|,
name|j
operator|+=
literal|2
control|)
block|{
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"region: %#x - %#x (%#x)"
argument_list|,
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
argument_list|,
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
argument_list|,
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
argument_list|)
expr_stmt|;
if|if
condition|(
name|hwphyssz
operator|!=
literal|0
operator|&&
operator|(
name|physsz
operator|+
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
operator|)
operator|>=
name|hwphyssz
condition|)
block|{
if|if
condition|(
name|physsz
operator|<
name|hwphyssz
condition|)
block|{
name|phys_avail
index|[
name|j
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|hwphyssz
operator|-
name|physsz
expr_stmt|;
name|physsz
operator|=
name|hwphyssz
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
break|break;
block|}
name|phys_avail
index|[
name|j
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
name|physsz
operator|+=
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
expr_stmt|;
block|}
comment|/* Check for overlap with the kernel and exception vectors */
for|for
control|(
name|j
operator|=
literal|0
init|;
name|j
operator|<
literal|2
operator|*
name|phys_avail_count
condition|;
name|j
operator|+=
literal|2
control|)
block|{
if|if
condition|(
name|phys_avail
index|[
name|j
index|]
operator|<
name|EXC_LAST
condition|)
name|phys_avail
index|[
name|j
index|]
operator|+=
name|EXC_LAST
expr_stmt|;
if|if
condition|(
name|kernelstart
operator|>=
name|phys_avail
index|[
name|j
index|]
operator|&&
name|kernelstart
operator|<
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
condition|)
block|{
if|if
condition|(
name|kernelend
operator|<
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
condition|)
block|{
name|phys_avail
index|[
literal|2
operator|*
name|phys_avail_count
index|]
operator|=
operator|(
name|kernelend
operator|&
operator|~
name|PAGE_MASK
operator|)
operator|+
name|PAGE_SIZE
expr_stmt|;
name|phys_avail
index|[
literal|2
operator|*
name|phys_avail_count
operator|+
literal|1
index|]
operator|=
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|kernelstart
operator|&
operator|~
name|PAGE_MASK
expr_stmt|;
block|}
if|if
condition|(
name|kernelend
operator|>=
name|phys_avail
index|[
name|j
index|]
operator|&&
name|kernelend
operator|<
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
condition|)
block|{
if|if
condition|(
name|kernelstart
operator|>
name|phys_avail
index|[
name|j
index|]
condition|)
block|{
name|phys_avail
index|[
literal|2
operator|*
name|phys_avail_count
index|]
operator|=
name|phys_avail
index|[
name|j
index|]
expr_stmt|;
name|phys_avail
index|[
literal|2
operator|*
name|phys_avail_count
operator|+
literal|1
index|]
operator|=
name|kernelstart
operator|&
operator|~
name|PAGE_MASK
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
name|phys_avail
index|[
name|j
index|]
operator|=
operator|(
name|kernelend
operator|&
operator|~
name|PAGE_MASK
operator|)
operator|+
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
name|physmem
operator|=
name|btoc
argument_list|(
name|physsz
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|PTEGCOUNT
name|moea64_pteg_count
operator|=
name|PTEGCOUNT
expr_stmt|;
else|#
directive|else
name|moea64_pteg_count
operator|=
literal|0x1000
expr_stmt|;
while|while
condition|(
name|moea64_pteg_count
operator|<
name|physmem
condition|)
name|moea64_pteg_count
operator|<<=
literal|1
expr_stmt|;
name|moea64_pteg_count
operator|>>=
literal|1
expr_stmt|;
endif|#
directive|endif
comment|/* PTEGCOUNT */
block|}
end_function

begin_function
name|void
name|moea64_mid_bootstrap
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|vm_offset_t
name|kernelstart
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
block|{
name|vm_size_t
name|size
decl_stmt|;
name|register_t
name|msr
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * Set PTEG mask 	 */
name|moea64_pteg_mask
operator|=
name|moea64_pteg_count
operator|-
literal|1
expr_stmt|;
comment|/* 	 * Allocate pv/overflow lists. 	 */
name|size
operator|=
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_head
argument_list|)
operator|*
name|moea64_pteg_count
expr_stmt|;
name|moea64_pvo_table
operator|=
operator|(
expr|struct
name|pvo_head
operator|*
operator|)
name|moea64_bootstrap_alloc
argument_list|(
name|size
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|CTR1
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_bootstrap: PVO table at %p"
argument_list|,
name|moea64_pvo_table
argument_list|)
expr_stmt|;
name|DISABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|moea64_pteg_count
condition|;
name|i
operator|++
control|)
name|LIST_INIT
argument_list|(
operator|&
name|moea64_pvo_table
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|ENABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the lock that synchronizes access to the pteg and pvo 	 * tables. 	 */
name|rw_init_flags
argument_list|(
operator|&
name|moea64_table_lock
argument_list|,
literal|"pmap tables"
argument_list|,
name|RW_RECURSE
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|,
literal|"SLB table"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* 	 * Initialise the unmanaged pvo pool. 	 */
name|moea64_bpvo_pool
operator|=
operator|(
expr|struct
name|pvo_entry
operator|*
operator|)
name|moea64_bootstrap_alloc
argument_list|(
name|BPVO_POOL_SIZE
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|moea64_bpvo_pool_index
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Make sure kernel vsid is allocated as well as VSID 0. 	 */
ifndef|#
directive|ifndef
name|__powerpc64__
name|moea64_vsid_bitmap
index|[
operator|(
name|KERNEL_VSIDBITS
operator|&
operator|(
name|NVSIDS
operator|-
literal|1
operator|)
operator|)
operator|/
name|VSID_NBPW
index|]
operator||=
literal|1
operator|<<
operator|(
name|KERNEL_VSIDBITS
operator|%
name|VSID_NBPW
operator|)
expr_stmt|;
name|moea64_vsid_bitmap
index|[
literal|0
index|]
operator||=
literal|1
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Initialize the kernel pmap (which is statically allocated). 	 */
ifdef|#
directive|ifdef
name|__powerpc64__
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|64
condition|;
name|i
operator|++
control|)
block|{
name|pcpup
operator|->
name|pc_slb
index|[
name|i
index|]
operator|.
name|slbv
operator|=
literal|0
expr_stmt|;
name|pcpup
operator|->
name|pc_slb
index|[
name|i
index|]
operator|.
name|slbe
operator|=
literal|0
expr_stmt|;
block|}
else|#
directive|else
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|16
condition|;
name|i
operator|++
control|)
name|kernel_pmap
operator|->
name|pm_sr
index|[
name|i
index|]
operator|=
name|EMPTY_SEGMENT
operator|+
name|i
expr_stmt|;
endif|#
directive|endif
name|kernel_pmap
operator|->
name|pmap_phys
operator|=
name|kernel_pmap
expr_stmt|;
name|CPU_FILL
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|RB_INIT
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pmap_pvo
argument_list|)
expr_stmt|;
name|PMAP_LOCK_INIT
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Now map in all the other buffers we allocated earlier 	 */
name|moea64_setup_direct_map
argument_list|(
name|mmup
argument_list|,
name|kernelstart
argument_list|,
name|kernelend
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_late_bootstrap
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|vm_offset_t
name|kernelstart
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
block|{
name|ihandle_t
name|mmui
decl_stmt|;
name|phandle_t
name|chosen
decl_stmt|;
name|phandle_t
name|mmu
decl_stmt|;
name|size_t
name|sz
decl_stmt|;
name|int
name|i
decl_stmt|;
name|vm_offset_t
name|pa
decl_stmt|,
name|va
decl_stmt|;
name|void
modifier|*
name|dpcpu
decl_stmt|;
comment|/* 	 * Set up the Open Firmware pmap and add its mappings if not in real 	 * mode. 	 */
name|chosen
operator|=
name|OF_finddevice
argument_list|(
literal|"/chosen"
argument_list|)
expr_stmt|;
if|if
condition|(
name|chosen
operator|!=
operator|-
literal|1
operator|&&
name|OF_getprop
argument_list|(
name|chosen
argument_list|,
literal|"mmu"
argument_list|,
operator|&
name|mmui
argument_list|,
literal|4
argument_list|)
operator|!=
operator|-
literal|1
condition|)
block|{
name|mmu
operator|=
name|OF_instance_to_package
argument_list|(
name|mmui
argument_list|)
expr_stmt|;
if|if
condition|(
name|mmu
operator|==
operator|-
literal|1
operator|||
operator|(
name|sz
operator|=
name|OF_getproplen
argument_list|(
name|mmu
argument_list|,
literal|"translations"
argument_list|)
operator|)
operator|==
operator|-
literal|1
condition|)
name|sz
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|sz
operator|>
literal|6144
comment|/* tmpstksz - 2 KB headroom */
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: too many ofw translations"
argument_list|)
expr_stmt|;
if|if
condition|(
name|sz
operator|>
literal|0
condition|)
name|moea64_add_ofw_mappings
argument_list|(
name|mmup
argument_list|,
name|mmu
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Calculate the last available physical address. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|2
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
empty_stmt|;
name|Maxmem
operator|=
name|powerpc_btop
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize MMU and remap early physical mappings 	 */
name|MMU_CPU_BOOTSTRAP
argument_list|(
name|mmup
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|mtmsr
argument_list|(
name|mfmsr
argument_list|()
operator||
name|PSL_DR
operator||
name|PSL_IR
argument_list|)
expr_stmt|;
name|pmap_bootstrapped
operator|++
expr_stmt|;
name|bs_remap_earlyboot
argument_list|()
expr_stmt|;
comment|/* 	 * Set the start and end of kva. 	 */
name|virtual_avail
operator|=
name|VM_MIN_KERNEL_ADDRESS
expr_stmt|;
name|virtual_end
operator|=
name|VM_MAX_SAFE_KERNEL_ADDRESS
expr_stmt|;
comment|/* 	 * Map the entire KVA range into the SLB. We must not fault there. 	 */
ifdef|#
directive|ifdef
name|__powerpc64__
for|for
control|(
name|va
operator|=
name|virtual_avail
init|;
name|va
operator|<
name|virtual_end
condition|;
name|va
operator|+=
name|SEGMENT_LENGTH
control|)
name|moea64_bootstrap_slb_prefault
argument_list|(
name|va
argument_list|,
literal|0
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Figure out how far we can extend virtual_end into segment 16 	 * without running into existing mappings. Segment 16 is guaranteed 	 * to contain neither RAM nor devices (at least on Apple hardware), 	 * but will generally contain some OFW mappings we should not 	 * step on. 	 */
ifndef|#
directive|ifndef
name|__powerpc64__
comment|/* KVA is in high memory on PPC64 */
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
while|while
condition|(
name|virtual_end
operator|<
name|VM_MAX_KERNEL_ADDRESS
operator|&&
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|virtual_end
operator|+
literal|1
argument_list|)
operator|==
name|NULL
condition|)
name|virtual_end
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Allocate a kernel stack with a guard page for thread0 and map it 	 * into the kernel page map. 	 */
name|pa
operator|=
name|moea64_bootstrap_alloc
argument_list|(
name|KSTACK_PAGES
operator|*
name|PAGE_SIZE
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|va
operator|=
name|virtual_avail
operator|+
name|KSTACK_GUARD_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
name|virtual_avail
operator|=
name|va
operator|+
name|KSTACK_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_bootstrap: kstack0 at %#x (%#x)"
argument_list|,
name|pa
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|thread0
operator|.
name|td_kstack
operator|=
name|va
expr_stmt|;
name|thread0
operator|.
name|td_kstack_pages
operator|=
name|KSTACK_PAGES
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|KSTACK_PAGES
condition|;
name|i
operator|++
control|)
block|{
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* 	 * Allocate virtual address space for the message buffer. 	 */
name|pa
operator|=
name|msgbuf_phys
operator|=
name|moea64_bootstrap_alloc
argument_list|(
name|msgbufsize
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|msgbufp
operator|=
operator|(
expr|struct
name|msgbuf
operator|*
operator|)
name|virtual_avail
expr_stmt|;
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|round_page
argument_list|(
name|msgbufsize
argument_list|)
expr_stmt|;
while|while
condition|(
name|va
operator|<
name|virtual_avail
condition|)
block|{
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* 	 * Allocate virtual address space for the dynamic percpu area. 	 */
name|pa
operator|=
name|moea64_bootstrap_alloc
argument_list|(
name|DPCPU_SIZE
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|dpcpu
operator|=
operator|(
name|void
operator|*
operator|)
name|virtual_avail
expr_stmt|;
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|DPCPU_SIZE
expr_stmt|;
while|while
condition|(
name|va
operator|<
name|virtual_avail
condition|)
block|{
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|dpcpu_init
argument_list|(
name|dpcpu
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate some things for page zeroing. We put this directly 	 * in the page table, marked with LPTE_LOCKED, to avoid any 	 * of the PVO book-keeping or other parts of the VM system 	 * from even knowing that this hack exists. 	 */
if|if
condition|(
operator|!
name|hw_direct_map
condition|)
block|{
name|mtx_init
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|,
literal|"pvo zero page"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|2
condition|;
name|i
operator|++
control|)
block|{
name|moea64_scratchpage_va
index|[
name|i
index|]
operator|=
operator|(
name|virtual_end
operator|+
literal|1
operator|)
operator|-
name|PAGE_SIZE
expr_stmt|;
name|virtual_end
operator|-=
name|PAGE_SIZE
expr_stmt|;
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|moea64_scratchpage_va
index|[
name|i
index|]
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|moea64_scratchpage_pvo
index|[
name|i
index|]
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|moea64_scratchpage_va
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|LOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|moea64_scratchpage_pte
index|[
name|i
index|]
operator|=
name|MOEA64_PVO_TO_PTE
argument_list|(
name|mmup
argument_list|,
name|moea64_scratchpage_pvo
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|moea64_scratchpage_pvo
index|[
name|i
index|]
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator||=
name|LPTE_LOCKED
expr_stmt|;
name|MOEA64_PTE_CHANGE
argument_list|(
name|mmup
argument_list|,
name|moea64_scratchpage_pte
index|[
name|i
index|]
argument_list|,
operator|&
name|moea64_scratchpage_pvo
index|[
name|i
index|]
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|moea64_scratchpage_pvo
index|[
name|i
index|]
operator|->
name|pvo_vpn
argument_list|)
expr_stmt|;
name|UNLOCK_TABLE_RD
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * Activate a user pmap.  The pmap must be activated before its address  * space can be accessed in any way.  */
end_comment

begin_function
name|void
name|moea64_activate
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|pm
decl_stmt|;
name|pm
operator|=
operator|&
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
expr_stmt|;
name|CPU_SET
argument_list|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|,
operator|&
name|pm
operator|->
name|pm_active
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|__powerpc64__
name|PCPU_SET
argument_list|(
name|userslb
argument_list|,
name|pm
operator|->
name|pm_slb
argument_list|)
expr_stmt|;
else|#
directive|else
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pm
operator|->
name|pmap_phys
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|moea64_deactivate
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|pm
decl_stmt|;
name|pm
operator|=
operator|&
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
expr_stmt|;
name|CPU_CLR
argument_list|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|,
operator|&
name|pm
operator|->
name|pm_active
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|__powerpc64__
name|PCPU_SET
argument_list|(
name|userslb
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
else|#
directive|else
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_function
name|void
name|moea64_change_wiring
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|boolean_t
name|wired
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|uintptr_t
name|pt
decl_stmt|;
name|uint64_t
name|vsid
decl_stmt|;
name|int
name|i
decl_stmt|,
name|ptegidx
decl_stmt|;
name|LOCK_TABLE_WR
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pm
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
condition|)
block|{
name|pt
operator|=
name|MOEA64_PVO_TO_PTE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
if|if
condition|(
name|wired
condition|)
block|{
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
operator|)
operator|==
literal|0
condition|)
name|pm
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_WIRED
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator||=
name|LPTE_WIRED
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
operator|)
operator|!=
literal|0
condition|)
name|pm
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator|&=
operator|~
name|PVO_WIRED
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&=
operator|~
name|LPTE_WIRED
expr_stmt|;
block|}
if|if
condition|(
name|pt
operator|!=
operator|-
literal|1
condition|)
block|{
comment|/* Update wiring flag in page table. */
name|MOEA64_PTE_CHANGE
argument_list|(
name|mmu
argument_list|,
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|pvo
operator|->
name|pvo_vpn
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|wired
condition|)
block|{
comment|/* 			 * If we are wiring the page, and it wasn't in the 			 * page table before, add it. 			 */
name|vsid
operator|=
name|PVO_VSID
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
name|ptegidx
operator|=
name|va_to_pteg
argument_list|(
name|vsid
argument_list|,
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
argument_list|,
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_LARGE
argument_list|)
expr_stmt|;
name|i
operator|=
name|MOEA64_PTE_INSERT
argument_list|(
name|mmu
argument_list|,
name|ptegidx
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|>=
literal|0
condition|)
block|{
name|PVO_PTEGIDX_CLR
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
name|PVO_PTEGIDX_SET
argument_list|(
name|pvo
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|UNLOCK_TABLE_WR
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This goes through and sets the physical address of our  * special scratch PTE to the PA we want to zero or copy. Because  * of locking issues (this can get called in pvo_enter() by  * the UMA allocator), we can't use most other utility functions here  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|moea64_set_scratchpage_pa
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|int
name|which
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|!
name|hw_direct_map
argument_list|,
operator|(
literal|"Using OEA64 scratchpage with a direct map!"
operator|)
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|moea64_scratchpage_pvo
index|[
name|which
index|]
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
operator|(
name|LPTE_WIMG
operator||
name|LPTE_RPGN
operator|)
expr_stmt|;
name|moea64_scratchpage_pvo
index|[
name|which
index|]
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator||=
name|moea64_calc_wimg
argument_list|(
name|pa
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
operator||
operator|(
name|uint64_t
operator|)
name|pa
expr_stmt|;
name|MOEA64_PTE_CHANGE
argument_list|(
name|mmup
argument_list|,
name|moea64_scratchpage_pte
index|[
name|which
index|]
argument_list|,
operator|&
name|moea64_scratchpage_pvo
index|[
name|which
index|]
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|moea64_scratchpage_pvo
index|[
name|which
index|]
operator|->
name|pvo_vpn
argument_list|)
expr_stmt|;
name|isync
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_copy_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|msrc
parameter_list|,
name|vm_page_t
name|mdst
parameter_list|)
block|{
name|vm_offset_t
name|dst
decl_stmt|;
name|vm_offset_t
name|src
decl_stmt|;
name|dst
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|mdst
argument_list|)
expr_stmt|;
name|src
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|msrc
argument_list|)
expr_stmt|;
if|if
condition|(
name|hw_direct_map
condition|)
block|{
name|bcopy
argument_list|(
operator|(
name|void
operator|*
operator|)
name|src
argument_list|,
operator|(
name|void
operator|*
operator|)
name|dst
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|0
argument_list|,
name|src
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|1
argument_list|,
name|dst
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
operator|(
name|void
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|0
index|]
argument_list|,
operator|(
name|void
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|1
index|]
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
specifier|inline
name|void
name|moea64_copy_pages_dmap
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
modifier|*
name|mb
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
block|{
name|void
modifier|*
name|a_cp
decl_stmt|,
modifier|*
name|b_cp
decl_stmt|;
name|vm_offset_t
name|a_pg_offset
decl_stmt|,
name|b_pg_offset
decl_stmt|;
name|int
name|cnt
decl_stmt|;
while|while
condition|(
name|xfersize
operator|>
literal|0
condition|)
block|{
name|a_pg_offset
operator|=
name|a_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|xfersize
argument_list|,
name|PAGE_SIZE
operator|-
name|a_pg_offset
argument_list|)
expr_stmt|;
name|a_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|VM_PAGE_TO_PHYS
argument_list|(
name|ma
index|[
name|a_offset
operator|>>
name|PAGE_SHIFT
index|]
argument_list|)
operator|+
name|a_pg_offset
expr_stmt|;
name|b_pg_offset
operator|=
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|cnt
argument_list|,
name|PAGE_SIZE
operator|-
name|b_pg_offset
argument_list|)
expr_stmt|;
name|b_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|VM_PAGE_TO_PHYS
argument_list|(
name|mb
index|[
name|b_offset
operator|>>
name|PAGE_SHIFT
index|]
argument_list|)
operator|+
name|b_pg_offset
expr_stmt|;
name|bcopy
argument_list|(
name|a_cp
argument_list|,
name|b_cp
argument_list|,
name|cnt
argument_list|)
expr_stmt|;
name|a_offset
operator|+=
name|cnt
expr_stmt|;
name|b_offset
operator|+=
name|cnt
expr_stmt|;
name|xfersize
operator|-=
name|cnt
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
specifier|inline
name|void
name|moea64_copy_pages_nodmap
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
modifier|*
name|mb
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
block|{
name|void
modifier|*
name|a_cp
decl_stmt|,
modifier|*
name|b_cp
decl_stmt|;
name|vm_offset_t
name|a_pg_offset
decl_stmt|,
name|b_pg_offset
decl_stmt|;
name|int
name|cnt
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
while|while
condition|(
name|xfersize
operator|>
literal|0
condition|)
block|{
name|a_pg_offset
operator|=
name|a_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|xfersize
argument_list|,
name|PAGE_SIZE
operator|-
name|a_pg_offset
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|0
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|ma
index|[
name|a_offset
operator|>>
name|PAGE_SHIFT
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|a_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|0
index|]
operator|+
name|a_pg_offset
expr_stmt|;
name|b_pg_offset
operator|=
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|cnt
argument_list|,
name|PAGE_SIZE
operator|-
name|b_pg_offset
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|1
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|mb
index|[
name|b_offset
operator|>>
name|PAGE_SHIFT
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|b_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|1
index|]
operator|+
name|b_pg_offset
expr_stmt|;
name|bcopy
argument_list|(
name|a_cp
argument_list|,
name|b_cp
argument_list|,
name|cnt
argument_list|)
expr_stmt|;
name|a_offset
operator|+=
name|cnt
expr_stmt|;
name|b_offset
operator|+=
name|cnt
expr_stmt|;
name|xfersize
operator|-=
name|cnt
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_copy_pages
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
modifier|*
name|mb
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
block|{
if|if
condition|(
name|hw_direct_map
condition|)
block|{
name|moea64_copy_pages_dmap
argument_list|(
name|mmu
argument_list|,
name|ma
argument_list|,
name|a_offset
argument_list|,
name|mb
argument_list|,
name|b_offset
argument_list|,
name|xfersize
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|moea64_copy_pages_nodmap
argument_list|(
name|mmu
argument_list|,
name|ma
argument_list|,
name|a_offset
argument_list|,
name|mb
argument_list|,
name|b_offset
argument_list|,
name|xfersize
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|moea64_zero_page_area
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_offset_t
name|pa
init|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
decl_stmt|;
if|if
condition|(
name|size
operator|+
name|off
operator|>
name|PAGE_SIZE
condition|)
name|panic
argument_list|(
literal|"moea64_zero_page: size + off> PAGE_SIZE"
argument_list|)
expr_stmt|;
if|if
condition|(
name|hw_direct_map
condition|)
block|{
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|pa
operator|+
name|off
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|0
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|moea64_scratchpage_va
index|[
literal|0
index|]
operator|+
name|off
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Zero a page of physical memory by temporarily mapping it  */
end_comment

begin_function
name|void
name|moea64_zero_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_offset_t
name|pa
init|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|off
decl_stmt|;
if|if
condition|(
operator|!
name|hw_direct_map
condition|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|0
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|va
operator|=
name|moea64_scratchpage_va
index|[
literal|0
index|]
expr_stmt|;
block|}
else|else
block|{
name|va
operator|=
name|pa
expr_stmt|;
block|}
for|for
control|(
name|off
operator|=
literal|0
init|;
name|off
operator|<
name|PAGE_SIZE
condition|;
name|off
operator|+=
name|cacheline_size
control|)
asm|__asm __volatile("dcbz 0,%0" :: "r"(va + off));
if|if
condition|(
operator|!
name|hw_direct_map
condition|)
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_zero_page_idle
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|moea64_zero_page
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map the given physical page at the specified virtual address in the  * target pmap with the protection requested.  If specified the page  * will be wired down.  */
end_comment

begin_function
name|void
name|moea64_enter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|boolean_t
name|wired
parameter_list|)
block|{
name|struct
name|pvo_head
modifier|*
name|pvo_head
decl_stmt|;
name|uma_zone_t
name|zone
decl_stmt|;
name|vm_page_t
name|pg
decl_stmt|;
name|uint64_t
name|pte_lo
decl_stmt|;
name|u_int
name|pvo_flags
decl_stmt|;
name|int
name|error
decl_stmt|;
if|if
condition|(
operator|!
name|moea64_initialized
condition|)
block|{
name|pvo_head
operator|=
name|NULL
expr_stmt|;
name|pg
operator|=
name|NULL
expr_stmt|;
name|zone
operator|=
name|moea64_upvo_zone
expr_stmt|;
name|pvo_flags
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
name|pvo_head
operator|=
name|vm_page_to_pvoh
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pg
operator|=
name|m
expr_stmt|;
name|zone
operator|=
name|moea64_mpvo_zone
expr_stmt|;
name|pvo_flags
operator|=
name|PVO_MANAGED
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
operator|(
name|VPO_UNMANAGED
operator||
name|VPO_BUSY
operator|)
operator|)
operator|==
literal|0
condition|)
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
comment|/* XXX change the pvo head for fake pages */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
block|{
name|pvo_flags
operator|&=
operator|~
name|PVO_MANAGED
expr_stmt|;
name|pvo_head
operator|=
name|NULL
expr_stmt|;
name|zone
operator|=
name|moea64_upvo_zone
expr_stmt|;
block|}
name|pte_lo
operator|=
name|moea64_calc_wimg
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
block|{
name|pte_lo
operator||=
name|LPTE_BW
expr_stmt|;
if|if
condition|(
name|pmap_bootstrapped
operator|&&
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
else|else
name|pte_lo
operator||=
name|LPTE_BR
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|pte_lo
operator||=
name|LPTE_NOEXEC
expr_stmt|;
if|if
condition|(
name|wired
condition|)
name|pvo_flags
operator||=
name|PVO_WIRED
expr_stmt|;
name|LOCK_TABLE_WR
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|error
operator|=
name|moea64_pvo_enter
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|zone
argument_list|,
name|pvo_head
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|pte_lo
argument_list|,
name|pvo_flags
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|UNLOCK_TABLE_WR
argument_list|()
expr_stmt|;
comment|/* 	 * Flush the page from the instruction cache if this page is 	 * mapped executable and cacheable. 	 */
if|if
condition|(
name|pmap
operator|!=
name|kernel_pmap
operator|&&
operator|!
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_EXECUTABLE
operator|)
operator|&&
operator|(
name|pte_lo
operator|&
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator||
name|LPTE_NOEXEC
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_EXECUTABLE
argument_list|)
expr_stmt|;
name|moea64_syncicache
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_syncicache
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|vm_size_t
name|sz
parameter_list|)
block|{
comment|/* 	 * This is much trickier than on older systems because 	 * we can't sync the icache on physical addresses directly 	 * without a direct map. Instead we check a couple of cases 	 * where the memory is already mapped in and, failing that, 	 * use the same trick we use for page zeroing to create 	 * a temporary mapping for this physical address. 	 */
if|if
condition|(
operator|!
name|pmap_bootstrapped
condition|)
block|{
comment|/* 		 * If PMAP is not bootstrapped, we are likely to be 		 * in real mode. 		 */
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|pa
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hw_direct_map
condition|)
block|{
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|pa
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Use the scratch page to set up a temp mapping */
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|1
argument_list|,
name|pa
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
operator|(
name|moea64_scratchpage_va
index|[
literal|1
index|]
operator|+
operator|(
name|va
operator|&
name|ADDR_POFF
operator|)
operator|)
argument_list|,
name|sz
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Maps a sequence of resident pages belonging to the same object.  * The sequence begins with the given page m_start.  This page is  * mapped at the given virtual address start.  Each subsequent page is  * mapped at a virtual address that is offset from start by the same  * amount as the page is offset from m_start within the object.  The  * last page in the sequence is the page with the largest offset from  * m_start that can be mapped at a virtual address less than the given  * virtual address end.  Not every virtual page between start and end  * is mapped; only those for which a resident page exists with the  * corresponding offset from m_start are mapped.  */
end_comment

begin_function
name|void
name|moea64_enter_object
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|start
parameter_list|,
name|vm_offset_t
name|end
parameter_list|,
name|vm_page_t
name|m_start
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_pindex_t
name|diff
decl_stmt|,
name|psize
decl_stmt|;
name|psize
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|m
operator|=
name|m_start
expr_stmt|;
while|while
condition|(
name|m
operator|!=
name|NULL
operator|&&
operator|(
name|diff
operator|=
name|m
operator|->
name|pindex
operator|-
name|m_start
operator|->
name|pindex
operator|)
operator|<
name|psize
condition|)
block|{
name|moea64_enter
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|start
operator|+
name|ptoa
argument_list|(
name|diff
argument_list|)
argument_list|,
name|m
argument_list|,
name|prot
operator|&
operator|(
name|VM_PROT_READ
operator||
name|VM_PROT_EXECUTE
operator|)
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|m
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|moea64_enter_quick
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|moea64_enter
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
operator|&
operator|(
name|VM_PROT_READ
operator||
name|VM_PROT_EXECUTE
operator|)
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|vm_paddr_t
name|moea64_extract
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|==
name|NULL
condition|)
name|pa
operator|=
literal|0
expr_stmt|;
else|else
name|pa
operator|=
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
operator|)
operator||
operator|(
name|va
operator|-
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Atomically extract and hold the physical page with the given  * pmap and virtual address pair if that mapping permits the given  * protection.  */
end_comment

begin_function
name|vm_page_t
name|moea64_extract_and_hold
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pmap
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&
name|LPTE_VALID
operator|)
operator|&&
operator|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_PP
operator|)
operator|==
name|LPTE_RW
operator|||
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
operator|)
condition|)
block|{
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
argument_list|,
operator|&
name|pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|PA_UNLOCK_COND
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|mmu_t
name|installed_mmu
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|void
modifier|*
name|moea64_uma_page_alloc
parameter_list|(
name|uma_zone_t
name|zone
parameter_list|,
name|int
name|bytes
parameter_list|,
name|u_int8_t
modifier|*
name|flags
parameter_list|,
name|int
name|wait
parameter_list|)
block|{
comment|/* 	 * This entire routine is a horrible hack to avoid bothering kmem 	 * for new KVA addresses. Because this can get called from inside 	 * kmem allocation routines, calling kmem for a new address here 	 * can lead to multiply locking non-recursive mutexes. 	 */
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|pflags
decl_stmt|,
name|needed_lock
decl_stmt|;
operator|*
name|flags
operator|=
name|UMA_SLAB_PRIV
expr_stmt|;
name|needed_lock
operator|=
operator|!
name|PMAP_LOCKED
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|pflags
operator|=
name|malloc2vm_flags
argument_list|(
name|wait
argument_list|)
operator||
name|VM_ALLOC_WIRED
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|pflags
operator||
name|VM_ALLOC_NOOBJ
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|wait
operator|&
name|M_NOWAIT
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|VM_WAIT
expr_stmt|;
block|}
else|else
break|break;
block|}
name|va
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|LOCK_TABLE_WR
argument_list|()
expr_stmt|;
if|if
condition|(
name|needed_lock
condition|)
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|moea64_pvo_enter
argument_list|(
name|installed_mmu
argument_list|,
name|kernel_pmap
argument_list|,
name|moea64_upvo_zone
argument_list|,
name|NULL
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|LPTE_M
argument_list|,
name|PVO_WIRED
operator||
name|PVO_BOOTSTRAP
argument_list|)
expr_stmt|;
if|if
condition|(
name|needed_lock
condition|)
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|UNLOCK_TABLE_WR
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|wait
operator|&
name|M_ZERO
operator|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
return|return
operator|(
name|void
operator|*
operator|)
name|va
return|;
block|}
end_function

begin_decl_stmt
specifier|extern
name|int
name|elf32_nxstack
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|moea64_init
parameter_list|(
name|mmu_t
name|mmu
parameter_list|)
block|{
name|CTR0
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_init"
argument_list|)
expr_stmt|;
name|moea64_upvo_zone
operator|=
name|uma_zcreate
argument_list|(
literal|"UPVO entry"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|UMA_ALIGN_PTR
argument_list|,
name|UMA_ZONE_VM
operator||
name|UMA_ZONE_NOFREE
argument_list|)
expr_stmt|;
name|moea64_mpvo_zone
operator|=
name|uma_zcreate
argument_list|(
literal|"MPVO entry"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|UMA_ALIGN_PTR
argument_list|,
name|UMA_ZONE_VM
operator||
name|UMA_ZONE_NOFREE
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|hw_direct_map
condition|)
block|{
name|installed_mmu
operator|=
name|mmu
expr_stmt|;
name|uma_zone_set_allocf
argument_list|(
name|moea64_upvo_zone
argument_list|,
name|moea64_uma_page_alloc
argument_list|)
expr_stmt|;
name|uma_zone_set_allocf
argument_list|(
name|moea64_mpvo_zone
argument_list|,
name|moea64_uma_page_alloc
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|COMPAT_FREEBSD32
name|elf32_nxstack
operator|=
literal|1
expr_stmt|;
endif|#
directive|endif
name|moea64_initialized
operator|=
name|TRUE
expr_stmt|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_is_referenced
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_is_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|moea64_query_bit
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
name|PTE_REF
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_is_modified
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_is_modified: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not VPO_BUSY, then PGA_WRITEABLE cannot be 	 * concurrently set while the object is locked.  Thus, if PGA_WRITEABLE 	 * is clear, no PTEs can have LPTE_CHG set. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
return|return
operator|(
name|moea64_query_bit
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
name|LPTE_CHG
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_is_prefaultable
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pmap
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
name|rv
operator|=
name|pvo
operator|==
name|NULL
operator|||
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&
name|LPTE_VALID
operator|)
operator|==
literal|0
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_function
name|void
name|moea64_clear_reference
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_clear_reference: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|moea64_clear_bit
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
name|LPTE_REF
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_clear_modify
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_clear_modify: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_clear_modify: page %p is busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not PGA_WRITEABLE, then no PTEs can have LPTE_CHG 	 * set.  If the object containing the page is locked and the page is 	 * not VPO_BUSY, then PGA_WRITEABLE cannot be concurrently set. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|moea64_clear_bit
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
name|LPTE_CHG
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Clear the write and modified bits in each of the given page's mappings.  */
end_comment

begin_function
name|void
name|moea64_remove_write
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|uintptr_t
name|pt
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|uint64_t
name|lo
init|=
literal|0
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_remove_write: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not VPO_BUSY, then PGA_WRITEABLE cannot be set by 	 * another thread while the object is locked.  Thus, if PGA_WRITEABLE 	 * is clear, no page table entries need updating. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|powerpc_sync
argument_list|()
expr_stmt|;
name|LOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|pmap
operator|=
name|pvo
operator|->
name|pvo_pmap
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_PP
operator|)
operator|!=
name|LPTE_BR
condition|)
block|{
name|pt
operator|=
name|MOEA64_PVO_TO_PTE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|LPTE_PP
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator||=
name|LPTE_BR
expr_stmt|;
if|if
condition|(
name|pt
operator|!=
operator|-
literal|1
condition|)
block|{
name|MOEA64_PTE_SYNCH
argument_list|(
name|mmu
argument_list|,
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|)
expr_stmt|;
name|lo
operator||=
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|LPTE_CHG
expr_stmt|;
name|MOEA64_PTE_CHANGE
argument_list|(
name|mmu
argument_list|,
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|pvo
operator|->
name|pvo_vpn
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|kernel_pmap
condition|)
name|isync
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|(
name|lo
operator|&
name|LPTE_CHG
operator|)
operator|!=
literal|0
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|UNLOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	moea64_ts_referenced:  *  *	Return a count of reference bits for a page, clearing those bits.  *	It is not necessary for every reference bit to be cleared, but it  *	is necessary that 0 only be returned when there are truly no  *	reference bits set.  *  *	XXX: The exact number of bits to check and clear is a matter that  *	should be tested and standardized at some point in the future for  *	optimal aging of shared pages.  */
end_comment

begin_function
name|int
name|moea64_ts_referenced
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_ts_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|moea64_clear_bit
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
name|LPTE_REF
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Modify the WIMG settings of all mappings for a page.  */
end_comment

begin_function
name|void
name|moea64_page_set_memattr
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|struct
name|pvo_head
modifier|*
name|pvo_head
decl_stmt|;
name|uintptr_t
name|pt
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|uint64_t
name|lo
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
block|{
name|m
operator|->
name|md
operator|.
name|mdpg_cache_attrs
operator|=
name|ma
expr_stmt|;
return|return;
block|}
name|pvo_head
operator|=
name|vm_page_to_pvoh
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|lo
operator|=
name|moea64_calc_wimg
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|ma
argument_list|)
expr_stmt|;
name|LOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|pvo_head
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|pmap
operator|=
name|pvo
operator|->
name|pvo_pmap
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pt
operator|=
name|MOEA64_PVO_TO_PTE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|LPTE_WIMG
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator||=
name|lo
expr_stmt|;
if|if
condition|(
name|pt
operator|!=
operator|-
literal|1
condition|)
block|{
name|MOEA64_PTE_CHANGE
argument_list|(
name|mmu
argument_list|,
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|pvo
operator|->
name|pvo_vpn
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|kernel_pmap
condition|)
name|isync
argument_list|()
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|UNLOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|mdpg_cache_attrs
operator|=
name|ma
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map a wired page into kernel virtual address space.  */
end_comment

begin_function
name|void
name|moea64_kenter_attr
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|uint64_t
name|pte_lo
decl_stmt|;
name|int
name|error
decl_stmt|;
name|pte_lo
operator|=
name|moea64_calc_wimg
argument_list|(
name|pa
argument_list|,
name|ma
argument_list|)
expr_stmt|;
name|LOCK_TABLE_WR
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|error
operator|=
name|moea64_pvo_enter
argument_list|(
name|mmu
argument_list|,
name|kernel_pmap
argument_list|,
name|moea64_upvo_zone
argument_list|,
name|NULL
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|pte_lo
argument_list|,
name|PVO_WIRED
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|UNLOCK_TABLE_WR
argument_list|()
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
operator|&&
name|error
operator|!=
name|ENOENT
condition|)
name|panic
argument_list|(
literal|"moea64_kenter: failed to enter va %#zx pa %#zx: %d"
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|error
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_kenter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|moea64_kenter_attr
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Extract the physical page address associated with the given kernel virtual  * address.  */
end_comment

begin_function
name|vm_paddr_t
name|moea64_kextract
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
comment|/* 	 * Shortcut the direct-mapped case when applicable.  We never put 	 * anything but 1:1 mappings below VM_MIN_KERNEL_ADDRESS. 	 */
if|if
condition|(
name|va
operator|<
name|VM_MIN_KERNEL_ADDRESS
condition|)
return|return
operator|(
name|va
operator|)
return|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pvo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"moea64_kextract: no addr found for %#"
name|PRIxPTR
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
name|pa
operator|=
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
operator|)
operator||
operator|(
name|va
operator|-
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Remove a wired page from kernel virtual address space.  */
end_comment

begin_function
name|void
name|moea64_kremove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|moea64_remove
argument_list|(
name|mmu
argument_list|,
name|kernel_pmap
argument_list|,
name|va
argument_list|,
name|va
operator|+
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map a range of physical addresses into kernel virtual address space.  *  * The value passed in *virt is a suggested virtual address for the mapping.  * Architectures which can support a direct-mapped physical to virtual region  * can return the appropriate address within that region, leaving '*virt'  * unchanged.  We cannot and therefore do not; *virt is updated with the  * first usable address after the mapped region.  */
end_comment

begin_function
name|vm_offset_t
name|moea64_map
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
modifier|*
name|virt
parameter_list|,
name|vm_paddr_t
name|pa_start
parameter_list|,
name|vm_paddr_t
name|pa_end
parameter_list|,
name|int
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|sva
decl_stmt|,
name|va
decl_stmt|;
name|sva
operator|=
operator|*
name|virt
expr_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
for|for
control|(
init|;
name|pa_start
operator|<
name|pa_end
condition|;
name|pa_start
operator|+=
name|PAGE_SIZE
operator|,
name|va
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|pa_start
argument_list|)
expr_stmt|;
operator|*
name|virt
operator|=
name|va
expr_stmt|;
return|return
operator|(
name|sva
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns true if the pmap's pv is one of the first  * 16 pvs linked to from this page.  This count may  * be changed upwards or downwards in the future; it  * is only necessary that true be returned for a small  * subset of pmaps for proper page aging.  */
end_comment

begin_function
name|boolean_t
name|moea64_page_exists_quick
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|loops
decl_stmt|;
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_page_exists_quick: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|loops
operator|=
literal|0
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|LOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|pmap
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
if|if
condition|(
operator|++
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
name|UNLOCK_TABLE_RD
argument_list|()
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return the number of managed mappings to the given physical page  * that are wired.  */
end_comment

begin_function
name|int
name|moea64_page_wired_mappings
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|int
name|count
decl_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|count
operator|)
return|;
name|LOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
operator|)
operator|!=
literal|0
condition|)
name|count
operator|++
expr_stmt|;
name|UNLOCK_TABLE_RD
argument_list|()
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|uintptr_t
name|moea64_vsidcontext
decl_stmt|;
end_decl_stmt

begin_function
name|uintptr_t
name|moea64_get_unique_vsid
parameter_list|(
name|void
parameter_list|)
block|{
name|u_int
name|entropy
decl_stmt|;
name|register_t
name|hash
decl_stmt|;
name|uint32_t
name|mask
decl_stmt|;
name|int
name|i
decl_stmt|;
name|entropy
operator|=
literal|0
expr_stmt|;
asm|__asm __volatile("mftb %0" : "=r"(entropy));
name|mtx_lock
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NVSIDS
condition|;
name|i
operator|+=
name|VSID_NBPW
control|)
block|{
name|u_int
name|n
decl_stmt|;
comment|/* 		 * Create a new value by mutiplying by a prime and adding in 		 * entropy from the timebase register.  This is to make the 		 * VSID more random so that the PT hash function collides 		 * less often.  (Note that the prime casues gcc to do shifts 		 * instead of a multiply.) 		 */
name|moea64_vsidcontext
operator|=
operator|(
name|moea64_vsidcontext
operator|*
literal|0x1105
operator|)
operator|+
name|entropy
expr_stmt|;
name|hash
operator|=
name|moea64_vsidcontext
operator|&
operator|(
name|NVSIDS
operator|-
literal|1
operator|)
expr_stmt|;
if|if
condition|(
name|hash
operator|==
literal|0
condition|)
comment|/* 0 is special, avoid it */
continue|continue;
name|n
operator|=
name|hash
operator|>>
literal|5
expr_stmt|;
name|mask
operator|=
literal|1
operator|<<
operator|(
name|hash
operator|&
operator|(
name|VSID_NBPW
operator|-
literal|1
operator|)
operator|)
expr_stmt|;
name|hash
operator|=
operator|(
name|moea64_vsidcontext
operator|&
name|VSID_HASHMASK
operator|)
expr_stmt|;
if|if
condition|(
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator|&
name|mask
condition|)
block|{
comment|/* collision? */
comment|/* anything free in this bucket? */
if|if
condition|(
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator|==
literal|0xffffffff
condition|)
block|{
name|entropy
operator|=
operator|(
name|moea64_vsidcontext
operator|>>
literal|20
operator|)
expr_stmt|;
continue|continue;
block|}
name|i
operator|=
name|ffs
argument_list|(
operator|~
name|moea64_vsid_bitmap
index|[
name|n
index|]
argument_list|)
operator|-
literal|1
expr_stmt|;
name|mask
operator|=
literal|1
operator|<<
name|i
expr_stmt|;
name|hash
operator|&=
name|VSID_HASHMASK
operator|&
operator|~
operator|(
name|VSID_NBPW
operator|-
literal|1
operator|)
expr_stmt|;
name|hash
operator||=
name|i
expr_stmt|;
block|}
name|KASSERT
argument_list|(
operator|!
operator|(
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator|&
name|mask
operator|)
argument_list|,
operator|(
literal|"Allocating in-use VSID %#zx\n"
operator|,
name|hash
operator|)
argument_list|)
expr_stmt|;
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator||=
name|mask
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|)
expr_stmt|;
return|return
operator|(
name|hash
operator|)
return|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|)
expr_stmt|;
name|panic
argument_list|(
literal|"%s: out of segments"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|__powerpc64__
end_ifdef

begin_function
name|void
name|moea64_pinit
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|PMAP_LOCK_INIT
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|RB_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pmap_pvo
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_slb_tree_root
operator|=
name|slb_alloc_tree
argument_list|()
expr_stmt|;
name|pmap
operator|->
name|pm_slb
operator|=
name|slb_alloc_user_cache
argument_list|()
expr_stmt|;
name|pmap
operator|->
name|pm_slb_len
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_else
else|#
directive|else
end_else

begin_function
name|void
name|moea64_pinit
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|uint32_t
name|hash
decl_stmt|;
name|PMAP_LOCK_INIT
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|RB_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pmap_pvo
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_bootstrapped
condition|)
name|pmap
operator|->
name|pmap_phys
operator|=
operator|(
name|pmap_t
operator|)
name|moea64_kextract
argument_list|(
name|mmu
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|pmap
argument_list|)
expr_stmt|;
else|else
name|pmap
operator|->
name|pmap_phys
operator|=
name|pmap
expr_stmt|;
comment|/* 	 * Allocate some segment registers for this pmap. 	 */
name|hash
operator|=
name|moea64_get_unique_vsid
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|16
condition|;
name|i
operator|++
control|)
name|pmap
operator|->
name|pm_sr
index|[
name|i
index|]
operator|=
name|VSID_MAKE
argument_list|(
name|i
argument_list|,
name|hash
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_sr
index|[
literal|0
index|]
operator|!=
literal|0
argument_list|,
operator|(
literal|"moea64_pinit: pm_sr[0] = 0"
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Initialize the pmap associated with process 0.  */
end_comment

begin_function
name|void
name|moea64_pinit0
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|)
block|{
name|moea64_pinit
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pm
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
argument_list|(
name|pm
operator|->
name|pm_stats
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Set the physical protection on the specified range of this map as requested.  */
end_comment

begin_function
specifier|static
name|void
name|moea64_pvo_protect
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|uintptr_t
name|pt
decl_stmt|;
name|struct
name|vm_page
modifier|*
name|pg
decl_stmt|;
name|uint64_t
name|oldlo
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pm
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Grab the PTE pointer before we diddle with the cached PTE 	 * copy. 	 */
name|pt
operator|=
name|MOEA64_PVO_TO_PTE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
comment|/* 	 * Change the protection of the page. 	 */
name|oldlo
operator|=
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|LPTE_PP
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|LPTE_NOEXEC
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator||=
name|LPTE_NOEXEC
expr_stmt|;
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator||=
name|LPTE_BW
expr_stmt|;
else|else
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator||=
name|LPTE_BR
expr_stmt|;
name|pg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
comment|/* 	 * If the PVO is in the page table, update that pte as well. 	 */
if|if
condition|(
name|pt
operator|!=
operator|-
literal|1
condition|)
name|MOEA64_PTE_CHANGE
argument_list|(
name|mmu
argument_list|,
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|pvo
operator|->
name|pvo_vpn
argument_list|)
expr_stmt|;
if|if
condition|(
name|pm
operator|!=
name|kernel_pmap
operator|&&
name|pg
operator|!=
name|NULL
operator|&&
operator|!
operator|(
name|pg
operator|->
name|aflags
operator|&
name|PGA_EXECUTABLE
operator|)
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator||
name|LPTE_NOEXEC
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|pg
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|pg
argument_list|,
name|PGA_EXECUTABLE
argument_list|)
expr_stmt|;
name|moea64_syncicache
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
argument_list|,
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Update vm about the REF/CHG bits if the page is managed and we have 	 * removed write access. 	 */
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_MANAGED
operator|)
operator|==
name|PVO_MANAGED
operator|&&
operator|(
name|oldlo
operator|&
name|LPTE_PP
operator|)
operator|!=
name|LPTE_BR
operator|&&
operator|!
operator|(
name|prot
operator|&&
name|VM_PROT_WRITE
operator|)
condition|)
block|{
if|if
condition|(
name|pg
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_CHG
condition|)
name|vm_page_dirty
argument_list|(
name|pg
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_REF
condition|)
name|vm_page_aflag_set
argument_list|(
name|pg
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
name|void
name|moea64_protect
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|tpvo
decl_stmt|,
name|key
decl_stmt|;
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_protect: pm=%p sva=%#x eva=%#x prot=%#x"
argument_list|,
name|pm
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|,
name|prot
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pm
operator|==
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
operator|||
name|pm
operator|==
name|kernel_pmap
argument_list|,
operator|(
literal|"moea64_protect: non current pmap"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_READ
operator|)
operator|==
name|VM_PROT_NONE
condition|)
block|{
name|moea64_remove
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
return|return;
block|}
name|LOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|key
operator|.
name|pvo_vaddr
operator|=
name|sva
expr_stmt|;
for|for
control|(
name|pvo
operator|=
name|RB_NFIND
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
operator|&
name|key
argument_list|)
init|;
name|pvo
operator|!=
name|NULL
operator|&&
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|<
name|eva
condition|;
name|pvo
operator|=
name|tpvo
control|)
block|{
name|tpvo
operator|=
name|RB_NEXT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|moea64_pvo_protect
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|pvo
argument_list|,
name|prot
argument_list|)
expr_stmt|;
block|}
name|UNLOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map a list of wired pages into kernel virtual address space.  This is  * intended for temporary mappings which do not need page modification or  * references recorded.  Existing mappings in the region are overwritten.  */
end_comment

begin_function
name|void
name|moea64_qenter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
modifier|*
name|m
parameter_list|,
name|int
name|count
parameter_list|)
block|{
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|moea64_kenter
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
operator|*
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|m
operator|++
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Remove page mappings from kernel virtual address space.  Intended for  * temporary mappings entered by moea64_qenter.  */
end_comment

begin_function
name|void
name|moea64_qremove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|int
name|count
parameter_list|)
block|{
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|moea64_kremove
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|moea64_release_vsid
parameter_list|(
name|uint64_t
name|vsid
parameter_list|)
block|{
name|int
name|idx
decl_stmt|,
name|mask
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|)
expr_stmt|;
name|idx
operator|=
name|vsid
operator|&
operator|(
name|NVSIDS
operator|-
literal|1
operator|)
expr_stmt|;
name|mask
operator|=
literal|1
operator|<<
operator|(
name|idx
operator|%
name|VSID_NBPW
operator|)
expr_stmt|;
name|idx
operator|/=
name|VSID_NBPW
expr_stmt|;
name|KASSERT
argument_list|(
name|moea64_vsid_bitmap
index|[
name|idx
index|]
operator|&
name|mask
argument_list|,
operator|(
literal|"Freeing unallocated VSID %#jx"
operator|,
name|vsid
operator|)
argument_list|)
expr_stmt|;
name|moea64_vsid_bitmap
index|[
name|idx
index|]
operator|&=
operator|~
name|mask
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_release
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
comment|/* 	 * Free segment registers' VSIDs 	 */
ifdef|#
directive|ifdef
name|__powerpc64__
name|slb_free_tree
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|slb_free_user_cache
argument_list|(
name|pmap
operator|->
name|pm_slb
argument_list|)
expr_stmt|;
else|#
directive|else
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_sr
index|[
literal|0
index|]
operator|!=
literal|0
argument_list|,
operator|(
literal|"moea64_release: pm_sr[0] = 0"
operator|)
argument_list|)
expr_stmt|;
name|moea64_release_vsid
argument_list|(
name|VSID_TO_HASH
argument_list|(
name|pmap
operator|->
name|pm_sr
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|PMAP_LOCK_DESTROY
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove all pages mapped by the specified pmap  */
end_comment

begin_function
name|void
name|moea64_remove_pages
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|tpvo
decl_stmt|;
name|LOCK_TABLE_WR
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|RB_FOREACH_SAFE
argument_list|(
argument|pvo
argument_list|,
argument|pvo_tree
argument_list|,
argument|&pm->pmap_pvo
argument_list|,
argument|tpvo
argument_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
operator|)
condition|)
name|moea64_pvo_remove
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
block|}
name|UNLOCK_TABLE_WR
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove the given range of addresses from the specified map.  */
end_comment

begin_function
name|void
name|moea64_remove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|tpvo
decl_stmt|,
name|key
decl_stmt|;
comment|/* 	 * Perform an unsynchronized read.  This is, however, safe. 	 */
if|if
condition|(
name|pm
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
condition|)
return|return;
name|LOCK_TABLE_WR
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|key
operator|.
name|pvo_vaddr
operator|=
name|sva
expr_stmt|;
for|for
control|(
name|pvo
operator|=
name|RB_NFIND
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
operator|&
name|key
argument_list|)
init|;
name|pvo
operator|!=
name|NULL
operator|&&
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|<
name|eva
condition|;
name|pvo
operator|=
name|tpvo
control|)
block|{
name|tpvo
operator|=
name|RB_NEXT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|moea64_pvo_remove
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
block|}
name|UNLOCK_TABLE_WR
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove physical page from all pmaps in which it resides. moea64_pvo_remove()  * will reflect changes in pte's back to the vm_page.  */
end_comment

begin_function
name|void
name|moea64_remove_all
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|next_pvo
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|LOCK_TABLE_WR
argument_list|()
expr_stmt|;
name|LIST_FOREACH_SAFE
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|,
argument|next_pvo
argument_list|)
block|{
name|pmap
operator|=
name|pvo
operator|->
name|pvo_pmap
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|moea64_pvo_remove
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|UNLOCK_TABLE_WR
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|&&
name|moea64_is_modified
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_EXECUTABLE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Allocate a physical page of memory directly from the phys_avail map.  * Can only be called from moea64_bootstrap before avail start and end are  * calculated.  */
end_comment

begin_function
name|vm_offset_t
name|moea64_bootstrap_alloc
parameter_list|(
name|vm_size_t
name|size
parameter_list|,
name|u_int
name|align
parameter_list|)
block|{
name|vm_offset_t
name|s
decl_stmt|,
name|e
decl_stmt|;
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|size
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
block|{
if|if
condition|(
name|align
operator|!=
literal|0
condition|)
name|s
operator|=
operator|(
name|phys_avail
index|[
name|i
index|]
operator|+
name|align
operator|-
literal|1
operator|)
operator|&
operator|~
operator|(
name|align
operator|-
literal|1
operator|)
expr_stmt|;
else|else
name|s
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
name|e
operator|=
name|s
operator|+
name|size
expr_stmt|;
if|if
condition|(
name|s
operator|<
name|phys_avail
index|[
name|i
index|]
operator|||
name|e
operator|>
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|)
continue|continue;
if|if
condition|(
name|s
operator|+
name|size
operator|>
name|platform_real_maxaddr
argument_list|()
condition|)
continue|continue;
if|if
condition|(
name|s
operator|==
name|phys_avail
index|[
name|i
index|]
condition|)
block|{
name|phys_avail
index|[
name|i
index|]
operator|+=
name|size
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|e
operator|==
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|)
block|{
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-=
name|size
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|j
operator|=
name|phys_avail_count
operator|*
literal|2
init|;
name|j
operator|>
name|i
condition|;
name|j
operator|-=
literal|2
control|)
block|{
name|phys_avail
index|[
name|j
index|]
operator|=
name|phys_avail
index|[
name|j
operator|-
literal|2
index|]
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|phys_avail
index|[
name|j
operator|-
literal|1
index|]
expr_stmt|;
block|}
name|phys_avail
index|[
name|i
operator|+
literal|3
index|]
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|=
name|s
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|2
index|]
operator|=
name|e
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
return|return
operator|(
name|s
operator|)
return|;
block|}
name|panic
argument_list|(
literal|"moea64_bootstrap_alloc: could not allocate memory"
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|moea64_pvo_enter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|uma_zone_t
name|zone
parameter_list|,
name|struct
name|pvo_head
modifier|*
name|pvo_head
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|uint64_t
name|pte_lo
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|uint64_t
name|vsid
decl_stmt|;
name|int
name|first
decl_stmt|;
name|u_int
name|ptegidx
decl_stmt|;
name|int
name|i
decl_stmt|;
name|int
name|bootstrap
decl_stmt|;
comment|/* 	 * One nasty thing that can happen here is that the UMA calls to 	 * allocate new PVOs need to map more memory, which calls pvo_enter(), 	 * which calls UMA... 	 * 	 * We break the loop by detecting recursion and allocating out of 	 * the bootstrap pool. 	 */
name|first
operator|=
literal|0
expr_stmt|;
name|bootstrap
operator|=
operator|(
name|flags
operator|&
name|PVO_BOOTSTRAP
operator|)
expr_stmt|;
if|if
condition|(
operator|!
name|moea64_initialized
condition|)
name|bootstrap
operator|=
literal|1
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pm
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|rw_assert
argument_list|(
operator|&
name|moea64_table_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
comment|/* 	 * Compute the PTE Group index. 	 */
name|va
operator|&=
operator|~
name|ADDR_POFF
expr_stmt|;
name|vsid
operator|=
name|va_to_vsid
argument_list|(
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|ptegidx
operator|=
name|va_to_pteg
argument_list|(
name|vsid
argument_list|,
name|va
argument_list|,
name|flags
operator|&
name|PVO_LARGE
argument_list|)
expr_stmt|;
comment|/* 	 * Remove any existing mapping for this page.  Reuse the pvo entry if 	 * there is a mapping. 	 */
name|moea64_pvo_enter_calls
operator|++
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|&moea64_pvo_table[ptegidx]
argument_list|,
argument|pvo_olink
argument_list|)
block|{
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|pm
operator|&&
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|==
name|va
condition|)
block|{
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
operator|)
operator|==
name|pa
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
operator|(
name|LPTE_NOEXEC
operator||
name|LPTE_PP
operator|)
operator|)
operator|==
operator|(
name|pte_lo
operator|&
operator|(
name|LPTE_NOEXEC
operator||
name|LPTE_PP
operator|)
operator|)
condition|)
block|{
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator|&
name|LPTE_VALID
operator|)
condition|)
block|{
comment|/* Re-insert if spilled */
name|i
operator|=
name|MOEA64_PTE_INSERT
argument_list|(
name|mmu
argument_list|,
name|ptegidx
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|>=
literal|0
condition|)
name|PVO_PTEGIDX_SET
argument_list|(
name|pvo
argument_list|,
name|i
argument_list|)
expr_stmt|;
name|moea64_pte_overflow
operator|--
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|moea64_pvo_remove
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
comment|/* 	 * If we aren't overwriting a mapping, try to allocate. 	 */
if|if
condition|(
name|bootstrap
condition|)
block|{
if|if
condition|(
name|moea64_bpvo_pool_index
operator|>=
name|BPVO_POOL_SIZE
condition|)
block|{
name|panic
argument_list|(
literal|"moea64_enter: bpvo pool exhausted, %d, %d, %zd"
argument_list|,
name|moea64_bpvo_pool_index
argument_list|,
name|BPVO_POOL_SIZE
argument_list|,
name|BPVO_POOL_SIZE
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|pvo
operator|=
operator|&
name|moea64_bpvo_pool
index|[
name|moea64_bpvo_pool_index
index|]
expr_stmt|;
name|moea64_bpvo_pool_index
operator|++
expr_stmt|;
name|bootstrap
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|pvo
operator|=
name|uma_zalloc
argument_list|(
name|zone
argument_list|,
name|M_NOWAIT
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pvo
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
name|moea64_pvo_entries
operator|++
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator|=
name|va
expr_stmt|;
name|pvo
operator|->
name|pvo_vpn
operator|=
call|(
name|uint64_t
call|)
argument_list|(
operator|(
name|va
operator|&
name|ADDR_PIDX
operator|)
operator|>>
name|ADDR_PIDX_SHFT
argument_list|)
operator||
operator|(
name|vsid
operator|<<
literal|16
operator|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pmap
operator|=
name|pm
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|moea64_pvo_table
index|[
name|ptegidx
index|]
argument_list|,
name|pvo
argument_list|,
name|pvo_olink
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator|&=
operator|~
name|ADDR_POFF
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|PVO_WIRED
condition|)
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_WIRED
expr_stmt|;
if|if
condition|(
name|pvo_head
operator|!=
name|NULL
condition|)
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_MANAGED
expr_stmt|;
if|if
condition|(
name|bootstrap
condition|)
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_BOOTSTRAP
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|PVO_LARGE
condition|)
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_LARGE
expr_stmt|;
name|moea64_pte_create
argument_list|(
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|vsid
argument_list|,
name|va
argument_list|,
call|(
name|uint64_t
call|)
argument_list|(
name|pa
argument_list|)
operator||
name|pte_lo
argument_list|,
name|flags
argument_list|)
expr_stmt|;
comment|/* 	 * Add to pmap list 	 */
name|RB_INSERT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
comment|/* 	 * Remember if the list was empty and therefore will be the first 	 * item. 	 */
if|if
condition|(
name|pvo_head
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|LIST_FIRST
argument_list|(
name|pvo_head
argument_list|)
operator|==
name|NULL
condition|)
name|first
operator|=
literal|1
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
name|pvo_head
argument_list|,
name|pvo
argument_list|,
name|pvo_vlink
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
condition|)
block|{
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_hi
operator||=
name|LPTE_WIRED
expr_stmt|;
name|pm
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
block|}
name|pm
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
comment|/* 	 * We hope this succeeds but it isn't required. 	 */
name|i
operator|=
name|MOEA64_PTE_INSERT
argument_list|(
name|mmu
argument_list|,
name|ptegidx
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|>=
literal|0
condition|)
block|{
name|PVO_PTEGIDX_SET
argument_list|(
name|pvo
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|panic
argument_list|(
literal|"moea64_pvo_enter: overflow"
argument_list|)
expr_stmt|;
name|moea64_pte_overflow
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|pm
operator|==
name|kernel_pmap
condition|)
name|isync
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|__powerpc64__
comment|/* 	 * Make sure all our bootstrap mappings are in the SLB as soon 	 * as virtual memory is switched on. 	 */
if|if
condition|(
operator|!
name|pmap_bootstrapped
condition|)
name|moea64_bootstrap_slb_prefault
argument_list|(
name|va
argument_list|,
name|flags
operator|&
name|PVO_LARGE
argument_list|)
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
name|first
condition|?
name|ENOENT
else|:
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_pvo_remove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|)
block|{
name|struct
name|vm_page
modifier|*
name|pg
decl_stmt|;
name|uintptr_t
name|pt
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|rw_assert
argument_list|(
operator|&
name|moea64_table_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
comment|/* 	 * If there is an active pte entry, we need to deactivate it (and 	 * save the ref& cfg bits). 	 */
name|pt
operator|=
name|MOEA64_PVO_TO_PTE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
if|if
condition|(
name|pt
operator|!=
operator|-
literal|1
condition|)
block|{
name|MOEA64_PTE_UNSET
argument_list|(
name|mmu
argument_list|,
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|pvo
operator|->
name|pvo_vpn
argument_list|)
expr_stmt|;
name|PVO_PTEGIDX_CLR
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|moea64_pte_overflow
operator|--
expr_stmt|;
block|}
comment|/* 	 * Update our statistics. 	 */
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
condition|)
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
comment|/* 	 * Remove this PVO from the pmap list. 	 */
name|RB_REMOVE
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
comment|/* 	 * Remove this from the overflow list and return it to the pool 	 * if we aren't going to reuse it. 	 */
name|LIST_REMOVE
argument_list|(
name|pvo
argument_list|,
name|pvo_olink
argument_list|)
expr_stmt|;
comment|/* 	 * Update vm about the REF/CHG bits if the page is managed. 	 */
name|pg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_MANAGED
operator|)
operator|==
name|PVO_MANAGED
operator|&&
name|pg
operator|!=
name|NULL
condition|)
block|{
name|LIST_REMOVE
argument_list|(
name|pvo
argument_list|,
name|pvo_vlink
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_PP
operator|)
operator|!=
name|LPTE_BR
condition|)
block|{
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_CHG
condition|)
name|vm_page_dirty
argument_list|(
name|pg
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_REF
condition|)
name|vm_page_aflag_set
argument_list|(
name|pg
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
if|if
condition|(
name|LIST_EMPTY
argument_list|(
name|vm_page_to_pvoh
argument_list|(
name|pg
argument_list|)
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|pg
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|LIST_EMPTY
argument_list|(
name|vm_page_to_pvoh
argument_list|(
name|pg
argument_list|)
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|pg
argument_list|,
name|PGA_EXECUTABLE
argument_list|)
expr_stmt|;
block|}
name|moea64_pvo_entries
operator|--
expr_stmt|;
name|moea64_pvo_remove_calls
operator|++
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_BOOTSTRAP
operator|)
condition|)
name|uma_zfree
argument_list|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_MANAGED
operator|)
condition|?
name|moea64_mpvo_zone
else|:
name|moea64_upvo_zone
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|struct
name|pvo_entry
modifier|*
name|moea64_pvo_find_va
parameter_list|(
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|pvo_entry
name|key
decl_stmt|;
name|key
operator|.
name|pvo_vaddr
operator|=
name|va
operator|&
operator|~
name|ADDR_POFF
expr_stmt|;
return|return
operator|(
name|RB_FIND
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
operator|&
name|key
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|boolean_t
name|moea64_query_bit
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|u_int64_t
name|ptebit
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|uintptr_t
name|pt
decl_stmt|;
name|LOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
comment|/* 		 * See if we saved the bit off.  If so, return success. 		 */
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|ptebit
condition|)
block|{
name|UNLOCK_TABLE_RD
argument_list|()
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
block|}
comment|/* 	 * No luck, now go through the hard part of looking at the PTEs 	 * themselves.  Sync so that any pending REF/CHG bits are flushed to 	 * the PTEs. 	 */
name|powerpc_sync
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
comment|/* 		 * See if this pvo has a valid PTE.  if so, fetch the 		 * REF/CHG bits from the valid PTE.  If the appropriate 		 * ptebit is set, return success. 		 */
name|PMAP_LOCK
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|)
expr_stmt|;
name|pt
operator|=
name|MOEA64_PVO_TO_PTE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
if|if
condition|(
name|pt
operator|!=
operator|-
literal|1
condition|)
block|{
name|MOEA64_PTE_SYNCH
argument_list|(
name|mmu
argument_list|,
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|ptebit
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|)
expr_stmt|;
name|UNLOCK_TABLE_RD
argument_list|()
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|)
expr_stmt|;
block|}
name|UNLOCK_TABLE_RD
argument_list|()
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|u_int
name|moea64_clear_bit
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|u_int64_t
name|ptebit
parameter_list|)
block|{
name|u_int
name|count
decl_stmt|;
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|uintptr_t
name|pt
decl_stmt|;
comment|/* 	 * Sync so that any pending REF/CHG bits are flushed to the PTEs (so 	 * we can reset the right ones).  note that since the pvo entries and 	 * list heads are accessed via BAT0 and are never placed in the page 	 * table, we don't have to worry about further accesses setting the 	 * REF/CHG bits. 	 */
name|powerpc_sync
argument_list|()
expr_stmt|;
comment|/* 	 * For each pvo entry, clear the pvo's ptebit.  If this pvo has a 	 * valid pte clear the ptebit from the valid pte. 	 */
name|count
operator|=
literal|0
expr_stmt|;
name|LOCK_TABLE_RD
argument_list|()
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|PMAP_LOCK
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|)
expr_stmt|;
name|pt
operator|=
name|MOEA64_PVO_TO_PTE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
if|if
condition|(
name|pt
operator|!=
operator|-
literal|1
condition|)
block|{
name|MOEA64_PTE_SYNCH
argument_list|(
name|mmu
argument_list|,
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|ptebit
condition|)
block|{
name|count
operator|++
expr_stmt|;
name|MOEA64_PTE_CLEAR
argument_list|(
name|mmu
argument_list|,
name|pt
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
argument_list|,
name|pvo
operator|->
name|pvo_vpn
argument_list|,
name|ptebit
argument_list|)
expr_stmt|;
block|}
block|}
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&=
operator|~
name|ptebit
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|)
expr_stmt|;
block|}
name|UNLOCK_TABLE_RD
argument_list|()
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_dev_direct_mapped
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
name|key
decl_stmt|;
name|vm_offset_t
name|ppa
decl_stmt|;
name|int
name|error
init|=
literal|0
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|key
operator|.
name|pvo_vaddr
operator|=
name|ppa
operator|=
name|pa
operator|&
operator|~
name|ADDR_POFF
expr_stmt|;
for|for
control|(
name|pvo
operator|=
name|RB_FIND
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|kernel_pmap
operator|->
name|pmap_pvo
argument_list|,
operator|&
name|key
argument_list|)
init|;
name|ppa
operator|<
name|pa
operator|+
name|size
condition|;
name|ppa
operator|+=
name|PAGE_SIZE
operator|,
name|pvo
operator|=
name|RB_NEXT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|kernel_pmap
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
control|)
block|{
if|if
condition|(
name|pvo
operator|==
name|NULL
operator|||
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
operator|)
operator|!=
name|ppa
condition|)
block|{
name|error
operator|=
name|EFAULT
expr_stmt|;
break|break;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Map a set of physical memory pages into the kernel virtual  * address space. Return a pointer to where it is mapped. This  * routine is intended to be used for mapping device memory,  * NOT real memory.  */
end_comment

begin_function
name|void
modifier|*
name|moea64_mapdev_attr
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|,
name|tmpva
decl_stmt|,
name|ppa
decl_stmt|,
name|offset
decl_stmt|;
name|ppa
operator|=
name|trunc_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|offset
operator|=
name|pa
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|roundup2
argument_list|(
name|offset
operator|+
name|size
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|va
operator|=
name|kmem_alloc_nofault
argument_list|(
name|kernel_map
argument_list|,
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|va
condition|)
name|panic
argument_list|(
literal|"moea64_mapdev: Couldn't alloc kernel virtual memory"
argument_list|)
expr_stmt|;
for|for
control|(
name|tmpva
operator|=
name|va
init|;
name|size
operator|>
literal|0
condition|;
control|)
block|{
name|moea64_kenter_attr
argument_list|(
name|mmu
argument_list|,
name|tmpva
argument_list|,
name|ppa
argument_list|,
name|ma
argument_list|)
expr_stmt|;
name|size
operator|-=
name|PAGE_SIZE
expr_stmt|;
name|tmpva
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|ppa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
return|return
operator|(
operator|(
name|void
operator|*
operator|)
operator|(
name|va
operator|+
name|offset
operator|)
operator|)
return|;
block|}
end_function

begin_function
name|void
modifier|*
name|moea64_mapdev
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
return|return
name|moea64_mapdev_attr
argument_list|(
name|mmu
argument_list|,
name|pa
argument_list|,
name|size
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
return|;
block|}
end_function

begin_function
name|void
name|moea64_unmapdev
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|vm_offset_t
name|base
decl_stmt|,
name|offset
decl_stmt|;
name|base
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|offset
operator|=
name|va
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|roundup2
argument_list|(
name|offset
operator|+
name|size
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|kernel_map
argument_list|,
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_sync_icache
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|sz
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_offset_t
name|lim
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_size_t
name|len
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
while|while
condition|(
name|sz
operator|>
literal|0
condition|)
block|{
name|lim
operator|=
name|round_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|len
operator|=
name|MIN
argument_list|(
name|lim
operator|-
name|va
argument_list|,
name|sz
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pm
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
operator|&&
operator|!
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_I
operator|)
condition|)
block|{
name|pa
operator|=
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|lpte
operator|.
name|pte_lo
operator|&
name|LPTE_RPGN
operator|)
operator||
operator|(
name|va
operator|&
name|ADDR_POFF
operator|)
expr_stmt|;
name|moea64_syncicache
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|len
argument_list|)
expr_stmt|;
block|}
name|va
operator|+=
name|len
expr_stmt|;
name|sz
operator|-=
name|len
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

end_unit

