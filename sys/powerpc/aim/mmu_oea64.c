begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2008-2015 Nathan Whitehorn  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  *  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,  * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT  * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,  * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY  * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF  * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Manages physical address maps.  *  * Since the information managed by this module is also stored by the  * logical address mapping module, this module may throw away valid virtual  * to physical mappings at almost any time.  However, invalidations of  * mappings must be done as requested.  *  * In order to cope with hardware architectures which make virtual to  * physical map invalidates expensive, this module may delay invalidate  * reduced protection operations until such time as they are actually  * necessary.  This module is given full information as to which processors  * are currently using which maps, and to when physical maps must be made  * correct.  */
end_comment

begin_include
include|#
directive|include
file|"opt_compat.h"
end_include

begin_include
include|#
directive|include
file|"opt_kstack_pages.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/conf.h>
end_include

begin_include
include|#
directive|include
file|<sys/queue.h>
end_include

begin_include
include|#
directive|include
file|<sys/cpuset.h>
end_include

begin_include
include|#
directive|include
file|<sys/kerneldump.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/msgbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/kdb.h>
end_include

begin_include
include|#
directive|include
file|<dev/ofw/openfirm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<machine/_inttypes.h>
end_include

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/platform.h>
end_include

begin_include
include|#
directive|include
file|<machine/frame.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_include
include|#
directive|include
file|<machine/psl.h>
end_include

begin_include
include|#
directive|include
file|<machine/bat.h>
end_include

begin_include
include|#
directive|include
file|<machine/hid.h>
end_include

begin_include
include|#
directive|include
file|<machine/pte.h>
end_include

begin_include
include|#
directive|include
file|<machine/sr.h>
end_include

begin_include
include|#
directive|include
file|<machine/trap.h>
end_include

begin_include
include|#
directive|include
file|<machine/mmuvar.h>
end_include

begin_include
include|#
directive|include
file|"mmu_oea64.h"
end_include

begin_include
include|#
directive|include
file|"mmu_if.h"
end_include

begin_include
include|#
directive|include
file|"moea64_if.h"
end_include

begin_function_decl
name|void
name|moea64_release_vsid
parameter_list|(
name|uint64_t
name|vsid
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|uintptr_t
name|moea64_get_unique_vsid
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_define
define|#
directive|define
name|DISABLE_TRANS
parameter_list|(
name|msr
parameter_list|)
value|msr = mfmsr(); mtmsr(msr& ~PSL_DR)
end_define

begin_define
define|#
directive|define
name|ENABLE_TRANS
parameter_list|(
name|msr
parameter_list|)
value|mtmsr(msr)
end_define

begin_define
define|#
directive|define
name|VSID_MAKE
parameter_list|(
name|sr
parameter_list|,
name|hash
parameter_list|)
value|((sr) | (((hash)& 0xfffff)<< 4))
end_define

begin_define
define|#
directive|define
name|VSID_TO_HASH
parameter_list|(
name|vsid
parameter_list|)
value|(((vsid)>> 4)& 0xfffff)
end_define

begin_define
define|#
directive|define
name|VSID_HASH_MASK
value|0x0000007fffffffffULL
end_define

begin_comment
comment|/*  * Locking semantics:  *   * There are two locks of interest: the page locks and the pmap locks, which  * protect their individual PVO lists and are locked in that order. The contents  * of all PVO entries are protected by the locks of their respective pmaps.  * The pmap of any PVO is guaranteed not to change so long as the PVO is linked  * into any list.  *  */
end_comment

begin_define
define|#
directive|define
name|PV_LOCK_COUNT
value|PA_LOCK_COUNT*3
end_define

begin_decl_stmt
specifier|static
name|struct
name|mtx_padalign
name|pv_lock
index|[
name|PV_LOCK_COUNT
index|]
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|PV_LOCKPTR
parameter_list|(
name|pa
parameter_list|)
value|((struct mtx *)(&pv_lock[pa_index(pa) % PV_LOCK_COUNT]))
end_define

begin_define
define|#
directive|define
name|PV_LOCK
parameter_list|(
name|pa
parameter_list|)
value|mtx_lock(PV_LOCKPTR(pa))
end_define

begin_define
define|#
directive|define
name|PV_UNLOCK
parameter_list|(
name|pa
parameter_list|)
value|mtx_unlock(PV_LOCKPTR(pa))
end_define

begin_define
define|#
directive|define
name|PV_LOCKASSERT
parameter_list|(
name|pa
parameter_list|)
value|mtx_assert(PV_LOCKPTR(pa), MA_OWNED)
end_define

begin_define
define|#
directive|define
name|PV_PAGE_LOCK
parameter_list|(
name|m
parameter_list|)
value|PV_LOCK(VM_PAGE_TO_PHYS(m))
end_define

begin_define
define|#
directive|define
name|PV_PAGE_UNLOCK
parameter_list|(
name|m
parameter_list|)
value|PV_UNLOCK(VM_PAGE_TO_PHYS(m))
end_define

begin_define
define|#
directive|define
name|PV_PAGE_LOCKASSERT
parameter_list|(
name|m
parameter_list|)
value|PV_LOCKASSERT(VM_PAGE_TO_PHYS(m))
end_define

begin_struct
struct|struct
name|ofw_map
block|{
name|cell_t
name|om_va
decl_stmt|;
name|cell_t
name|om_len
decl_stmt|;
name|uint64_t
name|om_pa
decl_stmt|;
name|cell_t
name|om_mode
decl_stmt|;
block|}
struct|;
end_struct

begin_decl_stmt
specifier|extern
name|unsigned
name|char
name|_etext
index|[]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|unsigned
name|char
name|_end
index|[]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Map of physical memory regions.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mem_region
modifier|*
name|regions
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mem_region
modifier|*
name|pregions
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|u_int
name|phys_avail_count
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|regions_sz
decl_stmt|,
name|pregions_sz
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|extern
name|void
name|bs_remap_earlyboot
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Lock for the SLB tables.  */
end_comment

begin_decl_stmt
name|struct
name|mtx
name|moea64_slb_mutex
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * PTEG data.  */
end_comment

begin_decl_stmt
name|u_int
name|moea64_pteg_count
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pteg_mask
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * PVO data.  */
end_comment

begin_decl_stmt
name|uma_zone_t
name|moea64_pvo_zone
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* zone for pvo entries */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|pvo_entry
modifier|*
name|moea64_bpvo_pool
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|moea64_bpvo_pool_index
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|moea64_bpvo_pool_size
init|=
literal|327680
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"machdep.moea64_bpvo_pool_size"
argument_list|,
operator|&
name|moea64_bpvo_pool_size
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_allocated_bpvo_entries
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_bpvo_pool_index
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_define
define|#
directive|define
name|VSID_NBPW
value|(sizeof(u_int32_t) * 8)
end_define

begin_ifdef
ifdef|#
directive|ifdef
name|__powerpc64__
end_ifdef

begin_define
define|#
directive|define
name|NVSIDS
value|(NPMAPS * 16)
end_define

begin_define
define|#
directive|define
name|VSID_HASHMASK
value|0xffffffffUL
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|NVSIDS
value|NPMAPS
end_define

begin_define
define|#
directive|define
name|VSID_HASHMASK
value|0xfffffUL
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|u_int
name|moea64_vsid_bitmap
index|[
name|NVSIDS
operator|/
name|VSID_NBPW
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|boolean_t
name|moea64_initialized
init|=
name|FALSE
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Statistics.  */
end_comment

begin_decl_stmt
name|u_int
name|moea64_pte_valid
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pte_overflow
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pvo_entries
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pvo_enter_calls
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|u_int
name|moea64_pvo_remove_calls
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pte_valid
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pte_valid
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pte_overflow
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pte_overflow
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pvo_entries
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pvo_entries
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pvo_enter_calls
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pvo_enter_calls
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_machdep
argument_list|,
name|OID_AUTO
argument_list|,
name|moea64_pvo_remove_calls
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|moea64_pvo_remove_calls
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|vm_offset_t
name|moea64_scratchpage_va
index|[
literal|2
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|pvo_entry
modifier|*
name|moea64_scratchpage_pvo
index|[
literal|2
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mtx
name|moea64_scratchpage_mtx
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|moea64_large_page_mask
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint64_t
name|moea64_large_page_size
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|moea64_large_page_shift
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * PVO calls.  */
end_comment

begin_function_decl
specifier|static
name|int
name|moea64_pvo_enter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|,
name|struct
name|pvo_head
modifier|*
name|pvo_head
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_pvo_remove_from_pmap
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_pvo_remove_from_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|pvo_entry
modifier|*
name|moea64_pvo_find_va
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Utility routines.  */
end_comment

begin_function_decl
specifier|static
name|boolean_t
name|moea64_query_bit
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|uint64_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|u_int
name|moea64_clear_bit
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|uint64_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_kremove
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_syncicache
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|sz
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_pmap_init_qpages
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Kernel MMU interface  */
end_comment

begin_function_decl
name|void
name|moea64_clear_modify
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_copy_page
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_copy_pages
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
modifier|*
name|mb
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|int
name|moea64_enter
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|,
name|u_int
name|flags
parameter_list|,
name|int8_t
name|psind
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_enter_object
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_enter_quick
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_paddr_t
name|moea64_extract
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_page_t
name|moea64_extract_and_hold
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_init
parameter_list|(
name|mmu_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_is_modified
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_is_prefaultable
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_is_referenced
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|int
name|moea64_ts_referenced
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_offset_t
name|moea64_map
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
modifier|*
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_page_exists_quick
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|int
name|moea64_page_wired_mappings
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_pinit
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_pinit0
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_protect
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_qenter
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_qremove
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_release
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove_pages
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove_all
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_remove_write
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_unwire
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_zero_page
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_zero_page_area
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_zero_page_idle
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_activate
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_deactivate
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
modifier|*
name|moea64_mapdev
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
modifier|*
name|moea64_mapdev_attr
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|vm_size_t
parameter_list|,
name|vm_memattr_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_unmapdev
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_paddr_t
name|moea64_kextract
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_page_set_memattr
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_kenter_attr
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_kenter
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_paddr_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|boolean_t
name|moea64_dev_direct_mapped
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|moea64_sync_icache
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_dumpsys_map
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|size_t
name|sz
parameter_list|,
name|void
modifier|*
modifier|*
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_scan_init
parameter_list|(
name|mmu_t
name|mmu
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|vm_offset_t
name|moea64_quick_enter_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
name|void
name|moea64_quick_remove_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
specifier|static
name|mmu_method_t
name|moea64_methods
index|[]
init|=
block|{
name|MMUMETHOD
argument_list|(
name|mmu_clear_modify
argument_list|,
name|moea64_clear_modify
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_copy_page
argument_list|,
name|moea64_copy_page
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_copy_pages
argument_list|,
name|moea64_copy_pages
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter
argument_list|,
name|moea64_enter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter_object
argument_list|,
name|moea64_enter_object
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter_quick
argument_list|,
name|moea64_enter_quick
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_extract
argument_list|,
name|moea64_extract
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_extract_and_hold
argument_list|,
name|moea64_extract_and_hold
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_init
argument_list|,
name|moea64_init
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_is_modified
argument_list|,
name|moea64_is_modified
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_is_prefaultable
argument_list|,
name|moea64_is_prefaultable
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_is_referenced
argument_list|,
name|moea64_is_referenced
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_ts_referenced
argument_list|,
name|moea64_ts_referenced
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_map
argument_list|,
name|moea64_map
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_exists_quick
argument_list|,
name|moea64_page_exists_quick
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_wired_mappings
argument_list|,
name|moea64_page_wired_mappings
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_pinit
argument_list|,
name|moea64_pinit
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_pinit0
argument_list|,
name|moea64_pinit0
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_protect
argument_list|,
name|moea64_protect
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_qenter
argument_list|,
name|moea64_qenter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_qremove
argument_list|,
name|moea64_qremove
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_release
argument_list|,
name|moea64_release
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove
argument_list|,
name|moea64_remove
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove_pages
argument_list|,
name|moea64_remove_pages
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove_all
argument_list|,
name|moea64_remove_all
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove_write
argument_list|,
name|moea64_remove_write
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_sync_icache
argument_list|,
name|moea64_sync_icache
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_unwire
argument_list|,
name|moea64_unwire
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page
argument_list|,
name|moea64_zero_page
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page_area
argument_list|,
name|moea64_zero_page_area
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page_idle
argument_list|,
name|moea64_zero_page_idle
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_activate
argument_list|,
name|moea64_activate
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_deactivate
argument_list|,
name|moea64_deactivate
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_set_memattr
argument_list|,
name|moea64_page_set_memattr
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_quick_enter_page
argument_list|,
name|moea64_quick_enter_page
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_quick_remove_page
argument_list|,
name|moea64_quick_remove_page
argument_list|)
block|,
comment|/* Internal interfaces */
name|MMUMETHOD
argument_list|(
name|mmu_mapdev
argument_list|,
name|moea64_mapdev
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_mapdev_attr
argument_list|,
name|moea64_mapdev_attr
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_unmapdev
argument_list|,
name|moea64_unmapdev
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_kextract
argument_list|,
name|moea64_kextract
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_kenter
argument_list|,
name|moea64_kenter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_kenter_attr
argument_list|,
name|moea64_kenter_attr
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_dev_direct_mapped
argument_list|,
name|moea64_dev_direct_mapped
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_scan_init
argument_list|,
name|moea64_scan_init
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_dumpsys_map
argument_list|,
name|moea64_dumpsys_map
argument_list|)
block|,
block|{
literal|0
block|,
literal|0
block|}
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|MMU_DEF
argument_list|(
name|oea64_mmu
argument_list|,
literal|"mmu_oea64_base"
argument_list|,
name|moea64_methods
argument_list|,
literal|0
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|struct
name|pvo_head
modifier|*
name|vm_page_to_pvoh
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|mtx_assert
argument_list|(
name|PV_LOCKPTR
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
operator|&
name|m
operator|->
name|md
operator|.
name|mdpg_pvoh
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|struct
name|pvo_entry
modifier|*
name|alloc_pvo_entry
parameter_list|(
name|int
name|bootstrap
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
if|if
condition|(
operator|!
name|moea64_initialized
operator|||
name|bootstrap
condition|)
block|{
if|if
condition|(
name|moea64_bpvo_pool_index
operator|>=
name|moea64_bpvo_pool_size
condition|)
block|{
name|panic
argument_list|(
literal|"moea64_enter: bpvo pool exhausted, %d, %d, %zd"
argument_list|,
name|moea64_bpvo_pool_index
argument_list|,
name|moea64_bpvo_pool_size
argument_list|,
name|moea64_bpvo_pool_size
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|pvo
operator|=
operator|&
name|moea64_bpvo_pool
index|[
name|atomic_fetchadd_int
argument_list|(
operator|&
name|moea64_bpvo_pool_index
argument_list|,
literal|1
argument_list|)
index|]
expr_stmt|;
name|bzero
argument_list|(
name|pvo
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|pvo
argument_list|)
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator|=
name|PVO_BOOTSTRAP
expr_stmt|;
block|}
else|else
block|{
name|pvo
operator|=
name|uma_zalloc
argument_list|(
name|moea64_pvo_zone
argument_list|,
name|M_NOWAIT
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
name|pvo
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|pvo
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|pvo
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|init_pvo_entry
parameter_list|(
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|uint64_t
name|vsid
decl_stmt|;
name|uint64_t
name|hash
decl_stmt|;
name|int
name|shift
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pmap
operator|=
name|pmap
expr_stmt|;
name|va
operator|&=
operator|~
name|ADDR_POFF
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|va
expr_stmt|;
name|vsid
operator|=
name|va_to_vsid
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_vpn
operator|=
call|(
name|uint64_t
call|)
argument_list|(
operator|(
name|va
operator|&
name|ADDR_PIDX
operator|)
operator|>>
name|ADDR_PIDX_SHFT
argument_list|)
operator||
operator|(
name|vsid
operator|<<
literal|16
operator|)
expr_stmt|;
name|shift
operator|=
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_LARGE
operator|)
condition|?
name|moea64_large_page_shift
else|:
name|ADDR_PIDX_SHFT
expr_stmt|;
name|hash
operator|=
operator|(
name|vsid
operator|&
name|VSID_HASH_MASK
operator|)
operator|^
operator|(
operator|(
operator|(
name|uint64_t
operator|)
name|va
operator|&
name|ADDR_PIDX
operator|)
operator|>>
name|shift
operator|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|slot
operator|=
operator|(
name|hash
operator|&
name|moea64_pteg_mask
operator|)
operator|<<
literal|3
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|free_pvo_entry
parameter_list|(
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_BOOTSTRAP
operator|)
condition|)
name|uma_zfree
argument_list|(
name|moea64_pvo_zone
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_pte_from_pvo
parameter_list|(
specifier|const
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|,
name|struct
name|lpte
modifier|*
name|lpte
parameter_list|)
block|{
name|lpte
operator|->
name|pte_hi
operator|=
operator|(
name|pvo
operator|->
name|pvo_vpn
operator|>>
operator|(
name|ADDR_API_SHFT64
operator|-
name|ADDR_PIDX_SHFT
operator|)
operator|)
operator|&
name|LPTE_AVPN_MASK
expr_stmt|;
name|lpte
operator|->
name|pte_hi
operator||=
name|LPTE_VALID
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_LARGE
condition|)
name|lpte
operator|->
name|pte_hi
operator||=
name|LPTE_BIG
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
condition|)
name|lpte
operator|->
name|pte_hi
operator||=
name|LPTE_WIRED
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_HID
condition|)
name|lpte
operator|->
name|pte_hi
operator||=
name|LPTE_HID
expr_stmt|;
name|lpte
operator|->
name|pte_lo
operator|=
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
expr_stmt|;
comment|/* Includes WIMG bits */
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
name|lpte
operator|->
name|pte_lo
operator||=
name|LPTE_BW
expr_stmt|;
else|else
name|lpte
operator|->
name|pte_lo
operator||=
name|LPTE_BR
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
condition|)
name|lpte
operator|->
name|pte_lo
operator||=
name|LPTE_NOEXEC
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|uint64_t
name|moea64_calc_wimg
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|uint64_t
name|pte_lo
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
name|ma
operator|!=
name|VM_MEMATTR_DEFAULT
condition|)
block|{
switch|switch
condition|(
name|ma
condition|)
block|{
case|case
name|VM_MEMATTR_UNCACHEABLE
case|:
return|return
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator|)
return|;
case|case
name|VM_MEMATTR_WRITE_COMBINING
case|:
case|case
name|VM_MEMATTR_WRITE_BACK
case|:
case|case
name|VM_MEMATTR_PREFETCHABLE
case|:
return|return
operator|(
name|LPTE_I
operator|)
return|;
case|case
name|VM_MEMATTR_WRITE_THROUGH
case|:
return|return
operator|(
name|LPTE_W
operator||
name|LPTE_M
operator|)
return|;
block|}
block|}
comment|/* 	 * Assume the page is cache inhibited and access is guarded unless 	 * it's in our available memory array. 	 */
name|pte_lo
operator|=
name|LPTE_I
operator||
name|LPTE_G
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pregions_sz
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|pa
operator|>=
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
operator|)
operator|&&
operator|(
name|pa
operator|<
operator|(
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|pregions
index|[
name|i
index|]
operator|.
name|mr_size
operator|)
operator|)
condition|)
block|{
name|pte_lo
operator|&=
operator|~
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator|)
expr_stmt|;
name|pte_lo
operator||=
name|LPTE_M
expr_stmt|;
break|break;
block|}
block|}
return|return
name|pte_lo
return|;
block|}
end_function

begin_comment
comment|/*  * Quick sort callout for comparing memory regions.  */
end_comment

begin_function_decl
specifier|static
name|int
name|om_cmp
parameter_list|(
specifier|const
name|void
modifier|*
name|a
parameter_list|,
specifier|const
name|void
modifier|*
name|b
parameter_list|)
function_decl|;
end_function_decl

begin_function
specifier|static
name|int
name|om_cmp
parameter_list|(
specifier|const
name|void
modifier|*
name|a
parameter_list|,
specifier|const
name|void
modifier|*
name|b
parameter_list|)
block|{
specifier|const
name|struct
name|ofw_map
modifier|*
name|mapa
decl_stmt|;
specifier|const
name|struct
name|ofw_map
modifier|*
name|mapb
decl_stmt|;
name|mapa
operator|=
name|a
expr_stmt|;
name|mapb
operator|=
name|b
expr_stmt|;
if|if
condition|(
name|mapa
operator|->
name|om_pa
operator|<
name|mapb
operator|->
name|om_pa
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
elseif|else
if|if
condition|(
name|mapa
operator|->
name|om_pa
operator|>
name|mapb
operator|->
name|om_pa
condition|)
return|return
operator|(
literal|1
operator|)
return|;
else|else
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_add_ofw_mappings
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|phandle_t
name|mmu
parameter_list|,
name|size_t
name|sz
parameter_list|)
block|{
name|struct
name|ofw_map
name|translations
index|[
name|sz
operator|/
operator|(
literal|4
operator|*
sizeof|sizeof
argument_list|(
name|cell_t
argument_list|)
operator|)
index|]
decl_stmt|;
comment|/*>= 4 cells per */
name|pcell_t
name|acells
decl_stmt|,
name|trans_cells
index|[
name|sz
operator|/
sizeof|sizeof
argument_list|(
name|cell_t
argument_list|)
index|]
decl_stmt|;
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|register_t
name|msr
decl_stmt|;
name|vm_offset_t
name|off
decl_stmt|;
name|vm_paddr_t
name|pa_base
decl_stmt|;
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
name|bzero
argument_list|(
name|translations
argument_list|,
name|sz
argument_list|)
expr_stmt|;
name|OF_getencprop
argument_list|(
name|OF_finddevice
argument_list|(
literal|"/"
argument_list|)
argument_list|,
literal|"#address-cells"
argument_list|,
operator|&
name|acells
argument_list|,
sizeof|sizeof
argument_list|(
name|acells
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|OF_getencprop
argument_list|(
name|mmu
argument_list|,
literal|"translations"
argument_list|,
name|trans_cells
argument_list|,
name|sz
argument_list|)
operator|==
operator|-
literal|1
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: can't get ofw translations"
argument_list|)
expr_stmt|;
name|CTR0
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_add_ofw_mappings: translations"
argument_list|)
expr_stmt|;
name|sz
operator|/=
sizeof|sizeof
argument_list|(
name|cell_t
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
operator|,
name|j
operator|=
literal|0
init|;
name|i
operator|<
name|sz
condition|;
name|j
operator|++
control|)
block|{
name|translations
index|[
name|j
index|]
operator|.
name|om_va
operator|=
name|trans_cells
index|[
name|i
operator|++
index|]
expr_stmt|;
name|translations
index|[
name|j
index|]
operator|.
name|om_len
operator|=
name|trans_cells
index|[
name|i
operator|++
index|]
expr_stmt|;
name|translations
index|[
name|j
index|]
operator|.
name|om_pa
operator|=
name|trans_cells
index|[
name|i
operator|++
index|]
expr_stmt|;
if|if
condition|(
name|acells
operator|==
literal|2
condition|)
block|{
name|translations
index|[
name|j
index|]
operator|.
name|om_pa
operator|<<=
literal|32
expr_stmt|;
name|translations
index|[
name|j
index|]
operator|.
name|om_pa
operator||=
name|trans_cells
index|[
name|i
operator|++
index|]
expr_stmt|;
block|}
name|translations
index|[
name|j
index|]
operator|.
name|om_mode
operator|=
name|trans_cells
index|[
name|i
operator|++
index|]
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|i
operator|==
name|sz
argument_list|,
operator|(
literal|"Translations map has incorrect cell count (%d/%zd)"
operator|,
name|i
operator|,
name|sz
operator|)
argument_list|)
expr_stmt|;
name|sz
operator|=
name|j
expr_stmt|;
name|qsort
argument_list|(
name|translations
argument_list|,
name|sz
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|translations
argument_list|)
argument_list|,
name|om_cmp
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|sz
condition|;
name|i
operator|++
control|)
block|{
name|pa_base
operator|=
name|translations
index|[
name|i
index|]
operator|.
name|om_pa
expr_stmt|;
ifndef|#
directive|ifndef
name|__powerpc64__
if|if
condition|(
operator|(
name|translations
index|[
name|i
index|]
operator|.
name|om_pa
operator|>>
literal|32
operator|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"OFW translations above 32-bit boundary!"
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|pa_base
operator|%
name|PAGE_SIZE
condition|)
name|panic
argument_list|(
literal|"OFW translation not page-aligned (phys)!"
argument_list|)
expr_stmt|;
if|if
condition|(
name|translations
index|[
name|i
index|]
operator|.
name|om_va
operator|%
name|PAGE_SIZE
condition|)
name|panic
argument_list|(
literal|"OFW translation not page-aligned (virt)!"
argument_list|)
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"translation: pa=%#zx va=%#x len=%#x"
argument_list|,
name|pa_base
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_va
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_len
argument_list|)
expr_stmt|;
comment|/* Now enter the pages for this mapping */
name|DISABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
for|for
control|(
name|off
operator|=
literal|0
init|;
name|off
operator|<
name|translations
index|[
name|i
index|]
operator|.
name|om_len
condition|;
name|off
operator|+=
name|PAGE_SIZE
control|)
block|{
comment|/* If this address is direct-mapped, skip remapping */
if|if
condition|(
name|hw_direct_map
operator|&&
name|translations
index|[
name|i
index|]
operator|.
name|om_va
operator|==
name|pa_base
operator|&&
name|moea64_calc_wimg
argument_list|(
name|pa_base
operator|+
name|off
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
operator|==
name|LPTE_M
condition|)
continue|continue;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_va
operator|+
name|off
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
condition|)
continue|continue;
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|translations
index|[
name|i
index|]
operator|.
name|om_va
operator|+
name|off
argument_list|,
name|pa_base
operator|+
name|off
argument_list|)
expr_stmt|;
block|}
name|ENABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|__powerpc64__
end_ifdef

begin_function
specifier|static
name|void
name|moea64_probe_large_page
parameter_list|(
name|void
parameter_list|)
block|{
name|uint16_t
name|pvr
init|=
name|mfpvr
argument_list|()
operator|>>
literal|16
decl_stmt|;
switch|switch
condition|(
name|pvr
condition|)
block|{
case|case
name|IBM970
case|:
case|case
name|IBM970FX
case|:
case|case
name|IBM970MP
case|:
name|powerpc_sync
argument_list|()
expr_stmt|;
name|isync
argument_list|()
expr_stmt|;
name|mtspr
argument_list|(
name|SPR_HID4
argument_list|,
name|mfspr
argument_list|(
name|SPR_HID4
argument_list|)
operator|&
operator|~
name|HID4_970_DISABLE_LG_PG
argument_list|)
expr_stmt|;
name|powerpc_sync
argument_list|()
expr_stmt|;
name|isync
argument_list|()
expr_stmt|;
comment|/* FALLTHROUGH */
default|default:
name|moea64_large_page_size
operator|=
literal|0x1000000
expr_stmt|;
comment|/* 16 MB */
name|moea64_large_page_shift
operator|=
literal|24
expr_stmt|;
block|}
name|moea64_large_page_mask
operator|=
name|moea64_large_page_size
operator|-
literal|1
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_bootstrap_slb_prefault
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|int
name|large
parameter_list|)
block|{
name|struct
name|slb
modifier|*
name|cache
decl_stmt|;
name|struct
name|slb
name|entry
decl_stmt|;
name|uint64_t
name|esid
decl_stmt|,
name|slbe
decl_stmt|;
name|uint64_t
name|i
decl_stmt|;
name|cache
operator|=
name|PCPU_GET
argument_list|(
name|slb
argument_list|)
expr_stmt|;
name|esid
operator|=
name|va
operator|>>
name|ADDR_SR_SHFT
expr_stmt|;
name|slbe
operator|=
operator|(
name|esid
operator|<<
name|SLBE_ESID_SHIFT
operator|)
operator||
name|SLBE_VALID
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|64
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|cache
index|[
name|i
index|]
operator|.
name|slbe
operator|==
operator|(
name|slbe
operator||
name|i
operator|)
condition|)
return|return;
block|}
name|entry
operator|.
name|slbe
operator|=
name|slbe
expr_stmt|;
name|entry
operator|.
name|slbv
operator|=
name|KERNEL_VSID
argument_list|(
name|esid
argument_list|)
operator|<<
name|SLBV_VSID_SHIFT
expr_stmt|;
if|if
condition|(
name|large
condition|)
name|entry
operator|.
name|slbv
operator||=
name|SLBV_L
expr_stmt|;
name|slb_insert_kernel
argument_list|(
name|entry
operator|.
name|slbe
argument_list|,
name|entry
operator|.
name|slbv
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_function
specifier|static
name|void
name|moea64_setup_direct_map
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|vm_offset_t
name|kernelstart
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|register_t
name|msr
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_offset_t
name|size
decl_stmt|,
name|off
decl_stmt|;
name|uint64_t
name|pte_lo
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
name|moea64_large_page_size
operator|==
literal|0
condition|)
name|hw_direct_map
operator|=
literal|0
expr_stmt|;
name|DISABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
if|if
condition|(
name|hw_direct_map
condition|)
block|{
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pregions_sz
condition|;
name|i
operator|++
control|)
block|{
for|for
control|(
name|pa
operator|=
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
init|;
name|pa
operator|<
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|pregions
index|[
name|i
index|]
operator|.
name|mr_size
condition|;
name|pa
operator|+=
name|moea64_large_page_size
control|)
block|{
name|pte_lo
operator|=
name|LPTE_M
expr_stmt|;
name|pvo
operator|=
name|alloc_pvo_entry
argument_list|(
literal|1
comment|/* bootstrap */
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_WIRED
operator||
name|PVO_LARGE
expr_stmt|;
name|init_pvo_entry
argument_list|(
name|pvo
argument_list|,
name|kernel_pmap
argument_list|,
name|pa
argument_list|)
expr_stmt|;
comment|/* 			 * Set memory access as guarded if prefetch within 			 * the page could exit the available physmem area. 			 */
if|if
condition|(
name|pa
operator|&
name|moea64_large_page_mask
condition|)
block|{
name|pa
operator|&=
name|moea64_large_page_mask
expr_stmt|;
name|pte_lo
operator||=
name|LPTE_G
expr_stmt|;
block|}
if|if
condition|(
name|pa
operator|+
name|moea64_large_page_size
operator|>
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|pregions
index|[
name|i
index|]
operator|.
name|mr_size
condition|)
name|pte_lo
operator||=
name|LPTE_G
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|=
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
operator||
name|VM_PROT_EXECUTE
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|=
name|pa
operator||
name|pte_lo
expr_stmt|;
name|moea64_pvo_enter
argument_list|(
name|mmup
argument_list|,
name|pvo
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|size
operator|=
name|moea64_bpvo_pool_size
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
expr_stmt|;
name|off
operator|=
call|(
name|vm_offset_t
call|)
argument_list|(
name|moea64_bpvo_pool
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|off
init|;
name|pa
operator|<
name|off
operator|+
name|size
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|)
expr_stmt|;
comment|/* 		 * Map certain important things, like ourselves. 		 * 		 * NOTE: We do not map the exception vector space. That code is 		 * used only in real mode, and leaving it unmapped allows us to 		 * catch NULL pointer deferences, instead of making NULL a valid 		 * address. 		 */
for|for
control|(
name|pa
operator|=
name|kernelstart
operator|&
operator|~
name|PAGE_MASK
init|;
name|pa
operator|<
name|kernelend
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|pa
argument_list|,
name|pa
argument_list|)
expr_stmt|;
block|}
name|ENABLE_TRANS
argument_list|(
name|msr
argument_list|)
expr_stmt|;
comment|/* 	 * Allow user to override unmapped_buf_allowed for testing. 	 * XXXKIB Only direct map implementation was tested. 	 */
if|if
condition|(
operator|!
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vfs.unmapped_buf_allowed"
argument_list|,
operator|&
name|unmapped_buf_allowed
argument_list|)
condition|)
name|unmapped_buf_allowed
operator|=
name|hw_direct_map
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_early_bootstrap
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|vm_offset_t
name|kernelstart
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
name|vm_size_t
name|physsz
decl_stmt|,
name|hwphyssz
decl_stmt|;
ifndef|#
directive|ifndef
name|__powerpc64__
comment|/* We don't have a direct map since there is no BAT */
name|hw_direct_map
operator|=
literal|0
expr_stmt|;
comment|/* Make sure battable is zero, since we have no BAT */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|16
condition|;
name|i
operator|++
control|)
block|{
name|battable
index|[
name|i
index|]
operator|.
name|batu
operator|=
literal|0
expr_stmt|;
name|battable
index|[
name|i
index|]
operator|.
name|batl
operator|=
literal|0
expr_stmt|;
block|}
else|#
directive|else
name|moea64_probe_large_page
argument_list|()
expr_stmt|;
comment|/* Use a direct map if we have large page support */
if|if
condition|(
name|moea64_large_page_size
operator|>
literal|0
condition|)
name|hw_direct_map
operator|=
literal|1
expr_stmt|;
else|else
name|hw_direct_map
operator|=
literal|0
expr_stmt|;
endif|#
directive|endif
comment|/* Get physical memory regions from firmware */
name|mem_regions
argument_list|(
operator|&
name|pregions
argument_list|,
operator|&
name|pregions_sz
argument_list|,
operator|&
name|regions
argument_list|,
operator|&
name|regions_sz
argument_list|)
expr_stmt|;
name|CTR0
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_bootstrap: physical memory"
argument_list|)
expr_stmt|;
if|if
condition|(
sizeof|sizeof
argument_list|(
name|phys_avail
argument_list|)
operator|/
sizeof|sizeof
argument_list|(
name|phys_avail
index|[
literal|0
index|]
argument_list|)
operator|<
name|regions_sz
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: phys_avail too small"
argument_list|)
expr_stmt|;
name|phys_avail_count
operator|=
literal|0
expr_stmt|;
name|physsz
operator|=
literal|0
expr_stmt|;
name|hwphyssz
operator|=
literal|0
expr_stmt|;
name|TUNABLE_ULONG_FETCH
argument_list|(
literal|"hw.physmem"
argument_list|,
operator|(
name|u_long
operator|*
operator|)
operator|&
name|hwphyssz
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
operator|,
name|j
operator|=
literal|0
init|;
name|i
operator|<
name|regions_sz
condition|;
name|i
operator|++
operator|,
name|j
operator|+=
literal|2
control|)
block|{
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"region: %#zx - %#zx (%#zx)"
argument_list|,
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
argument_list|,
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
argument_list|,
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
argument_list|)
expr_stmt|;
if|if
condition|(
name|hwphyssz
operator|!=
literal|0
operator|&&
operator|(
name|physsz
operator|+
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
operator|)
operator|>=
name|hwphyssz
condition|)
block|{
if|if
condition|(
name|physsz
operator|<
name|hwphyssz
condition|)
block|{
name|phys_avail
index|[
name|j
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|hwphyssz
operator|-
name|physsz
expr_stmt|;
name|physsz
operator|=
name|hwphyssz
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
break|break;
block|}
name|phys_avail
index|[
name|j
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
name|physsz
operator|+=
name|regions
index|[
name|i
index|]
operator|.
name|mr_size
expr_stmt|;
block|}
comment|/* Check for overlap with the kernel and exception vectors */
for|for
control|(
name|j
operator|=
literal|0
init|;
name|j
operator|<
literal|2
operator|*
name|phys_avail_count
condition|;
name|j
operator|+=
literal|2
control|)
block|{
if|if
condition|(
name|phys_avail
index|[
name|j
index|]
operator|<
name|EXC_LAST
condition|)
name|phys_avail
index|[
name|j
index|]
operator|+=
name|EXC_LAST
expr_stmt|;
if|if
condition|(
name|kernelstart
operator|>=
name|phys_avail
index|[
name|j
index|]
operator|&&
name|kernelstart
operator|<
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
condition|)
block|{
if|if
condition|(
name|kernelend
operator|<
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
condition|)
block|{
name|phys_avail
index|[
literal|2
operator|*
name|phys_avail_count
index|]
operator|=
operator|(
name|kernelend
operator|&
operator|~
name|PAGE_MASK
operator|)
operator|+
name|PAGE_SIZE
expr_stmt|;
name|phys_avail
index|[
literal|2
operator|*
name|phys_avail_count
operator|+
literal|1
index|]
operator|=
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|kernelstart
operator|&
operator|~
name|PAGE_MASK
expr_stmt|;
block|}
if|if
condition|(
name|kernelend
operator|>=
name|phys_avail
index|[
name|j
index|]
operator|&&
name|kernelend
operator|<
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
condition|)
block|{
if|if
condition|(
name|kernelstart
operator|>
name|phys_avail
index|[
name|j
index|]
condition|)
block|{
name|phys_avail
index|[
literal|2
operator|*
name|phys_avail_count
index|]
operator|=
name|phys_avail
index|[
name|j
index|]
expr_stmt|;
name|phys_avail
index|[
literal|2
operator|*
name|phys_avail_count
operator|+
literal|1
index|]
operator|=
name|kernelstart
operator|&
operator|~
name|PAGE_MASK
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
name|phys_avail
index|[
name|j
index|]
operator|=
operator|(
name|kernelend
operator|&
operator|~
name|PAGE_MASK
operator|)
operator|+
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
name|physmem
operator|=
name|btoc
argument_list|(
name|physsz
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|PTEGCOUNT
name|moea64_pteg_count
operator|=
name|PTEGCOUNT
expr_stmt|;
else|#
directive|else
name|moea64_pteg_count
operator|=
literal|0x1000
expr_stmt|;
while|while
condition|(
name|moea64_pteg_count
operator|<
name|physmem
condition|)
name|moea64_pteg_count
operator|<<=
literal|1
expr_stmt|;
name|moea64_pteg_count
operator|>>=
literal|1
expr_stmt|;
endif|#
directive|endif
comment|/* PTEGCOUNT */
block|}
end_function

begin_function
name|void
name|moea64_mid_bootstrap
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|vm_offset_t
name|kernelstart
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
comment|/* 	 * Set PTEG mask 	 */
name|moea64_pteg_mask
operator|=
name|moea64_pteg_count
operator|-
literal|1
expr_stmt|;
comment|/* 	 * Initialize SLB table lock and page locks 	 */
name|mtx_init
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|,
literal|"SLB table"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PV_LOCK_COUNT
condition|;
name|i
operator|++
control|)
name|mtx_init
argument_list|(
operator|&
name|pv_lock
index|[
name|i
index|]
argument_list|,
literal|"page pv"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* 	 * Initialise the bootstrap pvo pool. 	 */
name|moea64_bpvo_pool
operator|=
operator|(
expr|struct
name|pvo_entry
operator|*
operator|)
name|moea64_bootstrap_alloc
argument_list|(
name|moea64_bpvo_pool_size
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|moea64_bpvo_pool_index
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Make sure kernel vsid is allocated as well as VSID 0. 	 */
ifndef|#
directive|ifndef
name|__powerpc64__
name|moea64_vsid_bitmap
index|[
operator|(
name|KERNEL_VSIDBITS
operator|&
operator|(
name|NVSIDS
operator|-
literal|1
operator|)
operator|)
operator|/
name|VSID_NBPW
index|]
operator||=
literal|1
operator|<<
operator|(
name|KERNEL_VSIDBITS
operator|%
name|VSID_NBPW
operator|)
expr_stmt|;
name|moea64_vsid_bitmap
index|[
literal|0
index|]
operator||=
literal|1
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Initialize the kernel pmap (which is statically allocated). 	 */
ifdef|#
directive|ifdef
name|__powerpc64__
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|64
condition|;
name|i
operator|++
control|)
block|{
name|pcpup
operator|->
name|pc_slb
index|[
name|i
index|]
operator|.
name|slbv
operator|=
literal|0
expr_stmt|;
name|pcpup
operator|->
name|pc_slb
index|[
name|i
index|]
operator|.
name|slbe
operator|=
literal|0
expr_stmt|;
block|}
else|#
directive|else
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|16
condition|;
name|i
operator|++
control|)
name|kernel_pmap
operator|->
name|pm_sr
index|[
name|i
index|]
operator|=
name|EMPTY_SEGMENT
operator|+
name|i
expr_stmt|;
endif|#
directive|endif
name|kernel_pmap
operator|->
name|pmap_phys
operator|=
name|kernel_pmap
expr_stmt|;
name|CPU_FILL
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|RB_INIT
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pmap_pvo
argument_list|)
expr_stmt|;
name|PMAP_LOCK_INIT
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Now map in all the other buffers we allocated earlier 	 */
name|moea64_setup_direct_map
argument_list|(
name|mmup
argument_list|,
name|kernelstart
argument_list|,
name|kernelend
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_late_bootstrap
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|vm_offset_t
name|kernelstart
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
block|{
name|ihandle_t
name|mmui
decl_stmt|;
name|phandle_t
name|chosen
decl_stmt|;
name|phandle_t
name|mmu
decl_stmt|;
name|ssize_t
name|sz
decl_stmt|;
name|int
name|i
decl_stmt|;
name|vm_offset_t
name|pa
decl_stmt|,
name|va
decl_stmt|;
name|void
modifier|*
name|dpcpu
decl_stmt|;
comment|/* 	 * Set up the Open Firmware pmap and add its mappings if not in real 	 * mode. 	 */
name|chosen
operator|=
name|OF_finddevice
argument_list|(
literal|"/chosen"
argument_list|)
expr_stmt|;
if|if
condition|(
name|chosen
operator|!=
operator|-
literal|1
operator|&&
name|OF_getencprop
argument_list|(
name|chosen
argument_list|,
literal|"mmu"
argument_list|,
operator|&
name|mmui
argument_list|,
literal|4
argument_list|)
operator|!=
operator|-
literal|1
condition|)
block|{
name|mmu
operator|=
name|OF_instance_to_package
argument_list|(
name|mmui
argument_list|)
expr_stmt|;
if|if
condition|(
name|mmu
operator|==
operator|-
literal|1
operator|||
operator|(
name|sz
operator|=
name|OF_getproplen
argument_list|(
name|mmu
argument_list|,
literal|"translations"
argument_list|)
operator|)
operator|==
operator|-
literal|1
condition|)
name|sz
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|sz
operator|>
literal|6144
comment|/* tmpstksz - 2 KB headroom */
condition|)
name|panic
argument_list|(
literal|"moea64_bootstrap: too many ofw translations"
argument_list|)
expr_stmt|;
if|if
condition|(
name|sz
operator|>
literal|0
condition|)
name|moea64_add_ofw_mappings
argument_list|(
name|mmup
argument_list|,
name|mmu
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Calculate the last available physical address. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|2
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
empty_stmt|;
name|Maxmem
operator|=
name|powerpc_btop
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize MMU and remap early physical mappings 	 */
name|MMU_CPU_BOOTSTRAP
argument_list|(
name|mmup
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|mtmsr
argument_list|(
name|mfmsr
argument_list|()
operator||
name|PSL_DR
operator||
name|PSL_IR
argument_list|)
expr_stmt|;
name|pmap_bootstrapped
operator|++
expr_stmt|;
name|bs_remap_earlyboot
argument_list|()
expr_stmt|;
comment|/* 	 * Set the start and end of kva. 	 */
name|virtual_avail
operator|=
name|VM_MIN_KERNEL_ADDRESS
expr_stmt|;
name|virtual_end
operator|=
name|VM_MAX_SAFE_KERNEL_ADDRESS
expr_stmt|;
comment|/* 	 * Map the entire KVA range into the SLB. We must not fault there. 	 */
ifdef|#
directive|ifdef
name|__powerpc64__
for|for
control|(
name|va
operator|=
name|virtual_avail
init|;
name|va
operator|<
name|virtual_end
condition|;
name|va
operator|+=
name|SEGMENT_LENGTH
control|)
name|moea64_bootstrap_slb_prefault
argument_list|(
name|va
argument_list|,
literal|0
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Figure out how far we can extend virtual_end into segment 16 	 * without running into existing mappings. Segment 16 is guaranteed 	 * to contain neither RAM nor devices (at least on Apple hardware), 	 * but will generally contain some OFW mappings we should not 	 * step on. 	 */
ifndef|#
directive|ifndef
name|__powerpc64__
comment|/* KVA is in high memory on PPC64 */
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
while|while
condition|(
name|virtual_end
operator|<
name|VM_MAX_KERNEL_ADDRESS
operator|&&
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|virtual_end
operator|+
literal|1
argument_list|)
operator|==
name|NULL
condition|)
name|virtual_end
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Allocate a kernel stack with a guard page for thread0 and map it 	 * into the kernel page map. 	 */
name|pa
operator|=
name|moea64_bootstrap_alloc
argument_list|(
name|kstack_pages
operator|*
name|PAGE_SIZE
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|va
operator|=
name|virtual_avail
operator|+
name|KSTACK_GUARD_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
name|virtual_avail
operator|=
name|va
operator|+
name|kstack_pages
operator|*
name|PAGE_SIZE
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_bootstrap: kstack0 at %#x (%#x)"
argument_list|,
name|pa
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|thread0
operator|.
name|td_kstack
operator|=
name|va
expr_stmt|;
name|thread0
operator|.
name|td_kstack_pages
operator|=
name|kstack_pages
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|kstack_pages
condition|;
name|i
operator|++
control|)
block|{
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* 	 * Allocate virtual address space for the message buffer. 	 */
name|pa
operator|=
name|msgbuf_phys
operator|=
name|moea64_bootstrap_alloc
argument_list|(
name|msgbufsize
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|msgbufp
operator|=
operator|(
expr|struct
name|msgbuf
operator|*
operator|)
name|virtual_avail
expr_stmt|;
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|round_page
argument_list|(
name|msgbufsize
argument_list|)
expr_stmt|;
while|while
condition|(
name|va
operator|<
name|virtual_avail
condition|)
block|{
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* 	 * Allocate virtual address space for the dynamic percpu area. 	 */
name|pa
operator|=
name|moea64_bootstrap_alloc
argument_list|(
name|DPCPU_SIZE
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|dpcpu
operator|=
operator|(
name|void
operator|*
operator|)
name|virtual_avail
expr_stmt|;
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|DPCPU_SIZE
expr_stmt|;
while|while
condition|(
name|va
operator|<
name|virtual_avail
condition|)
block|{
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|dpcpu_init
argument_list|(
name|dpcpu
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate some things for page zeroing. We put this directly 	 * in the page table and use MOEA64_PTE_REPLACE to avoid any 	 * of the PVO book-keeping or other parts of the VM system 	 * from even knowing that this hack exists. 	 */
if|if
condition|(
operator|!
name|hw_direct_map
condition|)
block|{
name|mtx_init
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|,
literal|"pvo zero page"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|2
condition|;
name|i
operator|++
control|)
block|{
name|moea64_scratchpage_va
index|[
name|i
index|]
operator|=
operator|(
name|virtual_end
operator|+
literal|1
operator|)
operator|-
name|PAGE_SIZE
expr_stmt|;
name|virtual_end
operator|-=
name|PAGE_SIZE
expr_stmt|;
name|moea64_kenter
argument_list|(
name|mmup
argument_list|,
name|moea64_scratchpage_va
index|[
name|i
index|]
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|moea64_scratchpage_pvo
index|[
name|i
index|]
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|moea64_scratchpage_va
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_pmap_init_qpages
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
name|hw_direct_map
condition|)
return|return;
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
block|{
name|pc
operator|=
name|pcpu_find
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_qmap_addr
operator|=
name|kva_alloc
argument_list|(
name|PAGE_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|pc
operator|->
name|pc_qmap_addr
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_init_qpages: unable to allocate KVA"
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_qmap_pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|pc
operator|->
name|pc_qmap_addr
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|pc
operator|->
name|pc_qmap_lock
argument_list|,
literal|"qmap lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_expr_stmt
name|SYSINIT
argument_list|(
name|qpages_init
argument_list|,
name|SI_SUB_CPU
argument_list|,
name|SI_ORDER_ANY
argument_list|,
name|moea64_pmap_init_qpages
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Activate a user pmap.  This mostly involves setting some non-CPU  * state.  */
end_comment

begin_function
name|void
name|moea64_activate
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|pm
decl_stmt|;
name|pm
operator|=
operator|&
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
expr_stmt|;
name|CPU_SET
argument_list|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|,
operator|&
name|pm
operator|->
name|pm_active
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|__powerpc64__
name|PCPU_SET
argument_list|(
name|userslb
argument_list|,
name|pm
operator|->
name|pm_slb
argument_list|)
expr_stmt|;
asm|__asm __volatile("slbmte %0, %1; isync" ::
literal|"r"
operator|(
name|td
operator|->
name|td_pcb
operator|->
name|pcb_cpu
operator|.
name|aim
operator|.
name|usr_vsid
operator|)
operator|,
literal|"r"
operator|(
name|USER_SLB_SLBE
operator|)
block|)
function|;
end_function

begin_else
else|#
directive|else
end_else

begin_expr_stmt
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pm
operator|->
name|pmap_phys
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|mtsrin
argument_list|(
name|USER_SR
operator|<<
name|ADDR_SR_SHFT
argument_list|,
name|td
operator|->
name|td_pcb
operator|->
name|pcb_cpu
operator|.
name|aim
operator|.
name|usr_vsid
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_macro
unit|}  void
name|moea64_deactivate
argument_list|(
argument|mmu_t mmu
argument_list|,
argument|struct thread *td
argument_list|)
end_macro

begin_block
block|{
name|pmap_t
name|pm
decl_stmt|;
asm|__asm __volatile("isync; slbie %0" :: "r"(USER_ADDR));
name|pm
operator|=
operator|&
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
expr_stmt|;
name|CPU_CLR
argument_list|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|,
operator|&
name|pm
operator|->
name|pm_active
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|__powerpc64__
name|PCPU_SET
argument_list|(
name|userslb
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
else|#
directive|else
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_block

begin_function
name|void
name|moea64_unwire
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|struct
name|pvo_entry
name|key
decl_stmt|,
modifier|*
name|pvo
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int64_t
name|refchg
decl_stmt|;
name|key
operator|.
name|pvo_vaddr
operator|=
name|sva
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
for|for
control|(
name|pvo
operator|=
name|RB_NFIND
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
operator|&
name|key
argument_list|)
init|;
name|pvo
operator|!=
name|NULL
operator|&&
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|<
name|eva
condition|;
name|pvo
operator|=
name|RB_NEXT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
control|)
block|{
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"moea64_unwire: pvo %p is missing PVO_WIRED"
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator|&=
operator|~
name|PVO_WIRED
expr_stmt|;
name|refchg
operator|=
name|MOEA64_PTE_REPLACE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|,
literal|0
comment|/* No invalidation */
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_MANAGED
operator|)
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
condition|)
block|{
if|if
condition|(
name|refchg
operator|<
literal|0
condition|)
name|refchg
operator|=
name|LPTE_CHG
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|refchg
operator||=
name|atomic_readandclear_32
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|mdpg_attrs
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|&
name|LPTE_CHG
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|&
name|LPTE_REF
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
block|}
name|pm
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This goes through and sets the physical address of our  * special scratch PTE to the PA we want to zero or copy. Because  * of locking issues (this can get called in pvo_enter() by  * the UMA allocator), we can't use most other utility functions here  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|moea64_set_scratchpage_pa
parameter_list|(
name|mmu_t
name|mmup
parameter_list|,
name|int
name|which
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|!
name|hw_direct_map
argument_list|,
operator|(
literal|"Using OEA64 scratchpage with a direct map!"
operator|)
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|moea64_scratchpage_pvo
index|[
name|which
index|]
operator|->
name|pvo_pte
operator|.
name|pa
operator|=
name|moea64_calc_wimg
argument_list|(
name|pa
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
operator||
operator|(
name|uint64_t
operator|)
name|pa
expr_stmt|;
name|MOEA64_PTE_REPLACE
argument_list|(
name|mmup
argument_list|,
name|moea64_scratchpage_pvo
index|[
name|which
index|]
argument_list|,
name|MOEA64_PTE_INVALIDATE
argument_list|)
expr_stmt|;
name|isync
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_copy_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|msrc
parameter_list|,
name|vm_page_t
name|mdst
parameter_list|)
block|{
name|vm_offset_t
name|dst
decl_stmt|;
name|vm_offset_t
name|src
decl_stmt|;
name|dst
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|mdst
argument_list|)
expr_stmt|;
name|src
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|msrc
argument_list|)
expr_stmt|;
if|if
condition|(
name|hw_direct_map
condition|)
block|{
name|bcopy
argument_list|(
operator|(
name|void
operator|*
operator|)
name|src
argument_list|,
operator|(
name|void
operator|*
operator|)
name|dst
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|0
argument_list|,
name|src
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|1
argument_list|,
name|dst
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
operator|(
name|void
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|0
index|]
argument_list|,
operator|(
name|void
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|1
index|]
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
specifier|inline
name|void
name|moea64_copy_pages_dmap
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
modifier|*
name|mb
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
block|{
name|void
modifier|*
name|a_cp
decl_stmt|,
modifier|*
name|b_cp
decl_stmt|;
name|vm_offset_t
name|a_pg_offset
decl_stmt|,
name|b_pg_offset
decl_stmt|;
name|int
name|cnt
decl_stmt|;
while|while
condition|(
name|xfersize
operator|>
literal|0
condition|)
block|{
name|a_pg_offset
operator|=
name|a_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|xfersize
argument_list|,
name|PAGE_SIZE
operator|-
name|a_pg_offset
argument_list|)
expr_stmt|;
name|a_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|VM_PAGE_TO_PHYS
argument_list|(
name|ma
index|[
name|a_offset
operator|>>
name|PAGE_SHIFT
index|]
argument_list|)
operator|+
name|a_pg_offset
expr_stmt|;
name|b_pg_offset
operator|=
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|cnt
argument_list|,
name|PAGE_SIZE
operator|-
name|b_pg_offset
argument_list|)
expr_stmt|;
name|b_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|VM_PAGE_TO_PHYS
argument_list|(
name|mb
index|[
name|b_offset
operator|>>
name|PAGE_SHIFT
index|]
argument_list|)
operator|+
name|b_pg_offset
expr_stmt|;
name|bcopy
argument_list|(
name|a_cp
argument_list|,
name|b_cp
argument_list|,
name|cnt
argument_list|)
expr_stmt|;
name|a_offset
operator|+=
name|cnt
expr_stmt|;
name|b_offset
operator|+=
name|cnt
expr_stmt|;
name|xfersize
operator|-=
name|cnt
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
specifier|inline
name|void
name|moea64_copy_pages_nodmap
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
modifier|*
name|mb
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
block|{
name|void
modifier|*
name|a_cp
decl_stmt|,
modifier|*
name|b_cp
decl_stmt|;
name|vm_offset_t
name|a_pg_offset
decl_stmt|,
name|b_pg_offset
decl_stmt|;
name|int
name|cnt
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
while|while
condition|(
name|xfersize
operator|>
literal|0
condition|)
block|{
name|a_pg_offset
operator|=
name|a_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|xfersize
argument_list|,
name|PAGE_SIZE
operator|-
name|a_pg_offset
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|0
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|ma
index|[
name|a_offset
operator|>>
name|PAGE_SHIFT
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|a_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|0
index|]
operator|+
name|a_pg_offset
expr_stmt|;
name|b_pg_offset
operator|=
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|cnt
argument_list|,
name|PAGE_SIZE
operator|-
name|b_pg_offset
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|1
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|mb
index|[
name|b_offset
operator|>>
name|PAGE_SHIFT
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|b_cp
operator|=
operator|(
name|char
operator|*
operator|)
name|moea64_scratchpage_va
index|[
literal|1
index|]
operator|+
name|b_pg_offset
expr_stmt|;
name|bcopy
argument_list|(
name|a_cp
argument_list|,
name|b_cp
argument_list|,
name|cnt
argument_list|)
expr_stmt|;
name|a_offset
operator|+=
name|cnt
expr_stmt|;
name|b_offset
operator|+=
name|cnt
expr_stmt|;
name|xfersize
operator|-=
name|cnt
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_copy_pages
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
modifier|*
name|mb
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
block|{
if|if
condition|(
name|hw_direct_map
condition|)
block|{
name|moea64_copy_pages_dmap
argument_list|(
name|mmu
argument_list|,
name|ma
argument_list|,
name|a_offset
argument_list|,
name|mb
argument_list|,
name|b_offset
argument_list|,
name|xfersize
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|moea64_copy_pages_nodmap
argument_list|(
name|mmu
argument_list|,
name|ma
argument_list|,
name|a_offset
argument_list|,
name|mb
argument_list|,
name|b_offset
argument_list|,
name|xfersize
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|moea64_zero_page_area
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_paddr_t
name|pa
init|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
decl_stmt|;
if|if
condition|(
name|size
operator|+
name|off
operator|>
name|PAGE_SIZE
condition|)
name|panic
argument_list|(
literal|"moea64_zero_page: size + off> PAGE_SIZE"
argument_list|)
expr_stmt|;
if|if
condition|(
name|hw_direct_map
condition|)
block|{
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|pa
operator|+
name|off
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|0
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|moea64_scratchpage_va
index|[
literal|0
index|]
operator|+
name|off
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Zero a page of physical memory by temporarily mapping it  */
end_comment

begin_function
name|void
name|moea64_zero_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_paddr_t
name|pa
init|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|off
decl_stmt|;
if|if
condition|(
operator|!
name|hw_direct_map
condition|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|0
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|va
operator|=
name|moea64_scratchpage_va
index|[
literal|0
index|]
expr_stmt|;
block|}
else|else
block|{
name|va
operator|=
name|pa
expr_stmt|;
block|}
for|for
control|(
name|off
operator|=
literal|0
init|;
name|off
operator|<
name|PAGE_SIZE
condition|;
name|off
operator|+=
name|cacheline_size
control|)
asm|__asm __volatile("dcbz 0,%0" :: "r"(va + off));
if|if
condition|(
operator|!
name|hw_direct_map
condition|)
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_zero_page_idle
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|moea64_zero_page
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|vm_offset_t
name|moea64_quick_enter_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_paddr_t
name|pa
init|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
decl_stmt|;
if|if
condition|(
name|hw_direct_map
condition|)
return|return
operator|(
name|pa
operator|)
return|;
comment|/*  	 * MOEA64_PTE_REPLACE does some locking, so we can't just grab 	 * a critical section and access the PCPU data like on i386. 	 * Instead, pin the thread and grab the PCPU lock to prevent 	 * a preempting thread from using the same PCPU data. 	 */
name|sched_pin
argument_list|()
expr_stmt|;
name|mtx_assert
argument_list|(
name|PCPU_PTR
argument_list|(
name|qmap_lock
argument_list|)
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|PCPU_GET
argument_list|(
name|qmap_pvo
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|PCPU_PTR
argument_list|(
name|qmap_lock
argument_list|)
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|=
name|moea64_calc_wimg
argument_list|(
name|pa
argument_list|,
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
argument_list|)
operator||
operator|(
name|uint64_t
operator|)
name|pa
expr_stmt|;
name|MOEA64_PTE_REPLACE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|,
name|MOEA64_PTE_INVALIDATE
argument_list|)
expr_stmt|;
name|isync
argument_list|()
expr_stmt|;
return|return
operator|(
name|PCPU_GET
argument_list|(
name|qmap_addr
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|moea64_quick_remove_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|)
block|{
if|if
condition|(
name|hw_direct_map
condition|)
return|return;
name|mtx_assert
argument_list|(
name|PCPU_PTR
argument_list|(
name|qmap_lock
argument_list|)
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|PCPU_GET
argument_list|(
name|qmap_addr
argument_list|)
operator|==
name|addr
argument_list|,
operator|(
literal|"moea64_quick_remove_page: invalid address"
operator|)
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
name|PCPU_PTR
argument_list|(
name|qmap_lock
argument_list|)
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map the given physical page at the specified virtual address in the  * target pmap with the protection requested.  If specified the page  * will be wired down.  */
end_comment

begin_function
name|int
name|moea64_enter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|u_int
name|flags
parameter_list|,
name|int8_t
name|psind
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|oldpvo
decl_stmt|;
name|struct
name|pvo_head
modifier|*
name|pvo_head
decl_stmt|;
name|uint64_t
name|pte_lo
decl_stmt|;
name|int
name|error
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|&&
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|alloc_pvo_entry
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pmap
operator|=
name|NULL
expr_stmt|;
comment|/* to be filled in later */
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|=
name|prot
expr_stmt|;
name|pte_lo
operator|=
name|moea64_calc_wimg
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|pte_lo
expr_stmt|;
if|if
condition|(
operator|(
name|flags
operator|&
name|PMAP_ENTER_WIRED
operator|)
operator|!=
literal|0
condition|)
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_WIRED
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
operator|||
operator|!
name|moea64_initialized
condition|)
block|{
name|pvo_head
operator|=
name|NULL
expr_stmt|;
block|}
else|else
block|{
name|pvo_head
operator|=
operator|&
name|m
operator|->
name|md
operator|.
name|mdpg_pvoh
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_MANAGED
expr_stmt|;
block|}
for|for
control|(
init|;
condition|;
control|)
block|{
name|PV_PAGE_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|NULL
condition|)
name|init_pvo_entry
argument_list|(
name|pvo
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
if|if
condition|(
name|pmap_bootstrapped
operator|&&
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|oldpvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpvo
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|oldpvo
operator|->
name|pvo_vaddr
operator|==
name|pvo
operator|->
name|pvo_vaddr
operator|&&
name|oldpvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|==
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&&
name|oldpvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|==
name|prot
condition|)
block|{
comment|/* Identical mapping already exists */
name|error
operator|=
literal|0
expr_stmt|;
comment|/* If not in page table, reinsert it */
if|if
condition|(
name|MOEA64_PTE_SYNCH
argument_list|(
name|mmu
argument_list|,
name|oldpvo
argument_list|)
operator|<
literal|0
condition|)
block|{
name|moea64_pte_overflow
operator|--
expr_stmt|;
name|MOEA64_PTE_INSERT
argument_list|(
name|mmu
argument_list|,
name|oldpvo
argument_list|)
expr_stmt|;
block|}
comment|/* Then just clean up and go home */
name|PV_PAGE_UNLOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|free_pvo_entry
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
break|break;
block|}
comment|/* Otherwise, need to kill it first */
name|KASSERT
argument_list|(
name|oldpvo
operator|->
name|pvo_pmap
operator|==
name|pmap
argument_list|,
operator|(
literal|"pmap of old "
literal|"mapping does not match new mapping"
operator|)
argument_list|)
expr_stmt|;
name|moea64_pvo_remove_from_pmap
argument_list|(
name|mmu
argument_list|,
name|oldpvo
argument_list|)
expr_stmt|;
block|}
name|error
operator|=
name|moea64_pvo_enter
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|,
name|pvo_head
argument_list|)
expr_stmt|;
name|PV_PAGE_UNLOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Free any dead pages */
if|if
condition|(
name|oldpvo
operator|!=
name|NULL
condition|)
block|{
name|PV_LOCK
argument_list|(
name|oldpvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|moea64_pvo_remove_from_page
argument_list|(
name|mmu
argument_list|,
name|oldpvo
argument_list|)
expr_stmt|;
name|PV_UNLOCK
argument_list|(
name|oldpvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|free_pvo_entry
argument_list|(
name|oldpvo
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|error
operator|!=
name|ENOMEM
condition|)
break|break;
if|if
condition|(
operator|(
name|flags
operator|&
name|PMAP_ENTER_NOSLEEP
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|KERN_RESOURCE_SHORTAGE
operator|)
return|;
name|VM_OBJECT_ASSERT_UNLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
block|}
comment|/* 	 * Flush the page from the instruction cache if this page is 	 * mapped executable and cacheable. 	 */
if|if
condition|(
name|pmap
operator|!=
name|kernel_pmap
operator|&&
operator|!
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_EXECUTABLE
operator|)
operator|&&
operator|(
name|pte_lo
operator|&
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator||
name|LPTE_NOEXEC
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_EXECUTABLE
argument_list|)
expr_stmt|;
name|moea64_syncicache
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|KERN_SUCCESS
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_syncicache
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|sz
parameter_list|)
block|{
comment|/* 	 * This is much trickier than on older systems because 	 * we can't sync the icache on physical addresses directly 	 * without a direct map. Instead we check a couple of cases 	 * where the memory is already mapped in and, failing that, 	 * use the same trick we use for page zeroing to create 	 * a temporary mapping for this physical address. 	 */
if|if
condition|(
operator|!
name|pmap_bootstrapped
condition|)
block|{
comment|/* 		 * If PMAP is not bootstrapped, we are likely to be 		 * in real mode. 		 */
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|pa
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hw_direct_map
condition|)
block|{
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|pa
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Use the scratch page to set up a temp mapping */
name|mtx_lock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
name|moea64_set_scratchpage_pa
argument_list|(
name|mmu
argument_list|,
literal|1
argument_list|,
name|pa
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
operator|(
name|moea64_scratchpage_va
index|[
literal|1
index|]
operator|+
operator|(
name|va
operator|&
name|ADDR_POFF
operator|)
operator|)
argument_list|,
name|sz
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_scratchpage_mtx
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Maps a sequence of resident pages belonging to the same object.  * The sequence begins with the given page m_start.  This page is  * mapped at the given virtual address start.  Each subsequent page is  * mapped at a virtual address that is offset from start by the same  * amount as the page is offset from m_start within the object.  The  * last page in the sequence is the page with the largest offset from  * m_start that can be mapped at a virtual address less than the given  * virtual address end.  Not every virtual page between start and end  * is mapped; only those for which a resident page exists with the  * corresponding offset from m_start are mapped.  */
end_comment

begin_function
name|void
name|moea64_enter_object
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|start
parameter_list|,
name|vm_offset_t
name|end
parameter_list|,
name|vm_page_t
name|m_start
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_pindex_t
name|diff
decl_stmt|,
name|psize
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m_start
operator|->
name|object
argument_list|)
expr_stmt|;
name|psize
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|m
operator|=
name|m_start
expr_stmt|;
while|while
condition|(
name|m
operator|!=
name|NULL
operator|&&
operator|(
name|diff
operator|=
name|m
operator|->
name|pindex
operator|-
name|m_start
operator|->
name|pindex
operator|)
operator|<
name|psize
condition|)
block|{
name|moea64_enter
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|start
operator|+
name|ptoa
argument_list|(
name|diff
argument_list|)
argument_list|,
name|m
argument_list|,
name|prot
operator|&
operator|(
name|VM_PROT_READ
operator||
name|VM_PROT_EXECUTE
operator|)
argument_list|,
name|PMAP_ENTER_NOSLEEP
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|m
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|moea64_enter_quick
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|moea64_enter
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
operator|&
operator|(
name|VM_PROT_READ
operator||
name|VM_PROT_EXECUTE
operator|)
argument_list|,
name|PMAP_ENTER_NOSLEEP
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|vm_paddr_t
name|moea64_extract
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|==
name|NULL
condition|)
name|pa
operator|=
literal|0
expr_stmt|;
else|else
name|pa
operator|=
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
operator|)
operator||
operator|(
name|va
operator|-
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Atomically extract and hold the physical page with the given  * pmap and virtual address pair if that mapping permits the given  * protection.  */
end_comment

begin_function
name|vm_page_t
name|moea64_extract_and_hold
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pmap
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|&
name|prot
operator|)
operator|==
name|prot
condition|)
block|{
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|,
operator|&
name|pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|PA_UNLOCK_COND
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|mmu_t
name|installed_mmu
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|void
modifier|*
name|moea64_uma_page_alloc
parameter_list|(
name|uma_zone_t
name|zone
parameter_list|,
name|vm_size_t
name|bytes
parameter_list|,
name|uint8_t
modifier|*
name|flags
parameter_list|,
name|int
name|wait
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|pflags
decl_stmt|,
name|needed_lock
decl_stmt|;
comment|/* 	 * This entire routine is a horrible hack to avoid bothering kmem 	 * for new KVA addresses. Because this can get called from inside 	 * kmem allocation routines, calling kmem for a new address here 	 * can lead to multiply locking non-recursive mutexes. 	 */
operator|*
name|flags
operator|=
name|UMA_SLAB_PRIV
expr_stmt|;
name|needed_lock
operator|=
operator|!
name|PMAP_LOCKED
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|pflags
operator|=
name|malloc2vm_flags
argument_list|(
name|wait
argument_list|)
operator||
name|VM_ALLOC_WIRED
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|pflags
operator||
name|VM_ALLOC_NOOBJ
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|wait
operator|&
name|M_NOWAIT
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|VM_WAIT
expr_stmt|;
block|}
else|else
break|break;
block|}
name|va
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|alloc_pvo_entry
argument_list|(
literal|1
comment|/* bootstrap */
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|=
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|LPTE_M
expr_stmt|;
if|if
condition|(
name|needed_lock
condition|)
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|init_pvo_entry
argument_list|(
name|pvo
argument_list|,
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_WIRED
expr_stmt|;
name|moea64_pvo_enter
argument_list|(
name|installed_mmu
argument_list|,
name|pvo
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|needed_lock
condition|)
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|wait
operator|&
name|M_ZERO
operator|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
return|return
operator|(
name|void
operator|*
operator|)
name|va
return|;
block|}
end_function

begin_decl_stmt
specifier|extern
name|int
name|elf32_nxstack
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|moea64_init
parameter_list|(
name|mmu_t
name|mmu
parameter_list|)
block|{
name|CTR0
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_init"
argument_list|)
expr_stmt|;
name|moea64_pvo_zone
operator|=
name|uma_zcreate
argument_list|(
literal|"UPVO entry"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|pvo_entry
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|UMA_ALIGN_PTR
argument_list|,
name|UMA_ZONE_VM
operator||
name|UMA_ZONE_NOFREE
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|hw_direct_map
condition|)
block|{
name|installed_mmu
operator|=
name|mmu
expr_stmt|;
name|uma_zone_set_allocf
argument_list|(
name|moea64_pvo_zone
argument_list|,
name|moea64_uma_page_alloc
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|COMPAT_FREEBSD32
name|elf32_nxstack
operator|=
literal|1
expr_stmt|;
endif|#
directive|endif
name|moea64_initialized
operator|=
name|TRUE
expr_stmt|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_is_referenced
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_is_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|moea64_query_bit
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
name|LPTE_REF
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_is_modified
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_is_modified: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not exclusive busied, then PGA_WRITEABLE cannot be 	 * concurrently set while the object is locked.  Thus, if PGA_WRITEABLE 	 * is clear, no PTEs can have LPTE_CHG set. 	 */
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
return|return
operator|(
name|moea64_query_bit
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
name|LPTE_CHG
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_is_prefaultable
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|boolean_t
name|rv
init|=
name|TRUE
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pmap
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
condition|)
name|rv
operator|=
name|FALSE
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_function
name|void
name|moea64_clear_modify
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_clear_modify: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"moea64_clear_modify: page %p is exclusive busied"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not PGA_WRITEABLE, then no PTEs can have LPTE_CHG 	 * set.  If the object containing the page is locked and the page is 	 * not exclusive busied, then PGA_WRITEABLE cannot be concurrently set. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|moea64_clear_bit
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
name|LPTE_CHG
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Clear the write and modified bits in each of the given page's mappings.  */
end_comment

begin_function
name|void
name|moea64_remove_write
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|int64_t
name|refchg
decl_stmt|,
name|ret
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_remove_write: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not exclusive busied, then PGA_WRITEABLE cannot be 	 * set by another thread while the object is locked.  Thus, 	 * if PGA_WRITEABLE is clear, no page table entries need updating. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|powerpc_sync
argument_list|()
expr_stmt|;
name|PV_PAGE_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|refchg
operator|=
literal|0
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|pmap
operator|=
name|pvo
operator|->
name|pvo_pmap
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_DEAD
operator|)
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
condition|)
block|{
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|&=
operator|~
name|VM_PROT_WRITE
expr_stmt|;
name|ret
operator|=
name|MOEA64_PTE_REPLACE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|,
name|MOEA64_PTE_PROT_UPDATE
argument_list|)
expr_stmt|;
if|if
condition|(
name|ret
operator|<
literal|0
condition|)
name|ret
operator|=
name|LPTE_CHG
expr_stmt|;
name|refchg
operator||=
name|ret
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|kernel_pmap
condition|)
name|isync
argument_list|()
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|refchg
operator||
name|atomic_readandclear_32
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|mdpg_attrs
argument_list|)
operator|)
operator|&
name|LPTE_CHG
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|PV_PAGE_UNLOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	moea64_ts_referenced:  *  *	Return a count of reference bits for a page, clearing those bits.  *	It is not necessary for every reference bit to be cleared, but it  *	is necessary that 0 only be returned when there are truly no  *	reference bits set.  *  *	XXX: The exact number of bits to check and clear is a matter that  *	should be tested and standardized at some point in the future for  *	optimal aging of shared pages.  */
end_comment

begin_function
name|int
name|moea64_ts_referenced
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_ts_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|moea64_clear_bit
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
name|LPTE_REF
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Modify the WIMG settings of all mappings for a page.  */
end_comment

begin_function
name|void
name|moea64_page_set_memattr
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|int64_t
name|refchg
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|uint64_t
name|lo
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
block|{
name|m
operator|->
name|md
operator|.
name|mdpg_cache_attrs
operator|=
name|ma
expr_stmt|;
return|return;
block|}
name|lo
operator|=
name|moea64_calc_wimg
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|ma
argument_list|)
expr_stmt|;
name|PV_PAGE_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|pmap
operator|=
name|pvo
operator|->
name|pvo_pmap
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_DEAD
operator|)
condition|)
block|{
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&=
operator|~
name|LPTE_WIMG
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator||=
name|lo
expr_stmt|;
name|refchg
operator|=
name|MOEA64_PTE_REPLACE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|,
name|MOEA64_PTE_INVALIDATE
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|<
literal|0
condition|)
name|refchg
operator|=
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
condition|?
name|LPTE_CHG
else|:
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_MANAGED
operator|)
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
condition|)
block|{
name|refchg
operator||=
name|atomic_readandclear_32
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|mdpg_attrs
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|&
name|LPTE_CHG
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|&
name|LPTE_REF
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|kernel_pmap
condition|)
name|isync
argument_list|()
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|m
operator|->
name|md
operator|.
name|mdpg_cache_attrs
operator|=
name|ma
expr_stmt|;
name|PV_PAGE_UNLOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map a wired page into kernel virtual address space.  */
end_comment

begin_function
name|void
name|moea64_kenter_attr
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|oldpvo
decl_stmt|;
name|pvo
operator|=
name|alloc_pvo_entry
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|=
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
operator||
name|VM_PROT_EXECUTE
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|=
operator|(
name|pa
operator|&
operator|~
name|ADDR_POFF
operator|)
operator||
name|moea64_calc_wimg
argument_list|(
name|pa
argument_list|,
name|ma
argument_list|)
expr_stmt|;
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_WIRED
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|oldpvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpvo
operator|!=
name|NULL
condition|)
name|moea64_pvo_remove_from_pmap
argument_list|(
name|mmu
argument_list|,
name|oldpvo
argument_list|)
expr_stmt|;
name|init_pvo_entry
argument_list|(
name|pvo
argument_list|,
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|error
operator|=
name|moea64_pvo_enter
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
comment|/* Free any dead pages */
if|if
condition|(
name|oldpvo
operator|!=
name|NULL
condition|)
block|{
name|PV_LOCK
argument_list|(
name|oldpvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|moea64_pvo_remove_from_page
argument_list|(
name|mmu
argument_list|,
name|oldpvo
argument_list|)
expr_stmt|;
name|PV_UNLOCK
argument_list|(
name|oldpvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|free_pvo_entry
argument_list|(
name|oldpvo
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|error
operator|!=
literal|0
operator|&&
name|error
operator|!=
name|ENOENT
condition|)
name|panic
argument_list|(
literal|"moea64_kenter: failed to enter va %#zx pa %#zx: %d"
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|error
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_kenter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|moea64_kenter_attr
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Extract the physical page address associated with the given kernel virtual  * address.  */
end_comment

begin_function
name|vm_paddr_t
name|moea64_kextract
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
comment|/* 	 * Shortcut the direct-mapped case when applicable.  We never put 	 * anything but 1:1 mappings below VM_MIN_KERNEL_ADDRESS. 	 */
if|if
condition|(
name|va
operator|<
name|VM_MIN_KERNEL_ADDRESS
condition|)
return|return
operator|(
name|va
operator|)
return|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pvo
operator|!=
name|NULL
argument_list|,
operator|(
literal|"moea64_kextract: no addr found for %#"
name|PRIxPTR
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
name|pa
operator|=
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
operator|)
operator||
operator|(
name|va
operator|-
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Remove a wired page from kernel virtual address space.  */
end_comment

begin_function
name|void
name|moea64_kremove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|moea64_remove
argument_list|(
name|mmu
argument_list|,
name|kernel_pmap
argument_list|,
name|va
argument_list|,
name|va
operator|+
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map a range of physical addresses into kernel virtual address space.  *  * The value passed in *virt is a suggested virtual address for the mapping.  * Architectures which can support a direct-mapped physical to virtual region  * can return the appropriate address within that region, leaving '*virt'  * unchanged.  Other architectures should map the pages starting at '*virt' and  * update '*virt' with the first usable address after the mapped region.  */
end_comment

begin_function
name|vm_offset_t
name|moea64_map
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
modifier|*
name|virt
parameter_list|,
name|vm_paddr_t
name|pa_start
parameter_list|,
name|vm_paddr_t
name|pa_end
parameter_list|,
name|int
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|sva
decl_stmt|,
name|va
decl_stmt|;
if|if
condition|(
name|hw_direct_map
condition|)
block|{
comment|/* 		 * Check if every page in the region is covered by the direct 		 * map. The direct map covers all of physical memory. Use 		 * moea64_calc_wimg() as a shortcut to see if the page is in 		 * physical memory as a way to see if the direct map covers it. 		 */
for|for
control|(
name|va
operator|=
name|pa_start
init|;
name|va
operator|<
name|pa_end
condition|;
name|va
operator|+=
name|PAGE_SIZE
control|)
if|if
condition|(
name|moea64_calc_wimg
argument_list|(
name|va
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
operator|!=
name|LPTE_M
condition|)
break|break;
if|if
condition|(
name|va
operator|==
name|pa_end
condition|)
return|return
operator|(
name|pa_start
operator|)
return|;
block|}
name|sva
operator|=
operator|*
name|virt
expr_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
comment|/* XXX respect prot argument */
for|for
control|(
init|;
name|pa_start
operator|<
name|pa_end
condition|;
name|pa_start
operator|+=
name|PAGE_SIZE
operator|,
name|va
operator|+=
name|PAGE_SIZE
control|)
name|moea64_kenter
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|pa_start
argument_list|)
expr_stmt|;
operator|*
name|virt
operator|=
name|va
expr_stmt|;
return|return
operator|(
name|sva
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns true if the pmap's pv is one of the first  * 16 pvs linked to from this page.  This count may  * be changed upwards or downwards in the future; it  * is only necessary that true be returned for a small  * subset of pmaps for proper page aging.  */
end_comment

begin_function
name|boolean_t
name|moea64_page_exists_quick
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|loops
decl_stmt|;
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"moea64_page_exists_quick: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|loops
operator|=
literal|0
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|PV_PAGE_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_DEAD
operator|)
operator|&&
name|pvo
operator|->
name|pvo_pmap
operator|==
name|pmap
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
if|if
condition|(
operator|++
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
name|PV_PAGE_UNLOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return the number of managed mappings to the given physical page  * that are wired.  */
end_comment

begin_function
name|int
name|moea64_page_wired_mappings
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|int
name|count
decl_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|count
operator|)
return|;
name|PV_PAGE_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
operator|(
name|PVO_DEAD
operator||
name|PVO_WIRED
operator|)
operator|)
operator|==
name|PVO_WIRED
condition|)
name|count
operator|++
expr_stmt|;
name|PV_PAGE_UNLOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_decl_stmt
specifier|static
name|uintptr_t
name|moea64_vsidcontext
decl_stmt|;
end_decl_stmt

begin_function
name|uintptr_t
name|moea64_get_unique_vsid
parameter_list|(
name|void
parameter_list|)
block|{
name|u_int
name|entropy
decl_stmt|;
name|register_t
name|hash
decl_stmt|;
name|uint32_t
name|mask
decl_stmt|;
name|int
name|i
decl_stmt|;
name|entropy
operator|=
literal|0
expr_stmt|;
asm|__asm __volatile("mftb %0" : "=r"(entropy));
name|mtx_lock
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NVSIDS
condition|;
name|i
operator|+=
name|VSID_NBPW
control|)
block|{
name|u_int
name|n
decl_stmt|;
comment|/* 		 * Create a new value by mutiplying by a prime and adding in 		 * entropy from the timebase register.  This is to make the 		 * VSID more random so that the PT hash function collides 		 * less often.  (Note that the prime casues gcc to do shifts 		 * instead of a multiply.) 		 */
name|moea64_vsidcontext
operator|=
operator|(
name|moea64_vsidcontext
operator|*
literal|0x1105
operator|)
operator|+
name|entropy
expr_stmt|;
name|hash
operator|=
name|moea64_vsidcontext
operator|&
operator|(
name|NVSIDS
operator|-
literal|1
operator|)
expr_stmt|;
if|if
condition|(
name|hash
operator|==
literal|0
condition|)
comment|/* 0 is special, avoid it */
continue|continue;
name|n
operator|=
name|hash
operator|>>
literal|5
expr_stmt|;
name|mask
operator|=
literal|1
operator|<<
operator|(
name|hash
operator|&
operator|(
name|VSID_NBPW
operator|-
literal|1
operator|)
operator|)
expr_stmt|;
name|hash
operator|=
operator|(
name|moea64_vsidcontext
operator|&
name|VSID_HASHMASK
operator|)
expr_stmt|;
if|if
condition|(
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator|&
name|mask
condition|)
block|{
comment|/* collision? */
comment|/* anything free in this bucket? */
if|if
condition|(
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator|==
literal|0xffffffff
condition|)
block|{
name|entropy
operator|=
operator|(
name|moea64_vsidcontext
operator|>>
literal|20
operator|)
expr_stmt|;
continue|continue;
block|}
name|i
operator|=
name|ffs
argument_list|(
operator|~
name|moea64_vsid_bitmap
index|[
name|n
index|]
argument_list|)
operator|-
literal|1
expr_stmt|;
name|mask
operator|=
literal|1
operator|<<
name|i
expr_stmt|;
name|hash
operator|&=
name|VSID_HASHMASK
operator|&
operator|~
operator|(
name|VSID_NBPW
operator|-
literal|1
operator|)
expr_stmt|;
name|hash
operator||=
name|i
expr_stmt|;
block|}
if|if
condition|(
name|hash
operator|==
name|VSID_VRMA
condition|)
comment|/* also special, avoid this too */
continue|continue;
name|KASSERT
argument_list|(
operator|!
operator|(
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator|&
name|mask
operator|)
argument_list|,
operator|(
literal|"Allocating in-use VSID %#zx\n"
operator|,
name|hash
operator|)
argument_list|)
expr_stmt|;
name|moea64_vsid_bitmap
index|[
name|n
index|]
operator||=
name|mask
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|)
expr_stmt|;
return|return
operator|(
name|hash
operator|)
return|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|)
expr_stmt|;
name|panic
argument_list|(
literal|"%s: out of segments"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|__powerpc64__
end_ifdef

begin_function
name|void
name|moea64_pinit
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|RB_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pmap_pvo
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_slb_tree_root
operator|=
name|slb_alloc_tree
argument_list|()
expr_stmt|;
name|pmap
operator|->
name|pm_slb
operator|=
name|slb_alloc_user_cache
argument_list|()
expr_stmt|;
name|pmap
operator|->
name|pm_slb_len
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_else
else|#
directive|else
end_else

begin_function
name|void
name|moea64_pinit
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|uint32_t
name|hash
decl_stmt|;
name|RB_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pmap_pvo
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_bootstrapped
condition|)
name|pmap
operator|->
name|pmap_phys
operator|=
operator|(
name|pmap_t
operator|)
name|moea64_kextract
argument_list|(
name|mmu
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|pmap
argument_list|)
expr_stmt|;
else|else
name|pmap
operator|->
name|pmap_phys
operator|=
name|pmap
expr_stmt|;
comment|/* 	 * Allocate some segment registers for this pmap. 	 */
name|hash
operator|=
name|moea64_get_unique_vsid
argument_list|()
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
literal|16
condition|;
name|i
operator|++
control|)
name|pmap
operator|->
name|pm_sr
index|[
name|i
index|]
operator|=
name|VSID_MAKE
argument_list|(
name|i
argument_list|,
name|hash
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_sr
index|[
literal|0
index|]
operator|!=
literal|0
argument_list|,
operator|(
literal|"moea64_pinit: pm_sr[0] = 0"
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Initialize the pmap associated with process 0.  */
end_comment

begin_function
name|void
name|moea64_pinit0
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|)
block|{
name|PMAP_LOCK_INIT
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|moea64_pinit
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pm
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
argument_list|(
name|pm
operator|->
name|pm_stats
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Set the physical protection on the specified range of this map as requested.  */
end_comment

begin_function
specifier|static
name|void
name|moea64_pvo_protect
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|vm_page
modifier|*
name|pg
decl_stmt|;
name|vm_prot_t
name|oldprot
decl_stmt|;
name|int32_t
name|refchg
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pm
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Change the protection of the page. 	 */
name|oldprot
operator|=
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
expr_stmt|;
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|=
name|prot
expr_stmt|;
name|pg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
comment|/* 	 * If the PVO is in the page table, update mapping 	 */
name|refchg
operator|=
name|MOEA64_PTE_REPLACE
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|,
name|MOEA64_PTE_PROT_UPDATE
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|<
literal|0
condition|)
name|refchg
operator|=
operator|(
name|oldprot
operator|&
name|VM_PROT_WRITE
operator|)
condition|?
name|LPTE_CHG
else|:
literal|0
expr_stmt|;
if|if
condition|(
name|pm
operator|!=
name|kernel_pmap
operator|&&
name|pg
operator|!=
name|NULL
operator|&&
operator|!
operator|(
name|pg
operator|->
name|aflags
operator|&
name|PGA_EXECUTABLE
operator|)
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
operator|(
name|LPTE_I
operator||
name|LPTE_G
operator||
name|LPTE_NOEXEC
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|pg
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|pg
argument_list|,
name|PGA_EXECUTABLE
argument_list|)
expr_stmt|;
name|moea64_syncicache
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
argument_list|,
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Update vm about the REF/CHG bits if the page is managed and we have 	 * removed write access. 	 */
if|if
condition|(
name|pg
operator|!=
name|NULL
operator|&&
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_MANAGED
operator|)
operator|&&
operator|(
name|oldprot
operator|&
name|VM_PROT_WRITE
operator|)
condition|)
block|{
name|refchg
operator||=
name|atomic_readandclear_32
argument_list|(
operator|&
name|pg
operator|->
name|md
operator|.
name|mdpg_attrs
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|&
name|LPTE_CHG
condition|)
name|vm_page_dirty
argument_list|(
name|pg
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|&
name|LPTE_REF
condition|)
name|vm_page_aflag_set
argument_list|(
name|pg
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|moea64_protect
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|tpvo
decl_stmt|,
name|key
decl_stmt|;
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"moea64_protect: pm=%p sva=%#x eva=%#x prot=%#x"
argument_list|,
name|pm
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|,
name|prot
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pm
operator|==
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
operator|||
name|pm
operator|==
name|kernel_pmap
argument_list|,
operator|(
literal|"moea64_protect: non current pmap"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_READ
operator|)
operator|==
name|VM_PROT_NONE
condition|)
block|{
name|moea64_remove
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
return|return;
block|}
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|key
operator|.
name|pvo_vaddr
operator|=
name|sva
expr_stmt|;
for|for
control|(
name|pvo
operator|=
name|RB_NFIND
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
operator|&
name|key
argument_list|)
init|;
name|pvo
operator|!=
name|NULL
operator|&&
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|<
name|eva
condition|;
name|pvo
operator|=
name|tpvo
control|)
block|{
name|tpvo
operator|=
name|RB_NEXT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|moea64_pvo_protect
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|pvo
argument_list|,
name|prot
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map a list of wired pages into kernel virtual address space.  This is  * intended for temporary mappings which do not need page modification or  * references recorded.  Existing mappings in the region are overwritten.  */
end_comment

begin_function
name|void
name|moea64_qenter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
modifier|*
name|m
parameter_list|,
name|int
name|count
parameter_list|)
block|{
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|moea64_kenter
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
operator|*
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|m
operator|++
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Remove page mappings from kernel virtual address space.  Intended for  * temporary mappings entered by moea64_qenter.  */
end_comment

begin_function
name|void
name|moea64_qremove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|int
name|count
parameter_list|)
block|{
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|moea64_kremove
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|moea64_release_vsid
parameter_list|(
name|uint64_t
name|vsid
parameter_list|)
block|{
name|int
name|idx
decl_stmt|,
name|mask
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|)
expr_stmt|;
name|idx
operator|=
name|vsid
operator|&
operator|(
name|NVSIDS
operator|-
literal|1
operator|)
expr_stmt|;
name|mask
operator|=
literal|1
operator|<<
operator|(
name|idx
operator|%
name|VSID_NBPW
operator|)
expr_stmt|;
name|idx
operator|/=
name|VSID_NBPW
expr_stmt|;
name|KASSERT
argument_list|(
name|moea64_vsid_bitmap
index|[
name|idx
index|]
operator|&
name|mask
argument_list|,
operator|(
literal|"Freeing unallocated VSID %#jx"
operator|,
name|vsid
operator|)
argument_list|)
expr_stmt|;
name|moea64_vsid_bitmap
index|[
name|idx
index|]
operator|&=
operator|~
name|mask
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|moea64_slb_mutex
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_release
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
comment|/* 	 * Free segment registers' VSIDs 	 */
ifdef|#
directive|ifdef
name|__powerpc64__
name|slb_free_tree
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|slb_free_user_cache
argument_list|(
name|pmap
operator|->
name|pm_slb
argument_list|)
expr_stmt|;
else|#
directive|else
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_sr
index|[
literal|0
index|]
operator|!=
literal|0
argument_list|,
operator|(
literal|"moea64_release: pm_sr[0] = 0"
operator|)
argument_list|)
expr_stmt|;
name|moea64_release_vsid
argument_list|(
name|VSID_TO_HASH
argument_list|(
name|pmap
operator|->
name|pm_sr
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  * Remove all pages mapped by the specified pmap  */
end_comment

begin_function
name|void
name|moea64_remove_pages
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|tpvo
decl_stmt|;
name|struct
name|pvo_tree
name|tofree
decl_stmt|;
name|RB_INIT
argument_list|(
operator|&
name|tofree
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|RB_FOREACH_SAFE
argument_list|(
argument|pvo
argument_list|,
argument|pvo_tree
argument_list|,
argument|&pm->pmap_pvo
argument_list|,
argument|tpvo
argument_list|)
block|{
if|if
condition|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
condition|)
continue|continue;
comment|/* 		 * For locking reasons, remove this from the page table and 		 * pmap, but save delinking from the vm_page for a second 		 * pass 		 */
name|moea64_pvo_remove_from_pmap
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|RB_INSERT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|tofree
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|RB_FOREACH_SAFE
argument_list|(
argument|pvo
argument_list|,
argument|pvo_tree
argument_list|,
argument|&tofree
argument_list|,
argument|tpvo
argument_list|)
block|{
name|PV_LOCK
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|moea64_pvo_remove_from_page
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|PV_UNLOCK
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|RB_REMOVE
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|tofree
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|free_pvo_entry
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Remove the given range of addresses from the specified map.  */
end_comment

begin_function
name|void
name|moea64_remove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|tpvo
decl_stmt|,
name|key
decl_stmt|;
name|struct
name|pvo_tree
name|tofree
decl_stmt|;
comment|/* 	 * Perform an unsynchronized read.  This is, however, safe. 	 */
if|if
condition|(
name|pm
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
condition|)
return|return;
name|key
operator|.
name|pvo_vaddr
operator|=
name|sva
expr_stmt|;
name|RB_INIT
argument_list|(
operator|&
name|tofree
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
for|for
control|(
name|pvo
operator|=
name|RB_NFIND
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
operator|&
name|key
argument_list|)
init|;
name|pvo
operator|!=
name|NULL
operator|&&
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|<
name|eva
condition|;
name|pvo
operator|=
name|tpvo
control|)
block|{
name|tpvo
operator|=
name|RB_NEXT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
comment|/* 		 * For locking reasons, remove this from the page table and 		 * pmap, but save delinking from the vm_page for a second 		 * pass 		 */
name|moea64_pvo_remove_from_pmap
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|RB_INSERT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|tofree
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|RB_FOREACH_SAFE
argument_list|(
argument|pvo
argument_list|,
argument|pvo_tree
argument_list|,
argument|&tofree
argument_list|,
argument|tpvo
argument_list|)
block|{
name|PV_LOCK
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|moea64_pvo_remove_from_page
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|PV_UNLOCK
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|RB_REMOVE
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|tofree
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|free_pvo_entry
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Remove physical page from all pmaps in which it resides. moea64_pvo_remove()  * will reflect changes in pte's back to the vm_page.  */
end_comment

begin_function
name|void
name|moea64_remove_all
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
modifier|*
name|next_pvo
decl_stmt|;
name|struct
name|pvo_head
name|freequeue
decl_stmt|;
name|int
name|wasdead
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|freequeue
argument_list|)
expr_stmt|;
name|PV_PAGE_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|LIST_FOREACH_SAFE
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|,
argument|next_pvo
argument_list|)
block|{
name|pmap
operator|=
name|pvo
operator|->
name|pvo_pmap
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|wasdead
operator|=
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_DEAD
operator|)
expr_stmt|;
if|if
condition|(
operator|!
name|wasdead
condition|)
name|moea64_pvo_remove_from_pmap
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|moea64_pvo_remove_from_page
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|wasdead
condition|)
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|freequeue
argument_list|,
name|pvo
argument_list|,
name|pvo_vlink
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"Page still has mappings"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
argument_list|,
operator|(
literal|"Page still writable"
operator|)
argument_list|)
expr_stmt|;
name|PV_PAGE_UNLOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* Clean up UMA allocations */
name|LIST_FOREACH_SAFE
argument_list|(
argument|pvo
argument_list|,
argument|&freequeue
argument_list|,
argument|pvo_vlink
argument_list|,
argument|next_pvo
argument_list|)
name|free_pvo_entry
argument_list|(
name|pvo
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Allocate a physical page of memory directly from the phys_avail map.  * Can only be called from moea64_bootstrap before avail start and end are  * calculated.  */
end_comment

begin_function
name|vm_offset_t
name|moea64_bootstrap_alloc
parameter_list|(
name|vm_size_t
name|size
parameter_list|,
name|u_int
name|align
parameter_list|)
block|{
name|vm_offset_t
name|s
decl_stmt|,
name|e
decl_stmt|;
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|size
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
block|{
if|if
condition|(
name|align
operator|!=
literal|0
condition|)
name|s
operator|=
operator|(
name|phys_avail
index|[
name|i
index|]
operator|+
name|align
operator|-
literal|1
operator|)
operator|&
operator|~
operator|(
name|align
operator|-
literal|1
operator|)
expr_stmt|;
else|else
name|s
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
name|e
operator|=
name|s
operator|+
name|size
expr_stmt|;
if|if
condition|(
name|s
operator|<
name|phys_avail
index|[
name|i
index|]
operator|||
name|e
operator|>
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|)
continue|continue;
if|if
condition|(
name|s
operator|+
name|size
operator|>
name|platform_real_maxaddr
argument_list|()
condition|)
continue|continue;
if|if
condition|(
name|s
operator|==
name|phys_avail
index|[
name|i
index|]
condition|)
block|{
name|phys_avail
index|[
name|i
index|]
operator|+=
name|size
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|e
operator|==
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|)
block|{
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-=
name|size
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|j
operator|=
name|phys_avail_count
operator|*
literal|2
init|;
name|j
operator|>
name|i
condition|;
name|j
operator|-=
literal|2
control|)
block|{
name|phys_avail
index|[
name|j
index|]
operator|=
name|phys_avail
index|[
name|j
operator|-
literal|2
index|]
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|phys_avail
index|[
name|j
operator|-
literal|1
index|]
expr_stmt|;
block|}
name|phys_avail
index|[
name|i
operator|+
literal|3
index|]
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|=
name|s
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|2
index|]
operator|=
name|e
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
return|return
operator|(
name|s
operator|)
return|;
block|}
name|panic
argument_list|(
literal|"moea64_bootstrap_alloc: could not allocate memory"
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|moea64_pvo_enter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|,
name|struct
name|pvo_head
modifier|*
name|pvo_head
parameter_list|)
block|{
name|int
name|first
decl_stmt|,
name|err
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|moea64_pvo_find_va
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|,
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
argument_list|)
operator|==
name|NULL
argument_list|,
operator|(
literal|"Existing mapping for VA %#jx"
operator|,
operator|(
name|uintmax_t
operator|)
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
operator|)
argument_list|)
expr_stmt|;
name|moea64_pvo_enter_calls
operator|++
expr_stmt|;
comment|/* 	 * Add to pmap list 	 */
name|RB_INSERT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
comment|/* 	 * Remember if the list was empty and therefore will be the first 	 * item. 	 */
if|if
condition|(
name|pvo_head
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|LIST_FIRST
argument_list|(
name|pvo_head
argument_list|)
operator|==
name|NULL
condition|)
name|first
operator|=
literal|1
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
name|pvo_head
argument_list|,
name|pvo
argument_list|,
name|pvo_vlink
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
condition|)
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
comment|/* 	 * Insert it into the hardware page table 	 */
name|err
operator|=
name|MOEA64_PTE_INSERT
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
if|if
condition|(
name|err
operator|!=
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"moea64_pvo_enter: overflow"
argument_list|)
expr_stmt|;
block|}
name|moea64_pvo_entries
operator|++
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|kernel_pmap
condition|)
name|isync
argument_list|()
expr_stmt|;
ifdef|#
directive|ifdef
name|__powerpc64__
comment|/* 	 * Make sure all our bootstrap mappings are in the SLB as soon 	 * as virtual memory is switched on. 	 */
if|if
condition|(
operator|!
name|pmap_bootstrapped
condition|)
name|moea64_bootstrap_slb_prefault
argument_list|(
name|PVO_VADDR
argument_list|(
name|pvo
argument_list|)
argument_list|,
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_LARGE
argument_list|)
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
name|first
condition|?
name|ENOENT
else|:
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_pvo_remove_from_pmap
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|)
block|{
name|struct
name|vm_page
modifier|*
name|pg
decl_stmt|;
name|int32_t
name|refchg
decl_stmt|;
name|KASSERT
argument_list|(
name|pvo
operator|->
name|pvo_pmap
operator|!=
name|NULL
argument_list|,
operator|(
literal|"Trying to remove PVO with no pmap"
operator|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_DEAD
operator|)
argument_list|,
operator|(
literal|"Trying to remove dead PVO"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If there is an active pte entry, we need to deactivate it 	 */
name|refchg
operator|=
name|MOEA64_PTE_UNSET
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|<
literal|0
condition|)
block|{
comment|/* 		 * If it was evicted from the page table, be pessimistic and 		 * dirty the page. 		 */
if|if
condition|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
name|refchg
operator|=
name|LPTE_CHG
expr_stmt|;
else|else
name|refchg
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * Update our statistics. 	 */
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
if|if
condition|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_WIRED
condition|)
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
comment|/* 	 * Remove this PVO from the pmap list. 	 */
name|RB_REMOVE
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pvo
operator|->
name|pvo_pmap
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
comment|/* 	 * Mark this for the next sweep 	 */
name|pvo
operator|->
name|pvo_vaddr
operator||=
name|PVO_DEAD
expr_stmt|;
comment|/* Send RC bits to VM */
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_MANAGED
operator|)
operator|&&
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
condition|)
block|{
name|pg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
if|if
condition|(
name|pg
operator|!=
name|NULL
condition|)
block|{
name|refchg
operator||=
name|atomic_readandclear_32
argument_list|(
operator|&
name|pg
operator|->
name|md
operator|.
name|mdpg_attrs
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|&
name|LPTE_CHG
condition|)
name|vm_page_dirty
argument_list|(
name|pg
argument_list|)
expr_stmt|;
if|if
condition|(
name|refchg
operator|&
name|LPTE_REF
condition|)
name|vm_page_aflag_set
argument_list|(
name|pg
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|moea64_pvo_remove_from_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|pvo_entry
modifier|*
name|pvo
parameter_list|)
block|{
name|struct
name|vm_page
modifier|*
name|pg
decl_stmt|;
name|KASSERT
argument_list|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_DEAD
argument_list|,
operator|(
literal|"Trying to delink live page"
operator|)
argument_list|)
expr_stmt|;
comment|/* Use NULL pmaps as a sentinel for races in page deletion */
if|if
condition|(
name|pvo
operator|->
name|pvo_pmap
operator|==
name|NULL
condition|)
return|return;
name|pvo
operator|->
name|pvo_pmap
operator|=
name|NULL
expr_stmt|;
comment|/* 	 * Update vm about page writeability/executability if managed 	 */
name|PV_LOCKASSERT
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
name|pg
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_MANAGED
operator|)
operator|&&
name|pg
operator|!=
name|NULL
condition|)
block|{
name|LIST_REMOVE
argument_list|(
name|pvo
argument_list|,
name|pvo_vlink
argument_list|)
expr_stmt|;
if|if
condition|(
name|LIST_EMPTY
argument_list|(
name|vm_page_to_pvoh
argument_list|(
name|pg
argument_list|)
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|pg
argument_list|,
name|PGA_WRITEABLE
operator||
name|PGA_EXECUTABLE
argument_list|)
expr_stmt|;
block|}
name|moea64_pvo_entries
operator|--
expr_stmt|;
name|moea64_pvo_remove_calls
operator|++
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|struct
name|pvo_entry
modifier|*
name|moea64_pvo_find_va
parameter_list|(
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|pvo_entry
name|key
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pm
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|key
operator|.
name|pvo_vaddr
operator|=
name|va
operator|&
operator|~
name|ADDR_POFF
expr_stmt|;
return|return
operator|(
name|RB_FIND
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|pm
operator|->
name|pmap_pvo
argument_list|,
operator|&
name|key
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|boolean_t
name|moea64_query_bit
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|uint64_t
name|ptebit
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|int64_t
name|ret
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
comment|/* 	 * See if this bit is stored in the page already. 	 */
if|if
condition|(
name|m
operator|->
name|md
operator|.
name|mdpg_attrs
operator|&
name|ptebit
condition|)
return|return
operator|(
name|TRUE
operator|)
return|;
comment|/* 	 * Examine each PTE.  Sync so that any pending REF/CHG bits are 	 * flushed to the PTEs. 	 */
name|rv
operator|=
name|FALSE
expr_stmt|;
name|powerpc_sync
argument_list|()
expr_stmt|;
name|PV_PAGE_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|ret
operator|=
literal|0
expr_stmt|;
comment|/* 		 * See if this pvo has a valid PTE.  if so, fetch the 		 * REF/CHG bits from the valid PTE.  If the appropriate 		 * ptebit is set, return success. 		 */
name|PMAP_LOCK
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_DEAD
operator|)
condition|)
name|ret
operator|=
name|MOEA64_PTE_SYNCH
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|ret
operator|>
literal|0
condition|)
block|{
name|atomic_set_32
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|mdpg_attrs
argument_list|,
name|ret
operator|&
operator|(
name|LPTE_CHG
operator||
name|LPTE_REF
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|ret
operator|&
name|ptebit
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
block|}
block|}
name|PV_PAGE_UNLOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|u_int
name|moea64_clear_bit
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|u_int64_t
name|ptebit
parameter_list|)
block|{
name|u_int
name|count
decl_stmt|;
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|int64_t
name|ret
decl_stmt|;
comment|/* 	 * Sync so that any pending REF/CHG bits are flushed to the PTEs (so 	 * we can reset the right ones). 	 */
name|powerpc_sync
argument_list|()
expr_stmt|;
comment|/* 	 * For each pvo entry, clear the pte's ptebit. 	 */
name|count
operator|=
literal|0
expr_stmt|;
name|PV_PAGE_LOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pvo
argument_list|,
argument|vm_page_to_pvoh(m)
argument_list|,
argument|pvo_vlink
argument_list|)
block|{
name|ret
operator|=
literal|0
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_DEAD
operator|)
condition|)
name|ret
operator|=
name|MOEA64_PTE_CLEAR
argument_list|(
name|mmu
argument_list|,
name|pvo
argument_list|,
name|ptebit
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pvo
operator|->
name|pvo_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|ret
operator|>
literal|0
operator|&&
operator|(
name|ret
operator|&
name|ptebit
operator|)
condition|)
name|count
operator|++
expr_stmt|;
block|}
name|atomic_clear_32
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|mdpg_attrs
argument_list|,
name|ptebit
argument_list|)
expr_stmt|;
name|PV_PAGE_UNLOCK
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_function
name|boolean_t
name|moea64_dev_direct_mapped
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|,
name|key
decl_stmt|;
name|vm_offset_t
name|ppa
decl_stmt|;
name|int
name|error
init|=
literal|0
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|key
operator|.
name|pvo_vaddr
operator|=
name|ppa
operator|=
name|pa
operator|&
operator|~
name|ADDR_POFF
expr_stmt|;
for|for
control|(
name|pvo
operator|=
name|RB_FIND
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|kernel_pmap
operator|->
name|pmap_pvo
argument_list|,
operator|&
name|key
argument_list|)
init|;
name|ppa
operator|<
name|pa
operator|+
name|size
condition|;
name|ppa
operator|+=
name|PAGE_SIZE
operator|,
name|pvo
operator|=
name|RB_NEXT
argument_list|(
name|pvo_tree
argument_list|,
operator|&
name|kernel_pmap
operator|->
name|pmap_pvo
argument_list|,
name|pvo
argument_list|)
control|)
block|{
if|if
condition|(
name|pvo
operator|==
name|NULL
operator|||
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
operator|)
operator|!=
name|ppa
condition|)
block|{
name|error
operator|=
name|EFAULT
expr_stmt|;
break|break;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Map a set of physical memory pages into the kernel virtual  * address space. Return a pointer to where it is mapped. This  * routine is intended to be used for mapping device memory,  * NOT real memory.  */
end_comment

begin_function
name|void
modifier|*
name|moea64_mapdev_attr
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|,
name|tmpva
decl_stmt|,
name|ppa
decl_stmt|,
name|offset
decl_stmt|;
name|ppa
operator|=
name|trunc_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|offset
operator|=
name|pa
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|roundup2
argument_list|(
name|offset
operator|+
name|size
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|va
operator|=
name|kva_alloc
argument_list|(
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|va
condition|)
name|panic
argument_list|(
literal|"moea64_mapdev: Couldn't alloc kernel virtual memory"
argument_list|)
expr_stmt|;
for|for
control|(
name|tmpva
operator|=
name|va
init|;
name|size
operator|>
literal|0
condition|;
control|)
block|{
name|moea64_kenter_attr
argument_list|(
name|mmu
argument_list|,
name|tmpva
argument_list|,
name|ppa
argument_list|,
name|ma
argument_list|)
expr_stmt|;
name|size
operator|-=
name|PAGE_SIZE
expr_stmt|;
name|tmpva
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|ppa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
return|return
operator|(
operator|(
name|void
operator|*
operator|)
operator|(
name|va
operator|+
name|offset
operator|)
operator|)
return|;
block|}
end_function

begin_function
name|void
modifier|*
name|moea64_mapdev
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
return|return
name|moea64_mapdev_attr
argument_list|(
name|mmu
argument_list|,
name|pa
argument_list|,
name|size
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
return|;
block|}
end_function

begin_function
name|void
name|moea64_unmapdev
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|vm_offset_t
name|base
decl_stmt|,
name|offset
decl_stmt|;
name|base
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|offset
operator|=
name|va
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|roundup2
argument_list|(
name|offset
operator|+
name|size
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|kva_free
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_sync_icache
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|sz
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_offset_t
name|lim
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_size_t
name|len
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
while|while
condition|(
name|sz
operator|>
literal|0
condition|)
block|{
name|lim
operator|=
name|round_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|len
operator|=
name|MIN
argument_list|(
name|lim
operator|-
name|va
argument_list|,
name|sz
argument_list|)
expr_stmt|;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|pm
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
operator|&&
operator|!
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_I
operator|)
condition|)
block|{
name|pa
operator|=
operator|(
name|pvo
operator|->
name|pvo_pte
operator|.
name|pa
operator|&
name|LPTE_RPGN
operator|)
operator||
operator|(
name|va
operator|&
name|ADDR_POFF
operator|)
expr_stmt|;
name|moea64_syncicache
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|len
argument_list|)
expr_stmt|;
block|}
name|va
operator|+=
name|len
expr_stmt|;
name|sz
operator|-=
name|len
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|moea64_dumpsys_map
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|size_t
name|sz
parameter_list|,
name|void
modifier|*
modifier|*
name|va
parameter_list|)
block|{
operator|*
name|va
operator|=
operator|(
name|void
operator|*
operator|)
name|pa
expr_stmt|;
block|}
end_function

begin_decl_stmt
specifier|extern
name|struct
name|dump_pa
name|dump_map
index|[
name|PHYS_AVAIL_SZ
operator|+
literal|1
index|]
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|moea64_scan_init
parameter_list|(
name|mmu_t
name|mmu
parameter_list|)
block|{
name|struct
name|pvo_entry
modifier|*
name|pvo
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
operator|!
name|do_minidump
condition|)
block|{
comment|/* Initialize phys. segments for dumpsys(). */
name|memset
argument_list|(
operator|&
name|dump_map
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|dump_map
argument_list|)
argument_list|)
expr_stmt|;
name|mem_regions
argument_list|(
operator|&
name|pregions
argument_list|,
operator|&
name|pregions_sz
argument_list|,
operator|&
name|regions
argument_list|,
operator|&
name|regions_sz
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pregions_sz
condition|;
name|i
operator|++
control|)
block|{
name|dump_map
index|[
name|i
index|]
operator|.
name|pa_start
operator|=
name|pregions
index|[
name|i
index|]
operator|.
name|mr_start
expr_stmt|;
name|dump_map
index|[
name|i
index|]
operator|.
name|pa_size
operator|=
name|pregions
index|[
name|i
index|]
operator|.
name|mr_size
expr_stmt|;
block|}
return|return;
block|}
comment|/* Virtual segments for minidumps: */
name|memset
argument_list|(
operator|&
name|dump_map
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|dump_map
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 1st: kernel .data and .bss. */
name|dump_map
index|[
literal|0
index|]
operator|.
name|pa_start
operator|=
name|trunc_page
argument_list|(
operator|(
name|uintptr_t
operator|)
name|_etext
argument_list|)
expr_stmt|;
name|dump_map
index|[
literal|0
index|]
operator|.
name|pa_size
operator|=
name|round_page
argument_list|(
operator|(
name|uintptr_t
operator|)
name|_end
argument_list|)
operator|-
name|dump_map
index|[
literal|0
index|]
operator|.
name|pa_start
expr_stmt|;
comment|/* 2nd: msgbuf and tables (see pmap_bootstrap()). */
name|dump_map
index|[
literal|1
index|]
operator|.
name|pa_start
operator|=
operator|(
name|vm_paddr_t
operator|)
name|msgbufp
operator|->
name|msg_ptr
expr_stmt|;
name|dump_map
index|[
literal|1
index|]
operator|.
name|pa_size
operator|=
name|round_page
argument_list|(
name|msgbufp
operator|->
name|msg_size
argument_list|)
expr_stmt|;
comment|/* 3rd: kernel VM. */
name|va
operator|=
name|dump_map
index|[
literal|1
index|]
operator|.
name|pa_start
operator|+
name|dump_map
index|[
literal|1
index|]
operator|.
name|pa_size
expr_stmt|;
comment|/* Find start of next chunk (from va). */
while|while
condition|(
name|va
operator|<
name|virtual_end
condition|)
block|{
comment|/* Don't dump the buffer cache. */
if|if
condition|(
name|va
operator|>=
name|kmi
operator|.
name|buffer_sva
operator|&&
name|va
operator|<
name|kmi
operator|.
name|buffer_eva
condition|)
block|{
name|va
operator|=
name|kmi
operator|.
name|buffer_eva
expr_stmt|;
continue|continue;
block|}
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
operator|&&
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_DEAD
operator|)
condition|)
break|break;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
if|if
condition|(
name|va
operator|<
name|virtual_end
condition|)
block|{
name|dump_map
index|[
literal|2
index|]
operator|.
name|pa_start
operator|=
name|va
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
comment|/* Find last page in chunk. */
while|while
condition|(
name|va
operator|<
name|virtual_end
condition|)
block|{
comment|/* Don't run into the buffer cache. */
if|if
condition|(
name|va
operator|==
name|kmi
operator|.
name|buffer_sva
condition|)
break|break;
name|pvo
operator|=
name|moea64_pvo_find_va
argument_list|(
name|kernel_pmap
argument_list|,
name|va
operator|&
operator|~
name|ADDR_POFF
argument_list|)
expr_stmt|;
if|if
condition|(
name|pvo
operator|!=
name|NULL
operator|&&
operator|!
operator|(
name|pvo
operator|->
name|pvo_vaddr
operator|&
name|PVO_DEAD
operator|)
condition|)
break|break;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|dump_map
index|[
literal|2
index|]
operator|.
name|pa_size
operator|=
name|va
operator|-
name|dump_map
index|[
literal|2
index|]
operator|.
name|pa_start
expr_stmt|;
block|}
block|}
end_function

end_unit

