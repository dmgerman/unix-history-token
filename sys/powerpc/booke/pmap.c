begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (C) 2007-2009 Semihalf, Rafal Jaworowski<raj@semihalf.com>  * Copyright (C) 2006 Semihalf, Marian Balakowicz<m8@semihalf.com>  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN  * NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,  * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED  * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF  * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING  * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  *  * Some hw specific parts of this pmap were derived or influenced  * by NetBSD's ibm4xx pmap module. More generic code is shared with  * a few other pmap modules from the FreeBSD tree.  */
end_comment

begin_comment
comment|/*   * VM layout notes:   *   * Kernel and user threads run within one common virtual address space   * defined by AS=0.   *   * Virtual address space layout:   * -----------------------------   * 0x0000_0000 - 0xafff_ffff	: user process   * 0xb000_0000 - 0xbfff_ffff	: pmap_mapdev()-ed area (PCI/PCIE etc.)   * 0xc000_0000 - 0xc0ff_ffff	: kernel reserved   *   0xc000_0000 - data_end	: kernel code+data, env, metadata etc.   * 0xc100_0000 - 0xfeef_ffff	: KVA   *   0xc100_0000 - 0xc100_3fff : reserved for page zero/copy   *   0xc100_4000 - 0xc200_3fff : reserved for ptbl bufs   *   0xc200_4000 - 0xc200_8fff : guard page + kstack0   *   0xc200_9000 - 0xfeef_ffff	: actual free KVA space   * 0xfef0_0000 - 0xffff_ffff	: I/O devices region   */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|<sys/types.h>
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/user.h>
end_include

begin_include
include|#
directive|include
file|<sys/queue.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/msgbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/pcb.h>
end_include

begin_include
include|#
directive|include
file|<machine/platform.h>
end_include

begin_include
include|#
directive|include
file|<machine/tlb.h>
end_include

begin_include
include|#
directive|include
file|<machine/spr.h>
end_include

begin_include
include|#
directive|include
file|<machine/vmparam.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_include
include|#
directive|include
file|<machine/mmuvar.h>
end_include

begin_include
include|#
directive|include
file|<machine/pmap.h>
end_include

begin_include
include|#
directive|include
file|<machine/pte.h>
end_include

begin_include
include|#
directive|include
file|"mmu_if.h"
end_include

begin_define
define|#
directive|define
name|DEBUG
end_define

begin_undef
undef|#
directive|undef
name|DEBUG
end_undef

begin_ifdef
ifdef|#
directive|ifdef
name|DEBUG
end_ifdef

begin_define
define|#
directive|define
name|debugf
parameter_list|(
name|fmt
parameter_list|,
name|args
modifier|...
parameter_list|)
value|printf(fmt, ##args)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|debugf
parameter_list|(
name|fmt
parameter_list|,
name|args
modifier|...
parameter_list|)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|TODO
value|panic("%s: not implemented", __func__);
end_define

begin_include
include|#
directive|include
file|"opt_sched.h"
end_include

begin_ifndef
ifndef|#
directive|ifndef
name|SCHED_4BSD
end_ifndef

begin_error
error|#
directive|error
literal|"e500 only works with SCHED_4BSD which uses a global scheduler lock."
end_error

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|extern
name|struct
name|mtx
name|sched_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|int
name|dumpsys_minidump
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|unsigned
name|char
name|_etext
index|[]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|unsigned
name|char
name|_end
index|[]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Kernel physical load address. */
end_comment

begin_decl_stmt
specifier|extern
name|uint32_t
name|kernload
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|kernstart
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_size_t
name|kernsize
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Message buffer and tables. */
end_comment

begin_decl_stmt
specifier|static
name|vm_offset_t
name|data_start
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|vm_size_t
name|data_end
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Phys/avail memory regions. */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|mem_region
modifier|*
name|availmem_regions
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|availmem_regions_sz
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mem_region
modifier|*
name|physmem_regions
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|physmem_regions_sz
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Reserved KVA space and mutex for mmu_booke_zero_page. */
end_comment

begin_decl_stmt
specifier|static
name|vm_offset_t
name|zero_page_va
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|zero_page_mutex
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|tlbivax_mutex
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Reserved KVA space for mmu_booke_zero_page_idle. This is used  * by idle thred only, no lock required.  */
end_comment

begin_decl_stmt
specifier|static
name|vm_offset_t
name|zero_page_idle_va
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Reserved KVA space and mutex for mmu_booke_copy_page. */
end_comment

begin_decl_stmt
specifier|static
name|vm_offset_t
name|copy_page_src_va
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|vm_offset_t
name|copy_page_dst_va
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|copy_page_mutex
decl_stmt|;
end_decl_stmt

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/* PMAP */
end_comment

begin_comment
comment|/**************************************************************************/
end_comment

begin_function_decl
specifier|static
name|void
name|mmu_booke_enter_locked
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|,
name|boolean_t
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
name|unsigned
name|int
name|kptbl_min
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Index of the first kernel ptbl. */
end_comment

begin_decl_stmt
name|unsigned
name|int
name|kernel_ptbls
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Number of KVA ptbls. */
end_comment

begin_comment
comment|/*  * If user pmap is processed with mmu_booke_remove and the resident count  * drops to 0, there are no more pages to remove, so we need not continue.  */
end_comment

begin_define
define|#
directive|define
name|PMAP_REMOVE_DONE
parameter_list|(
name|pmap
parameter_list|)
define|\
value|((pmap) != kernel_pmap&& (pmap)->pm_stats.resident_count == 0)
end_define

begin_function_decl
specifier|extern
name|void
name|tid_flush
parameter_list|(
name|tlbtid_t
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/* TLB and TID handling */
end_comment

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/* Translation ID busy table */
end_comment

begin_decl_stmt
specifier|static
specifier|volatile
name|pmap_t
name|tidbusy
index|[
name|MAXCPU
index|]
index|[
name|TID_MAX
operator|+
literal|1
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * TLB0 capabilities (entry, way numbers etc.). These can vary between e500  * core revisions and should be read from h/w registers during early config.  */
end_comment

begin_decl_stmt
name|uint32_t
name|tlb0_entries
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint32_t
name|tlb0_ways
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|uint32_t
name|tlb0_entries_per_way
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|TLB0_ENTRIES
value|(tlb0_entries)
end_define

begin_define
define|#
directive|define
name|TLB0_WAYS
value|(tlb0_ways)
end_define

begin_define
define|#
directive|define
name|TLB0_ENTRIES_PER_WAY
value|(tlb0_entries_per_way)
end_define

begin_define
define|#
directive|define
name|TLB1_ENTRIES
value|16
end_define

begin_comment
comment|/* In-ram copy of the TLB1 */
end_comment

begin_decl_stmt
specifier|static
name|tlb_entry_t
name|tlb1
index|[
name|TLB1_ENTRIES
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Next free entry in the TLB1 */
end_comment

begin_decl_stmt
specifier|static
name|unsigned
name|int
name|tlb1_idx
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|tlbtid_t
name|tid_alloc
parameter_list|(
name|struct
name|pmap
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tlb_print_entry
parameter_list|(
name|int
parameter_list|,
name|uint32_t
parameter_list|,
name|uint32_t
parameter_list|,
name|uint32_t
parameter_list|,
name|uint32_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|tlb1_set_entry
parameter_list|(
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|,
name|uint32_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|tlb1_write_entry
parameter_list|(
name|unsigned
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|tlb1_iomapped
parameter_list|(
name|int
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|vm_size_t
parameter_list|,
name|vm_offset_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_size_t
name|tlb1_mapin_region
parameter_list|(
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_size_t
name|tsize2size
parameter_list|(
name|unsigned
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|unsigned
name|int
name|size2tsize
parameter_list|(
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|unsigned
name|int
name|ilog2
parameter_list|(
name|unsigned
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|set_mas4_defaults
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
specifier|inline
name|void
name|tlb0_flush_entry
parameter_list|(
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
specifier|inline
name|unsigned
name|int
name|tlb0_tableidx
parameter_list|(
name|vm_offset_t
parameter_list|,
name|unsigned
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/* Page table management */
end_comment

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/* Data for the pv entry allocation mechanism */
end_comment

begin_decl_stmt
specifier|static
name|uma_zone_t
name|pvzone
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|vm_object
name|pvzone_obj
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|pv_entry_count
init|=
literal|0
decl_stmt|,
name|pv_entry_max
init|=
literal|0
decl_stmt|,
name|pv_entry_high_water
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|PV_ENTRY_ZONE_MIN
value|2048
end_define

begin_comment
comment|/* min pv entries in uma zone */
end_comment

begin_ifndef
ifndef|#
directive|ifndef
name|PMAP_SHPGPERPROC
end_ifndef

begin_define
define|#
directive|define
name|PMAP_SHPGPERPROC
value|200
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_function_decl
specifier|static
name|void
name|ptbl_init
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|ptbl_buf
modifier|*
name|ptbl_buf_alloc
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|ptbl_buf_free
parameter_list|(
name|struct
name|ptbl_buf
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|ptbl_free_pmap_ptbl
parameter_list|(
name|pmap_t
parameter_list|,
name|pte_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|pte_t
modifier|*
name|ptbl_alloc
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|unsigned
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|ptbl_free
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|unsigned
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|ptbl_hold
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|unsigned
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|ptbl_unhold
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|unsigned
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_paddr_t
name|pte_vatopa
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|pte_t
modifier|*
name|pte_find
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pte_enter
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|uint32_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pte_remove
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|uint8_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|pv_entry_t
name|pv_alloc
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pv_free
parameter_list|(
name|pv_entry_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pv_insert
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pv_remove
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/* Number of kva ptbl buffers, each covering one ptbl (PTBL_PAGES). */
end_comment

begin_define
define|#
directive|define
name|PTBL_BUFS
value|(128 * 16)
end_define

begin_struct
struct|struct
name|ptbl_buf
block|{
name|TAILQ_ENTRY
argument_list|(
argument|ptbl_buf
argument_list|)
name|link
expr_stmt|;
comment|/* list link */
name|vm_offset_t
name|kva
decl_stmt|;
comment|/* va of mapping */
block|}
struct|;
end_struct

begin_comment
comment|/* ptbl free list and a lock used for access synchronization. */
end_comment

begin_expr_stmt
specifier|static
name|TAILQ_HEAD
argument_list|(
argument_list|,
argument|ptbl_buf
argument_list|)
name|ptbl_buf_freelist
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|ptbl_buf_freelist_lock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Base address of kva space allocated fot ptbl bufs. */
end_comment

begin_decl_stmt
specifier|static
name|vm_offset_t
name|ptbl_buf_pool_vabase
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Pointer to ptbl_buf structures. */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|ptbl_buf
modifier|*
name|ptbl_bufs
decl_stmt|;
end_decl_stmt

begin_function_decl
name|void
name|pmap_bootstrap_ap
parameter_list|(
specifier|volatile
name|uint32_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Kernel MMU interface  */
end_comment

begin_function_decl
specifier|static
name|void
name|mmu_booke_change_wiring
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|boolean_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_clear_modify
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_clear_reference
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_copy
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_copy_page
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_enter
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|,
name|boolean_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_enter_object
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_enter_quick
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_paddr_t
name|mmu_booke_extract
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|mmu_booke_extract_and_hold
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_init
parameter_list|(
name|mmu_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|mmu_booke_is_modified
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|mmu_booke_is_prefaultable
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|mmu_booke_is_referenced
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|mmu_booke_ts_referenced
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_offset_t
name|mmu_booke_map
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
modifier|*
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|mmu_booke_mincore
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_paddr_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_object_init_pt
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_object_t
parameter_list|,
name|vm_pindex_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|mmu_booke_page_exists_quick
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_page_init
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|mmu_booke_page_wired_mappings
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_pinit
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_pinit0
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_protect
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_prot_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_qenter
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_page_t
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_qremove
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_release
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_remove
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_remove_all
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_remove_write
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_zero_page
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_zero_page_area
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_zero_page_idle
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_activate
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_deactivate
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|thread
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_bootstrap
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
modifier|*
name|mmu_booke_mapdev
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_unmapdev
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_offset_t
name|mmu_booke_kextract
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_kenter
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_kremove
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|mmu_booke_dev_direct_mapped
parameter_list|(
name|mmu_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_sync_icache
parameter_list|(
name|mmu_t
parameter_list|,
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_offset_t
name|mmu_booke_dumpsys_map
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|pmap_md
modifier|*
parameter_list|,
name|vm_size_t
parameter_list|,
name|vm_size_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mmu_booke_dumpsys_unmap
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|pmap_md
modifier|*
parameter_list|,
name|vm_size_t
parameter_list|,
name|vm_offset_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|pmap_md
modifier|*
name|mmu_booke_scan_md
parameter_list|(
name|mmu_t
parameter_list|,
name|struct
name|pmap_md
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
specifier|static
name|mmu_method_t
name|mmu_booke_methods
index|[]
init|=
block|{
comment|/* pmap dispatcher interface */
name|MMUMETHOD
argument_list|(
name|mmu_change_wiring
argument_list|,
name|mmu_booke_change_wiring
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_clear_modify
argument_list|,
name|mmu_booke_clear_modify
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_clear_reference
argument_list|,
name|mmu_booke_clear_reference
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_copy
argument_list|,
name|mmu_booke_copy
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_copy_page
argument_list|,
name|mmu_booke_copy_page
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter
argument_list|,
name|mmu_booke_enter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter_object
argument_list|,
name|mmu_booke_enter_object
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_enter_quick
argument_list|,
name|mmu_booke_enter_quick
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_extract
argument_list|,
name|mmu_booke_extract
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_extract_and_hold
argument_list|,
name|mmu_booke_extract_and_hold
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_init
argument_list|,
name|mmu_booke_init
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_is_modified
argument_list|,
name|mmu_booke_is_modified
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_is_prefaultable
argument_list|,
name|mmu_booke_is_prefaultable
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_is_referenced
argument_list|,
name|mmu_booke_is_referenced
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_ts_referenced
argument_list|,
name|mmu_booke_ts_referenced
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_map
argument_list|,
name|mmu_booke_map
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_mincore
argument_list|,
name|mmu_booke_mincore
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_object_init_pt
argument_list|,
name|mmu_booke_object_init_pt
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_exists_quick
argument_list|,
name|mmu_booke_page_exists_quick
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_init
argument_list|,
name|mmu_booke_page_init
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_page_wired_mappings
argument_list|,
name|mmu_booke_page_wired_mappings
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_pinit
argument_list|,
name|mmu_booke_pinit
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_pinit0
argument_list|,
name|mmu_booke_pinit0
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_protect
argument_list|,
name|mmu_booke_protect
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_qenter
argument_list|,
name|mmu_booke_qenter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_qremove
argument_list|,
name|mmu_booke_qremove
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_release
argument_list|,
name|mmu_booke_release
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove
argument_list|,
name|mmu_booke_remove
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove_all
argument_list|,
name|mmu_booke_remove_all
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_remove_write
argument_list|,
name|mmu_booke_remove_write
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_sync_icache
argument_list|,
name|mmu_booke_sync_icache
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page
argument_list|,
name|mmu_booke_zero_page
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page_area
argument_list|,
name|mmu_booke_zero_page_area
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_zero_page_idle
argument_list|,
name|mmu_booke_zero_page_idle
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_activate
argument_list|,
name|mmu_booke_activate
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_deactivate
argument_list|,
name|mmu_booke_deactivate
argument_list|)
block|,
comment|/* Internal interfaces */
name|MMUMETHOD
argument_list|(
name|mmu_bootstrap
argument_list|,
name|mmu_booke_bootstrap
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_dev_direct_mapped
argument_list|,
name|mmu_booke_dev_direct_mapped
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_mapdev
argument_list|,
name|mmu_booke_mapdev
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_kenter
argument_list|,
name|mmu_booke_kenter
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_kextract
argument_list|,
name|mmu_booke_kextract
argument_list|)
block|,
comment|/*	MMUMETHOD(mmu_kremove,		mmu_booke_kremove),	*/
name|MMUMETHOD
argument_list|(
name|mmu_unmapdev
argument_list|,
name|mmu_booke_unmapdev
argument_list|)
block|,
comment|/* dumpsys() support */
name|MMUMETHOD
argument_list|(
name|mmu_dumpsys_map
argument_list|,
name|mmu_booke_dumpsys_map
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_dumpsys_unmap
argument_list|,
name|mmu_booke_dumpsys_unmap
argument_list|)
block|,
name|MMUMETHOD
argument_list|(
name|mmu_scan_md
argument_list|,
name|mmu_booke_scan_md
argument_list|)
block|,
block|{
literal|0
block|,
literal|0
block|}
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|MMU_DEF
argument_list|(
name|booke_mmu
argument_list|,
name|MMU_TYPE_BOOKE
argument_list|,
name|mmu_booke_methods
argument_list|,
literal|0
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
specifier|inline
name|void
name|tlb_miss_lock
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
if|if
condition|(
operator|!
name|smp_started
condition|)
return|return;
name|SLIST_FOREACH
argument_list|(
argument|pc
argument_list|,
argument|&cpuhead
argument_list|,
argument|pc_allcpu
argument_list|)
block|{
if|if
condition|(
name|pc
operator|!=
name|pcpup
condition|)
block|{
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: tlb miss LOCK of CPU=%d, "
literal|"tlb_lock=%p"
argument_list|,
name|__func__
argument_list|,
name|pc
operator|->
name|pc_cpuid
argument_list|,
name|pc
operator|->
name|pc_booke_tlb_lock
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pc
operator|->
name|pc_cpuid
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
operator|)
argument_list|,
operator|(
literal|"tlb_miss_lock: tried to lock self"
operator|)
argument_list|)
expr_stmt|;
name|tlb_lock
argument_list|(
name|pc
operator|->
name|pc_booke_tlb_lock
argument_list|)
expr_stmt|;
name|CTR1
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: locked"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
block|}
endif|#
directive|endif
block|}
end_function

begin_function
specifier|static
specifier|inline
name|void
name|tlb_miss_unlock
parameter_list|(
name|void
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|SMP
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
if|if
condition|(
operator|!
name|smp_started
condition|)
return|return;
name|SLIST_FOREACH
argument_list|(
argument|pc
argument_list|,
argument|&cpuhead
argument_list|,
argument|pc_allcpu
argument_list|)
block|{
if|if
condition|(
name|pc
operator|!=
name|pcpup
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: tlb miss UNLOCK of CPU=%d"
argument_list|,
name|__func__
argument_list|,
name|pc
operator|->
name|pc_cpuid
argument_list|)
expr_stmt|;
name|tlb_unlock
argument_list|(
name|pc
operator|->
name|pc_booke_tlb_lock
argument_list|)
expr_stmt|;
name|CTR1
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: unlocked"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
block|}
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/* Return number of entries in TLB0. */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|tlb0_get_tlbconf
parameter_list|(
name|void
parameter_list|)
block|{
name|uint32_t
name|tlb0_cfg
decl_stmt|;
name|tlb0_cfg
operator|=
name|mfspr
argument_list|(
name|SPR_TLB0CFG
argument_list|)
expr_stmt|;
name|tlb0_entries
operator|=
name|tlb0_cfg
operator|&
name|TLBCFG_NENTRY_MASK
expr_stmt|;
name|tlb0_ways
operator|=
operator|(
name|tlb0_cfg
operator|&
name|TLBCFG_ASSOC_MASK
operator|)
operator|>>
name|TLBCFG_ASSOC_SHIFT
expr_stmt|;
name|tlb0_entries_per_way
operator|=
name|tlb0_entries
operator|/
name|tlb0_ways
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Initialize pool of kva ptbl buffers. */
end_comment

begin_function
specifier|static
name|void
name|ptbl_init
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: s (ptbl_bufs = 0x%08x size 0x%08x)"
argument_list|,
name|__func__
argument_list|,
operator|(
name|uint32_t
operator|)
name|ptbl_bufs
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|ptbl_buf
argument_list|)
operator|*
name|PTBL_BUFS
argument_list|)
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: s (ptbl_buf_pool_vabase = 0x%08x size = 0x%08x)"
argument_list|,
name|__func__
argument_list|,
name|ptbl_buf_pool_vabase
argument_list|,
name|PTBL_BUFS
operator|*
name|PTBL_PAGES
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|ptbl_buf_freelist_lock
argument_list|,
literal|"ptbl bufs lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|ptbl_buf_freelist
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PTBL_BUFS
condition|;
name|i
operator|++
control|)
block|{
name|ptbl_bufs
index|[
name|i
index|]
operator|.
name|kva
operator|=
name|ptbl_buf_pool_vabase
operator|+
name|i
operator|*
name|PTBL_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|ptbl_buf_freelist
argument_list|,
operator|&
name|ptbl_bufs
index|[
name|i
index|]
argument_list|,
name|link
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/* Get a ptbl_buf from the freelist. */
end_comment

begin_function
specifier|static
name|struct
name|ptbl_buf
modifier|*
name|ptbl_buf_alloc
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|ptbl_buf
modifier|*
name|buf
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|ptbl_buf_freelist_lock
argument_list|)
expr_stmt|;
name|buf
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|ptbl_buf_freelist
argument_list|)
expr_stmt|;
if|if
condition|(
name|buf
operator|!=
name|NULL
condition|)
name|TAILQ_REMOVE
argument_list|(
operator|&
name|ptbl_buf_freelist
argument_list|,
name|buf
argument_list|,
name|link
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|ptbl_buf_freelist_lock
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: buf = %p"
argument_list|,
name|__func__
argument_list|,
name|buf
argument_list|)
expr_stmt|;
return|return
operator|(
name|buf
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Return ptbl buff to free pool. */
end_comment

begin_function
specifier|static
name|void
name|ptbl_buf_free
parameter_list|(
name|struct
name|ptbl_buf
modifier|*
name|buf
parameter_list|)
block|{
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: buf = %p"
argument_list|,
name|__func__
argument_list|,
name|buf
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|ptbl_buf_freelist_lock
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|ptbl_buf_freelist
argument_list|,
name|buf
argument_list|,
name|link
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|ptbl_buf_freelist_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Search the list of allocated ptbl bufs and find on list of allocated ptbls  */
end_comment

begin_function
specifier|static
name|void
name|ptbl_free_pmap_ptbl
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pte_t
modifier|*
name|ptbl
parameter_list|)
block|{
name|struct
name|ptbl_buf
modifier|*
name|pbuf
decl_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: ptbl = %p"
argument_list|,
name|__func__
argument_list|,
name|ptbl
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pbuf
argument_list|,
argument|&pmap->pm_ptbl_list
argument_list|,
argument|link
argument_list|)
if|if
condition|(
name|pbuf
operator|->
name|kva
operator|==
operator|(
name|vm_offset_t
operator|)
name|ptbl
condition|)
block|{
comment|/* Remove from pmap ptbl buf list. */
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_ptbl_list
argument_list|,
name|pbuf
argument_list|,
name|link
argument_list|)
expr_stmt|;
comment|/* Free corresponding ptbl buf. */
name|ptbl_buf_free
argument_list|(
name|pbuf
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
end_function

begin_comment
comment|/* Allocate page table. */
end_comment

begin_function
specifier|static
name|pte_t
modifier|*
name|ptbl_alloc
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|unsigned
name|int
name|pdir_idx
parameter_list|)
block|{
name|vm_page_t
name|mtbl
index|[
name|PTBL_PAGES
index|]
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|struct
name|ptbl_buf
modifier|*
name|pbuf
decl_stmt|;
name|unsigned
name|int
name|pidx
decl_stmt|;
name|pte_t
modifier|*
name|ptbl
decl_stmt|;
name|int
name|i
decl_stmt|;
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: pmap = %p su = %d pdir_idx = %d"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
operator|(
name|pmap
operator|==
name|kernel_pmap
operator|)
argument_list|,
name|pdir_idx
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pdir_idx
operator|<=
operator|(
name|VM_MAXUSER_ADDRESS
operator|/
name|PDIR_SIZE
operator|)
operator|)
argument_list|,
operator|(
literal|"ptbl_alloc: invalid pdir_idx"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
operator|==
name|NULL
operator|)
argument_list|,
operator|(
literal|"pte_alloc: valid ptbl entry exists!"
operator|)
argument_list|)
expr_stmt|;
name|pbuf
operator|=
name|ptbl_buf_alloc
argument_list|()
expr_stmt|;
if|if
condition|(
name|pbuf
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pte_alloc: couldn't alloc kernel virtual memory"
argument_list|)
expr_stmt|;
name|ptbl
operator|=
operator|(
name|pte_t
operator|*
operator|)
name|pbuf
operator|->
name|kva
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: ptbl kva = %p"
argument_list|,
name|__func__
argument_list|,
name|ptbl
argument_list|)
expr_stmt|;
comment|/* Allocate ptbl pages, this will sleep! */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PTBL_PAGES
condition|;
name|i
operator|++
control|)
block|{
name|pidx
operator|=
operator|(
name|PTBL_PAGES
operator|*
name|pdir_idx
operator|)
operator|+
name|i
expr_stmt|;
while|while
condition|(
operator|(
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|pidx
argument_list|,
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|mtbl
index|[
name|i
index|]
operator|=
name|m
expr_stmt|;
block|}
comment|/* Map allocated pages into kernel_pmap. */
name|mmu_booke_qenter
argument_list|(
name|mmu
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|ptbl
argument_list|,
name|mtbl
argument_list|,
name|PTBL_PAGES
argument_list|)
expr_stmt|;
comment|/* Zero whole ptbl. */
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|ptbl
argument_list|,
name|PTBL_PAGES
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
comment|/* Add pbuf to the pmap ptbl bufs list. */
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pmap
operator|->
name|pm_ptbl_list
argument_list|,
name|pbuf
argument_list|,
name|link
argument_list|)
expr_stmt|;
return|return
operator|(
name|ptbl
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Free ptbl pages and invalidate pdir entry. */
end_comment

begin_function
specifier|static
name|void
name|ptbl_free
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|unsigned
name|int
name|pdir_idx
parameter_list|)
block|{
name|pte_t
modifier|*
name|ptbl
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: pmap = %p su = %d pdir_idx = %d"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
operator|(
name|pmap
operator|==
name|kernel_pmap
operator|)
argument_list|,
name|pdir_idx
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pdir_idx
operator|<=
operator|(
name|VM_MAXUSER_ADDRESS
operator|/
name|PDIR_SIZE
operator|)
operator|)
argument_list|,
operator|(
literal|"ptbl_free: invalid pdir_idx"
operator|)
argument_list|)
expr_stmt|;
name|ptbl
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: ptbl = %p"
argument_list|,
name|__func__
argument_list|,
name|ptbl
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|ptbl
operator|!=
name|NULL
operator|)
argument_list|,
operator|(
literal|"ptbl_free: null ptbl"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Invalidate the pdir entry as soon as possible, so that other CPUs 	 * don't attempt to look up the page tables we are releasing. 	 */
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
operator|=
name|NULL
expr_stmt|;
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PTBL_PAGES
condition|;
name|i
operator|++
control|)
block|{
name|va
operator|=
operator|(
operator|(
name|vm_offset_t
operator|)
name|ptbl
operator|+
operator|(
name|i
operator|*
name|PAGE_SIZE
operator|)
operator|)
expr_stmt|;
name|pa
operator|=
name|pte_vatopa
argument_list|(
name|mmu
argument_list|,
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|vm_page_free_zero
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|mmu_booke_kremove
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
name|ptbl_free_pmap_ptbl
argument_list|(
name|pmap
argument_list|,
name|ptbl
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Decrement ptbl pages hold count and attempt to free ptbl pages.  * Called when removing pte entry from ptbl.  *  * Return 1 if ptbl pages were freed.  */
end_comment

begin_function
specifier|static
name|int
name|ptbl_unhold
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|unsigned
name|int
name|pdir_idx
parameter_list|)
block|{
name|pte_t
modifier|*
name|ptbl
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: pmap = %p su = %d pdir_idx = %d"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
operator|(
name|pmap
operator|==
name|kernel_pmap
operator|)
argument_list|,
name|pdir_idx
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pdir_idx
operator|<=
operator|(
name|VM_MAXUSER_ADDRESS
operator|/
name|PDIR_SIZE
operator|)
operator|)
argument_list|,
operator|(
literal|"ptbl_unhold: invalid pdir_idx"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pmap
operator|!=
name|kernel_pmap
operator|)
argument_list|,
operator|(
literal|"ptbl_unhold: unholding kernel ptbl!"
operator|)
argument_list|)
expr_stmt|;
name|ptbl
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
expr_stmt|;
comment|//debugf("ptbl_unhold: ptbl = 0x%08x\n", (u_int32_t)ptbl);
name|KASSERT
argument_list|(
operator|(
operator|(
name|vm_offset_t
operator|)
name|ptbl
operator|>=
name|VM_MIN_KERNEL_ADDRESS
operator|)
argument_list|,
operator|(
literal|"ptbl_unhold: non kva ptbl"
operator|)
argument_list|)
expr_stmt|;
comment|/* decrement hold count */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PTBL_PAGES
condition|;
name|i
operator|++
control|)
block|{
name|pa
operator|=
name|pte_vatopa
argument_list|(
name|mmu
argument_list|,
name|kernel_pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|ptbl
operator|+
operator|(
name|i
operator|*
name|PAGE_SIZE
operator|)
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|--
expr_stmt|;
block|}
comment|/* 	 * Free ptbl pages if there are no pte etries in this ptbl. 	 * wire_count has the same value for all ptbl pages, so check the last 	 * page. 	 */
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|ptbl_free
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|pdir_idx
argument_list|)
expr_stmt|;
comment|//debugf("ptbl_unhold: e (freed ptbl)\n");
return|return
operator|(
literal|1
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Increment hold count for ptbl pages. This routine is used when a new pte  * entry is being inserted into the ptbl.  */
end_comment

begin_function
specifier|static
name|void
name|ptbl_hold
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|unsigned
name|int
name|pdir_idx
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|pte_t
modifier|*
name|ptbl
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: pmap = %p pdir_idx = %d"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|pdir_idx
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pdir_idx
operator|<=
operator|(
name|VM_MAXUSER_ADDRESS
operator|/
name|PDIR_SIZE
operator|)
operator|)
argument_list|,
operator|(
literal|"ptbl_hold: invalid pdir_idx"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pmap
operator|!=
name|kernel_pmap
operator|)
argument_list|,
operator|(
literal|"ptbl_hold: holding kernel ptbl!"
operator|)
argument_list|)
expr_stmt|;
name|ptbl
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|ptbl
operator|!=
name|NULL
operator|)
argument_list|,
operator|(
literal|"ptbl_hold: null ptbl"
operator|)
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PTBL_PAGES
condition|;
name|i
operator|++
control|)
block|{
name|pa
operator|=
name|pte_vatopa
argument_list|(
name|mmu
argument_list|,
name|kernel_pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|ptbl
operator|+
operator|(
name|i
operator|*
name|PAGE_SIZE
operator|)
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/* Allocate pv_entry structure. */
end_comment

begin_function
name|pv_entry_t
name|pv_alloc
parameter_list|(
name|void
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pv_entry_count
operator|++
expr_stmt|;
if|if
condition|(
name|pv_entry_count
operator|>
name|pv_entry_high_water
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
name|pv
operator|=
name|uma_zalloc
argument_list|(
name|pvzone
argument_list|,
name|M_NOWAIT
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Free pv_entry structure. */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pv_free
parameter_list|(
name|pv_entry_t
name|pve
parameter_list|)
block|{
name|pv_entry_count
operator|--
expr_stmt|;
name|uma_zfree
argument_list|(
name|pvzone
argument_list|,
name|pve
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Allocate and initialize pv_entry structure. */
end_comment

begin_function
specifier|static
name|void
name|pv_insert
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pve
decl_stmt|;
comment|//int su = (pmap == kernel_pmap);
comment|//debugf("pv_insert: s (su = %d pmap = 0x%08x va = 0x%08x m = 0x%08x)\n", su,
comment|//	(u_int32_t)pmap, va, (u_int32_t)m);
name|pve
operator|=
name|pv_alloc
argument_list|()
expr_stmt|;
if|if
condition|(
name|pve
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pv_insert: no pv entries!"
argument_list|)
expr_stmt|;
name|pve
operator|->
name|pv_pmap
operator|=
name|pmap
expr_stmt|;
name|pve
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
comment|/* add to pv_list */
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pve
argument_list|,
name|pv_link
argument_list|)
expr_stmt|;
comment|//debugf("pv_insert: e\n");
block|}
end_function

begin_comment
comment|/* Destroy pv entry. */
end_comment

begin_function
specifier|static
name|void
name|pv_remove
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pve
decl_stmt|;
comment|//int su = (pmap == kernel_pmap);
comment|//debugf("pv_remove: s (su = %d pmap = 0x%08x va = 0x%08x)\n", su, (u_int32_t)pmap, va);
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* find pv entry */
name|TAILQ_FOREACH
argument_list|(
argument|pve
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_link
argument_list|)
block|{
if|if
condition|(
operator|(
name|pmap
operator|==
name|pve
operator|->
name|pv_pmap
operator|)
operator|&&
operator|(
name|va
operator|==
name|pve
operator|->
name|pv_va
operator|)
condition|)
block|{
comment|/* remove from pv_list */
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pve
argument_list|,
name|pv_link
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
condition|)
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WRITEABLE
argument_list|)
expr_stmt|;
comment|/* free pv entry struct */
name|pv_free
argument_list|(
name|pve
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
comment|//debugf("pv_remove: e\n");
block|}
end_function

begin_comment
comment|/*  * Clean pte entry, try to free page table page if requested.  *  * Return 1 if ptbl pages were freed, otherwise return 0.  */
end_comment

begin_function
specifier|static
name|int
name|pte_remove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|uint8_t
name|flags
parameter_list|)
block|{
name|unsigned
name|int
name|pdir_idx
init|=
name|PDIR_IDX
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|unsigned
name|int
name|ptbl_idx
init|=
name|PTBL_IDX
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|pte_t
modifier|*
name|ptbl
decl_stmt|;
name|pte_t
modifier|*
name|pte
decl_stmt|;
comment|//int su = (pmap == kernel_pmap);
comment|//debugf("pte_remove: s (su = %d pmap = 0x%08x va = 0x%08x flags = %d)\n",
comment|//		su, (u_int32_t)pmap, va, flags);
name|ptbl
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
expr_stmt|;
name|KASSERT
argument_list|(
name|ptbl
argument_list|,
operator|(
literal|"pte_remove: null ptbl"
operator|)
argument_list|)
expr_stmt|;
name|pte
operator|=
operator|&
name|ptbl
index|[
name|ptbl_idx
index|]
expr_stmt|;
if|if
condition|(
name|pte
operator|==
name|NULL
operator|||
operator|!
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|if
condition|(
name|PTE_ISWIRED
argument_list|(
name|pte
argument_list|)
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
comment|/* Handle managed entry. */
if|if
condition|(
name|PTE_ISMANAGED
argument_list|(
name|pte
argument_list|)
condition|)
block|{
comment|/* Get vm_page_t for mapped pte. */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|PTE_PA
argument_list|(
name|pte
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|PTE_ISMODIFIED
argument_list|(
name|pte
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|PTE_ISREFERENCED
argument_list|(
name|pte
argument_list|)
condition|)
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_REFERENCED
argument_list|)
expr_stmt|;
name|pv_remove
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
name|tlb0_flush_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte
operator|->
name|flags
operator|=
literal|0
expr_stmt|;
name|pte
operator|->
name|rpn
operator|=
literal|0
expr_stmt|;
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
if|if
condition|(
name|flags
operator|&
name|PTBL_UNHOLD
condition|)
block|{
comment|//debugf("pte_remove: e (unhold)\n");
return|return
operator|(
name|ptbl_unhold
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|pdir_idx
argument_list|)
operator|)
return|;
block|}
comment|//debugf("pte_remove: e\n");
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Insert PTE for a given page and virtual address.  */
end_comment

begin_function
specifier|static
name|void
name|pte_enter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|uint32_t
name|flags
parameter_list|)
block|{
name|unsigned
name|int
name|pdir_idx
init|=
name|PDIR_IDX
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|unsigned
name|int
name|ptbl_idx
init|=
name|PTBL_IDX
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|pte_t
modifier|*
name|ptbl
decl_stmt|,
modifier|*
name|pte
decl_stmt|;
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: su = %d pmap = %p va = %p"
argument_list|,
name|__func__
argument_list|,
name|pmap
operator|==
name|kernel_pmap
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* Get the page table pointer. */
name|ptbl
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
expr_stmt|;
if|if
condition|(
name|ptbl
operator|==
name|NULL
condition|)
block|{
comment|/* Allocate page table pages. */
name|ptbl
operator|=
name|ptbl_alloc
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|pdir_idx
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Check if there is valid mapping for requested 		 * va, if there is, remove it. 		 */
name|pte
operator|=
operator|&
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
index|[
name|ptbl_idx
index|]
expr_stmt|;
if|if
condition|(
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|pte_remove
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|,
name|PTBL_HOLD
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * pte is not used, increment hold count 			 * for ptbl pages. 			 */
if|if
condition|(
name|pmap
operator|!=
name|kernel_pmap
condition|)
name|ptbl_hold
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|pdir_idx
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 	 * Insert pv_entry into pv_list for mapped page if part of managed 	 * memory. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|flags
operator||=
name|PTE_MANAGED
expr_stmt|;
comment|/* Create and insert pv entry. */
name|pv_insert
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
block|}
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
name|tlb0_flush_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
operator|==
name|NULL
condition|)
block|{
comment|/* 		 * If we just allocated a new page table, hook it in 		 * the pdir. 		 */
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
operator|=
name|ptbl
expr_stmt|;
block|}
name|pte
operator|=
operator|&
operator|(
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
index|[
name|ptbl_idx
index|]
operator|)
expr_stmt|;
name|pte
operator|->
name|rpn
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator|&
operator|~
name|PTE_PA_MASK
expr_stmt|;
name|pte
operator|->
name|flags
operator||=
operator|(
name|PTE_VALID
operator||
name|flags
operator|)
expr_stmt|;
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Return the pa for the given pmap/va. */
end_comment

begin_function
specifier|static
name|vm_paddr_t
name|pte_vatopa
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|vm_paddr_t
name|pa
init|=
literal|0
decl_stmt|;
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|!=
name|NULL
operator|)
operator|&&
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
name|pa
operator|=
operator|(
name|PTE_PA
argument_list|(
name|pte
argument_list|)
operator||
operator|(
name|va
operator|&
name|PTE_PA_MASK
operator|)
operator|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Get a pointer to a PTE in a page table. */
end_comment

begin_function
specifier|static
name|pte_t
modifier|*
name|pte_find
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|unsigned
name|int
name|pdir_idx
init|=
name|PDIR_IDX
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|unsigned
name|int
name|ptbl_idx
init|=
name|PTBL_IDX
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pmap
operator|!=
name|NULL
operator|)
argument_list|,
operator|(
literal|"pte_find: invalid pmap"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
condition|)
return|return
operator|(
operator|&
operator|(
name|pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
index|[
name|ptbl_idx
index|]
operator|)
operator|)
return|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/* PMAP related */
end_comment

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/*  * This is called during e500_init, before the system is really initialized.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_bootstrap
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|start
parameter_list|,
name|vm_offset_t
name|kernelend
parameter_list|)
block|{
name|vm_offset_t
name|phys_kernelend
decl_stmt|;
name|struct
name|mem_region
modifier|*
name|mp
decl_stmt|,
modifier|*
name|mp1
decl_stmt|;
name|int
name|cnt
decl_stmt|,
name|i
decl_stmt|,
name|j
decl_stmt|;
name|u_int
name|s
decl_stmt|,
name|e
decl_stmt|,
name|sz
decl_stmt|;
name|u_int
name|phys_avail_count
decl_stmt|;
name|vm_size_t
name|physsz
decl_stmt|,
name|hwphyssz
decl_stmt|,
name|kstack0_sz
decl_stmt|;
name|vm_offset_t
name|kernel_pdir
decl_stmt|,
name|kstack0
decl_stmt|,
name|va
decl_stmt|;
name|vm_paddr_t
name|kstack0_phys
decl_stmt|;
name|void
modifier|*
name|dpcpu
decl_stmt|;
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|debugf
argument_list|(
literal|"mmu_booke_bootstrap: entered\n"
argument_list|)
expr_stmt|;
comment|/* Initialize invalidation mutex */
name|mtx_init
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|,
literal|"tlbivax"
argument_list|,
name|NULL
argument_list|,
name|MTX_SPIN
argument_list|)
expr_stmt|;
comment|/* Read TLB0 size and associativity. */
name|tlb0_get_tlbconf
argument_list|()
expr_stmt|;
comment|/* Align kernel start and end address (kernel image). */
name|kernstart
operator|=
name|trunc_page
argument_list|(
name|start
argument_list|)
expr_stmt|;
name|data_start
operator|=
name|round_page
argument_list|(
name|kernelend
argument_list|)
expr_stmt|;
name|kernsize
operator|=
name|data_start
operator|-
name|kernstart
expr_stmt|;
name|data_end
operator|=
name|data_start
expr_stmt|;
comment|/* Allocate space for the message buffer. */
name|msgbufp
operator|=
operator|(
expr|struct
name|msgbuf
operator|*
operator|)
name|data_end
expr_stmt|;
name|data_end
operator|+=
name|MSGBUF_SIZE
expr_stmt|;
name|debugf
argument_list|(
literal|" msgbufp at 0x%08x end = 0x%08x\n"
argument_list|,
operator|(
name|uint32_t
operator|)
name|msgbufp
argument_list|,
name|data_end
argument_list|)
expr_stmt|;
name|data_end
operator|=
name|round_page
argument_list|(
name|data_end
argument_list|)
expr_stmt|;
comment|/* Allocate the dynamic per-cpu area. */
name|dpcpu
operator|=
operator|(
name|void
operator|*
operator|)
name|data_end
expr_stmt|;
name|data_end
operator|+=
name|DPCPU_SIZE
expr_stmt|;
name|dpcpu_init
argument_list|(
name|dpcpu
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* Allocate space for ptbl_bufs. */
name|ptbl_bufs
operator|=
operator|(
expr|struct
name|ptbl_buf
operator|*
operator|)
name|data_end
expr_stmt|;
name|data_end
operator|+=
sizeof|sizeof
argument_list|(
expr|struct
name|ptbl_buf
argument_list|)
operator|*
name|PTBL_BUFS
expr_stmt|;
name|debugf
argument_list|(
literal|" ptbl_bufs at 0x%08x end = 0x%08x\n"
argument_list|,
operator|(
name|uint32_t
operator|)
name|ptbl_bufs
argument_list|,
name|data_end
argument_list|)
expr_stmt|;
name|data_end
operator|=
name|round_page
argument_list|(
name|data_end
argument_list|)
expr_stmt|;
comment|/* Allocate PTE tables for kernel KVA. */
name|kernel_pdir
operator|=
name|data_end
expr_stmt|;
name|kernel_ptbls
operator|=
operator|(
name|VM_MAX_KERNEL_ADDRESS
operator|-
name|VM_MIN_KERNEL_ADDRESS
operator|+
name|PDIR_SIZE
operator|-
literal|1
operator|)
operator|/
name|PDIR_SIZE
expr_stmt|;
name|data_end
operator|+=
name|kernel_ptbls
operator|*
name|PTBL_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
name|debugf
argument_list|(
literal|" kernel ptbls: %d\n"
argument_list|,
name|kernel_ptbls
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|" kernel pdir at 0x%08x end = 0x%08x\n"
argument_list|,
name|kernel_pdir
argument_list|,
name|data_end
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|" data_end: 0x%08x\n"
argument_list|,
name|data_end
argument_list|)
expr_stmt|;
if|if
condition|(
name|data_end
operator|-
name|kernstart
operator|>
literal|0x1000000
condition|)
block|{
name|data_end
operator|=
operator|(
name|data_end
operator|+
literal|0x3fffff
operator|)
operator|&
operator|~
literal|0x3fffff
expr_stmt|;
name|tlb1_mapin_region
argument_list|(
name|kernstart
operator|+
literal|0x1000000
argument_list|,
name|kernload
operator|+
literal|0x1000000
argument_list|,
name|data_end
operator|-
name|kernstart
operator|-
literal|0x1000000
argument_list|)
expr_stmt|;
block|}
else|else
name|data_end
operator|=
operator|(
name|data_end
operator|+
literal|0xffffff
operator|)
operator|&
operator|~
literal|0xffffff
expr_stmt|;
name|debugf
argument_list|(
literal|" updated data_end: 0x%08x\n"
argument_list|,
name|data_end
argument_list|)
expr_stmt|;
name|kernsize
operator|+=
name|data_end
operator|-
name|data_start
expr_stmt|;
comment|/* 	 * Clear the structures - note we can only do it safely after the 	 * possible additional TLB1 translations are in place (above) so that 	 * all range up to the currently calculated 'data_end' is covered. 	 */
name|memset
argument_list|(
operator|(
name|void
operator|*
operator|)
name|ptbl_bufs
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|ptbl_buf
argument_list|)
operator|*
name|PTBL_SIZE
argument_list|)
expr_stmt|;
name|memset
argument_list|(
operator|(
name|void
operator|*
operator|)
name|kernel_pdir
argument_list|,
literal|0
argument_list|,
name|kernel_ptbls
operator|*
name|PTBL_PAGES
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
comment|/*******************************************************/
comment|/* Set the start and end of kva. */
comment|/*******************************************************/
name|virtual_avail
operator|=
name|round_page
argument_list|(
name|data_end
argument_list|)
expr_stmt|;
name|virtual_end
operator|=
name|VM_MAX_KERNEL_ADDRESS
expr_stmt|;
comment|/* Allocate KVA space for page zero/copy operations. */
name|zero_page_va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|zero_page_idle_va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|copy_page_src_va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|copy_page_dst_va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|debugf
argument_list|(
literal|"zero_page_va = 0x%08x\n"
argument_list|,
name|zero_page_va
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"zero_page_idle_va = 0x%08x\n"
argument_list|,
name|zero_page_idle_va
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"copy_page_src_va = 0x%08x\n"
argument_list|,
name|copy_page_src_va
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"copy_page_dst_va = 0x%08x\n"
argument_list|,
name|copy_page_dst_va
argument_list|)
expr_stmt|;
comment|/* Initialize page zero/copy mutexes. */
name|mtx_init
argument_list|(
operator|&
name|zero_page_mutex
argument_list|,
literal|"mmu_booke_zero_page"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|copy_page_mutex
argument_list|,
literal|"mmu_booke_copy_page"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* Allocate KVA space for ptbl bufs. */
name|ptbl_buf_pool_vabase
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|PTBL_BUFS
operator|*
name|PTBL_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
name|debugf
argument_list|(
literal|"ptbl_buf_pool_vabase = 0x%08x end = 0x%08x\n"
argument_list|,
name|ptbl_buf_pool_vabase
argument_list|,
name|virtual_avail
argument_list|)
expr_stmt|;
comment|/* Calculate corresponding physical addresses for the kernel region. */
name|phys_kernelend
operator|=
name|kernload
operator|+
name|kernsize
expr_stmt|;
name|debugf
argument_list|(
literal|"kernel image and allocated data:\n"
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|" kernload    = 0x%08x\n"
argument_list|,
name|kernload
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|" kernstart   = 0x%08x\n"
argument_list|,
name|kernstart
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|" kernsize    = 0x%08x\n"
argument_list|,
name|kernsize
argument_list|)
expr_stmt|;
if|if
condition|(
sizeof|sizeof
argument_list|(
name|phys_avail
argument_list|)
operator|/
sizeof|sizeof
argument_list|(
name|phys_avail
index|[
literal|0
index|]
argument_list|)
operator|<
name|availmem_regions_sz
condition|)
name|panic
argument_list|(
literal|"mmu_booke_bootstrap: phys_avail too small"
argument_list|)
expr_stmt|;
comment|/* 	 * Remove kernel physical address range from avail regions list. Page 	 * align all regions.  Non-page aligned memory isn't very interesting 	 * to us.  Also, sort the entries for ascending addresses. 	 */
comment|/* Retrieve phys/avail mem regions */
name|mem_regions
argument_list|(
operator|&
name|physmem_regions
argument_list|,
operator|&
name|physmem_regions_sz
argument_list|,
operator|&
name|availmem_regions
argument_list|,
operator|&
name|availmem_regions_sz
argument_list|)
expr_stmt|;
name|sz
operator|=
literal|0
expr_stmt|;
name|cnt
operator|=
name|availmem_regions_sz
expr_stmt|;
name|debugf
argument_list|(
literal|"processing avail regions:\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|mp
operator|=
name|availmem_regions
init|;
name|mp
operator|->
name|mr_size
condition|;
name|mp
operator|++
control|)
block|{
name|s
operator|=
name|mp
operator|->
name|mr_start
expr_stmt|;
name|e
operator|=
name|mp
operator|->
name|mr_start
operator|+
name|mp
operator|->
name|mr_size
expr_stmt|;
name|debugf
argument_list|(
literal|" %08x-%08x -> "
argument_list|,
name|s
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|/* Check whether this region holds all of the kernel. */
if|if
condition|(
name|s
operator|<
name|kernload
operator|&&
name|e
operator|>
name|phys_kernelend
condition|)
block|{
name|availmem_regions
index|[
name|cnt
index|]
operator|.
name|mr_start
operator|=
name|phys_kernelend
expr_stmt|;
name|availmem_regions
index|[
name|cnt
operator|++
index|]
operator|.
name|mr_size
operator|=
name|e
operator|-
name|phys_kernelend
expr_stmt|;
name|e
operator|=
name|kernload
expr_stmt|;
block|}
comment|/* Look whether this regions starts within the kernel. */
if|if
condition|(
name|s
operator|>=
name|kernload
operator|&&
name|s
operator|<
name|phys_kernelend
condition|)
block|{
if|if
condition|(
name|e
operator|<=
name|phys_kernelend
condition|)
goto|goto
name|empty
goto|;
name|s
operator|=
name|phys_kernelend
expr_stmt|;
block|}
comment|/* Now look whether this region ends within the kernel. */
if|if
condition|(
name|e
operator|>
name|kernload
operator|&&
name|e
operator|<=
name|phys_kernelend
condition|)
block|{
if|if
condition|(
name|s
operator|>=
name|kernload
condition|)
goto|goto
name|empty
goto|;
name|e
operator|=
name|kernload
expr_stmt|;
block|}
comment|/* Now page align the start and size of the region. */
name|s
operator|=
name|round_page
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|e
operator|=
name|trunc_page
argument_list|(
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|e
operator|<
name|s
condition|)
name|e
operator|=
name|s
expr_stmt|;
name|sz
operator|=
name|e
operator|-
name|s
expr_stmt|;
name|debugf
argument_list|(
literal|"%08x-%08x = %x\n"
argument_list|,
name|s
argument_list|,
name|e
argument_list|,
name|sz
argument_list|)
expr_stmt|;
comment|/* Check whether some memory is left here. */
if|if
condition|(
name|sz
operator|==
literal|0
condition|)
block|{
name|empty
label|:
name|memmove
argument_list|(
name|mp
argument_list|,
name|mp
operator|+
literal|1
argument_list|,
operator|(
name|cnt
operator|-
operator|(
name|mp
operator|-
name|availmem_regions
operator|)
operator|)
operator|*
sizeof|sizeof
argument_list|(
operator|*
name|mp
argument_list|)
argument_list|)
expr_stmt|;
name|cnt
operator|--
expr_stmt|;
name|mp
operator|--
expr_stmt|;
continue|continue;
block|}
comment|/* Do an insertion sort. */
for|for
control|(
name|mp1
operator|=
name|availmem_regions
init|;
name|mp1
operator|<
name|mp
condition|;
name|mp1
operator|++
control|)
if|if
condition|(
name|s
operator|<
name|mp1
operator|->
name|mr_start
condition|)
break|break;
if|if
condition|(
name|mp1
operator|<
name|mp
condition|)
block|{
name|memmove
argument_list|(
name|mp1
operator|+
literal|1
argument_list|,
name|mp1
argument_list|,
operator|(
name|char
operator|*
operator|)
name|mp
operator|-
operator|(
name|char
operator|*
operator|)
name|mp1
argument_list|)
expr_stmt|;
name|mp1
operator|->
name|mr_start
operator|=
name|s
expr_stmt|;
name|mp1
operator|->
name|mr_size
operator|=
name|sz
expr_stmt|;
block|}
else|else
block|{
name|mp
operator|->
name|mr_start
operator|=
name|s
expr_stmt|;
name|mp
operator|->
name|mr_size
operator|=
name|sz
expr_stmt|;
block|}
block|}
name|availmem_regions_sz
operator|=
name|cnt
expr_stmt|;
comment|/*******************************************************/
comment|/* Steal physical memory for kernel stack from the end */
comment|/* of the first avail region                           */
comment|/*******************************************************/
name|kstack0_sz
operator|=
name|KSTACK_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
name|kstack0_phys
operator|=
name|availmem_regions
index|[
literal|0
index|]
operator|.
name|mr_start
operator|+
name|availmem_regions
index|[
literal|0
index|]
operator|.
name|mr_size
expr_stmt|;
name|kstack0_phys
operator|-=
name|kstack0_sz
expr_stmt|;
name|availmem_regions
index|[
literal|0
index|]
operator|.
name|mr_size
operator|-=
name|kstack0_sz
expr_stmt|;
comment|/*******************************************************/
comment|/* Fill in phys_avail table, based on availmem_regions */
comment|/*******************************************************/
name|phys_avail_count
operator|=
literal|0
expr_stmt|;
name|physsz
operator|=
literal|0
expr_stmt|;
name|hwphyssz
operator|=
literal|0
expr_stmt|;
name|TUNABLE_ULONG_FETCH
argument_list|(
literal|"hw.physmem"
argument_list|,
operator|(
name|u_long
operator|*
operator|)
operator|&
name|hwphyssz
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"fill in phys_avail:\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
operator|,
name|j
operator|=
literal|0
init|;
name|i
operator|<
name|availmem_regions_sz
condition|;
name|i
operator|++
operator|,
name|j
operator|+=
literal|2
control|)
block|{
name|debugf
argument_list|(
literal|" region: 0x%08x - 0x%08x (0x%08x)\n"
argument_list|,
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_start
argument_list|,
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_size
argument_list|,
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_size
argument_list|)
expr_stmt|;
if|if
condition|(
name|hwphyssz
operator|!=
literal|0
operator|&&
operator|(
name|physsz
operator|+
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_size
operator|)
operator|>=
name|hwphyssz
condition|)
block|{
name|debugf
argument_list|(
literal|" hw.physmem adjust\n"
argument_list|)
expr_stmt|;
if|if
condition|(
name|physsz
operator|<
name|hwphyssz
condition|)
block|{
name|phys_avail
index|[
name|j
index|]
operator|=
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_start
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|hwphyssz
operator|-
name|physsz
expr_stmt|;
name|physsz
operator|=
name|hwphyssz
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
block|}
break|break;
block|}
name|phys_avail
index|[
name|j
index|]
operator|=
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_start
expr_stmt|;
name|phys_avail
index|[
name|j
operator|+
literal|1
index|]
operator|=
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_start
operator|+
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_size
expr_stmt|;
name|phys_avail_count
operator|++
expr_stmt|;
name|physsz
operator|+=
name|availmem_regions
index|[
name|i
index|]
operator|.
name|mr_size
expr_stmt|;
block|}
name|physmem
operator|=
name|btoc
argument_list|(
name|physsz
argument_list|)
expr_stmt|;
comment|/* Calculate the last available physical address. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|2
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
empty_stmt|;
name|Maxmem
operator|=
name|powerpc_btop
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"Maxmem = 0x%08lx\n"
argument_list|,
name|Maxmem
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"phys_avail_count = %d\n"
argument_list|,
name|phys_avail_count
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"physsz = 0x%08x physmem = %ld (0x%08lx)\n"
argument_list|,
name|physsz
argument_list|,
name|physmem
argument_list|,
name|physmem
argument_list|)
expr_stmt|;
comment|/*******************************************************/
comment|/* Initialize (statically allocated) kernel pmap. */
comment|/*******************************************************/
name|PMAP_LOCK_INIT
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|kptbl_min
operator|=
name|VM_MIN_KERNEL_ADDRESS
operator|/
name|PDIR_SIZE
expr_stmt|;
name|debugf
argument_list|(
literal|"kernel_pmap = 0x%08x\n"
argument_list|,
operator|(
name|uint32_t
operator|)
name|kernel_pmap
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"kptbl_min = %d, kernel_ptbls = %d\n"
argument_list|,
name|kptbl_min
argument_list|,
name|kernel_ptbls
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"kernel pdir range: 0x%08x - 0x%08x\n"
argument_list|,
name|kptbl_min
operator|*
name|PDIR_SIZE
argument_list|,
operator|(
name|kptbl_min
operator|+
name|kernel_ptbls
operator|)
operator|*
name|PDIR_SIZE
operator|-
literal|1
argument_list|)
expr_stmt|;
comment|/* Initialize kernel pdir */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|kernel_ptbls
condition|;
name|i
operator|++
control|)
name|kernel_pmap
operator|->
name|pm_pdir
index|[
name|kptbl_min
operator|+
name|i
index|]
operator|=
operator|(
name|pte_t
operator|*
operator|)
operator|(
name|kernel_pdir
operator|+
operator|(
name|i
operator|*
name|PAGE_SIZE
operator|*
name|PTBL_PAGES
operator|)
operator|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
name|i
operator|++
control|)
block|{
name|kernel_pmap
operator|->
name|pm_tid
index|[
name|i
index|]
operator|=
name|TID_KERNEL
expr_stmt|;
comment|/* Initialize each CPU's tidbusy entry 0 with kernel_pmap */
name|tidbusy
index|[
name|i
index|]
index|[
literal|0
index|]
operator|=
name|kernel_pmap
expr_stmt|;
block|}
comment|/* 	 * Fill in PTEs covering kernel code and data. They are not required 	 * for address translation, as this area is covered by static TLB1 	 * entries, but for pte_vatopa() to work correctly with kernel area 	 * addresses. 	 */
for|for
control|(
name|va
operator|=
name|KERNBASE
init|;
name|va
operator|<
name|data_end
condition|;
name|va
operator|+=
name|PAGE_SIZE
control|)
block|{
name|pte
operator|=
operator|&
operator|(
name|kernel_pmap
operator|->
name|pm_pdir
index|[
name|PDIR_IDX
argument_list|(
name|va
argument_list|)
index|]
index|[
name|PTBL_IDX
argument_list|(
name|va
argument_list|)
index|]
operator|)
expr_stmt|;
name|pte
operator|->
name|rpn
operator|=
name|kernload
operator|+
operator|(
name|va
operator|-
name|KERNBASE
operator|)
expr_stmt|;
name|pte
operator|->
name|flags
operator|=
name|PTE_M
operator||
name|PTE_SR
operator||
name|PTE_SW
operator||
name|PTE_SX
operator||
name|PTE_WIRED
operator||
name|PTE_VALID
expr_stmt|;
block|}
comment|/* Mark kernel_pmap active on all CPUs */
name|kernel_pmap
operator|->
name|pm_active
operator|=
operator|~
literal|0
expr_stmt|;
comment|/*******************************************************/
comment|/* Final setup */
comment|/*******************************************************/
comment|/* Enter kstack0 into kernel map, provide guard page */
name|kstack0
operator|=
name|virtual_avail
operator|+
name|KSTACK_GUARD_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
name|thread0
operator|.
name|td_kstack
operator|=
name|kstack0
expr_stmt|;
name|thread0
operator|.
name|td_kstack_pages
operator|=
name|KSTACK_PAGES
expr_stmt|;
name|debugf
argument_list|(
literal|"kstack_sz = 0x%08x\n"
argument_list|,
name|kstack0_sz
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"kstack0_phys at 0x%08x - 0x%08x\n"
argument_list|,
name|kstack0_phys
argument_list|,
name|kstack0_phys
operator|+
name|kstack0_sz
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"kstack0 at 0x%08x - 0x%08x\n"
argument_list|,
name|kstack0
argument_list|,
name|kstack0
operator|+
name|kstack0_sz
argument_list|)
expr_stmt|;
name|virtual_avail
operator|+=
name|KSTACK_GUARD_PAGES
operator|*
name|PAGE_SIZE
operator|+
name|kstack0_sz
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|KSTACK_PAGES
condition|;
name|i
operator|++
control|)
block|{
name|mmu_booke_kenter
argument_list|(
name|mmu
argument_list|,
name|kstack0
argument_list|,
name|kstack0_phys
argument_list|)
expr_stmt|;
name|kstack0
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|kstack0_phys
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|debugf
argument_list|(
literal|"virtual_avail = %08x\n"
argument_list|,
name|virtual_avail
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"virtual_end   = %08x\n"
argument_list|,
name|virtual_end
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"mmu_booke_bootstrap: exit\n"
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_bootstrap_ap
parameter_list|(
specifier|volatile
name|uint32_t
modifier|*
name|trcp
name|__unused
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
comment|/* 	 * Finish TLB1 configuration: the BSP already set up its TLB1 and we 	 * have the snapshot of its contents in the s/w tlb1[] table, so use 	 * these values directly to (re)program AP's TLB1 hardware. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|tlb1_idx
condition|;
name|i
operator|++
control|)
block|{
comment|/* Skip invalid entries */
if|if
condition|(
operator|!
operator|(
name|tlb1
index|[
name|i
index|]
operator|.
name|mas1
operator|&
name|MAS1_VALID
operator|)
condition|)
continue|continue;
name|tlb1_write_entry
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
name|set_mas4_defaults
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Get the physical page address for the given pmap/virtual address.  */
end_comment

begin_function
specifier|static
name|vm_paddr_t
name|mmu_booke_extract
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pa
operator|=
name|pte_vatopa
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|pa
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Extract the physical page address associated with the given  * kernel virtual address.  */
end_comment

begin_function
specifier|static
name|vm_paddr_t
name|mmu_booke_kextract
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
return|return
operator|(
name|pte_vatopa
argument_list|(
name|mmu
argument_list|,
name|kernel_pmap
argument_list|,
name|va
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Initialize the pmap module.  * Called by vm_init, to initialize any structures that the pmap  * system needs to map virtual memory.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_init
parameter_list|(
name|mmu_t
name|mmu
parameter_list|)
block|{
name|int
name|shpgperproc
init|=
name|PMAP_SHPGPERPROC
decl_stmt|;
comment|/* 	 * Initialize the address space (zone) for the pv entries.  Set a 	 * high water mark so that the system can recover from excessive 	 * numbers of pv entries. 	 */
name|pvzone
operator|=
name|uma_zcreate
argument_list|(
literal|"PV ENTRY"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|pv_entry
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|UMA_ALIGN_PTR
argument_list|,
name|UMA_ZONE_VM
operator||
name|UMA_ZONE_NOFREE
argument_list|)
expr_stmt|;
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.pmap.shpgperproc"
argument_list|,
operator|&
name|shpgperproc
argument_list|)
expr_stmt|;
name|pv_entry_max
operator|=
name|shpgperproc
operator|*
name|maxproc
operator|+
name|cnt
operator|.
name|v_page_count
expr_stmt|;
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.pmap.pv_entries"
argument_list|,
operator|&
name|pv_entry_max
argument_list|)
expr_stmt|;
name|pv_entry_high_water
operator|=
literal|9
operator|*
operator|(
name|pv_entry_max
operator|/
literal|10
operator|)
expr_stmt|;
name|uma_zone_set_obj
argument_list|(
name|pvzone
argument_list|,
operator|&
name|pvzone_obj
argument_list|,
name|pv_entry_max
argument_list|)
expr_stmt|;
comment|/* Pre-fill pvzone with initial number of pv entries. */
name|uma_prealloc
argument_list|(
name|pvzone
argument_list|,
name|PV_ENTRY_ZONE_MIN
argument_list|)
expr_stmt|;
comment|/* Initialize ptbl allocation. */
name|ptbl_init
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map a list of wired pages into kernel virtual address space.  This is  * intended for temporary mappings which do not need page modification or  * references recorded.  Existing mappings in the region are overwritten.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_qenter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_page_t
modifier|*
name|m
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|mmu_booke_kenter
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
operator|*
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|m
operator|++
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Remove page mappings from kernel virtual address space.  Intended for  * temporary mappings entered by mmu_booke_qenter.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_qremove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|mmu_booke_kremove
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Map a wired page into kernel virtual address space.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_kenter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|)
block|{
name|unsigned
name|int
name|pdir_idx
init|=
name|PDIR_IDX
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|unsigned
name|int
name|ptbl_idx
init|=
name|PTBL_IDX
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|uint32_t
name|flags
decl_stmt|;
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|(
name|va
operator|>=
name|VM_MIN_KERNEL_ADDRESS
operator|)
operator|&&
operator|(
name|va
operator|<=
name|VM_MAX_KERNEL_ADDRESS
operator|)
operator|)
argument_list|,
operator|(
literal|"mmu_booke_kenter: invalid va"
operator|)
argument_list|)
expr_stmt|;
name|flags
operator|=
literal|0
expr_stmt|;
name|flags
operator||=
operator|(
name|PTE_SR
operator||
name|PTE_SW
operator||
name|PTE_SX
operator||
name|PTE_WIRED
operator||
name|PTE_VALID
operator|)
expr_stmt|;
name|flags
operator||=
name|PTE_M
expr_stmt|;
name|pte
operator|=
operator|&
operator|(
name|kernel_pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
index|[
name|ptbl_idx
index|]
operator|)
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
if|if
condition|(
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|CTR1
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: replacing entry!"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
comment|/* Flush entry from TLB0 */
name|tlb0_flush_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
name|pte
operator|->
name|rpn
operator|=
name|pa
operator|&
operator|~
name|PTE_PA_MASK
expr_stmt|;
name|pte
operator|->
name|flags
operator|=
name|flags
expr_stmt|;
comment|//debugf("mmu_booke_kenter: pdir_idx = %d ptbl_idx = %d va=0x%08x "
comment|//		"pa=0x%08x rpn=0x%08x flags=0x%08x\n",
comment|//		pdir_idx, ptbl_idx, va, pa, pte->rpn, pte->flags);
comment|/* Flush the real memory from the instruction cache. */
if|if
condition|(
operator|(
name|flags
operator|&
operator|(
name|PTE_I
operator||
name|PTE_G
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove a page from kernel page table.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_kremove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|unsigned
name|int
name|pdir_idx
init|=
name|PDIR_IDX
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|unsigned
name|int
name|ptbl_idx
init|=
name|PTBL_IDX
argument_list|(
name|va
argument_list|)
decl_stmt|;
name|pte_t
modifier|*
name|pte
decl_stmt|;
comment|//	CTR2(KTR_PMAP,("%s: s (va = 0x%08x)\n", __func__, va));
name|KASSERT
argument_list|(
operator|(
operator|(
name|va
operator|>=
name|VM_MIN_KERNEL_ADDRESS
operator|)
operator|&&
operator|(
name|va
operator|<=
name|VM_MAX_KERNEL_ADDRESS
operator|)
operator|)
argument_list|,
operator|(
literal|"mmu_booke_kremove: invalid va"
operator|)
argument_list|)
expr_stmt|;
name|pte
operator|=
operator|&
operator|(
name|kernel_pmap
operator|->
name|pm_pdir
index|[
name|pdir_idx
index|]
index|[
name|ptbl_idx
index|]
operator|)
expr_stmt|;
if|if
condition|(
operator|!
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|CTR1
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: invalid pte"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
return|return;
block|}
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
comment|/* Invalidate entry in TLB0, update PTE. */
name|tlb0_flush_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte
operator|->
name|flags
operator|=
literal|0
expr_stmt|;
name|pte
operator|->
name|rpn
operator|=
literal|0
expr_stmt|;
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Initialize pmap associated with process 0.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_pinit0
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|mmu_booke_pinit
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Initialize a preallocated and zeroed pmap structure,  * such as one in a vmspace structure.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_pinit
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: pmap = %p, proc %d '%s'"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_pid
argument_list|,
name|curthread
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pmap
operator|!=
name|kernel_pmap
operator|)
argument_list|,
operator|(
literal|"pmap_pinit: initializing kernel_pmap"
operator|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_INIT
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|MAXCPU
condition|;
name|i
operator|++
control|)
name|pmap
operator|->
name|pm_tid
index|[
name|i
index|]
operator|=
name|TID_NONE
expr_stmt|;
name|pmap
operator|->
name|pm_active
operator|=
literal|0
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pmap
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
argument_list|(
name|pmap
operator|->
name|pm_stats
argument_list|)
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pdir
argument_list|,
sizeof|sizeof
argument_list|(
name|pte_t
operator|*
argument_list|)
operator|*
name|PDIR_NENTRIES
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pm_ptbl_list
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Release any resources held by the given physical map.  * Called when a pmap initialized by mmu_booke_pinit is being released.  * Should only be called if the map contains no valid mappings.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_release
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_release: pmap resident count %ld != 0"
operator|,
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_DESTROY
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Insert the given physical page at the specified virtual address in the  * target physical map with the protection requested. If specified the page  * will be wired down.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_enter
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|boolean_t
name|wired
parameter_list|)
block|{
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|mmu_booke_enter_locked
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|mmu_booke_enter_locked
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|boolean_t
name|wired
parameter_list|)
block|{
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|uint32_t
name|flags
decl_stmt|;
name|int
name|su
decl_stmt|,
name|sync
decl_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|su
operator|=
operator|(
name|pmap
operator|==
name|kernel_pmap
operator|)
expr_stmt|;
name|sync
operator|=
literal|0
expr_stmt|;
comment|//debugf("mmu_booke_enter_locked: s (pmap=0x%08x su=%d tid=%d m=0x%08x va=0x%08x "
comment|//		"pa=0x%08x prot=0x%08x wired=%d)\n",
comment|//		(u_int32_t)pmap, su, pmap->pm_tid,
comment|//		(u_int32_t)m, va, pa, prot, wired);
if|if
condition|(
name|su
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
operator|(
name|va
operator|>=
name|virtual_avail
operator|)
operator|&&
operator|(
name|va
operator|<=
name|VM_MAX_KERNEL_ADDRESS
operator|)
operator|)
argument_list|,
operator|(
literal|"mmu_booke_enter_locked: kernel pmap, non kernel va"
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
operator|(
name|va
operator|<=
name|VM_MAXUSER_ADDRESS
operator|)
argument_list|,
operator|(
literal|"mmu_booke_enter_locked: user pmap, non user va"
operator|)
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|!=
literal|0
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|!=
literal|0
operator|||
name|VM_OBJECT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
argument_list|,
operator|(
literal|"mmu_booke_enter_locked: page %p is not busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * If there is an existing mapping, and the physical address has not 	 * changed, must be protection or wiring change. 	 */
if|if
condition|(
operator|(
operator|(
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
operator|)
operator|!=
name|NULL
operator|)
operator|&&
operator|(
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
operator|)
operator|&&
operator|(
name|PTE_PA
argument_list|(
name|pte
argument_list|)
operator|==
name|pa
operator|)
condition|)
block|{
comment|/* 		 * Before actually updating pte->flags we calculate and 		 * prepare its new value in a helper var. 		 */
name|flags
operator|=
name|pte
operator|->
name|flags
expr_stmt|;
name|flags
operator|&=
operator|~
operator|(
name|PTE_UW
operator||
name|PTE_UX
operator||
name|PTE_SW
operator||
name|PTE_SX
operator||
name|PTE_MODIFIED
operator|)
expr_stmt|;
comment|/* Wiring change, just update stats. */
if|if
condition|(
name|wired
condition|)
block|{
if|if
condition|(
operator|!
name|PTE_ISWIRED
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|flags
operator||=
name|PTE_WIRED
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|PTE_ISWIRED
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|flags
operator|&=
operator|~
name|PTE_WIRED
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
block|}
block|}
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
block|{
comment|/* Add write permissions. */
name|flags
operator||=
name|PTE_SW
expr_stmt|;
if|if
condition|(
operator|!
name|su
condition|)
name|flags
operator||=
name|PTE_UW
expr_stmt|;
if|if
condition|(
operator|(
name|flags
operator|&
name|PTE_MANAGED
operator|)
operator|!=
literal|0
condition|)
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_WRITEABLE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Handle modified pages, sense modify status. */
comment|/* 			 * The PTE_MODIFIED flag could be set by underlying 			 * TLB misses since we last read it (above), possibly 			 * other CPUs could update it so we check in the PTE 			 * directly rather than rely on that saved local flags 			 * copy. 			 */
if|if
condition|(
name|PTE_ISMODIFIED
argument_list|(
name|pte
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|prot
operator|&
name|VM_PROT_EXECUTE
condition|)
block|{
name|flags
operator||=
name|PTE_SX
expr_stmt|;
if|if
condition|(
operator|!
name|su
condition|)
name|flags
operator||=
name|PTE_UX
expr_stmt|;
comment|/* 			 * Check existing flags for execute permissions: if we 			 * are turning execute permissions on, icache should 			 * be flushed. 			 */
if|if
condition|(
operator|(
name|pte
operator|->
name|flags
operator|&
operator|(
name|PTE_UX
operator||
name|PTE_SX
operator|)
operator|)
operator|==
literal|0
condition|)
name|sync
operator|++
expr_stmt|;
block|}
name|flags
operator|&=
operator|~
name|PTE_REFERENCED
expr_stmt|;
comment|/* 		 * The new flags value is all calculated -- only now actually 		 * update the PTE. 		 */
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
name|tlb0_flush_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte
operator|->
name|flags
operator|=
name|flags
expr_stmt|;
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * If there is an existing mapping, but it's for a different 		 * physical address, pte_enter() will delete the old mapping. 		 */
comment|//if ((pte != NULL)&& PTE_ISVALID(pte))
comment|//	debugf("mmu_booke_enter_locked: replace\n");
comment|//else
comment|//	debugf("mmu_booke_enter_locked: new\n");
comment|/* Now set up the flags and install the new mapping. */
name|flags
operator|=
operator|(
name|PTE_SR
operator||
name|PTE_VALID
operator|)
expr_stmt|;
name|flags
operator||=
name|PTE_M
expr_stmt|;
if|if
condition|(
operator|!
name|su
condition|)
name|flags
operator||=
name|PTE_UR
expr_stmt|;
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
block|{
name|flags
operator||=
name|PTE_SW
expr_stmt|;
if|if
condition|(
operator|!
name|su
condition|)
name|flags
operator||=
name|PTE_UW
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|==
literal|0
condition|)
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_WRITEABLE
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|prot
operator|&
name|VM_PROT_EXECUTE
condition|)
block|{
name|flags
operator||=
name|PTE_SX
expr_stmt|;
if|if
condition|(
operator|!
name|su
condition|)
name|flags
operator||=
name|PTE_UX
expr_stmt|;
block|}
comment|/* If its wired update stats. */
if|if
condition|(
name|wired
condition|)
block|{
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
name|flags
operator||=
name|PTE_WIRED
expr_stmt|;
block|}
name|pte_enter
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|m
argument_list|,
name|va
argument_list|,
name|flags
argument_list|)
expr_stmt|;
comment|/* Flush the real memory from the instruction cache. */
if|if
condition|(
name|prot
operator|&
name|VM_PROT_EXECUTE
condition|)
name|sync
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|sync
operator|&&
operator|(
name|su
operator|||
name|pmap
operator|==
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
operator|)
condition|)
block|{
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|sync
operator|=
literal|0
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Maps a sequence of resident pages belonging to the same object.  * The sequence begins with the given page m_start.  This page is  * mapped at the given virtual address start.  Each subsequent page is  * mapped at a virtual address that is offset from start by the same  * amount as the page is offset from m_start within the object.  The  * last page in the sequence is the page with the largest offset from  * m_start that can be mapped at a virtual address less than the given  * virtual address end.  Not every virtual page between start and end  * is mapped; only those for which a resident page exists with the  * corresponding offset from m_start are mapped.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_enter_object
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|start
parameter_list|,
name|vm_offset_t
name|end
parameter_list|,
name|vm_page_t
name|m_start
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_pindex_t
name|diff
decl_stmt|,
name|psize
decl_stmt|;
name|psize
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|m
operator|=
name|m_start
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
while|while
condition|(
name|m
operator|!=
name|NULL
operator|&&
operator|(
name|diff
operator|=
name|m
operator|->
name|pindex
operator|-
name|m_start
operator|->
name|pindex
operator|)
operator|<
name|psize
condition|)
block|{
name|mmu_booke_enter_locked
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|start
operator|+
name|ptoa
argument_list|(
name|diff
argument_list|)
argument_list|,
name|m
argument_list|,
name|prot
operator|&
operator|(
name|VM_PROT_READ
operator||
name|VM_PROT_EXECUTE
operator|)
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|m
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|mmu_booke_enter_quick
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|mmu_booke_enter_locked
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
operator|&
operator|(
name|VM_PROT_READ
operator||
name|VM_PROT_EXECUTE
operator|)
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove the given range of addresses from the specified map.  *  * It is assumed that the start and end are properly rounded to the page size.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_remove
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|endva
parameter_list|)
block|{
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|uint8_t
name|hold_flag
decl_stmt|;
name|int
name|su
init|=
operator|(
name|pmap
operator|==
name|kernel_pmap
operator|)
decl_stmt|;
comment|//debugf("mmu_booke_remove: s (su = %d pmap=0x%08x tid=%d va=0x%08x endva=0x%08x)\n",
comment|//		su, (u_int32_t)pmap, pmap->pm_tid, va, endva);
if|if
condition|(
name|su
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
operator|(
name|va
operator|>=
name|virtual_avail
operator|)
operator|&&
operator|(
name|va
operator|<=
name|VM_MAX_KERNEL_ADDRESS
operator|)
operator|)
argument_list|,
operator|(
literal|"mmu_booke_remove: kernel pmap, non kernel va"
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
operator|(
name|va
operator|<=
name|VM_MAXUSER_ADDRESS
operator|)
argument_list|,
operator|(
literal|"mmu_booke_remove: user pmap, non user va"
operator|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|PMAP_REMOVE_DONE
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
comment|//debugf("mmu_booke_remove: e (empty)\n");
return|return;
block|}
name|hold_flag
operator|=
name|PTBL_HOLD_FLAG
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|//debugf("mmu_booke_remove: hold_flag = %d\n", hold_flag);
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|va
operator|<
name|endva
condition|;
name|va
operator|+=
name|PAGE_SIZE
control|)
block|{
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|!=
name|NULL
operator|)
operator|&&
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
name|pte_remove
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|,
name|hold_flag
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
comment|//debugf("mmu_booke_remove: e\n");
block|}
end_function

begin_comment
comment|/*  * Remove physical page from all pmaps in which it resides.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_remove_all
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|,
name|pvn
decl_stmt|;
name|uint8_t
name|hold_flag
decl_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
for|for
control|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
init|;
name|pv
operator|!=
name|NULL
condition|;
name|pv
operator|=
name|pvn
control|)
block|{
name|pvn
operator|=
name|TAILQ_NEXT
argument_list|(
name|pv
argument_list|,
name|pv_link
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
name|hold_flag
operator|=
name|PTBL_HOLD_FLAG
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
name|pte_remove
argument_list|(
name|mmu
argument_list|,
name|pv
operator|->
name|pv_pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
name|hold_flag
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WRITEABLE
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map a range of physical addresses into kernel virtual address space.  */
end_comment

begin_function
specifier|static
name|vm_offset_t
name|mmu_booke_map
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
modifier|*
name|virt
parameter_list|,
name|vm_offset_t
name|pa_start
parameter_list|,
name|vm_offset_t
name|pa_end
parameter_list|,
name|int
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|sva
init|=
operator|*
name|virt
decl_stmt|;
name|vm_offset_t
name|va
init|=
name|sva
decl_stmt|;
comment|//debugf("mmu_booke_map: s (sva = 0x%08x pa_start = 0x%08x pa_end = 0x%08x)\n",
comment|//		sva, pa_start, pa_end);
while|while
condition|(
name|pa_start
operator|<
name|pa_end
condition|)
block|{
name|mmu_booke_kenter
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|pa_start
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pa_start
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
operator|*
name|virt
operator|=
name|va
expr_stmt|;
comment|//debugf("mmu_booke_map: e (va = 0x%08x)\n", va);
return|return
operator|(
name|sva
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * The pmap must be activated before it's address space can be accessed in any  * way.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_activate
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|pmap
operator|=
operator|&
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
expr_stmt|;
name|CTR5
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: s (td = %p, proc = '%s', id = %d, pmap = 0x%08x)"
argument_list|,
name|__func__
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_pid
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pmap
operator|!=
name|kernel_pmap
operator|)
argument_list|,
operator|(
literal|"mmu_booke_activate: kernel_pmap!"
operator|)
argument_list|)
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|atomic_set_int
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|,
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_tid
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
operator|==
name|TID_NONE
condition|)
name|tid_alloc
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Load PID0 register with pmap tid value. */
name|mtspr
argument_list|(
name|SPR_PID0
argument_list|,
name|pmap
operator|->
name|pm_tid
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync");
name|mtx_unlock_spin
argument_list|(
operator|&
name|sched_lock
argument_list|)
expr_stmt|;
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: e (tid = %d for '%s')"
argument_list|,
name|__func__
argument_list|,
name|pmap
operator|->
name|pm_tid
index|[
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
index|]
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Deactivate the specified process's address space.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_deactivate
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|pmap
operator|=
operator|&
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
operator|->
name|vm_pmap
expr_stmt|;
name|CTR5
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: td=%p, proc = '%s', id = %d, pmap = 0x%08x"
argument_list|,
name|__func__
argument_list|,
name|td
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_comm
argument_list|,
name|td
operator|->
name|td_proc
operator|->
name|p_pid
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|atomic_clear_int
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|,
name|PCPU_GET
argument_list|(
name|cpumask
argument_list|)
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Copy the range specified by src_addr/len  * from the source map to the range dst_addr/len  * in the destination map.  *  * This routine is only advisory and need not do anything.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_copy
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|dst_pmap
parameter_list|,
name|pmap_t
name|src_pmap
parameter_list|,
name|vm_offset_t
name|dst_addr
parameter_list|,
name|vm_size_t
name|len
parameter_list|,
name|vm_offset_t
name|src_addr
parameter_list|)
block|{  }
end_function

begin_comment
comment|/*  * Set the physical protection on the specified range of this map as requested.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_protect
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|pte_t
modifier|*
name|pte
decl_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_READ
operator|)
operator|==
name|VM_PROT_NONE
condition|)
block|{
name|mmu_booke_remove
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
return|return;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
name|va
operator|=
name|sva
init|;
name|va
operator|<
name|eva
condition|;
name|va
operator|+=
name|PAGE_SIZE
control|)
block|{
if|if
condition|(
operator|(
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|PTE_PA
argument_list|(
name|pte
argument_list|)
argument_list|)
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
comment|/* Handle modified pages. */
if|if
condition|(
name|PTE_ISMODIFIED
argument_list|(
name|pte
argument_list|)
operator|&&
name|PTE_ISMANAGED
argument_list|(
name|pte
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|tlb0_flush_entry
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte
operator|->
name|flags
operator|&=
operator|~
operator|(
name|PTE_UW
operator||
name|PTE_SW
operator||
name|PTE_MODIFIED
operator|)
expr_stmt|;
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Clear the write and modified bits in each of the given page's mappings.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_remove_write
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"mmu_booke_remove_write: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not VPO_BUSY, then PG_WRITEABLE cannot be set by 	 * another thread while the object is locked.  Thus, if PG_WRITEABLE 	 * is clear, no page table entries need updating. 	 */
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_link
argument_list|)
block|{
name|PMAP_LOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pv
operator|->
name|pv_pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|PTE_PA
argument_list|(
name|pte
argument_list|)
argument_list|)
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
comment|/* Handle modified pages. */
if|if
condition|(
name|PTE_ISMODIFIED
argument_list|(
name|pte
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* Flush mapping from TLB0. */
name|pte
operator|->
name|flags
operator|&=
operator|~
operator|(
name|PTE_UW
operator||
name|PTE_SW
operator||
name|PTE_MODIFIED
operator|)
expr_stmt|;
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WRITEABLE
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|mmu_booke_sync_icache
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|sz
parameter_list|)
block|{
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_offset_t
name|addr
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|int
name|active
decl_stmt|,
name|valid
decl_stmt|;
name|va
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|sz
operator|=
name|round_page
argument_list|(
name|sz
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|pmap
operator|=
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
expr_stmt|;
name|active
operator|=
operator|(
name|pm
operator|==
name|kernel_pmap
operator|||
name|pm
operator|==
name|pmap
operator|)
condition|?
literal|1
else|:
literal|0
expr_stmt|;
while|while
condition|(
name|sz
operator|>
literal|0
condition|)
block|{
name|PMAP_LOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|valid
operator|=
operator|(
name|pte
operator|!=
name|NULL
operator|&&
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
operator|)
condition|?
literal|1
else|:
literal|0
expr_stmt|;
if|if
condition|(
name|valid
condition|)
name|pa
operator|=
name|PTE_PA
argument_list|(
name|pte
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pm
argument_list|)
expr_stmt|;
if|if
condition|(
name|valid
condition|)
block|{
if|if
condition|(
operator|!
name|active
condition|)
block|{
comment|/* Create a mapping in the active pmap. */
name|addr
operator|=
literal|0
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte_enter
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|m
argument_list|,
name|addr
argument_list|,
name|PTE_SR
operator||
name|PTE_VALID
operator||
name|PTE_UR
argument_list|)
expr_stmt|;
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|addr
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|pte_remove
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|addr
argument_list|,
name|PTBL_UNHOLD
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
else|else
name|__syncicache
argument_list|(
operator|(
name|void
operator|*
operator|)
name|va
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|sz
operator|-=
name|PAGE_SIZE
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Atomically extract and hold the physical page with the given  * pmap and virtual address pair if that mapping permits the given  * protection.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|mmu_booke_extract_and_hold
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|uint32_t
name|pte_wbit
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|!=
name|NULL
operator|)
operator|&&
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|pte_wbit
operator|=
name|PTE_SW
expr_stmt|;
else|else
name|pte_wbit
operator|=
name|PTE_UW
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|->
name|flags
operator|&
name|pte_wbit
operator|)
operator|||
operator|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
operator|)
condition|)
block|{
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|PTE_PA
argument_list|(
name|pte
argument_list|)
argument_list|,
operator|&
name|pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|PTE_PA
argument_list|(
name|pte
argument_list|)
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
name|PA_UNLOCK_COND
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Initialize a vm_page's machine-dependent fields.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_page_init
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|TAILQ_INIT
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * mmu_booke_zero_page_area zeros the specified hardware page by  * mapping it into virtual memory and using bzero to clear  * its contents.  *  * off and size must reside within a single page.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_zero_page_area
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
comment|/* XXX KASSERT off and size are within a single page? */
name|mtx_lock
argument_list|(
operator|&
name|zero_page_mutex
argument_list|)
expr_stmt|;
name|va
operator|=
name|zero_page_va
expr_stmt|;
name|mmu_booke_kenter
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|va
operator|+
name|off
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|mmu_booke_kremove
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|zero_page_mutex
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * mmu_booke_zero_page zeros the specified hardware page.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_zero_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|mmu_booke_zero_page_area
argument_list|(
name|mmu
argument_list|,
name|m
argument_list|,
literal|0
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * mmu_booke_copy_page copies the specified (machine independent) page by  * mapping the page into virtual memory and using memcopy to copy the page,  * one machine dependent page at a time.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_copy_page
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|sm
parameter_list|,
name|vm_page_t
name|dm
parameter_list|)
block|{
name|vm_offset_t
name|sva
decl_stmt|,
name|dva
decl_stmt|;
name|sva
operator|=
name|copy_page_src_va
expr_stmt|;
name|dva
operator|=
name|copy_page_dst_va
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|copy_page_mutex
argument_list|)
expr_stmt|;
name|mmu_booke_kenter
argument_list|(
name|mmu
argument_list|,
name|sva
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|sm
argument_list|)
argument_list|)
expr_stmt|;
name|mmu_booke_kenter
argument_list|(
name|mmu
argument_list|,
name|dva
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|dm
argument_list|)
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
operator|(
name|caddr_t
operator|)
name|dva
argument_list|,
operator|(
name|caddr_t
operator|)
name|sva
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|mmu_booke_kremove
argument_list|(
name|mmu
argument_list|,
name|dva
argument_list|)
expr_stmt|;
name|mmu_booke_kremove
argument_list|(
name|mmu
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|copy_page_mutex
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * mmu_booke_zero_page_idle zeros the specified hardware page by mapping it  * into virtual memory and using bzero to clear its contents. This is intended  * to be called from the vm_pagezero process only and outside of Giant. No  * lock is required.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_zero_page_idle
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|va
operator|=
name|zero_page_idle_va
expr_stmt|;
name|mmu_booke_kenter
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|va
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|mmu_booke_kremove
argument_list|(
name|mmu
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return whether or not the specified physical page was modified  * in any of physical maps.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|mmu_booke_is_modified
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"mmu_booke_is_modified: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
comment|/* 	 * If the page is not VPO_BUSY, then PG_WRITEABLE cannot be 	 * concurrently set while the object is locked.  Thus, if PG_WRITEABLE 	 * is clear, no PTEs can be modified. 	 */
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|rv
operator|)
return|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_link
argument_list|)
block|{
name|PMAP_LOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pv
operator|->
name|pv_pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
if|if
condition|(
name|PTE_ISMODIFIED
argument_list|(
name|pte
argument_list|)
condition|)
name|rv
operator|=
name|TRUE
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
condition|)
break|break;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return whether or not the specified virtual address is eligible  * for prefault.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|mmu_booke_is_prefaultable
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|)
block|{
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return whether or not the specified physical page was referenced  * in any physical maps.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|mmu_booke_is_referenced
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"mmu_booke_is_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_link
argument_list|)
block|{
name|PMAP_LOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pv
operator|->
name|pv_pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
if|if
condition|(
name|PTE_ISREFERENCED
argument_list|(
name|pte
argument_list|)
condition|)
name|rv
operator|=
name|TRUE
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
condition|)
break|break;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Clear the modify bits on the specified physical page.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_clear_modify
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"mmu_booke_clear_modify: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"mmu_booke_clear_modify: page %p is busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not PG_WRITEABLE, then no PTEs can be modified. 	 * If the object containing the page is locked and the page is not 	 * VPO_BUSY, then PG_WRITEABLE cannot be concurrently set. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_link
argument_list|)
block|{
name|PMAP_LOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pv
operator|->
name|pv_pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
if|if
condition|(
name|pte
operator|->
name|flags
operator|&
operator|(
name|PTE_SW
operator||
name|PTE_UW
operator||
name|PTE_MODIFIED
operator|)
condition|)
block|{
name|tlb0_flush_entry
argument_list|(
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|pte
operator|->
name|flags
operator|&=
operator|~
operator|(
name|PTE_SW
operator||
name|PTE_UW
operator||
name|PTE_MODIFIED
operator||
name|PTE_REFERENCED
operator|)
expr_stmt|;
block|}
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return a count of reference bits for a page, clearing those bits.  * It is not necessary for every reference bit to be cleared, but it  * is necessary that 0 only be returned when there are truly no  * reference bits set.  *  * XXX: The exact number of bits to check and clear is a matter that  * should be tested and standardized at some point in the future for  * optimal aging of shared pages.  */
end_comment

begin_function
specifier|static
name|int
name|mmu_booke_ts_referenced
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|int
name|count
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"mmu_booke_ts_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_link
argument_list|)
block|{
name|PMAP_LOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pv
operator|->
name|pv_pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
if|if
condition|(
name|PTE_ISREFERENCED
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
name|tlb0_flush_entry
argument_list|(
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|pte
operator|->
name|flags
operator|&=
operator|~
name|PTE_REFERENCED
expr_stmt|;
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
if|if
condition|(
operator|++
name|count
operator|>
literal|4
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Clear the reference bit on the specified physical page.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_clear_reference
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"mmu_booke_clear_reference: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_link
argument_list|)
block|{
name|PMAP_LOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pv
operator|->
name|pv_pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
block|{
if|if
condition|(
name|PTE_ISREFERENCED
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|mtx_lock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
name|tlb_miss_lock
argument_list|()
expr_stmt|;
name|tlb0_flush_entry
argument_list|(
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|pte
operator|->
name|flags
operator|&=
operator|~
name|PTE_REFERENCED
expr_stmt|;
name|tlb_miss_unlock
argument_list|()
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|)
expr_stmt|;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Change wiring attribute for a map/virtual-address pair.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_change_wiring
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|boolean_t
name|wired
parameter_list|)
block|{
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|wired
condition|)
block|{
if|if
condition|(
operator|!
name|PTE_ISWIRED
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|pte
operator|->
name|flags
operator||=
name|PTE_WIRED
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|PTE_ISWIRED
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|pte
operator|->
name|flags
operator|&=
operator|~
name|PTE_WIRED
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
block|}
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return true if the pmap's pv is one of the first 16 pvs linked to from this  * page.  This count may be changed upwards or downwards in the future; it is  * only necessary that true be returned for a small subset of pmaps for proper  * page aging.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|mmu_booke_page_exists_quick
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|int
name|loops
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"mmu_booke_page_exists_quick: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|loops
operator|=
literal|0
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_link
argument_list|)
block|{
if|if
condition|(
name|pv
operator|->
name|pv_pmap
operator|==
name|pmap
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
if|if
condition|(
operator|++
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return the number of managed mappings to the given physical page that are  * wired.  */
end_comment

begin_function
specifier|static
name|int
name|mmu_booke_page_wired_mappings
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|int
name|count
init|=
literal|0
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|count
operator|)
return|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_link
argument_list|)
block|{
name|PMAP_LOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|pv
operator|->
name|pv_pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
if|if
condition|(
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
operator|&&
name|PTE_ISWIRED
argument_list|(
name|pte
argument_list|)
condition|)
name|count
operator|++
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pv
operator|->
name|pv_pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|mmu_booke_dev_direct_mapped
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
comment|/* 	 * This currently does not work for entries that 	 * overlap TLB1 entries. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|tlb1_idx
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|tlb1_iomapped
argument_list|(
name|i
argument_list|,
name|pa
argument_list|,
name|size
argument_list|,
operator|&
name|va
argument_list|)
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
block|}
return|return
operator|(
name|EFAULT
operator|)
return|;
block|}
end_function

begin_function
name|vm_offset_t
name|mmu_booke_dumpsys_map
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|pmap_md
modifier|*
name|md
parameter_list|,
name|vm_size_t
name|ofs
parameter_list|,
name|vm_size_t
modifier|*
name|sz
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|,
name|ppa
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_size_t
name|gran
decl_stmt|;
comment|/* Raw physical memory dumps don't have a virtual address. */
if|if
condition|(
name|md
operator|->
name|md_vaddr
operator|==
operator|~
literal|0UL
condition|)
block|{
comment|/* We always map a 256MB page at 256M. */
name|gran
operator|=
literal|256
operator|*
literal|1024
operator|*
literal|1024
expr_stmt|;
name|pa
operator|=
name|md
operator|->
name|md_paddr
operator|+
name|ofs
expr_stmt|;
name|ppa
operator|=
name|pa
operator|&
operator|~
operator|(
name|gran
operator|-
literal|1
operator|)
expr_stmt|;
name|ofs
operator|=
name|pa
operator|-
name|ppa
expr_stmt|;
name|va
operator|=
name|gran
expr_stmt|;
name|tlb1_set_entry
argument_list|(
name|va
argument_list|,
name|ppa
argument_list|,
name|gran
argument_list|,
name|_TLB_ENTRY_IO
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|sz
operator|>
operator|(
name|gran
operator|-
name|ofs
operator|)
condition|)
operator|*
name|sz
operator|=
name|gran
operator|-
name|ofs
expr_stmt|;
return|return
operator|(
name|va
operator|+
name|ofs
operator|)
return|;
block|}
comment|/* Minidumps are based on virtual memory addresses. */
name|va
operator|=
name|md
operator|->
name|md_vaddr
operator|+
name|ofs
expr_stmt|;
if|if
condition|(
name|va
operator|>=
name|kernstart
operator|+
name|kernsize
condition|)
block|{
name|gran
operator|=
name|PAGE_SIZE
operator|-
operator|(
name|va
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
if|if
condition|(
operator|*
name|sz
operator|>
name|gran
condition|)
operator|*
name|sz
operator|=
name|gran
expr_stmt|;
block|}
return|return
operator|(
name|va
operator|)
return|;
block|}
end_function

begin_function
name|void
name|mmu_booke_dumpsys_unmap
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|pmap_md
modifier|*
name|md
parameter_list|,
name|vm_size_t
name|ofs
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
comment|/* Raw physical memory dumps don't have a virtual address. */
if|if
condition|(
name|md
operator|->
name|md_vaddr
operator|==
operator|~
literal|0UL
condition|)
block|{
name|tlb1_idx
operator|--
expr_stmt|;
name|tlb1
index|[
name|tlb1_idx
index|]
operator|.
name|mas1
operator|=
literal|0
expr_stmt|;
name|tlb1
index|[
name|tlb1_idx
index|]
operator|.
name|mas2
operator|=
literal|0
expr_stmt|;
name|tlb1
index|[
name|tlb1_idx
index|]
operator|.
name|mas3
operator|=
literal|0
expr_stmt|;
name|tlb1_write_entry
argument_list|(
name|tlb1_idx
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* Minidumps are based on virtual memory addresses. */
comment|/* Nothing to do... */
block|}
end_function

begin_function
name|struct
name|pmap_md
modifier|*
name|mmu_booke_scan_md
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|struct
name|pmap_md
modifier|*
name|prev
parameter_list|)
block|{
specifier|static
name|struct
name|pmap_md
name|md
decl_stmt|;
name|pte_t
modifier|*
name|pte
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
if|if
condition|(
name|dumpsys_minidump
condition|)
block|{
name|md
operator|.
name|md_paddr
operator|=
operator|~
literal|0UL
expr_stmt|;
comment|/* Minidumps use virtual addresses. */
if|if
condition|(
name|prev
operator|==
name|NULL
condition|)
block|{
comment|/* 1st: kernel .data and .bss. */
name|md
operator|.
name|md_index
operator|=
literal|1
expr_stmt|;
name|md
operator|.
name|md_vaddr
operator|=
name|trunc_page
argument_list|(
operator|(
name|uintptr_t
operator|)
name|_etext
argument_list|)
expr_stmt|;
name|md
operator|.
name|md_size
operator|=
name|round_page
argument_list|(
operator|(
name|uintptr_t
operator|)
name|_end
argument_list|)
operator|-
name|md
operator|.
name|md_vaddr
expr_stmt|;
return|return
operator|(
operator|&
name|md
operator|)
return|;
block|}
switch|switch
condition|(
name|prev
operator|->
name|md_index
condition|)
block|{
case|case
literal|1
case|:
comment|/* 2nd: msgbuf and tables (see pmap_bootstrap()). */
name|md
operator|.
name|md_index
operator|=
literal|2
expr_stmt|;
name|md
operator|.
name|md_vaddr
operator|=
name|data_start
expr_stmt|;
name|md
operator|.
name|md_size
operator|=
name|data_end
operator|-
name|data_start
expr_stmt|;
break|break;
case|case
literal|2
case|:
comment|/* 3rd: kernel VM. */
name|va
operator|=
name|prev
operator|->
name|md_vaddr
operator|+
name|prev
operator|->
name|md_size
expr_stmt|;
comment|/* Find start of next chunk (from va). */
while|while
condition|(
name|va
operator|<
name|virtual_end
condition|)
block|{
comment|/* Don't dump the buffer cache. */
if|if
condition|(
name|va
operator|>=
name|kmi
operator|.
name|buffer_sva
operator|&&
name|va
operator|<
name|kmi
operator|.
name|buffer_eva
condition|)
block|{
name|va
operator|=
name|kmi
operator|.
name|buffer_eva
expr_stmt|;
continue|continue;
block|}
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte
operator|!=
name|NULL
operator|&&
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
break|break;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
if|if
condition|(
name|va
operator|<
name|virtual_end
condition|)
block|{
name|md
operator|.
name|md_vaddr
operator|=
name|va
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
comment|/* Find last page in chunk. */
while|while
condition|(
name|va
operator|<
name|virtual_end
condition|)
block|{
comment|/* Don't run into the buffer cache. */
if|if
condition|(
name|va
operator|==
name|kmi
operator|.
name|buffer_sva
condition|)
break|break;
name|pte
operator|=
name|pte_find
argument_list|(
name|mmu
argument_list|,
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte
operator|==
name|NULL
operator|||
operator|!
name|PTE_ISVALID
argument_list|(
name|pte
argument_list|)
condition|)
break|break;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|md
operator|.
name|md_size
operator|=
name|va
operator|-
name|md
operator|.
name|md_vaddr
expr_stmt|;
break|break;
block|}
name|md
operator|.
name|md_index
operator|=
literal|3
expr_stmt|;
comment|/* FALLTHROUGH */
default|default:
return|return
operator|(
name|NULL
operator|)
return|;
block|}
block|}
else|else
block|{
comment|/* minidumps */
name|mem_regions
argument_list|(
operator|&
name|physmem_regions
argument_list|,
operator|&
name|physmem_regions_sz
argument_list|,
operator|&
name|availmem_regions
argument_list|,
operator|&
name|availmem_regions_sz
argument_list|)
expr_stmt|;
if|if
condition|(
name|prev
operator|==
name|NULL
condition|)
block|{
comment|/* first physical chunk. */
name|md
operator|.
name|md_paddr
operator|=
name|physmem_regions
index|[
literal|0
index|]
operator|.
name|mr_start
expr_stmt|;
name|md
operator|.
name|md_size
operator|=
name|physmem_regions
index|[
literal|0
index|]
operator|.
name|mr_size
expr_stmt|;
name|md
operator|.
name|md_vaddr
operator|=
operator|~
literal|0UL
expr_stmt|;
name|md
operator|.
name|md_index
operator|=
literal|1
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|md
operator|.
name|md_index
operator|<
name|physmem_regions_sz
condition|)
block|{
name|md
operator|.
name|md_paddr
operator|=
name|physmem_regions
index|[
name|md
operator|.
name|md_index
index|]
operator|.
name|mr_start
expr_stmt|;
name|md
operator|.
name|md_size
operator|=
name|physmem_regions
index|[
name|md
operator|.
name|md_index
index|]
operator|.
name|mr_size
expr_stmt|;
name|md
operator|.
name|md_vaddr
operator|=
operator|~
literal|0UL
expr_stmt|;
name|md
operator|.
name|md_index
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* There's no next physical chunk. */
return|return
operator|(
name|NULL
operator|)
return|;
block|}
block|}
return|return
operator|(
operator|&
name|md
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Map a set of physical memory pages into the kernel virtual address space.  * Return a pointer to where it is mapped. This routine is intended to be used  * for mapping device memory, NOT real memory.  */
end_comment

begin_function
specifier|static
name|void
modifier|*
name|mmu_booke_mapdev
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|void
modifier|*
name|res
decl_stmt|;
name|uintptr_t
name|va
decl_stmt|;
name|vm_size_t
name|sz
decl_stmt|;
name|va
operator|=
operator|(
name|pa
operator|>=
literal|0x80000000
operator|)
condition|?
name|pa
else|:
operator|(
literal|0xe2000000
operator|+
name|pa
operator|)
expr_stmt|;
name|res
operator|=
operator|(
name|void
operator|*
operator|)
name|va
expr_stmt|;
do|do
block|{
name|sz
operator|=
literal|1
operator|<<
operator|(
name|ilog2
argument_list|(
name|size
argument_list|)
operator|&
operator|~
literal|1
operator|)
expr_stmt|;
if|if
condition|(
name|bootverbose
condition|)
name|printf
argument_list|(
literal|"Wiring VA=%x to PA=%x (size=%x), "
literal|"using TLB1[%d]\n"
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|sz
argument_list|,
name|tlb1_idx
argument_list|)
expr_stmt|;
name|tlb1_set_entry
argument_list|(
name|va
argument_list|,
name|pa
argument_list|,
name|sz
argument_list|,
name|_TLB_ENTRY_IO
argument_list|)
expr_stmt|;
name|size
operator|-=
name|sz
expr_stmt|;
name|pa
operator|+=
name|sz
expr_stmt|;
name|va
operator|+=
name|sz
expr_stmt|;
block|}
do|while
condition|(
name|size
operator|>
literal|0
condition|)
do|;
return|return
operator|(
name|res
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * 'Unmap' a range mapped by mmu_booke_mapdev().  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_unmapdev
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|vm_offset_t
name|base
decl_stmt|,
name|offset
decl_stmt|;
comment|/* 	 * Unmap only if this is inside kernel virtual space. 	 */
if|if
condition|(
operator|(
name|va
operator|>=
name|VM_MIN_KERNEL_ADDRESS
operator|)
operator|&&
operator|(
name|va
operator|<=
name|VM_MAX_KERNEL_ADDRESS
operator|)
condition|)
block|{
name|base
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|offset
operator|=
name|va
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|roundup
argument_list|(
name|offset
operator|+
name|size
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|kmem_free
argument_list|(
name|kernel_map
argument_list|,
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * mmu_booke_object_init_pt preloads the ptes for a given object into the  * specified pmap. This eliminates the blast of soft faults on process startup  * and immediately after an mmap.  */
end_comment

begin_function
specifier|static
name|void
name|mmu_booke_object_init_pt
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|object
operator|->
name|type
operator|==
name|OBJT_DEVICE
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_SG
argument_list|,
operator|(
literal|"mmu_booke_object_init_pt: non-device object"
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Perform the pmap work for mincore.  */
end_comment

begin_function
specifier|static
name|int
name|mmu_booke_mincore
parameter_list|(
name|mmu_t
name|mmu
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|vm_paddr_t
modifier|*
name|locked_pa
parameter_list|)
block|{
name|TODO
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/* TID handling */
end_comment

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/*  * Allocate a TID. If necessary, steal one from someone else.  * The new TID is flushed from the TLB before returning.  */
end_comment

begin_function
specifier|static
name|tlbtid_t
name|tid_alloc
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|tlbtid_t
name|tid
decl_stmt|;
name|int
name|thiscpu
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pmap
operator|!=
name|kernel_pmap
operator|)
argument_list|,
operator|(
literal|"tid_alloc: kernel pmap"
operator|)
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: s (pmap = %p)"
argument_list|,
name|__func__
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|thiscpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|tid
operator|=
name|PCPU_GET
argument_list|(
name|tid_next
argument_list|)
expr_stmt|;
if|if
condition|(
name|tid
operator|>
name|TID_MAX
condition|)
name|tid
operator|=
name|TID_MIN
expr_stmt|;
name|PCPU_SET
argument_list|(
name|tid_next
argument_list|,
name|tid
operator|+
literal|1
argument_list|)
expr_stmt|;
comment|/* If we are stealing TID then clear the relevant pmap's field */
if|if
condition|(
name|tidbusy
index|[
name|thiscpu
index|]
index|[
name|tid
index|]
operator|!=
name|NULL
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: warning: stealing tid %d"
argument_list|,
name|__func__
argument_list|,
name|tid
argument_list|)
expr_stmt|;
name|tidbusy
index|[
name|thiscpu
index|]
index|[
name|tid
index|]
operator|->
name|pm_tid
index|[
name|thiscpu
index|]
operator|=
name|TID_NONE
expr_stmt|;
comment|/* Flush all entries from TLB0 matching this TID. */
name|tid_flush
argument_list|(
name|tid
argument_list|)
expr_stmt|;
block|}
name|tidbusy
index|[
name|thiscpu
index|]
index|[
name|tid
index|]
operator|=
name|pmap
expr_stmt|;
name|pmap
operator|->
name|pm_tid
index|[
name|thiscpu
index|]
operator|=
name|tid
expr_stmt|;
asm|__asm __volatile("msync; isync");
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: e (%02d next = %02d)"
argument_list|,
name|__func__
argument_list|,
name|tid
argument_list|,
name|PCPU_GET
argument_list|(
name|tid_next
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|tid
operator|)
return|;
block|}
end_function

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/* TLB0 handling */
end_comment

begin_comment
comment|/**************************************************************************/
end_comment

begin_function
specifier|static
name|void
name|tlb_print_entry
parameter_list|(
name|int
name|i
parameter_list|,
name|uint32_t
name|mas1
parameter_list|,
name|uint32_t
name|mas2
parameter_list|,
name|uint32_t
name|mas3
parameter_list|,
name|uint32_t
name|mas7
parameter_list|)
block|{
name|int
name|as
decl_stmt|;
name|char
name|desc
index|[
literal|3
index|]
decl_stmt|;
name|tlbtid_t
name|tid
decl_stmt|;
name|vm_size_t
name|size
decl_stmt|;
name|unsigned
name|int
name|tsize
decl_stmt|;
name|desc
index|[
literal|2
index|]
operator|=
literal|'\0'
expr_stmt|;
if|if
condition|(
name|mas1
operator|&
name|MAS1_VALID
condition|)
name|desc
index|[
literal|0
index|]
operator|=
literal|'V'
expr_stmt|;
else|else
name|desc
index|[
literal|0
index|]
operator|=
literal|' '
expr_stmt|;
if|if
condition|(
name|mas1
operator|&
name|MAS1_IPROT
condition|)
name|desc
index|[
literal|1
index|]
operator|=
literal|'P'
expr_stmt|;
else|else
name|desc
index|[
literal|1
index|]
operator|=
literal|' '
expr_stmt|;
name|as
operator|=
operator|(
name|mas1
operator|&
name|MAS1_TS_MASK
operator|)
condition|?
literal|1
else|:
literal|0
expr_stmt|;
name|tid
operator|=
name|MAS1_GETTID
argument_list|(
name|mas1
argument_list|)
expr_stmt|;
name|tsize
operator|=
operator|(
name|mas1
operator|&
name|MAS1_TSIZE_MASK
operator|)
operator|>>
name|MAS1_TSIZE_SHIFT
expr_stmt|;
name|size
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|tsize
condition|)
name|size
operator|=
name|tsize2size
argument_list|(
name|tsize
argument_list|)
expr_stmt|;
name|debugf
argument_list|(
literal|"%3d: (%s) [AS=%d] "
literal|"sz = 0x%08x tsz = %d tid = %d mas1 = 0x%08x "
literal|"mas2(va) = 0x%08x mas3(pa) = 0x%08x mas7 = 0x%08x\n"
argument_list|,
name|i
argument_list|,
name|desc
argument_list|,
name|as
argument_list|,
name|size
argument_list|,
name|tsize
argument_list|,
name|tid
argument_list|,
name|mas1
argument_list|,
name|mas2
argument_list|,
name|mas3
argument_list|,
name|mas7
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Convert TLB0 va and way number to tlb0[] table index. */
end_comment

begin_function
specifier|static
specifier|inline
name|unsigned
name|int
name|tlb0_tableidx
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|unsigned
name|int
name|way
parameter_list|)
block|{
name|unsigned
name|int
name|idx
decl_stmt|;
name|idx
operator|=
operator|(
name|way
operator|*
name|TLB0_ENTRIES_PER_WAY
operator|)
expr_stmt|;
name|idx
operator|+=
operator|(
name|va
operator|&
name|MAS2_TLB0_ENTRY_IDX_MASK
operator|)
operator|>>
name|MAS2_TLB0_ENTRY_IDX_SHIFT
expr_stmt|;
return|return
operator|(
name|idx
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Invalidate TLB0 entry.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|tlb0_flush_entry
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: s va=0x%08x"
argument_list|,
name|__func__
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|tlbivax_mutex
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
asm|__asm __volatile("tlbivax 0, %0" :: "r"(va& MAS2_EPN_MASK));
asm|__asm __volatile("isync; msync");
asm|__asm __volatile("tlbsync; msync");
name|CTR1
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: e"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Print out contents of the MAS registers for each TLB0 entry */
end_comment

begin_function
name|void
name|tlb0_print_tlbentries
parameter_list|(
name|void
parameter_list|)
block|{
name|uint32_t
name|mas0
decl_stmt|,
name|mas1
decl_stmt|,
name|mas2
decl_stmt|,
name|mas3
decl_stmt|,
name|mas7
decl_stmt|;
name|int
name|entryidx
decl_stmt|,
name|way
decl_stmt|,
name|idx
decl_stmt|;
name|debugf
argument_list|(
literal|"TLB0 entries:\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|way
operator|=
literal|0
init|;
name|way
operator|<
name|TLB0_WAYS
condition|;
name|way
operator|++
control|)
for|for
control|(
name|entryidx
operator|=
literal|0
init|;
name|entryidx
operator|<
name|TLB0_ENTRIES_PER_WAY
condition|;
name|entryidx
operator|++
control|)
block|{
name|mas0
operator|=
name|MAS0_TLBSEL
argument_list|(
literal|0
argument_list|)
operator||
name|MAS0_ESEL
argument_list|(
name|way
argument_list|)
expr_stmt|;
name|mtspr
argument_list|(
name|SPR_MAS0
argument_list|,
name|mas0
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync");
name|mas2
operator|=
name|entryidx
operator|<<
name|MAS2_TLB0_ENTRY_IDX_SHIFT
expr_stmt|;
name|mtspr
argument_list|(
name|SPR_MAS2
argument_list|,
name|mas2
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync; tlbre");
name|mas1
operator|=
name|mfspr
argument_list|(
name|SPR_MAS1
argument_list|)
expr_stmt|;
name|mas2
operator|=
name|mfspr
argument_list|(
name|SPR_MAS2
argument_list|)
expr_stmt|;
name|mas3
operator|=
name|mfspr
argument_list|(
name|SPR_MAS3
argument_list|)
expr_stmt|;
name|mas7
operator|=
name|mfspr
argument_list|(
name|SPR_MAS7
argument_list|)
expr_stmt|;
name|idx
operator|=
name|tlb0_tableidx
argument_list|(
name|mas2
argument_list|,
name|way
argument_list|)
expr_stmt|;
name|tlb_print_entry
argument_list|(
name|idx
argument_list|,
name|mas1
argument_list|,
name|mas2
argument_list|,
name|mas3
argument_list|,
name|mas7
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/* TLB1 handling */
end_comment

begin_comment
comment|/**************************************************************************/
end_comment

begin_comment
comment|/*  * TLB1 mapping notes:  *  * TLB1[0]	CCSRBAR  * TLB1[1]	Kernel text and data.  * TLB1[2-15]	Additional kernel text and data mappings (if required), PCI  *		windows, other devices mappings.  */
end_comment

begin_comment
comment|/*  * Write given entry to TLB1 hardware.  * Use 32 bit pa, clear 4 high-order bits of RPN (mas7).  */
end_comment

begin_function
specifier|static
name|void
name|tlb1_write_entry
parameter_list|(
name|unsigned
name|int
name|idx
parameter_list|)
block|{
name|uint32_t
name|mas0
decl_stmt|,
name|mas7
decl_stmt|;
comment|//debugf("tlb1_write_entry: s\n");
comment|/* Clear high order RPN bits */
name|mas7
operator|=
literal|0
expr_stmt|;
comment|/* Select entry */
name|mas0
operator|=
name|MAS0_TLBSEL
argument_list|(
literal|1
argument_list|)
operator||
name|MAS0_ESEL
argument_list|(
name|idx
argument_list|)
expr_stmt|;
comment|//debugf("tlb1_write_entry: mas0 = 0x%08x\n", mas0);
name|mtspr
argument_list|(
name|SPR_MAS0
argument_list|,
name|mas0
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync");
name|mtspr
argument_list|(
name|SPR_MAS1
argument_list|,
name|tlb1
index|[
name|idx
index|]
operator|.
name|mas1
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync");
name|mtspr
argument_list|(
name|SPR_MAS2
argument_list|,
name|tlb1
index|[
name|idx
index|]
operator|.
name|mas2
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync");
name|mtspr
argument_list|(
name|SPR_MAS3
argument_list|,
name|tlb1
index|[
name|idx
index|]
operator|.
name|mas3
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync");
name|mtspr
argument_list|(
name|SPR_MAS7
argument_list|,
name|mas7
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync; tlbwe; isync; msync");
comment|//debugf("tlb1_write_entry: e\n");
block|}
end_function

begin_comment
comment|/*  * Return the largest uint value log such that 2^log<= num.  */
end_comment

begin_function
specifier|static
name|unsigned
name|int
name|ilog2
parameter_list|(
name|unsigned
name|int
name|num
parameter_list|)
block|{
name|int
name|lz
decl_stmt|;
asm|__asm ("cntlzw %0, %1" : "=r" (lz) : "r" (num));
return|return
operator|(
literal|31
operator|-
name|lz
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Convert TLB TSIZE value to mapped region size.  */
end_comment

begin_function
specifier|static
name|vm_size_t
name|tsize2size
parameter_list|(
name|unsigned
name|int
name|tsize
parameter_list|)
block|{
comment|/* 	 * size = 4^tsize KB 	 * size = 4^tsize * 2^10 = 2^(2 * tsize - 10) 	 */
return|return
operator|(
operator|(
literal|1
operator|<<
operator|(
literal|2
operator|*
name|tsize
operator|)
operator|)
operator|*
literal|1024
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Convert region size (must be power of 4) to TLB TSIZE value.  */
end_comment

begin_function
specifier|static
name|unsigned
name|int
name|size2tsize
parameter_list|(
name|vm_size_t
name|size
parameter_list|)
block|{
return|return
operator|(
name|ilog2
argument_list|(
name|size
argument_list|)
operator|/
literal|2
operator|-
literal|5
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Register permanent kernel mapping in TLB1.  *  * Entries are created starting from index 0 (current free entry is  * kept in tlb1_idx) and are not supposed to be invalidated.  */
end_comment

begin_function
specifier|static
name|int
name|tlb1_set_entry
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|uint32_t
name|flags
parameter_list|)
block|{
name|uint32_t
name|ts
decl_stmt|,
name|tid
decl_stmt|;
name|int
name|tsize
decl_stmt|;
if|if
condition|(
name|tlb1_idx
operator|>=
name|TLB1_ENTRIES
condition|)
block|{
name|printf
argument_list|(
literal|"tlb1_set_entry: TLB1 full!\n"
argument_list|)
expr_stmt|;
return|return
operator|(
operator|-
literal|1
operator|)
return|;
block|}
comment|/* Convert size to TSIZE */
name|tsize
operator|=
name|size2tsize
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|tid
operator|=
operator|(
name|TID_KERNEL
operator|<<
name|MAS1_TID_SHIFT
operator|)
operator|&
name|MAS1_TID_MASK
expr_stmt|;
comment|/* XXX TS is hard coded to 0 for now as we only use single address space */
name|ts
operator|=
operator|(
literal|0
operator|<<
name|MAS1_TS_SHIFT
operator|)
operator|&
name|MAS1_TS_MASK
expr_stmt|;
comment|/* XXX LOCK tlb1[] */
name|tlb1
index|[
name|tlb1_idx
index|]
operator|.
name|mas1
operator|=
name|MAS1_VALID
operator||
name|MAS1_IPROT
operator||
name|ts
operator||
name|tid
expr_stmt|;
name|tlb1
index|[
name|tlb1_idx
index|]
operator|.
name|mas1
operator||=
operator|(
operator|(
name|tsize
operator|<<
name|MAS1_TSIZE_SHIFT
operator|)
operator|&
name|MAS1_TSIZE_MASK
operator|)
expr_stmt|;
name|tlb1
index|[
name|tlb1_idx
index|]
operator|.
name|mas2
operator|=
operator|(
name|va
operator|&
name|MAS2_EPN_MASK
operator|)
operator||
name|flags
expr_stmt|;
comment|/* Set supervisor RWX permission bits */
name|tlb1
index|[
name|tlb1_idx
index|]
operator|.
name|mas3
operator|=
operator|(
name|pa
operator|&
name|MAS3_RPN
operator|)
operator||
name|MAS3_SR
operator||
name|MAS3_SW
operator||
name|MAS3_SX
expr_stmt|;
name|tlb1_write_entry
argument_list|(
name|tlb1_idx
operator|++
argument_list|)
expr_stmt|;
comment|/* XXX UNLOCK tlb1[] */
comment|/* 	 * XXX in general TLB1 updates should be propagated between CPUs, 	 * since current design assumes to have the same TLB1 set-up on all 	 * cores. 	 */
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|tlb1_entry_size_cmp
parameter_list|(
specifier|const
name|void
modifier|*
name|a
parameter_list|,
specifier|const
name|void
modifier|*
name|b
parameter_list|)
block|{
specifier|const
name|vm_size_t
modifier|*
name|sza
decl_stmt|;
specifier|const
name|vm_size_t
modifier|*
name|szb
decl_stmt|;
name|sza
operator|=
name|a
expr_stmt|;
name|szb
operator|=
name|b
expr_stmt|;
if|if
condition|(
operator|*
name|sza
operator|>
operator|*
name|szb
condition|)
return|return
operator|(
operator|-
literal|1
operator|)
return|;
elseif|else
if|if
condition|(
operator|*
name|sza
operator|<
operator|*
name|szb
condition|)
return|return
operator|(
literal|1
operator|)
return|;
else|else
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Map in contiguous RAM region into the TLB1 using maximum of  * KERNEL_REGION_MAX_TLB_ENTRIES entries.  *  * If necessary round up last entry size and return total size  * used by all allocated entries.  */
end_comment

begin_function
name|vm_size_t
name|tlb1_mapin_region
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|vm_size_t
name|entry_size
index|[
name|KERNEL_REGION_MAX_TLB_ENTRIES
index|]
decl_stmt|;
name|vm_size_t
name|mapped_size
decl_stmt|,
name|sz
decl_stmt|,
name|esz
decl_stmt|;
name|unsigned
name|int
name|log
decl_stmt|;
name|int
name|i
decl_stmt|;
name|CTR4
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: region size = 0x%08x va = 0x%08x pa = 0x%08x"
argument_list|,
name|__func__
argument_list|,
name|size
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|mapped_size
operator|=
literal|0
expr_stmt|;
name|sz
operator|=
name|size
expr_stmt|;
name|memset
argument_list|(
name|entry_size
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|entry_size
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Calculate entry sizes. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|KERNEL_REGION_MAX_TLB_ENTRIES
operator|&&
name|sz
operator|>
literal|0
condition|;
name|i
operator|++
control|)
block|{
comment|/* Largest region that is power of 4 and fits within size */
name|log
operator|=
name|ilog2
argument_list|(
name|sz
argument_list|)
operator|/
literal|2
expr_stmt|;
name|esz
operator|=
literal|1
operator|<<
operator|(
literal|2
operator|*
name|log
operator|)
expr_stmt|;
comment|/* If this is last entry cover remaining size. */
if|if
condition|(
name|i
operator|==
name|KERNEL_REGION_MAX_TLB_ENTRIES
operator|-
literal|1
condition|)
block|{
while|while
condition|(
name|esz
operator|<
name|sz
condition|)
name|esz
operator|=
name|esz
operator|<<
literal|2
expr_stmt|;
block|}
name|entry_size
index|[
name|i
index|]
operator|=
name|esz
expr_stmt|;
name|mapped_size
operator|+=
name|esz
expr_stmt|;
if|if
condition|(
name|esz
operator|<
name|sz
condition|)
name|sz
operator|-=
name|esz
expr_stmt|;
else|else
name|sz
operator|=
literal|0
expr_stmt|;
block|}
comment|/* Sort entry sizes, required to get proper entry address alignment. */
name|qsort
argument_list|(
name|entry_size
argument_list|,
name|KERNEL_REGION_MAX_TLB_ENTRIES
argument_list|,
sizeof|sizeof
argument_list|(
name|vm_size_t
argument_list|)
argument_list|,
name|tlb1_entry_size_cmp
argument_list|)
expr_stmt|;
comment|/* Load TLB1 entries. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|KERNEL_REGION_MAX_TLB_ENTRIES
condition|;
name|i
operator|++
control|)
block|{
name|esz
operator|=
name|entry_size
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
operator|!
name|esz
condition|)
break|break;
name|CTR5
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: entry %d: sz  = 0x%08x (va = 0x%08x "
literal|"pa = 0x%08x)"
argument_list|,
name|__func__
argument_list|,
name|tlb1_idx
argument_list|,
name|esz
argument_list|,
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|tlb1_set_entry
argument_list|(
name|va
argument_list|,
name|pa
argument_list|,
name|esz
argument_list|,
name|_TLB_ENTRY_MEM
argument_list|)
expr_stmt|;
name|va
operator|+=
name|esz
expr_stmt|;
name|pa
operator|+=
name|esz
expr_stmt|;
block|}
name|CTR3
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"%s: mapped size 0x%08x (wasted space 0x%08x)"
argument_list|,
name|__func__
argument_list|,
name|mapped_size
argument_list|,
name|mapped_size
operator|-
name|size
argument_list|)
expr_stmt|;
return|return
operator|(
name|mapped_size
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * TLB1 initialization routine, to be called after the very first  * assembler level setup done in locore.S.  */
end_comment

begin_function
name|void
name|tlb1_init
parameter_list|(
name|vm_offset_t
name|ccsrbar
parameter_list|)
block|{
name|uint32_t
name|mas0
decl_stmt|;
comment|/* TLB1[1] is used to map the kernel. Save that entry. */
name|mas0
operator|=
name|MAS0_TLBSEL
argument_list|(
literal|1
argument_list|)
operator||
name|MAS0_ESEL
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|mtspr
argument_list|(
name|SPR_MAS0
argument_list|,
name|mas0
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync; tlbre");
name|tlb1
index|[
literal|1
index|]
operator|.
name|mas1
operator|=
name|mfspr
argument_list|(
name|SPR_MAS1
argument_list|)
expr_stmt|;
name|tlb1
index|[
literal|1
index|]
operator|.
name|mas2
operator|=
name|mfspr
argument_list|(
name|SPR_MAS2
argument_list|)
expr_stmt|;
name|tlb1
index|[
literal|1
index|]
operator|.
name|mas3
operator|=
name|mfspr
argument_list|(
name|SPR_MAS3
argument_list|)
expr_stmt|;
comment|/* Map in CCSRBAR in TLB1[0] */
name|tlb1_idx
operator|=
literal|0
expr_stmt|;
name|tlb1_set_entry
argument_list|(
name|CCSRBAR_VA
argument_list|,
name|ccsrbar
argument_list|,
name|CCSRBAR_SIZE
argument_list|,
name|_TLB_ENTRY_IO
argument_list|)
expr_stmt|;
comment|/* 	 * Set the next available TLB1 entry index. Note TLB[1] is reserved 	 * for initial mapping of kernel text+data, which was set early in 	 * locore, we need to skip this [busy] entry. 	 */
name|tlb1_idx
operator|=
literal|2
expr_stmt|;
comment|/* Setup TLB miss defaults */
name|set_mas4_defaults
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Setup MAS4 defaults.  * These values are loaded to MAS0-2 on a TLB miss.  */
end_comment

begin_function
specifier|static
name|void
name|set_mas4_defaults
parameter_list|(
name|void
parameter_list|)
block|{
name|uint32_t
name|mas4
decl_stmt|;
comment|/* Defaults: TLB0, PID0, TSIZED=4K */
name|mas4
operator|=
name|MAS4_TLBSELD0
expr_stmt|;
name|mas4
operator||=
operator|(
name|TLB_SIZE_4K
operator|<<
name|MAS4_TSIZED_SHIFT
operator|)
operator|&
name|MAS4_TSIZED_MASK
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|mas4
operator||=
name|MAS4_MD
expr_stmt|;
endif|#
directive|endif
name|mtspr
argument_list|(
name|SPR_MAS4
argument_list|,
name|mas4
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync");
block|}
end_function

begin_comment
comment|/*  * Print out contents of the MAS registers for each TLB1 entry  */
end_comment

begin_function
name|void
name|tlb1_print_tlbentries
parameter_list|(
name|void
parameter_list|)
block|{
name|uint32_t
name|mas0
decl_stmt|,
name|mas1
decl_stmt|,
name|mas2
decl_stmt|,
name|mas3
decl_stmt|,
name|mas7
decl_stmt|;
name|int
name|i
decl_stmt|;
name|debugf
argument_list|(
literal|"TLB1 entries:\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|TLB1_ENTRIES
condition|;
name|i
operator|++
control|)
block|{
name|mas0
operator|=
name|MAS0_TLBSEL
argument_list|(
literal|1
argument_list|)
operator||
name|MAS0_ESEL
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|mtspr
argument_list|(
name|SPR_MAS0
argument_list|,
name|mas0
argument_list|)
expr_stmt|;
asm|__asm __volatile("isync; tlbre");
name|mas1
operator|=
name|mfspr
argument_list|(
name|SPR_MAS1
argument_list|)
expr_stmt|;
name|mas2
operator|=
name|mfspr
argument_list|(
name|SPR_MAS2
argument_list|)
expr_stmt|;
name|mas3
operator|=
name|mfspr
argument_list|(
name|SPR_MAS3
argument_list|)
expr_stmt|;
name|mas7
operator|=
name|mfspr
argument_list|(
name|SPR_MAS7
argument_list|)
expr_stmt|;
name|tlb_print_entry
argument_list|(
name|i
argument_list|,
name|mas1
argument_list|,
name|mas2
argument_list|,
name|mas3
argument_list|,
name|mas7
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Print out contents of the in-ram tlb1 table.  */
end_comment

begin_function
name|void
name|tlb1_print_entries
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|debugf
argument_list|(
literal|"tlb1[] table entries:\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|TLB1_ENTRIES
condition|;
name|i
operator|++
control|)
name|tlb_print_entry
argument_list|(
name|i
argument_list|,
name|tlb1
index|[
name|i
index|]
operator|.
name|mas1
argument_list|,
name|tlb1
index|[
name|i
index|]
operator|.
name|mas2
argument_list|,
name|tlb1
index|[
name|i
index|]
operator|.
name|mas3
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Return 0 if the physical IO range is encompassed by one of the  * the TLB1 entries, otherwise return related error code.  */
end_comment

begin_function
specifier|static
name|int
name|tlb1_iomapped
parameter_list|(
name|int
name|i
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|vm_offset_t
modifier|*
name|va
parameter_list|)
block|{
name|uint32_t
name|prot
decl_stmt|;
name|vm_paddr_t
name|pa_start
decl_stmt|;
name|vm_paddr_t
name|pa_end
decl_stmt|;
name|unsigned
name|int
name|entry_tsize
decl_stmt|;
name|vm_size_t
name|entry_size
decl_stmt|;
operator|*
name|va
operator|=
operator|(
name|vm_offset_t
operator|)
name|NULL
expr_stmt|;
comment|/* Skip invalid entries */
if|if
condition|(
operator|!
operator|(
name|tlb1
index|[
name|i
index|]
operator|.
name|mas1
operator|&
name|MAS1_VALID
operator|)
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
comment|/* 	 * The entry must be cache-inhibited, guarded, and r/w 	 * so it can function as an i/o page 	 */
name|prot
operator|=
name|tlb1
index|[
name|i
index|]
operator|.
name|mas2
operator|&
operator|(
name|MAS2_I
operator||
name|MAS2_G
operator|)
expr_stmt|;
if|if
condition|(
name|prot
operator|!=
operator|(
name|MAS2_I
operator||
name|MAS2_G
operator|)
condition|)
return|return
operator|(
name|EPERM
operator|)
return|;
name|prot
operator|=
name|tlb1
index|[
name|i
index|]
operator|.
name|mas3
operator|&
operator|(
name|MAS3_SR
operator||
name|MAS3_SW
operator|)
expr_stmt|;
if|if
condition|(
name|prot
operator|!=
operator|(
name|MAS3_SR
operator||
name|MAS3_SW
operator|)
condition|)
return|return
operator|(
name|EPERM
operator|)
return|;
comment|/* The address should be within the entry range. */
name|entry_tsize
operator|=
operator|(
name|tlb1
index|[
name|i
index|]
operator|.
name|mas1
operator|&
name|MAS1_TSIZE_MASK
operator|)
operator|>>
name|MAS1_TSIZE_SHIFT
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|entry_tsize
operator|)
argument_list|,
operator|(
literal|"tlb1_iomapped: invalid entry tsize"
operator|)
argument_list|)
expr_stmt|;
name|entry_size
operator|=
name|tsize2size
argument_list|(
name|entry_tsize
argument_list|)
expr_stmt|;
name|pa_start
operator|=
name|tlb1
index|[
name|i
index|]
operator|.
name|mas3
operator|&
name|MAS3_RPN
expr_stmt|;
name|pa_end
operator|=
name|pa_start
operator|+
name|entry_size
operator|-
literal|1
expr_stmt|;
if|if
condition|(
operator|(
name|pa
operator|<
name|pa_start
operator|)
operator|||
operator|(
operator|(
name|pa
operator|+
name|size
operator|)
operator|>
name|pa_end
operator|)
condition|)
return|return
operator|(
name|ERANGE
operator|)
return|;
comment|/* Return virtual address of this mapping. */
operator|*
name|va
operator|=
operator|(
name|tlb1
index|[
name|i
index|]
operator|.
name|mas2
operator|&
name|MAS2_EPN_MASK
operator|)
operator|+
operator|(
name|pa
operator|-
name|pa_start
operator|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

end_unit

