begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*   * Copyright (c) 1991 Regents of the University of California.  * All rights reserved.  * Copyright (c) John S. Dyson  * All rights reserved.  * Copyright (c) David Greenman  * All rights reserved.  *  * This code is derived from software contributed to Berkeley by  * The Mach Operating System project at Carnegie-Mellon University.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. All advertising materials mentioning features or use of this software  *    must display the following acknowledgement:  *	This product includes software developed by the University of  *	California, Berkeley and its contributors.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	@(#)vm_fault.c	7.6 (Berkeley) 5/7/91  *  *  * Copyright (c) 1987, 1990 Carnegie-Mellon University.  * All rights reserved.  *  * Authors: Avadis Tevanian, Jr., Michael Wayne Young  *   * Permission to use, copy, modify and distribute this software and  * its documentation is hereby granted, provided that both the copyright  * notice and this permission notice appear in all copies of the  * software, derivative works or modified versions, and any portions  * thereof, and that both notices appear in supporting documentation.  *   * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"   * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND   * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.  *   * Carnegie Mellon requests users of this software to return to  *  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU  *  School of Computer Science  *  Carnegie Mellon University  *  Pittsburgh PA 15213-3890  *  * any improvements or extensions that they make and grant Carnegie the  * rights to redistribute these changes.  */
end_comment

begin_comment
comment|/*  * $Id: vm_fault.c,v 1.13 1994/01/17 09:33:31 davidg Exp $  */
end_comment

begin_comment
comment|/*  *	Page fault handling module.  */
end_comment

begin_include
include|#
directive|include
file|"param.h"
end_include

begin_include
include|#
directive|include
file|"vm.h"
end_include

begin_include
include|#
directive|include
file|"vm_page.h"
end_include

begin_include
include|#
directive|include
file|"vm_pageout.h"
end_include

begin_include
include|#
directive|include
file|"proc.h"
end_include

begin_include
include|#
directive|include
file|"resource.h"
end_include

begin_include
include|#
directive|include
file|"resourcevar.h"
end_include

begin_define
define|#
directive|define
name|VM_FAULT_READ_AHEAD
value|3
end_define

begin_define
define|#
directive|define
name|VM_FAULT_READ_AHEAD_MIN
value|1
end_define

begin_define
define|#
directive|define
name|VM_FAULT_READ_BEHIND
value|2
end_define

begin_define
define|#
directive|define
name|VM_FAULT_READ
value|(VM_FAULT_READ_AHEAD+VM_FAULT_READ_BEHIND+1)
end_define

begin_decl_stmt
specifier|extern
name|int
name|swap_pager_full
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|int
name|vm_pageout_proc_limit
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_statistics_data_t
name|vm_stat
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  *	vm_fault:  *  *	Handle a page fault occuring at the given address,  *	requiring the given permissions, in the map specified.  *	If successful, the page is inserted into the  *	associated physical map.  *  *	NOTE: the given address should be truncated to the  *	proper page address.  *  *	KERN_SUCCESS is returned if the page fault is handled; otherwise,  *	a standard error specifying why the fault is fatal is returned.  *  *  *	The map in question must be referenced, and remains so.  *	Caller may hold no locks.  */
end_comment

begin_function
name|int
name|vm_fault
parameter_list|(
name|map
parameter_list|,
name|vaddr
parameter_list|,
name|fault_type
parameter_list|,
name|change_wiring
parameter_list|)
name|vm_map_t
name|map
decl_stmt|;
name|vm_offset_t
name|vaddr
decl_stmt|;
name|vm_prot_t
name|fault_type
decl_stmt|;
name|boolean_t
name|change_wiring
decl_stmt|;
block|{
name|vm_object_t
name|first_object
decl_stmt|;
name|vm_offset_t
name|first_offset
decl_stmt|;
name|vm_map_entry_t
name|entry
decl_stmt|;
specifier|register
name|vm_object_t
name|object
decl_stmt|;
specifier|register
name|vm_offset_t
name|offset
decl_stmt|;
specifier|register
name|vm_page_t
name|m
decl_stmt|;
name|vm_page_t
name|first_m
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
name|int
name|result
decl_stmt|;
name|boolean_t
name|wired
decl_stmt|;
name|boolean_t
name|su
decl_stmt|;
name|boolean_t
name|lookup_still_valid
decl_stmt|;
name|boolean_t
name|page_exists
decl_stmt|;
name|vm_page_t
name|old_m
decl_stmt|;
name|vm_object_t
name|next_object
decl_stmt|;
name|vm_page_t
name|marray
index|[
name|VM_FAULT_READ
index|]
decl_stmt|;
name|int
name|reqpage
decl_stmt|;
name|int
name|spl
decl_stmt|;
name|vm_stat
operator|.
name|faults
operator|++
expr_stmt|;
comment|/* needs lock XXX */
comment|/*  *	Recovery actions  */
define|#
directive|define
name|FREE_PAGE
parameter_list|(
name|m
parameter_list|)
value|{				\ 	PAGE_WAKEUP(m);					\ 	vm_page_lock_queues();				\ 	vm_page_free(m);				\ 	vm_page_unlock_queues();			\ }
define|#
directive|define
name|RELEASE_PAGE
parameter_list|(
name|m
parameter_list|)
value|{				\ 	PAGE_WAKEUP(m);					\ 	vm_page_lock_queues();				\ 	vm_page_activate(m);				\ 	vm_page_unlock_queues();			\ }
define|#
directive|define
name|UNLOCK_MAP
value|{				\ 	if (lookup_still_valid) {			\ 		vm_map_lookup_done(map, entry);		\ 		lookup_still_valid = FALSE;		\ 	}						\ }
define|#
directive|define
name|UNLOCK_THINGS
value|{				\ 	object->paging_in_progress--;			\ 	if (object->paging_in_progress == 0)		\ 		wakeup((caddr_t)object);		\ 	vm_object_unlock(object);			\ 	if (object != first_object) {			\ 		vm_object_lock(first_object);		\ 		FREE_PAGE(first_m);			\ 		first_object->paging_in_progress--;	\ 		if (first_object->paging_in_progress == 0) \ 			wakeup((caddr_t)first_object);	\ 		vm_object_unlock(first_object);		\ 	}						\ 	UNLOCK_MAP;					\ }
define|#
directive|define
name|UNLOCK_AND_DEALLOCATE
value|{			\ 	UNLOCK_THINGS;					\ 	vm_object_deallocate(first_object);		\ }
name|RetryFault
label|:
empty_stmt|;
comment|/* 	 *	Find the backing store object and offset into 	 *	it to begin the search. 	 */
if|if
condition|(
operator|(
name|result
operator|=
name|vm_map_lookup
argument_list|(
operator|&
name|map
argument_list|,
name|vaddr
argument_list|,
name|fault_type
argument_list|,
operator|&
name|entry
argument_list|,
operator|&
name|first_object
argument_list|,
operator|&
name|first_offset
argument_list|,
operator|&
name|prot
argument_list|,
operator|&
name|wired
argument_list|,
operator|&
name|su
argument_list|)
operator|)
operator|!=
name|KERN_SUCCESS
condition|)
block|{
return|return
operator|(
name|result
operator|)
return|;
block|}
name|lookup_still_valid
operator|=
name|TRUE
expr_stmt|;
if|if
condition|(
name|wired
condition|)
name|fault_type
operator|=
name|prot
expr_stmt|;
name|first_m
operator|=
name|NULL
expr_stmt|;
comment|/* 	 *	Make a reference to this object to 	 *	prevent its disposal while we are messing with 	 *	it.  Once we have the reference, the map is free 	 *	to be diddled.  Since objects reference their 	 *	shadows (and copies), they will stay around as well. 	 */
name|vm_object_lock
argument_list|(
name|first_object
argument_list|)
expr_stmt|;
name|first_object
operator|->
name|ref_count
operator|++
expr_stmt|;
name|first_object
operator|->
name|paging_in_progress
operator|++
expr_stmt|;
comment|/* 	 *	INVARIANTS (through entire routine): 	 * 	 *	1)	At all times, we must either have the object 	 *		lock or a busy page in some object to prevent 	 *		some other thread from trying to bring in 	 *		the same page. 	 * 	 *		Note that we cannot hold any locks during the 	 *		pager access or when waiting for memory, so 	 *		we use a busy page then. 	 * 	 *		Note also that we aren't as concerned about 	 *		more than one thead attempting to pager_data_unlock 	 *		the same page at once, so we don't hold the page 	 *		as busy then, but do record the highest unlock 	 *		value so far.  [Unlock requests may also be delivered 	 *		out of order.] 	 * 	 *	2)	Once we have a busy page, we must remove it from 	 *		the pageout queues, so that the pageout daemon 	 *		will not grab it away. 	 * 	 *	3)	To prevent another thread from racing us down the 	 *		shadow chain and entering a new page in the top 	 *		object before we do, we must keep a busy page in 	 *		the top object while following the shadow chain. 	 * 	 *	4)	We must increment paging_in_progress on any object 	 *		for which we have a busy page, to prevent 	 *		vm_object_collapse from removing the busy page 	 *		without our noticing. 	 */
comment|/* 	 *	Search for the page at object/offset. 	 */
name|object
operator|=
name|first_object
expr_stmt|;
name|offset
operator|=
name|first_offset
expr_stmt|;
comment|/* 	 *	See whether this page is resident 	 */
while|while
condition|(
name|TRUE
condition|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|!=
name|NULL
condition|)
block|{
comment|/* 			 *	If the page is being brought in, 			 *	wait for it and then retry. 			 */
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_BUSY
condition|)
block|{
name|UNLOCK_THINGS
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_BUSY
condition|)
block|{
name|m
operator|->
name|flags
operator||=
name|PG_WANTED
expr_stmt|;
name|tsleep
argument_list|(
operator|(
name|caddr_t
operator|)
name|m
argument_list|,
name|PSWP
argument_list|,
literal|"vmpfw"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|vm_object_deallocate
argument_list|(
name|first_object
argument_list|)
expr_stmt|;
goto|goto
name|RetryFault
goto|;
block|}
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_ABSENT
condition|)
name|panic
argument_list|(
literal|"vm_fault: absent"
argument_list|)
expr_stmt|;
comment|/* 			 *	Remove the page from the pageout daemon's 			 *	reach while we play with it. 			 */
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|spl
operator|=
name|vm_disable_intr
argument_list|()
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_INACTIVE
condition|)
block|{
name|queue_remove
argument_list|(
operator|&
name|vm_page_queue_inactive
argument_list|,
name|m
argument_list|,
name|vm_page_t
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_INACTIVE
expr_stmt|;
name|vm_page_inactive_count
operator|--
expr_stmt|;
name|vm_stat
operator|.
name|reactivations
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_ACTIVE
condition|)
block|{
name|queue_remove
argument_list|(
operator|&
name|vm_page_queue_active
argument_list|,
name|m
argument_list|,
name|vm_page_t
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ACTIVE
expr_stmt|;
name|vm_page_active_count
operator|--
expr_stmt|;
block|}
name|vm_set_intr
argument_list|(
name|spl
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
comment|/* 			 *	Mark page busy for other threads. 			 */
name|m
operator|->
name|flags
operator||=
name|PG_BUSY
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ABSENT
expr_stmt|;
break|break;
block|}
if|if
condition|(
operator|(
operator|(
name|object
operator|->
name|pager
operator|!=
name|NULL
operator|)
operator|&&
operator|(
operator|!
name|change_wiring
operator|||
name|wired
operator|)
operator|)
operator|||
operator|(
name|object
operator|==
name|first_object
operator|)
condition|)
block|{
if|#
directive|if
literal|0
block|if (curproc&& (vaddr< VM_MAXUSER_ADDRESS)&& 				(curproc->p_rlimit[RLIMIT_RSS].rlim_max< 			    curproc->p_vmspace->vm_pmap.pm_stats.resident_count * NBPG)) { 				UNLOCK_AND_DEALLOCATE; 				vm_fault_free_pages(curproc); 				goto RetryFault; 			}
endif|#
directive|endif
if|if
condition|(
name|swap_pager_full
operator|&&
operator|!
name|object
operator|->
name|shadow
operator|&&
operator|(
operator|!
name|object
operator|->
name|pager
operator|||
operator|(
name|object
operator|->
name|pager
operator|&&
name|object
operator|->
name|pager
operator|->
name|pg_type
operator|==
name|PG_SWAP
operator|&&
operator|!
name|vm_pager_has_page
argument_list|(
name|object
operator|->
name|pager
argument_list|,
name|offset
operator|+
name|object
operator|->
name|paging_offset
argument_list|)
operator|)
operator|)
condition|)
block|{
if|if
condition|(
name|vaddr
operator|<
name|VM_MAXUSER_ADDRESS
operator|&&
name|curproc
operator|&&
name|curproc
operator|->
name|p_pid
operator|>=
literal|48
condition|)
comment|/* XXX */
block|{
name|UNLOCK_AND_DEALLOCATE
expr_stmt|;
name|printf
argument_list|(
literal|"Process %d killed by vm_fault -- out of swap\n"
argument_list|,
name|curproc
operator|->
name|p_pid
argument_list|)
expr_stmt|;
name|psignal
argument_list|(
name|curproc
argument_list|,
name|SIGKILL
argument_list|)
expr_stmt|;
return|return
name|KERN_RESOURCE_SHORTAGE
return|;
block|}
block|}
comment|/* 			 *	Allocate a new page for this object/offset 			 *	pair. 			 */
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|object
argument_list|,
name|offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|UNLOCK_AND_DEALLOCATE
expr_stmt|;
name|VM_WAIT
expr_stmt|;
goto|goto
name|RetryFault
goto|;
block|}
block|}
if|if
condition|(
operator|(
name|object
operator|->
name|pager
operator|!=
name|NULL
operator|)
operator|&&
operator|(
operator|!
name|change_wiring
operator|||
name|wired
operator|)
condition|)
block|{
name|int
name|rv
decl_stmt|;
name|int
name|faultcount
decl_stmt|;
name|int
name|reqpage
decl_stmt|;
comment|/* 			 *	Now that we have a busy page, we can 			 *	release the object lock. 			 */
name|vm_object_unlock
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 			 * now we find out if any other pages should 			 * be paged in at this time 			 * this routine checks to see if the pages surrounding this fault 			 * reside in the same object as the page for this fault.  If 			 * they do, then they are faulted in also into the 			 * object.  The array "marray" returned contains an array of vm_page_t structs 			 * where one of them is the vm_page_t passed to the routine.  The reqpage 			 * return value is the index into the marray for the vm_page_t passed to the 			 * routine. 			 */
name|faultcount
operator|=
name|vm_fault_additional_pages
argument_list|(
name|first_object
argument_list|,
name|first_offset
argument_list|,
name|m
argument_list|,
name|VM_FAULT_READ_BEHIND
argument_list|,
name|VM_FAULT_READ_AHEAD
argument_list|,
name|marray
argument_list|,
operator|&
name|reqpage
argument_list|)
expr_stmt|;
comment|/* 			 *	Call the pager to retrieve the data, if any, 			 *	after releasing the lock on the map. 			 */
name|UNLOCK_MAP
expr_stmt|;
if|if
condition|(
name|faultcount
operator|!=
literal|1
condition|)
block|{
name|rv
operator|=
name|faultcount
condition|?
name|vm_pager_getmulti
argument_list|(
name|object
operator|->
name|pager
argument_list|,
name|marray
argument_list|,
name|faultcount
argument_list|,
name|reqpage
argument_list|,
name|TRUE
argument_list|)
else|:
name|VM_PAGER_FAIL
expr_stmt|;
block|}
else|else
block|{
name|rv
operator|=
name|vm_pager_get
argument_list|(
name|object
operator|->
name|pager
argument_list|,
name|m
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|rv
operator|==
name|VM_PAGER_OK
condition|)
block|{
comment|/* 				 *	Found the page. 				 *	Leave it busy while we play with it. 				 */
name|vm_object_lock
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 				 *	Relookup in case pager changed page. 				 *	Pager is responsible for disposition 				 *	of old page if moved. 				 */
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|vm_stat
operator|.
name|pageins
operator|++
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_FAKE
expr_stmt|;
name|pmap_clear_modify
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
break|break;
block|}
comment|/* 			 *	Remove the bogus page (which does not 			 *	exist at this object/offset); before 			 *	doing so, we must get back our object 			 *	lock to preserve our invariant. 			 * 			 *	Also wake up any other thread that may want 			 *	to bring in this page. 			 * 			 *	If this is the top-level object, we must 			 *	leave the busy page to prevent another 			 *	thread from rushing past us, and inserting 			 *	the page in that object at the same time 			 *	that we are. 			 */
name|vm_object_lock
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 			 * Data outside the range of the pager; an error 			 */
if|if
condition|(
name|rv
operator|==
name|VM_PAGER_BAD
condition|)
block|{
name|FREE_PAGE
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|UNLOCK_AND_DEALLOCATE
expr_stmt|;
return|return
operator|(
name|KERN_PROTECTION_FAILURE
operator|)
return|;
comment|/* XXX */
block|}
if|if
condition|(
name|object
operator|!=
name|first_object
condition|)
block|{
name|FREE_PAGE
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 				 * XXX - we cannot just fall out at this 				 * point, m has been freed and is invalid! 				 */
block|}
block|}
comment|/* 		 * We get here if the object has no pager (or unwiring) 		 * or the pager doesn't have the page. 		 */
if|if
condition|(
name|object
operator|==
name|first_object
condition|)
name|first_m
operator|=
name|m
expr_stmt|;
comment|/* 		 *	Move on to the next object.  Lock the next 		 *	object before unlocking the current one. 		 */
name|offset
operator|+=
name|object
operator|->
name|shadow_offset
expr_stmt|;
name|next_object
operator|=
name|object
operator|->
name|shadow
expr_stmt|;
if|if
condition|(
name|next_object
operator|==
name|NULL
condition|)
block|{
comment|/* 			 *	If there's no object left, fill the page 			 *	in the top object with zeros. 			 */
if|if
condition|(
name|object
operator|!=
name|first_object
condition|)
block|{
name|object
operator|->
name|paging_in_progress
operator|--
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|paging_in_progress
operator|==
literal|0
condition|)
name|wakeup
argument_list|(
operator|(
name|caddr_t
operator|)
name|object
argument_list|)
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|object
operator|=
name|first_object
expr_stmt|;
name|offset
operator|=
name|first_offset
expr_stmt|;
name|m
operator|=
name|first_m
expr_stmt|;
name|vm_object_lock
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
name|first_m
operator|=
name|NULL
expr_stmt|;
name|vm_page_zero_fill
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_stat
operator|.
name|zero_fill_count
operator|++
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
operator|~
operator|(
name|PG_FAKE
operator||
name|PG_ABSENT
operator|)
expr_stmt|;
break|break;
block|}
else|else
block|{
name|vm_object_lock
argument_list|(
name|next_object
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|first_object
condition|)
block|{
name|object
operator|->
name|paging_in_progress
operator|--
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|paging_in_progress
operator|==
literal|0
condition|)
name|wakeup
argument_list|(
operator|(
name|caddr_t
operator|)
name|object
argument_list|)
expr_stmt|;
block|}
name|vm_object_unlock
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|object
operator|=
name|next_object
expr_stmt|;
name|object
operator|->
name|paging_in_progress
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_ABSENT
operator||
name|PG_ACTIVE
operator||
name|PG_INACTIVE
operator|)
operator|!=
literal|0
operator|)
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_BUSY
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_fault: absent or active or inactive or not busy after main loop"
argument_list|)
expr_stmt|;
comment|/* 	 *	PAGE HAS BEEN FOUND. 	 *	[Loop invariant still holds -- the object lock 	 *	is held.] 	 */
name|old_m
operator|=
name|m
expr_stmt|;
comment|/* save page that would be copied */
comment|/* 	 *	If the page is being written, but isn't 	 *	already owned by the top-level object, 	 *	we have to copy it into a new page owned 	 *	by the top-level object. 	 */
if|if
condition|(
name|object
operator|!=
name|first_object
condition|)
block|{
comment|/* 		 *	We only really need to copy if we 		 *	want to write it. 		 */
if|if
condition|(
name|fault_type
operator|&
name|VM_PROT_WRITE
condition|)
block|{
comment|/* 			 *	If we try to collapse first_object at this 			 *	point, we may deadlock when we try to get 			 *	the lock on an intermediate object (since we 			 *	have the bottom object locked).  We can't 			 *	unlock the bottom object, because the page 			 *	we found may move (by collapse) if we do. 			 * 			 *	Instead, we first copy the page.  Then, when 			 *	we have no more use for the bottom object, 			 *	we unlock it and try to collapse. 			 * 			 *	Note that we copy the page even if we didn't 			 *	need to... that's the breaks. 			 */
comment|/* 			 *	We already have an empty page in 			 *	first_object - use it. 			 */
name|vm_page_copy
argument_list|(
name|m
argument_list|,
name|first_m
argument_list|)
expr_stmt|;
name|first_m
operator|->
name|flags
operator|&=
operator|~
operator|(
name|PG_FAKE
operator||
name|PG_ABSENT
operator|)
expr_stmt|;
comment|/* 			 *	If another map is truly sharing this 			 *	page with us, we have to flush all 			 *	uses of the original page, since we 			 *	can't distinguish those which want the 			 *	original from those which need the 			 *	new copy. 			 * 			 *	XXX If we know that only one map has 			 *	access to this page, then we could 			 *	avoid the pmap_page_protect() call. 			 */
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_activate
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_page_protect
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|VM_PROT_NONE
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CLEAN
operator|)
operator|==
literal|0
condition|)
name|m
operator|->
name|flags
operator||=
name|PG_LAUNDRY
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
comment|/* 			 *	We no longer need the old page or object. 			 */
name|PAGE_WAKEUP
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|object
operator|->
name|paging_in_progress
operator|--
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|paging_in_progress
operator|==
literal|0
condition|)
name|wakeup
argument_list|(
operator|(
name|caddr_t
operator|)
name|object
argument_list|)
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 			 *	Only use the new page below... 			 */
name|vm_stat
operator|.
name|cow_faults
operator|++
expr_stmt|;
name|m
operator|=
name|first_m
expr_stmt|;
name|object
operator|=
name|first_object
expr_stmt|;
name|offset
operator|=
name|first_offset
expr_stmt|;
comment|/* 			 *	Now that we've gotten the copy out of the 			 *	way, let's try to collapse the top object. 			 */
name|vm_object_lock
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 			 *	But we have to play ugly games with 			 *	paging_in_progress to do that... 			 */
name|object
operator|->
name|paging_in_progress
operator|--
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|paging_in_progress
operator|==
literal|0
condition|)
name|wakeup
argument_list|(
operator|(
name|caddr_t
operator|)
name|object
argument_list|)
expr_stmt|;
name|vm_object_collapse
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|object
operator|->
name|paging_in_progress
operator|++
expr_stmt|;
block|}
else|else
block|{
name|prot
operator|&=
operator|(
operator|~
name|VM_PROT_WRITE
operator|)
expr_stmt|;
name|m
operator|->
name|flags
operator||=
name|PG_COPY_ON_WRITE
expr_stmt|;
block|}
block|}
if|if
condition|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_ACTIVE
operator||
name|PG_INACTIVE
operator|)
condition|)
name|panic
argument_list|(
literal|"vm_fault: active or inactive before copy object handling"
argument_list|)
expr_stmt|;
comment|/* 	 *	If the page is being written, but hasn't been 	 *	copied to the copy-object, we have to copy it there. 	 */
name|RetryCopy
label|:
if|if
condition|(
name|first_object
operator|->
name|copy
operator|!=
name|NULL
condition|)
block|{
name|vm_object_t
name|copy_object
init|=
name|first_object
operator|->
name|copy
decl_stmt|;
name|vm_offset_t
name|copy_offset
decl_stmt|;
name|vm_page_t
name|copy_m
decl_stmt|;
comment|/* 		 *	We only need to copy if we want to write it. 		 */
if|if
condition|(
operator|(
name|fault_type
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
condition|)
block|{
name|prot
operator|&=
operator|~
name|VM_PROT_WRITE
expr_stmt|;
name|m
operator|->
name|flags
operator||=
name|PG_COPY_ON_WRITE
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 *	Try to get the lock on the copy_object. 			 */
if|if
condition|(
operator|!
name|vm_object_lock_try
argument_list|(
name|copy_object
argument_list|)
condition|)
block|{
name|vm_object_unlock
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* should spin a bit here... */
name|vm_object_lock
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|RetryCopy
goto|;
block|}
comment|/* 			 *	Make another reference to the copy-object, 			 *	to keep it from disappearing during the 			 *	copy. 			 */
name|copy_object
operator|->
name|ref_count
operator|++
expr_stmt|;
comment|/* 			 *	Does the page exist in the copy? 			 */
name|copy_offset
operator|=
name|first_offset
operator|-
name|copy_object
operator|->
name|shadow_offset
expr_stmt|;
name|copy_m
operator|=
name|vm_page_lookup
argument_list|(
name|copy_object
argument_list|,
name|copy_offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|page_exists
operator|=
operator|(
name|copy_m
operator|!=
name|NULL
operator|)
condition|)
block|{
if|if
condition|(
name|copy_m
operator|->
name|flags
operator|&
name|PG_BUSY
condition|)
block|{
comment|/* 					 *	If the page is being brought 					 *	in, wait for it and then retry. 					 */
name|PAGE_ASSERT_WAIT
argument_list|(
name|copy_m
argument_list|,
operator|!
name|change_wiring
argument_list|)
expr_stmt|;
name|RELEASE_PAGE
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|copy_object
operator|->
name|ref_count
operator|--
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|copy_object
argument_list|)
expr_stmt|;
name|UNLOCK_THINGS
expr_stmt|;
name|thread_block
argument_list|(
literal|"fltcpy"
argument_list|)
expr_stmt|;
name|vm_object_deallocate
argument_list|(
name|first_object
argument_list|)
expr_stmt|;
goto|goto
name|RetryFault
goto|;
block|}
block|}
comment|/* 			 *	If the page is not in memory (in the object) 			 *	and the object has a pager, we have to check 			 *	if the pager has the data in secondary 			 *	storage. 			 */
if|if
condition|(
operator|!
name|page_exists
condition|)
block|{
comment|/* 				 *	If we don't allocate a (blank) page 				 *	here... another thread could try 				 *	to page it in, allocate a page, and 				 *	then block on the busy page in its 				 *	shadow (first_object).  Then we'd 				 *	trip over the busy page after we 				 *	found that the copy_object's pager 				 *	doesn't have the page... 				 */
name|copy_m
operator|=
name|vm_page_alloc
argument_list|(
name|copy_object
argument_list|,
name|copy_offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|copy_m
operator|==
name|NULL
condition|)
block|{
comment|/* 					 *	Wait for a page, then retry. 					 */
name|RELEASE_PAGE
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|copy_object
operator|->
name|ref_count
operator|--
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|copy_object
argument_list|)
expr_stmt|;
name|UNLOCK_AND_DEALLOCATE
expr_stmt|;
name|VM_WAIT
expr_stmt|;
goto|goto
name|RetryFault
goto|;
block|}
if|if
condition|(
name|copy_object
operator|->
name|pager
operator|!=
name|NULL
condition|)
block|{
name|vm_object_unlock
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|copy_object
argument_list|)
expr_stmt|;
name|UNLOCK_MAP
expr_stmt|;
name|page_exists
operator|=
name|vm_pager_has_page
argument_list|(
name|copy_object
operator|->
name|pager
argument_list|,
operator|(
name|copy_offset
operator|+
name|copy_object
operator|->
name|paging_offset
operator|)
argument_list|)
expr_stmt|;
name|vm_object_lock
argument_list|(
name|copy_object
argument_list|)
expr_stmt|;
comment|/* 					 * Since the map is unlocked, someone 					 * else could have copied this object 					 * and put a different copy_object 					 * between the two.  Or, the last 					 * reference to the copy-object (other 					 * than the one we have) may have 					 * disappeared - if that has happened, 					 * we don't need to make the copy. 					 */
if|if
condition|(
name|copy_object
operator|->
name|shadow
operator|!=
name|object
operator|||
name|copy_object
operator|->
name|ref_count
operator|==
literal|1
condition|)
block|{
comment|/* 						 *	Gaah... start over! 						 */
name|FREE_PAGE
argument_list|(
name|copy_m
argument_list|)
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|copy_object
argument_list|)
expr_stmt|;
name|vm_object_deallocate
argument_list|(
name|copy_object
argument_list|)
expr_stmt|;
comment|/* may block */
name|vm_object_lock
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|RetryCopy
goto|;
block|}
name|vm_object_lock
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|page_exists
condition|)
block|{
comment|/* 						 *	We didn't need the page 						 */
name|FREE_PAGE
argument_list|(
name|copy_m
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
operator|!
name|page_exists
condition|)
block|{
comment|/* 				 *	Must copy page into copy-object. 				 */
name|vm_page_copy
argument_list|(
name|m
argument_list|,
name|copy_m
argument_list|)
expr_stmt|;
name|copy_m
operator|->
name|flags
operator|&=
operator|~
operator|(
name|PG_FAKE
operator||
name|PG_ABSENT
operator|)
expr_stmt|;
comment|/* 				 * Things to remember: 				 * 1. The copied page must be marked 'dirty' 				 *    so it will be paged out to the copy 				 *    object. 				 * 2. If the old page was in use by any users 				 *    of the copy-object, it must be removed 				 *    from all pmaps.  (We can't know which 				 *    pmaps use it.) 				 */
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_activate
argument_list|(
name|old_m
argument_list|)
expr_stmt|;
name|pmap_page_protect
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|old_m
argument_list|)
argument_list|,
name|VM_PROT_NONE
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|old_m
operator|->
name|flags
operator|&
name|PG_CLEAN
operator|)
operator|==
literal|0
condition|)
name|old_m
operator|->
name|flags
operator||=
name|PG_LAUNDRY
expr_stmt|;
name|copy_m
operator|->
name|flags
operator|&=
operator|~
name|PG_CLEAN
expr_stmt|;
name|vm_page_activate
argument_list|(
name|copy_m
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|PAGE_WAKEUP
argument_list|(
name|copy_m
argument_list|)
expr_stmt|;
block|}
comment|/* 			 *	The reference count on copy_object must be 			 *	at least 2: one for our extra reference, 			 *	and at least one from the outside world 			 *	(we checked that when we last locked 			 *	copy_object). 			 */
name|copy_object
operator|->
name|ref_count
operator|--
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|copy_object
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_COPY_ON_WRITE
expr_stmt|;
block|}
block|}
if|if
condition|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_ACTIVE
operator||
name|PG_INACTIVE
operator|)
condition|)
name|panic
argument_list|(
literal|"vm_fault: active or inactive before retrying lookup"
argument_list|)
expr_stmt|;
comment|/* 	 *	We must verify that the maps have not changed 	 *	since our last lookup. 	 */
if|if
condition|(
operator|!
name|lookup_still_valid
condition|)
block|{
name|vm_object_t
name|retry_object
decl_stmt|;
name|vm_offset_t
name|retry_offset
decl_stmt|;
name|vm_prot_t
name|retry_prot
decl_stmt|;
comment|/* 		 *	Since map entries may be pageable, make sure we can 		 *	take a page fault on them. 		 */
name|vm_object_unlock
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 		 *	To avoid trying to write_lock the map while another 		 *	thread has it read_locked (in vm_map_pageable), we 		 *	do not try for write permission.  If the page is 		 *	still writable, we will get write permission.  If it 		 *	is not, or has been marked needs_copy, we enter the 		 *	mapping without write permission, and will merely 		 *	take another fault. 		 */
name|result
operator|=
name|vm_map_lookup
argument_list|(
operator|&
name|map
argument_list|,
name|vaddr
argument_list|,
name|fault_type
operator|&
operator|~
name|VM_PROT_WRITE
argument_list|,
operator|&
name|entry
argument_list|,
operator|&
name|retry_object
argument_list|,
operator|&
name|retry_offset
argument_list|,
operator|&
name|retry_prot
argument_list|,
operator|&
name|wired
argument_list|,
operator|&
name|su
argument_list|)
expr_stmt|;
name|vm_object_lock
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 		 *	If we don't need the page any longer, put it on the 		 *	active list (the easiest thing to do here).  If no 		 *	one needs it, pageout will grab it eventually. 		 */
if|if
condition|(
name|result
operator|!=
name|KERN_SUCCESS
condition|)
block|{
name|RELEASE_PAGE
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|UNLOCK_AND_DEALLOCATE
expr_stmt|;
return|return
operator|(
name|result
operator|)
return|;
block|}
name|lookup_still_valid
operator|=
name|TRUE
expr_stmt|;
if|if
condition|(
operator|(
name|retry_object
operator|!=
name|first_object
operator|)
operator|||
operator|(
name|retry_offset
operator|!=
name|first_offset
operator|)
condition|)
block|{
name|RELEASE_PAGE
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|UNLOCK_AND_DEALLOCATE
expr_stmt|;
goto|goto
name|RetryFault
goto|;
block|}
comment|/* 		 *	Check whether the protection has changed or the object 		 *	has been copied while we left the map unlocked. 		 *	Changing from read to write permission is OK - we leave 		 *	the page write-protected, and catch the write fault. 		 *	Changing from write to read permission means that we 		 *	can't mark the page write-enabled after all. 		 */
name|prot
operator|&=
name|retry_prot
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_COPY_ON_WRITE
condition|)
name|prot
operator|&=
operator|~
name|VM_PROT_WRITE
expr_stmt|;
block|}
comment|/* 	 * (the various bits we're fiddling with here are locked by 	 * the object's lock) 	 */
comment|/* XXX This distorts the meaning of the copy_on_write bit */
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_COPY_ON_WRITE
expr_stmt|;
block|}
comment|/* 	 *	It's critically important that a wired-down page be faulted 	 *	only once in each map for which it is wired. 	 */
if|if
condition|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_ACTIVE
operator||
name|PG_INACTIVE
operator|)
condition|)
name|panic
argument_list|(
literal|"vm_fault: active or inactive before pmap_enter"
argument_list|)
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 	 *	Put this page into the physical map. 	 *	We had to do the unlock above because pmap_enter 	 *	may cause other faults.   We don't put the 	 *	page back on the active queue until later so 	 *	that the page-out daemon won't find us (yet). 	 */
name|pmap_enter
argument_list|(
name|map
operator|->
name|pmap
argument_list|,
name|vaddr
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|)
expr_stmt|;
comment|/* 	 *	If the page is not wired down, then put it where the 	 *	pageout daemon can find it. 	 */
name|vm_object_lock
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
if|if
condition|(
name|change_wiring
condition|)
block|{
if|if
condition|(
name|wired
condition|)
name|vm_page_wire
argument_list|(
name|m
argument_list|)
expr_stmt|;
else|else
name|vm_page_unwire
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|vm_page_activate
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pageout_deact_bump
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
comment|/* 	 *	Unlock everything, and return 	 */
name|PAGE_WAKEUP
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|UNLOCK_AND_DEALLOCATE
expr_stmt|;
return|return
operator|(
name|KERN_SUCCESS
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_fault_wire:  *  *	Wire down a range of virtual addresses in a map.  */
end_comment

begin_function
name|void
name|vm_fault_wire
parameter_list|(
name|map
parameter_list|,
name|start
parameter_list|,
name|end
parameter_list|)
name|vm_map_t
name|map
decl_stmt|;
name|vm_offset_t
name|start
decl_stmt|,
name|end
decl_stmt|;
block|{
specifier|register
name|vm_offset_t
name|va
decl_stmt|;
specifier|register
name|pmap_t
name|pmap
decl_stmt|;
name|pmap
operator|=
name|vm_map_pmap
argument_list|(
name|map
argument_list|)
expr_stmt|;
comment|/* 	 *	Inform the physical mapping system that the 	 *	range of addresses may not fault, so that 	 *	page tables and such can be locked down as well. 	 */
name|pmap_pageable
argument_list|(
name|pmap
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
comment|/* 	 *	We simulate a fault to get the page and enter it 	 *	in the physical map. 	 */
for|for
control|(
name|va
operator|=
name|start
init|;
name|va
operator|<
name|end
condition|;
name|va
operator|+=
name|PAGE_SIZE
control|)
block|{
operator|(
name|void
operator|)
name|vm_fault
argument_list|(
name|map
argument_list|,
name|va
argument_list|,
name|VM_PROT_NONE
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_fault_unwire:  *  *	Unwire a range of virtual addresses in a map.  */
end_comment

begin_function
name|void
name|vm_fault_unwire
parameter_list|(
name|map
parameter_list|,
name|start
parameter_list|,
name|end
parameter_list|)
name|vm_map_t
name|map
decl_stmt|;
name|vm_offset_t
name|start
decl_stmt|,
name|end
decl_stmt|;
block|{
specifier|register
name|vm_offset_t
name|va
decl_stmt|,
name|pa
decl_stmt|;
specifier|register
name|pmap_t
name|pmap
decl_stmt|;
name|pmap
operator|=
name|vm_map_pmap
argument_list|(
name|map
argument_list|)
expr_stmt|;
comment|/* 	 *	Since the pages are wired down, we must be able to 	 *	get their mappings from the physical map system. 	 */
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
for|for
control|(
name|va
operator|=
name|start
init|;
name|va
operator|<
name|end
condition|;
name|va
operator|+=
name|PAGE_SIZE
control|)
block|{
name|pa
operator|=
name|pmap_extract
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pa
operator|==
operator|(
name|vm_offset_t
operator|)
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"unwire: page not in pmap"
argument_list|)
expr_stmt|;
block|}
name|pmap_change_wiring
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
comment|/* 	 *	Inform the physical mapping system that the range 	 *	of addresses may fault, so that page tables and 	 *	such may be unwired themselves. 	 */
name|pmap_pageable
argument_list|(
name|pmap
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Routine:  *		vm_fault_copy_entry  *	Function:  *		Copy all of the pages from a wired-down map entry to another.  *  *	In/out conditions:  *		The source and destination maps must be locked for write.  *		The source map entry must be wired down (or be a sharing map  *		entry corresponding to a main map entry that is wired down).  */
end_comment

begin_function
name|void
name|vm_fault_copy_entry
parameter_list|(
name|dst_map
parameter_list|,
name|src_map
parameter_list|,
name|dst_entry
parameter_list|,
name|src_entry
parameter_list|)
name|vm_map_t
name|dst_map
decl_stmt|;
name|vm_map_t
name|src_map
decl_stmt|;
name|vm_map_entry_t
name|dst_entry
decl_stmt|;
name|vm_map_entry_t
name|src_entry
decl_stmt|;
block|{
name|vm_object_t
name|dst_object
decl_stmt|;
name|vm_object_t
name|src_object
decl_stmt|;
name|vm_offset_t
name|dst_offset
decl_stmt|;
name|vm_offset_t
name|src_offset
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
name|vm_offset_t
name|vaddr
decl_stmt|;
name|vm_page_t
name|dst_m
decl_stmt|;
name|vm_page_t
name|src_m
decl_stmt|;
ifdef|#
directive|ifdef
name|lint
name|src_map
operator|++
expr_stmt|;
endif|#
directive|endif
endif|lint
name|src_object
operator|=
name|src_entry
operator|->
name|object
operator|.
name|vm_object
expr_stmt|;
name|src_offset
operator|=
name|src_entry
operator|->
name|offset
expr_stmt|;
comment|/* 	 *	Create the top-level object for the destination entry. 	 *	(Doesn't actually shadow anything - we copy the pages 	 *	directly.) 	 */
name|dst_object
operator|=
name|vm_object_allocate
argument_list|(
call|(
name|vm_size_t
call|)
argument_list|(
name|dst_entry
operator|->
name|end
operator|-
name|dst_entry
operator|->
name|start
argument_list|)
argument_list|)
expr_stmt|;
name|dst_entry
operator|->
name|object
operator|.
name|vm_object
operator|=
name|dst_object
expr_stmt|;
name|dst_entry
operator|->
name|offset
operator|=
literal|0
expr_stmt|;
name|prot
operator|=
name|dst_entry
operator|->
name|max_protection
expr_stmt|;
comment|/* 	 *	Loop through all of the pages in the entry's range, copying 	 *	each one from the source object (it should be there) to the 	 *	destination object. 	 */
for|for
control|(
name|vaddr
operator|=
name|dst_entry
operator|->
name|start
operator|,
name|dst_offset
operator|=
literal|0
init|;
name|vaddr
operator|<
name|dst_entry
operator|->
name|end
condition|;
name|vaddr
operator|+=
name|PAGE_SIZE
operator|,
name|dst_offset
operator|+=
name|PAGE_SIZE
control|)
block|{
comment|/* 		 *	Allocate a page in the destination object 		 */
name|vm_object_lock
argument_list|(
name|dst_object
argument_list|)
expr_stmt|;
do|do
block|{
name|dst_m
operator|=
name|vm_page_alloc
argument_list|(
name|dst_object
argument_list|,
name|dst_offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|dst_m
operator|==
name|NULL
condition|)
block|{
name|vm_object_unlock
argument_list|(
name|dst_object
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|vm_object_lock
argument_list|(
name|dst_object
argument_list|)
expr_stmt|;
block|}
block|}
do|while
condition|(
name|dst_m
operator|==
name|NULL
condition|)
do|;
comment|/* 		 *	Find the page in the source object, and copy it in. 		 *	(Because the source is wired down, the page will be 		 *	in memory.) 		 */
name|vm_object_lock
argument_list|(
name|src_object
argument_list|)
expr_stmt|;
name|src_m
operator|=
name|vm_page_lookup
argument_list|(
name|src_object
argument_list|,
name|dst_offset
operator|+
name|src_offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|src_m
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"vm_fault_copy_wired: page missing"
argument_list|)
expr_stmt|;
name|vm_page_copy
argument_list|(
name|src_m
argument_list|,
name|dst_m
argument_list|)
expr_stmt|;
comment|/* 		 *	Enter it in the pmap... 		 */
name|vm_object_unlock
argument_list|(
name|src_object
argument_list|)
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|dst_object
argument_list|)
expr_stmt|;
name|pmap_enter
argument_list|(
name|dst_map
operator|->
name|pmap
argument_list|,
name|vaddr
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|dst_m
argument_list|)
argument_list|,
name|prot
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
comment|/* 		 *	Mark it no longer busy, and put it on the active list. 		 */
name|vm_object_lock
argument_list|(
name|dst_object
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_activate
argument_list|(
name|dst_m
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|PAGE_WAKEUP
argument_list|(
name|dst_m
argument_list|)
expr_stmt|;
name|vm_object_unlock
argument_list|(
name|dst_object
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * looks page up in shadow chain  */
end_comment

begin_function
name|int
name|vm_fault_page_lookup
parameter_list|(
name|object
parameter_list|,
name|offset
parameter_list|,
name|rtobject
parameter_list|,
name|rtoffset
parameter_list|,
name|rtm
parameter_list|)
name|vm_object_t
name|object
decl_stmt|;
name|vm_offset_t
name|offset
decl_stmt|;
name|vm_object_t
modifier|*
name|rtobject
decl_stmt|;
name|vm_offset_t
modifier|*
name|rtoffset
decl_stmt|;
name|vm_page_t
modifier|*
name|rtm
decl_stmt|;
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_object_t
name|first_object
init|=
name|object
decl_stmt|;
operator|*
name|rtm
operator|=
literal|0
expr_stmt|;
operator|*
name|rtobject
operator|=
literal|0
expr_stmt|;
operator|*
name|rtoffset
operator|=
literal|0
expr_stmt|;
while|while
condition|(
operator|!
operator|(
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|offset
argument_list|)
operator|)
condition|)
block|{
if|if
condition|(
name|object
operator|->
name|pager
condition|)
block|{
if|if
condition|(
name|vm_pager_has_page
argument_list|(
name|object
operator|->
name|pager
argument_list|,
name|object
operator|->
name|paging_offset
operator|+
name|offset
argument_list|)
condition|)
block|{
operator|*
name|rtobject
operator|=
name|object
expr_stmt|;
operator|*
name|rtoffset
operator|=
name|offset
expr_stmt|;
return|return
literal|1
return|;
block|}
block|}
if|if
condition|(
operator|!
name|object
operator|->
name|shadow
condition|)
return|return
literal|0
return|;
else|else
block|{
name|offset
operator|+=
name|object
operator|->
name|shadow_offset
expr_stmt|;
name|object
operator|=
name|object
operator|->
name|shadow
expr_stmt|;
block|}
block|}
operator|*
name|rtobject
operator|=
name|object
expr_stmt|;
operator|*
name|rtoffset
operator|=
name|offset
expr_stmt|;
operator|*
name|rtm
operator|=
name|m
expr_stmt|;
return|return
literal|1
return|;
block|}
end_function

begin_comment
comment|/*  * This routine checks around the requested page for other pages that  * might be able to be faulted in.  *  * Inputs:  *	first_object, first_offset, m, rbehind, rahead  *  * Outputs:  *  marray (array of vm_page_t), reqpage (index of requested page)  *  * Return value:  *  number of pages in marray  */
end_comment

begin_function
name|int
name|vm_fault_additional_pages
parameter_list|(
name|first_object
parameter_list|,
name|first_offset
parameter_list|,
name|m
parameter_list|,
name|rbehind
parameter_list|,
name|raheada
parameter_list|,
name|marray
parameter_list|,
name|reqpage
parameter_list|)
name|vm_object_t
name|first_object
decl_stmt|;
name|vm_offset_t
name|first_offset
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|rbehind
decl_stmt|;
name|int
name|raheada
decl_stmt|;
name|vm_page_t
modifier|*
name|marray
decl_stmt|;
name|int
modifier|*
name|reqpage
decl_stmt|;
block|{
name|int
name|i
decl_stmt|;
name|vm_page_t
name|tmpm
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|vm_offset_t
name|offset
decl_stmt|,
name|startoffset
decl_stmt|,
name|endoffset
decl_stmt|,
name|toffset
decl_stmt|,
name|size
decl_stmt|;
name|vm_object_t
name|rtobject
decl_stmt|;
name|vm_page_t
name|rtm
decl_stmt|;
name|vm_offset_t
name|rtoffset
decl_stmt|;
name|vm_offset_t
name|offsetdiff
decl_stmt|;
name|int
name|rahead
decl_stmt|;
name|int
name|treqpage
decl_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|offset
operator|=
name|m
operator|->
name|offset
expr_stmt|;
name|offsetdiff
operator|=
name|offset
operator|-
name|first_offset
expr_stmt|;
comment|/* 	 * if the requested page is not available, then give up now 	 */
if|if
condition|(
operator|!
name|vm_pager_has_page
argument_list|(
name|object
operator|->
name|pager
argument_list|,
name|object
operator|->
name|paging_offset
operator|+
name|offset
argument_list|)
condition|)
return|return
literal|0
return|;
comment|/* 	 * if there is no getmulti routine for this pager, then just allow 	 * one page to be read. 	 */
if|if
condition|(
operator|!
name|object
operator|->
name|pager
operator|->
name|pg_ops
operator|->
name|pgo_getmulti
condition|)
block|{
operator|*
name|reqpage
operator|=
literal|0
expr_stmt|;
name|marray
index|[
literal|0
index|]
operator|=
name|m
expr_stmt|;
return|return
literal|1
return|;
block|}
comment|/* 	 * try to do any readahead that we might have free pages for. 	 */
name|rahead
operator|=
name|raheada
expr_stmt|;
if|if
condition|(
name|rahead
operator|>
operator|(
name|vm_page_free_count
operator|-
name|vm_page_free_reserved
operator|)
condition|)
block|{
name|rahead
operator|=
name|vm_page_free_count
operator|-
name|vm_page_free_reserved
expr_stmt|;
name|rbehind
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|vm_page_free_count
operator|<
name|vm_page_free_min
condition|)
block|{
if|if
condition|(
name|rahead
operator|>
name|VM_FAULT_READ_AHEAD_MIN
condition|)
name|rahead
operator|=
name|VM_FAULT_READ_AHEAD_MIN
expr_stmt|;
name|rbehind
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * if we don't have any free pages, then just read one page. 	 */
if|if
condition|(
name|rahead
operator|<=
literal|0
condition|)
block|{
operator|*
name|reqpage
operator|=
literal|0
expr_stmt|;
name|marray
index|[
literal|0
index|]
operator|=
name|m
expr_stmt|;
return|return
literal|1
return|;
block|}
comment|/* 	 * scan backward for the read behind pages -- 	 * in memory or on disk not in same object 	 */
name|toffset
operator|=
name|offset
operator|-
name|NBPG
expr_stmt|;
name|startoffset
operator|=
name|offset
operator|-
name|rbehind
operator|*
name|NBPG
expr_stmt|;
while|while
condition|(
operator|(
call|(
name|int
call|)
argument_list|(
name|toffset
operator|+
name|NBPG
argument_list|)
operator|)
operator|>=
literal|0
operator|&&
name|toffset
operator|>=
name|startoffset
condition|)
block|{
if|if
condition|(
operator|!
name|vm_fault_page_lookup
argument_list|(
name|first_object
argument_list|,
name|toffset
operator|-
name|offsetdiff
argument_list|,
operator|&
name|rtobject
argument_list|,
operator|&
name|rtoffset
argument_list|,
operator|&
name|rtm
argument_list|)
operator|||
name|rtm
operator|!=
literal|0
operator|||
name|rtobject
operator|!=
name|object
condition|)
block|{
name|startoffset
operator|=
name|toffset
operator|+
name|NBPG
expr_stmt|;
break|break;
block|}
name|toffset
operator|-=
name|NBPG
expr_stmt|;
block|}
comment|/* 	 * scan forward for the read ahead pages -- 	 * in memory or on disk not in same object 	 */
name|toffset
operator|=
name|offset
operator|+
name|NBPG
expr_stmt|;
name|endoffset
operator|=
name|offset
operator|+
operator|(
name|rahead
operator|+
literal|1
operator|)
operator|*
name|NBPG
expr_stmt|;
while|while
condition|(
name|toffset
operator|<
name|object
operator|->
name|size
operator|&&
name|toffset
operator|<
name|endoffset
condition|)
block|{
if|if
condition|(
operator|!
name|vm_fault_page_lookup
argument_list|(
name|first_object
argument_list|,
name|toffset
operator|-
name|offsetdiff
argument_list|,
operator|&
name|rtobject
argument_list|,
operator|&
name|rtoffset
argument_list|,
operator|&
name|rtm
argument_list|)
operator|||
name|rtm
operator|!=
literal|0
operator|||
name|rtobject
operator|!=
name|object
condition|)
block|{
name|endoffset
operator|=
name|toffset
expr_stmt|;
break|break;
block|}
name|toffset
operator|+=
name|NBPG
expr_stmt|;
block|}
comment|/* calculate number of bytes of pages */
name|size
operator|=
operator|(
name|endoffset
operator|-
name|startoffset
operator|)
operator|/
name|NBPG
expr_stmt|;
comment|/* calculate the page offset of the required page */
name|treqpage
operator|=
operator|(
name|offset
operator|-
name|startoffset
operator|)
operator|/
name|NBPG
expr_stmt|;
comment|/* see if we have space (again) */
if|if
condition|(
name|vm_page_free_count
operator|>=
name|vm_page_free_reserved
operator|+
name|size
condition|)
block|{
name|bzero
argument_list|(
name|marray
argument_list|,
operator|(
name|rahead
operator|+
name|rbehind
operator|+
literal|1
operator|)
operator|*
sizeof|sizeof
argument_list|(
name|vm_page_t
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 		 * get our pages and don't block for them 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|size
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|!=
name|treqpage
condition|)
name|rtm
operator|=
name|vm_page_alloc
argument_list|(
name|object
argument_list|,
name|startoffset
operator|+
name|i
operator|*
name|NBPG
argument_list|)
expr_stmt|;
else|else
name|rtm
operator|=
name|m
expr_stmt|;
name|marray
index|[
name|i
index|]
operator|=
name|rtm
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|size
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|marray
index|[
name|i
index|]
operator|==
literal|0
condition|)
break|break;
block|}
comment|/* 		 * if we could not get our block of pages, then 		 * free the readahead/readbehind pages. 		 */
if|if
condition|(
name|i
operator|<
name|size
condition|)
block|{
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|size
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|!=
name|treqpage
operator|&&
name|marray
index|[
name|i
index|]
condition|)
name|FREE_PAGE
argument_list|(
name|marray
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
operator|*
name|reqpage
operator|=
literal|0
expr_stmt|;
name|marray
index|[
literal|0
index|]
operator|=
name|m
expr_stmt|;
return|return
literal|1
return|;
block|}
operator|*
name|reqpage
operator|=
name|treqpage
expr_stmt|;
return|return
name|size
return|;
block|}
operator|*
name|reqpage
operator|=
literal|0
expr_stmt|;
name|marray
index|[
literal|0
index|]
operator|=
name|m
expr_stmt|;
return|return
literal|1
return|;
block|}
end_function

end_unit

