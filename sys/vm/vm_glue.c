begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1991, 1993  *	The Regents of the University of California.  All rights reserved.  *  * This code is derived from software contributed to Berkeley by  * The Mach Operating System project at Carnegie-Mellon University.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from: @(#)vm_glue.c	8.6 (Berkeley) 1/5/94  *  *  * Copyright (c) 1987, 1990 Carnegie-Mellon University.  * All rights reserved.  *  * Permission to use, copy, modify and distribute this software and  * its documentation is hereby granted, provided that both the copyright  * notice and this permission notice appear in all copies of the  * software, derivative works or modified versions, and any portions  * thereof, and that both notices appear in supporting documentation.  *  * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"  * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND  * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.  *  * Carnegie Mellon requests users of this software to return to  *  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU  *  School of Computer Science  *  Carnegie Mellon University  *  Pittsburgh PA 15213-3890  *  * any improvements or extensions that they make and grant Carnegie the  * rights to redistribute these changes.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_vm.h"
end_include

begin_include
include|#
directive|include
file|"opt_kstack_pages.h"
end_include

begin_include
include|#
directive|include
file|"opt_kstack_max_pages.h"
end_include

begin_include
include|#
directive|include
file|"opt_kstack_usage_prof.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/limits.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/racct.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/sf_buf.h>
end_include

begin_include
include|#
directive|include
file|<sys/shm.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmem.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/_kstack_cache.h>
end_include

begin_include
include|#
directive|include
file|<sys/eventhandler.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/unistd.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/pmap.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/swap_pager.h>
end_include

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_ifndef
ifndef|#
directive|ifndef
name|NO_SWAPPING
end_ifndef

begin_function_decl
specifier|static
name|int
name|swapout
parameter_list|(
name|struct
name|proc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|swapclear
parameter_list|(
name|struct
name|proc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_thread_swapin
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_thread_swapout
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * MPSAFE  *  * WARNING!  This code calls vm_map_check_protection() which only checks  * the associated vm_map_entry range.  It does not determine whether the  * contents of the memory is actually readable or writable.  In most cases  * just checking the vm_map_entry is sufficient within the kernel's address  * space.  */
end_comment

begin_function
name|int
name|kernacc
parameter_list|(
name|addr
parameter_list|,
name|len
parameter_list|,
name|rw
parameter_list|)
name|void
modifier|*
name|addr
decl_stmt|;
name|int
name|len
decl_stmt|,
name|rw
decl_stmt|;
block|{
name|boolean_t
name|rv
decl_stmt|;
name|vm_offset_t
name|saddr
decl_stmt|,
name|eaddr
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|rw
operator|&
operator|~
name|VM_PROT_ALL
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"illegal ``rw'' argument to kernacc (%x)\n"
operator|,
name|rw
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
operator|>
name|kernel_map
operator|->
name|max_offset
operator|||
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
operator|<
operator|(
name|vm_offset_t
operator|)
name|addr
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
name|prot
operator|=
name|rw
expr_stmt|;
name|saddr
operator|=
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
argument_list|)
expr_stmt|;
name|eaddr
operator|=
name|round_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
argument_list|)
expr_stmt|;
name|vm_map_lock_read
argument_list|(
name|kernel_map
argument_list|)
expr_stmt|;
name|rv
operator|=
name|vm_map_check_protection
argument_list|(
name|kernel_map
argument_list|,
name|saddr
argument_list|,
name|eaddr
argument_list|,
name|prot
argument_list|)
expr_stmt|;
name|vm_map_unlock_read
argument_list|(
name|kernel_map
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|==
name|TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * MPSAFE  *  * WARNING!  This code calls vm_map_check_protection() which only checks  * the associated vm_map_entry range.  It does not determine whether the  * contents of the memory is actually readable or writable.  vmapbuf(),  * vm_fault_quick(), or copyin()/copout()/su*()/fu*() functions should be  * used in conjunction with this call.  */
end_comment

begin_function
name|int
name|useracc
parameter_list|(
name|addr
parameter_list|,
name|len
parameter_list|,
name|rw
parameter_list|)
name|void
modifier|*
name|addr
decl_stmt|;
name|int
name|len
decl_stmt|,
name|rw
decl_stmt|;
block|{
name|boolean_t
name|rv
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
name|vm_map_t
name|map
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|rw
operator|&
operator|~
name|VM_PROT_ALL
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"illegal ``rw'' argument to useracc (%x)\n"
operator|,
name|rw
operator|)
argument_list|)
expr_stmt|;
name|prot
operator|=
name|rw
expr_stmt|;
name|map
operator|=
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_map
expr_stmt|;
if|if
condition|(
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
operator|>
name|vm_map_max
argument_list|(
name|map
argument_list|)
operator|||
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
operator|<
operator|(
name|vm_offset_t
operator|)
name|addr
condition|)
block|{
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
name|vm_map_lock_read
argument_list|(
name|map
argument_list|)
expr_stmt|;
name|rv
operator|=
name|vm_map_check_protection
argument_list|(
name|map
argument_list|,
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
argument_list|)
argument_list|,
name|round_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
argument_list|)
argument_list|,
name|prot
argument_list|)
expr_stmt|;
name|vm_map_unlock_read
argument_list|(
name|map
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|==
name|TRUE
operator|)
return|;
block|}
end_function

begin_function
name|int
name|vslock
parameter_list|(
name|void
modifier|*
name|addr
parameter_list|,
name|size_t
name|len
parameter_list|)
block|{
name|vm_offset_t
name|end
decl_stmt|,
name|last
decl_stmt|,
name|start
decl_stmt|;
name|vm_size_t
name|npages
decl_stmt|;
name|int
name|error
decl_stmt|;
name|last
operator|=
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
expr_stmt|;
name|start
operator|=
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
argument_list|)
expr_stmt|;
name|end
operator|=
name|round_page
argument_list|(
name|last
argument_list|)
expr_stmt|;
if|if
condition|(
name|last
operator|<
operator|(
name|vm_offset_t
operator|)
name|addr
operator|||
name|end
operator|<
operator|(
name|vm_offset_t
operator|)
name|addr
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|npages
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
if|if
condition|(
name|npages
operator|>
name|vm_page_max_wired
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
if|#
directive|if
literal|0
comment|/* 	 * XXX - not yet 	 * 	 * The limit for transient usage of wired pages should be 	 * larger than for "permanent" wired pages (mlock()). 	 * 	 * Also, the sysctl code, which is the only present user 	 * of vslock(), does a hard loop on EAGAIN. 	 */
block|if (npages + vm_cnt.v_wire_count> vm_page_max_wired) 		return (EAGAIN);
endif|#
directive|endif
name|error
operator|=
name|vm_map_wire
argument_list|(
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_map
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
name|VM_MAP_WIRE_SYSTEM
operator||
name|VM_MAP_WIRE_NOHOLES
argument_list|)
expr_stmt|;
comment|/* 	 * Return EFAULT on error to match copy{in,out}() behaviour 	 * rather than returning ENOMEM like mlock() would. 	 */
return|return
operator|(
name|error
operator|==
name|KERN_SUCCESS
condition|?
literal|0
else|:
name|EFAULT
operator|)
return|;
block|}
end_function

begin_function
name|void
name|vsunlock
parameter_list|(
name|void
modifier|*
name|addr
parameter_list|,
name|size_t
name|len
parameter_list|)
block|{
comment|/* Rely on the parameter sanity checks performed by vslock(). */
operator|(
name|void
operator|)
name|vm_map_unwire
argument_list|(
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_map
argument_list|,
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
argument_list|)
argument_list|,
name|round_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
argument_list|)
argument_list|,
name|VM_MAP_WIRE_SYSTEM
operator||
name|VM_MAP_WIRE_NOHOLES
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Pin the page contained within the given object at the given offset.  If the  * page is not resident, allocate and load it using the given object's pager.  * Return the pinned page if successful; otherwise, return NULL.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|vm_imgact_hold_page
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_ooffset_t
name|offset
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_pindex_t
name|pindex
decl_stmt|;
name|int
name|rv
decl_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|pindex
operator|=
name|OFF_TO_IDX
argument_list|(
name|offset
argument_list|)
expr_stmt|;
name|m
operator|=
name|vm_page_grab
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOBUSY
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|!=
name|VM_PAGE_BITS_ALL
condition|)
block|{
name|vm_page_xbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|rv
operator|=
name|vm_pager_get_pages
argument_list|(
name|object
argument_list|,
operator|&
name|m
argument_list|,
literal|1
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
operator|!=
name|VM_PAGER_OK
condition|)
block|{
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
goto|goto
name|out
goto|;
block|}
name|vm_page_xunbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_activate
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|out
label|:
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return a CPU private mapping to the page at the given offset within the  * given object.  The page is pinned before it is mapped.  */
end_comment

begin_function
name|struct
name|sf_buf
modifier|*
name|vm_imgact_map_page
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_ooffset_t
name|offset
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|vm_imgact_hold_page
argument_list|(
name|object
argument_list|,
name|offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|sched_pin
argument_list|()
expr_stmt|;
return|return
operator|(
name|sf_buf_alloc
argument_list|(
name|m
argument_list|,
name|SFB_CPUPRIVATE
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Destroy the given CPU private mapping and unpin the page that it mapped.  */
end_comment

begin_function
name|void
name|vm_imgact_unmap_page
parameter_list|(
name|struct
name|sf_buf
modifier|*
name|sf
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|sf_buf_page
argument_list|(
name|sf
argument_list|)
expr_stmt|;
name|sf_buf_free
argument_list|(
name|sf
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unhold
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_sync_icache
parameter_list|(
name|vm_map_t
name|map
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|sz
parameter_list|)
block|{
name|pmap_sync_icache
argument_list|(
name|map
operator|->
name|pmap
argument_list|,
name|va
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
end_function

begin_decl_stmt
name|struct
name|kstack_cache_entry
modifier|*
name|kstack_cache
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|kstack_cache_size
init|=
literal|128
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|kstacks
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|kstack_cache_mtx
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|MTX_SYSINIT
argument_list|(
name|kstack_cache
argument_list|,
operator|&
name|kstack_cache_mtx
argument_list|,
literal|"kstkch"
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|kstack_cache_size
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|kstack_cache_size
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|kstacks
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|kstacks
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_ifndef
ifndef|#
directive|ifndef
name|KSTACK_MAX_PAGES
end_ifndef

begin_define
define|#
directive|define
name|KSTACK_MAX_PAGES
value|32
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Create the kernel stack (including pcb for i386) for a new thread.  * This routine directly affects the fork perf for a process and  * create performance for a thread.  */
end_comment

begin_function
name|int
name|vm_thread_new
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|pages
parameter_list|)
block|{
name|vm_object_t
name|ksobj
decl_stmt|;
name|vm_offset_t
name|ks
decl_stmt|;
name|vm_page_t
name|ma
index|[
name|KSTACK_MAX_PAGES
index|]
decl_stmt|;
name|struct
name|kstack_cache_entry
modifier|*
name|ks_ce
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* Bounds check */
if|if
condition|(
name|pages
operator|<=
literal|1
condition|)
name|pages
operator|=
name|kstack_pages
expr_stmt|;
elseif|else
if|if
condition|(
name|pages
operator|>
name|KSTACK_MAX_PAGES
condition|)
name|pages
operator|=
name|KSTACK_MAX_PAGES
expr_stmt|;
if|if
condition|(
name|pages
operator|==
name|kstack_pages
condition|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|kstack_cache
operator|!=
name|NULL
condition|)
block|{
name|ks_ce
operator|=
name|kstack_cache
expr_stmt|;
name|kstack_cache
operator|=
name|ks_ce
operator|->
name|next_ks_entry
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_kstack_obj
operator|=
name|ks_ce
operator|->
name|ksobj
expr_stmt|;
name|td
operator|->
name|td_kstack
operator|=
operator|(
name|vm_offset_t
operator|)
name|ks_ce
expr_stmt|;
name|td
operator|->
name|td_kstack_pages
operator|=
name|kstack_pages
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Allocate an object for the kstack. 	 */
name|ksobj
operator|=
name|vm_object_allocate
argument_list|(
name|OBJT_DEFAULT
argument_list|,
name|pages
argument_list|)
expr_stmt|;
comment|/* 	 * Get a kernel virtual address for this thread's kstack. 	 */
if|#
directive|if
name|defined
argument_list|(
name|__mips__
argument_list|)
comment|/* 	 * We need to align the kstack's mapped address to fit within 	 * a single TLB entry. 	 */
if|if
condition|(
name|vmem_xalloc
argument_list|(
name|kernel_arena
argument_list|,
operator|(
name|pages
operator|+
name|KSTACK_GUARD_PAGES
operator|)
operator|*
name|PAGE_SIZE
argument_list|,
name|PAGE_SIZE
operator|*
literal|2
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|VMEM_ADDR_MIN
argument_list|,
name|VMEM_ADDR_MAX
argument_list|,
name|M_BESTFIT
operator||
name|M_NOWAIT
argument_list|,
operator|&
name|ks
argument_list|)
condition|)
block|{
name|ks
operator|=
literal|0
expr_stmt|;
block|}
else|#
directive|else
name|ks
operator|=
name|kva_alloc
argument_list|(
operator|(
name|pages
operator|+
name|KSTACK_GUARD_PAGES
operator|)
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|ks
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"vm_thread_new: kstack allocation failed\n"
argument_list|)
expr_stmt|;
name|vm_object_deallocate
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|atomic_add_int
argument_list|(
operator|&
name|kstacks
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|KSTACK_GUARD_PAGES
operator|!=
literal|0
condition|)
block|{
name|pmap_qremove
argument_list|(
name|ks
argument_list|,
name|KSTACK_GUARD_PAGES
argument_list|)
expr_stmt|;
name|ks
operator|+=
name|KSTACK_GUARD_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
block|}
name|td
operator|->
name|td_kstack_obj
operator|=
name|ksobj
expr_stmt|;
name|td
operator|->
name|td_kstack
operator|=
name|ks
expr_stmt|;
comment|/* 	 * Knowing the number of pages allocated is useful when you 	 * want to deallocate them. 	 */
name|td
operator|->
name|td_kstack_pages
operator|=
name|pages
expr_stmt|;
comment|/*  	 * For the length of the stack, link in a real page of ram for each 	 * page of stack. 	 */
name|VM_OBJECT_WLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
name|vm_page_grab_pages
argument_list|(
name|ksobj
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_WIRED
argument_list|,
name|ma
argument_list|,
name|pages
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pages
condition|;
name|i
operator|++
control|)
name|ma
index|[
name|i
index|]
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
name|ks
argument_list|,
name|ma
argument_list|,
name|pages
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vm_thread_stack_dispose
parameter_list|(
name|vm_object_t
name|ksobj
parameter_list|,
name|vm_offset_t
name|ks
parameter_list|,
name|int
name|pages
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|kstacks
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
name|ks
argument_list|,
name|pages
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|ksobj
argument_list|,
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"vm_thread_dispose: kstack already missing?"
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
name|PQ_NONE
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
name|vm_object_deallocate
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
name|kva_free
argument_list|(
name|ks
operator|-
operator|(
name|KSTACK_GUARD_PAGES
operator|*
name|PAGE_SIZE
operator|)
argument_list|,
operator|(
name|pages
operator|+
name|KSTACK_GUARD_PAGES
operator|)
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Dispose of a thread's kernel stack.  */
end_comment

begin_function
name|void
name|vm_thread_dispose
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|vm_object_t
name|ksobj
decl_stmt|;
name|vm_offset_t
name|ks
decl_stmt|;
name|struct
name|kstack_cache_entry
modifier|*
name|ks_ce
decl_stmt|;
name|int
name|pages
decl_stmt|;
name|pages
operator|=
name|td
operator|->
name|td_kstack_pages
expr_stmt|;
name|ksobj
operator|=
name|td
operator|->
name|td_kstack_obj
expr_stmt|;
name|ks
operator|=
name|td
operator|->
name|td_kstack
expr_stmt|;
name|td
operator|->
name|td_kstack
operator|=
literal|0
expr_stmt|;
name|td
operator|->
name|td_kstack_pages
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|pages
operator|==
name|kstack_pages
operator|&&
name|kstacks
operator|<=
name|kstack_cache_size
condition|)
block|{
name|ks_ce
operator|=
operator|(
expr|struct
name|kstack_cache_entry
operator|*
operator|)
name|ks
expr_stmt|;
name|ks_ce
operator|->
name|ksobj
operator|=
name|ksobj
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
name|ks_ce
operator|->
name|next_ks_entry
operator|=
name|kstack_cache
expr_stmt|;
name|kstack_cache
operator|=
name|ks_ce
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
return|return;
block|}
name|vm_thread_stack_dispose
argument_list|(
name|ksobj
argument_list|,
name|ks
argument_list|,
name|pages
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vm_thread_stack_lowmem
parameter_list|(
name|void
modifier|*
name|nulll
parameter_list|)
block|{
name|struct
name|kstack_cache_entry
modifier|*
name|ks_ce
decl_stmt|,
modifier|*
name|ks_ce1
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
name|ks_ce
operator|=
name|kstack_cache
expr_stmt|;
name|kstack_cache
operator|=
name|NULL
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
while|while
condition|(
name|ks_ce
operator|!=
name|NULL
condition|)
block|{
name|ks_ce1
operator|=
name|ks_ce
expr_stmt|;
name|ks_ce
operator|=
name|ks_ce
operator|->
name|next_ks_entry
expr_stmt|;
name|vm_thread_stack_dispose
argument_list|(
name|ks_ce1
operator|->
name|ksobj
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|ks_ce1
argument_list|,
name|kstack_pages
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|kstack_cache_init
parameter_list|(
name|void
modifier|*
name|nulll
parameter_list|)
block|{
name|EVENTHANDLER_REGISTER
argument_list|(
name|vm_lowmem
argument_list|,
name|vm_thread_stack_lowmem
argument_list|,
name|NULL
argument_list|,
name|EVENTHANDLER_PRI_ANY
argument_list|)
expr_stmt|;
block|}
end_function

begin_expr_stmt
name|SYSINIT
argument_list|(
name|vm_kstacks
argument_list|,
name|SI_SUB_KTHREAD_INIT
argument_list|,
name|SI_ORDER_ANY
argument_list|,
name|kstack_cache_init
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|KSTACK_USAGE_PROF
end_ifdef

begin_comment
comment|/*  * Track maximum stack used by a thread in kernel.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|max_kstack_used
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_debug
argument_list|,
name|OID_AUTO
argument_list|,
name|max_kstack_used
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|max_kstack_used
argument_list|,
literal|0
argument_list|,
literal|"Maxiumum stack depth used by a thread in kernel"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
name|void
name|intr_prof_stack_use
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|trapframe
modifier|*
name|frame
parameter_list|)
block|{
name|vm_offset_t
name|stack_top
decl_stmt|;
name|vm_offset_t
name|current
decl_stmt|;
name|int
name|used
decl_stmt|,
name|prev_used
decl_stmt|;
comment|/* 	 * Testing for interrupted kernel mode isn't strictly 	 * needed. It optimizes the execution, since interrupts from 	 * usermode will have only the trap frame on the stack. 	 */
if|if
condition|(
name|TRAPF_USERMODE
argument_list|(
name|frame
argument_list|)
condition|)
return|return;
name|stack_top
operator|=
name|td
operator|->
name|td_kstack
operator|+
name|td
operator|->
name|td_kstack_pages
operator|*
name|PAGE_SIZE
expr_stmt|;
name|current
operator|=
call|(
name|vm_offset_t
call|)
argument_list|(
name|uintptr_t
argument_list|)
operator|&
name|stack_top
expr_stmt|;
comment|/* 	 * Try to detect if interrupt is using kernel thread stack. 	 * Hardware could use a dedicated stack for interrupt handling. 	 */
if|if
condition|(
name|stack_top
operator|<=
name|current
operator|||
name|current
operator|<
name|td
operator|->
name|td_kstack
condition|)
return|return;
name|used
operator|=
name|stack_top
operator|-
name|current
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|prev_used
operator|=
name|max_kstack_used
expr_stmt|;
if|if
condition|(
name|prev_used
operator|>=
name|used
condition|)
break|break;
if|if
condition|(
name|atomic_cmpset_int
argument_list|(
operator|&
name|max_kstack_used
argument_list|,
name|prev_used
argument_list|,
name|used
argument_list|)
condition|)
break|break;
block|}
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* KSTACK_USAGE_PROF */
end_comment

begin_ifndef
ifndef|#
directive|ifndef
name|NO_SWAPPING
end_ifndef

begin_comment
comment|/*  * Allow a thread's kernel stack to be paged out.  */
end_comment

begin_function
specifier|static
name|void
name|vm_thread_swapout
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|vm_object_t
name|ksobj
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|,
name|pages
decl_stmt|;
name|cpu_thread_swapout
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|pages
operator|=
name|td
operator|->
name|td_kstack_pages
expr_stmt|;
name|ksobj
operator|=
name|td
operator|->
name|td_kstack_obj
expr_stmt|;
name|pmap_qremove
argument_list|(
name|td
operator|->
name|td_kstack
argument_list|,
name|pages
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|ksobj
argument_list|,
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"vm_thread_swapout: kstack already missing?"
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
name|PQ_INACTIVE
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Bring the kernel stack for a specified thread back in.  */
end_comment

begin_function
specifier|static
name|void
name|vm_thread_swapin
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|vm_object_t
name|ksobj
decl_stmt|;
name|vm_page_t
name|ma
index|[
name|KSTACK_MAX_PAGES
index|]
decl_stmt|;
name|int
name|pages
decl_stmt|;
name|pages
operator|=
name|td
operator|->
name|td_kstack_pages
expr_stmt|;
name|ksobj
operator|=
name|td
operator|->
name|td_kstack_obj
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
name|vm_page_grab_pages
argument_list|(
name|ksobj
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_WIRED
argument_list|,
name|ma
argument_list|,
name|pages
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|pages
condition|;
control|)
block|{
name|int
name|j
decl_stmt|,
name|a
decl_stmt|,
name|count
decl_stmt|,
name|rv
decl_stmt|;
name|vm_page_assert_xbusied
argument_list|(
name|ma
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|ma
index|[
name|i
index|]
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
condition|)
block|{
name|vm_page_xunbusy
argument_list|(
name|ma
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|i
operator|++
expr_stmt|;
continue|continue;
block|}
name|vm_object_pip_add
argument_list|(
name|ksobj
argument_list|,
literal|1
argument_list|)
expr_stmt|;
for|for
control|(
name|j
operator|=
name|i
operator|+
literal|1
init|;
name|j
operator|<
name|pages
condition|;
name|j
operator|++
control|)
if|if
condition|(
name|ma
index|[
name|j
index|]
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
condition|)
break|break;
name|rv
operator|=
name|vm_pager_has_page
argument_list|(
name|ksobj
argument_list|,
name|ma
index|[
name|i
index|]
operator|->
name|pindex
argument_list|,
name|NULL
argument_list|,
operator|&
name|a
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|rv
operator|==
literal|1
argument_list|,
operator|(
literal|"%s: missing page %p"
operator|,
name|__func__
operator|,
name|ma
index|[
name|i
index|]
operator|)
argument_list|)
expr_stmt|;
name|count
operator|=
name|min
argument_list|(
name|a
operator|+
literal|1
argument_list|,
name|j
operator|-
name|i
argument_list|)
expr_stmt|;
name|rv
operator|=
name|vm_pager_get_pages
argument_list|(
name|ksobj
argument_list|,
name|ma
operator|+
name|i
argument_list|,
name|count
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|rv
operator|==
name|VM_PAGER_OK
argument_list|,
operator|(
literal|"%s: cannot get kstack for proc %d"
operator|,
name|__func__
operator|,
name|td
operator|->
name|td_proc
operator|->
name|p_pid
operator|)
argument_list|)
expr_stmt|;
name|vm_object_pip_wakeup
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
for|for
control|(
name|j
operator|=
name|i
init|;
name|j
operator|<
name|i
operator|+
name|count
condition|;
name|j
operator|++
control|)
name|vm_page_xunbusy
argument_list|(
name|ma
index|[
name|j
index|]
argument_list|)
expr_stmt|;
name|i
operator|+=
name|count
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
name|td
operator|->
name|td_kstack
argument_list|,
name|ma
argument_list|,
name|pages
argument_list|)
expr_stmt|;
name|cpu_thread_swapin
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* !NO_SWAPPING */
end_comment

begin_comment
comment|/*  * Implement fork's actions on an address space.  * Here we arrange for the address space to be copied or referenced,  * allocate a user struct (pcb and kernel stack), then call the  * machine-dependent layer to fill those in and make the new process  * ready to run.  The new process is set up so that it returns directly  * to user mode to avoid stack copying and relocation problems.  */
end_comment

begin_function
name|int
name|vm_forkproc
parameter_list|(
name|td
parameter_list|,
name|p2
parameter_list|,
name|td2
parameter_list|,
name|vm2
parameter_list|,
name|flags
parameter_list|)
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|proc
modifier|*
name|p2
decl_stmt|;
name|struct
name|thread
modifier|*
name|td2
decl_stmt|;
name|struct
name|vmspace
modifier|*
name|vm2
decl_stmt|;
name|int
name|flags
decl_stmt|;
block|{
name|struct
name|proc
modifier|*
name|p1
init|=
name|td
operator|->
name|td_proc
decl_stmt|;
name|int
name|error
decl_stmt|;
if|if
condition|(
operator|(
name|flags
operator|&
name|RFPROC
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 		 * Divorce the memory, if it is shared, essentially 		 * this changes shared memory amongst threads, into 		 * COW locally. 		 */
if|if
condition|(
operator|(
name|flags
operator|&
name|RFMEM
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|p1
operator|->
name|p_vmspace
operator|->
name|vm_refcnt
operator|>
literal|1
condition|)
block|{
name|error
operator|=
name|vmspace_unshare
argument_list|(
name|p1
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
return|return
operator|(
name|error
operator|)
return|;
block|}
block|}
name|cpu_fork
argument_list|(
name|td
argument_list|,
name|p2
argument_list|,
name|td2
argument_list|,
name|flags
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
if|if
condition|(
name|flags
operator|&
name|RFMEM
condition|)
block|{
name|p2
operator|->
name|p_vmspace
operator|=
name|p1
operator|->
name|p_vmspace
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|p1
operator|->
name|p_vmspace
operator|->
name|vm_refcnt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
while|while
condition|(
name|vm_page_count_severe
argument_list|()
condition|)
block|{
name|VM_WAIT
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|flags
operator|&
name|RFMEM
operator|)
operator|==
literal|0
condition|)
block|{
name|p2
operator|->
name|p_vmspace
operator|=
name|vm2
expr_stmt|;
if|if
condition|(
name|p1
operator|->
name|p_vmspace
operator|->
name|vm_shm
condition|)
name|shmfork
argument_list|(
name|p1
argument_list|,
name|p2
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * cpu_fork will copy and update the pcb, set up the kernel stack, 	 * and make the child ready to run. 	 */
name|cpu_fork
argument_list|(
name|td
argument_list|,
name|p2
argument_list|,
name|td2
argument_list|,
name|flags
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Called after process has been wait(2)'ed upon and is being reaped.  * The idea is to reclaim resources that we could not reclaim while  * the process was still executing.  */
end_comment

begin_function
name|void
name|vm_waitproc
parameter_list|(
name|p
parameter_list|)
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
block|{
name|vmspace_exitfree
argument_list|(
name|p
argument_list|)
expr_stmt|;
comment|/* and clean-out the vmspace */
block|}
end_function

begin_function
name|void
name|faultin
parameter_list|(
name|p
parameter_list|)
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
block|{
ifdef|#
directive|ifdef
name|NO_SWAPPING
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|p
operator|->
name|p_flag
operator|&
name|P_INMEM
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"faultin: proc swapped out with NO_SWAPPING!"
argument_list|)
expr_stmt|;
else|#
directive|else
comment|/* !NO_SWAPPING */
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * If another process is swapping in this process, 	 * just wait until it finishes. 	 */
if|if
condition|(
name|p
operator|->
name|p_flag
operator|&
name|P_SWAPPINGIN
condition|)
block|{
while|while
condition|(
name|p
operator|->
name|p_flag
operator|&
name|P_SWAPPINGIN
condition|)
name|msleep
argument_list|(
operator|&
name|p
operator|->
name|p_flag
argument_list|,
operator|&
name|p
operator|->
name|p_mtx
argument_list|,
name|PVM
argument_list|,
literal|"faultin"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|p
operator|->
name|p_flag
operator|&
name|P_INMEM
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 		 * Don't let another thread swap process p out while we are 		 * busy swapping it in. 		 */
operator|++
name|p
operator|->
name|p_lock
expr_stmt|;
name|p
operator|->
name|p_flag
operator||=
name|P_SWAPPINGIN
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
comment|/* 		 * We hold no lock here because the list of threads 		 * can not change while all threads in the process are 		 * swapped out. 		 */
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
name|vm_thread_swapin
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|PROC_LOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|swapclear
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|p
operator|->
name|p_swtick
operator|=
name|ticks
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|p
operator|->
name|p_flag
argument_list|)
expr_stmt|;
comment|/* Allow other threads to swap p out now. */
operator|--
name|p
operator|->
name|p_lock
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* NO_SWAPPING */
block|}
end_function

begin_comment
comment|/*  * This swapin algorithm attempts to swap-in processes only if there  * is enough space for them.  Of course, if a process waits for a long  * time, it will be swapped in anyway.  */
end_comment

begin_function
name|void
name|swapper
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|proc
modifier|*
name|pp
decl_stmt|;
name|int
name|slptime
decl_stmt|;
name|int
name|swtime
decl_stmt|;
name|int
name|ppri
decl_stmt|;
name|int
name|pri
decl_stmt|;
name|loop
label|:
if|if
condition|(
name|vm_page_count_min
argument_list|()
condition|)
block|{
name|VM_WAIT
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
name|pp
operator|=
name|NULL
expr_stmt|;
name|ppri
operator|=
name|INT_MIN
expr_stmt|;
name|sx_slock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
name|FOREACH_PROC_IN_SYSTEM
argument_list|(
argument|p
argument_list|)
block|{
name|PROC_LOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
operator|->
name|p_state
operator|==
name|PRS_NEW
operator|||
name|p
operator|->
name|p_flag
operator|&
operator|(
name|P_SWAPPINGOUT
operator||
name|P_SWAPPINGIN
operator||
name|P_INMEM
operator|)
condition|)
block|{
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|swtime
operator|=
operator|(
name|ticks
operator|-
name|p
operator|->
name|p_swtick
operator|)
operator|/
name|hz
expr_stmt|;
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
comment|/* 			 * An otherwise runnable thread of a process 			 * swapped out has only the TDI_SWAPPED bit set. 			 *  			 */
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
name|td
operator|->
name|td_inhibitors
operator|==
name|TDI_SWAPPED
condition|)
block|{
name|slptime
operator|=
operator|(
name|ticks
operator|-
name|td
operator|->
name|td_slptick
operator|)
operator|/
name|hz
expr_stmt|;
name|pri
operator|=
name|swtime
operator|+
name|slptime
expr_stmt|;
if|if
condition|(
operator|(
name|td
operator|->
name|td_flags
operator|&
name|TDF_SWAPINREQ
operator|)
operator|==
literal|0
condition|)
name|pri
operator|-=
name|p
operator|->
name|p_nice
operator|*
literal|8
expr_stmt|;
comment|/* 				 * if this thread is higher priority 				 * and there is enough space, then select 				 * this process instead of the previous 				 * selection. 				 */
if|if
condition|(
name|pri
operator|>
name|ppri
condition|)
block|{
name|pp
operator|=
name|p
expr_stmt|;
name|ppri
operator|=
name|pri
expr_stmt|;
block|}
block|}
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
comment|/* 	 * Nothing to do, back to sleep. 	 */
if|if
condition|(
operator|(
name|p
operator|=
name|pp
operator|)
operator|==
name|NULL
condition|)
block|{
name|tsleep
argument_list|(
operator|&
name|proc0
argument_list|,
name|PVM
argument_list|,
literal|"swapin"
argument_list|,
name|MAXSLP
operator|*
name|hz
operator|/
literal|2
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
name|PROC_LOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
comment|/* 	 * Another process may be bringing or may have already 	 * brought this process in while we traverse all threads. 	 * Or, this process may even be being swapped out again. 	 */
if|if
condition|(
name|p
operator|->
name|p_flag
operator|&
operator|(
name|P_INMEM
operator||
name|P_SWAPPINGOUT
operator||
name|P_SWAPPINGIN
operator|)
condition|)
block|{
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
comment|/* 	 * We would like to bring someone in. (only if there is space). 	 * [What checks the space? ] 	 */
name|faultin
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
end_function

begin_function
name|void
name|kick_proc0
parameter_list|(
name|void
parameter_list|)
block|{
name|wakeup
argument_list|(
operator|&
name|proc0
argument_list|)
expr_stmt|;
block|}
end_function

begin_ifndef
ifndef|#
directive|ifndef
name|NO_SWAPPING
end_ifndef

begin_comment
comment|/*  * Swap_idle_threshold1 is the guaranteed swapped in time for a process  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|swap_idle_threshold1
init|=
literal|2
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|swap_idle_threshold1
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|swap_idle_threshold1
argument_list|,
literal|0
argument_list|,
literal|"Guaranteed swapped in time for a process"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Swap_idle_threshold2 is the time that a process can be idle before  * it will be swapped out, if idle swapping is enabled.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|swap_idle_threshold2
init|=
literal|10
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|swap_idle_threshold2
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|swap_idle_threshold2
argument_list|,
literal|0
argument_list|,
literal|"Time before a process will be swapped out"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * First, if any processes have been sleeping or stopped for at least  * "swap_idle_threshold1" seconds, they are swapped out.  If, however,  * no such processes exist, then the longest-sleeping or stopped  * process is swapped out.  Finally, and only as a last resort, if  * there are no sleeping or stopped processes, the longest-resident  * process is swapped out.  */
end_comment

begin_function
name|void
name|swapout_procs
parameter_list|(
name|action
parameter_list|)
name|int
name|action
decl_stmt|;
block|{
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|int
name|didswap
init|=
literal|0
decl_stmt|;
name|retry
label|:
name|sx_slock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
name|FOREACH_PROC_IN_SYSTEM
argument_list|(
argument|p
argument_list|)
block|{
name|struct
name|vmspace
modifier|*
name|vm
decl_stmt|;
name|int
name|minslptime
init|=
literal|100000
decl_stmt|;
name|int
name|slptime
decl_stmt|;
name|PROC_LOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
comment|/* 		 * Watch out for a process in 		 * creation.  It may have no 		 * address space or lock yet. 		 */
if|if
condition|(
name|p
operator|->
name|p_state
operator|==
name|PRS_NEW
condition|)
block|{
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * An aio daemon switches its 		 * address space while running. 		 * Perform a quick check whether 		 * a process has P_SYSTEM. 		 * Filter out exiting processes. 		 */
if|if
condition|(
operator|(
name|p
operator|->
name|p_flag
operator|&
operator|(
name|P_SYSTEM
operator||
name|P_WEXIT
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|_PHOLD_LITE
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
comment|/* 		 * Do not swapout a process that 		 * is waiting for VM data 		 * structures as there is a possible 		 * deadlock.  Test this first as 		 * this may block. 		 * 		 * Lock the map until swapout 		 * finishes, or a thread of this 		 * process may attempt to alter 		 * the map. 		 */
name|vm
operator|=
name|vmspace_acquire_ref
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm
operator|==
name|NULL
condition|)
goto|goto
name|nextproc2
goto|;
if|if
condition|(
operator|!
name|vm_map_trylock
argument_list|(
operator|&
name|vm
operator|->
name|vm_map
argument_list|)
condition|)
goto|goto
name|nextproc1
goto|;
name|PROC_LOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
operator|->
name|p_lock
operator|!=
literal|1
operator|||
operator|(
name|p
operator|->
name|p_flag
operator|&
operator|(
name|P_STOPPED_SINGLE
operator||
name|P_TRACED
operator||
name|P_SYSTEM
operator|)
operator|)
operator|!=
literal|0
condition|)
goto|goto
name|nextproc
goto|;
comment|/* 		 * only aiod changes vmspace, however it will be 		 * skipped because of the if statement above checking  		 * for P_SYSTEM 		 */
if|if
condition|(
operator|(
name|p
operator|->
name|p_flag
operator|&
operator|(
name|P_INMEM
operator||
name|P_SWAPPINGOUT
operator||
name|P_SWAPPINGIN
operator|)
operator|)
operator|!=
name|P_INMEM
condition|)
goto|goto
name|nextproc
goto|;
switch|switch
condition|(
name|p
operator|->
name|p_state
condition|)
block|{
default|default:
comment|/* Don't swap out processes in any sort 			 * of 'special' state. */
break|break;
case|case
name|PRS_NORMAL
case|:
comment|/* 			 * do not swapout a realtime process 			 * Check all the thread groups.. 			 */
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
name|PRI_IS_REALTIME
argument_list|(
name|td
operator|->
name|td_pri_class
argument_list|)
condition|)
block|{
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
goto|goto
name|nextproc
goto|;
block|}
name|slptime
operator|=
operator|(
name|ticks
operator|-
name|td
operator|->
name|td_slptick
operator|)
operator|/
name|hz
expr_stmt|;
comment|/* 				 * Guarantee swap_idle_threshold1 				 * time in memory. 				 */
if|if
condition|(
name|slptime
operator|<
name|swap_idle_threshold1
condition|)
block|{
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
goto|goto
name|nextproc
goto|;
block|}
comment|/* 				 * Do not swapout a process if it is 				 * waiting on a critical event of some 				 * kind or there is a thread whose 				 * pageable memory may be accessed. 				 * 				 * This could be refined to support 				 * swapping out a thread. 				 */
if|if
condition|(
operator|!
name|thread_safetoswapout
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
goto|goto
name|nextproc
goto|;
block|}
comment|/* 				 * If the system is under memory stress, 				 * or if we are swapping 				 * idle processes>= swap_idle_threshold2, 				 * then swap the process out. 				 */
if|if
condition|(
operator|(
operator|(
name|action
operator|&
name|VM_SWAP_NORMAL
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
operator|(
operator|(
name|action
operator|&
name|VM_SWAP_IDLE
operator|)
operator|==
literal|0
operator|)
operator|||
operator|(
name|slptime
operator|<
name|swap_idle_threshold2
operator|)
operator|)
condition|)
block|{
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
goto|goto
name|nextproc
goto|;
block|}
if|if
condition|(
name|minslptime
operator|>
name|slptime
condition|)
name|minslptime
operator|=
name|slptime
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
comment|/* 			 * If the pageout daemon didn't free enough pages, 			 * or if this process is idle and the system is 			 * configured to swap proactively, swap it out. 			 */
if|if
condition|(
operator|(
name|action
operator|&
name|VM_SWAP_NORMAL
operator|)
operator|||
operator|(
operator|(
name|action
operator|&
name|VM_SWAP_IDLE
operator|)
operator|&&
operator|(
name|minslptime
operator|>
name|swap_idle_threshold2
operator|)
operator|)
condition|)
block|{
name|_PRELE
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|swapout
argument_list|(
name|p
argument_list|)
operator|==
literal|0
condition|)
name|didswap
operator|++
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_map_unlock
argument_list|(
operator|&
name|vm
operator|->
name|vm_map
argument_list|)
expr_stmt|;
name|vmspace_free
argument_list|(
name|vm
argument_list|)
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
block|}
name|nextproc
label|:
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_map_unlock
argument_list|(
operator|&
name|vm
operator|->
name|vm_map
argument_list|)
expr_stmt|;
name|nextproc1
label|:
name|vmspace_free
argument_list|(
name|vm
argument_list|)
expr_stmt|;
name|nextproc2
label|:
name|sx_slock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
name|PRELE
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
comment|/* 	 * If we swapped something out, and another process needed memory, 	 * then wakeup the sched process. 	 */
if|if
condition|(
name|didswap
condition|)
name|wakeup
argument_list|(
operator|&
name|proc0
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|swapclear
parameter_list|(
name|p
parameter_list|)
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_flags
operator||=
name|TDF_INMEM
expr_stmt|;
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_SWAPINREQ
expr_stmt|;
name|TD_CLR_SWAPPED
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
name|TD_CAN_RUN
argument_list|(
name|td
argument_list|)
condition|)
if|if
condition|(
name|setrunnable
argument_list|(
name|td
argument_list|)
condition|)
block|{
ifdef|#
directive|ifdef
name|INVARIANTS
comment|/* 				 * XXX: We just cleared TDI_SWAPPED 				 * above and set TDF_INMEM, so this 				 * should never happen. 				 */
name|panic
argument_list|(
literal|"not waking up swapper"
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
name|p
operator|->
name|p_flag
operator|&=
operator|~
operator|(
name|P_SWAPPINGIN
operator||
name|P_SWAPPINGOUT
operator|)
expr_stmt|;
name|p
operator|->
name|p_flag
operator||=
name|P_INMEM
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|swapout
parameter_list|(
name|p
parameter_list|)
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
block|{
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|PROC_LOCK_ASSERT
argument_list|(
name|p
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|SWAP_DEBUG
argument_list|)
name|printf
argument_list|(
literal|"swapping out %d\n"
argument_list|,
name|p
operator|->
name|p_pid
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * The states of this process and its threads may have changed 	 * by now.  Assuming that there is only one pageout daemon thread, 	 * this process should still be in memory. 	 */
name|KASSERT
argument_list|(
operator|(
name|p
operator|->
name|p_flag
operator|&
operator|(
name|P_INMEM
operator||
name|P_SWAPPINGOUT
operator||
name|P_SWAPPINGIN
operator|)
operator|)
operator|==
name|P_INMEM
argument_list|,
operator|(
literal|"swapout: lost a swapout race?"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * remember the process resident count 	 */
name|p
operator|->
name|p_vmspace
operator|->
name|vm_swrss
operator|=
name|vmspace_resident_count
argument_list|(
name|p
operator|->
name|p_vmspace
argument_list|)
expr_stmt|;
comment|/* 	 * Check and mark all threads before we proceed. 	 */
name|p
operator|->
name|p_flag
operator|&=
operator|~
name|P_INMEM
expr_stmt|;
name|p
operator|->
name|p_flag
operator||=
name|P_SWAPPINGOUT
expr_stmt|;
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|thread_safetoswapout
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|swapclear
argument_list|(
name|p
argument_list|)
expr_stmt|;
return|return
operator|(
name|EBUSY
operator|)
return|;
block|}
name|td
operator|->
name|td_flags
operator|&=
operator|~
name|TDF_INMEM
expr_stmt|;
name|TD_SET_SWAPPED
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
name|td
operator|=
name|FIRST_THREAD_IN_PROC
argument_list|(
name|p
argument_list|)
expr_stmt|;
operator|++
name|td
operator|->
name|td_ru
operator|.
name|ru_nswap
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
comment|/* 	 * This list is stable because all threads are now prevented from 	 * running.  The list is only modified in the context of a running 	 * thread in this process. 	 */
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
name|vm_thread_swapout
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|PROC_LOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|p
operator|->
name|p_flag
operator|&=
operator|~
name|P_SWAPPINGOUT
expr_stmt|;
name|p
operator|->
name|p_swtick
operator|=
name|ticks
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* !NO_SWAPPING */
end_comment

end_unit

