begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * SPDX-License-Identifier: BSD-3-Clause  *  * Copyright (c) 1991, 1993  *	The Regents of the University of California.  All rights reserved.  *  * This code is derived from software contributed to Berkeley by  * The Mach Operating System project at Carnegie-Mellon University.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from: @(#)vm_glue.c	8.6 (Berkeley) 1/5/94  *  *  * Copyright (c) 1987, 1990 Carnegie-Mellon University.  * All rights reserved.  *  * Permission to use, copy, modify and distribute this software and  * its documentation is hereby granted, provided that both the copyright  * notice and this permission notice appear in all copies of the  * software, derivative works or modified versions, and any portions  * thereof, and that both notices appear in supporting documentation.  *  * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"  * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND  * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.  *  * Carnegie Mellon requests users of this software to return to  *  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU  *  School of Computer Science  *  Carnegie Mellon University  *  Pittsburgh PA 15213-3890  *  * any improvements or extensions that they make and grant Carnegie the  * rights to redistribute these changes.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_vm.h"
end_include

begin_include
include|#
directive|include
file|"opt_kstack_pages.h"
end_include

begin_include
include|#
directive|include
file|"opt_kstack_max_pages.h"
end_include

begin_include
include|#
directive|include
file|"opt_kstack_usage_prof.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/limits.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/racct.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/sf_buf.h>
end_include

begin_include
include|#
directive|include
file|<sys/shm.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmem.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/_kstack_cache.h>
end_include

begin_include
include|#
directive|include
file|<sys/eventhandler.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/unistd.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/pmap.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/swap_pager.h>
end_include

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_comment
comment|/*  * MPSAFE  *  * WARNING!  This code calls vm_map_check_protection() which only checks  * the associated vm_map_entry range.  It does not determine whether the  * contents of the memory is actually readable or writable.  In most cases  * just checking the vm_map_entry is sufficient within the kernel's address  * space.  */
end_comment

begin_function
name|int
name|kernacc
parameter_list|(
name|addr
parameter_list|,
name|len
parameter_list|,
name|rw
parameter_list|)
name|void
modifier|*
name|addr
decl_stmt|;
name|int
name|len
decl_stmt|,
name|rw
decl_stmt|;
block|{
name|boolean_t
name|rv
decl_stmt|;
name|vm_offset_t
name|saddr
decl_stmt|,
name|eaddr
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|rw
operator|&
operator|~
name|VM_PROT_ALL
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"illegal ``rw'' argument to kernacc (%x)\n"
operator|,
name|rw
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
operator|>
name|kernel_map
operator|->
name|max_offset
operator|||
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
operator|<
operator|(
name|vm_offset_t
operator|)
name|addr
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
name|prot
operator|=
name|rw
expr_stmt|;
name|saddr
operator|=
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
argument_list|)
expr_stmt|;
name|eaddr
operator|=
name|round_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
argument_list|)
expr_stmt|;
name|vm_map_lock_read
argument_list|(
name|kernel_map
argument_list|)
expr_stmt|;
name|rv
operator|=
name|vm_map_check_protection
argument_list|(
name|kernel_map
argument_list|,
name|saddr
argument_list|,
name|eaddr
argument_list|,
name|prot
argument_list|)
expr_stmt|;
name|vm_map_unlock_read
argument_list|(
name|kernel_map
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|==
name|TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * MPSAFE  *  * WARNING!  This code calls vm_map_check_protection() which only checks  * the associated vm_map_entry range.  It does not determine whether the  * contents of the memory is actually readable or writable.  vmapbuf(),  * vm_fault_quick(), or copyin()/copout()/su*()/fu*() functions should be  * used in conjunction with this call.  */
end_comment

begin_function
name|int
name|useracc
parameter_list|(
name|addr
parameter_list|,
name|len
parameter_list|,
name|rw
parameter_list|)
name|void
modifier|*
name|addr
decl_stmt|;
name|int
name|len
decl_stmt|,
name|rw
decl_stmt|;
block|{
name|boolean_t
name|rv
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
name|vm_map_t
name|map
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|rw
operator|&
operator|~
name|VM_PROT_ALL
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"illegal ``rw'' argument to useracc (%x)\n"
operator|,
name|rw
operator|)
argument_list|)
expr_stmt|;
name|prot
operator|=
name|rw
expr_stmt|;
name|map
operator|=
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_map
expr_stmt|;
if|if
condition|(
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
operator|>
name|vm_map_max
argument_list|(
name|map
argument_list|)
operator|||
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
operator|<
operator|(
name|vm_offset_t
operator|)
name|addr
condition|)
block|{
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
name|vm_map_lock_read
argument_list|(
name|map
argument_list|)
expr_stmt|;
name|rv
operator|=
name|vm_map_check_protection
argument_list|(
name|map
argument_list|,
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
argument_list|)
argument_list|,
name|round_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
argument_list|)
argument_list|,
name|prot
argument_list|)
expr_stmt|;
name|vm_map_unlock_read
argument_list|(
name|map
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|==
name|TRUE
operator|)
return|;
block|}
end_function

begin_function
name|int
name|vslock
parameter_list|(
name|void
modifier|*
name|addr
parameter_list|,
name|size_t
name|len
parameter_list|)
block|{
name|vm_offset_t
name|end
decl_stmt|,
name|last
decl_stmt|,
name|start
decl_stmt|;
name|vm_size_t
name|npages
decl_stmt|;
name|int
name|error
decl_stmt|;
name|last
operator|=
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
expr_stmt|;
name|start
operator|=
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
argument_list|)
expr_stmt|;
name|end
operator|=
name|round_page
argument_list|(
name|last
argument_list|)
expr_stmt|;
if|if
condition|(
name|last
operator|<
operator|(
name|vm_offset_t
operator|)
name|addr
operator|||
name|end
operator|<
operator|(
name|vm_offset_t
operator|)
name|addr
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|npages
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
if|if
condition|(
name|npages
operator|>
name|vm_page_max_wired
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
if|#
directive|if
literal|0
comment|/* 	 * XXX - not yet 	 * 	 * The limit for transient usage of wired pages should be 	 * larger than for "permanent" wired pages (mlock()). 	 * 	 * Also, the sysctl code, which is the only present user 	 * of vslock(), does a hard loop on EAGAIN. 	 */
block|if (npages + vm_cnt.v_wire_count> vm_page_max_wired) 		return (EAGAIN);
endif|#
directive|endif
name|error
operator|=
name|vm_map_wire
argument_list|(
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_map
argument_list|,
name|start
argument_list|,
name|end
argument_list|,
name|VM_MAP_WIRE_SYSTEM
operator||
name|VM_MAP_WIRE_NOHOLES
argument_list|)
expr_stmt|;
comment|/* 	 * Return EFAULT on error to match copy{in,out}() behaviour 	 * rather than returning ENOMEM like mlock() would. 	 */
return|return
operator|(
name|error
operator|==
name|KERN_SUCCESS
condition|?
literal|0
else|:
name|EFAULT
operator|)
return|;
block|}
end_function

begin_function
name|void
name|vsunlock
parameter_list|(
name|void
modifier|*
name|addr
parameter_list|,
name|size_t
name|len
parameter_list|)
block|{
comment|/* Rely on the parameter sanity checks performed by vslock(). */
operator|(
name|void
operator|)
name|vm_map_unwire
argument_list|(
operator|&
name|curproc
operator|->
name|p_vmspace
operator|->
name|vm_map
argument_list|,
name|trunc_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
argument_list|)
argument_list|,
name|round_page
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|addr
operator|+
name|len
argument_list|)
argument_list|,
name|VM_MAP_WIRE_SYSTEM
operator||
name|VM_MAP_WIRE_NOHOLES
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Pin the page contained within the given object at the given offset.  If the  * page is not resident, allocate and load it using the given object's pager.  * Return the pinned page if successful; otherwise, return NULL.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|vm_imgact_hold_page
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_ooffset_t
name|offset
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|vm_pindex_t
name|pindex
decl_stmt|;
name|int
name|rv
decl_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|pindex
operator|=
name|OFF_TO_IDX
argument_list|(
name|offset
argument_list|)
expr_stmt|;
name|m
operator|=
name|vm_page_grab
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOBUSY
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|!=
name|VM_PAGE_BITS_ALL
condition|)
block|{
name|vm_page_xbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|rv
operator|=
name|vm_pager_get_pages
argument_list|(
name|object
argument_list|,
operator|&
name|m
argument_list|,
literal|1
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
operator|!=
name|VM_PAGER_OK
condition|)
block|{
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
goto|goto
name|out
goto|;
block|}
name|vm_page_xunbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_activate
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|out
label|:
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Return a CPU private mapping to the page at the given offset within the  * given object.  The page is pinned before it is mapped.  */
end_comment

begin_function
name|struct
name|sf_buf
modifier|*
name|vm_imgact_map_page
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_ooffset_t
name|offset
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|vm_imgact_hold_page
argument_list|(
name|object
argument_list|,
name|offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|sched_pin
argument_list|()
expr_stmt|;
return|return
operator|(
name|sf_buf_alloc
argument_list|(
name|m
argument_list|,
name|SFB_CPUPRIVATE
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Destroy the given CPU private mapping and unpin the page that it mapped.  */
end_comment

begin_function
name|void
name|vm_imgact_unmap_page
parameter_list|(
name|struct
name|sf_buf
modifier|*
name|sf
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|sf_buf_page
argument_list|(
name|sf
argument_list|)
expr_stmt|;
name|sf_buf_free
argument_list|(
name|sf
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unhold
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_sync_icache
parameter_list|(
name|vm_map_t
name|map
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_offset_t
name|sz
parameter_list|)
block|{
name|pmap_sync_icache
argument_list|(
name|map
operator|->
name|pmap
argument_list|,
name|va
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
end_function

begin_decl_stmt
name|struct
name|kstack_cache_entry
modifier|*
name|kstack_cache
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|kstack_cache_size
init|=
literal|128
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|kstacks
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|kstack_cache_mtx
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|MTX_SYSINIT
argument_list|(
name|kstack_cache
argument_list|,
operator|&
name|kstack_cache_mtx
argument_list|,
literal|"kstkch"
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|kstack_cache_size
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|kstack_cache_size
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|kstacks
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|kstacks
argument_list|,
literal|0
argument_list|,
literal|""
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Create the kernel stack (including pcb for i386) for a new thread.  * This routine directly affects the fork perf for a process and  * create performance for a thread.  */
end_comment

begin_function
name|int
name|vm_thread_new
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|int
name|pages
parameter_list|)
block|{
name|vm_object_t
name|ksobj
decl_stmt|;
name|vm_offset_t
name|ks
decl_stmt|;
name|vm_page_t
name|ma
index|[
name|KSTACK_MAX_PAGES
index|]
decl_stmt|;
name|struct
name|kstack_cache_entry
modifier|*
name|ks_ce
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* Bounds check */
if|if
condition|(
name|pages
operator|<=
literal|1
condition|)
name|pages
operator|=
name|kstack_pages
expr_stmt|;
elseif|else
if|if
condition|(
name|pages
operator|>
name|KSTACK_MAX_PAGES
condition|)
name|pages
operator|=
name|KSTACK_MAX_PAGES
expr_stmt|;
if|if
condition|(
name|pages
operator|==
name|kstack_pages
condition|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|kstack_cache
operator|!=
name|NULL
condition|)
block|{
name|ks_ce
operator|=
name|kstack_cache
expr_stmt|;
name|kstack_cache
operator|=
name|ks_ce
operator|->
name|next_ks_entry
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
name|td
operator|->
name|td_kstack_obj
operator|=
name|ks_ce
operator|->
name|ksobj
expr_stmt|;
name|td
operator|->
name|td_kstack
operator|=
operator|(
name|vm_offset_t
operator|)
name|ks_ce
expr_stmt|;
name|td
operator|->
name|td_kstack_pages
operator|=
name|kstack_pages
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Allocate an object for the kstack. 	 */
name|ksobj
operator|=
name|vm_object_allocate
argument_list|(
name|OBJT_DEFAULT
argument_list|,
name|pages
argument_list|)
expr_stmt|;
comment|/* 	 * Get a kernel virtual address for this thread's kstack. 	 */
if|#
directive|if
name|defined
argument_list|(
name|__mips__
argument_list|)
comment|/* 	 * We need to align the kstack's mapped address to fit within 	 * a single TLB entry. 	 */
if|if
condition|(
name|vmem_xalloc
argument_list|(
name|kernel_arena
argument_list|,
operator|(
name|pages
operator|+
name|KSTACK_GUARD_PAGES
operator|)
operator|*
name|PAGE_SIZE
argument_list|,
name|PAGE_SIZE
operator|*
literal|2
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|VMEM_ADDR_MIN
argument_list|,
name|VMEM_ADDR_MAX
argument_list|,
name|M_BESTFIT
operator||
name|M_NOWAIT
argument_list|,
operator|&
name|ks
argument_list|)
condition|)
block|{
name|ks
operator|=
literal|0
expr_stmt|;
block|}
else|#
directive|else
name|ks
operator|=
name|kva_alloc
argument_list|(
operator|(
name|pages
operator|+
name|KSTACK_GUARD_PAGES
operator|)
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|ks
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"vm_thread_new: kstack allocation failed\n"
argument_list|)
expr_stmt|;
name|vm_object_deallocate
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|atomic_add_int
argument_list|(
operator|&
name|kstacks
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|KSTACK_GUARD_PAGES
operator|!=
literal|0
condition|)
block|{
name|pmap_qremove
argument_list|(
name|ks
argument_list|,
name|KSTACK_GUARD_PAGES
argument_list|)
expr_stmt|;
name|ks
operator|+=
name|KSTACK_GUARD_PAGES
operator|*
name|PAGE_SIZE
expr_stmt|;
block|}
name|td
operator|->
name|td_kstack_obj
operator|=
name|ksobj
expr_stmt|;
name|td
operator|->
name|td_kstack
operator|=
name|ks
expr_stmt|;
comment|/* 	 * Knowing the number of pages allocated is useful when you 	 * want to deallocate them. 	 */
name|td
operator|->
name|td_kstack_pages
operator|=
name|pages
expr_stmt|;
comment|/*  	 * For the length of the stack, link in a real page of ram for each 	 * page of stack. 	 */
name|VM_OBJECT_WLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|vm_page_grab_pages
argument_list|(
name|ksobj
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_WIRED
argument_list|,
name|ma
argument_list|,
name|pages
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pages
condition|;
name|i
operator|++
control|)
name|ma
index|[
name|i
index|]
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
name|ks
argument_list|,
name|ma
argument_list|,
name|pages
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vm_thread_stack_dispose
parameter_list|(
name|vm_object_t
name|ksobj
parameter_list|,
name|vm_offset_t
name|ks
parameter_list|,
name|int
name|pages
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|i
decl_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|kstacks
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
name|ks
argument_list|,
name|pages
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pages
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|ksobj
argument_list|,
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"vm_thread_dispose: kstack already missing?"
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
name|PQ_NONE
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|VM_OBJECT_WUNLOCK
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
name|vm_object_deallocate
argument_list|(
name|ksobj
argument_list|)
expr_stmt|;
name|kva_free
argument_list|(
name|ks
operator|-
operator|(
name|KSTACK_GUARD_PAGES
operator|*
name|PAGE_SIZE
operator|)
argument_list|,
operator|(
name|pages
operator|+
name|KSTACK_GUARD_PAGES
operator|)
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Dispose of a thread's kernel stack.  */
end_comment

begin_function
name|void
name|vm_thread_dispose
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|vm_object_t
name|ksobj
decl_stmt|;
name|vm_offset_t
name|ks
decl_stmt|;
name|struct
name|kstack_cache_entry
modifier|*
name|ks_ce
decl_stmt|;
name|int
name|pages
decl_stmt|;
name|pages
operator|=
name|td
operator|->
name|td_kstack_pages
expr_stmt|;
name|ksobj
operator|=
name|td
operator|->
name|td_kstack_obj
expr_stmt|;
name|ks
operator|=
name|td
operator|->
name|td_kstack
expr_stmt|;
name|td
operator|->
name|td_kstack
operator|=
literal|0
expr_stmt|;
name|td
operator|->
name|td_kstack_pages
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|pages
operator|==
name|kstack_pages
operator|&&
name|kstacks
operator|<=
name|kstack_cache_size
condition|)
block|{
name|ks_ce
operator|=
operator|(
expr|struct
name|kstack_cache_entry
operator|*
operator|)
name|ks
expr_stmt|;
name|ks_ce
operator|->
name|ksobj
operator|=
name|ksobj
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
name|ks_ce
operator|->
name|next_ks_entry
operator|=
name|kstack_cache
expr_stmt|;
name|kstack_cache
operator|=
name|ks_ce
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
return|return;
block|}
name|vm_thread_stack_dispose
argument_list|(
name|ksobj
argument_list|,
name|ks
argument_list|,
name|pages
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vm_thread_stack_lowmem
parameter_list|(
name|void
modifier|*
name|nulll
parameter_list|)
block|{
name|struct
name|kstack_cache_entry
modifier|*
name|ks_ce
decl_stmt|,
modifier|*
name|ks_ce1
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
name|ks_ce
operator|=
name|kstack_cache
expr_stmt|;
name|kstack_cache
operator|=
name|NULL
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|kstack_cache_mtx
argument_list|)
expr_stmt|;
while|while
condition|(
name|ks_ce
operator|!=
name|NULL
condition|)
block|{
name|ks_ce1
operator|=
name|ks_ce
expr_stmt|;
name|ks_ce
operator|=
name|ks_ce
operator|->
name|next_ks_entry
expr_stmt|;
name|vm_thread_stack_dispose
argument_list|(
name|ks_ce1
operator|->
name|ksobj
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|ks_ce1
argument_list|,
name|kstack_pages
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|kstack_cache_init
parameter_list|(
name|void
modifier|*
name|nulll
parameter_list|)
block|{
name|EVENTHANDLER_REGISTER
argument_list|(
name|vm_lowmem
argument_list|,
name|vm_thread_stack_lowmem
argument_list|,
name|NULL
argument_list|,
name|EVENTHANDLER_PRI_ANY
argument_list|)
expr_stmt|;
block|}
end_function

begin_expr_stmt
name|SYSINIT
argument_list|(
name|vm_kstacks
argument_list|,
name|SI_SUB_KTHREAD_INIT
argument_list|,
name|SI_ORDER_ANY
argument_list|,
name|kstack_cache_init
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|KSTACK_USAGE_PROF
end_ifdef

begin_comment
comment|/*  * Track maximum stack used by a thread in kernel.  */
end_comment

begin_decl_stmt
specifier|static
name|int
name|max_kstack_used
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_debug
argument_list|,
name|OID_AUTO
argument_list|,
name|max_kstack_used
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|max_kstack_used
argument_list|,
literal|0
argument_list|,
literal|"Maxiumum stack depth used by a thread in kernel"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
name|void
name|intr_prof_stack_use
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|,
name|struct
name|trapframe
modifier|*
name|frame
parameter_list|)
block|{
name|vm_offset_t
name|stack_top
decl_stmt|;
name|vm_offset_t
name|current
decl_stmt|;
name|int
name|used
decl_stmt|,
name|prev_used
decl_stmt|;
comment|/* 	 * Testing for interrupted kernel mode isn't strictly 	 * needed. It optimizes the execution, since interrupts from 	 * usermode will have only the trap frame on the stack. 	 */
if|if
condition|(
name|TRAPF_USERMODE
argument_list|(
name|frame
argument_list|)
condition|)
return|return;
name|stack_top
operator|=
name|td
operator|->
name|td_kstack
operator|+
name|td
operator|->
name|td_kstack_pages
operator|*
name|PAGE_SIZE
expr_stmt|;
name|current
operator|=
call|(
name|vm_offset_t
call|)
argument_list|(
name|uintptr_t
argument_list|)
operator|&
name|stack_top
expr_stmt|;
comment|/* 	 * Try to detect if interrupt is using kernel thread stack. 	 * Hardware could use a dedicated stack for interrupt handling. 	 */
if|if
condition|(
name|stack_top
operator|<=
name|current
operator|||
name|current
operator|<
name|td
operator|->
name|td_kstack
condition|)
return|return;
name|used
operator|=
name|stack_top
operator|-
name|current
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|prev_used
operator|=
name|max_kstack_used
expr_stmt|;
if|if
condition|(
name|prev_used
operator|>=
name|used
condition|)
break|break;
if|if
condition|(
name|atomic_cmpset_int
argument_list|(
operator|&
name|max_kstack_used
argument_list|,
name|prev_used
argument_list|,
name|used
argument_list|)
condition|)
break|break;
block|}
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* KSTACK_USAGE_PROF */
end_comment

begin_comment
comment|/*  * Implement fork's actions on an address space.  * Here we arrange for the address space to be copied or referenced,  * allocate a user struct (pcb and kernel stack), then call the  * machine-dependent layer to fill those in and make the new process  * ready to run.  The new process is set up so that it returns directly  * to user mode to avoid stack copying and relocation problems.  */
end_comment

begin_function
name|int
name|vm_forkproc
parameter_list|(
name|td
parameter_list|,
name|p2
parameter_list|,
name|td2
parameter_list|,
name|vm2
parameter_list|,
name|flags
parameter_list|)
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|proc
modifier|*
name|p2
decl_stmt|;
name|struct
name|thread
modifier|*
name|td2
decl_stmt|;
name|struct
name|vmspace
modifier|*
name|vm2
decl_stmt|;
name|int
name|flags
decl_stmt|;
block|{
name|struct
name|proc
modifier|*
name|p1
init|=
name|td
operator|->
name|td_proc
decl_stmt|;
name|int
name|error
decl_stmt|;
if|if
condition|(
operator|(
name|flags
operator|&
name|RFPROC
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 		 * Divorce the memory, if it is shared, essentially 		 * this changes shared memory amongst threads, into 		 * COW locally. 		 */
if|if
condition|(
operator|(
name|flags
operator|&
name|RFMEM
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|p1
operator|->
name|p_vmspace
operator|->
name|vm_refcnt
operator|>
literal|1
condition|)
block|{
name|error
operator|=
name|vmspace_unshare
argument_list|(
name|p1
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
return|return
operator|(
name|error
operator|)
return|;
block|}
block|}
name|cpu_fork
argument_list|(
name|td
argument_list|,
name|p2
argument_list|,
name|td2
argument_list|,
name|flags
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
if|if
condition|(
name|flags
operator|&
name|RFMEM
condition|)
block|{
name|p2
operator|->
name|p_vmspace
operator|=
name|p1
operator|->
name|p_vmspace
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|p1
operator|->
name|p_vmspace
operator|->
name|vm_refcnt
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
while|while
condition|(
name|vm_page_count_severe
argument_list|()
condition|)
block|{
name|VM_WAIT
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|flags
operator|&
name|RFMEM
operator|)
operator|==
literal|0
condition|)
block|{
name|p2
operator|->
name|p_vmspace
operator|=
name|vm2
expr_stmt|;
if|if
condition|(
name|p1
operator|->
name|p_vmspace
operator|->
name|vm_shm
condition|)
name|shmfork
argument_list|(
name|p1
argument_list|,
name|p2
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * cpu_fork will copy and update the pcb, set up the kernel stack, 	 * and make the child ready to run. 	 */
name|cpu_fork
argument_list|(
name|td
argument_list|,
name|p2
argument_list|,
name|td2
argument_list|,
name|flags
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Called after process has been wait(2)'ed upon and is being reaped.  * The idea is to reclaim resources that we could not reclaim while  * the process was still executing.  */
end_comment

begin_function
name|void
name|vm_waitproc
parameter_list|(
name|p
parameter_list|)
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
block|{
name|vmspace_exitfree
argument_list|(
name|p
argument_list|)
expr_stmt|;
comment|/* and clean-out the vmspace */
block|}
end_function

begin_function
name|void
name|kick_proc0
parameter_list|(
name|void
parameter_list|)
block|{
name|wakeup
argument_list|(
operator|&
name|proc0
argument_list|)
expr_stmt|;
block|}
end_function

end_unit

