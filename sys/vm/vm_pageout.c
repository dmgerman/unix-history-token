begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1991 Regents of the University of California.  * All rights reserved.  * Copyright (c) 1994 John S. Dyson  * All rights reserved.  * Copyright (c) 1994 David Greenman  * All rights reserved.  * Copyright (c) 2005 Yahoo! Technologies Norway AS  * All rights reserved.  *  * This code is derived from software contributed to Berkeley by  * The Mach Operating System project at Carnegie-Mellon University.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. All advertising materials mentioning features or use of this software  *    must display the following acknowledgement:  *	This product includes software developed by the University of  *	California, Berkeley and its contributors.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from: @(#)vm_pageout.c	7.4 (Berkeley) 5/7/91  *  *  * Copyright (c) 1987, 1990 Carnegie-Mellon University.  * All rights reserved.  *  * Authors: Avadis Tevanian, Jr., Michael Wayne Young  *  * Permission to use, copy, modify and distribute this software and  * its documentation is hereby granted, provided that both the copyright  * notice and this permission notice appear in all copies of the  * software, derivative works or modified versions, and any portions  * thereof, and that both notices appear in supporting documentation.  *  * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"  * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND  * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.  *  * Carnegie Mellon requests users of this software to return to  *  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU  *  School of Computer Science  *  Carnegie Mellon University  *  Pittsburgh PA 15213-3890  *  * any improvements or extensions that they make and grant Carnegie the  * rights to redistribute these changes.  */
end_comment

begin_comment
comment|/*  *	The proverbial page-out daemon.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_vm.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/eventhandler.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/kthread.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/mount.h>
end_include

begin_include
include|#
directive|include
file|<sys/racct.h>
end_include

begin_include
include|#
directive|include
file|<sys/resourcevar.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/signalvar.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/swap_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_comment
comment|/*  * System initialization  */
end_comment

begin_comment
comment|/* the kernel process "vm_pageout"*/
end_comment

begin_function_decl
specifier|static
name|void
name|vm_pageout
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vm_pageout_clean
parameter_list|(
name|vm_page_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_pageout_scan
parameter_list|(
name|int
name|pass
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
name|struct
name|proc
modifier|*
name|pageproc
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|kproc_desc
name|page_kp
init|=
block|{
literal|"pagedaemon"
block|,
name|vm_pageout
block|,
operator|&
name|pageproc
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSINIT
argument_list|(
name|pagedaemon
argument_list|,
name|SI_SUB_KTHREAD_PAGE
argument_list|,
name|SI_ORDER_FIRST
argument_list|,
name|kproc_start
argument_list|,
operator|&
name|page_kp
argument_list|)
expr_stmt|;
end_expr_stmt

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_SWAPPING
argument_list|)
end_if

begin_comment
comment|/* the kernel process "vm_daemon"*/
end_comment

begin_function_decl
specifier|static
name|void
name|vm_daemon
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_decl_stmt
specifier|static
name|struct
name|proc
modifier|*
name|vmproc
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|kproc_desc
name|vm_kp
init|=
block|{
literal|"vmdaemon"
block|,
name|vm_daemon
block|,
operator|&
name|vmproc
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSINIT
argument_list|(
name|vmdaemon
argument_list|,
name|SI_SUB_KTHREAD_VM
argument_list|,
name|SI_ORDER_FIRST
argument_list|,
name|kproc_start
argument_list|,
operator|&
name|vm_kp
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
name|int
name|vm_pages_needed
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Event on which pageout daemon sleeps */
end_comment

begin_decl_stmt
name|int
name|vm_pageout_deficit
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Estimated number of pages deficit */
end_comment

begin_decl_stmt
name|int
name|vm_pageout_pages_needed
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* flag saying that the pageout daemon needs pages */
end_comment

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_SWAPPING
argument_list|)
end_if

begin_decl_stmt
specifier|static
name|int
name|vm_pageout_req_swapout
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* XXX */
end_comment

begin_decl_stmt
specifier|static
name|int
name|vm_daemon_needed
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|vm_daemon_mtx
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Allow for use by vm_pageout before vm_daemon is initialized. */
end_comment

begin_expr_stmt
name|MTX_SYSINIT
argument_list|(
name|vm_daemon
argument_list|,
operator|&
name|vm_daemon_mtx
argument_list|,
literal|"vm daemon"
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|int
name|vm_max_launder
init|=
literal|32
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|vm_pageout_stats_max
init|=
literal|0
decl_stmt|,
name|vm_pageout_stats_interval
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|vm_pageout_full_stats_interval
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|vm_pageout_algorithm
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|defer_swap_pageouts
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|disable_swap_pageouts
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_if
if|#
directive|if
name|defined
argument_list|(
name|NO_SWAPPING
argument_list|)
end_if

begin_decl_stmt
specifier|static
name|int
name|vm_swap_enabled
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|vm_swap_idle_enabled
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_else
else|#
directive|else
end_else

begin_decl_stmt
specifier|static
name|int
name|vm_swap_enabled
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|vm_swap_idle_enabled
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|VM_PAGEOUT_ALGORITHM
argument_list|,
name|pageout_algorithm
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vm_pageout_algorithm
argument_list|,
literal|0
argument_list|,
literal|"LRU page mgmt"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|max_launder
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vm_max_launder
argument_list|,
literal|0
argument_list|,
literal|"Limit dirty flushes in pageout"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|pageout_stats_max
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vm_pageout_stats_max
argument_list|,
literal|0
argument_list|,
literal|"Max pageout stats scan length"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|pageout_full_stats_interval
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vm_pageout_full_stats_interval
argument_list|,
literal|0
argument_list|,
literal|"Interval for full stats scan"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|pageout_stats_interval
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vm_pageout_stats_interval
argument_list|,
literal|0
argument_list|,
literal|"Interval for partial stats scan"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_if
if|#
directive|if
name|defined
argument_list|(
name|NO_SWAPPING
argument_list|)
end_if

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|VM_SWAPPING_ENABLED
argument_list|,
name|swap_enabled
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|vm_swap_enabled
argument_list|,
literal|0
argument_list|,
literal|"Enable entire process swapout"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|swap_idle_enabled
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|vm_swap_idle_enabled
argument_list|,
literal|0
argument_list|,
literal|"Allow swapout on idle criteria"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_else
else|#
directive|else
end_else

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|VM_SWAPPING_ENABLED
argument_list|,
name|swap_enabled
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vm_swap_enabled
argument_list|,
literal|0
argument_list|,
literal|"Enable entire process swapout"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|swap_idle_enabled
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vm_swap_idle_enabled
argument_list|,
literal|0
argument_list|,
literal|"Allow swapout on idle criteria"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|defer_swapspace_pageouts
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|defer_swap_pageouts
argument_list|,
literal|0
argument_list|,
literal|"Give preference to dirty pages in mem"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|disable_swapspace_pageouts
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|disable_swap_pageouts
argument_list|,
literal|0
argument_list|,
literal|"Disallow swapout of dirty pages"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pageout_lock_miss
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|pageout_lock_miss
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pageout_lock_miss
argument_list|,
literal|0
argument_list|,
literal|"vget() lock misses during pageout"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_define
define|#
directive|define
name|VM_PAGEOUT_PAGE_COUNT
value|16
end_define

begin_decl_stmt
name|int
name|vm_pageout_page_count
init|=
name|VM_PAGEOUT_PAGE_COUNT
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|vm_page_max_wired
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* XXX max # of wired pages system-wide */
end_comment

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|max_wired
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|vm_page_max_wired
argument_list|,
literal|0
argument_list|,
literal|"System-wide limit to wired page count"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function_decl
specifier|static
name|boolean_t
name|vm_pageout_fallback_object_lock
parameter_list|(
name|vm_page_t
parameter_list|,
name|vm_page_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|vm_pageout_launder
parameter_list|(
name|int
parameter_list|,
name|int
parameter_list|,
name|vm_paddr_t
parameter_list|,
name|vm_paddr_t
parameter_list|)
function_decl|;
end_function_decl

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_SWAPPING
argument_list|)
end_if

begin_function_decl
specifier|static
name|void
name|vm_pageout_map_deactivate_pages
parameter_list|(
name|vm_map_t
parameter_list|,
name|long
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_pageout_object_deactivate_pages
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_object_t
parameter_list|,
name|long
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_req_vmdaemon
parameter_list|(
name|int
name|req
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_function_decl
specifier|static
name|boolean_t
name|vm_pageout_page_lock
parameter_list|(
name|vm_page_t
parameter_list|,
name|vm_page_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_pageout_page_stats
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Initialize a dummy page for marking the caller's place in the specified  * paging queue.  In principle, this function only needs to set the flag  * PG_MARKER.  Nonetheless, it sets the flag VPO_BUSY and initializes the hold  * count to one as safety precautions.  */
end_comment

begin_function
specifier|static
name|void
name|vm_pageout_init_marker
parameter_list|(
name|vm_page_t
name|marker
parameter_list|,
name|u_short
name|queue
parameter_list|)
block|{
name|bzero
argument_list|(
name|marker
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|marker
argument_list|)
argument_list|)
expr_stmt|;
name|marker
operator|->
name|flags
operator|=
name|PG_MARKER
expr_stmt|;
name|marker
operator|->
name|oflags
operator|=
name|VPO_BUSY
expr_stmt|;
name|marker
operator|->
name|queue
operator|=
name|queue
expr_stmt|;
name|marker
operator|->
name|hold_count
operator|=
literal|1
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_pageout_fallback_object_lock:  *   * Lock vm object currently associated with `m'. VM_OBJECT_TRYLOCK is  * known to have failed and page queue must be either PQ_ACTIVE or  * PQ_INACTIVE.  To avoid lock order violation, unlock the page queues  * while locking the vm object.  Use marker page to detect page queue  * changes and maintain notion of next page on page queue.  Return  * TRUE if no changes were detected, FALSE otherwise.  vm object is  * locked on return.  *   * This function depends on both the lock portion of struct vm_object  * and normal struct vm_page being type stable.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|vm_pageout_fallback_object_lock
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_page_t
modifier|*
name|next
parameter_list|)
block|{
name|struct
name|vm_page
name|marker
decl_stmt|;
name|boolean_t
name|unchanged
decl_stmt|;
name|u_short
name|queue
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|queue
operator|=
name|m
operator|->
name|queue
expr_stmt|;
name|vm_pageout_init_marker
argument_list|(
operator|&
name|marker
argument_list|,
name|queue
argument_list|)
expr_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|vm_page_queues
index|[
name|queue
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
operator|&
name|marker
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
comment|/* Page queue might have changed. */
operator|*
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
operator|&
name|marker
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|unchanged
operator|=
operator|(
name|m
operator|->
name|queue
operator|==
name|queue
operator|&&
name|m
operator|->
name|object
operator|==
name|object
operator|&&
operator|&
name|marker
operator|==
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|pageq
argument_list|)
operator|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|vm_page_queues
index|[
name|queue
index|]
operator|.
name|pl
argument_list|,
operator|&
name|marker
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
return|return
operator|(
name|unchanged
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Lock the page while holding the page queue lock.  Use marker page  * to detect page queue changes and maintain notion of next page on  * page queue.  Return TRUE if no changes were detected, FALSE  * otherwise.  The page is locked on return. The page queue lock might  * be dropped and reacquired.  *  * This function depends on normal struct vm_page being type stable.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|vm_pageout_page_lock
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_page_t
modifier|*
name|next
parameter_list|)
block|{
name|struct
name|vm_page
name|marker
decl_stmt|;
name|boolean_t
name|unchanged
decl_stmt|;
name|u_short
name|queue
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_trylock
argument_list|(
name|m
argument_list|)
condition|)
return|return
operator|(
name|TRUE
operator|)
return|;
name|queue
operator|=
name|m
operator|->
name|queue
expr_stmt|;
name|vm_pageout_init_marker
argument_list|(
operator|&
name|marker
argument_list|,
name|queue
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|vm_page_queues
index|[
name|queue
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
operator|&
name|marker
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
comment|/* Page queue might have changed. */
operator|*
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
operator|&
name|marker
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|unchanged
operator|=
operator|(
name|m
operator|->
name|queue
operator|==
name|queue
operator|&&
operator|&
name|marker
operator|==
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|pageq
argument_list|)
operator|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|vm_page_queues
index|[
name|queue
index|]
operator|.
name|pl
argument_list|,
operator|&
name|marker
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
return|return
operator|(
name|unchanged
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_pageout_clean:  *  * Clean the page and remove it from the laundry.  *   * We set the busy bit to cause potential page faults on this page to  * block.  Note the careful timing, however, the busy bit isn't set till  * late and we cannot do anything that will mess with the page.  */
end_comment

begin_function
specifier|static
name|int
name|vm_pageout_clean
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|vm_page_t
name|mc
index|[
literal|2
operator|*
name|vm_pageout_page_count
index|]
decl_stmt|,
name|pb
decl_stmt|,
name|ps
decl_stmt|;
name|int
name|pageout_count
decl_stmt|;
name|int
name|ib
decl_stmt|,
name|is
decl_stmt|,
name|page_base
decl_stmt|;
name|vm_pindex_t
name|pindex
init|=
name|m
operator|->
name|pindex
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * It doesn't cost us anything to pageout OBJT_DEFAULT or OBJT_SWAP 	 * with the new swapper, but we could have serious problems paging 	 * out other object types if there is insufficient memory.   	 * 	 * Unfortunately, checking free memory here is far too late, so the 	 * check has been moved up a procedural level. 	 */
comment|/* 	 * Can't clean the page if it's busy or held. 	 */
name|KASSERT
argument_list|(
name|m
operator|->
name|busy
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_pageout_clean: page %p is busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|hold_count
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_pageout_clean: page %p is held"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|mc
index|[
name|vm_pageout_page_count
index|]
operator|=
name|pb
operator|=
name|ps
operator|=
name|m
expr_stmt|;
name|pageout_count
operator|=
literal|1
expr_stmt|;
name|page_base
operator|=
name|vm_pageout_page_count
expr_stmt|;
name|ib
operator|=
literal|1
expr_stmt|;
name|is
operator|=
literal|1
expr_stmt|;
comment|/* 	 * Scan object for clusterable pages. 	 * 	 * We can cluster ONLY if: ->> the page is NOT 	 * clean, wired, busy, held, or mapped into a 	 * buffer, and one of the following: 	 * 1) The page is inactive, or a seldom used 	 *    active page. 	 * -or- 	 * 2) we force the issue. 	 * 	 * During heavy mmap/modification loads the pageout 	 * daemon can really fragment the underlying file 	 * due to flushing pages out of order and not trying 	 * align the clusters (which leave sporatic out-of-order 	 * holes).  To solve this problem we do the reverse scan 	 * first and attempt to align our cluster, then do a  	 * forward scan if room remains. 	 */
name|more
label|:
while|while
condition|(
name|ib
operator|&&
name|pageout_count
operator|<
name|vm_pageout_page_count
condition|)
block|{
name|vm_page_t
name|p
decl_stmt|;
if|if
condition|(
name|ib
operator|>
name|pindex
condition|)
block|{
name|ib
operator|=
literal|0
expr_stmt|;
break|break;
block|}
if|if
condition|(
operator|(
name|p
operator|=
name|vm_page_prev
argument_list|(
name|pb
argument_list|)
operator|)
operator|==
name|NULL
operator|||
operator|(
name|p
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|!=
literal|0
operator|||
name|p
operator|->
name|busy
operator|!=
literal|0
condition|)
block|{
name|ib
operator|=
literal|0
expr_stmt|;
break|break;
block|}
name|vm_page_lock
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_page_test_dirty
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
operator|->
name|dirty
operator|==
literal|0
operator|||
name|p
operator|->
name|queue
operator|!=
name|PQ_INACTIVE
operator|||
name|p
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
comment|/* may be undergoing I/O */
name|vm_page_unlock
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|ib
operator|=
literal|0
expr_stmt|;
break|break;
block|}
name|vm_page_unlock
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|mc
index|[
operator|--
name|page_base
index|]
operator|=
name|pb
operator|=
name|p
expr_stmt|;
operator|++
name|pageout_count
expr_stmt|;
operator|++
name|ib
expr_stmt|;
comment|/* 		 * alignment boundry, stop here and switch directions.  Do 		 * not clear ib. 		 */
if|if
condition|(
operator|(
name|pindex
operator|-
operator|(
name|ib
operator|-
literal|1
operator|)
operator|)
operator|%
name|vm_pageout_page_count
operator|==
literal|0
condition|)
break|break;
block|}
while|while
condition|(
name|pageout_count
operator|<
name|vm_pageout_page_count
operator|&&
name|pindex
operator|+
name|is
operator|<
name|object
operator|->
name|size
condition|)
block|{
name|vm_page_t
name|p
decl_stmt|;
if|if
condition|(
operator|(
name|p
operator|=
name|vm_page_next
argument_list|(
name|ps
argument_list|)
operator|)
operator|==
name|NULL
operator|||
operator|(
name|p
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|!=
literal|0
operator|||
name|p
operator|->
name|busy
operator|!=
literal|0
condition|)
break|break;
name|vm_page_lock
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_page_test_dirty
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
operator|->
name|dirty
operator|==
literal|0
operator|||
name|p
operator|->
name|queue
operator|!=
name|PQ_INACTIVE
operator|||
name|p
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
comment|/* may be undergoing I/O */
name|vm_page_unlock
argument_list|(
name|p
argument_list|)
expr_stmt|;
break|break;
block|}
name|vm_page_unlock
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|mc
index|[
name|page_base
operator|+
name|pageout_count
index|]
operator|=
name|ps
operator|=
name|p
expr_stmt|;
operator|++
name|pageout_count
expr_stmt|;
operator|++
name|is
expr_stmt|;
block|}
comment|/* 	 * If we exhausted our forward scan, continue with the reverse scan 	 * when possible, even past a page boundry.  This catches boundry 	 * conditions. 	 */
if|if
condition|(
name|ib
operator|&&
name|pageout_count
operator|<
name|vm_pageout_page_count
condition|)
goto|goto
name|more
goto|;
comment|/* 	 * we allow reads during pageouts... 	 */
return|return
operator|(
name|vm_pageout_flush
argument_list|(
operator|&
name|mc
index|[
name|page_base
index|]
argument_list|,
name|pageout_count
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_pageout_flush() - launder the given pages  *  *	The given pages are laundered.  Note that we setup for the start of  *	I/O ( i.e. busy the page ), mark it read-only, and bump the object  *	reference count all in here rather then in the parent.  If we want  *	the parent to do more sophisticated things we may have to change  *	the ordering.  *  *	Returned runlen is the count of pages between mreq and first  *	page after mreq with status VM_PAGER_AGAIN.  *	*eio is set to TRUE if pager returned VM_PAGER_ERROR or VM_PAGER_FAIL  *	for any page in runlen set.  */
end_comment

begin_function
name|int
name|vm_pageout_flush
parameter_list|(
name|vm_page_t
modifier|*
name|mc
parameter_list|,
name|int
name|count
parameter_list|,
name|int
name|flags
parameter_list|,
name|int
name|mreq
parameter_list|,
name|int
modifier|*
name|prunlen
parameter_list|,
name|boolean_t
modifier|*
name|eio
parameter_list|)
block|{
name|vm_object_t
name|object
init|=
name|mc
index|[
literal|0
index|]
operator|->
name|object
decl_stmt|;
name|int
name|pageout_status
index|[
name|count
index|]
decl_stmt|;
name|int
name|numpagedout
init|=
literal|0
decl_stmt|;
name|int
name|i
decl_stmt|,
name|runlen
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Initiate I/O.  Bump the vm_page_t->busy counter and 	 * mark the pages read-only. 	 * 	 * We do not have to fixup the clean/dirty bits here... we can 	 * allow the pager to do it after the I/O completes. 	 * 	 * NOTE! mc[i]->dirty may be partial or fragmented due to an 	 * edge case with file fragments. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|KASSERT
argument_list|(
name|mc
index|[
name|i
index|]
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
argument_list|,
operator|(
literal|"vm_pageout_flush: partially invalid page %p index %d/%d"
operator|,
name|mc
index|[
name|i
index|]
operator|,
name|i
operator|,
name|count
operator|)
argument_list|)
expr_stmt|;
name|vm_page_io_start
argument_list|(
name|mc
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|pmap_remove_write
argument_list|(
name|mc
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
name|vm_object_pip_add
argument_list|(
name|object
argument_list|,
name|count
argument_list|)
expr_stmt|;
name|vm_pager_put_pages
argument_list|(
name|object
argument_list|,
name|mc
argument_list|,
name|count
argument_list|,
name|flags
argument_list|,
name|pageout_status
argument_list|)
expr_stmt|;
name|runlen
operator|=
name|count
operator|-
name|mreq
expr_stmt|;
if|if
condition|(
name|eio
operator|!=
name|NULL
condition|)
operator|*
name|eio
operator|=
name|FALSE
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|mt
init|=
name|mc
index|[
name|i
index|]
decl_stmt|;
name|KASSERT
argument_list|(
name|pageout_status
index|[
name|i
index|]
operator|==
name|VM_PAGER_PEND
operator|||
operator|!
name|pmap_page_is_write_mapped
argument_list|(
name|mt
argument_list|)
argument_list|,
operator|(
literal|"vm_pageout_flush: page %p is not write protected"
operator|,
name|mt
operator|)
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|pageout_status
index|[
name|i
index|]
condition|)
block|{
case|case
name|VM_PAGER_OK
case|:
case|case
name|VM_PAGER_PEND
case|:
name|numpagedout
operator|++
expr_stmt|;
break|break;
case|case
name|VM_PAGER_BAD
case|:
comment|/* 			 * Page outside of range of object. Right now we 			 * essentially lose the changes by pretending it 			 * worked. 			 */
name|vm_page_undirty
argument_list|(
name|mt
argument_list|)
expr_stmt|;
break|break;
case|case
name|VM_PAGER_ERROR
case|:
case|case
name|VM_PAGER_FAIL
case|:
comment|/* 			 * If page couldn't be paged out, then reactivate the 			 * page so it doesn't clog the inactive list.  (We 			 * will try paging out it again later). 			 */
name|vm_page_lock
argument_list|(
name|mt
argument_list|)
expr_stmt|;
name|vm_page_activate
argument_list|(
name|mt
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|mt
argument_list|)
expr_stmt|;
if|if
condition|(
name|eio
operator|!=
name|NULL
operator|&&
name|i
operator|>=
name|mreq
operator|&&
name|i
operator|-
name|mreq
operator|<
name|runlen
condition|)
operator|*
name|eio
operator|=
name|TRUE
expr_stmt|;
break|break;
case|case
name|VM_PAGER_AGAIN
case|:
if|if
condition|(
name|i
operator|>=
name|mreq
operator|&&
name|i
operator|-
name|mreq
operator|<
name|runlen
condition|)
name|runlen
operator|=
name|i
operator|-
name|mreq
expr_stmt|;
break|break;
block|}
comment|/* 		 * If the operation is still going, leave the page busy to 		 * block all other accesses. Also, leave the paging in 		 * progress indicator set so that we don't attempt an object 		 * collapse. 		 */
if|if
condition|(
name|pageout_status
index|[
name|i
index|]
operator|!=
name|VM_PAGER_PEND
condition|)
block|{
name|vm_object_pip_wakeup
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_io_finish
argument_list|(
name|mt
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_count_severe
argument_list|()
condition|)
block|{
name|vm_page_lock
argument_list|(
name|mt
argument_list|)
expr_stmt|;
name|vm_page_try_to_cache
argument_list|(
name|mt
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|mt
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|prunlen
operator|!=
name|NULL
condition|)
operator|*
name|prunlen
operator|=
name|runlen
expr_stmt|;
return|return
operator|(
name|numpagedout
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|boolean_t
name|vm_pageout_launder
parameter_list|(
name|int
name|queue
parameter_list|,
name|int
name|tries
parameter_list|,
name|vm_paddr_t
name|low
parameter_list|,
name|vm_paddr_t
name|high
parameter_list|)
block|{
name|struct
name|mount
modifier|*
name|mp
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|m_tmp
decl_stmt|,
name|next
decl_stmt|;
name|int
name|vfslocked
decl_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|m
argument_list|,
argument|&vm_page_queues[queue].pl
argument_list|,
argument|pageq
argument_list|,
argument|next
argument_list|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|queue
argument_list|,
operator|(
literal|"vm_pageout_launder: page %p's queue is not %d"
operator|,
name|m
operator|,
name|queue
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_MARKER
operator|)
operator|!=
literal|0
condition|)
continue|continue;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|pa
operator|<
name|low
operator|||
name|pa
operator|+
name|PAGE_SIZE
operator|>
name|high
condition|)
continue|continue;
if|if
condition|(
operator|!
name|vm_pageout_page_lock
argument_list|(
name|m
argument_list|,
operator|&
name|next
argument_list|)
operator|||
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
if|if
condition|(
operator|(
operator|!
name|VM_OBJECT_TRYLOCK
argument_list|(
name|object
argument_list|)
operator|&&
operator|(
operator|!
name|vm_pageout_fallback_object_lock
argument_list|(
name|m
argument_list|,
operator|&
name|next
argument_list|)
operator|||
name|m
operator|->
name|hold_count
operator|!=
literal|0
operator|)
operator|)
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|!=
literal|0
operator|||
name|m
operator|->
name|busy
operator|!=
literal|0
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|vm_page_test_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|==
literal|0
condition|)
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|!=
literal|0
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|tries
operator|==
literal|0
operator|||
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_DEAD
operator|)
operator|!=
literal|0
condition|)
block|{
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
block|{
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|vp
operator|=
name|object
operator|->
name|handle
expr_stmt|;
name|vm_object_reference_locked
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|vn_start_write
argument_list|(
name|vp
argument_list|,
operator|&
name|mp
argument_list|,
name|V_WAIT
argument_list|)
expr_stmt|;
name|vfslocked
operator|=
name|VFS_LOCK_GIANT
argument_list|(
name|vp
operator|->
name|v_mount
argument_list|)
expr_stmt|;
name|vn_lock
argument_list|(
name|vp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_RETRY
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_object_page_clean
argument_list|(
name|object
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|OBJPC_SYNC
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|VOP_UNLOCK
argument_list|(
name|vp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|VFS_UNLOCK_GIANT
argument_list|(
name|vfslocked
argument_list|)
expr_stmt|;
name|vm_object_deallocate
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vn_finished_write
argument_list|(
name|mp
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_SWAP
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_DEFAULT
condition|)
block|{
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|m_tmp
operator|=
name|m
expr_stmt|;
name|vm_pageout_flush
argument_list|(
operator|&
name|m_tmp
argument_list|,
literal|1
argument_list|,
name|VM_PAGER_PUT_SYNC
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
block|}
else|else
block|{
name|vm_page_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Increase the number of cached pages.  The specified value, "tries",  * determines which categories of pages are cached:  *  *  0: All clean, inactive pages within the specified physical address range  *     are cached.  Will not sleep.  *  1: The vm_lowmem handlers are called.  All inactive pages within  *     the specified physical address range are cached.  May sleep.  *  2: The vm_lowmem handlers are called.  All inactive and active pages  *     within the specified physical address range are cached.  May sleep.  */
end_comment

begin_function
name|void
name|vm_pageout_grow_cache
parameter_list|(
name|int
name|tries
parameter_list|,
name|vm_paddr_t
name|low
parameter_list|,
name|vm_paddr_t
name|high
parameter_list|)
block|{
name|int
name|actl
decl_stmt|,
name|actmax
decl_stmt|,
name|inactl
decl_stmt|,
name|inactmax
decl_stmt|;
if|if
condition|(
name|tries
operator|>
literal|0
condition|)
block|{
comment|/* 		 * Decrease registered cache sizes.  The vm_lowmem handlers 		 * may acquire locks and/or sleep, so they can only be invoked 		 * when "tries" is greater than zero. 		 */
name|EVENTHANDLER_INVOKE
argument_list|(
name|vm_lowmem
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 		 * We do this explicitly after the caches have been drained 		 * above. 		 */
name|uma_reclaim
argument_list|()
expr_stmt|;
block|}
name|inactl
operator|=
literal|0
expr_stmt|;
name|inactmax
operator|=
name|cnt
operator|.
name|v_inactive_count
expr_stmt|;
name|actl
operator|=
literal|0
expr_stmt|;
name|actmax
operator|=
name|tries
operator|<
literal|2
condition|?
literal|0
else|:
name|cnt
operator|.
name|v_active_count
expr_stmt|;
name|again
label|:
if|if
condition|(
name|inactl
operator|<
name|inactmax
operator|&&
name|vm_pageout_launder
argument_list|(
name|PQ_INACTIVE
argument_list|,
name|tries
argument_list|,
name|low
argument_list|,
name|high
argument_list|)
condition|)
block|{
name|inactl
operator|++
expr_stmt|;
goto|goto
name|again
goto|;
block|}
if|if
condition|(
name|actl
operator|<
name|actmax
operator|&&
name|vm_pageout_launder
argument_list|(
name|PQ_ACTIVE
argument_list|,
name|tries
argument_list|,
name|low
argument_list|,
name|high
argument_list|)
condition|)
block|{
name|actl
operator|++
expr_stmt|;
goto|goto
name|again
goto|;
block|}
block|}
end_function

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_SWAPPING
argument_list|)
end_if

begin_comment
comment|/*  *	vm_pageout_object_deactivate_pages  *  *	Deactivate enough pages to satisfy the inactive target  *	requirements.  *  *	The object and map must be locked.  */
end_comment

begin_function
specifier|static
name|void
name|vm_pageout_object_deactivate_pages
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_object_t
name|first_object
parameter_list|,
name|long
name|desired
parameter_list|)
block|{
name|vm_object_t
name|backing_object
decl_stmt|,
name|object
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|int
name|actcount
decl_stmt|,
name|remove_mode
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|first_object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|first_object
operator|->
name|type
operator|==
name|OBJT_DEVICE
operator|||
name|first_object
operator|->
name|type
operator|==
name|OBJT_SG
condition|)
return|return;
for|for
control|(
name|object
operator|=
name|first_object
init|;
condition|;
name|object
operator|=
name|backing_object
control|)
block|{
if|if
condition|(
name|pmap_resident_count
argument_list|(
name|pmap
argument_list|)
operator|<=
name|desired
condition|)
goto|goto
name|unlock_return
goto|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_PHYS
operator|||
name|object
operator|->
name|paging_in_progress
condition|)
goto|goto
name|unlock_return
goto|;
name|remove_mode
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|shadow_count
operator|>
literal|1
condition|)
name|remove_mode
operator|=
literal|1
expr_stmt|;
comment|/* 		 * Scan the object's entire memory queue. 		 */
name|TAILQ_FOREACH
argument_list|(
argument|p
argument_list|,
argument|&object->memq
argument_list|,
argument|listq
argument_list|)
block|{
if|if
condition|(
name|pmap_resident_count
argument_list|(
name|pmap
argument_list|)
operator|<=
name|desired
condition|)
goto|goto
name|unlock_return
goto|;
if|if
condition|(
operator|(
name|p
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|!=
literal|0
operator|||
name|p
operator|->
name|busy
operator|!=
literal|0
condition|)
continue|continue;
name|PCPU_INC
argument_list|(
name|cnt
operator|.
name|v_pdpages
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
operator|->
name|wire_count
operator|!=
literal|0
operator|||
name|p
operator|->
name|hold_count
operator|!=
literal|0
operator|||
operator|!
name|pmap_page_exists_quick
argument_list|(
name|pmap
argument_list|,
name|p
argument_list|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|actcount
operator|=
name|pmap_ts_referenced
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|p
operator|->
name|aflags
operator|&
name|PGA_REFERENCED
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|actcount
operator|==
literal|0
condition|)
name|actcount
operator|=
literal|1
expr_stmt|;
name|vm_page_aflag_clear
argument_list|(
name|p
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|p
operator|->
name|queue
operator|!=
name|PQ_ACTIVE
operator|&&
name|actcount
operator|!=
literal|0
condition|)
block|{
name|vm_page_activate
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|p
operator|->
name|act_count
operator|+=
name|actcount
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|p
operator|->
name|queue
operator|==
name|PQ_ACTIVE
condition|)
block|{
if|if
condition|(
name|actcount
operator|==
literal|0
condition|)
block|{
name|p
operator|->
name|act_count
operator|-=
name|min
argument_list|(
name|p
operator|->
name|act_count
argument_list|,
name|ACT_DECLINE
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|remove_mode
operator|&&
operator|(
name|vm_pageout_algorithm
operator|||
name|p
operator|->
name|act_count
operator|==
literal|0
operator|)
condition|)
block|{
name|pmap_remove_all
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_page_deactivate
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_requeue
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
name|vm_page_activate
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
operator|->
name|act_count
operator|<
name|ACT_MAX
operator|-
name|ACT_ADVANCE
condition|)
name|p
operator|->
name|act_count
operator|+=
name|ACT_ADVANCE
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_requeue
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|p
operator|->
name|queue
operator|==
name|PQ_INACTIVE
condition|)
name|pmap_remove_all
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|backing_object
operator|=
name|object
operator|->
name|backing_object
operator|)
operator|==
name|NULL
condition|)
goto|goto
name|unlock_return
goto|;
name|VM_OBJECT_LOCK
argument_list|(
name|backing_object
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|first_object
condition|)
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
name|unlock_return
label|:
if|if
condition|(
name|object
operator|!=
name|first_object
condition|)
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * deactivate some number of pages in a map, try to do it fairly, but  * that is really hard to do.  */
end_comment

begin_function
specifier|static
name|void
name|vm_pageout_map_deactivate_pages
parameter_list|(
name|map
parameter_list|,
name|desired
parameter_list|)
name|vm_map_t
name|map
decl_stmt|;
name|long
name|desired
decl_stmt|;
block|{
name|vm_map_entry_t
name|tmpe
decl_stmt|;
name|vm_object_t
name|obj
decl_stmt|,
name|bigobj
decl_stmt|;
name|int
name|nothingwired
decl_stmt|;
if|if
condition|(
operator|!
name|vm_map_trylock
argument_list|(
name|map
argument_list|)
condition|)
return|return;
name|bigobj
operator|=
name|NULL
expr_stmt|;
name|nothingwired
operator|=
name|TRUE
expr_stmt|;
comment|/* 	 * first, search out the biggest object, and try to free pages from 	 * that. 	 */
name|tmpe
operator|=
name|map
operator|->
name|header
operator|.
name|next
expr_stmt|;
while|while
condition|(
name|tmpe
operator|!=
operator|&
name|map
operator|->
name|header
condition|)
block|{
if|if
condition|(
operator|(
name|tmpe
operator|->
name|eflags
operator|&
name|MAP_ENTRY_IS_SUB_MAP
operator|)
operator|==
literal|0
condition|)
block|{
name|obj
operator|=
name|tmpe
operator|->
name|object
operator|.
name|vm_object
expr_stmt|;
if|if
condition|(
name|obj
operator|!=
name|NULL
operator|&&
name|VM_OBJECT_TRYLOCK
argument_list|(
name|obj
argument_list|)
condition|)
block|{
if|if
condition|(
name|obj
operator|->
name|shadow_count
operator|<=
literal|1
operator|&&
operator|(
name|bigobj
operator|==
name|NULL
operator|||
name|bigobj
operator|->
name|resident_page_count
operator|<
name|obj
operator|->
name|resident_page_count
operator|)
condition|)
block|{
if|if
condition|(
name|bigobj
operator|!=
name|NULL
condition|)
name|VM_OBJECT_UNLOCK
argument_list|(
name|bigobj
argument_list|)
expr_stmt|;
name|bigobj
operator|=
name|obj
expr_stmt|;
block|}
else|else
name|VM_OBJECT_UNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|tmpe
operator|->
name|wired_count
operator|>
literal|0
condition|)
name|nothingwired
operator|=
name|FALSE
expr_stmt|;
name|tmpe
operator|=
name|tmpe
operator|->
name|next
expr_stmt|;
block|}
if|if
condition|(
name|bigobj
operator|!=
name|NULL
condition|)
block|{
name|vm_pageout_object_deactivate_pages
argument_list|(
name|map
operator|->
name|pmap
argument_list|,
name|bigobj
argument_list|,
name|desired
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|bigobj
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Next, hunt around for other pages to deactivate.  We actually 	 * do this search sort of wrong -- .text first is not the best idea. 	 */
name|tmpe
operator|=
name|map
operator|->
name|header
operator|.
name|next
expr_stmt|;
while|while
condition|(
name|tmpe
operator|!=
operator|&
name|map
operator|->
name|header
condition|)
block|{
if|if
condition|(
name|pmap_resident_count
argument_list|(
name|vm_map_pmap
argument_list|(
name|map
argument_list|)
argument_list|)
operator|<=
name|desired
condition|)
break|break;
if|if
condition|(
operator|(
name|tmpe
operator|->
name|eflags
operator|&
name|MAP_ENTRY_IS_SUB_MAP
operator|)
operator|==
literal|0
condition|)
block|{
name|obj
operator|=
name|tmpe
operator|->
name|object
operator|.
name|vm_object
expr_stmt|;
if|if
condition|(
name|obj
operator|!=
name|NULL
condition|)
block|{
name|VM_OBJECT_LOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
name|vm_pageout_object_deactivate_pages
argument_list|(
name|map
operator|->
name|pmap
argument_list|,
name|obj
argument_list|,
name|desired
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
block|}
block|}
name|tmpe
operator|=
name|tmpe
operator|->
name|next
expr_stmt|;
block|}
comment|/* 	 * Remove all mappings if a process is swapped out, this will free page 	 * table pages. 	 */
if|if
condition|(
name|desired
operator|==
literal|0
operator|&&
name|nothingwired
condition|)
block|{
name|pmap_remove
argument_list|(
name|vm_map_pmap
argument_list|(
name|map
argument_list|)
argument_list|,
name|vm_map_min
argument_list|(
name|map
argument_list|)
argument_list|,
name|vm_map_max
argument_list|(
name|map
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|vm_map_unlock
argument_list|(
name|map
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* !defined(NO_SWAPPING) */
end_comment

begin_comment
comment|/*  *	vm_pageout_scan does the dirty work for the pageout daemon.  */
end_comment

begin_function
specifier|static
name|void
name|vm_pageout_scan
parameter_list|(
name|int
name|pass
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|,
name|next
decl_stmt|;
name|struct
name|vm_page
name|marker
decl_stmt|;
name|int
name|page_shortage
decl_stmt|,
name|maxscan
decl_stmt|,
name|pcount
decl_stmt|;
name|int
name|addl_page_shortage
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|int
name|actcount
decl_stmt|;
name|int
name|vnodes_skipped
init|=
literal|0
decl_stmt|;
name|int
name|maxlaunder
decl_stmt|;
name|boolean_t
name|queues_locked
decl_stmt|;
comment|/* 	 * Decrease registered cache sizes. 	 */
name|EVENTHANDLER_INVOKE
argument_list|(
name|vm_lowmem
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/* 	 * We do this explicitly after the caches have been drained above. 	 */
name|uma_reclaim
argument_list|()
expr_stmt|;
comment|/* 	 * The addl_page_shortage is the number of temporarily 	 * stuck pages in the inactive queue.  In other words, the 	 * number of pages from cnt.v_inactive_count that should be 	 * discounted in setting the target for the active queue scan. 	 */
name|addl_page_shortage
operator|=
name|atomic_readandclear_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|)
expr_stmt|;
comment|/* 	 * Calculate the number of pages we want to either free or move 	 * to the cache. 	 */
name|page_shortage
operator|=
name|vm_paging_target
argument_list|()
operator|+
name|addl_page_shortage
expr_stmt|;
name|vm_pageout_init_marker
argument_list|(
operator|&
name|marker
argument_list|,
name|PQ_INACTIVE
argument_list|)
expr_stmt|;
comment|/* 	 * Start scanning the inactive queue for pages we can move to the 	 * cache or free.  The scan will stop when the target is reached or 	 * we have scanned the entire inactive queue.  Note that m->act_count 	 * is not used to form decisions for the inactive queue, only for the 	 * active queue. 	 * 	 * maxlaunder limits the number of dirty pages we flush per scan. 	 * For most systems a smaller value (16 or 32) is more robust under 	 * extreme memory and disk pressure because any unnecessary writes 	 * to disk can result in extreme performance degredation.  However, 	 * systems with excessive dirty pages (especially when MAP_NOSYNC is 	 * used) will die horribly with limited laundering.  If the pageout 	 * daemon cannot clean enough pages in the first pass, we let it go 	 * all out in succeeding passes. 	 */
if|if
condition|(
operator|(
name|maxlaunder
operator|=
name|vm_max_launder
operator|)
operator|<=
literal|1
condition|)
name|maxlaunder
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|pass
condition|)
name|maxlaunder
operator|=
literal|10000
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|queues_locked
operator|=
name|TRUE
expr_stmt|;
name|maxscan
operator|=
name|cnt
operator|.
name|v_inactive_count
expr_stmt|;
for|for
control|(
name|m
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|)
init|;
name|m
operator|!=
name|NULL
operator|&&
name|maxscan
operator|--
operator|>
literal|0
operator|&&
name|page_shortage
operator|>
literal|0
condition|;
name|m
operator|=
name|next
control|)
block|{
name|KASSERT
argument_list|(
name|queues_locked
argument_list|,
operator|(
literal|"unlocked queues"
operator|)
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_INACTIVE
argument_list|,
operator|(
literal|"Inactive queue %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|cnt
operator|.
name|v_pdpages
operator|++
expr_stmt|;
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
comment|/* 		 * skip marker pages 		 */
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_MARKER
condition|)
continue|continue;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"Fictitious page %p cannot be in inactive queue"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"Unmanaged page %p cannot be in inactive queue"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * The page or object lock acquisitions fail if the 		 * page was removed from the queue or moved to a 		 * different position within the queue.  In either 		 * case, addl_page_shortage should not be incremented. 		 */
if|if
condition|(
operator|!
name|vm_pageout_page_lock
argument_list|(
name|m
argument_list|,
operator|&
name|next
argument_list|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
if|if
condition|(
operator|!
name|VM_OBJECT_TRYLOCK
argument_list|(
name|object
argument_list|)
operator|&&
operator|!
name|vm_pageout_fallback_object_lock
argument_list|(
name|m
argument_list|,
operator|&
name|next
argument_list|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Don't mess with busy pages, keep them at at the 		 * front of the queue, most likely they are being 		 * paged out.  Increment addl_page_shortage for busy 		 * pages, because they may leave the inactive queue 		 * shortly after page scan is finished. 		 */
if|if
condition|(
name|m
operator|->
name|busy
operator|!=
literal|0
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|!=
literal|0
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|addl_page_shortage
operator|++
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * We unlock vm_page_queue_mtx, invalidating the 		 * 'next' pointer.  Use our marker to remember our 		 * place. 		 */
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
operator|&
name|marker
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|queues_locked
operator|=
name|FALSE
expr_stmt|;
comment|/* 		 * If the object is not being used, we ignore previous  		 * references. 		 */
if|if
condition|(
name|object
operator|->
name|ref_count
operator|==
literal|0
condition|)
block|{
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_pageout_scan: page %p is mapped"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Otherwise, if the page has been referenced while in the  		 * inactive queue, we bump the "activation count" upwards,  		 * making it less likely that the page will be added back to  		 * the inactive queue prematurely again.  Here we check the  		 * page tables (or emulated bits, if any), given the upper  		 * level VM system not knowing anything about existing  		 * references. 		 */
block|}
elseif|else
if|if
condition|(
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_REFERENCED
operator|)
operator|==
literal|0
operator|&&
operator|(
name|actcount
operator|=
name|pmap_ts_referenced
argument_list|(
name|m
argument_list|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|vm_page_activate
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|act_count
operator|+=
name|actcount
operator|+
name|ACT_ADVANCE
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|relock_queues
goto|;
block|}
comment|/* 		 * If the upper level VM system knows about any page  		 * references, we activate the page.  We also set the  		 * "activation count" higher than normal so that we will less  		 * likely place pages back onto the inactive queue again. 		 */
if|if
condition|(
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_REFERENCED
operator|)
operator|!=
literal|0
condition|)
block|{
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|actcount
operator|=
name|pmap_ts_referenced
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_activate
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|act_count
operator|+=
name|actcount
operator|+
name|ACT_ADVANCE
operator|+
literal|1
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|relock_queues
goto|;
block|}
if|if
condition|(
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 			 * Held pages are essentially stuck in the 			 * queue.  So, they ought to be discounted 			 * from cnt.v_inactive_count.  See the 			 * calculation of the page_shortage for the 			 * loop over the active queue below. 			 */
name|addl_page_shortage
operator|++
expr_stmt|;
goto|goto
name|relock_queues
goto|;
block|}
comment|/* 		 * If the upper level VM system does not believe that the page 		 * is fully dirty, but it is mapped for write access, then we 		 * consult the pmap to see if the page's dirty status should 		 * be updated. 		 */
if|if
condition|(
name|m
operator|->
name|dirty
operator|!=
name|VM_PAGE_BITS_ALL
operator|&&
name|pmap_page_is_write_mapped
argument_list|(
name|m
argument_list|)
condition|)
block|{
comment|/* 			 * Avoid a race condition: Unless write access is 			 * removed from the page, another processor could 			 * modify it before all access is removed by the call 			 * to vm_page_cache() below.  If vm_page_cache() finds 			 * that the page has been modified when it removes all 			 * access, it panics because it cannot cache dirty 			 * pages.  In principle, we could eliminate just write 			 * access here rather than all access.  In the expected 			 * case, when there are no last instant modifications 			 * to the page, removing all access will be cheaper 			 * overall. 			 */
if|if
condition|(
name|pmap_is_modified
argument_list|(
name|m
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|m
operator|->
name|dirty
operator|==
literal|0
condition|)
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|m
operator|->
name|valid
operator|==
literal|0
condition|)
block|{
comment|/* 			 * Invalid pages can be easily freed 			 */
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|PCPU_INC
argument_list|(
name|cnt
operator|.
name|v_dfree
argument_list|)
expr_stmt|;
operator|--
name|page_shortage
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|m
operator|->
name|dirty
operator|==
literal|0
condition|)
block|{
comment|/* 			 * Clean pages can be placed onto the cache queue. 			 * This effectively frees them. 			 */
name|vm_page_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
operator|--
name|page_shortage
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_WINATCFLS
operator|)
operator|==
literal|0
operator|&&
name|pass
operator|==
literal|0
condition|)
block|{
comment|/* 			 * Dirty pages need to be paged out, but flushing 			 * a page is extremely expensive verses freeing 			 * a clean page.  Rather then artificially limiting 			 * the number of pages we can flush, we instead give 			 * dirty pages extra priority on the inactive queue 			 * by forcing them to be cycled through the queue 			 * twice before being flushed, after which the 			 * (now clean) page will cycle through once more 			 * before being freed.  This significantly extends 			 * the thrash point for a heavily loaded machine. 			 */
name|m
operator|->
name|flags
operator||=
name|PG_WINATCFLS
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|queues_locked
operator|=
name|TRUE
expr_stmt|;
name|vm_page_requeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|maxlaunder
operator|>
literal|0
condition|)
block|{
comment|/* 			 * We always want to try to flush some dirty pages if 			 * we encounter them, to keep the system stable. 			 * Normally this number is small, but under extreme 			 * pressure where there are insufficient clean pages 			 * on the inactive queue, we may have to go all out. 			 */
name|int
name|swap_pageouts_ok
decl_stmt|,
name|vfslocked
init|=
literal|0
decl_stmt|;
name|struct
name|vnode
modifier|*
name|vp
init|=
name|NULL
decl_stmt|;
name|struct
name|mount
modifier|*
name|mp
init|=
name|NULL
decl_stmt|;
if|if
condition|(
operator|(
name|object
operator|->
name|type
operator|!=
name|OBJT_SWAP
operator|)
operator|&&
operator|(
name|object
operator|->
name|type
operator|!=
name|OBJT_DEFAULT
operator|)
condition|)
block|{
name|swap_pageouts_ok
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|swap_pageouts_ok
operator|=
operator|!
operator|(
name|defer_swap_pageouts
operator|||
name|disable_swap_pageouts
operator|)
expr_stmt|;
name|swap_pageouts_ok
operator||=
operator|(
operator|!
name|disable_swap_pageouts
operator|&&
name|defer_swap_pageouts
operator|&&
name|vm_page_count_min
argument_list|()
operator|)
expr_stmt|;
block|}
comment|/* 			 * We don't bother paging objects that are "dead".   			 * Those objects are in a "rundown" state. 			 */
if|if
condition|(
operator|!
name|swap_pageouts_ok
operator|||
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_DEAD
operator|)
condition|)
block|{
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|queues_locked
operator|=
name|TRUE
expr_stmt|;
name|vm_page_requeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
goto|goto
name|relock_queues
goto|;
block|}
comment|/* 			 * The object is already known NOT to be dead.   It 			 * is possible for the vget() to block the whole 			 * pageout daemon, but the new low-memory handling 			 * code should prevent it. 			 * 			 * The previous code skipped locked vnodes and, worse, 			 * reordered pages in the queue.  This results in 			 * completely non-deterministic operation and, on a 			 * busy system, can lead to extremely non-optimal 			 * pageouts.  For example, it can cause clean pages 			 * to be freed and dirty pages to be moved to the end 			 * of the queue.  Since dirty pages are also moved to 			 * the end of the queue once-cleaned, this gives 			 * way too large a weighting to defering the freeing 			 * of dirty pages. 			 * 			 * We can't wait forever for the vnode lock, we might 			 * deadlock due to a vn_read() getting stuck in 			 * vm_wait while holding this vnode.  We skip the  			 * vnode if we can't get it in a reasonable amount 			 * of time. 			 */
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vp
operator|=
name|object
operator|->
name|handle
expr_stmt|;
if|if
condition|(
name|vp
operator|->
name|v_type
operator|==
name|VREG
operator|&&
name|vn_start_write
argument_list|(
name|vp
argument_list|,
operator|&
name|mp
argument_list|,
name|V_NOWAIT
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|mp
operator|=
name|NULL
expr_stmt|;
operator|++
name|pageout_lock_miss
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|flags
operator|&
name|OBJ_MIGHTBEDIRTY
condition|)
name|vnodes_skipped
operator|++
expr_stmt|;
goto|goto
name|unlock_and_continue
goto|;
block|}
name|KASSERT
argument_list|(
name|mp
operator|!=
name|NULL
argument_list|,
operator|(
literal|"vp %p with NULL v_mount"
operator|,
name|vp
operator|)
argument_list|)
expr_stmt|;
name|vm_object_reference_locked
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vfslocked
operator|=
name|VFS_LOCK_GIANT
argument_list|(
name|vp
operator|->
name|v_mount
argument_list|)
expr_stmt|;
if|if
condition|(
name|vget
argument_list|(
name|vp
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_TIMELOCK
argument_list|,
name|curthread
argument_list|)
condition|)
block|{
name|VM_OBJECT_LOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
operator|++
name|pageout_lock_miss
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|flags
operator|&
name|OBJ_MIGHTBEDIRTY
condition|)
name|vnodes_skipped
operator|++
expr_stmt|;
name|vp
operator|=
name|NULL
expr_stmt|;
goto|goto
name|unlock_and_continue
goto|;
block|}
name|VM_OBJECT_LOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|queues_locked
operator|=
name|TRUE
expr_stmt|;
comment|/* 				 * The page might have been moved to another 				 * queue during potential blocking in vget() 				 * above.  The page might have been freed and 				 * reused for another vnode. 				 */
if|if
condition|(
name|m
operator|->
name|queue
operator|!=
name|PQ_INACTIVE
operator|||
name|m
operator|->
name|object
operator|!=
name|object
operator|||
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|pageq
argument_list|)
operator|!=
operator|&
name|marker
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|flags
operator|&
name|OBJ_MIGHTBEDIRTY
condition|)
name|vnodes_skipped
operator|++
expr_stmt|;
goto|goto
name|unlock_and_continue
goto|;
block|}
comment|/* 				 * The page may have been busied during the 				 * blocking in vget().  We don't move the 				 * page back onto the end of the queue so that 				 * statistics are more correct if we don't. 				 */
if|if
condition|(
name|m
operator|->
name|busy
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
goto|goto
name|unlock_and_continue
goto|;
block|}
comment|/* 				 * If the page has become held it might 				 * be undergoing I/O, so skip it 				 */
if|if
condition|(
name|m
operator|->
name|hold_count
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_requeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|flags
operator|&
name|OBJ_MIGHTBEDIRTY
condition|)
name|vnodes_skipped
operator|++
expr_stmt|;
goto|goto
name|unlock_and_continue
goto|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|queues_locked
operator|=
name|FALSE
expr_stmt|;
block|}
comment|/* 			 * If a page is dirty, then it is either being washed 			 * (but not yet cleaned) or it is still in the 			 * laundry.  If it is still in the laundry, then we 			 * start the cleaning operation.  			 * 			 * decrement page_shortage on success to account for 			 * the (future) cleaned page.  Otherwise we could wind 			 * up laundering or cleaning too many pages. 			 */
if|if
condition|(
name|vm_pageout_clean
argument_list|(
name|m
argument_list|)
operator|!=
literal|0
condition|)
block|{
operator|--
name|page_shortage
expr_stmt|;
operator|--
name|maxlaunder
expr_stmt|;
block|}
name|unlock_and_continue
label|:
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|mp
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|queues_locked
condition|)
block|{
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|queues_locked
operator|=
name|FALSE
expr_stmt|;
block|}
if|if
condition|(
name|vp
operator|!=
name|NULL
condition|)
name|vput
argument_list|(
name|vp
argument_list|)
expr_stmt|;
name|VFS_UNLOCK_GIANT
argument_list|(
name|vfslocked
argument_list|)
expr_stmt|;
name|vm_object_deallocate
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vn_finished_write
argument_list|(
name|mp
argument_list|)
expr_stmt|;
block|}
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
goto|goto
name|relock_queues
goto|;
block|}
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|relock_queues
label|:
if|if
condition|(
operator|!
name|queues_locked
condition|)
block|{
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|queues_locked
operator|=
name|TRUE
expr_stmt|;
block|}
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
operator|&
name|marker
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|,
operator|&
name|marker
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Compute the number of pages we want to try to move from the 	 * active queue to the inactive queue. 	 */
name|page_shortage
operator|=
name|vm_paging_target
argument_list|()
operator|+
name|cnt
operator|.
name|v_inactive_target
operator|-
name|cnt
operator|.
name|v_inactive_count
expr_stmt|;
name|page_shortage
operator|+=
name|addl_page_shortage
expr_stmt|;
comment|/* 	 * Scan the active queue for things we can deactivate. We nominally 	 * track the per-page activity counter and use it to locate 	 * deactivation candidates. 	 */
name|pcount
operator|=
name|cnt
operator|.
name|v_active_count
expr_stmt|;
name|m
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pl
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|m
operator|!=
name|NULL
operator|)
operator|&&
operator|(
name|pcount
operator|--
operator|>
literal|0
operator|)
operator|&&
operator|(
name|page_shortage
operator|>
literal|0
operator|)
condition|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_ACTIVE
argument_list|,
operator|(
literal|"vm_pageout_scan: page %p isn't active"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_MARKER
operator|)
operator|!=
literal|0
condition|)
block|{
name|m
operator|=
name|next
expr_stmt|;
continue|continue;
block|}
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"Fictitious page %p cannot be in active queue"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"Unmanaged page %p cannot be in active queue"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_pageout_page_lock
argument_list|(
name|m
argument_list|,
operator|&
name|next
argument_list|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|=
name|next
expr_stmt|;
continue|continue;
block|}
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
if|if
condition|(
operator|!
name|VM_OBJECT_TRYLOCK
argument_list|(
name|object
argument_list|)
operator|&&
operator|!
name|vm_pageout_fallback_object_lock
argument_list|(
name|m
argument_list|,
operator|&
name|next
argument_list|)
condition|)
block|{
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|=
name|next
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Don't deactivate pages that are busy. 		 */
if|if
condition|(
operator|(
name|m
operator|->
name|busy
operator|!=
literal|0
operator|)
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|||
operator|(
name|m
operator|->
name|hold_count
operator|!=
literal|0
operator|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_requeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|=
name|next
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * The count for pagedaemon pages is done after checking the 		 * page for eligibility... 		 */
name|cnt
operator|.
name|v_pdpages
operator|++
expr_stmt|;
comment|/* 		 * Check to see "how much" the page has been used. 		 */
name|actcount
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|ref_count
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|aflags
operator|&
name|PGA_REFERENCED
condition|)
block|{
name|actcount
operator|+=
literal|1
expr_stmt|;
block|}
name|actcount
operator|+=
name|pmap_ts_referenced
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|actcount
condition|)
block|{
name|m
operator|->
name|act_count
operator|+=
name|ACT_ADVANCE
operator|+
name|actcount
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|act_count
operator|>
name|ACT_MAX
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_MAX
expr_stmt|;
block|}
block|}
comment|/* 		 * Since we have "tested" this bit, we need to clear it now. 		 */
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
comment|/* 		 * Only if an object is currently being used, do we use the 		 * page activation count stats. 		 */
if|if
condition|(
name|actcount
operator|&&
operator|(
name|object
operator|->
name|ref_count
operator|!=
literal|0
operator|)
condition|)
block|{
name|vm_page_requeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|m
operator|->
name|act_count
operator|-=
name|min
argument_list|(
name|m
operator|->
name|act_count
argument_list|,
name|ACT_DECLINE
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_pageout_algorithm
operator|||
name|object
operator|->
name|ref_count
operator|==
literal|0
operator|||
name|m
operator|->
name|act_count
operator|==
literal|0
condition|)
block|{
name|page_shortage
operator|--
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|ref_count
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_pageout_scan: page %p is mapped"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|==
literal|0
condition|)
name|vm_page_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
else|else
name|vm_page_deactivate
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|vm_page_deactivate
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|vm_page_requeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|m
operator|=
name|next
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_SWAPPING
argument_list|)
comment|/* 	 * Idle process swapout -- run once per second. 	 */
if|if
condition|(
name|vm_swap_idle_enabled
condition|)
block|{
specifier|static
name|long
name|lsec
decl_stmt|;
if|if
condition|(
name|time_second
operator|!=
name|lsec
condition|)
block|{
name|vm_req_vmdaemon
argument_list|(
name|VM_SWAP_IDLE
argument_list|)
expr_stmt|;
name|lsec
operator|=
name|time_second
expr_stmt|;
block|}
block|}
endif|#
directive|endif
comment|/* 	 * If we didn't get enough free pages, and we have skipped a vnode 	 * in a writeable object, wakeup the sync daemon.  And kick swapout 	 * if we did not get enough free pages. 	 */
if|if
condition|(
name|vm_paging_target
argument_list|()
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|vnodes_skipped
operator|&&
name|vm_page_count_min
argument_list|()
condition|)
operator|(
name|void
operator|)
name|speedup_syncer
argument_list|()
expr_stmt|;
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_SWAPPING
argument_list|)
if|if
condition|(
name|vm_swap_enabled
operator|&&
name|vm_page_count_target
argument_list|()
condition|)
name|vm_req_vmdaemon
argument_list|(
name|VM_SWAP_NORMAL
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
comment|/* 	 * If we are critically low on one of RAM or swap and low on 	 * the other, kill the largest process.  However, we avoid 	 * doing this on the first pass in order to give ourselves a 	 * chance to flush out dirty vnode-backed pages and to allow 	 * active pages to be moved to the inactive queue and reclaimed. 	 */
if|if
condition|(
name|pass
operator|!=
literal|0
operator|&&
operator|(
operator|(
name|swap_pager_avail
operator|<
literal|64
operator|&&
name|vm_page_count_min
argument_list|()
operator|)
operator|||
operator|(
name|swap_pager_full
operator|&&
name|vm_paging_target
argument_list|()
operator|>
literal|0
operator|)
operator|)
condition|)
name|vm_pageout_oom
argument_list|(
name|VM_OOM_MEM
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_pageout_oom
parameter_list|(
name|int
name|shortage
parameter_list|)
block|{
name|struct
name|proc
modifier|*
name|p
decl_stmt|,
modifier|*
name|bigproc
decl_stmt|;
name|vm_offset_t
name|size
decl_stmt|,
name|bigsize
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|vmspace
modifier|*
name|vm
decl_stmt|;
comment|/* 	 * We keep the process bigproc locked once we find it to keep anyone 	 * from messing with it; however, there is a possibility of 	 * deadlock if process B is bigproc and one of it's child processes 	 * attempts to propagate a signal to B while we are waiting for A's 	 * lock while walking this list.  To avoid this, we don't block on 	 * the process lock but just skip a process if it is already locked. 	 */
name|bigproc
operator|=
name|NULL
expr_stmt|;
name|bigsize
operator|=
literal|0
expr_stmt|;
name|sx_slock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
name|FOREACH_PROC_IN_SYSTEM
argument_list|(
argument|p
argument_list|)
block|{
name|int
name|breakout
decl_stmt|;
if|if
condition|(
name|PROC_TRYLOCK
argument_list|(
name|p
argument_list|)
operator|==
literal|0
condition|)
continue|continue;
comment|/* 		 * If this is a system, protected or killed process, skip it. 		 */
if|if
condition|(
name|p
operator|->
name|p_state
operator|!=
name|PRS_NORMAL
operator|||
operator|(
name|p
operator|->
name|p_flag
operator|&
operator|(
name|P_INEXEC
operator||
name|P_PROTECTED
operator||
name|P_SYSTEM
operator|)
operator|)
operator|||
operator|(
name|p
operator|->
name|p_pid
operator|==
literal|1
operator|)
operator|||
name|P_KILLED
argument_list|(
name|p
argument_list|)
operator|||
operator|(
operator|(
name|p
operator|->
name|p_pid
operator|<
literal|48
operator|)
operator|&&
operator|(
name|swap_pager_avail
operator|!=
literal|0
operator|)
operator|)
condition|)
block|{
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * If the process is in a non-running type state, 		 * don't touch it.  Check all the threads individually. 		 */
name|breakout
operator|=
literal|0
expr_stmt|;
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
operator|&&
operator|!
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
operator|&&
operator|!
name|TD_IS_SLEEPING
argument_list|(
name|td
argument_list|)
operator|&&
operator|!
name|TD_IS_SUSPENDED
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|breakout
operator|=
literal|1
expr_stmt|;
break|break;
block|}
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|breakout
condition|)
block|{
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * get the process size 		 */
name|vm
operator|=
name|vmspace_acquire_ref
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm
operator|==
name|NULL
condition|)
block|{
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|!
name|vm_map_trylock_read
argument_list|(
operator|&
name|vm
operator|->
name|vm_map
argument_list|)
condition|)
block|{
name|vmspace_free
argument_list|(
name|vm
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|size
operator|=
name|vmspace_swap_count
argument_list|(
name|vm
argument_list|)
expr_stmt|;
name|vm_map_unlock_read
argument_list|(
operator|&
name|vm
operator|->
name|vm_map
argument_list|)
expr_stmt|;
if|if
condition|(
name|shortage
operator|==
name|VM_OOM_MEM
condition|)
name|size
operator|+=
name|vmspace_resident_count
argument_list|(
name|vm
argument_list|)
expr_stmt|;
name|vmspace_free
argument_list|(
name|vm
argument_list|)
expr_stmt|;
comment|/* 		 * if the this process is bigger than the biggest one 		 * remember it. 		 */
if|if
condition|(
name|size
operator|>
name|bigsize
condition|)
block|{
if|if
condition|(
name|bigproc
operator|!=
name|NULL
condition|)
name|PROC_UNLOCK
argument_list|(
name|bigproc
argument_list|)
expr_stmt|;
name|bigproc
operator|=
name|p
expr_stmt|;
name|bigsize
operator|=
name|size
expr_stmt|;
block|}
else|else
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|bigproc
operator|!=
name|NULL
condition|)
block|{
name|killproc
argument_list|(
name|bigproc
argument_list|,
literal|"out of swap space"
argument_list|)
expr_stmt|;
name|sched_nice
argument_list|(
name|bigproc
argument_list|,
name|PRIO_MIN
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|bigproc
argument_list|)
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * This routine tries to maintain the pseudo LRU active queue,  * so that during long periods of time where there is no paging,  * that some statistic accumulation still occurs.  This code  * helps the situation where paging just starts to occur.  */
end_comment

begin_function
specifier|static
name|void
name|vm_pageout_page_stats
parameter_list|()
block|{
name|vm_object_t
name|object
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|next
decl_stmt|;
name|int
name|pcount
decl_stmt|,
name|tpcount
decl_stmt|;
comment|/* Number of pages to check */
specifier|static
name|int
name|fullintervalcount
init|=
literal|0
decl_stmt|;
name|int
name|page_shortage
decl_stmt|;
name|page_shortage
operator|=
operator|(
name|cnt
operator|.
name|v_inactive_target
operator|+
name|cnt
operator|.
name|v_cache_max
operator|+
name|cnt
operator|.
name|v_free_min
operator|)
operator|-
operator|(
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_inactive_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|)
expr_stmt|;
if|if
condition|(
name|page_shortage
operator|<=
literal|0
condition|)
return|return;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|pcount
operator|=
name|cnt
operator|.
name|v_active_count
expr_stmt|;
name|fullintervalcount
operator|+=
name|vm_pageout_stats_interval
expr_stmt|;
if|if
condition|(
name|fullintervalcount
operator|<
name|vm_pageout_full_stats_interval
condition|)
block|{
name|tpcount
operator|=
operator|(
name|int64_t
operator|)
name|vm_pageout_stats_max
operator|*
name|cnt
operator|.
name|v_active_count
operator|/
name|cnt
operator|.
name|v_page_count
expr_stmt|;
if|if
condition|(
name|pcount
operator|>
name|tpcount
condition|)
name|pcount
operator|=
name|tpcount
expr_stmt|;
block|}
else|else
block|{
name|fullintervalcount
operator|=
literal|0
expr_stmt|;
block|}
name|m
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pl
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|m
operator|!=
name|NULL
operator|)
operator|&&
operator|(
name|pcount
operator|--
operator|>
literal|0
operator|)
condition|)
block|{
name|int
name|actcount
decl_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_ACTIVE
argument_list|,
operator|(
literal|"vm_pageout_page_stats: page %p isn't active"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_MARKER
operator|)
operator|!=
literal|0
condition|)
block|{
name|m
operator|=
name|next
expr_stmt|;
continue|continue;
block|}
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_pageout_page_lock
argument_list|(
name|m
argument_list|,
operator|&
name|next
argument_list|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|=
name|next
expr_stmt|;
continue|continue;
block|}
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
if|if
condition|(
operator|!
name|VM_OBJECT_TRYLOCK
argument_list|(
name|object
argument_list|)
operator|&&
operator|!
name|vm_pageout_fallback_object_lock
argument_list|(
name|m
argument_list|,
operator|&
name|next
argument_list|)
condition|)
block|{
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|=
name|next
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Don't deactivate pages that are busy. 		 */
if|if
condition|(
operator|(
name|m
operator|->
name|busy
operator|!=
literal|0
operator|)
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|||
operator|(
name|m
operator|->
name|hold_count
operator|!=
literal|0
operator|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_requeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|=
name|next
expr_stmt|;
continue|continue;
block|}
name|actcount
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|aflags
operator|&
name|PGA_REFERENCED
condition|)
block|{
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|actcount
operator|+=
literal|1
expr_stmt|;
block|}
name|actcount
operator|+=
name|pmap_ts_referenced
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|actcount
condition|)
block|{
name|m
operator|->
name|act_count
operator|+=
name|ACT_ADVANCE
operator|+
name|actcount
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|act_count
operator|>
name|ACT_MAX
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_MAX
expr_stmt|;
name|vm_page_requeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|==
literal|0
condition|)
block|{
comment|/* 				 * We turn off page access, so that we have 				 * more accurate RSS stats.  We don't do this 				 * in the normal page deactivation when the 				 * system is loaded VM wise, because the 				 * cost of the large number of page protect 				 * operations would be higher than the value 				 * of doing the operation. 				 */
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_deactivate
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|m
operator|->
name|act_count
operator|-=
name|min
argument_list|(
name|m
operator|->
name|act_count
argument_list|,
name|ACT_DECLINE
argument_list|)
expr_stmt|;
name|vm_page_requeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|m
operator|=
name|next
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_pageout is the high level pageout daemon.  */
end_comment

begin_function
specifier|static
name|void
name|vm_pageout
parameter_list|()
block|{
name|int
name|error
decl_stmt|,
name|pass
decl_stmt|;
comment|/* 	 * Initialize some paging parameters. 	 */
name|cnt
operator|.
name|v_interrupt_free_min
operator|=
literal|2
expr_stmt|;
if|if
condition|(
name|cnt
operator|.
name|v_page_count
operator|<
literal|2000
condition|)
name|vm_pageout_page_count
operator|=
literal|8
expr_stmt|;
comment|/* 	 * v_free_reserved needs to include enough for the largest 	 * swap pager structures plus enough for any pv_entry structs 	 * when paging.  	 */
if|if
condition|(
name|cnt
operator|.
name|v_page_count
operator|>
literal|1024
condition|)
name|cnt
operator|.
name|v_free_min
operator|=
literal|4
operator|+
operator|(
name|cnt
operator|.
name|v_page_count
operator|-
literal|1024
operator|)
operator|/
literal|200
expr_stmt|;
else|else
name|cnt
operator|.
name|v_free_min
operator|=
literal|4
expr_stmt|;
name|cnt
operator|.
name|v_pageout_free_min
operator|=
operator|(
literal|2
operator|*
name|MAXBSIZE
operator|)
operator|/
name|PAGE_SIZE
operator|+
name|cnt
operator|.
name|v_interrupt_free_min
expr_stmt|;
name|cnt
operator|.
name|v_free_reserved
operator|=
name|vm_pageout_page_count
operator|+
name|cnt
operator|.
name|v_pageout_free_min
operator|+
operator|(
name|cnt
operator|.
name|v_page_count
operator|/
literal|768
operator|)
expr_stmt|;
name|cnt
operator|.
name|v_free_severe
operator|=
name|cnt
operator|.
name|v_free_min
operator|/
literal|2
expr_stmt|;
name|cnt
operator|.
name|v_free_min
operator|+=
name|cnt
operator|.
name|v_free_reserved
expr_stmt|;
name|cnt
operator|.
name|v_free_severe
operator|+=
name|cnt
operator|.
name|v_free_reserved
expr_stmt|;
comment|/* 	 * v_free_target and v_cache_min control pageout hysteresis.  Note 	 * that these are more a measure of the VM cache queue hysteresis 	 * then the VM free queue.  Specifically, v_free_target is the 	 * high water mark (free+cache pages). 	 * 	 * v_free_reserved + v_cache_min (mostly means v_cache_min) is the 	 * low water mark, while v_free_min is the stop.  v_cache_min must 	 * be big enough to handle memory needs while the pageout daemon 	 * is signalled and run to free more pages. 	 */
if|if
condition|(
name|cnt
operator|.
name|v_free_count
operator|>
literal|6144
condition|)
name|cnt
operator|.
name|v_free_target
operator|=
literal|4
operator|*
name|cnt
operator|.
name|v_free_min
operator|+
name|cnt
operator|.
name|v_free_reserved
expr_stmt|;
else|else
name|cnt
operator|.
name|v_free_target
operator|=
literal|2
operator|*
name|cnt
operator|.
name|v_free_min
operator|+
name|cnt
operator|.
name|v_free_reserved
expr_stmt|;
if|if
condition|(
name|cnt
operator|.
name|v_free_count
operator|>
literal|2048
condition|)
block|{
name|cnt
operator|.
name|v_cache_min
operator|=
name|cnt
operator|.
name|v_free_target
expr_stmt|;
name|cnt
operator|.
name|v_cache_max
operator|=
literal|2
operator|*
name|cnt
operator|.
name|v_cache_min
expr_stmt|;
name|cnt
operator|.
name|v_inactive_target
operator|=
operator|(
literal|3
operator|*
name|cnt
operator|.
name|v_free_target
operator|)
operator|/
literal|2
expr_stmt|;
block|}
else|else
block|{
name|cnt
operator|.
name|v_cache_min
operator|=
literal|0
expr_stmt|;
name|cnt
operator|.
name|v_cache_max
operator|=
literal|0
expr_stmt|;
name|cnt
operator|.
name|v_inactive_target
operator|=
name|cnt
operator|.
name|v_free_count
operator|/
literal|4
expr_stmt|;
block|}
if|if
condition|(
name|cnt
operator|.
name|v_inactive_target
operator|>
name|cnt
operator|.
name|v_free_count
operator|/
literal|3
condition|)
name|cnt
operator|.
name|v_inactive_target
operator|=
name|cnt
operator|.
name|v_free_count
operator|/
literal|3
expr_stmt|;
comment|/* XXX does not really belong here */
if|if
condition|(
name|vm_page_max_wired
operator|==
literal|0
condition|)
name|vm_page_max_wired
operator|=
name|cnt
operator|.
name|v_free_count
operator|/
literal|3
expr_stmt|;
if|if
condition|(
name|vm_pageout_stats_max
operator|==
literal|0
condition|)
name|vm_pageout_stats_max
operator|=
name|cnt
operator|.
name|v_free_target
expr_stmt|;
comment|/* 	 * Set interval in seconds for stats scan. 	 */
if|if
condition|(
name|vm_pageout_stats_interval
operator|==
literal|0
condition|)
name|vm_pageout_stats_interval
operator|=
literal|5
expr_stmt|;
if|if
condition|(
name|vm_pageout_full_stats_interval
operator|==
literal|0
condition|)
name|vm_pageout_full_stats_interval
operator|=
name|vm_pageout_stats_interval
operator|*
literal|4
expr_stmt|;
name|swap_pager_swap_init
argument_list|()
expr_stmt|;
name|pass
operator|=
literal|0
expr_stmt|;
comment|/* 	 * The pageout daemon is never done, so loop forever. 	 */
while|while
condition|(
name|TRUE
condition|)
block|{
comment|/* 		 * If we have enough free memory, wakeup waiters.  Do 		 * not clear vm_pages_needed until we reach our target, 		 * otherwise we may be woken up over and over again and 		 * waste a lot of cpu. 		 */
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_pages_needed
operator|&&
operator|!
name|vm_page_count_min
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|vm_paging_needed
argument_list|()
condition|)
name|vm_pages_needed
operator|=
literal|0
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|vm_pages_needed
condition|)
block|{
comment|/* 			 * Still not done, take a second pass without waiting 			 * (unlimited dirty cleaning), otherwise sleep a bit 			 * and try again. 			 */
operator|++
name|pass
expr_stmt|;
if|if
condition|(
name|pass
operator|>
literal|1
condition|)
name|msleep
argument_list|(
operator|&
name|vm_pages_needed
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PVM
argument_list|,
literal|"psleep"
argument_list|,
name|hz
operator|/
literal|2
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * Good enough, sleep& handle stats.  Prime the pass 			 * for the next run. 			 */
if|if
condition|(
name|pass
operator|>
literal|1
condition|)
name|pass
operator|=
literal|1
expr_stmt|;
else|else
name|pass
operator|=
literal|0
expr_stmt|;
name|error
operator|=
name|msleep
argument_list|(
operator|&
name|vm_pages_needed
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PVM
argument_list|,
literal|"psleep"
argument_list|,
name|vm_pageout_stats_interval
operator|*
name|hz
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|&&
operator|!
name|vm_pages_needed
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|pass
operator|=
literal|0
expr_stmt|;
name|vm_pageout_page_stats
argument_list|()
expr_stmt|;
continue|continue;
block|}
block|}
if|if
condition|(
name|vm_pages_needed
condition|)
name|cnt
operator|.
name|v_pdwakeups
operator|++
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|vm_pageout_scan
argument_list|(
name|pass
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Unless the free page queue lock is held by the caller, this function  * should be regarded as advisory.  Specifically, the caller should  * not msleep() on&cnt.v_free_count following this function unless  * the free page queue lock is held until the msleep() is performed.  */
end_comment

begin_function
name|void
name|pagedaemon_wakeup
parameter_list|()
block|{
if|if
condition|(
operator|!
name|vm_pages_needed
operator|&&
name|curthread
operator|->
name|td_proc
operator|!=
name|pageproc
condition|)
block|{
name|vm_pages_needed
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pages_needed
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|NO_SWAPPING
argument_list|)
end_if

begin_function
specifier|static
name|void
name|vm_req_vmdaemon
parameter_list|(
name|int
name|req
parameter_list|)
block|{
specifier|static
name|int
name|lastrun
init|=
literal|0
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_daemon_mtx
argument_list|)
expr_stmt|;
name|vm_pageout_req_swapout
operator||=
name|req
expr_stmt|;
if|if
condition|(
operator|(
name|ticks
operator|>
operator|(
name|lastrun
operator|+
name|hz
operator|)
operator|)
operator|||
operator|(
name|ticks
operator|<
name|lastrun
operator|)
condition|)
block|{
name|wakeup
argument_list|(
operator|&
name|vm_daemon_needed
argument_list|)
expr_stmt|;
name|lastrun
operator|=
name|ticks
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|vm_daemon_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vm_daemon
parameter_list|()
block|{
name|struct
name|rlimit
name|rsslim
decl_stmt|;
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
name|struct
name|thread
modifier|*
name|td
decl_stmt|;
name|struct
name|vmspace
modifier|*
name|vm
decl_stmt|;
name|int
name|breakout
decl_stmt|,
name|swapout_flags
decl_stmt|,
name|tryagain
decl_stmt|,
name|attempts
decl_stmt|;
ifdef|#
directive|ifdef
name|RACCT
name|uint64_t
name|rsize
decl_stmt|,
name|ravailable
decl_stmt|;
endif|#
directive|endif
while|while
condition|(
name|TRUE
condition|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_daemon_mtx
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|RACCT
name|msleep
argument_list|(
operator|&
name|vm_daemon_needed
argument_list|,
operator|&
name|vm_daemon_mtx
argument_list|,
name|PPAUSE
argument_list|,
literal|"psleep"
argument_list|,
name|hz
argument_list|)
expr_stmt|;
else|#
directive|else
name|msleep
argument_list|(
operator|&
name|vm_daemon_needed
argument_list|,
operator|&
name|vm_daemon_mtx
argument_list|,
name|PPAUSE
argument_list|,
literal|"psleep"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|swapout_flags
operator|=
name|vm_pageout_req_swapout
expr_stmt|;
name|vm_pageout_req_swapout
operator|=
literal|0
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_daemon_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|swapout_flags
condition|)
name|swapout_procs
argument_list|(
name|swapout_flags
argument_list|)
expr_stmt|;
comment|/* 		 * scan the processes for exceeding their rlimits or if 		 * process is swapped out -- deactivate pages 		 */
name|tryagain
operator|=
literal|0
expr_stmt|;
name|attempts
operator|=
literal|0
expr_stmt|;
name|again
label|:
name|attempts
operator|++
expr_stmt|;
name|sx_slock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
name|FOREACH_PROC_IN_SYSTEM
argument_list|(
argument|p
argument_list|)
block|{
name|vm_pindex_t
name|limit
decl_stmt|,
name|size
decl_stmt|;
comment|/* 			 * if this is a system process or if we have already 			 * looked at this process, skip it. 			 */
name|PROC_LOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
operator|->
name|p_state
operator|!=
name|PRS_NORMAL
operator|||
name|p
operator|->
name|p_flag
operator|&
operator|(
name|P_INEXEC
operator||
name|P_SYSTEM
operator||
name|P_WEXIT
operator|)
condition|)
block|{
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 			 * if the process is in a non-running type state, 			 * don't touch it. 			 */
name|breakout
operator|=
literal|0
expr_stmt|;
name|FOREACH_THREAD_IN_PROC
argument_list|(
argument|p
argument_list|,
argument|td
argument_list|)
block|{
name|thread_lock
argument_list|(
name|td
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|TD_ON_RUNQ
argument_list|(
name|td
argument_list|)
operator|&&
operator|!
name|TD_IS_RUNNING
argument_list|(
name|td
argument_list|)
operator|&&
operator|!
name|TD_IS_SLEEPING
argument_list|(
name|td
argument_list|)
operator|&&
operator|!
name|TD_IS_SUSPENDED
argument_list|(
name|td
argument_list|)
condition|)
block|{
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
name|breakout
operator|=
literal|1
expr_stmt|;
break|break;
block|}
name|thread_unlock
argument_list|(
name|td
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|breakout
condition|)
block|{
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* 			 * get a limit 			 */
name|lim_rlimit
argument_list|(
name|p
argument_list|,
name|RLIMIT_RSS
argument_list|,
operator|&
name|rsslim
argument_list|)
expr_stmt|;
name|limit
operator|=
name|OFF_TO_IDX
argument_list|(
name|qmin
argument_list|(
name|rsslim
operator|.
name|rlim_cur
argument_list|,
name|rsslim
operator|.
name|rlim_max
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 			 * let processes that are swapped out really be 			 * swapped out set the limit to nothing (will force a 			 * swap-out.) 			 */
if|if
condition|(
operator|(
name|p
operator|->
name|p_flag
operator|&
name|P_INMEM
operator|)
operator|==
literal|0
condition|)
name|limit
operator|=
literal|0
expr_stmt|;
comment|/* XXX */
name|vm
operator|=
name|vmspace_acquire_ref
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm
operator|==
name|NULL
condition|)
continue|continue;
name|size
operator|=
name|vmspace_resident_count
argument_list|(
name|vm
argument_list|)
expr_stmt|;
if|if
condition|(
name|limit
operator|>=
literal|0
operator|&&
name|size
operator|>=
name|limit
condition|)
block|{
name|vm_pageout_map_deactivate_pages
argument_list|(
operator|&
name|vm
operator|->
name|vm_map
argument_list|,
name|limit
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|RACCT
name|rsize
operator|=
name|IDX_TO_OFF
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|PROC_LOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|racct_set
argument_list|(
name|p
argument_list|,
name|RACCT_RSS
argument_list|,
name|rsize
argument_list|)
expr_stmt|;
name|ravailable
operator|=
name|racct_get_available
argument_list|(
name|p
argument_list|,
name|RACCT_RSS
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|rsize
operator|>
name|ravailable
condition|)
block|{
comment|/* 				 * Don't be overly aggressive; this might be 				 * an innocent process, and the limit could've 				 * been exceeded by some memory hog.  Don't 				 * try to deactivate more than 1/4th of process' 				 * resident set size. 				 */
if|if
condition|(
name|attempts
operator|<=
literal|8
condition|)
block|{
if|if
condition|(
name|ravailable
operator|<
name|rsize
operator|-
operator|(
name|rsize
operator|/
literal|4
operator|)
condition|)
name|ravailable
operator|=
name|rsize
operator|-
operator|(
name|rsize
operator|/
literal|4
operator|)
expr_stmt|;
block|}
name|vm_pageout_map_deactivate_pages
argument_list|(
operator|&
name|vm
operator|->
name|vm_map
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|ravailable
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Update RSS usage after paging out. */
name|size
operator|=
name|vmspace_resident_count
argument_list|(
name|vm
argument_list|)
expr_stmt|;
name|rsize
operator|=
name|IDX_TO_OFF
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|PROC_LOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|racct_set
argument_list|(
name|p
argument_list|,
name|RACCT_RSS
argument_list|,
name|rsize
argument_list|)
expr_stmt|;
name|PROC_UNLOCK
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|rsize
operator|>
name|ravailable
condition|)
name|tryagain
operator|=
literal|1
expr_stmt|;
block|}
endif|#
directive|endif
name|vmspace_free
argument_list|(
name|vm
argument_list|)
expr_stmt|;
block|}
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|tryagain
operator|!=
literal|0
operator|&&
name|attempts
operator|<=
literal|10
condition|)
goto|goto
name|again
goto|;
block|}
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* !defined(NO_SWAPPING) */
end_comment

end_unit

