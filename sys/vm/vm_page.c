begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * Copyright (c) 1991 Regents of the University of California.  * All rights reserved.  *  * This code is derived from software contributed to Berkeley by  * The Mach Operating System project at Carnegie-Mellon University.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. All advertising materials mentioning features or use of this software  *    must display the following acknowledgement:  *	This product includes software developed by the University of  *	California, Berkeley and its contributors.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from: @(#)vm_page.c	7.4 (Berkeley) 5/7/91  * $FreeBSD$  */
end_comment

begin_comment
comment|/*  * Copyright (c) 1987, 1990 Carnegie-Mellon University.  * All rights reserved.  *  * Authors: Avadis Tevanian, Jr., Michael Wayne Young  *  * Permission to use, copy, modify and distribute this software and  * its documentation is hereby granted, provided that both the copyright  * notice and this permission notice appear in all copies of the  * software, derivative works or modified versions, and any portions  * thereof, and that both notices appear in supporting documentation.  *  * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"  * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND  * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.  *  * Carnegie Mellon requests users of this software to return to  *  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU  *  School of Computer Science  *  Carnegie Mellon University  *  Pittsburgh PA 15213-3890  *  * any improvements or extensions that they make and grant Carnegie the  * rights to redistribute these changes.  */
end_comment

begin_comment
comment|/*  *	Resident memory management module.  */
end_comment

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/pmap.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_function_decl
specifier|static
name|void
name|vm_page_queue_init
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|vm_page_select_cache
parameter_list|(
name|vm_object_t
parameter_list|,
name|vm_pindex_t
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  *	Associated with page of user-allocatable memory is a  *	page structure.  */
end_comment

begin_decl_stmt
specifier|static
name|struct
name|vm_page
modifier|*
modifier|*
name|vm_page_buckets
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Array of buckets */
end_comment

begin_decl_stmt
specifier|static
name|int
name|vm_page_bucket_count
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* How big is array? */
end_comment

begin_decl_stmt
specifier|static
name|int
name|vm_page_hash_mask
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Mask for hash function */
end_comment

begin_decl_stmt
specifier|static
specifier|volatile
name|int
name|vm_page_bucket_generation
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|vpgqueues
name|vm_page_queues
index|[
name|PQ_COUNT
index|]
decl_stmt|;
end_decl_stmt

begin_function
specifier|static
name|void
name|vm_page_queue_init
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PQ_L2_SIZE
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_queues
index|[
name|PQ_FREE
operator|+
name|i
index|]
operator|.
name|cnt
operator|=
operator|&
name|cnt
operator|.
name|v_free_count
expr_stmt|;
block|}
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|cnt
operator|=
operator|&
name|cnt
operator|.
name|v_inactive_count
expr_stmt|;
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|cnt
operator|=
operator|&
name|cnt
operator|.
name|v_active_count
expr_stmt|;
name|vm_page_queues
index|[
name|PQ_HOLD
index|]
operator|.
name|cnt
operator|=
operator|&
name|cnt
operator|.
name|v_active_count
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PQ_L2_SIZE
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_queues
index|[
name|PQ_CACHE
operator|+
name|i
index|]
operator|.
name|cnt
operator|=
operator|&
name|cnt
operator|.
name|v_cache_count
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PQ_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|TAILQ_INIT
argument_list|(
operator|&
name|vm_page_queues
index|[
name|i
index|]
operator|.
name|pl
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_decl_stmt
name|vm_page_t
name|vm_page_array
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|vm_page_array_size
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|long
name|first_page
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|vm_page_zero_count
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|__inline
name|int
name|vm_page_hash
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_free_wakeup
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  *	vm_set_page_size:  *  *	Sets the page size, perhaps based upon the memory  *	size.  Must be called before any use of page-size  *	dependent functions.  */
end_comment

begin_function
name|void
name|vm_set_page_size
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|cnt
operator|.
name|v_page_size
operator|==
literal|0
condition|)
name|cnt
operator|.
name|v_page_size
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|cnt
operator|.
name|v_page_size
operator|-
literal|1
operator|)
operator|&
name|cnt
operator|.
name|v_page_size
operator|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_set_page_size: page size not a power of two"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_add_new_page:  *  *	Add a new page to the freelist for use by the system.  *	Must be called at splhigh().  */
end_comment

begin_function
name|vm_page_t
name|vm_add_new_page
parameter_list|(
name|vm_offset_t
name|pa
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
operator|++
name|cnt
operator|.
name|v_page_count
expr_stmt|;
operator|++
name|cnt
operator|.
name|v_free_count
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|m
operator|->
name|phys_addr
operator|=
name|pa
expr_stmt|;
name|m
operator|->
name|flags
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|pc
operator|=
operator|(
name|pa
operator|>>
name|PAGE_SHIFT
operator|)
operator|&
name|PQ_L2_MASK
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|m
operator|->
name|pc
operator|+
name|PQ_FREE
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|vm_page_queues
index|[
name|m
operator|->
name|queue
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|vm_page_queues
index|[
name|m
operator|->
name|queue
index|]
operator|.
name|lcnt
operator|++
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_startup:  *  *	Initializes the resident memory module.  *  *	Allocates memory for the page cells, and  *	for the object/offset-to-page hash table headers.  *	Each page cell is initialized and placed on the free list.  */
end_comment

begin_function
name|vm_offset_t
name|vm_page_startup
parameter_list|(
name|vm_offset_t
name|starta
parameter_list|,
name|vm_offset_t
name|enda
parameter_list|,
name|vm_offset_t
name|vaddr
parameter_list|)
block|{
name|vm_offset_t
name|mapped
decl_stmt|;
name|struct
name|vm_page
modifier|*
modifier|*
name|bucket
decl_stmt|;
name|vm_size_t
name|npages
decl_stmt|,
name|page_range
decl_stmt|;
name|vm_offset_t
name|new_end
decl_stmt|;
name|int
name|i
decl_stmt|;
name|vm_offset_t
name|pa
decl_stmt|;
name|int
name|nblocks
decl_stmt|;
name|vm_offset_t
name|last_pa
decl_stmt|;
comment|/* the biggest memory array is the second group of pages */
name|vm_offset_t
name|end
decl_stmt|;
name|vm_offset_t
name|biggestone
decl_stmt|,
name|biggestsize
decl_stmt|;
name|vm_offset_t
name|total
decl_stmt|;
name|total
operator|=
literal|0
expr_stmt|;
name|biggestsize
operator|=
literal|0
expr_stmt|;
name|biggestone
operator|=
literal|0
expr_stmt|;
name|nblocks
operator|=
literal|0
expr_stmt|;
name|vaddr
operator|=
name|round_page
argument_list|(
name|vaddr
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|phys_avail
index|[
name|i
index|]
operator|=
name|round_page
argument_list|(
name|phys_avail
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|=
name|trunc_page
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|int
name|size
init|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|size
operator|>
name|biggestsize
condition|)
block|{
name|biggestone
operator|=
name|i
expr_stmt|;
name|biggestsize
operator|=
name|size
expr_stmt|;
block|}
operator|++
name|nblocks
expr_stmt|;
name|total
operator|+=
name|size
expr_stmt|;
block|}
name|end
operator|=
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
expr_stmt|;
comment|/* 	 * Initialize the queue headers for the free queue, the active queue 	 * and the inactive queue. 	 */
name|vm_page_queue_init
argument_list|()
expr_stmt|;
comment|/* 	 * Allocate (and initialize) the hash table buckets. 	 * 	 * The number of buckets MUST BE a power of 2, and the actual value is 	 * the next power of 2 greater than the number of physical pages in 	 * the system.   	 * 	 * We make the hash table approximately 2x the number of pages to 	 * reduce the chain length.  This is about the same size using the  	 * singly-linked list as the 1x hash table we were using before  	 * using TAILQ but the chain length will be smaller. 	 * 	 * Note: This computation can be tweaked if desired. 	 */
name|vm_page_buckets
operator|=
operator|(
expr|struct
name|vm_page
operator|*
operator|*
operator|)
name|vaddr
expr_stmt|;
name|bucket
operator|=
name|vm_page_buckets
expr_stmt|;
if|if
condition|(
name|vm_page_bucket_count
operator|==
literal|0
condition|)
block|{
name|vm_page_bucket_count
operator|=
literal|1
expr_stmt|;
while|while
condition|(
name|vm_page_bucket_count
operator|<
name|atop
argument_list|(
name|total
argument_list|)
condition|)
name|vm_page_bucket_count
operator|<<=
literal|1
expr_stmt|;
block|}
name|vm_page_bucket_count
operator|<<=
literal|1
expr_stmt|;
name|vm_page_hash_mask
operator|=
name|vm_page_bucket_count
operator|-
literal|1
expr_stmt|;
comment|/* 	 * Validate these addresses. 	 */
name|new_end
operator|=
name|end
operator|-
name|vm_page_bucket_count
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
operator|*
argument_list|)
expr_stmt|;
name|new_end
operator|=
name|trunc_page
argument_list|(
name|new_end
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|round_page
argument_list|(
name|vaddr
argument_list|)
expr_stmt|;
name|vaddr
operator|=
name|pmap_map
argument_list|(
name|mapped
argument_list|,
name|new_end
argument_list|,
name|end
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|vaddr
operator|=
name|round_page
argument_list|(
name|vaddr
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|mapped
argument_list|,
name|vaddr
operator|-
name|mapped
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|vm_page_bucket_count
condition|;
name|i
operator|++
control|)
block|{
operator|*
name|bucket
operator|=
name|NULL
expr_stmt|;
name|bucket
operator|++
expr_stmt|;
block|}
comment|/* 	 * Compute the number of pages of memory that will be available for 	 * use (taking into account the overhead of a page structure per 	 * page). 	 */
name|first_page
operator|=
name|phys_avail
index|[
literal|0
index|]
operator|/
name|PAGE_SIZE
expr_stmt|;
name|page_range
operator|=
name|phys_avail
index|[
operator|(
name|nblocks
operator|-
literal|1
operator|)
operator|*
literal|2
operator|+
literal|1
index|]
operator|/
name|PAGE_SIZE
operator|-
name|first_page
expr_stmt|;
name|npages
operator|=
operator|(
name|total
operator|-
operator|(
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
operator|)
operator|-
operator|(
name|end
operator|-
name|new_end
operator|)
operator|)
operator|/
name|PAGE_SIZE
expr_stmt|;
name|end
operator|=
name|new_end
expr_stmt|;
comment|/* 	 * Initialize the mem entry structures now, and put them in the free 	 * queue. 	 */
name|vm_page_array
operator|=
operator|(
name|vm_page_t
operator|)
name|vaddr
expr_stmt|;
name|mapped
operator|=
name|vaddr
expr_stmt|;
comment|/* 	 * Validate these addresses. 	 */
name|new_end
operator|=
name|trunc_page
argument_list|(
name|end
operator|-
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|pmap_map
argument_list|(
name|mapped
argument_list|,
name|new_end
argument_list|,
name|end
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
comment|/* 	 * Clear all of the page structures 	 */
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|vm_page_array
argument_list|,
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|)
expr_stmt|;
name|vm_page_array_size
operator|=
name|page_range
expr_stmt|;
comment|/* 	 * Construct the free queue(s) in descending order (by physical 	 * address) so that the first 16MB of physical memory is allocated 	 * last rather than first.  On large-memory machines, this avoids 	 * the exhaustion of low physical memory before isa_dmainit has run. 	 */
name|cnt
operator|.
name|v_page_count
operator|=
literal|0
expr_stmt|;
name|cnt
operator|.
name|v_free_count
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|&&
name|npages
operator|>
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|pa
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|i
operator|==
name|biggestone
condition|)
name|last_pa
operator|=
name|new_end
expr_stmt|;
else|else
name|last_pa
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
while|while
condition|(
name|pa
operator|<
name|last_pa
operator|&&
name|npages
operator|--
operator|>
literal|0
condition|)
block|{
name|vm_add_new_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
return|return
operator|(
name|mapped
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_hash:  *  *	Distributes the object/offset key pair among hash buckets.  *  *	NOTE:  This macro depends on vm_page_bucket_count being a power of 2.  *	This routine may not block.  *  *	We try to randomize the hash based on the object to spread the pages  *	out in the hash table without it costing us too much.  */
end_comment

begin_function
specifier|static
name|__inline
name|int
name|vm_page_hash
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|int
name|i
init|=
operator|(
operator|(
name|uintptr_t
operator|)
name|object
operator|+
name|pindex
operator|)
operator|^
name|object
operator|->
name|hash_rand
decl_stmt|;
return|return
operator|(
name|i
operator|&
name|vm_page_hash_mask
operator|)
return|;
block|}
end_function

begin_function
name|void
name|vm_page_unhold
parameter_list|(
name|vm_page_t
name|mem
parameter_list|)
block|{
operator|--
name|mem
operator|->
name|hold_count
expr_stmt|;
name|KASSERT
argument_list|(
name|mem
operator|->
name|hold_count
operator|>=
literal|0
argument_list|,
operator|(
literal|"vm_page_unhold: hold count< 0!!!"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|mem
operator|->
name|hold_count
operator|==
literal|0
operator|&&
name|mem
operator|->
name|queue
operator|==
name|PQ_HOLD
condition|)
name|vm_page_free_toq
argument_list|(
name|mem
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_insert:		[ internal use only ]  *  *	Inserts the given mem entry into the object and object list.  *  *	The pagetables are not updated but will presumably fault the page  *	in if necessary, or if a kernel page the caller will at some point  *	enter the page into the kernel's pmap.  We are not allowed to block  *	here so we *can't* do this anyway.  *  *	The object and page must be locked, and must be splhigh.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_insert
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|struct
name|vm_page
modifier|*
modifier|*
name|bucket
decl_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|NULL
condition|)
name|panic
argument_list|(
literal|"vm_page_insert: already inserted"
argument_list|)
expr_stmt|;
comment|/* 	 * Record the object/offset pair in this page 	 */
name|m
operator|->
name|object
operator|=
name|object
expr_stmt|;
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
comment|/* 	 * Insert it into the object_object/offset hash table 	 */
name|bucket
operator|=
operator|&
name|vm_page_buckets
index|[
name|vm_page_hash
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
index|]
expr_stmt|;
name|m
operator|->
name|hnext
operator|=
operator|*
name|bucket
expr_stmt|;
operator|*
name|bucket
operator|=
name|m
expr_stmt|;
name|vm_page_bucket_generation
operator|++
expr_stmt|;
comment|/* 	 * Now link into the object's list of backed pages. 	 */
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
name|object
operator|->
name|generation
operator|++
expr_stmt|;
comment|/* 	 * show that the object has one more resident page. 	 */
name|object
operator|->
name|resident_page_count
operator|++
expr_stmt|;
comment|/* 	 * Since we are inserting a new and possibly dirty page, 	 * update the object's OBJ_WRITEABLE and OBJ_MIGHTBEDIRTY flags. 	 */
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_WRITEABLE
condition|)
name|vm_object_set_writeable_dirty
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_remove:  *				NOTE: used by device pager as well -wfj  *  *	Removes the given mem entry from the object/offset-page  *	table and the object page list, but do not invalidate/terminate  *	the backing store.  *  *	The object and page must be locked, and at splhigh.  *	The underlying pmap entry (if any) is NOT removed here.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_remove
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|==
name|NULL
condition|)
return|return;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_BUSY
operator|)
operator|==
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"vm_page_remove: page not busy"
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Basically destroy the page. 	 */
name|vm_page_wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
comment|/* 	 * Remove from the object_object/offset hash table.  The object 	 * must be on the hash queue, we will panic if it isn't 	 * 	 * Note: we must NULL-out m->hnext to prevent loops in detached 	 * buffers with vm_page_lookup(). 	 */
block|{
name|struct
name|vm_page
modifier|*
modifier|*
name|bucket
decl_stmt|;
name|bucket
operator|=
operator|&
name|vm_page_buckets
index|[
name|vm_page_hash
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|m
operator|->
name|pindex
argument_list|)
index|]
expr_stmt|;
while|while
condition|(
operator|*
name|bucket
operator|!=
name|m
condition|)
block|{
if|if
condition|(
operator|*
name|bucket
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"vm_page_remove(): page not found in hash"
argument_list|)
expr_stmt|;
name|bucket
operator|=
operator|&
operator|(
operator|*
name|bucket
operator|)
operator|->
name|hnext
expr_stmt|;
block|}
operator|*
name|bucket
operator|=
name|m
operator|->
name|hnext
expr_stmt|;
name|m
operator|->
name|hnext
operator|=
name|NULL
expr_stmt|;
name|vm_page_bucket_generation
operator|++
expr_stmt|;
block|}
comment|/* 	 * Now remove from the object's list of backed pages. 	 */
name|TAILQ_REMOVE
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
comment|/* 	 * And show that the object has one fewer resident page. 	 */
name|object
operator|->
name|resident_page_count
operator|--
expr_stmt|;
name|object
operator|->
name|generation
operator|++
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_lookup:  *  *	Returns the page associated with the object/offset  *	pair specified; if none is found, NULL is returned.  *  *	NOTE: the code below does not lock.  It will operate properly if  *	an interrupt makes a change, but the generation algorithm will not   *	operate properly in an SMP environment where both cpu's are able to run  *	kernel code simultaneously.  *  *	The object must be locked.  No side effects.  *	This routine may not block.  *	This is a critical path routine  */
end_comment

begin_function
name|vm_page_t
name|vm_page_lookup
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|struct
name|vm_page
modifier|*
modifier|*
name|bucket
decl_stmt|;
name|int
name|generation
decl_stmt|;
comment|/* 	 * Search the hash table for this object/offset pair 	 */
name|retry
label|:
name|generation
operator|=
name|vm_page_bucket_generation
expr_stmt|;
name|bucket
operator|=
operator|&
name|vm_page_buckets
index|[
name|vm_page_hash
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
index|]
expr_stmt|;
for|for
control|(
name|m
operator|=
operator|*
name|bucket
init|;
name|m
operator|!=
name|NULL
condition|;
name|m
operator|=
name|m
operator|->
name|hnext
control|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|object
operator|==
name|object
operator|)
operator|&&
operator|(
name|m
operator|->
name|pindex
operator|==
name|pindex
operator|)
condition|)
block|{
if|if
condition|(
name|vm_page_bucket_generation
operator|!=
name|generation
condition|)
goto|goto
name|retry
goto|;
return|return
operator|(
name|m
operator|)
return|;
block|}
block|}
if|if
condition|(
name|vm_page_bucket_generation
operator|!=
name|generation
condition|)
goto|goto
name|retry
goto|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_rename:  *  *	Move the given memory entry from its  *	current object to the specified target object/offset.  *  *	The object must be locked.  *	This routine may not block.  *  *	Note: this routine will raise itself to splvm(), the caller need not.   *  *	Note: swap associated with the page must be invalidated by the move.  We  *	      have to do this for several reasons:  (1) we aren't freeing the  *	      page, (2) we are dirtying the page, (3) the VM system is probably  *	      moving the page from object A to B, and will then later move  *	      the backing store from A to B and we can't have a conflict.  *  *	Note: we *always* dirty the page.  It is necessary both for the  *	      fact that we moved it, and because we may be invalidating  *	      swap.  If the page is on the cache, we have to deactivate it  *	      or vm_page_dirty() will panic.  Dirty pages are not allowed  *	      on the cache.  */
end_comment

begin_function
name|void
name|vm_page_rename
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|new_object
parameter_list|,
name|vm_pindex_t
name|new_pindex
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|new_object
argument_list|,
name|new_pindex
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|queue
operator|-
name|m
operator|->
name|pc
operator|==
name|PQ_CACHE
condition|)
name|vm_page_deactivate
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_unqueue_nowakeup:  *  * 	vm_page_unqueue() without any wakeup  *  *	This routine must be called at splhigh().  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_unqueue_nowakeup
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|queue
init|=
name|m
operator|->
name|queue
decl_stmt|;
name|struct
name|vpgqueues
modifier|*
name|pq
decl_stmt|;
if|if
condition|(
name|queue
operator|!=
name|PQ_NONE
condition|)
block|{
name|pq
operator|=
operator|&
name|vm_page_queues
index|[
name|queue
index|]
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_NONE
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
operator|(
operator|*
name|pq
operator|->
name|cnt
operator|)
operator|--
expr_stmt|;
name|pq
operator|->
name|lcnt
operator|--
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * vm_page_unqueue:  *  *	Remove a page from its queue.  *  *	This routine must be called at splhigh().  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_unqueue
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|queue
init|=
name|m
operator|->
name|queue
decl_stmt|;
name|struct
name|vpgqueues
modifier|*
name|pq
decl_stmt|;
if|if
condition|(
name|queue
operator|!=
name|PQ_NONE
condition|)
block|{
name|m
operator|->
name|queue
operator|=
name|PQ_NONE
expr_stmt|;
name|pq
operator|=
operator|&
name|vm_page_queues
index|[
name|queue
index|]
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
operator|(
operator|*
name|pq
operator|->
name|cnt
operator|)
operator|--
expr_stmt|;
name|pq
operator|->
name|lcnt
operator|--
expr_stmt|;
if|if
condition|(
operator|(
name|queue
operator|-
name|m
operator|->
name|pc
operator|)
operator|==
name|PQ_CACHE
condition|)
block|{
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_function

begin_if
if|#
directive|if
name|PQ_L2_SIZE
operator|>
literal|1
end_if

begin_comment
comment|/*  *	vm_page_list_find:  *  *	Find a page on the specified queue with color optimization.  *  *	The page coloring optimization attempts to locate a page  *	that does not overload other nearby pages in the object in  *	the cpu's L1 or L2 caches.  We need this optimization because   *	cpu caches tend to be physical caches, while object spaces tend   *	to be virtual.  *  *	This routine must be called at splvm().  *	This routine may not block.  *  *	This routine may only be called from the vm_page_list_find() macro  *	in vm_page.h  */
end_comment

begin_function
name|vm_page_t
name|_vm_page_list_find
parameter_list|(
name|int
name|basequeue
parameter_list|,
name|int
name|index
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|vm_page_t
name|m
init|=
name|NULL
decl_stmt|;
name|struct
name|vpgqueues
modifier|*
name|pq
decl_stmt|;
name|pq
operator|=
operator|&
name|vm_page_queues
index|[
name|basequeue
index|]
expr_stmt|;
comment|/* 	 * Note that for the first loop, index+i and index-i wind up at the 	 * same place.  Even though this is not totally optimal, we've already 	 * blown it by missing the cache case so we do not care. 	 */
for|for
control|(
name|i
operator|=
name|PQ_L2_SIZE
operator|/
literal|2
init|;
name|i
operator|>
literal|0
condition|;
operator|--
name|i
control|)
block|{
if|if
condition|(
operator|(
name|m
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pq
index|[
operator|(
name|index
operator|+
name|i
operator|)
operator|&
name|PQ_L2_MASK
index|]
operator|.
name|pl
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
break|break;
if|if
condition|(
operator|(
name|m
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pq
index|[
operator|(
name|index
operator|-
name|i
operator|)
operator|&
name|PQ_L2_MASK
index|]
operator|.
name|pl
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
break|break;
block|}
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  *	vm_page_select_cache:  *  *	Find a page on the cache queue with color optimization.  As pages  *	might be found, but not applicable, they are deactivated.  This  *	keeps us from using potentially busy cached pages.  *  *	This routine must be called at splvm().  *	This routine may not block.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_select_cache
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
while|while
condition|(
name|TRUE
condition|)
block|{
name|m
operator|=
name|vm_page_list_find
argument_list|(
name|PQ_CACHE
argument_list|,
operator|(
name|pindex
operator|+
name|object
operator|->
name|pg_color
operator|)
operator|&
name|PQ_L2_MASK
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|&&
operator|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_BUSY
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|||
name|m
operator|->
name|busy
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|wire_count
operator|)
condition|)
block|{
name|vm_page_deactivate
argument_list|(
name|m
argument_list|)
expr_stmt|;
continue|continue;
block|}
return|return
name|m
return|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_select_free:  *  *	Find a free or zero page, with specified preference.  We attempt to  *	inline the nominal case and fall back to _vm_page_select_free()   *	otherwise.  *  *	This routine must be called at splvm().  *	This routine may not block.  */
end_comment

begin_function
specifier|static
name|__inline
name|vm_page_t
name|vm_page_select_free
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|boolean_t
name|prefer_zero
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|vm_page_list_find
argument_list|(
name|PQ_FREE
argument_list|,
operator|(
name|pindex
operator|+
name|object
operator|->
name|pg_color
operator|)
operator|&
name|PQ_L2_MASK
argument_list|,
name|prefer_zero
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_alloc:  *  *	Allocate and return a memory cell associated  *	with this VM object/offset pair.  *  *	page_req classes:  *	VM_ALLOC_NORMAL		normal process request  *	VM_ALLOC_SYSTEM		system *really* needs a page  *	VM_ALLOC_INTERRUPT	interrupt time request  *	VM_ALLOC_ZERO		zero page  *  *	Object must be locked.  *	This routine may not block.  *  *	Additional special handling is required when called from an  *	interrupt (VM_ALLOC_INTERRUPT).  We are not allowed to mess with  *	the page cache in this case.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_alloc
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|page_req
parameter_list|)
block|{
name|vm_page_t
name|m
init|=
name|NULL
decl_stmt|;
name|int
name|s
decl_stmt|;
name|KASSERT
argument_list|(
operator|!
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
argument_list|,
operator|(
literal|"vm_page_alloc: page already allocated"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * The pager is allowed to eat deeper into the free page list. 	 */
if|if
condition|(
operator|(
name|curproc
operator|==
name|pageproc
operator|)
operator|&&
operator|(
name|page_req
operator|!=
name|VM_ALLOC_INTERRUPT
operator|)
condition|)
block|{
name|page_req
operator|=
name|VM_ALLOC_SYSTEM
expr_stmt|;
block|}
empty_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
name|loop
label|:
if|if
condition|(
name|cnt
operator|.
name|v_free_count
operator|>
name|cnt
operator|.
name|v_free_reserved
condition|)
block|{
comment|/* 		 * Allocate from the free queue if there are plenty of pages 		 * in it. 		 */
if|if
condition|(
name|page_req
operator|==
name|VM_ALLOC_ZERO
condition|)
name|m
operator|=
name|vm_page_select_free
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
else|else
name|m
operator|=
name|vm_page_select_free
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|page_req
operator|==
name|VM_ALLOC_SYSTEM
operator|&&
name|cnt
operator|.
name|v_cache_count
operator|==
literal|0
operator|&&
name|cnt
operator|.
name|v_free_count
operator|>
name|cnt
operator|.
name|v_interrupt_free_min
operator|)
operator|||
operator|(
name|page_req
operator|==
name|VM_ALLOC_INTERRUPT
operator|&&
name|cnt
operator|.
name|v_free_count
operator|>
literal|0
operator|)
condition|)
block|{
comment|/* 		 * Interrupt or system, dig deeper into the free list. 		 */
name|m
operator|=
name|vm_page_select_free
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|page_req
operator|!=
name|VM_ALLOC_INTERRUPT
condition|)
block|{
comment|/* 		 * Allocatable from cache (non-interrupt only).  On success, 		 * we must free the page and try again, thus ensuring that 		 * cnt.v_*_free_min counters are replenished. 		 */
name|m
operator|=
name|vm_page_select_cache
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|DIAGNOSTIC
argument_list|)
if|if
condition|(
name|cnt
operator|.
name|v_cache_count
operator|>
literal|0
condition|)
name|printf
argument_list|(
literal|"vm_page_alloc(NORMAL): missing pages on cache queue: %d\n"
argument_list|,
name|cnt
operator|.
name|v_cache_count
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|vm_pageout_deficit
operator|++
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"Found dirty cache page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vm_page_busy
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_protect
argument_list|(
name|m
argument_list|,
name|VM_PROT_NONE
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
else|else
block|{
comment|/* 		 * Not allocatable from cache from interrupt, give up. 		 */
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|vm_pageout_deficit
operator|++
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
comment|/* 	 *  At this point we had better have found a good page. 	 */
name|KASSERT
argument_list|(
name|m
operator|!=
name|NULL
argument_list|,
operator|(
literal|"vm_page_alloc(): missing page on free queue\n"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Remove from free queue 	 */
name|vm_page_unqueue_nowakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize structure.  Only the PG_ZERO flag is inherited. 	 */
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
condition|)
block|{
name|vm_page_zero_count
operator|--
expr_stmt|;
name|m
operator|->
name|flags
operator|=
name|PG_ZERO
operator||
name|PG_BUSY
expr_stmt|;
block|}
else|else
block|{
name|m
operator|->
name|flags
operator|=
name|PG_BUSY
expr_stmt|;
block|}
name|m
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|hold_count
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|act_count
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|busy
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: free/cache page %p was dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * vm_page_insert() is safe prior to the splx().  Note also that 	 * inserting a page here does not insert it into the pmap (which 	 * could cause us to block allocating memory).  We cannot block  	 * anywhere. 	 */
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
comment|/* 	 * Don't wakeup too often - wakeup the pageout daemon when 	 * we would be nearly out of memory. 	 */
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_wait:	(also see VM_WAIT macro)  *  *	Block until free pages are available for allocation  *	- Called in various places before memory allocations.  */
end_comment

begin_function
name|void
name|vm_wait
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
if|if
condition|(
name|curproc
operator|==
name|pageproc
condition|)
block|{
name|vm_pageout_pages_needed
operator|=
literal|1
expr_stmt|;
name|tsleep
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|,
name|PSWP
argument_list|,
literal|"VMWait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|vm_pages_needed
condition|)
block|{
name|vm_pages_needed
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pages_needed
argument_list|)
expr_stmt|;
block|}
name|tsleep
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|,
name|PVM
argument_list|,
literal|"vmwait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_waitpfault:	(also see VM_WAITPFAULT macro)  *  *	Block until free pages are available for allocation  *	- Called only in vm_fault so that processes page faulting  *	  can be easily tracked.  *	- Sleeps at a lower priority than vm_wait() so that vm_wait()ing  *	  processes will be able to grab memory first.  Do not change  *	  this balance without careful testing first.  */
end_comment

begin_function
name|void
name|vm_waitpfault
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|vm_pages_needed
condition|)
block|{
name|vm_pages_needed
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pages_needed
argument_list|)
expr_stmt|;
block|}
name|tsleep
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|,
name|PUSER
argument_list|,
literal|"pfault"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_await:	(also see VM_AWAIT macro)  *  *	asleep on an event that will signal when free pages are available  *	for allocation.  */
end_comment

begin_function
name|void
name|vm_await
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
if|if
condition|(
name|curproc
operator|==
name|pageproc
condition|)
block|{
name|vm_pageout_pages_needed
operator|=
literal|1
expr_stmt|;
name|asleep
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|,
name|PSWP
argument_list|,
literal|"vmwait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|vm_pages_needed
condition|)
block|{
name|vm_pages_needed
operator|++
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pages_needed
argument_list|)
expr_stmt|;
block|}
name|asleep
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|,
name|PVM
argument_list|,
literal|"vmwait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_if
if|#
directive|if
literal|0
end_if

begin_comment
comment|/*  *	vm_page_sleep:  *  *	Block until page is no longer busy.  */
end_comment

begin_endif
unit|int vm_page_sleep(vm_page_t m, char *msg, char *busy)  { 	int slept = 0; 	if ((busy&& *busy) || (m->flags& PG_BUSY)) { 		int s; 		s = splvm(); 		if ((busy&& *busy) || (m->flags& PG_BUSY)) { 			vm_page_flag_set(m, PG_WANTED); 			tsleep(m, PVM, msg, 0); 			slept = 1; 		} 		splx(s); 	} 	return slept; }
endif|#
directive|endif
end_endif

begin_if
if|#
directive|if
literal|0
end_if

begin_comment
comment|/*  *	vm_page_asleep:  *  *	Similar to vm_page_sleep(), but does not block.  Returns 0 if  *	the page is not busy, or 1 if the page is busy.  *  *	This routine has the side effect of calling asleep() if the page  *	was busy (1 returned).  */
end_comment

begin_endif
unit|int vm_page_asleep(vm_page_t m, char *msg, char *busy)  { 	int slept = 0; 	if ((busy&& *busy) || (m->flags& PG_BUSY)) { 		int s; 		s = splvm(); 		if ((busy&& *busy) || (m->flags& PG_BUSY)) { 			vm_page_flag_set(m, PG_WANTED); 			asleep(m, PVM, msg, 0); 			slept = 1; 		} 		splx(s); 	} 	return slept; }
endif|#
directive|endif
end_endif

begin_comment
comment|/*  *	vm_page_activate:  *  *	Put the specified page on the active list (if appropriate).  *	Ensure that act_count is at least ACT_INIT but do not otherwise  *	mess with it.  *  *	The page queues must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_activate
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|queue
operator|!=
name|PQ_ACTIVE
condition|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|queue
operator|-
name|m
operator|->
name|pc
operator|)
operator|==
name|PQ_CACHE
condition|)
name|cnt
operator|.
name|v_reactivated
operator|++
expr_stmt|;
name|vm_page_unqueue
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|m
operator|->
name|queue
operator|=
name|PQ_ACTIVE
expr_stmt|;
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|lcnt
operator|++
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|act_count
operator|<
name|ACT_INIT
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_INIT
expr_stmt|;
name|cnt
operator|.
name|v_active_count
operator|++
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|<
name|ACT_INIT
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_INIT
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_wakeup:  *  *	Helper routine for vm_page_free_toq() and vm_page_cache().  This  *	routine is called when a page has been added to the cache or free  *	queues.  *  *	This routine may not block.  *	This routine must be called at splvm()  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|vm_page_free_wakeup
parameter_list|(
name|void
parameter_list|)
block|{
comment|/* 	 * if pageout daemon needs pages, then tell it that there are 	 * some free. 	 */
if|if
condition|(
name|vm_pageout_pages_needed
operator|&&
name|cnt
operator|.
name|v_cache_count
operator|+
name|cnt
operator|.
name|v_free_count
operator|>=
name|cnt
operator|.
name|v_pageout_free_min
condition|)
block|{
name|wakeup
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|)
expr_stmt|;
name|vm_pageout_pages_needed
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * wakeup processes that are waiting on memory if we hit a 	 * high water mark. And wakeup scheduler process if we have 	 * lots of memory. this process will swapin processes. 	 */
if|if
condition|(
name|vm_pages_needed
operator|&&
operator|!
name|vm_page_count_min
argument_list|()
condition|)
block|{
name|vm_pages_needed
operator|=
literal|0
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_toq:  *  *	Returns the given page to the PQ_FREE list,  *	disassociating it with any VM object.  *  *	Object and page must be locked prior to entry.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_free_toq
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|struct
name|vpgqueues
modifier|*
name|pq
decl_stmt|;
name|vm_object_t
name|object
init|=
name|m
operator|->
name|object
decl_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
name|cnt
operator|.
name|v_tfree
operator|++
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|busy
operator|||
operator|(
operator|(
name|m
operator|->
name|queue
operator|-
name|m
operator|->
name|pc
operator|)
operator|==
name|PQ_FREE
operator|)
condition|)
block|{
name|printf
argument_list|(
literal|"vm_page_free: pindex(%lu), busy(%d), PG_BUSY(%d), hold(%d)\n"
argument_list|,
operator|(
name|u_long
operator|)
name|m
operator|->
name|pindex
argument_list|,
name|m
operator|->
name|busy
argument_list|,
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_BUSY
operator|)
condition|?
literal|1
else|:
literal|0
argument_list|,
name|m
operator|->
name|hold_count
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|queue
operator|-
name|m
operator|->
name|pc
operator|)
operator|==
name|PQ_FREE
condition|)
name|panic
argument_list|(
literal|"vm_page_free: freeing free page"
argument_list|)
expr_stmt|;
else|else
name|panic
argument_list|(
literal|"vm_page_free: freeing busy page"
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * unqueue, then remove page.  Note that we cannot destroy 	 * the page here because we do not want to call the pager's 	 * callback routine until after we've put the page on the 	 * appropriate free queue. 	 */
name|vm_page_unqueue_nowakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * If fictitious remove object association and 	 * return, otherwise delay object association removal. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|vm_page_undirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|wire_count
operator|>
literal|1
condition|)
block|{
name|panic
argument_list|(
literal|"vm_page_free: invalid wire count (%d), pindex: 0x%lx"
argument_list|,
name|m
operator|->
name|wire_count
argument_list|,
operator|(
name|long
operator|)
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
block|}
name|panic
argument_list|(
literal|"vm_page_free: freeing wired page\n"
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If we've exhausted the object's resident pages we want to free 	 * it up. 	 */
if|if
condition|(
name|object
operator|&&
operator|(
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
operator|)
operator|&&
operator|(
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_DEAD
operator|)
operator|==
literal|0
operator|)
condition|)
block|{
name|struct
name|vnode
modifier|*
name|vp
init|=
operator|(
expr|struct
name|vnode
operator|*
operator|)
name|object
operator|->
name|handle
decl_stmt|;
if|if
condition|(
name|vp
operator|&&
name|VSHOULDFREE
argument_list|(
name|vp
argument_list|)
condition|)
name|vfree
argument_list|(
name|vp
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Clear the UNMANAGED flag when freeing an unmanaged page. 	 */
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
condition|)
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_UNMANAGED
expr_stmt|;
block|}
else|else
block|{
ifdef|#
directive|ifdef
name|__alpha__
name|pmap_page_is_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
if|if
condition|(
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_HOLD
expr_stmt|;
block|}
else|else
name|m
operator|->
name|queue
operator|=
name|PQ_FREE
operator|+
name|m
operator|->
name|pc
expr_stmt|;
name|pq
operator|=
operator|&
name|vm_page_queues
index|[
name|m
operator|->
name|queue
index|]
expr_stmt|;
name|pq
operator|->
name|lcnt
operator|++
expr_stmt|;
operator|++
operator|(
operator|*
name|pq
operator|->
name|cnt
operator|)
expr_stmt|;
comment|/* 	 * Put zero'd pages on the end ( where we look for zero'd pages 	 * first ) and non-zerod pages at the head. 	 */
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
condition|)
block|{
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pq
operator|->
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
operator|++
name|vm_page_zero_count
expr_stmt|;
block|}
else|else
block|{
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pq
operator|->
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
block|}
name|vm_page_free_wakeup
argument_list|()
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_unmanage:  *  * 	Prevent PV management from being done on the page.  The page is  *	removed from the paging queues as if it were wired, and as a   *	consequence of no longer being managed the pageout daemon will not  *	touch it (since there is no way to locate the pte mappings for the  *	page).  madvise() calls that mess with the pmap will also no longer  *	operate on the page.  *  *	Beyond that the page is still reasonably 'normal'.  Freeing the page  *	will clear the flag.  *  *	This routine is used by OBJT_PHYS objects - objects using unswappable  *	physical memory as backing store rather then swap-backed memory and  *	will eventually be extended to support 4MB unmanaged physical   *	mappings.  */
end_comment

begin_function
name|void
name|vm_page_unmanage
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
name|vm_page_unqueue
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_UNMANAGED
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_wire:  *  *	Mark this page as wired down by yet  *	another map, removing it from paging queues  *	as necessary.  *  *	The page queues must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_wire
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
comment|/* 	 * Only bump the wire statistics if the page is not already wired, 	 * and only unqueue the page if it is on some queue (if it is unmanaged 	 * it is already off the queues). 	 */
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_unqueue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|cnt
operator|.
name|v_wire_count
operator|++
expr_stmt|;
block|}
name|m
operator|->
name|wire_count
operator|++
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_wire: wire_count overflow m=%p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_MAPPED
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_unwire:  *  *	Release one wiring of this page, potentially  *	enabling it to be paged again.  *  *	Many pages placed on the inactive queue should actually go  *	into the cache, but it is difficult to figure out which.  What  *	we do instead, if the inactive target is well met, is to put  *	clean pages at the head of the inactive queue instead of the tail.  *	This will cause them to be moved to the cache more quickly and  *	if not actively re-referenced, freed more quickly.  If we just  *	stick these pages at the end of the inactive queue, heavy filesystem  *	meta-data accesses can cause an unnecessary paging load on memory bound   *	processes.  This optimization causes one-time-use metadata to be  *	reused more quickly.  *  *	BUT, if we are in a low-memory situation we have no choice but to  *	put clean pages on the cache queue.  *  *	A number of routines use vm_page_unwire() to guarantee that the page  *	will go into either the inactive or active queues, and will NEVER  *	be placed in the cache - for example, just after dirtying a page.  *	dirty pages in the cache are not allowed.  *  *	The page queues must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_unwire
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|activate
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|>
literal|0
condition|)
block|{
name|m
operator|->
name|wire_count
operator|--
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|cnt
operator|.
name|v_wire_count
operator|--
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
condition|)
block|{
empty_stmt|;
block|}
elseif|else
if|if
condition|(
name|activate
condition|)
block|{
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_ACTIVE
expr_stmt|;
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|lcnt
operator|++
expr_stmt|;
name|cnt
operator|.
name|v_active_count
operator|++
expr_stmt|;
block|}
else|else
block|{
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WINATCFLS
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_INACTIVE
expr_stmt|;
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|lcnt
operator|++
expr_stmt|;
name|cnt
operator|.
name|v_inactive_count
operator|++
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|panic
argument_list|(
literal|"vm_page_unwire: invalid wire count: %d\n"
argument_list|,
name|m
operator|->
name|wire_count
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Move the specified page to the inactive queue.  If the page has  * any associated swap, the swap is deallocated.  *  * Normally athead is 0 resulting in LRU operation.  athead is set  * to 1 if we want this page to be 'as if it were placed in the cache',  * except without unmapping it from the process address space.  *  * This routine may not block.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|_vm_page_deactivate
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|athead
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
comment|/* 	 * Ignore if already inactive. 	 */
if|if
condition|(
name|m
operator|->
name|queue
operator|==
name|PQ_INACTIVE
condition|)
return|return;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|queue
operator|-
name|m
operator|->
name|pc
operator|)
operator|==
name|PQ_CACHE
condition|)
name|cnt
operator|.
name|v_reactivated
operator|++
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WINATCFLS
argument_list|)
expr_stmt|;
name|vm_page_unqueue
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|athead
condition|)
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_INACTIVE
expr_stmt|;
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|lcnt
operator|++
expr_stmt|;
name|cnt
operator|.
name|v_inactive_count
operator|++
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_deactivate
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|_vm_page_deactivate
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_try_to_cache:  *  * Returns 0 on failure, 1 on success  */
end_comment

begin_function
name|int
name|vm_page_try_to_cache
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|busy
operator|||
name|m
operator|->
name|wire_count
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_BUSY
operator||
name|PG_UNMANAGED
operator|)
operator|)
condition|)
block|{
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|vm_page_test_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|vm_page_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_page_try_to_free()  *  *	Attempt to free the page.  If we cannot free it, we do nothing.  *	1 is returned on success, 0 on failure.  */
end_comment

begin_function
name|int
name|vm_page_try_to_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|busy
operator|||
name|m
operator|->
name|wire_count
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_BUSY
operator||
name|PG_UNMANAGED
operator|)
operator|)
condition|)
block|{
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|vm_page_test_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|vm_page_busy
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_protect
argument_list|(
name|m
argument_list|,
name|VM_PROT_NONE
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_page_cache  *  * Put the specified page onto the page cache queue (if appropriate).  *  * This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_cache
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|s
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_BUSY
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|||
name|m
operator|->
name|busy
operator|||
name|m
operator|->
name|wire_count
condition|)
block|{
name|printf
argument_list|(
literal|"vm_page_cache: attempting to cache busy page\n"
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|queue
operator|-
name|m
operator|->
name|pc
operator|)
operator|==
name|PQ_CACHE
condition|)
return|return;
comment|/* 	 * Remove all pmaps and indicate that the page is not 	 * writeable or mapped. 	 */
name|vm_page_protect
argument_list|(
name|m
argument_list|,
name|VM_PROT_NONE
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|!=
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"vm_page_cache: caching a dirty page, pindex: %ld"
argument_list|,
operator|(
name|long
operator|)
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
block|}
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
name|vm_page_unqueue_nowakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_CACHE
operator|+
name|m
operator|->
name|pc
expr_stmt|;
name|vm_page_queues
index|[
name|m
operator|->
name|queue
index|]
operator|.
name|lcnt
operator|++
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|vm_page_queues
index|[
name|m
operator|->
name|queue
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|cnt
operator|.
name|v_cache_count
operator|++
expr_stmt|;
name|vm_page_free_wakeup
argument_list|()
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_dontneed  *  *	Cache, deactivate, or do nothing as appropriate.  This routine  *	is typically used by madvise() MADV_DONTNEED.  *  *	Generally speaking we want to move the page into the cache so  *	it gets reused quickly.  However, this can result in a silly syndrome  *	due to the page recycling too quickly.  Small objects will not be  *	fully cached.  On the otherhand, if we move the page to the inactive  *	queue we wind up with a problem whereby very large objects   *	unnecessarily blow away our inactive and cache queues.  *  *	The solution is to move the pages based on a fixed weighting.  We  *	either leave them alone, deactivate them, or move them to the cache,  *	where moving them to the cache has the highest weighting.  *	By forcing some pages into other queues we eventually force the  *	system to balance the queues, potentially recovering other unrelated  *	space from active.  The idea is to not force this to happen too  *	often.  */
end_comment

begin_function
name|void
name|vm_page_dontneed
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
specifier|static
name|int
name|dnweight
decl_stmt|;
name|int
name|dnw
decl_stmt|;
name|int
name|head
decl_stmt|;
name|dnw
operator|=
operator|++
name|dnweight
expr_stmt|;
comment|/* 	 * occassionally leave the page alone 	 */
if|if
condition|(
operator|(
name|dnw
operator|&
literal|0x01F0
operator|)
operator|==
literal|0
operator|||
name|m
operator|->
name|queue
operator|==
name|PQ_INACTIVE
operator|||
name|m
operator|->
name|queue
operator|-
name|m
operator|->
name|pc
operator|==
name|PQ_CACHE
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|>=
name|ACT_INIT
condition|)
operator|--
name|m
operator|->
name|act_count
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|m
operator|->
name|dirty
operator|==
literal|0
condition|)
name|vm_page_test_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
operator|(
name|dnw
operator|&
literal|0x0070
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 		 * Deactivate the page 3 times out of 32. 		 */
name|head
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Cache the page 28 times out of every 32.  Note that 		 * the page is deactivated instead of cached, but placed 		 * at the head of the queue instead of the tail. 		 */
name|head
operator|=
literal|1
expr_stmt|;
block|}
name|_vm_page_deactivate
argument_list|(
name|m
argument_list|,
name|head
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Grab a page, waiting until we are waken up due to the page  * changing state.  We keep on waiting, if the page continues  * to be in the object.  If the page doesn't exist, allocate it.  *  * This routine may block.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_grab
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|allocflags
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|s
decl_stmt|,
name|generation
decl_stmt|;
name|retrylookup
label|:
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|busy
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_BUSY
operator|)
condition|)
block|{
name|generation
operator|=
name|object
operator|->
name|generation
expr_stmt|;
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
while|while
condition|(
operator|(
name|object
operator|->
name|generation
operator|==
name|generation
operator|)
operator|&&
operator|(
name|m
operator|->
name|busy
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_BUSY
operator|)
operator|)
condition|)
block|{
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_WANTED
operator||
name|PG_REFERENCED
argument_list|)
expr_stmt|;
name|tsleep
argument_list|(
name|m
argument_list|,
name|PVM
argument_list|,
literal|"pgrbwt"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_RETRY
operator|)
operator|==
literal|0
condition|)
block|{
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
name|NULL
return|;
block|}
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
goto|goto
name|retrylookup
goto|;
block|}
else|else
block|{
name|vm_page_busy
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
name|m
return|;
block|}
block|}
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|allocflags
operator|&
operator|~
name|VM_ALLOC_RETRY
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|VM_WAIT
expr_stmt|;
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_RETRY
operator|)
operator|==
literal|0
condition|)
return|return
name|NULL
return|;
goto|goto
name|retrylookup
goto|;
block|}
return|return
name|m
return|;
block|}
end_function

begin_comment
comment|/*  * Mapping function for valid bits or for dirty bits in  * a page.  May not block.  *  * Inputs are required to range within a page.  */
end_comment

begin_function
name|__inline
name|int
name|vm_page_bits
parameter_list|(
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|first_bit
decl_stmt|;
name|int
name|last_bit
decl_stmt|;
name|KASSERT
argument_list|(
name|base
operator|+
name|size
operator|<=
name|PAGE_SIZE
argument_list|,
operator|(
literal|"vm_page_bits: illegal base/size %d/%d"
operator|,
name|base
operator|,
name|size
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return
operator|(
literal|0
operator|)
return|;
name|first_bit
operator|=
name|base
operator|>>
name|DEV_BSHIFT
expr_stmt|;
name|last_bit
operator|=
operator|(
name|base
operator|+
name|size
operator|-
literal|1
operator|)
operator|>>
name|DEV_BSHIFT
expr_stmt|;
return|return
operator|(
operator|(
literal|2
operator|<<
name|last_bit
operator|)
operator|-
operator|(
literal|1
operator|<<
name|first_bit
operator|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_set_validclean:  *  *	Sets portions of a page valid and clean.  The arguments are expected  *	to be DEV_BSIZE aligned but if they aren't the bitmap is inclusive  *	of any partial chunks touched by the range.  The invalid portion of  *	such chunks will be zero'd.  *  *	This routine may not block.  *  *	(base + size) must be less then or equal to PAGE_SIZE.  */
end_comment

begin_function
name|void
name|vm_page_set_validclean
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|pagebits
decl_stmt|;
name|int
name|frag
decl_stmt|;
name|int
name|endoff
decl_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return;
comment|/* 	 * If the base is not DEV_BSIZE aligned and the valid 	 * bit is clear, we have to zero out a portion of the 	 * first block. 	 */
if|if
condition|(
operator|(
name|frag
operator|=
name|base
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|base
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|base
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|frag
argument_list|,
name|base
operator|-
name|frag
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If the ending offset is not DEV_BSIZE aligned and the  	 * valid bit is clear, we have to zero out a portion of 	 * the last block. 	 */
name|endoff
operator|=
name|base
operator|+
name|size
expr_stmt|;
if|if
condition|(
operator|(
name|frag
operator|=
name|endoff
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|endoff
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|endoff
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|endoff
argument_list|,
name|DEV_BSIZE
operator|-
operator|(
name|endoff
operator|&
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Set valid, clear dirty bits.  If validating the entire 	 * page we can safely clear the pmap modify bit.  We also 	 * use this opportunity to clear the PG_NOSYNC flag.  If a process 	 * takes a write fault on a MAP_NOSYNC memory area the flag will 	 * be set again. 	 * 	 * We set valid bits inclusive of any overlap, but we can only 	 * clear dirty bits for DEV_BSIZE chunks that are fully within 	 * the range. 	 */
name|pagebits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator||=
name|pagebits
expr_stmt|;
if|#
directive|if
literal|0
comment|/* NOT YET */
block|if ((frag = base& (DEV_BSIZE - 1)) != 0) { 		frag = DEV_BSIZE - frag; 		base += frag; 		size -= frag; 		if (size< 0) 		    size = 0; 	} 	pagebits = vm_page_bits(base, size& (DEV_BSIZE - 1));
endif|#
directive|endif
name|m
operator|->
name|dirty
operator|&=
operator|~
name|pagebits
expr_stmt|;
if|if
condition|(
name|base
operator|==
literal|0
operator|&&
name|size
operator|==
name|PAGE_SIZE
condition|)
block|{
name|pmap_clear_modify
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_NOSYNC
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_if
if|#
directive|if
literal|0
end_if

begin_endif
unit|void vm_page_set_dirty(vm_page_t m, int base, int size) { 	m->dirty |= vm_page_bits(base, size); }
endif|#
directive|endif
end_endif

begin_function
name|void
name|vm_page_clear_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|m
operator|->
name|dirty
operator|&=
operator|~
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_set_invalid:  *  *	Invalidates DEV_BSIZE'd chunks within a page.  Both the  *	valid and dirty bits for the effected areas are cleared.  *  *	May not block.  */
end_comment

begin_function
name|void
name|vm_page_set_invalid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|bits
decl_stmt|;
name|bits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator|&=
operator|~
name|bits
expr_stmt|;
name|m
operator|->
name|dirty
operator|&=
operator|~
name|bits
expr_stmt|;
name|m
operator|->
name|object
operator|->
name|generation
operator|++
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_zero_invalid()  *  *	The kernel assumes that the invalid portions of a page contain   *	garbage, but such pages can be mapped into memory by user code.  *	When this occurs, we must zero out the non-valid portions of the  *	page so user code sees what it expects.  *  *	Pages are most often semi-valid when the end of a file is mapped   *	into memory and the file's size is not page aligned.  */
end_comment

begin_function
name|void
name|vm_page_zero_invalid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|boolean_t
name|setvalid
parameter_list|)
block|{
name|int
name|b
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * Scan the valid bits looking for invalid sections that 	 * must be zerod.  Invalid sub-DEV_BSIZE'd areas ( where the 	 * valid bit may be set ) have already been zerod by 	 * vm_page_set_validclean(). 	 */
for|for
control|(
name|b
operator|=
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|PAGE_SIZE
operator|/
name|DEV_BSIZE
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|i
operator|==
operator|(
name|PAGE_SIZE
operator|/
name|DEV_BSIZE
operator|)
operator|||
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
name|i
operator|)
operator|)
condition|)
block|{
if|if
condition|(
name|i
operator|>
name|b
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|,
name|b
operator|<<
name|DEV_BSHIFT
argument_list|,
operator|(
name|i
operator|-
name|b
operator|)
operator|<<
name|DEV_BSHIFT
argument_list|)
expr_stmt|;
block|}
name|b
operator|=
name|i
operator|+
literal|1
expr_stmt|;
block|}
block|}
comment|/* 	 * setvalid is TRUE when we can safely set the zero'd areas 	 * as being valid.  We can do this if there are no cache consistency 	 * issues.  e.g. it is ok to do with UFS, but not ok to do with NFS. 	 */
if|if
condition|(
name|setvalid
condition|)
name|m
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_is_valid:  *  *	Is (partial) page valid?  Note that the case where size == 0  *	will return FALSE in the degenerate case where the page is  *	entirely invalid, and TRUE otherwise.  *  *	May not block.  */
end_comment

begin_function
name|int
name|vm_page_is_valid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|bits
init|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
decl_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|&&
operator|(
operator|(
name|m
operator|->
name|valid
operator|&
name|bits
operator|)
operator|==
name|bits
operator|)
condition|)
return|return
literal|1
return|;
else|else
return|return
literal|0
return|;
block|}
end_function

begin_comment
comment|/*  * update dirty bits from pmap/mmu.  May not block.  */
end_comment

begin_function
name|void
name|vm_page_test_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|dirty
operator|!=
name|VM_PAGE_BITS_ALL
operator|)
operator|&&
name|pmap_is_modified
argument_list|(
name|m
argument_list|)
condition|)
block|{
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * This interface is for merging with malloc() someday.  * Even if we never implement compaction so that contiguous allocation  * works after initialization time, malloc()'s data structures are good  * for statistics and for allocations of less than a page.  */
end_comment

begin_function
name|void
modifier|*
name|contigmalloc1
parameter_list|(
name|unsigned
name|long
name|size
parameter_list|,
comment|/* should be size_t here and for malloc() */
name|struct
name|malloc_type
modifier|*
name|type
parameter_list|,
name|int
name|flags
parameter_list|,
name|unsigned
name|long
name|low
parameter_list|,
name|unsigned
name|long
name|high
parameter_list|,
name|unsigned
name|long
name|alignment
parameter_list|,
name|unsigned
name|long
name|boundary
parameter_list|,
name|vm_map_t
name|map
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|s
decl_stmt|,
name|start
decl_stmt|;
name|vm_offset_t
name|addr
decl_stmt|,
name|phys
decl_stmt|,
name|tmp_addr
decl_stmt|;
name|int
name|pass
decl_stmt|;
name|vm_page_t
name|pga
init|=
name|vm_page_array
decl_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"contigmalloc1: size must not be 0"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|alignment
operator|&
operator|(
name|alignment
operator|-
literal|1
operator|)
operator|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"contigmalloc1: alignment must be a power of 2"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|boundary
operator|&
operator|(
name|boundary
operator|-
literal|1
operator|)
operator|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"contigmalloc1: boundary must be a power of 2"
argument_list|)
expr_stmt|;
name|start
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|pass
operator|=
literal|0
init|;
name|pass
operator|<=
literal|1
condition|;
name|pass
operator|++
control|)
block|{
name|s
operator|=
name|splvm
argument_list|()
expr_stmt|;
name|again
label|:
comment|/* 		 * Find first page in array that is free, within range, aligned, and 		 * such that the boundary won't be crossed. 		 */
for|for
control|(
name|i
operator|=
name|start
init|;
name|i
operator|<
name|cnt
operator|.
name|v_page_count
condition|;
name|i
operator|++
control|)
block|{
name|int
name|pqtype
decl_stmt|;
name|phys
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
operator|&
name|pga
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|pqtype
operator|=
name|pga
index|[
name|i
index|]
operator|.
name|queue
operator|-
name|pga
index|[
name|i
index|]
operator|.
name|pc
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|pqtype
operator|==
name|PQ_FREE
operator|)
operator|||
operator|(
name|pqtype
operator|==
name|PQ_CACHE
operator|)
operator|)
operator|&&
operator|(
name|phys
operator|>=
name|low
operator|)
operator|&&
operator|(
name|phys
operator|<
name|high
operator|)
operator|&&
operator|(
operator|(
name|phys
operator|&
operator|(
name|alignment
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
operator|(
operator|(
name|phys
operator|^
operator|(
name|phys
operator|+
name|size
operator|-
literal|1
operator|)
operator|)
operator|&
operator|~
operator|(
name|boundary
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
operator|)
condition|)
break|break;
block|}
comment|/* 		 * If the above failed or we will exceed the upper bound, fail. 		 */
if|if
condition|(
operator|(
name|i
operator|==
name|cnt
operator|.
name|v_page_count
operator|)
operator|||
operator|(
operator|(
name|VM_PAGE_TO_PHYS
argument_list|(
operator|&
name|pga
index|[
name|i
index|]
argument_list|)
operator|+
name|size
operator|)
operator|>
name|high
operator|)
condition|)
block|{
name|vm_page_t
name|m
decl_stmt|,
name|next
decl_stmt|;
name|again1
label|:
for|for
control|(
name|m
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|)
init|;
name|m
operator|!=
name|NULL
condition|;
name|m
operator|=
name|next
control|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_INACTIVE
argument_list|,
operator|(
literal|"contigmalloc1: page %p is not PQ_INACTIVE"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_sleep_busy
argument_list|(
name|m
argument_list|,
name|TRUE
argument_list|,
literal|"vpctw0"
argument_list|)
condition|)
goto|goto
name|again1
goto|;
name|vm_page_test_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
block|{
name|vn_lock
argument_list|(
name|m
operator|->
name|object
operator|->
name|handle
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_RETRY
argument_list|,
name|curproc
argument_list|)
expr_stmt|;
name|vm_object_page_clean
argument_list|(
name|m
operator|->
name|object
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|OBJPC_SYNC
argument_list|)
expr_stmt|;
name|VOP_UNLOCK
argument_list|(
name|m
operator|->
name|object
operator|->
name|handle
argument_list|,
literal|0
argument_list|,
name|curproc
argument_list|)
expr_stmt|;
goto|goto
name|again1
goto|;
block|}
elseif|else
if|if
condition|(
name|m
operator|->
name|object
operator|->
name|type
operator|==
name|OBJT_SWAP
operator|||
name|m
operator|->
name|object
operator|->
name|type
operator|==
name|OBJT_DEFAULT
condition|)
block|{
name|vm_pageout_flush
argument_list|(
operator|&
name|m
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|)
expr_stmt|;
goto|goto
name|again1
goto|;
block|}
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|dirty
operator|==
literal|0
operator|)
operator|&&
operator|(
name|m
operator|->
name|busy
operator|==
literal|0
operator|)
operator|&&
operator|(
name|m
operator|->
name|hold_count
operator|==
literal|0
operator|)
condition|)
name|vm_page_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|m
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pl
argument_list|)
init|;
name|m
operator|!=
name|NULL
condition|;
name|m
operator|=
name|next
control|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_ACTIVE
argument_list|,
operator|(
literal|"contigmalloc1: page %p is not PQ_ACTIVE"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_sleep_busy
argument_list|(
name|m
argument_list|,
name|TRUE
argument_list|,
literal|"vpctw1"
argument_list|)
condition|)
goto|goto
name|again1
goto|;
name|vm_page_test_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
block|{
name|vn_lock
argument_list|(
name|m
operator|->
name|object
operator|->
name|handle
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_RETRY
argument_list|,
name|curproc
argument_list|)
expr_stmt|;
name|vm_object_page_clean
argument_list|(
name|m
operator|->
name|object
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|OBJPC_SYNC
argument_list|)
expr_stmt|;
name|VOP_UNLOCK
argument_list|(
name|m
operator|->
name|object
operator|->
name|handle
argument_list|,
literal|0
argument_list|,
name|curproc
argument_list|)
expr_stmt|;
goto|goto
name|again1
goto|;
block|}
elseif|else
if|if
condition|(
name|m
operator|->
name|object
operator|->
name|type
operator|==
name|OBJT_SWAP
operator|||
name|m
operator|->
name|object
operator|->
name|type
operator|==
name|OBJT_DEFAULT
condition|)
block|{
name|vm_pageout_flush
argument_list|(
operator|&
name|m
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|)
expr_stmt|;
goto|goto
name|again1
goto|;
block|}
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|dirty
operator|==
literal|0
operator|)
operator|&&
operator|(
name|m
operator|->
name|busy
operator|==
literal|0
operator|)
operator|&&
operator|(
name|m
operator|->
name|hold_count
operator|==
literal|0
operator|)
condition|)
name|vm_page_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|start
operator|=
name|i
expr_stmt|;
comment|/* 		 * Check successive pages for contiguous and free. 		 */
for|for
control|(
name|i
operator|=
name|start
operator|+
literal|1
init|;
name|i
operator|<
operator|(
name|start
operator|+
name|size
operator|/
name|PAGE_SIZE
operator|)
condition|;
name|i
operator|++
control|)
block|{
name|int
name|pqtype
decl_stmt|;
name|pqtype
operator|=
name|pga
index|[
name|i
index|]
operator|.
name|queue
operator|-
name|pga
index|[
name|i
index|]
operator|.
name|pc
expr_stmt|;
if|if
condition|(
operator|(
name|VM_PAGE_TO_PHYS
argument_list|(
operator|&
name|pga
index|[
name|i
index|]
argument_list|)
operator|!=
operator|(
name|VM_PAGE_TO_PHYS
argument_list|(
operator|&
name|pga
index|[
name|i
operator|-
literal|1
index|]
argument_list|)
operator|+
name|PAGE_SIZE
operator|)
operator|)
operator|||
operator|(
operator|(
name|pqtype
operator|!=
name|PQ_FREE
operator|)
operator|&&
operator|(
name|pqtype
operator|!=
name|PQ_CACHE
operator|)
operator|)
condition|)
block|{
name|start
operator|++
expr_stmt|;
goto|goto
name|again
goto|;
block|}
block|}
for|for
control|(
name|i
operator|=
name|start
init|;
name|i
operator|<
operator|(
name|start
operator|+
name|size
operator|/
name|PAGE_SIZE
operator|)
condition|;
name|i
operator|++
control|)
block|{
name|int
name|pqtype
decl_stmt|;
name|vm_page_t
name|m
init|=
operator|&
name|pga
index|[
name|i
index|]
decl_stmt|;
name|pqtype
operator|=
name|m
operator|->
name|queue
operator|-
name|m
operator|->
name|pc
expr_stmt|;
if|if
condition|(
name|pqtype
operator|==
name|PQ_CACHE
condition|)
block|{
name|vm_page_busy
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_unqueue_nowakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
condition|)
name|vm_page_zero_count
operator|--
expr_stmt|;
name|m
operator|->
name|flags
operator|=
literal|0
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"contigmalloc1: page %p was dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|busy
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
block|}
comment|/* 		 * We've found a contiguous chunk that meets are requirements. 		 * Allocate kernel VM, unfree and assign the physical pages to it and 		 * return kernel VM pointer. 		 */
name|vm_map_lock
argument_list|(
name|map
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_map_findspace
argument_list|(
name|map
argument_list|,
name|vm_map_min
argument_list|(
name|map
argument_list|)
argument_list|,
name|size
argument_list|,
operator|&
name|addr
argument_list|)
operator|!=
name|KERN_SUCCESS
condition|)
block|{
comment|/* 			 * XXX We almost never run out of kernel virtual 			 * space, so we don't make the allocated memory 			 * above available. 			 */
name|vm_map_unlock
argument_list|(
name|map
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|vm_object_reference
argument_list|(
name|kernel_object
argument_list|)
expr_stmt|;
name|vm_map_insert
argument_list|(
name|map
argument_list|,
name|kernel_object
argument_list|,
name|addr
operator|-
name|VM_MIN_KERNEL_ADDRESS
argument_list|,
name|addr
argument_list|,
name|addr
operator|+
name|size
argument_list|,
name|VM_PROT_ALL
argument_list|,
name|VM_PROT_ALL
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|vm_map_unlock
argument_list|(
name|map
argument_list|)
expr_stmt|;
name|tmp_addr
operator|=
name|addr
expr_stmt|;
for|for
control|(
name|i
operator|=
name|start
init|;
name|i
operator|<
operator|(
name|start
operator|+
name|size
operator|/
name|PAGE_SIZE
operator|)
condition|;
name|i
operator|++
control|)
block|{
name|vm_page_t
name|m
init|=
operator|&
name|pga
index|[
name|i
index|]
decl_stmt|;
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|kernel_object
argument_list|,
name|OFF_TO_IDX
argument_list|(
name|tmp_addr
operator|-
name|VM_MIN_KERNEL_ADDRESS
argument_list|)
argument_list|)
expr_stmt|;
name|tmp_addr
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|vm_map_pageable
argument_list|(
name|map
argument_list|,
name|addr
argument_list|,
name|addr
operator|+
name|size
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
operator|(
operator|(
name|void
operator|*
operator|)
name|addr
operator|)
return|;
block|}
return|return
name|NULL
return|;
block|}
end_function

begin_function
name|void
modifier|*
name|contigmalloc
parameter_list|(
name|unsigned
name|long
name|size
parameter_list|,
comment|/* should be size_t here and for malloc() */
name|struct
name|malloc_type
modifier|*
name|type
parameter_list|,
name|int
name|flags
parameter_list|,
name|unsigned
name|long
name|low
parameter_list|,
name|unsigned
name|long
name|high
parameter_list|,
name|unsigned
name|long
name|alignment
parameter_list|,
name|unsigned
name|long
name|boundary
parameter_list|)
block|{
return|return
name|contigmalloc1
argument_list|(
name|size
argument_list|,
name|type
argument_list|,
name|flags
argument_list|,
name|low
argument_list|,
name|high
argument_list|,
name|alignment
argument_list|,
name|boundary
argument_list|,
name|kernel_map
argument_list|)
return|;
block|}
end_function

begin_function
name|void
name|contigfree
parameter_list|(
name|void
modifier|*
name|addr
parameter_list|,
name|unsigned
name|long
name|size
parameter_list|,
name|struct
name|malloc_type
modifier|*
name|type
parameter_list|)
block|{
name|kmem_free
argument_list|(
name|kernel_map
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|addr
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|vm_offset_t
name|vm_page_alloc_contig
parameter_list|(
name|vm_offset_t
name|size
parameter_list|,
name|vm_offset_t
name|low
parameter_list|,
name|vm_offset_t
name|high
parameter_list|,
name|vm_offset_t
name|alignment
parameter_list|)
block|{
return|return
operator|(
operator|(
name|vm_offset_t
operator|)
name|contigmalloc1
argument_list|(
name|size
argument_list|,
name|M_DEVBUF
argument_list|,
name|M_NOWAIT
argument_list|,
name|low
argument_list|,
name|high
argument_list|,
name|alignment
argument_list|,
literal|0ul
argument_list|,
name|kernel_map
argument_list|)
operator|)
return|;
block|}
end_function

begin_include
include|#
directive|include
file|"opt_ddb.h"
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<ddb/ddb.h>
end_include

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|page
argument_list|,
argument|vm_page_print_page_info
argument_list|)
end_macro

begin_block
block|{
name|db_printf
argument_list|(
literal|"cnt.v_free_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_cache_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_cache_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_inactive_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_inactive_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_active_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_active_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_wire_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_wire_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_reserved: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_reserved
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_min: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_min
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_target: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_target
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_cache_min: %d\n"
argument_list|,
name|cnt
operator|.
name|v_cache_min
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_inactive_target: %d\n"
argument_list|,
name|cnt
operator|.
name|v_inactive_target
argument_list|)
expr_stmt|;
block|}
end_block

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|pageq
argument_list|,
argument|vm_page_print_pageq_info
argument_list|)
end_macro

begin_block
block|{
name|int
name|i
decl_stmt|;
name|db_printf
argument_list|(
literal|"PQ_FREE:"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PQ_L2_SIZE
condition|;
name|i
operator|++
control|)
block|{
name|db_printf
argument_list|(
literal|" %d"
argument_list|,
name|vm_page_queues
index|[
name|PQ_FREE
operator|+
name|i
index|]
operator|.
name|lcnt
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"PQ_CACHE:"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PQ_L2_SIZE
condition|;
name|i
operator|++
control|)
block|{
name|db_printf
argument_list|(
literal|" %d"
argument_list|,
name|vm_page_queues
index|[
name|PQ_CACHE
operator|+
name|i
index|]
operator|.
name|lcnt
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"PQ_ACTIVE: %d, PQ_INACTIVE: %d\n"
argument_list|,
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|lcnt
argument_list|,
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|lcnt
argument_list|)
expr_stmt|;
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* DDB */
end_comment

end_unit

