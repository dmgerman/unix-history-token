begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1991 Regents of the University of California.  * All rights reserved.  *  * This code is derived from software contributed to Berkeley by  * The Mach Operating System project at Carnegie-Mellon University.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from: @(#)vm_page.c	7.4 (Berkeley) 5/7/91  */
end_comment

begin_comment
comment|/*-  * Copyright (c) 1987, 1990 Carnegie-Mellon University.  * All rights reserved.  *  * Authors: Avadis Tevanian, Jr., Michael Wayne Young  *  * Permission to use, copy, modify and distribute this software and  * its documentation is hereby granted, provided that both the copyright  * notice and this permission notice appear in all copies of the  * software, derivative works or modified versions, and any portions  * thereof, and that both notices appear in supporting documentation.  *  * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"  * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND  * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.  *  * Carnegie Mellon requests users of this software to return to  *  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU  *  School of Computer Science  *  Carnegie Mellon University  *  Pittsburgh PA 15213-3890  *  * any improvements or extensions that they make and grant Carnegie the  * rights to redistribute these changes.  */
end_comment

begin_comment
comment|/*  *			GENERAL RULES ON VM_PAGE MANIPULATION  *  *	- a pageq mutex is required when adding or removing a page from a  *	  page queue (vm_page_queue[]), regardless of other mutexes or the  *	  busy state of a page.  *  *	- a hash chain mutex is required when associating or disassociating  *	  a page from the VM PAGE CACHE hash table (vm_page_buckets),  *	  regardless of other mutexes or the busy state of a page.  *  *	- either a hash chain mutex OR a busied page is required in order  *	  to modify the page flags.  A hash chain mutex must be obtained in  *	  order to busy a page.  A page's flags cannot be modified by a  *	  hash chain mutex if the page is marked busy.  *  *	- The object memq mutex is held when inserting or removing  *	  pages from an object (vm_page_insert() or vm_page_remove()).  This  *	  is different from the object's main mutex.  *  *	Generally speaking, you have to be aware of side effects when running  *	vm_page ops.  A vm_page_lookup() will return with the hash chain  *	locked, whether it was able to lookup the page or not.  vm_page_free(),  *	vm_page_cache(), vm_page_activate(), and a number of other routines  *	will release the hash chain mutex for you.  Intermediate manipulation  *	routines such as vm_page_flag_set() expect the hash chain to be held  *	on entry and the hash chain will remain held on return.  *  *	pageq scanning can only occur with the pageq in question locked.  *	We have a known bottleneck with the active queue, but the cache  *	and free queues are actually arrays already.   */
end_comment

begin_comment
comment|/*  *	Resident memory management module.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma_int.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_comment
comment|/*  *	Associated with page of user-allocatable memory is a  *	page structure.  */
end_comment

begin_decl_stmt
name|struct
name|mtx
name|vm_page_queue_mtx
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mtx
name|vm_page_queue_free_mtx
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_page_t
name|vm_page_array
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|vm_page_array_size
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|long
name|first_page
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|vm_page_zero_count
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|boot_pages
init|=
name|UMA_BOOT_PAGES
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"vm.boot_pages"
argument_list|,
operator|&
name|boot_pages
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|boot_pages
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|boot_pages
argument_list|,
literal|0
argument_list|,
literal|"number of pages allocated for bootstrapping the VM system"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *	vm_set_page_size:  *  *	Sets the page size, perhaps based upon the memory  *	size.  Must be called before any use of page-size  *	dependent functions.  */
end_comment

begin_function
name|void
name|vm_set_page_size
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|cnt
operator|.
name|v_page_size
operator|==
literal|0
condition|)
name|cnt
operator|.
name|v_page_size
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|cnt
operator|.
name|v_page_size
operator|-
literal|1
operator|)
operator|&
name|cnt
operator|.
name|v_page_size
operator|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_set_page_size: page size not a power of two"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_blacklist_lookup:  *  *	See if a physical address in this page has been listed  *	in the blacklist tunable.  Entries in the tunable are  *	separated by spaces or commas.  If an invalid integer is  *	encountered then the rest of the string is skipped.  */
end_comment

begin_function
specifier|static
name|int
name|vm_page_blacklist_lookup
parameter_list|(
name|char
modifier|*
name|list
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|vm_paddr_t
name|bad
decl_stmt|;
name|char
modifier|*
name|cp
decl_stmt|,
modifier|*
name|pos
decl_stmt|;
for|for
control|(
name|pos
operator|=
name|list
init|;
operator|*
name|pos
operator|!=
literal|'\0'
condition|;
name|pos
operator|=
name|cp
control|)
block|{
name|bad
operator|=
name|strtoq
argument_list|(
name|pos
argument_list|,
operator|&
name|cp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cp
operator|!=
literal|'\0'
condition|)
block|{
if|if
condition|(
operator|*
name|cp
operator|==
literal|' '
operator|||
operator|*
name|cp
operator|==
literal|','
condition|)
block|{
name|cp
operator|++
expr_stmt|;
if|if
condition|(
name|cp
operator|==
name|pos
condition|)
continue|continue;
block|}
else|else
break|break;
block|}
if|if
condition|(
name|pa
operator|==
name|trunc_page
argument_list|(
name|bad
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_startup:  *  *	Initializes the resident memory module.  *  *	Allocates memory for the page cells, and  *	for the object/offset-to-page hash table headers.  *	Each page cell is initialized and placed on the free list.  */
end_comment

begin_function
name|vm_offset_t
name|vm_page_startup
parameter_list|(
name|vm_offset_t
name|vaddr
parameter_list|)
block|{
name|vm_offset_t
name|mapped
decl_stmt|;
name|vm_size_t
name|npages
decl_stmt|;
name|vm_paddr_t
name|page_range
decl_stmt|;
name|vm_paddr_t
name|new_end
decl_stmt|;
name|int
name|i
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|int
name|nblocks
decl_stmt|;
name|vm_paddr_t
name|last_pa
decl_stmt|;
name|char
modifier|*
name|list
decl_stmt|;
comment|/* the biggest memory array is the second group of pages */
name|vm_paddr_t
name|end
decl_stmt|;
name|vm_paddr_t
name|biggestsize
decl_stmt|;
name|vm_paddr_t
name|low_water
decl_stmt|,
name|high_water
decl_stmt|;
name|int
name|biggestone
decl_stmt|;
name|vm_paddr_t
name|total
decl_stmt|;
name|total
operator|=
literal|0
expr_stmt|;
name|biggestsize
operator|=
literal|0
expr_stmt|;
name|biggestone
operator|=
literal|0
expr_stmt|;
name|nblocks
operator|=
literal|0
expr_stmt|;
name|vaddr
operator|=
name|round_page
argument_list|(
name|vaddr
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|phys_avail
index|[
name|i
index|]
operator|=
name|round_page
argument_list|(
name|phys_avail
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|=
name|trunc_page
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
name|low_water
operator|=
name|phys_avail
index|[
literal|0
index|]
expr_stmt|;
name|high_water
operator|=
name|phys_avail
index|[
literal|1
index|]
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|vm_paddr_t
name|size
init|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|size
operator|>
name|biggestsize
condition|)
block|{
name|biggestone
operator|=
name|i
expr_stmt|;
name|biggestsize
operator|=
name|size
expr_stmt|;
block|}
if|if
condition|(
name|phys_avail
index|[
name|i
index|]
operator|<
name|low_water
condition|)
name|low_water
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|>
name|high_water
condition|)
name|high_water
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
operator|++
name|nblocks
expr_stmt|;
name|total
operator|+=
name|size
expr_stmt|;
block|}
name|end
operator|=
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
expr_stmt|;
comment|/* 	 * Initialize the locks. 	 */
name|mtx_init
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
literal|"vm page queue mutex"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
operator||
name|MTX_RECURSE
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
literal|"vm page queue free mutex"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the queue headers for the free queue, the active queue 	 * and the inactive queue. 	 */
name|vm_pageq_init
argument_list|()
expr_stmt|;
comment|/* 	 * Allocate memory for use when boot strapping the kernel memory 	 * allocator. 	 */
name|new_end
operator|=
name|end
operator|-
operator|(
name|boot_pages
operator|*
name|UMA_SLAB_SIZE
operator|)
expr_stmt|;
name|new_end
operator|=
name|trunc_page
argument_list|(
name|new_end
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|end
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|mapped
argument_list|,
name|end
operator|-
name|new_end
argument_list|)
expr_stmt|;
name|uma_startup
argument_list|(
operator|(
name|void
operator|*
operator|)
name|mapped
argument_list|,
name|boot_pages
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__i386__
argument_list|)
comment|/* 	 * Allocate a bitmap to indicate that a random physical page 	 * needs to be included in a minidump. 	 * 	 * The amd64 port needs this to indicate which direct map pages 	 * need to be dumped, via calls to dump_add_page()/dump_drop_page(). 	 * 	 * However, i386 still needs this workspace internally within the 	 * minidump code.  In theory, they are not needed on i386, but are 	 * included should the sf_buf code decide to use them. 	 */
name|page_range
operator|=
name|phys_avail
index|[
operator|(
name|nblocks
operator|-
literal|1
operator|)
operator|*
literal|2
operator|+
literal|1
index|]
operator|/
name|PAGE_SIZE
expr_stmt|;
name|vm_page_dump_size
operator|=
name|round_page
argument_list|(
name|roundup2
argument_list|(
name|page_range
argument_list|,
name|NBBY
argument_list|)
operator|/
name|NBBY
argument_list|)
expr_stmt|;
name|new_end
operator|-=
name|vm_page_dump_size
expr_stmt|;
name|vm_page_dump
operator|=
operator|(
name|void
operator|*
operator|)
operator|(
name|uintptr_t
operator|)
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|new_end
operator|+
name|vm_page_dump_size
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|vm_page_dump
argument_list|,
name|vm_page_dump_size
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Compute the number of pages of memory that will be available for 	 * use (taking into account the overhead of a page structure per 	 * page). 	 */
name|first_page
operator|=
name|low_water
operator|/
name|PAGE_SIZE
expr_stmt|;
name|page_range
operator|=
name|high_water
operator|/
name|PAGE_SIZE
operator|-
name|first_page
expr_stmt|;
name|npages
operator|=
operator|(
name|total
operator|-
operator|(
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
operator|)
operator|-
operator|(
name|end
operator|-
name|new_end
operator|)
operator|)
operator|/
name|PAGE_SIZE
expr_stmt|;
name|end
operator|=
name|new_end
expr_stmt|;
comment|/* 	 * Reserve an unmapped guard page to trap access to vm_page_array[-1]. 	 */
name|vaddr
operator|+=
name|PAGE_SIZE
expr_stmt|;
comment|/* 	 * Initialize the mem entry structures now, and put them in the free 	 * queue. 	 */
name|new_end
operator|=
name|trunc_page
argument_list|(
name|end
operator|-
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|end
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|vm_page_array
operator|=
operator|(
name|vm_page_t
operator|)
name|mapped
expr_stmt|;
ifdef|#
directive|ifdef
name|__amd64__
comment|/* 	 * pmap_map on amd64 comes out of the direct-map, not kvm like i386, 	 * so the pages must be tracked for a crashdump to include this data. 	 * This includes the vm_page_array and the early UMA bootstrap pages. 	 */
for|for
control|(
name|pa
operator|=
name|new_end
init|;
name|pa
operator|<
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|dump_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
operator|=
name|new_end
expr_stmt|;
comment|/* 	 * Clear all of the page structures 	 */
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|vm_page_array
argument_list|,
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|)
expr_stmt|;
name|vm_page_array_size
operator|=
name|page_range
expr_stmt|;
comment|/* 	 * This assertion tests the hypothesis that npages and total are 	 * redundant.  XXX 	 */
name|page_range
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
name|page_range
operator|+=
name|atop
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|page_range
operator|==
name|npages
argument_list|,
operator|(
literal|"vm_page_startup: inconsistent page counts"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Construct the free queue(s) in descending order (by physical 	 * address) so that the first 16MB of physical memory is allocated 	 * last rather than first.  On large-memory machines, this avoids 	 * the exhaustion of low physical memory before isa_dma_init has run. 	 */
name|cnt
operator|.
name|v_page_count
operator|=
literal|0
expr_stmt|;
name|cnt
operator|.
name|v_free_count
operator|=
literal|0
expr_stmt|;
name|list
operator|=
name|getenv
argument_list|(
literal|"vm.blacklist"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|pa
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
name|last_pa
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
while|while
condition|(
name|pa
operator|<
name|last_pa
condition|)
block|{
if|if
condition|(
name|list
operator|!=
name|NULL
operator|&&
name|vm_page_blacklist_lookup
argument_list|(
name|list
argument_list|,
name|pa
argument_list|)
condition|)
name|printf
argument_list|(
literal|"Skipping page with pa 0x%jx\n"
argument_list|,
operator|(
name|uintmax_t
operator|)
name|pa
argument_list|)
expr_stmt|;
else|else
name|vm_pageq_add_new_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
name|freeenv
argument_list|(
name|list
argument_list|)
expr_stmt|;
return|return
operator|(
name|vaddr
operator|)
return|;
block|}
end_function

begin_function
name|void
name|vm_page_flag_set
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|unsigned
name|short
name|bits
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator||=
name|bits
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_flag_clear
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|unsigned
name|short
name|bits
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
operator|~
name|bits
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_busy
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_busy: page already busy!!!"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|oflags
operator||=
name|VPO_BUSY
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *      vm_page_flash:  *  *      wakeup anyone waiting for the page.  */
end_comment

begin_function
name|void
name|vm_page_flash
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|oflags
operator|&
name|VPO_WANTED
condition|)
block|{
name|m
operator|->
name|oflags
operator|&=
operator|~
name|VPO_WANTED
expr_stmt|;
name|wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *      vm_page_wakeup:  *  *      clear the VPO_BUSY flag and wakeup anyone waiting for the  *      page.  *  */
end_comment

begin_function
name|void
name|vm_page_wakeup
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
argument_list|,
operator|(
literal|"vm_page_wakeup: page not busy!!!"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|oflags
operator|&=
operator|~
name|VPO_BUSY
expr_stmt|;
name|vm_page_flash
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_io_start
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|->
name|busy
operator|++
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_io_finish
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|->
name|busy
operator|--
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|busy
operator|==
literal|0
condition|)
name|vm_page_flash
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Keep page from being freed by the page daemon  * much of the same effect as wiring, except much lower  * overhead and should be used only for *very* temporary  * holding ("wiring").  */
end_comment

begin_function
name|void
name|vm_page_hold
parameter_list|(
name|vm_page_t
name|mem
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mem
operator|->
name|hold_count
operator|++
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_unhold
parameter_list|(
name|vm_page_t
name|mem
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
operator|--
name|mem
operator|->
name|hold_count
expr_stmt|;
name|KASSERT
argument_list|(
name|mem
operator|->
name|hold_count
operator|>=
literal|0
argument_list|,
operator|(
literal|"vm_page_unhold: hold count< 0!!!"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|mem
operator|->
name|hold_count
operator|==
literal|0
operator|&&
name|VM_PAGE_INQUEUE2
argument_list|(
name|mem
argument_list|,
name|PQ_HOLD
argument_list|)
condition|)
name|vm_page_free_toq
argument_list|(
name|mem
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_free:  *  *	Free a page  *  *	The clearing of PG_ZERO is a temporary safety until the code can be  *	reviewed to determine that PG_ZERO is being properly cleared on  *	write faults or maps.  PG_ZERO was previously cleared in  *	vm_page_alloc().  */
end_comment

begin_function
name|void
name|vm_page_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_zero:  *  *	Free a page to the zerod-pages queue  */
end_comment

begin_function
name|void
name|vm_page_free_zero
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_ZERO
argument_list|)
expr_stmt|;
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_sleep:  *  *	Sleep and release the page queues lock.  *  *	The object containing the given page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_sleep
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|msg
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|mtx_owned
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|)
condition|)
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_REFERENCED
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
comment|/* 	 * It's possible that while we sleep, the page will get 	 * unbusied and freed.  If we are holding the object 	 * lock, we will assume we hold a reference to the object 	 * such that even if m->object changes, we can re-lock 	 * it. 	 */
name|m
operator|->
name|oflags
operator||=
name|VPO_WANTED
expr_stmt|;
name|msleep
argument_list|(
name|m
argument_list|,
name|VM_OBJECT_MTX
argument_list|(
name|m
operator|->
name|object
argument_list|)
argument_list|,
name|PVM
argument_list|,
name|msg
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_dirty:  *  *	make page all dirty  */
end_comment

begin_function
name|void
name|vm_page_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|VM_PAGE_GETKNOWNQUEUE1
argument_list|(
name|m
argument_list|)
operator|!=
name|PQ_CACHE
argument_list|,
operator|(
literal|"vm_page_dirty: page in cache!"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|VM_PAGE_GETKNOWNQUEUE1
argument_list|(
name|m
argument_list|)
operator|!=
name|PQ_FREE
argument_list|,
operator|(
literal|"vm_page_dirty: page is free!"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|dirty
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_splay:  *  *	Implements Sleator and Tarjan's top-down splay algorithm.  Returns  *	the vm_page containing the given pindex.  If, however, that  *	pindex is not found in the vm_object, returns a vm_page that is  *	adjacent to the pindex, coming before or after it.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_splay
parameter_list|(
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_page_t
name|root
parameter_list|)
block|{
name|struct
name|vm_page
name|dummy
decl_stmt|;
name|vm_page_t
name|lefttreemax
decl_stmt|,
name|righttreemin
decl_stmt|,
name|y
decl_stmt|;
if|if
condition|(
name|root
operator|==
name|NULL
condition|)
return|return
operator|(
name|root
operator|)
return|;
name|lefttreemax
operator|=
name|righttreemin
operator|=
operator|&
name|dummy
expr_stmt|;
for|for
control|(
init|;
condition|;
name|root
operator|=
name|y
control|)
block|{
if|if
condition|(
name|pindex
operator|<
name|root
operator|->
name|pindex
condition|)
block|{
if|if
condition|(
operator|(
name|y
operator|=
name|root
operator|->
name|left
operator|)
operator|==
name|NULL
condition|)
break|break;
if|if
condition|(
name|pindex
operator|<
name|y
operator|->
name|pindex
condition|)
block|{
comment|/* Rotate right. */
name|root
operator|->
name|left
operator|=
name|y
operator|->
name|right
expr_stmt|;
name|y
operator|->
name|right
operator|=
name|root
expr_stmt|;
name|root
operator|=
name|y
expr_stmt|;
if|if
condition|(
operator|(
name|y
operator|=
name|root
operator|->
name|left
operator|)
operator|==
name|NULL
condition|)
break|break;
block|}
comment|/* Link into the new root's right tree. */
name|righttreemin
operator|->
name|left
operator|=
name|root
expr_stmt|;
name|righttreemin
operator|=
name|root
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pindex
operator|>
name|root
operator|->
name|pindex
condition|)
block|{
if|if
condition|(
operator|(
name|y
operator|=
name|root
operator|->
name|right
operator|)
operator|==
name|NULL
condition|)
break|break;
if|if
condition|(
name|pindex
operator|>
name|y
operator|->
name|pindex
condition|)
block|{
comment|/* Rotate left. */
name|root
operator|->
name|right
operator|=
name|y
operator|->
name|left
expr_stmt|;
name|y
operator|->
name|left
operator|=
name|root
expr_stmt|;
name|root
operator|=
name|y
expr_stmt|;
if|if
condition|(
operator|(
name|y
operator|=
name|root
operator|->
name|right
operator|)
operator|==
name|NULL
condition|)
break|break;
block|}
comment|/* Link into the new root's left tree. */
name|lefttreemax
operator|->
name|right
operator|=
name|root
expr_stmt|;
name|lefttreemax
operator|=
name|root
expr_stmt|;
block|}
else|else
break|break;
block|}
comment|/* Assemble the new root. */
name|lefttreemax
operator|->
name|right
operator|=
name|root
operator|->
name|left
expr_stmt|;
name|righttreemin
operator|->
name|left
operator|=
name|root
operator|->
name|right
expr_stmt|;
name|root
operator|->
name|left
operator|=
name|dummy
operator|.
name|right
expr_stmt|;
name|root
operator|->
name|right
operator|=
name|dummy
operator|.
name|left
expr_stmt|;
return|return
operator|(
name|root
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_insert:		[ internal use only ]  *  *	Inserts the given mem entry into the object and object list.  *  *	The pagetables are not updated but will presumably fault the page  *	in if necessary, or if a kernel page the caller will at some point  *	enter the page into the kernel's pmap.  We are not allowed to block  *	here so we *can't* do this anyway.  *  *	The object and page must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_insert
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|root
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|NULL
condition|)
name|panic
argument_list|(
literal|"vm_page_insert: page already inserted"
argument_list|)
expr_stmt|;
comment|/* 	 * Record the object/offset pair in this page 	 */
name|m
operator|->
name|object
operator|=
name|object
expr_stmt|;
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
comment|/* 	 * Now link into the object's ordered list of backed pages. 	 */
name|root
operator|=
name|object
operator|->
name|root
expr_stmt|;
if|if
condition|(
name|root
operator|==
name|NULL
condition|)
block|{
name|m
operator|->
name|left
operator|=
name|NULL
expr_stmt|;
name|m
operator|->
name|right
operator|=
name|NULL
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|root
operator|=
name|vm_page_splay
argument_list|(
name|pindex
argument_list|,
name|root
argument_list|)
expr_stmt|;
if|if
condition|(
name|pindex
operator|<
name|root
operator|->
name|pindex
condition|)
block|{
name|m
operator|->
name|left
operator|=
name|root
operator|->
name|left
expr_stmt|;
name|m
operator|->
name|right
operator|=
name|root
expr_stmt|;
name|root
operator|->
name|left
operator|=
name|NULL
expr_stmt|;
name|TAILQ_INSERT_BEFORE
argument_list|(
name|root
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pindex
operator|==
name|root
operator|->
name|pindex
condition|)
name|panic
argument_list|(
literal|"vm_page_insert: offset already allocated"
argument_list|)
expr_stmt|;
else|else
block|{
name|m
operator|->
name|right
operator|=
name|root
operator|->
name|right
expr_stmt|;
name|m
operator|->
name|left
operator|=
name|root
expr_stmt|;
name|root
operator|->
name|right
operator|=
name|NULL
expr_stmt|;
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|root
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
block|}
name|object
operator|->
name|root
operator|=
name|m
expr_stmt|;
name|object
operator|->
name|generation
operator|++
expr_stmt|;
comment|/* 	 * show that the object has one more resident page. 	 */
name|object
operator|->
name|resident_page_count
operator|++
expr_stmt|;
comment|/* 	 * Hold the vnode until the last page is released. 	 */
if|if
condition|(
name|object
operator|->
name|resident_page_count
operator|==
literal|1
operator|&&
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
name|vhold
argument_list|(
operator|(
expr|struct
name|vnode
operator|*
operator|)
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
comment|/* 	 * Since we are inserting a new and possibly dirty page, 	 * update the object's OBJ_MIGHTBEDIRTY flag. 	 */
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_WRITEABLE
condition|)
name|vm_object_set_writeable_dirty
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_remove:  *				NOTE: used by device pager as well -wfj  *  *	Removes the given mem entry from the object/offset-page  *	table and the object page list, but do not invalidate/terminate  *	the backing store.  *  *	The object and page must be locked.  *	The underlying pmap entry (if any) is NOT removed here.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_remove
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|vm_page_t
name|root
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|object
operator|=
name|m
operator|->
name|object
operator|)
operator|==
name|NULL
condition|)
return|return;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
condition|)
block|{
name|m
operator|->
name|oflags
operator|&=
operator|~
name|VPO_BUSY
expr_stmt|;
name|vm_page_flash
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Now remove from the object's list of backed pages. 	 */
if|if
condition|(
name|m
operator|!=
name|object
operator|->
name|root
condition|)
name|vm_page_splay
argument_list|(
name|m
operator|->
name|pindex
argument_list|,
name|object
operator|->
name|root
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|left
operator|==
name|NULL
condition|)
name|root
operator|=
name|m
operator|->
name|right
expr_stmt|;
else|else
block|{
name|root
operator|=
name|vm_page_splay
argument_list|(
name|m
operator|->
name|pindex
argument_list|,
name|m
operator|->
name|left
argument_list|)
expr_stmt|;
name|root
operator|->
name|right
operator|=
name|m
operator|->
name|right
expr_stmt|;
block|}
name|object
operator|->
name|root
operator|=
name|root
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
comment|/* 	 * And show that the object has one fewer resident page. 	 */
name|object
operator|->
name|resident_page_count
operator|--
expr_stmt|;
name|object
operator|->
name|generation
operator|++
expr_stmt|;
comment|/* 	 * The vnode may now be recycled. 	 */
if|if
condition|(
name|object
operator|->
name|resident_page_count
operator|==
literal|0
operator|&&
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
name|vdrop
argument_list|(
operator|(
expr|struct
name|vnode
operator|*
operator|)
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_lookup:  *  *	Returns the page associated with the object/offset  *	pair specified; if none is found, NULL is returned.  *  *	The object must be locked.  *	This routine may not block.  *	This is a critical path routine  */
end_comment

begin_function
name|vm_page_t
name|vm_page_lookup
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|object
operator|->
name|root
operator|)
operator|!=
name|NULL
operator|&&
name|m
operator|->
name|pindex
operator|!=
name|pindex
condition|)
block|{
name|m
operator|=
name|vm_page_splay
argument_list|(
name|pindex
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|object
operator|->
name|root
operator|=
name|m
operator|)
operator|->
name|pindex
operator|!=
name|pindex
condition|)
name|m
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_rename:  *  *	Move the given memory entry from its  *	current object to the specified target object/offset.  *  *	The object must be locked.  *	This routine may not block.  *  *	Note: swap associated with the page must be invalidated by the move.  We  *	      have to do this for several reasons:  (1) we aren't freeing the  *	      page, (2) we are dirtying the page, (3) the VM system is probably  *	      moving the page from object A to B, and will then later move  *	      the backing store from A to B and we can't have a conflict.  *  *	Note: we *always* dirty the page.  It is necessary both for the  *	      fact that we moved it, and because we may be invalidating  *	      swap.  If the page is on the cache, we have to deactivate it  *	      or vm_page_dirty() will panic.  Dirty pages are not allowed  *	      on the cache.  */
end_comment

begin_function
name|void
name|vm_page_rename
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|new_object
parameter_list|,
name|vm_pindex_t
name|new_pindex
parameter_list|)
block|{
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|new_object
argument_list|,
name|new_pindex
argument_list|)
expr_stmt|;
if|if
condition|(
name|VM_PAGE_INQUEUE1
argument_list|(
name|m
argument_list|,
name|PQ_CACHE
argument_list|)
condition|)
name|vm_page_deactivate
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_select_cache:  *  *	Move a page of the given color from the cache queue to the free  *	queue.  As pages might be found, but are not applicable, they are  *	deactivated.  *  *	This routine may not block.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_select_cache
parameter_list|(
name|int
name|color
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|boolean_t
name|was_trylocked
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|m
operator|=
name|vm_pageq_find
argument_list|(
name|PQ_CACHE
argument_list|,
name|color
argument_list|,
name|FALSE
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"Found dirty cache page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"Found mapped cache page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"Found unmanaged cache page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|0
argument_list|,
operator|(
literal|"Found wired cache page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|hold_count
operator|==
literal|0
operator|&&
operator|(
name|object
operator|=
name|m
operator|->
name|object
operator|,
operator|(
name|was_trylocked
operator|=
name|VM_OBJECT_TRYLOCK
argument_list|(
name|object
argument_list|)
operator|)
operator|||
name|VM_OBJECT_LOCKED
argument_list|(
name|object
argument_list|)
operator|)
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
operator|&&
name|m
operator|->
name|busy
operator|==
literal|0
argument_list|,
operator|(
literal|"Found busy cache page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|was_trylocked
condition|)
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
break|break;
block|}
name|vm_page_deactivate
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_alloc:  *  *	Allocate and return a memory cell associated  *	with this VM object/offset pair.  *  *	page_req classes:  *	VM_ALLOC_NORMAL		normal process request  *	VM_ALLOC_SYSTEM		system *really* needs a page  *	VM_ALLOC_INTERRUPT	interrupt time request  *	VM_ALLOC_ZERO		zero page  *  *	This routine may not block.  *  *	Additional special handling is required when called from an  *	interrupt (VM_ALLOC_INTERRUPT).  We are not allowed to mess with  *	the page cache in this case.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_alloc
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|req
parameter_list|)
block|{
name|vm_page_t
name|m
init|=
name|NULL
decl_stmt|;
name|int
name|color
decl_stmt|,
name|flags
decl_stmt|,
name|page_req
decl_stmt|;
name|page_req
operator|=
name|req
operator|&
name|VM_ALLOC_CLASS_MASK
expr_stmt|;
name|KASSERT
argument_list|(
name|curthread
operator|->
name|td_intr_nesting_level
operator|==
literal|0
operator|||
name|page_req
operator|==
name|VM_ALLOC_INTERRUPT
argument_list|,
operator|(
literal|"vm_page_alloc(NORMAL|SYSTEM) in interrupt context"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_NOOBJ
operator|)
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|object
operator|!=
name|NULL
argument_list|,
operator|(
literal|"vm_page_alloc: NULL object."
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|color
operator|=
operator|(
name|pindex
operator|+
name|object
operator|->
name|pg_color
operator|)
operator|&
name|PQ_COLORMASK
expr_stmt|;
block|}
else|else
name|color
operator|=
name|pindex
operator|&
name|PQ_COLORMASK
expr_stmt|;
comment|/* 	 * The pager is allowed to eat deeper into the free page list. 	 */
if|if
condition|(
operator|(
name|curproc
operator|==
name|pageproc
operator|)
operator|&&
operator|(
name|page_req
operator|!=
name|VM_ALLOC_INTERRUPT
operator|)
condition|)
block|{
name|page_req
operator|=
name|VM_ALLOC_SYSTEM
expr_stmt|;
block|}
empty_stmt|;
name|loop
label|:
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|cnt
operator|.
name|v_free_count
operator|>
name|cnt
operator|.
name|v_free_reserved
operator|||
operator|(
name|page_req
operator|==
name|VM_ALLOC_SYSTEM
operator|&&
name|cnt
operator|.
name|v_cache_count
operator|==
literal|0
operator|&&
name|cnt
operator|.
name|v_free_count
operator|>
name|cnt
operator|.
name|v_interrupt_free_min
operator|)
operator|||
operator|(
name|page_req
operator|==
name|VM_ALLOC_INTERRUPT
operator|&&
name|cnt
operator|.
name|v_free_count
operator|>
literal|0
operator|)
condition|)
block|{
comment|/* 		 * Allocate from the free queue if the number of free pages 		 * exceeds the minimum for the request class. 		 */
name|m
operator|=
name|vm_pageq_find
argument_list|(
name|PQ_FREE
argument_list|,
name|color
argument_list|,
operator|(
name|req
operator|&
name|VM_ALLOC_ZERO
operator|)
operator|!=
literal|0
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|page_req
operator|!=
name|VM_ALLOC_INTERRUPT
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
comment|/* 		 * Allocatable from cache (non-interrupt only).  On success, 		 * we must free the page and try again, thus ensuring that 		 * cnt.v_*_free_min counters are replenished. 		 */
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_select_cache
argument_list|(
name|color
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
name|cnt
operator|.
name|v_cache_count
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: cache queue is missing %d pages"
operator|,
name|cnt
operator|.
name|v_cache_count
operator|)
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
if|if
condition|(
name|page_req
operator|!=
name|VM_ALLOC_SYSTEM
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|cnt
operator|.
name|v_free_count
operator|<=
name|cnt
operator|.
name|v_interrupt_free_min
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|m
operator|=
name|vm_pageq_find
argument_list|(
name|PQ_FREE
argument_list|,
name|color
argument_list|,
operator|(
name|req
operator|&
name|VM_ALLOC_ZERO
operator|)
operator|!=
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
goto|goto
name|loop
goto|;
block|}
block|}
else|else
block|{
comment|/* 		 * Not allocatable from cache from interrupt, give up. 		 */
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
comment|/* 	 *  At this point we had better have found a good page. 	 */
name|KASSERT
argument_list|(
name|m
operator|!=
name|NULL
argument_list|,
operator|(
literal|"vm_page_alloc(): missing page on free queue"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Remove from free queue 	 */
name|vm_pageq_remove_nowakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize structure.  Only the PG_ZERO flag is inherited. 	 */
name|flags
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
condition|)
block|{
name|vm_page_zero_count
operator|--
expr_stmt|;
if|if
condition|(
name|req
operator|&
name|VM_ALLOC_ZERO
condition|)
name|flags
operator|=
name|PG_ZERO
expr_stmt|;
block|}
name|m
operator|->
name|flags
operator|=
name|flags
expr_stmt|;
if|if
condition|(
name|req
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_NOOBJ
operator|)
condition|)
name|m
operator|->
name|oflags
operator|=
literal|0
expr_stmt|;
else|else
name|m
operator|->
name|oflags
operator|=
name|VPO_BUSY
expr_stmt|;
if|if
condition|(
name|req
operator|&
name|VM_ALLOC_WIRED
condition|)
block|{
name|atomic_add_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
block|}
else|else
name|m
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|hold_count
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|act_count
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|busy
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: free/cache page %p was dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_NOOBJ
operator|)
operator|==
literal|0
condition|)
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
else|else
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
comment|/* 	 * Don't wakeup too often - wakeup the pageout daemon when 	 * we would be nearly out of memory. 	 */
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_wait:	(also see VM_WAIT macro)  *  *	Block until free pages are available for allocation  *	- Called in various places before memory allocations.  */
end_comment

begin_function
name|void
name|vm_wait
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|curproc
operator|==
name|pageproc
condition|)
block|{
name|vm_pageout_pages_needed
operator|=
literal|1
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PSWP
argument_list|,
literal|"VMWait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|vm_pages_needed
condition|)
block|{
name|vm_pages_needed
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pages_needed
argument_list|)
expr_stmt|;
block|}
name|msleep
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PVM
argument_list|,
literal|"vmwait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_waitpfault:	(also see VM_WAITPFAULT macro)  *  *	Block until free pages are available for allocation  *	- Called only in vm_fault so that processes page faulting  *	  can be easily tracked.  *	- Sleeps at a lower priority than vm_wait() so that vm_wait()ing  *	  processes will be able to grab memory first.  Do not change  *	  this balance without careful testing first.  */
end_comment

begin_function
name|void
name|vm_waitpfault
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_pages_needed
condition|)
block|{
name|vm_pages_needed
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pages_needed
argument_list|)
expr_stmt|;
block|}
name|msleep
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PUSER
argument_list|,
literal|"pfault"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_activate:  *  *	Put the specified page on the active list (if appropriate).  *	Ensure that act_count is at least ACT_INIT but do not otherwise  *	mess with it.  *  *	The page queues must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_activate
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|VM_PAGE_GETKNOWNQUEUE2
argument_list|(
name|m
argument_list|)
operator|!=
name|PQ_ACTIVE
condition|)
block|{
if|if
condition|(
name|VM_PAGE_INQUEUE1
argument_list|(
name|m
argument_list|,
name|PQ_CACHE
argument_list|)
condition|)
name|cnt
operator|.
name|v_reactivated
operator|++
expr_stmt|;
name|vm_pageq_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|<
name|ACT_INIT
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_INIT
expr_stmt|;
name|vm_pageq_enqueue
argument_list|(
name|PQ_ACTIVE
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|<
name|ACT_INIT
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_INIT
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_wakeup:  *  *	Helper routine for vm_page_free_toq() and vm_page_cache().  This  *	routine is called when a page has been added to the cache or free  *	queues.  *  *	The page queues must be locked.  *	This routine may not block.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|vm_page_free_wakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * if pageout daemon needs pages, then tell it that there are 	 * some free. 	 */
if|if
condition|(
name|vm_pageout_pages_needed
operator|&&
name|cnt
operator|.
name|v_cache_count
operator|+
name|cnt
operator|.
name|v_free_count
operator|>=
name|cnt
operator|.
name|v_pageout_free_min
condition|)
block|{
name|wakeup
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|)
expr_stmt|;
name|vm_pageout_pages_needed
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * wakeup processes that are waiting on memory if we hit a 	 * high water mark. And wakeup scheduler process if we have 	 * lots of memory. this process will swapin processes. 	 */
if|if
condition|(
name|vm_pages_needed
operator|&&
operator|!
name|vm_page_count_min
argument_list|()
condition|)
block|{
name|vm_pages_needed
operator|=
literal|0
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_toq:  *  *	Returns the given page to the PQ_FREE list,  *	disassociating it with any VM object.  *  *	Object and page must be locked prior to entry.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_free_toq
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vpgqueues
modifier|*
name|pq
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_free_toq: freeing mapped page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|cnt
operator|.
name|v_tfree
operator|++
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|busy
operator|||
name|VM_PAGE_INQUEUE1
argument_list|(
name|m
argument_list|,
name|PQ_FREE
argument_list|)
condition|)
block|{
name|printf
argument_list|(
literal|"vm_page_free: pindex(%lu), busy(%d), VPO_BUSY(%d), hold(%d)\n"
argument_list|,
operator|(
name|u_long
operator|)
name|m
operator|->
name|pindex
argument_list|,
name|m
operator|->
name|busy
argument_list|,
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
condition|?
literal|1
else|:
literal|0
argument_list|,
name|m
operator|->
name|hold_count
argument_list|)
expr_stmt|;
if|if
condition|(
name|VM_PAGE_INQUEUE1
argument_list|(
name|m
argument_list|,
name|PQ_FREE
argument_list|)
condition|)
name|panic
argument_list|(
literal|"vm_page_free: freeing free page"
argument_list|)
expr_stmt|;
else|else
name|panic
argument_list|(
literal|"vm_page_free: freeing busy page"
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * unqueue, then remove page.  Note that we cannot destroy 	 * the page here because we do not want to call the pager's 	 * callback routine until after we've put the page on the 	 * appropriate free queue. 	 */
name|vm_pageq_remove_nowakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * If fictitious remove object association and 	 * return, otherwise delay object association removal. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
return|return;
block|}
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|vm_page_undirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|wire_count
operator|>
literal|1
condition|)
block|{
name|panic
argument_list|(
literal|"vm_page_free: invalid wire count (%d), pindex: 0x%lx"
argument_list|,
name|m
operator|->
name|wire_count
argument_list|,
operator|(
name|long
operator|)
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
block|}
name|panic
argument_list|(
literal|"vm_page_free: freeing wired page"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|vm_pageq_enqueue
argument_list|(
name|PQ_HOLD
argument_list|,
name|m
argument_list|)
expr_stmt|;
return|return;
block|}
name|VM_PAGE_SETQUEUE1
argument_list|(
name|m
argument_list|,
name|PQ_FREE
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|pq
operator|=
operator|&
name|vm_page_queues
index|[
name|VM_PAGE_GETQUEUE
argument_list|(
name|m
argument_list|)
index|]
expr_stmt|;
name|pq
operator|->
name|lcnt
operator|++
expr_stmt|;
operator|++
operator|(
operator|*
name|pq
operator|->
name|cnt
operator|)
expr_stmt|;
comment|/* 	 * Put zero'd pages on the end ( where we look for zero'd pages 	 * first ) and non-zerod pages at the head. 	 */
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
condition|)
block|{
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pq
operator|->
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
operator|++
name|vm_page_zero_count
expr_stmt|;
block|}
else|else
block|{
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pq
operator|->
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|vm_page_zero_idle_wakeup
argument_list|()
expr_stmt|;
block|}
name|vm_page_free_wakeup
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_unmanage:  *  * 	Prevent PV management from being done on the page.  The page is  *	removed from the paging queues as if it were wired, and as a   *	consequence of no longer being managed the pageout daemon will not  *	touch it (since there is no way to locate the pte mappings for the  *	page).  madvise() calls that mess with the pmap will also no longer  *	operate on the page.  *  *	Beyond that the page is still reasonably 'normal'.  Freeing the page  *	will clear the flag.  *  *	This routine is used by OBJT_PHYS objects - objects using unswappable  *	physical memory as backing store rather then swap-backed memory and  *	will eventually be extended to support 4MB unmanaged physical   *	mappings.  */
end_comment

begin_function
name|void
name|vm_page_unmanage
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
name|vm_pageq_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_UNMANAGED
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_wire:  *  *	Mark this page as wired down by yet  *	another map, removing it from paging queues  *	as necessary.  *  *	The page queues must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_wire
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
comment|/* 	 * Only bump the wire statistics if the page is not already wired, 	 * and only unqueue the page if it is on some queue (if it is unmanaged 	 * it is already off the queues). 	 */
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
condition|)
return|return;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_pageq_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
name|m
operator|->
name|wire_count
operator|++
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_wire: wire_count overflow m=%p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_unwire:  *  *	Release one wiring of this page, potentially  *	enabling it to be paged again.  *  *	Many pages placed on the inactive queue should actually go  *	into the cache, but it is difficult to figure out which.  What  *	we do instead, if the inactive target is well met, is to put  *	clean pages at the head of the inactive queue instead of the tail.  *	This will cause them to be moved to the cache more quickly and  *	if not actively re-referenced, freed more quickly.  If we just  *	stick these pages at the end of the inactive queue, heavy filesystem  *	meta-data accesses can cause an unnecessary paging load on memory bound   *	processes.  This optimization causes one-time-use metadata to be  *	reused more quickly.  *  *	BUT, if we are in a low-memory situation we have no choice but to  *	put clean pages on the cache queue.  *  *	A number of routines use vm_page_unwire() to guarantee that the page  *	will go into either the inactive or active queues, and will NEVER  *	be placed in the cache - for example, just after dirtying a page.  *	dirty pages in the cache are not allowed.  *  *	The page queues must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_unwire
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|activate
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
condition|)
return|return;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|>
literal|0
condition|)
block|{
name|m
operator|->
name|wire_count
operator|--
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|atomic_subtract_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
condition|)
block|{
empty_stmt|;
block|}
elseif|else
if|if
condition|(
name|activate
condition|)
name|vm_pageq_enqueue
argument_list|(
name|PQ_ACTIVE
argument_list|,
name|m
argument_list|)
expr_stmt|;
else|else
block|{
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WINATCFLS
argument_list|)
expr_stmt|;
name|vm_pageq_enqueue
argument_list|(
name|PQ_INACTIVE
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|panic
argument_list|(
literal|"vm_page_unwire: invalid wire count: %d"
argument_list|,
name|m
operator|->
name|wire_count
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Move the specified page to the inactive queue.  If the page has  * any associated swap, the swap is deallocated.  *  * Normally athead is 0 resulting in LRU operation.  athead is set  * to 1 if we want this page to be 'as if it were placed in the cache',  * except without unmapping it from the process address space.  *  * This routine may not block.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|_vm_page_deactivate
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|athead
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Ignore if already inactive. 	 */
if|if
condition|(
name|VM_PAGE_INQUEUE2
argument_list|(
name|m
argument_list|,
name|PQ_INACTIVE
argument_list|)
condition|)
return|return;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|VM_PAGE_INQUEUE1
argument_list|(
name|m
argument_list|,
name|PQ_CACHE
argument_list|)
condition|)
name|cnt
operator|.
name|v_reactivated
operator|++
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WINATCFLS
argument_list|)
expr_stmt|;
name|vm_pageq_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|athead
condition|)
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|VM_PAGE_SETQUEUE2
argument_list|(
name|m
argument_list|,
name|PQ_INACTIVE
argument_list|)
expr_stmt|;
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|lcnt
operator|++
expr_stmt|;
name|cnt
operator|.
name|v_inactive_count
operator|++
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|vm_page_deactivate
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|_vm_page_deactivate
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_try_to_cache:  *  * Returns 0 on failure, 1 on success  */
end_comment

begin_function
name|int
name|vm_page_try_to_cache
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|busy
operator|||
name|m
operator|->
name|wire_count
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
condition|)
block|{
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|vm_page_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_page_try_to_free()  *  *	Attempt to free the page.  If we cannot free it, we do nothing.  *	1 is returned on success, 0 on failure.  */
end_comment

begin_function
name|int
name|vm_page_try_to_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|NULL
condition|)
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|busy
operator|||
name|m
operator|->
name|wire_count
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
condition|)
block|{
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_page_cache  *  * Put the specified page onto the page cache queue (if appropriate).  *  * This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_cache
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|||
name|m
operator|->
name|busy
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|wire_count
condition|)
block|{
name|printf
argument_list|(
literal|"vm_page_cache: attempting to cache busy page\n"
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|VM_PAGE_INQUEUE1
argument_list|(
name|m
argument_list|,
name|PQ_CACHE
argument_list|)
condition|)
return|return;
comment|/* 	 * Remove all pmaps and indicate that the page is not 	 * writeable or mapped. 	 */
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|!=
literal|0
condition|)
block|{
name|panic
argument_list|(
literal|"vm_page_cache: caching a dirty page, pindex: %ld"
argument_list|,
operator|(
name|long
operator|)
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
block|}
name|vm_pageq_remove_nowakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pageq_enqueue
argument_list|(
name|PQ_CACHE
operator|+
name|m
operator|->
name|pc
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|vm_page_free_wakeup
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_dontneed  *  *	Cache, deactivate, or do nothing as appropriate.  This routine  *	is typically used by madvise() MADV_DONTNEED.  *  *	Generally speaking we want to move the page into the cache so  *	it gets reused quickly.  However, this can result in a silly syndrome  *	due to the page recycling too quickly.  Small objects will not be  *	fully cached.  On the otherhand, if we move the page to the inactive  *	queue we wind up with a problem whereby very large objects   *	unnecessarily blow away our inactive and cache queues.  *  *	The solution is to move the pages based on a fixed weighting.  We  *	either leave them alone, deactivate them, or move them to the cache,  *	where moving them to the cache has the highest weighting.  *	By forcing some pages into other queues we eventually force the  *	system to balance the queues, potentially recovering other unrelated  *	space from active.  The idea is to not force this to happen too  *	often.  */
end_comment

begin_function
name|void
name|vm_page_dontneed
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
specifier|static
name|int
name|dnweight
decl_stmt|;
name|int
name|dnw
decl_stmt|;
name|int
name|head
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|dnw
operator|=
operator|++
name|dnweight
expr_stmt|;
comment|/* 	 * occassionally leave the page alone 	 */
if|if
condition|(
operator|(
name|dnw
operator|&
literal|0x01F0
operator|)
operator|==
literal|0
operator|||
name|VM_PAGE_INQUEUE2
argument_list|(
name|m
argument_list|,
name|PQ_INACTIVE
argument_list|)
operator|||
name|VM_PAGE_INQUEUE1
argument_list|(
name|m
argument_list|,
name|PQ_CACHE
argument_list|)
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|>=
name|ACT_INIT
condition|)
operator|--
name|m
operator|->
name|act_count
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|m
operator|->
name|dirty
operator|==
literal|0
operator|&&
name|pmap_is_modified
argument_list|(
name|m
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
operator|(
name|dnw
operator|&
literal|0x0070
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 		 * Deactivate the page 3 times out of 32. 		 */
name|head
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Cache the page 28 times out of every 32.  Note that 		 * the page is deactivated instead of cached, but placed 		 * at the head of the queue instead of the tail. 		 */
name|head
operator|=
literal|1
expr_stmt|;
block|}
name|_vm_page_deactivate
argument_list|(
name|m
argument_list|,
name|head
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Grab a page, waiting until we are waken up due to the page  * changing state.  We keep on waiting, if the page continues  * to be in the object.  If the page doesn't exist, first allocate it  * and then conditionally zero it.  *  * This routine may block.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_grab
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|allocflags
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|retrylookup
label|:
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|vm_page_sleep_if_busy
argument_list|(
name|m
argument_list|,
name|TRUE
argument_list|,
literal|"pgrbwt"
argument_list|)
condition|)
block|{
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_RETRY
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
goto|goto
name|retrylookup
goto|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
block|{
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_wire
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_NOBUSY
operator|)
operator|==
literal|0
condition|)
name|vm_page_busy
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
block|}
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|allocflags
operator|&
operator|~
name|VM_ALLOC_RETRY
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|VM_OBJECT_LOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_RETRY
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
goto|goto
name|retrylookup
goto|;
block|}
if|if
condition|(
name|allocflags
operator|&
name|VM_ALLOC_ZERO
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Mapping function for valid bits or for dirty bits in  * a page.  May not block.  *  * Inputs are required to range within a page.  */
end_comment

begin_function
specifier|inline
name|int
name|vm_page_bits
parameter_list|(
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|first_bit
decl_stmt|;
name|int
name|last_bit
decl_stmt|;
name|KASSERT
argument_list|(
name|base
operator|+
name|size
operator|<=
name|PAGE_SIZE
argument_list|,
operator|(
literal|"vm_page_bits: illegal base/size %d/%d"
operator|,
name|base
operator|,
name|size
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return
operator|(
literal|0
operator|)
return|;
name|first_bit
operator|=
name|base
operator|>>
name|DEV_BSHIFT
expr_stmt|;
name|last_bit
operator|=
operator|(
name|base
operator|+
name|size
operator|-
literal|1
operator|)
operator|>>
name|DEV_BSHIFT
expr_stmt|;
return|return
operator|(
operator|(
literal|2
operator|<<
name|last_bit
operator|)
operator|-
operator|(
literal|1
operator|<<
name|first_bit
operator|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_set_validclean:  *  *	Sets portions of a page valid and clean.  The arguments are expected  *	to be DEV_BSIZE aligned but if they aren't the bitmap is inclusive  *	of any partial chunks touched by the range.  The invalid portion of  *	such chunks will be zero'd.  *  *	This routine may not block.  *  *	(base + size) must be less then or equal to PAGE_SIZE.  */
end_comment

begin_function
name|void
name|vm_page_set_validclean
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|pagebits
decl_stmt|;
name|int
name|frag
decl_stmt|;
name|int
name|endoff
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return;
comment|/* 	 * If the base is not DEV_BSIZE aligned and the valid 	 * bit is clear, we have to zero out a portion of the 	 * first block. 	 */
if|if
condition|(
operator|(
name|frag
operator|=
name|base
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|base
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|base
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|frag
argument_list|,
name|base
operator|-
name|frag
argument_list|)
expr_stmt|;
comment|/* 	 * If the ending offset is not DEV_BSIZE aligned and the  	 * valid bit is clear, we have to zero out a portion of 	 * the last block. 	 */
name|endoff
operator|=
name|base
operator|+
name|size
expr_stmt|;
if|if
condition|(
operator|(
name|frag
operator|=
name|endoff
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|endoff
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|endoff
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|endoff
argument_list|,
name|DEV_BSIZE
operator|-
operator|(
name|endoff
operator|&
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Set valid, clear dirty bits.  If validating the entire 	 * page we can safely clear the pmap modify bit.  We also 	 * use this opportunity to clear the VPO_NOSYNC flag.  If a process 	 * takes a write fault on a MAP_NOSYNC memory area the flag will 	 * be set again. 	 * 	 * We set valid bits inclusive of any overlap, but we can only 	 * clear dirty bits for DEV_BSIZE chunks that are fully within 	 * the range. 	 */
name|pagebits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator||=
name|pagebits
expr_stmt|;
if|#
directive|if
literal|0
comment|/* NOT YET */
block|if ((frag = base& (DEV_BSIZE - 1)) != 0) { 		frag = DEV_BSIZE - frag; 		base += frag; 		size -= frag; 		if (size< 0) 			size = 0; 	} 	pagebits = vm_page_bits(base, size& (DEV_BSIZE - 1));
endif|#
directive|endif
name|m
operator|->
name|dirty
operator|&=
operator|~
name|pagebits
expr_stmt|;
if|if
condition|(
name|base
operator|==
literal|0
operator|&&
name|size
operator|==
name|PAGE_SIZE
condition|)
block|{
name|pmap_clear_modify
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|oflags
operator|&=
operator|~
name|VPO_NOSYNC
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|vm_page_clear_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|->
name|dirty
operator|&=
operator|~
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_set_invalid:  *  *	Invalidates DEV_BSIZE'd chunks within a page.  Both the  *	valid and dirty bits for the effected areas are cleared.  *  *	May not block.  */
end_comment

begin_function
name|void
name|vm_page_set_invalid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|bits
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|bits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|&&
name|bits
operator|!=
literal|0
condition|)
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator|&=
operator|~
name|bits
expr_stmt|;
name|m
operator|->
name|dirty
operator|&=
operator|~
name|bits
expr_stmt|;
name|m
operator|->
name|object
operator|->
name|generation
operator|++
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_zero_invalid()  *  *	The kernel assumes that the invalid portions of a page contain   *	garbage, but such pages can be mapped into memory by user code.  *	When this occurs, we must zero out the non-valid portions of the  *	page so user code sees what it expects.  *  *	Pages are most often semi-valid when the end of a file is mapped   *	into memory and the file's size is not page aligned.  */
end_comment

begin_function
name|void
name|vm_page_zero_invalid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|boolean_t
name|setvalid
parameter_list|)
block|{
name|int
name|b
decl_stmt|;
name|int
name|i
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Scan the valid bits looking for invalid sections that 	 * must be zerod.  Invalid sub-DEV_BSIZE'd areas ( where the 	 * valid bit may be set ) have already been zerod by 	 * vm_page_set_validclean(). 	 */
for|for
control|(
name|b
operator|=
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|PAGE_SIZE
operator|/
name|DEV_BSIZE
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|i
operator|==
operator|(
name|PAGE_SIZE
operator|/
name|DEV_BSIZE
operator|)
operator|||
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
name|i
operator|)
operator|)
condition|)
block|{
if|if
condition|(
name|i
operator|>
name|b
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|b
operator|<<
name|DEV_BSHIFT
argument_list|,
operator|(
name|i
operator|-
name|b
operator|)
operator|<<
name|DEV_BSHIFT
argument_list|)
expr_stmt|;
block|}
name|b
operator|=
name|i
operator|+
literal|1
expr_stmt|;
block|}
block|}
comment|/* 	 * setvalid is TRUE when we can safely set the zero'd areas 	 * as being valid.  We can do this if there are no cache consistancy 	 * issues.  e.g. it is ok to do with UFS, but not ok to do with NFS. 	 */
if|if
condition|(
name|setvalid
condition|)
name|m
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_is_valid:  *  *	Is (partial) page valid?  Note that the case where size == 0  *	will return FALSE in the degenerate case where the page is  *	entirely invalid, and TRUE otherwise.  *  *	May not block.  */
end_comment

begin_function
name|int
name|vm_page_is_valid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|bits
init|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|&&
operator|(
operator|(
name|m
operator|->
name|valid
operator|&
name|bits
operator|)
operator|==
name|bits
operator|)
condition|)
return|return
literal|1
return|;
else|else
return|return
literal|0
return|;
block|}
end_function

begin_comment
comment|/*  * update dirty bits from pmap/mmu.  May not block.  */
end_comment

begin_function
name|void
name|vm_page_test_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|dirty
operator|!=
name|VM_PAGE_BITS_ALL
operator|)
operator|&&
name|pmap_is_modified
argument_list|(
name|m
argument_list|)
condition|)
block|{
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_decl_stmt
name|int
name|so_zerocp_fullpage
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|vm_page_cowfault
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_t
name|mnew
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|vm_pindex_t
name|pindex
decl_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|pindex
operator|=
name|m
operator|->
name|pindex
expr_stmt|;
name|retry_alloc
label|:
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|mnew
operator|=
name|vm_page_alloc
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOBUSY
argument_list|)
expr_stmt|;
if|if
condition|(
name|mnew
operator|==
name|NULL
condition|)
block|{
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|VM_OBJECT_LOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
goto|goto
name|retry_alloc
goto|;
block|}
if|if
condition|(
name|m
operator|->
name|cow
operator|==
literal|0
condition|)
block|{
comment|/*  		 * check to see if we raced with an xmit complete when  		 * waiting to allocate a page.  If so, put things back  		 * the way they were  		 */
name|vm_page_free
argument_list|(
name|mnew
argument_list|)
expr_stmt|;
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* clear COW& copy page */
if|if
condition|(
operator|!
name|so_zerocp_fullpage
condition|)
name|pmap_copy_page
argument_list|(
name|m
argument_list|,
name|mnew
argument_list|)
expr_stmt|;
name|mnew
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|mnew
argument_list|)
expr_stmt|;
name|mnew
operator|->
name|wire_count
operator|=
name|m
operator|->
name|wire_count
operator|-
name|m
operator|->
name|cow
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
name|m
operator|->
name|cow
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|vm_page_cowclear
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|cow
condition|)
block|{
name|m
operator|->
name|cow
operator|--
expr_stmt|;
comment|/*  		 * let vm_fault add back write permission  lazily 		 */
block|}
comment|/* 	 *  sf_buf_free() will free the page, so we needn't do it here 	 */
block|}
end_function

begin_function
name|void
name|vm_page_cowsetup
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|->
name|cow
operator|++
expr_stmt|;
name|pmap_remove_write
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_include
include|#
directive|include
file|"opt_ddb.h"
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<ddb/ddb.h>
end_include

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|page
argument_list|,
argument|vm_page_print_page_info
argument_list|)
end_macro

begin_block
block|{
name|db_printf
argument_list|(
literal|"cnt.v_free_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_cache_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_cache_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_inactive_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_inactive_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_active_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_active_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_wire_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_wire_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_reserved: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_reserved
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_min: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_min
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_target: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_target
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_cache_min: %d\n"
argument_list|,
name|cnt
operator|.
name|v_cache_min
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_inactive_target: %d\n"
argument_list|,
name|cnt
operator|.
name|v_inactive_target
argument_list|)
expr_stmt|;
block|}
end_block

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|pageq
argument_list|,
argument|vm_page_print_pageq_info
argument_list|)
end_macro

begin_block
block|{
name|int
name|i
decl_stmt|;
name|db_printf
argument_list|(
literal|"PQ_FREE:"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PQ_NUMCOLORS
condition|;
name|i
operator|++
control|)
block|{
name|db_printf
argument_list|(
literal|" %d"
argument_list|,
name|vm_page_queues
index|[
name|PQ_FREE
operator|+
name|i
index|]
operator|.
name|lcnt
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"PQ_CACHE:"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PQ_NUMCOLORS
condition|;
name|i
operator|++
control|)
block|{
name|db_printf
argument_list|(
literal|" %d"
argument_list|,
name|vm_page_queues
index|[
name|PQ_CACHE
operator|+
name|i
index|]
operator|.
name|lcnt
argument_list|)
expr_stmt|;
block|}
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"PQ_ACTIVE: %d, PQ_INACTIVE: %d\n"
argument_list|,
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|lcnt
argument_list|,
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|lcnt
argument_list|)
expr_stmt|;
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* DDB */
end_comment

end_unit

