begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1991 Regents of the University of California.  * All rights reserved.  * Copyright (c) 1998 Matthew Dillon.  All Rights Reserved.  *  * This code is derived from software contributed to Berkeley by  * The Mach Operating System project at Carnegie-Mellon University.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from: @(#)vm_page.c	7.4 (Berkeley) 5/7/91  */
end_comment

begin_comment
comment|/*-  * Copyright (c) 1987, 1990 Carnegie-Mellon University.  * All rights reserved.  *  * Authors: Avadis Tevanian, Jr., Michael Wayne Young  *  * Permission to use, copy, modify and distribute this software and  * its documentation is hereby granted, provided that both the copyright  * notice and this permission notice appear in all copies of the  * software, derivative works or modified versions, and any portions  * thereof, and that both notices appear in supporting documentation.  *  * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"  * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND  * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.  *  * Carnegie Mellon requests users of this software to return to  *  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU  *  School of Computer Science  *  Carnegie Mellon University  *  Pittsburgh PA 15213-3890  *  * any improvements or extensions that they make and grant Carnegie the  * rights to redistribute these changes.  */
end_comment

begin_comment
comment|/*  *			GENERAL RULES ON VM_PAGE MANIPULATION  *  *	- A page queue lock is required when adding or removing a page from a  *	  page queue regardless of other locks or the busy state of a page.  *  *		* In general, no thread besides the page daemon can acquire or  *		  hold more than one page queue lock at a time.  *  *		* The page daemon can acquire and hold any pair of page queue  *		  locks in any order.  *  *	- The object lock is required when inserting or removing  *	  pages from an object (vm_page_insert() or vm_page_remove()).  *  */
end_comment

begin_comment
comment|/*  *	Resident memory management module.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_vm.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/limits.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mman.h>
end_include

begin_include
include|#
directive|include
file|<sys/msgbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/pmap.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_phys.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_radix.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_reserv.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma_int.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_comment
comment|/*  *	Associated with page of user-allocatable memory is a  *	page structure.  */
end_comment

begin_decl_stmt
name|struct
name|vm_domain
name|vm_dom
index|[
name|MAXMEMDOM
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mtx_padalign
name|vm_page_queue_free_mtx
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mtx_padalign
name|pa_lock
index|[
name|PA_LOCK_COUNT
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_page_t
name|vm_page_array
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|long
name|vm_page_array_size
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|long
name|first_page
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|vm_page_zero_count
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|boot_pages
init|=
name|UMA_BOOT_PAGES
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"vm.boot_pages"
argument_list|,
operator|&
name|boot_pages
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|boot_pages
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|boot_pages
argument_list|,
literal|0
argument_list|,
literal|"number of pages allocated for bootstrapping the VM system"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pa_tryrelock_restart
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|tryrelock_restart
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pa_tryrelock_restart
argument_list|,
literal|0
argument_list|,
literal|"Number of tryrelock restarts"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|uma_zone_t
name|fakepg_zone
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|struct
name|vnode
modifier|*
name|vm_page_alloc_init
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_cache_turn_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_clear_dirty_mask
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_page_bits_t
name|pagebits
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_enqueue
parameter_list|(
name|int
name|queue
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_init_fakepg
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vm_page_insert_after
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_page_t
name|mpred
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_insert_radixdone
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_page_t
name|mpred
parameter_list|)
function_decl|;
end_function_decl

begin_expr_stmt
name|SYSINIT
argument_list|(
name|vm_page
argument_list|,
name|SI_SUB_VM
argument_list|,
name|SI_ORDER_SECOND
argument_list|,
name|vm_page_init_fakepg
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|void
name|vm_page_init_fakepg
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|fakepg_zone
operator|=
name|uma_zcreate
argument_list|(
literal|"fakepg"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|UMA_ALIGN_PTR
argument_list|,
name|UMA_ZONE_NOFREE
operator||
name|UMA_ZONE_VM
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Make sure that u_long is at least 64 bits when PAGE_SIZE is 32K. */
end_comment

begin_if
if|#
directive|if
name|PAGE_SIZE
operator|==
literal|32768
end_if

begin_ifdef
ifdef|#
directive|ifdef
name|CTASSERT
end_ifdef

begin_expr_stmt
name|CTASSERT
argument_list|(
sizeof|sizeof
argument_list|(
name|u_long
argument_list|)
operator|>=
literal|8
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Try to acquire a physical address lock while a pmap is locked.  If we  * fail to trylock we unlock and lock the pmap directly and cache the  * locked pa in *locked.  The caller should then restart their loop in case  * the virtual to physical mapping has changed.  */
end_comment

begin_function
name|int
name|vm_page_pa_tryrelock
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_paddr_t
modifier|*
name|locked
parameter_list|)
block|{
name|vm_paddr_t
name|lockpa
decl_stmt|;
name|lockpa
operator|=
operator|*
name|locked
expr_stmt|;
operator|*
name|locked
operator|=
name|pa
expr_stmt|;
if|if
condition|(
name|lockpa
condition|)
block|{
name|PA_LOCK_ASSERT
argument_list|(
name|lockpa
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|PA_LOCKPTR
argument_list|(
name|pa
argument_list|)
operator|==
name|PA_LOCKPTR
argument_list|(
name|lockpa
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|PA_UNLOCK
argument_list|(
name|lockpa
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|PA_TRYLOCK
argument_list|(
name|pa
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|pa_tryrelock_restart
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|PA_LOCK
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|EAGAIN
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_set_page_size:  *  *	Sets the page size, perhaps based upon the memory  *	size.  Must be called before any use of page-size  *	dependent functions.  */
end_comment

begin_function
name|void
name|vm_set_page_size
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|cnt
operator|.
name|v_page_size
operator|==
literal|0
condition|)
name|cnt
operator|.
name|v_page_size
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|cnt
operator|.
name|v_page_size
operator|-
literal|1
operator|)
operator|&
name|cnt
operator|.
name|v_page_size
operator|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_set_page_size: page size not a power of two"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_blacklist_lookup:  *  *	See if a physical address in this page has been listed  *	in the blacklist tunable.  Entries in the tunable are  *	separated by spaces or commas.  If an invalid integer is  *	encountered then the rest of the string is skipped.  */
end_comment

begin_function
specifier|static
name|int
name|vm_page_blacklist_lookup
parameter_list|(
name|char
modifier|*
name|list
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|vm_paddr_t
name|bad
decl_stmt|;
name|char
modifier|*
name|cp
decl_stmt|,
modifier|*
name|pos
decl_stmt|;
for|for
control|(
name|pos
operator|=
name|list
init|;
operator|*
name|pos
operator|!=
literal|'\0'
condition|;
name|pos
operator|=
name|cp
control|)
block|{
name|bad
operator|=
name|strtoq
argument_list|(
name|pos
argument_list|,
operator|&
name|cp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cp
operator|!=
literal|'\0'
condition|)
block|{
if|if
condition|(
operator|*
name|cp
operator|==
literal|' '
operator|||
operator|*
name|cp
operator|==
literal|','
condition|)
block|{
name|cp
operator|++
expr_stmt|;
if|if
condition|(
name|cp
operator|==
name|pos
condition|)
continue|continue;
block|}
else|else
break|break;
block|}
if|if
condition|(
name|pa
operator|==
name|trunc_page
argument_list|(
name|bad
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vm_page_domain_init
parameter_list|(
name|struct
name|vm_domain
modifier|*
name|vmd
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|int
name|i
decl_stmt|;
operator|*
name|__DECONST
argument_list|(
name|char
operator|*
operator|*
argument_list|,
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pq_name
argument_list|)
operator|=
literal|"vm inactive pagequeue"
expr_stmt|;
operator|*
name|__DECONST
argument_list|(
name|u_int
operator|*
operator|*
argument_list|,
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pq_vcnt
argument_list|)
operator|=
operator|&
name|cnt
operator|.
name|v_inactive_count
expr_stmt|;
operator|*
name|__DECONST
argument_list|(
name|char
operator|*
operator|*
argument_list|,
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pq_name
argument_list|)
operator|=
literal|"vm active pagequeue"
expr_stmt|;
operator|*
name|__DECONST
argument_list|(
name|u_int
operator|*
operator|*
argument_list|,
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pq_vcnt
argument_list|)
operator|=
operator|&
name|cnt
operator|.
name|v_active_count
expr_stmt|;
name|vmd
operator|->
name|vmd_page_count
operator|=
literal|0
expr_stmt|;
name|vmd
operator|->
name|vmd_free_count
operator|=
literal|0
expr_stmt|;
name|vmd
operator|->
name|vmd_segs
operator|=
literal|0
expr_stmt|;
name|vmd
operator|->
name|vmd_oom
operator|=
name|FALSE
expr_stmt|;
name|vmd
operator|->
name|vmd_pass
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PQ_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|pq
operator|=
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|i
index|]
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|pq
operator|->
name|pq_mutex
argument_list|,
name|pq
operator|->
name|pq_name
argument_list|,
literal|"vm pagequeue"
argument_list|,
name|MTX_DEF
operator||
name|MTX_DUPOK
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_startup:  *  *	Initializes the resident memory module.  Allocates physical memory for  *	bootstrapping UMA and some data structures that are used to manage  *	physical pages.  Initializes these structures, and populates the free  *	page queues.  */
end_comment

begin_function
name|vm_offset_t
name|vm_page_startup
parameter_list|(
name|vm_offset_t
name|vaddr
parameter_list|)
block|{
name|vm_offset_t
name|mapped
decl_stmt|;
name|vm_paddr_t
name|high_avail
decl_stmt|,
name|low_avail
decl_stmt|,
name|page_range
decl_stmt|,
name|size
decl_stmt|;
name|vm_paddr_t
name|new_end
decl_stmt|;
name|int
name|i
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_paddr_t
name|last_pa
decl_stmt|;
name|char
modifier|*
name|list
decl_stmt|;
comment|/* the biggest memory array is the second group of pages */
name|vm_paddr_t
name|end
decl_stmt|;
name|vm_paddr_t
name|biggestsize
decl_stmt|;
name|int
name|biggestone
decl_stmt|;
name|biggestsize
operator|=
literal|0
expr_stmt|;
name|biggestone
operator|=
literal|0
expr_stmt|;
name|vaddr
operator|=
name|round_page
argument_list|(
name|vaddr
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|phys_avail
index|[
name|i
index|]
operator|=
name|round_page
argument_list|(
name|phys_avail
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|=
name|trunc_page
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|XEN
comment|/* 	 * There is no obvious reason why i386 PV Xen needs vm_page structs 	 * created for these pseudo-physical addresses.  XXX 	 */
name|vm_phys_add_seg
argument_list|(
literal|0
argument_list|,
name|phys_avail
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
endif|#
directive|endif
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|size
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|size
operator|>
name|biggestsize
condition|)
block|{
name|biggestone
operator|=
name|i
expr_stmt|;
name|biggestsize
operator|=
name|size
expr_stmt|;
block|}
block|}
name|end
operator|=
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
expr_stmt|;
comment|/* 	 * Initialize the page and queue locks. 	 */
name|mtx_init
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
literal|"vm page free queue"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PA_LOCK_COUNT
condition|;
name|i
operator|++
control|)
name|mtx_init
argument_list|(
operator|&
name|pa_lock
index|[
name|i
index|]
argument_list|,
literal|"vm page"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|vm_ndomains
condition|;
name|i
operator|++
control|)
name|vm_page_domain_init
argument_list|(
operator|&
name|vm_dom
index|[
name|i
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate memory for use when boot strapping the kernel memory 	 * allocator. 	 */
name|new_end
operator|=
name|end
operator|-
operator|(
name|boot_pages
operator|*
name|UMA_SLAB_SIZE
operator|)
expr_stmt|;
name|new_end
operator|=
name|trunc_page
argument_list|(
name|new_end
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|end
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|mapped
argument_list|,
name|end
operator|-
name|new_end
argument_list|)
expr_stmt|;
name|uma_startup
argument_list|(
operator|(
name|void
operator|*
operator|)
name|mapped
argument_list|,
name|boot_pages
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__i386__
argument_list|)
operator|||
name|defined
argument_list|(
name|__arm__
argument_list|)
operator|||
expr|\
name|defined
argument_list|(
name|__mips__
argument_list|)
comment|/* 	 * Allocate a bitmap to indicate that a random physical page 	 * needs to be included in a minidump. 	 * 	 * The amd64 port needs this to indicate which direct map pages 	 * need to be dumped, via calls to dump_add_page()/dump_drop_page(). 	 * 	 * However, i386 still needs this workspace internally within the 	 * minidump code.  In theory, they are not needed on i386, but are 	 * included should the sf_buf code decide to use them. 	 */
name|last_pa
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|dump_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
if|if
condition|(
name|dump_avail
index|[
name|i
operator|+
literal|1
index|]
operator|>
name|last_pa
condition|)
name|last_pa
operator|=
name|dump_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
name|page_range
operator|=
name|last_pa
operator|/
name|PAGE_SIZE
expr_stmt|;
name|vm_page_dump_size
operator|=
name|round_page
argument_list|(
name|roundup2
argument_list|(
name|page_range
argument_list|,
name|NBBY
argument_list|)
operator|/
name|NBBY
argument_list|)
expr_stmt|;
name|new_end
operator|-=
name|vm_page_dump_size
expr_stmt|;
name|vm_page_dump
operator|=
operator|(
name|void
operator|*
operator|)
operator|(
name|uintptr_t
operator|)
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|new_end
operator|+
name|vm_page_dump_size
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|vm_page_dump
argument_list|,
name|vm_page_dump_size
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|#
directive|if
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__mips__
argument_list|)
comment|/* 	 * Include the UMA bootstrap pages and vm_page_dump in a crash dump. 	 * When pmap_map() uses the direct map, they are not automatically  	 * included. 	 */
for|for
control|(
name|pa
operator|=
name|new_end
init|;
name|pa
operator|<
name|end
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|dump_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
operator|=
name|new_end
expr_stmt|;
ifdef|#
directive|ifdef
name|__amd64__
comment|/* 	 * Request that the physical pages underlying the message buffer be 	 * included in a crash dump.  Since the message buffer is accessed 	 * through the direct map, they are not automatically included. 	 */
name|pa
operator|=
name|DMAP_TO_PHYS
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|msgbufp
operator|->
name|msg_ptr
argument_list|)
expr_stmt|;
name|last_pa
operator|=
name|pa
operator|+
name|round_page
argument_list|(
name|msgbufsize
argument_list|)
expr_stmt|;
while|while
condition|(
name|pa
operator|<
name|last_pa
condition|)
block|{
name|dump_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* 	 * Compute the number of pages of memory that will be available for 	 * use, taking into account the overhead of a page structure per page. 	 * In other words, solve 	 *	"available physical memory" - round_page(page_range * 	 *	    sizeof(struct vm_page)) = page_range * PAGE_SIZE  	 * for page_range.   	 */
name|low_avail
operator|=
name|phys_avail
index|[
literal|0
index|]
expr_stmt|;
name|high_avail
operator|=
name|phys_avail
index|[
literal|1
index|]
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|vm_phys_nsegs
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|start
operator|<
name|low_avail
condition|)
name|low_avail
operator|=
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|start
expr_stmt|;
if|if
condition|(
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|end
operator|>
name|high_avail
condition|)
name|high_avail
operator|=
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|end
expr_stmt|;
block|}
comment|/* Skip the first chunk.  It is already accounted for. */
for|for
control|(
name|i
operator|=
literal|2
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
block|{
if|if
condition|(
name|phys_avail
index|[
name|i
index|]
operator|<
name|low_avail
condition|)
name|low_avail
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|>
name|high_avail
condition|)
name|high_avail
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
block|}
name|first_page
operator|=
name|low_avail
operator|/
name|PAGE_SIZE
expr_stmt|;
ifdef|#
directive|ifdef
name|VM_PHYSSEG_SPARSE
name|size
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|vm_phys_nsegs
condition|;
name|i
operator|++
control|)
name|size
operator|+=
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|end
operator|-
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|start
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
name|size
operator|+=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
elif|#
directive|elif
name|defined
argument_list|(
name|VM_PHYSSEG_DENSE
argument_list|)
name|size
operator|=
name|high_avail
operator|-
name|low_avail
expr_stmt|;
else|#
directive|else
error|#
directive|error
literal|"Either VM_PHYSSEG_DENSE or VM_PHYSSEG_SPARSE must be defined."
endif|#
directive|endif
ifdef|#
directive|ifdef
name|VM_PHYSSEG_DENSE
comment|/* 	 * In the VM_PHYSSEG_DENSE case, the number of pages can account for 	 * the overhead of a page structure per page only if vm_page_array is 	 * allocated from the last physical memory chunk.  Otherwise, we must 	 * allocate page structures representing the physical memory 	 * underlying vm_page_array, even though they will not be used. 	 */
if|if
condition|(
name|new_end
operator|!=
name|high_avail
condition|)
name|page_range
operator|=
name|size
operator|/
name|PAGE_SIZE
expr_stmt|;
else|else
endif|#
directive|endif
block|{
name|page_range
operator|=
name|size
operator|/
operator|(
name|PAGE_SIZE
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
operator|)
expr_stmt|;
comment|/* 		 * If the partial bytes remaining are large enough for 		 * a page (PAGE_SIZE) without a corresponding 		 * 'struct vm_page', then new_end will contain an 		 * extra page after subtracting the length of the VM 		 * page array.  Compensate by subtracting an extra 		 * page from new_end. 		 */
if|if
condition|(
name|size
operator|%
operator|(
name|PAGE_SIZE
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
operator|)
operator|>=
name|PAGE_SIZE
condition|)
block|{
if|if
condition|(
name|new_end
operator|==
name|high_avail
condition|)
name|high_avail
operator|-=
name|PAGE_SIZE
expr_stmt|;
name|new_end
operator|-=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
name|end
operator|=
name|new_end
expr_stmt|;
comment|/* 	 * Reserve an unmapped guard page to trap access to vm_page_array[-1]. 	 * However, because this page is allocated from KVM, out-of-bounds 	 * accesses using the direct map will not be trapped. 	 */
name|vaddr
operator|+=
name|PAGE_SIZE
expr_stmt|;
comment|/* 	 * Allocate physical memory for the page structures, and map it. 	 */
name|new_end
operator|=
name|trunc_page
argument_list|(
name|end
operator|-
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|end
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|vm_page_array
operator|=
operator|(
name|vm_page_t
operator|)
name|mapped
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
comment|/* 	 * Allocate physical memory for the reservation management system's 	 * data structures, and map it. 	 */
if|if
condition|(
name|high_avail
operator|==
name|end
condition|)
name|high_avail
operator|=
name|new_end
expr_stmt|;
name|new_end
operator|=
name|vm_reserv_startup
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|high_avail
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|#
directive|if
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__mips__
argument_list|)
comment|/* 	 * Include vm_page_array and vm_reserv_array in a crash dump. 	 */
for|for
control|(
name|pa
operator|=
name|new_end
init|;
name|pa
operator|<
name|end
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|dump_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
operator|=
name|new_end
expr_stmt|;
comment|/* 	 * Add physical memory segments corresponding to the available 	 * physical pages. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
name|vm_phys_add_seg
argument_list|(
name|phys_avail
index|[
name|i
index|]
argument_list|,
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * Clear all of the page structures 	 */
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|vm_page_array
argument_list|,
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|page_range
condition|;
name|i
operator|++
control|)
name|vm_page_array
index|[
name|i
index|]
operator|.
name|order
operator|=
name|VM_NFREEORDER
expr_stmt|;
name|vm_page_array_size
operator|=
name|page_range
expr_stmt|;
comment|/* 	 * Initialize the physical memory allocator. 	 */
name|vm_phys_init
argument_list|()
expr_stmt|;
comment|/* 	 * Add every available physical page that is not blacklisted to 	 * the free lists. 	 */
name|cnt
operator|.
name|v_page_count
operator|=
literal|0
expr_stmt|;
name|cnt
operator|.
name|v_free_count
operator|=
literal|0
expr_stmt|;
name|list
operator|=
name|getenv
argument_list|(
literal|"vm.blacklist"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|pa
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
name|last_pa
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
while|while
condition|(
name|pa
operator|<
name|last_pa
condition|)
block|{
if|if
condition|(
name|list
operator|!=
name|NULL
operator|&&
name|vm_page_blacklist_lookup
argument_list|(
name|list
argument_list|,
name|pa
argument_list|)
condition|)
name|printf
argument_list|(
literal|"Skipping page with pa 0x%jx\n"
argument_list|,
operator|(
name|uintmax_t
operator|)
name|pa
argument_list|)
expr_stmt|;
else|else
name|vm_phys_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
name|freeenv
argument_list|(
name|list
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
comment|/* 	 * Initialize the reservation management system. 	 */
name|vm_reserv_init
argument_list|()
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
name|vaddr
operator|)
return|;
block|}
end_function

begin_function
name|void
name|vm_page_reference
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_busy_downgrade:  *  *	Downgrade an exclusive busy page into a single shared busy page.  */
end_comment

begin_function
name|void
name|vm_page_busy_downgrade
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
name|bool
name|locked
decl_stmt|;
name|vm_page_assert_xbusied
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|locked
operator|=
name|mtx_owned
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
name|x
operator|&=
name|VPB_BIT_WAITERS
expr_stmt|;
if|if
condition|(
name|x
operator|!=
literal|0
operator|&&
operator|!
name|locked
condition|)
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|atomic_cmpset_rel_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|VPB_SINGLE_EXCLUSIVER
operator||
name|x
argument_list|,
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
argument_list|)
condition|)
break|break;
if|if
condition|(
name|x
operator|!=
literal|0
operator|&&
operator|!
name|locked
condition|)
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|x
operator|!=
literal|0
condition|)
block|{
name|wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|locked
condition|)
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_sbusied:  *  *	Return a positive value if the page is shared busied, 0 otherwise.  */
end_comment

begin_function
name|int
name|vm_page_sbusied
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
return|return
operator|(
operator|(
name|x
operator|&
name|VPB_BIT_SHARED
operator|)
operator|!=
literal|0
operator|&&
name|x
operator|!=
name|VPB_UNBUSIED
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_sunbusy:  *  *	Shared unbusy a page.  */
end_comment

begin_function
name|void
name|vm_page_sunbusy
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
name|vm_page_assert_sbusied
argument_list|(
name|m
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
if|if
condition|(
name|VPB_SHARERS
argument_list|(
name|x
argument_list|)
operator|>
literal|1
condition|)
block|{
if|if
condition|(
name|atomic_cmpset_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|x
argument_list|,
name|x
operator|-
name|VPB_ONE_SHARER
argument_list|)
condition|)
break|break;
continue|continue;
block|}
if|if
condition|(
operator|(
name|x
operator|&
name|VPB_BIT_WAITERS
operator|)
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|x
operator|==
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
argument_list|,
operator|(
literal|"vm_page_sunbusy: invalid lock state"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|atomic_cmpset_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
argument_list|,
name|VPB_UNBUSIED
argument_list|)
condition|)
break|break;
continue|continue;
block|}
name|KASSERT
argument_list|(
name|x
operator|==
operator|(
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
operator||
name|VPB_BIT_WAITERS
operator|)
argument_list|,
operator|(
literal|"vm_page_sunbusy: invalid lock state for waiters"
operator|)
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|atomic_cmpset_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|x
argument_list|,
name|VPB_UNBUSIED
argument_list|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_busy_sleep:  *  *	Sleep and release the page lock, using the page pointer as wchan.  *	This is used to implement the hard-path of busying mechanism.  *  *	The given page must be locked.  *  *	If nonshared is true, sleep only if the page is xbusy.  */
end_comment

begin_function
name|void
name|vm_page_busy_sleep
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|wmesg
parameter_list|,
name|bool
name|nonshared
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
if|if
condition|(
name|x
operator|==
name|VPB_UNBUSIED
operator|||
operator|(
name|nonshared
operator|&&
operator|(
name|x
operator|&
name|VPB_BIT_SHARED
operator|)
operator|!=
literal|0
operator|)
operator|||
operator|(
operator|(
name|x
operator|&
name|VPB_BIT_WAITERS
operator|)
operator|==
literal|0
operator|&&
operator|!
name|atomic_cmpset_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|x
argument_list|,
name|x
operator||
name|VPB_BIT_WAITERS
argument_list|)
operator|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return;
block|}
name|msleep
argument_list|(
name|m
argument_list|,
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|,
name|PVM
operator||
name|PDROP
argument_list|,
name|wmesg
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_trysbusy:  *  *	Try to shared busy a page.  *	If the operation succeeds 1 is returned otherwise 0.  *	The operation never sleeps.  */
end_comment

begin_function
name|int
name|vm_page_trysbusy
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
if|if
condition|(
operator|(
name|x
operator|&
name|VPB_BIT_SHARED
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|if
condition|(
name|atomic_cmpset_acq_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|x
argument_list|,
name|x
operator|+
name|VPB_ONE_SHARER
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_xunbusy_hard:  *  *	Called after the first try the exclusive unbusy of a page failed.  *	It is assumed that the waiters bit is on.  */
end_comment

begin_function
name|void
name|vm_page_xunbusy_hard
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_assert_xbusied
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|atomic_store_rel_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|VPB_UNBUSIED
argument_list|)
expr_stmt|;
name|wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_flash:  *  *	Wakeup anyone waiting for the page.  *	The ownership bits do not change.  *  *	The given page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_flash
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
if|if
condition|(
operator|(
name|x
operator|&
name|VPB_BIT_WAITERS
operator|)
operator|==
literal|0
condition|)
return|return;
if|if
condition|(
name|atomic_cmpset_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|x
argument_list|,
name|x
operator|&
operator|(
operator|~
name|VPB_BIT_WAITERS
operator|)
argument_list|)
condition|)
break|break;
block|}
name|wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Keep page from being freed by the page daemon  * much of the same effect as wiring, except much lower  * overhead and should be used only for *very* temporary  * holding ("wiring").  */
end_comment

begin_function
name|void
name|vm_page_hold
parameter_list|(
name|vm_page_t
name|mem
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|mem
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mem
operator|->
name|hold_count
operator|++
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_unhold
parameter_list|(
name|vm_page_t
name|mem
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|mem
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mem
operator|->
name|hold_count
operator|>=
literal|1
argument_list|,
operator|(
literal|"vm_page_unhold: hold count< 0!!!"
operator|)
argument_list|)
expr_stmt|;
operator|--
name|mem
operator|->
name|hold_count
expr_stmt|;
if|if
condition|(
name|mem
operator|->
name|hold_count
operator|==
literal|0
operator|&&
operator|(
name|mem
operator|->
name|flags
operator|&
name|PG_UNHOLDFREE
operator|)
operator|!=
literal|0
condition|)
name|vm_page_free_toq
argument_list|(
name|mem
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_unhold_pages:  *  *	Unhold each of the pages that is referenced by the given array.  */
end_comment

begin_function
name|void
name|vm_page_unhold_pages
parameter_list|(
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtx
decl_stmt|,
modifier|*
name|new_mtx
decl_stmt|;
name|mtx
operator|=
name|NULL
expr_stmt|;
for|for
control|(
init|;
name|count
operator|!=
literal|0
condition|;
name|count
operator|--
control|)
block|{
comment|/* 		 * Avoid releasing and reacquiring the same page lock. 		 */
name|new_mtx
operator|=
name|vm_page_lockptr
argument_list|(
operator|*
name|ma
argument_list|)
expr_stmt|;
if|if
condition|(
name|mtx
operator|!=
name|new_mtx
condition|)
block|{
if|if
condition|(
name|mtx
operator|!=
name|NULL
condition|)
name|mtx_unlock
argument_list|(
name|mtx
argument_list|)
expr_stmt|;
name|mtx
operator|=
name|new_mtx
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtx
argument_list|)
expr_stmt|;
block|}
name|vm_page_unhold
argument_list|(
operator|*
name|ma
argument_list|)
expr_stmt|;
name|ma
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|mtx
operator|!=
name|NULL
condition|)
name|mtx_unlock
argument_list|(
name|mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|vm_page_t
name|PHYS_TO_VM_PAGE
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
ifdef|#
directive|ifdef
name|VM_PHYSSEG_SPARSE
name|m
operator|=
name|vm_phys_paddr_to_vm_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
name|m
operator|=
name|vm_phys_fictitious_to_vm_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
elif|#
directive|elif
name|defined
argument_list|(
name|VM_PHYSSEG_DENSE
argument_list|)
name|long
name|pi
decl_stmt|;
name|pi
operator|=
name|atop
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
name|pi
operator|>=
name|first_page
operator|&&
operator|(
name|pi
operator|-
name|first_page
operator|)
operator|<
name|vm_page_array_size
condition|)
block|{
name|m
operator|=
operator|&
name|vm_page_array
index|[
name|pi
operator|-
name|first_page
index|]
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
return|return
operator|(
name|vm_phys_fictitious_to_vm_page
argument_list|(
name|pa
argument_list|)
operator|)
return|;
else|#
directive|else
error|#
directive|error
literal|"Either VM_PHYSSEG_DENSE or VM_PHYSSEG_SPARSE must be defined."
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  *	vm_page_getfake:  *  *	Create a fictitious page with the specified physical address and  *	memory attribute.  The memory attribute is the only the machine-  *	dependent aspect of a fictitious page that must be initialized.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_getfake
parameter_list|(
name|vm_paddr_t
name|paddr
parameter_list|,
name|vm_memattr_t
name|memattr
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|uma_zalloc
argument_list|(
name|fakepg_zone
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
name|vm_page_initfake
argument_list|(
name|m
argument_list|,
name|paddr
argument_list|,
name|memattr
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
name|void
name|vm_page_initfake
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_paddr_t
name|paddr
parameter_list|,
name|vm_memattr_t
name|memattr
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * The page's memattr might have changed since the 		 * previous initialization.  Update the pmap to the 		 * new memattr. 		 */
goto|goto
name|memattr
goto|;
block|}
name|m
operator|->
name|phys_addr
operator|=
name|paddr
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_NONE
expr_stmt|;
comment|/* Fictitious pages don't use "segind". */
name|m
operator|->
name|flags
operator|=
name|PG_FICTITIOUS
expr_stmt|;
comment|/* Fictitious pages don't use "order" or "pool". */
name|m
operator|->
name|oflags
operator|=
name|VPO_UNMANAGED
expr_stmt|;
name|m
operator|->
name|busy_lock
operator|=
name|VPB_SINGLE_EXCLUSIVER
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
name|pmap_page_init
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|memattr
label|:
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|memattr
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_putfake:  *  *	Release a fictitious page.  */
end_comment

begin_function
name|void
name|vm_page_putfake
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"managed %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_putfake: bad page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|uma_zfree
argument_list|(
name|fakepg_zone
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_updatefake:  *  *	Update the given fictitious page to the specified physical address and  *	memory attribute.  */
end_comment

begin_function
name|void
name|vm_page_updatefake
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_paddr_t
name|paddr
parameter_list|,
name|vm_memattr_t
name|memattr
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_updatefake: bad page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|phys_addr
operator|=
name|paddr
expr_stmt|;
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|memattr
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_free:  *  *	Free a page.  */
end_comment

begin_function
name|void
name|vm_page_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_zero:  *  *	Free a page to the zerod-pages queue  */
end_comment

begin_function
name|void
name|vm_page_free_zero
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|m
operator|->
name|flags
operator||=
name|PG_ZERO
expr_stmt|;
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Unbusy and handle the page queueing for a page from the VOP_GETPAGES()  * array which is not the request page.  */
end_comment

begin_function
name|void
name|vm_page_readahead_finish
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
name|m
operator|->
name|valid
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * Since the page is not the requested page, whether 		 * it should be activated or deactivated is not 		 * obvious.  Empirical results have shown that 		 * deactivating the page is usually the best choice, 		 * unless the page is wanted by another thread. 		 */
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|busy_lock
operator|&
name|VPB_BIT_WAITERS
operator|)
operator|!=
literal|0
condition|)
name|vm_page_activate
argument_list|(
name|m
argument_list|)
expr_stmt|;
else|else
name|vm_page_deactivate
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_xunbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Free the completely invalid page.  Such page state 		 * occurs due to the short read operation which did 		 * not covered our page at all, or in case when a read 		 * error happens. 		 */
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_sleep_if_busy:  *  *	Sleep and release the page queues lock if the page is busied.  *	Returns TRUE if the thread slept.  *  *	The given page must be unlocked and object containing it must  *	be locked.  */
end_comment

begin_function
name|int
name|vm_page_sleep_if_busy
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|msg
parameter_list|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_busied
argument_list|(
name|m
argument_list|)
condition|)
block|{
comment|/* 		 * The page-specific object must be cached because page 		 * identity can change during the sleep, causing the 		 * re-lock of a different object. 		 * It is assumed that a reference to the object is already 		 * held by the callers. 		 */
name|obj
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
name|vm_page_busy_sleep
argument_list|(
name|m
argument_list|,
name|msg
argument_list|,
name|false
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_dirty_KBI:		[ internal use only ]  *  *	Set all bits in the page's dirty field.  *  *	The object containing the specified page must be locked if the  *	call is made from the machine-independent layer.  *  *	See vm_page_clear_dirty_mask().  *  *	This function should only be called by vm_page_dirty().  */
end_comment

begin_function
name|void
name|vm_page_dirty_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
comment|/* These assertions refer to this operation by its public name. */
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CACHED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_dirty: page in cache!"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|VM_PAGE_IS_FREE
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_dirty: page is free!"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
argument_list|,
operator|(
literal|"vm_page_dirty: page is invalid!"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|dirty
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_insert:		[ internal use only ]  *  *	Inserts the given mem entry into the object and object list.  *  *	The object must be locked.  */
end_comment

begin_function
name|int
name|vm_page_insert
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|mpred
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|mpred
operator|=
name|vm_radix_lookup_le
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
return|return
operator|(
name|vm_page_insert_after
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|,
name|mpred
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_insert_after:  *  *	Inserts the page "m" into the specified object at offset "pindex".  *  *	The page "mpred" must immediately precede the offset "pindex" within  *	the specified object.  *  *	The object must be locked.  */
end_comment

begin_function
specifier|static
name|int
name|vm_page_insert_after
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_page_t
name|mpred
parameter_list|)
block|{
name|vm_page_t
name|msucc
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|object
operator|==
name|NULL
argument_list|,
operator|(
literal|"vm_page_insert_after: page already inserted"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpred
operator|!=
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
name|mpred
operator|->
name|object
operator|==
name|object
argument_list|,
operator|(
literal|"vm_page_insert_after: object doesn't contain mpred"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpred
operator|->
name|pindex
operator|<
name|pindex
argument_list|,
operator|(
literal|"vm_page_insert_after: mpred doesn't precede pindex"
operator|)
argument_list|)
expr_stmt|;
name|msucc
operator|=
name|TAILQ_NEXT
argument_list|(
name|mpred
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
else|else
name|msucc
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|)
expr_stmt|;
if|if
condition|(
name|msucc
operator|!=
name|NULL
condition|)
name|KASSERT
argument_list|(
name|msucc
operator|->
name|pindex
operator|>
name|pindex
argument_list|,
operator|(
literal|"vm_page_insert_after: msucc doesn't succeed pindex"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Record the object/offset pair in this page 	 */
name|m
operator|->
name|object
operator|=
name|object
expr_stmt|;
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
comment|/* 	 * Now link into the object's ordered list of backed pages. 	 */
if|if
condition|(
name|vm_radix_insert
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|m
argument_list|)
condition|)
block|{
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|m
operator|->
name|pindex
operator|=
literal|0
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
name|vm_page_insert_radixdone
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|mpred
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_insert_radixdone:  *  *	Complete page "m" insertion into the specified object after the  *	radix trie hooking.  *  *	The page "mpred" must precede the offset "m->pindex" within the  *	specified object.  *  *	The object must be locked.  */
end_comment

begin_function
specifier|static
name|void
name|vm_page_insert_radixdone
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_page_t
name|mpred
parameter_list|)
block|{
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|object
operator|!=
name|NULL
operator|&&
name|m
operator|->
name|object
operator|==
name|object
argument_list|,
operator|(
literal|"vm_page_insert_radixdone: page %p has inconsistent object"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpred
operator|!=
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
name|mpred
operator|->
name|object
operator|==
name|object
argument_list|,
operator|(
literal|"vm_page_insert_after: object doesn't contain mpred"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpred
operator|->
name|pindex
operator|<
name|m
operator|->
name|pindex
argument_list|,
operator|(
literal|"vm_page_insert_after: mpred doesn't precede pindex"
operator|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mpred
operator|!=
name|NULL
condition|)
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|mpred
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
comment|/* 	 * Show that the object has one more resident page. 	 */
name|object
operator|->
name|resident_page_count
operator|++
expr_stmt|;
comment|/* 	 * Hold the vnode until the last page is released. 	 */
if|if
condition|(
name|object
operator|->
name|resident_page_count
operator|==
literal|1
operator|&&
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
name|vhold
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
comment|/* 	 * Since we are inserting a new and possibly dirty page, 	 * update the object's OBJ_MIGHTBEDIRTY flag. 	 */
if|if
condition|(
name|pmap_page_is_write_mapped
argument_list|(
name|m
argument_list|)
condition|)
name|vm_object_set_writeable_dirty
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_remove:  *  *	Removes the given mem entry from the object/offset-page  *	table and the object page list, but do not invalidate/terminate  *	the backing store.  *  *	The object must be locked.  The page must be locked if it is managed.  */
end_comment

begin_function
name|void
name|vm_page_remove
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|boolean_t
name|lockacq
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|object
operator|=
name|m
operator|->
name|object
operator|)
operator|==
name|NULL
condition|)
return|return;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
block|{
name|lockacq
operator|=
name|FALSE
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
operator|&&
operator|!
name|mtx_owned
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|)
condition|)
block|{
name|lockacq
operator|=
name|TRUE
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_flash
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|atomic_store_rel_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|VPB_UNBUSIED
argument_list|)
expr_stmt|;
if|if
condition|(
name|lockacq
condition|)
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Now remove from the object's list of backed pages. 	 */
name|vm_radix_remove
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
comment|/* 	 * And show that the object has one fewer resident page. 	 */
name|object
operator|->
name|resident_page_count
operator|--
expr_stmt|;
comment|/* 	 * The vnode may now be recycled. 	 */
if|if
condition|(
name|object
operator|->
name|resident_page_count
operator|==
literal|0
operator|&&
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
name|vdrop
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_lookup:  *  *	Returns the page associated with the object/offset  *	pair specified; if none is found, NULL is returned.  *  *	The object must be locked.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_lookup
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
return|return
operator|(
name|vm_radix_lookup
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|pindex
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_find_least:  *  *	Returns the page associated with the object with least pindex  *	greater than or equal to the parameter pindex, or NULL.  *  *	The object must be locked.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_find_least
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
name|m
operator|->
name|pindex
operator|<
name|pindex
condition|)
name|m
operator|=
name|vm_radix_lookup_ge
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns the given page's successor (by pindex) within the object if it is  * resident; if none is found, NULL is returned.  *  * The object must be locked.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_next
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_t
name|next
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|MPASS
argument_list|(
name|next
operator|->
name|object
operator|==
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|next
operator|->
name|pindex
operator|!=
name|m
operator|->
name|pindex
operator|+
literal|1
condition|)
name|next
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|next
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns the given page's predecessor (by pindex) within the object if it is  * resident; if none is found, NULL is returned.  *  * The object must be locked.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_prev
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_t
name|prev
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|prev
operator|=
name|TAILQ_PREV
argument_list|(
name|m
argument_list|,
name|pglist
argument_list|,
name|listq
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|MPASS
argument_list|(
name|prev
operator|->
name|object
operator|==
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|prev
operator|->
name|pindex
operator|!=
name|m
operator|->
name|pindex
operator|-
literal|1
condition|)
name|prev
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|prev
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Uses the page mnew as a replacement for an existing page at index  * pindex which must be already present in the object.  *  * The existing page must not be on a paging queue.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_replace
parameter_list|(
name|vm_page_t
name|mnew
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|mold
decl_stmt|,
name|mpred
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
comment|/* 	 * This function mostly follows vm_page_insert() and 	 * vm_page_remove() without the radix, object count and vnode 	 * dance.  Double check such functions for more comments. 	 */
name|mpred
operator|=
name|vm_radix_lookup
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpred
operator|!=
name|NULL
argument_list|,
operator|(
literal|"vm_page_replace: replacing page not present with pindex"
operator|)
argument_list|)
expr_stmt|;
name|mpred
operator|=
name|TAILQ_PREV
argument_list|(
name|mpred
argument_list|,
name|respgs
argument_list|,
name|listq
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpred
operator|!=
name|NULL
condition|)
name|KASSERT
argument_list|(
name|mpred
operator|->
name|pindex
operator|<
name|pindex
argument_list|,
operator|(
literal|"vm_page_insert_after: mpred doesn't precede pindex"
operator|)
argument_list|)
expr_stmt|;
name|mnew
operator|->
name|object
operator|=
name|object
expr_stmt|;
name|mnew
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
name|mold
operator|=
name|vm_radix_replace
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|mnew
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mold
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_replace: mold is on a paging queue"
operator|)
argument_list|)
expr_stmt|;
comment|/* Detach the old page from the resident tailq. */
name|TAILQ_REMOVE
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|mold
argument_list|,
name|listq
argument_list|)
expr_stmt|;
name|mold
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|vm_page_xunbusy
argument_list|(
name|mold
argument_list|)
expr_stmt|;
comment|/* Insert the new page in the resident tailq. */
if|if
condition|(
name|mpred
operator|!=
name|NULL
condition|)
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|mpred
argument_list|,
name|mnew
argument_list|,
name|listq
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|mnew
argument_list|,
name|listq
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_page_is_write_mapped
argument_list|(
name|mnew
argument_list|)
condition|)
name|vm_object_set_writeable_dirty
argument_list|(
name|object
argument_list|)
expr_stmt|;
return|return
operator|(
name|mold
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_rename:  *  *	Move the given memory entry from its  *	current object to the specified target object/offset.  *  *	Note: swap associated with the page must be invalidated by the move.  We  *	      have to do this for several reasons:  (1) we aren't freeing the  *	      page, (2) we are dirtying the page, (3) the VM system is probably  *	      moving the page from object A to B, and will then later move  *	      the backing store from A to B and we can't have a conflict.  *  *	Note: we *always* dirty the page.  It is necessary both for the  *	      fact that we moved it, and because we may be invalidating  *	      swap.  If the page is on the cache, we have to deactivate it  *	      or vm_page_dirty() will panic.  Dirty pages are not allowed  *	      on the cache.  *  *	The objects must be locked.  */
end_comment

begin_function
name|int
name|vm_page_rename
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|new_object
parameter_list|,
name|vm_pindex_t
name|new_pindex
parameter_list|)
block|{
name|vm_page_t
name|mpred
decl_stmt|;
name|vm_pindex_t
name|opidx
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|new_object
argument_list|)
expr_stmt|;
name|mpred
operator|=
name|vm_radix_lookup_le
argument_list|(
operator|&
name|new_object
operator|->
name|rtree
argument_list|,
name|new_pindex
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpred
operator|==
name|NULL
operator|||
name|mpred
operator|->
name|pindex
operator|!=
name|new_pindex
argument_list|,
operator|(
literal|"vm_page_rename: pindex already renamed"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Create a custom version of vm_page_insert() which does not depend 	 * by m_prev and can cheat on the implementation aspects of the 	 * function. 	 */
name|opidx
operator|=
name|m
operator|->
name|pindex
expr_stmt|;
name|m
operator|->
name|pindex
operator|=
name|new_pindex
expr_stmt|;
if|if
condition|(
name|vm_radix_insert
argument_list|(
operator|&
name|new_object
operator|->
name|rtree
argument_list|,
name|m
argument_list|)
condition|)
block|{
name|m
operator|->
name|pindex
operator|=
name|opidx
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
comment|/* 	 * The operation cannot fail anymore.  The removal must happen before 	 * the listq iterator is tainted. 	 */
name|m
operator|->
name|pindex
operator|=
name|opidx
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* Return back to the new pindex to complete vm_page_insert(). */
name|m
operator|->
name|pindex
operator|=
name|new_pindex
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|new_object
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_insert_radixdone
argument_list|(
name|m
argument_list|,
name|new_object
argument_list|,
name|mpred
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Convert all of the given object's cached pages that have a  *	pindex within the given range into free pages.  If the value  *	zero is given for "end", then the range's upper bound is  *	infinity.  If the given object is backed by a vnode and it  *	transitions from having one or more cached pages to none, the  *	vnode's hold count is reduced.   */
end_comment

begin_function
name|void
name|vm_page_cache_free
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|start
parameter_list|,
name|vm_pindex_t
name|end
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|boolean_t
name|empty
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|__predict_false
argument_list|(
name|vm_radix_is_empty
argument_list|(
operator|&
name|object
operator|->
name|cache
argument_list|)
argument_list|)
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return;
block|}
while|while
condition|(
operator|(
name|m
operator|=
name|vm_radix_lookup_ge
argument_list|(
operator|&
name|object
operator|->
name|cache
argument_list|,
name|start
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|end
operator|!=
literal|0
operator|&&
name|m
operator|->
name|pindex
operator|>=
name|end
condition|)
break|break;
name|vm_radix_remove
argument_list|(
operator|&
name|object
operator|->
name|cache
argument_list|,
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
name|vm_page_cache_turn_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|empty
operator|=
name|vm_radix_is_empty
argument_list|(
operator|&
name|object
operator|->
name|cache
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
operator|&&
name|empty
condition|)
name|vdrop
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Returns the cached page that is associated with the given  *	object and offset.  If, however, none exists, returns NULL.  *  *	The free page queue must be locked.  */
end_comment

begin_function
specifier|static
specifier|inline
name|vm_page_t
name|vm_page_cache_lookup
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
name|vm_radix_lookup
argument_list|(
operator|&
name|object
operator|->
name|cache
argument_list|,
name|pindex
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Remove the given cached page from its containing object's  *	collection of cached pages.  *  *	The free page queue must be locked.  */
end_comment

begin_function
specifier|static
name|void
name|vm_page_cache_remove
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CACHED
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_cache_remove: page %p is not cached"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vm_radix_remove
argument_list|(
operator|&
name|m
operator|->
name|object
operator|->
name|cache
argument_list|,
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|cnt
operator|.
name|v_cache_count
operator|--
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Transfer all of the cached pages with offset greater than or  *	equal to 'offidxstart' from the original object's cache to the  *	new object's cache.  However, any cached pages with offset  *	greater than or equal to the new object's size are kept in the  *	original object.  Initially, the new object's cache must be  *	empty.  Offset 'offidxstart' in the original object must  *	correspond to offset zero in the new object.  *  *	The new object must be locked.  */
end_comment

begin_function
name|void
name|vm_page_cache_transfer
parameter_list|(
name|vm_object_t
name|orig_object
parameter_list|,
name|vm_pindex_t
name|offidxstart
parameter_list|,
name|vm_object_t
name|new_object
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
comment|/* 	 * Insertion into an object's collection of cached pages 	 * requires the object to be locked.  In contrast, removal does 	 * not. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|new_object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|vm_radix_is_empty
argument_list|(
operator|&
name|new_object
operator|->
name|cache
argument_list|)
argument_list|,
operator|(
literal|"vm_page_cache_transfer: object %p has cached pages"
operator|,
name|new_object
operator|)
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|m
operator|=
name|vm_radix_lookup_ge
argument_list|(
operator|&
name|orig_object
operator|->
name|cache
argument_list|,
name|offidxstart
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
comment|/* 		 * Transfer all of the pages with offset greater than or 		 * equal to 'offidxstart' from the original object's 		 * cache to the new object's cache. 		 */
if|if
condition|(
operator|(
name|m
operator|->
name|pindex
operator|-
name|offidxstart
operator|)
operator|>=
name|new_object
operator|->
name|size
condition|)
break|break;
name|vm_radix_remove
argument_list|(
operator|&
name|orig_object
operator|->
name|cache
argument_list|,
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
comment|/* Update the page's object and offset. */
name|m
operator|->
name|object
operator|=
name|new_object
expr_stmt|;
name|m
operator|->
name|pindex
operator|-=
name|offidxstart
expr_stmt|;
if|if
condition|(
name|vm_radix_insert
argument_list|(
operator|&
name|new_object
operator|->
name|cache
argument_list|,
name|m
argument_list|)
condition|)
name|vm_page_cache_turn_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Returns TRUE if a cached page is associated with the given object and  *	offset, and FALSE otherwise.  *  *	The object must be locked.  */
end_comment

begin_function
name|boolean_t
name|vm_page_is_cached
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
comment|/* 	 * Insertion into an object's collection of cached pages requires the 	 * object to be locked.  Therefore, if the object is locked and the 	 * object's collection is empty, there is no need to acquire the free 	 * page queues lock in order to prove that the specified page doesn't 	 * exist. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|__predict_true
argument_list|(
name|vm_object_cache_is_empty
argument_list|(
name|object
argument_list|)
argument_list|)
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|m
operator|=
name|vm_page_cache_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|!=
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_alloc:  *  *	Allocate and return a page that is associated with the specified  *	object and offset pair.  By default, this page is exclusive busied.  *  *	The caller must always specify an allocation class.  *  *	allocation classes:  *	VM_ALLOC_NORMAL		normal process request  *	VM_ALLOC_SYSTEM		system *really* needs a page  *	VM_ALLOC_INTERRUPT	interrupt time request  *  *	optional allocation flags:  *	VM_ALLOC_COUNT(number)	the number of additional pages that the caller  *				intends to allocate  *	VM_ALLOC_IFCACHED	return page only if it is cached  *	VM_ALLOC_IFNOTCACHED	return NULL, do not reactivate if the page  *				is cached  *	VM_ALLOC_NOBUSY		do not exclusive busy the page  *	VM_ALLOC_NODUMP		do not include the page in a kernel core dump  *	VM_ALLOC_NOOBJ		page is not associated with an object and  *				should not be exclusive busy   *	VM_ALLOC_SBUSY		shared busy the allocated page  *	VM_ALLOC_WIRED		wire the allocated page  *	VM_ALLOC_ZERO		prefer a zeroed page  *  *	This routine may not sleep.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_alloc
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|req
parameter_list|)
block|{
name|struct
name|vnode
modifier|*
name|vp
init|=
name|NULL
decl_stmt|;
name|vm_object_t
name|m_object
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mpred
decl_stmt|;
name|int
name|flags
decl_stmt|,
name|req_class
decl_stmt|;
name|mpred
operator|=
literal|0
expr_stmt|;
comment|/* XXX: pacify gcc */
name|KASSERT
argument_list|(
operator|(
name|object
operator|!=
name|NULL
operator|)
operator|==
operator|(
operator|(
name|req
operator|&
name|VM_ALLOC_NOOBJ
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|object
operator|!=
name|NULL
operator|||
operator|(
name|req
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
operator|(
name|req
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
operator|!=
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
argument_list|,
operator|(
literal|"vm_page_alloc: inconsistent object(%p)/req(%x)"
operator|,
operator|(
name|void
operator|*
operator|)
name|object
operator|,
name|req
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|req_class
operator|=
name|req
operator|&
name|VM_ALLOC_CLASS_MASK
expr_stmt|;
comment|/* 	 * The page daemon is allowed to dig deeper into the free page list. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
operator|&&
name|req_class
operator|!=
name|VM_ALLOC_INTERRUPT
condition|)
name|req_class
operator|=
name|VM_ALLOC_SYSTEM
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
name|mpred
operator|=
name|vm_radix_lookup_le
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpred
operator|==
name|NULL
operator|||
name|mpred
operator|->
name|pindex
operator|!=
name|pindex
argument_list|,
operator|(
literal|"vm_page_alloc: pindex already allocated"
operator|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * The page allocation request can came from consumers which already 	 * hold the free page queue mutex, like vm_page_insert() in 	 * vm_page_cache(). 	 */
name|mtx_lock_flags
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MTX_RECURSE
argument_list|)
expr_stmt|;
if|if
condition|(
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
name|cnt
operator|.
name|v_free_reserved
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_SYSTEM
operator|&&
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
name|cnt
operator|.
name|v_interrupt_free_min
operator|)
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_INTERRUPT
operator|&&
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
literal|0
operator|)
condition|)
block|{
comment|/* 		 * Allocate from the free queue if the number of free pages 		 * exceeds the minimum for the request class. 		 */
if|if
condition|(
name|object
operator|!=
name|NULL
operator|&&
operator|(
name|m
operator|=
name|vm_page_cache_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_IFNOTCACHED
operator|)
operator|!=
literal|0
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
if|if
condition|(
name|vm_phys_unfree_page
argument_list|(
name|m
argument_list|)
condition|)
name|vm_phys_set_pool
argument_list|(
name|VM_FREEPOOL_DEFAULT
argument_list|,
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
elseif|else
if|if
condition|(
operator|!
name|vm_reserv_reactivate_page
argument_list|(
name|m
argument_list|)
condition|)
else|#
directive|else
else|else
endif|#
directive|endif
name|panic
argument_list|(
literal|"vm_page_alloc: cache page %p is missing"
literal|" from the free queue"
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_IFCACHED
operator|)
operator|!=
literal|0
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
block|}
elseif|else
if|if
condition|(
name|object
operator|==
name|NULL
operator|||
operator|(
name|object
operator|->
name|flags
operator|&
operator|(
name|OBJ_COLORED
operator||
name|OBJ_FICTITIOUS
operator|)
operator|)
operator|!=
name|OBJ_COLORED
operator|||
operator|(
name|m
operator|=
name|vm_reserv_alloc_page
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|mpred
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
else|#
directive|else
block|}
else|else
block|{
endif|#
directive|endif
name|m
operator|=
name|vm_phys_alloc_pages
argument_list|(
name|object
operator|!=
name|NULL
condition|?
name|VM_FREEPOOL_DEFAULT
else|:
name|VM_FREEPOOL_DIRECT
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
name|m
operator|==
name|NULL
operator|&&
name|vm_reserv_reclaim_inactive
argument_list|()
condition|)
block|{
name|m
operator|=
name|vm_phys_alloc_pages
argument_list|(
name|object
operator|!=
name|NULL
condition|?
name|VM_FREEPOOL_DEFAULT
else|:
name|VM_FREEPOOL_DIRECT
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
block|}
else|else
block|{
comment|/* 		 * Not allocatable, give up. 		 */
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
name|max
argument_list|(
operator|(
name|u_int
operator|)
name|req
operator|>>
name|VM_ALLOC_COUNT_SHIFT
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
comment|/* 	 *  At this point we had better have found a good page. 	 */
name|KASSERT
argument_list|(
name|m
operator|!=
name|NULL
argument_list|,
operator|(
literal|"vm_page_alloc: missing page"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_alloc: page %p has unexpected queue %d"
operator|,
name|m
operator|,
name|m
operator|->
name|queue
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: page %p is wired"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|hold_count
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: page %p is held"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|vm_page_busied
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_alloc: page %p is busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: page %p is dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|==
name|VM_MEMATTR_DEFAULT
argument_list|,
operator|(
literal|"vm_page_alloc: page %p has unexpected memattr %d"
operator|,
name|m
operator|,
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CACHED
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: cached page %p is PG_ZERO"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: cached page %p is invalid"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|==
name|object
operator|&&
name|m
operator|->
name|pindex
operator|==
name|pindex
condition|)
name|cnt
operator|.
name|v_reactivated
operator|++
expr_stmt|;
else|else
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|m_object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|vm_page_cache_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_object
operator|->
name|type
operator|==
name|OBJT_VNODE
operator|&&
name|vm_object_cache_is_empty
argument_list|(
name|m_object
argument_list|)
condition|)
name|vp
operator|=
name|m_object
operator|->
name|handle
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
name|VM_PAGE_IS_FREE
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_alloc: page %p is not free"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: free page %p is valid"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vm_phys_freecnt_adj
argument_list|(
name|m
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Only the PG_ZERO flag is inherited.  The PG_CACHED or PG_FREE flag 	 * must be cleared before the free page queues lock is released. 	 */
name|flags
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
condition|)
block|{
name|vm_page_zero_count
operator|--
expr_stmt|;
if|if
condition|(
name|req
operator|&
name|VM_ALLOC_ZERO
condition|)
name|flags
operator|=
name|PG_ZERO
expr_stmt|;
block|}
if|if
condition|(
name|req
operator|&
name|VM_ALLOC_NODUMP
condition|)
name|flags
operator||=
name|PG_NODUMP
expr_stmt|;
name|m
operator|->
name|flags
operator|=
name|flags
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|m
operator|->
name|aflags
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|oflags
operator|=
name|object
operator|==
name|NULL
operator|||
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_UNMANAGED
operator|)
operator|!=
literal|0
condition|?
name|VPO_UNMANAGED
else|:
literal|0
expr_stmt|;
name|m
operator|->
name|busy_lock
operator|=
name|VPB_UNBUSIED
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
operator|==
literal|0
condition|)
name|m
operator|->
name|busy_lock
operator|=
name|VPB_SINGLE_EXCLUSIVER
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|!=
literal|0
condition|)
name|m
operator|->
name|busy_lock
operator|=
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|req
operator|&
name|VM_ALLOC_WIRED
condition|)
block|{
comment|/* 		 * The page lock is not required for wiring a page until that 		 * page is inserted into the object. 		 */
name|atomic_add_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
block|}
name|m
operator|->
name|act_count
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|vm_page_insert_after
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|,
name|mpred
argument_list|)
condition|)
block|{
comment|/* See the comment below about hold count. */
if|if
condition|(
name|vp
operator|!=
name|NULL
condition|)
name|vdrop
argument_list|(
name|vp
argument_list|)
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
if|if
condition|(
name|req
operator|&
name|VM_ALLOC_WIRED
condition|)
block|{
name|atomic_subtract_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
block|}
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|m
operator|->
name|oflags
operator|=
name|VPO_UNMANAGED
expr_stmt|;
name|m
operator|->
name|busy_lock
operator|=
name|VPB_UNBUSIED
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
comment|/* Ignore device objects; the pager sets "memattr" for them. */
if|if
condition|(
name|object
operator|->
name|memattr
operator|!=
name|VM_MEMATTR_DEFAULT
operator|&&
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|object
operator|->
name|memattr
argument_list|)
expr_stmt|;
block|}
else|else
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
comment|/* 	 * The following call to vdrop() must come after the above call 	 * to vm_page_insert() in case both affect the same object and 	 * vnode.  Otherwise, the affected vnode's hold count could 	 * temporarily become zero. 	 */
if|if
condition|(
name|vp
operator|!=
name|NULL
condition|)
name|vdrop
argument_list|(
name|vp
argument_list|)
expr_stmt|;
comment|/* 	 * Don't wakeup too often - wakeup the pageout daemon when 	 * we would be nearly out of memory. 	 */
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vm_page_alloc_contig_vdrop
parameter_list|(
name|struct
name|spglist
modifier|*
name|lst
parameter_list|)
block|{
while|while
condition|(
operator|!
name|SLIST_EMPTY
argument_list|(
name|lst
argument_list|)
condition|)
block|{
name|vdrop
argument_list|(
operator|(
expr|struct
name|vnode
operator|*
operator|)
name|SLIST_FIRST
argument_list|(
name|lst
argument_list|)
operator|->
name|plinks
operator|.
name|s
operator|.
name|pv
argument_list|)
expr_stmt|;
name|SLIST_REMOVE_HEAD
argument_list|(
name|lst
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_alloc_contig:  *  *	Allocate a contiguous set of physical pages of the given size "npages"  *	from the free lists.  All of the physical pages must be at or above  *	the given physical address "low" and below the given physical address  *	"high".  The given value "alignment" determines the alignment of the  *	first physical page in the set.  If the given value "boundary" is  *	non-zero, then the set of physical pages cannot cross any physical  *	address boundary that is a multiple of that value.  Both "alignment"  *	and "boundary" must be a power of two.  *  *	If the specified memory attribute, "memattr", is VM_MEMATTR_DEFAULT,  *	then the memory attribute setting for the physical pages is configured  *	to the object's memory attribute setting.  Otherwise, the memory  *	attribute setting for the physical pages is configured to "memattr",  *	overriding the object's memory attribute setting.  However, if the  *	object's memory attribute setting is not VM_MEMATTR_DEFAULT, then the  *	memory attribute setting for the physical pages cannot be configured  *	to VM_MEMATTR_DEFAULT.  *  *	The caller must always specify an allocation class.  *  *	allocation classes:  *	VM_ALLOC_NORMAL		normal process request  *	VM_ALLOC_SYSTEM		system *really* needs a page  *	VM_ALLOC_INTERRUPT	interrupt time request  *  *	optional allocation flags:  *	VM_ALLOC_NOBUSY		do not exclusive busy the page  *	VM_ALLOC_NODUMP		do not include the page in a kernel core dump  *	VM_ALLOC_NOOBJ		page is not associated with an object and  *				should not be exclusive busy   *	VM_ALLOC_SBUSY		shared busy the allocated page  *	VM_ALLOC_WIRED		wire the allocated page  *	VM_ALLOC_ZERO		prefer a zeroed page  *  *	This routine may not sleep.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_alloc_contig
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|req
parameter_list|,
name|u_long
name|npages
parameter_list|,
name|vm_paddr_t
name|low
parameter_list|,
name|vm_paddr_t
name|high
parameter_list|,
name|u_long
name|alignment
parameter_list|,
name|vm_paddr_t
name|boundary
parameter_list|,
name|vm_memattr_t
name|memattr
parameter_list|)
block|{
name|struct
name|vnode
modifier|*
name|drop
decl_stmt|;
name|struct
name|spglist
name|deferred_vdrop_list
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|m_tmp
decl_stmt|,
name|m_ret
decl_stmt|;
name|u_int
name|flags
decl_stmt|,
name|oflags
decl_stmt|;
name|int
name|req_class
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|object
operator|!=
name|NULL
operator|)
operator|==
operator|(
operator|(
name|req
operator|&
name|VM_ALLOC_NOOBJ
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|object
operator|!=
name|NULL
operator|||
operator|(
name|req
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
operator|(
name|req
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
operator|!=
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
argument_list|,
operator|(
literal|"vm_page_alloc: inconsistent object(%p)/req(%x)"
operator|,
operator|(
name|void
operator|*
operator|)
name|object
operator|,
name|req
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|object
operator|->
name|type
operator|==
name|OBJT_PHYS
argument_list|,
operator|(
literal|"vm_page_alloc_contig: object %p isn't OBJT_PHYS"
operator|,
name|object
operator|)
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|npages
operator|>
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_contig: npages is zero"
operator|)
argument_list|)
expr_stmt|;
name|req_class
operator|=
name|req
operator|&
name|VM_ALLOC_CLASS_MASK
expr_stmt|;
comment|/* 	 * The page daemon is allowed to dig deeper into the free page list. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
operator|&&
name|req_class
operator|!=
name|VM_ALLOC_INTERRUPT
condition|)
name|req_class
operator|=
name|VM_ALLOC_SYSTEM
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|deferred_vdrop_list
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>=
name|npages
operator|+
name|cnt
operator|.
name|v_free_reserved
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_SYSTEM
operator|&&
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>=
name|npages
operator|+
name|cnt
operator|.
name|v_interrupt_free_min
operator|)
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_INTERRUPT
operator|&&
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>=
name|npages
operator|)
condition|)
block|{
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
name|retry
label|:
if|if
condition|(
name|object
operator|==
name|NULL
operator|||
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_COLORED
operator|)
operator|==
literal|0
operator|||
operator|(
name|m_ret
operator|=
name|vm_reserv_alloc_contig
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|npages
argument_list|,
name|low
argument_list|,
name|high
argument_list|,
name|alignment
argument_list|,
name|boundary
argument_list|)
operator|)
operator|==
name|NULL
condition|)
endif|#
directive|endif
name|m_ret
operator|=
name|vm_phys_alloc_contig
argument_list|(
name|npages
argument_list|,
name|low
argument_list|,
name|high
argument_list|,
name|alignment
argument_list|,
name|boundary
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
name|npages
argument_list|)
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
if|if
condition|(
name|m_ret
operator|!=
name|NULL
condition|)
for|for
control|(
name|m
operator|=
name|m_ret
init|;
name|m
operator|<
operator|&
name|m_ret
index|[
name|npages
index|]
condition|;
name|m
operator|++
control|)
block|{
name|drop
operator|=
name|vm_page_alloc_init
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|drop
operator|!=
name|NULL
condition|)
block|{
comment|/* 				 * Enqueue the vnode for deferred vdrop(). 				 */
name|m
operator|->
name|plinks
operator|.
name|s
operator|.
name|pv
operator|=
name|drop
expr_stmt|;
name|SLIST_INSERT_HEAD
argument_list|(
operator|&
name|deferred_vdrop_list
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
name|vm_reserv_reclaim_contig
argument_list|(
name|npages
argument_list|,
name|low
argument_list|,
name|high
argument_list|,
name|alignment
argument_list|,
name|boundary
argument_list|)
condition|)
goto|goto
name|retry
goto|;
endif|#
directive|endif
block|}
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_ret
operator|==
name|NULL
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
comment|/* 	 * Initialize the pages.  Only the PG_ZERO flag is inherited. 	 */
name|flags
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_ZERO
operator|)
operator|!=
literal|0
condition|)
name|flags
operator|=
name|PG_ZERO
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_NODUMP
operator|)
operator|!=
literal|0
condition|)
name|flags
operator||=
name|PG_NODUMP
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
name|atomic_add_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
name|npages
argument_list|)
expr_stmt|;
name|oflags
operator|=
name|VPO_UNMANAGED
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|object
operator|->
name|memattr
operator|!=
name|VM_MEMATTR_DEFAULT
operator|&&
name|memattr
operator|==
name|VM_MEMATTR_DEFAULT
condition|)
name|memattr
operator|=
name|object
operator|->
name|memattr
expr_stmt|;
block|}
for|for
control|(
name|m
operator|=
name|m_ret
init|;
name|m
operator|<
operator|&
name|m_ret
index|[
name|npages
index|]
condition|;
name|m
operator|++
control|)
block|{
name|m
operator|->
name|aflags
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|flags
operator|=
operator|(
name|m
operator|->
name|flags
operator||
name|PG_NODUMP
operator|)
operator|&
name|flags
expr_stmt|;
name|m
operator|->
name|busy_lock
operator|=
name|VPB_UNBUSIED
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|req
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
operator|==
literal|0
condition|)
name|m
operator|->
name|busy_lock
operator|=
name|VPB_SINGLE_EXCLUSIVER
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|!=
literal|0
condition|)
name|m
operator|->
name|busy_lock
operator|=
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
comment|/* Unmanaged pages don't use "act_count". */
name|m
operator|->
name|oflags
operator|=
name|oflags
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|)
condition|)
block|{
name|vm_page_alloc_contig_vdrop
argument_list|(
operator|&
name|deferred_vdrop_list
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
name|atomic_subtract_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
name|npages
argument_list|)
expr_stmt|;
for|for
control|(
name|m_tmp
operator|=
name|m
operator|,
name|m
operator|=
name|m_ret
init|;
name|m
operator|<
operator|&
name|m_ret
index|[
name|npages
index|]
condition|;
name|m
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
name|m
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|m
operator|>=
name|m_tmp
condition|)
block|{
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|m
operator|->
name|oflags
operator||=
name|VPO_UNMANAGED
expr_stmt|;
block|}
name|m
operator|->
name|busy_lock
operator|=
name|VPB_UNBUSIED
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
block|}
else|else
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
if|if
condition|(
name|memattr
operator|!=
name|VM_MEMATTR_DEFAULT
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|memattr
argument_list|)
expr_stmt|;
name|pindex
operator|++
expr_stmt|;
block|}
name|vm_page_alloc_contig_vdrop
argument_list|(
operator|&
name|deferred_vdrop_list
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|m_ret
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Initialize a page that has been freshly dequeued from a freelist.  * The caller has to drop the vnode returned, if it is not NULL.  *  * This function may only be used to initialize unmanaged pages.  *  * To be called with vm_page_queue_free_mtx held.  */
end_comment

begin_function
specifier|static
name|struct
name|vnode
modifier|*
name|vm_page_alloc_init
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vnode
modifier|*
name|drop
decl_stmt|;
name|vm_object_t
name|m_object
decl_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p has unexpected queue %d"
operator|,
name|m
operator|,
name|m
operator|->
name|queue
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p is wired"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|hold_count
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p is held"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|vm_page_busied
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p is busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p is dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|==
name|VM_MEMATTR_DEFAULT
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p has unexpected memattr %d"
operator|,
name|m
operator|,
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|)
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|drop
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CACHED
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_init: cached page %p is PG_ZERO"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|m_object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|vm_page_cache_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_object
operator|->
name|type
operator|==
name|OBJT_VNODE
operator|&&
name|vm_object_cache_is_empty
argument_list|(
name|m_object
argument_list|)
condition|)
name|drop
operator|=
name|m_object
operator|->
name|handle
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
name|VM_PAGE_IS_FREE
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p is not free"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_init: free page %p is valid"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vm_phys_freecnt_adj
argument_list|(
name|m
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|!=
literal|0
condition|)
name|vm_page_zero_count
operator|--
expr_stmt|;
block|}
comment|/* Don't clear the PG_ZERO flag; we'll need it later. */
name|m
operator|->
name|flags
operator|&=
name|PG_ZERO
expr_stmt|;
return|return
operator|(
name|drop
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * 	vm_page_alloc_freelist:  *  *	Allocate a physical page from the specified free page list.  *  *	The caller must always specify an allocation class.  *  *	allocation classes:  *	VM_ALLOC_NORMAL		normal process request  *	VM_ALLOC_SYSTEM		system *really* needs a page  *	VM_ALLOC_INTERRUPT	interrupt time request  *  *	optional allocation flags:  *	VM_ALLOC_COUNT(number)	the number of additional pages that the caller  *				intends to allocate  *	VM_ALLOC_WIRED		wire the allocated page  *	VM_ALLOC_ZERO		prefer a zeroed page  *  *	This routine may not sleep.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_alloc_freelist
parameter_list|(
name|int
name|flind
parameter_list|,
name|int
name|req
parameter_list|)
block|{
name|struct
name|vnode
modifier|*
name|drop
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|u_int
name|flags
decl_stmt|;
name|int
name|req_class
decl_stmt|;
name|req_class
operator|=
name|req
operator|&
name|VM_ALLOC_CLASS_MASK
expr_stmt|;
comment|/* 	 * The page daemon is allowed to dig deeper into the free page list. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
operator|&&
name|req_class
operator|!=
name|VM_ALLOC_INTERRUPT
condition|)
name|req_class
operator|=
name|VM_ALLOC_SYSTEM
expr_stmt|;
comment|/* 	 * Do not allocate reserved pages unless the req has asked for it. 	 */
name|mtx_lock_flags
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MTX_RECURSE
argument_list|)
expr_stmt|;
if|if
condition|(
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
name|cnt
operator|.
name|v_free_reserved
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_SYSTEM
operator|&&
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
name|cnt
operator|.
name|v_interrupt_free_min
operator|)
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_INTERRUPT
operator|&&
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
literal|0
operator|)
condition|)
name|m
operator|=
name|vm_phys_alloc_freelist_pages
argument_list|(
name|flind
argument_list|,
name|VM_FREEPOOL_DIRECT
argument_list|,
literal|0
argument_list|)
expr_stmt|;
else|else
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
name|max
argument_list|(
operator|(
name|u_int
operator|)
name|req
operator|>>
name|VM_ALLOC_COUNT_SHIFT
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|drop
operator|=
name|vm_page_alloc_init
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the page.  Only the PG_ZERO flag is inherited. 	 */
name|m
operator|->
name|aflags
operator|=
literal|0
expr_stmt|;
name|flags
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_ZERO
operator|)
operator|!=
literal|0
condition|)
name|flags
operator|=
name|PG_ZERO
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
name|flags
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * The page lock is not required for wiring a page that does 		 * not belong to an object. 		 */
name|atomic_add_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
block|}
comment|/* Unmanaged pages don't use "act_count". */
name|m
operator|->
name|oflags
operator|=
name|VPO_UNMANAGED
expr_stmt|;
if|if
condition|(
name|drop
operator|!=
name|NULL
condition|)
name|vdrop
argument_list|(
name|drop
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_wait:	(also see VM_WAIT macro)  *  *	Sleep until free pages are available for allocation.  *	- Called in various places before memory allocations.  */
end_comment

begin_function
name|void
name|vm_wait
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|curproc
operator|==
name|pageproc
condition|)
block|{
name|vm_pageout_pages_needed
operator|=
literal|1
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PSWP
argument_list|,
literal|"VMWait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|vm_pages_needed
condition|)
block|{
name|vm_pages_needed
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pages_needed
argument_list|)
expr_stmt|;
block|}
name|msleep
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PVM
argument_list|,
literal|"vmwait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_waitpfault:	(also see VM_WAITPFAULT macro)  *  *	Sleep until free pages are available for allocation.  *	- Called only in vm_fault so that processes page faulting  *	  can be easily tracked.  *	- Sleeps at a lower priority than vm_wait() so that vm_wait()ing  *	  processes will be able to grab memory first.  Do not change  *	  this balance without careful testing first.  */
end_comment

begin_function
name|void
name|vm_waitpfault
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_pages_needed
condition|)
block|{
name|vm_pages_needed
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pages_needed
argument_list|)
expr_stmt|;
block|}
name|msleep
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PUSER
argument_list|,
literal|"pfault"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|struct
name|vm_pagequeue
modifier|*
name|vm_page_pagequeue
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
return|return
operator|(
operator|&
name|vm_phys_domain
argument_list|(
name|m
argument_list|)
operator|->
name|vmd_pagequeues
index|[
name|m
operator|->
name|queue
index|]
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_dequeue:  *  *	Remove the given page from its current page queue.  *  *	The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_dequeue
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|!=
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_dequeue: page %p is not queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pq
operator|=
name|vm_page_pagequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pagequeue_lock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_NONE
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|vm_pagequeue_cnt_dec
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|vm_pagequeue_unlock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_dequeue_locked:  *  *	Remove the given page from its current page queue.  *  *	The page and page queue must be locked.  */
end_comment

begin_function
name|void
name|vm_page_dequeue_locked
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pq
operator|=
name|vm_page_pagequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pagequeue_assert_locked
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_NONE
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|vm_pagequeue_cnt_dec
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_enqueue:  *  *	Add the given page to the specified page queue.  *  *	The page must be locked.  */
end_comment

begin_function
specifier|static
name|void
name|vm_page_enqueue
parameter_list|(
name|int
name|queue
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pq
operator|=
operator|&
name|vm_phys_domain
argument_list|(
name|m
argument_list|)
operator|->
name|vmd_pagequeues
index|[
name|queue
index|]
expr_stmt|;
name|vm_pagequeue_lock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|queue
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|vm_pagequeue_cnt_inc
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|vm_pagequeue_unlock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_requeue:  *  *	Move the given page to the tail of its current page queue.  *  *	The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_requeue
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|!=
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_requeue: page %p is not queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pq
operator|=
name|vm_page_pagequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pagequeue_lock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|vm_pagequeue_unlock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_requeue_locked:  *  *	Move the given page to the tail of its current page queue.  *  *	The page queue must be locked.  */
end_comment

begin_function
name|void
name|vm_page_requeue_locked
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|!=
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_requeue_locked: page %p is not queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pq
operator|=
name|vm_page_pagequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pagequeue_assert_locked
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_activate:  *  *	Put the specified page on the active list (if appropriate).  *	Ensure that act_count is at least ACT_INIT but do not otherwise  *	mess with it.  *  *	The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_activate
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|queue
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|queue
operator|=
name|m
operator|->
name|queue
operator|)
operator|!=
name|PQ_ACTIVE
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|<
name|ACT_INIT
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_INIT
expr_stmt|;
if|if
condition|(
name|queue
operator|!=
name|PQ_NONE
condition|)
name|vm_page_dequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_enqueue
argument_list|(
name|PQ_ACTIVE
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
else|else
name|KASSERT
argument_list|(
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_activate: wired page %p is queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|<
name|ACT_INIT
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_INIT
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_wakeup:  *  *	Helper routine for vm_page_free_toq() and vm_page_cache().  This  *	routine is called when a page has been added to the cache or free  *	queues.  *  *	The page queues must be locked.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|vm_page_free_wakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * if pageout daemon needs pages, then tell it that there are 	 * some free. 	 */
if|if
condition|(
name|vm_pageout_pages_needed
operator|&&
name|cnt
operator|.
name|v_cache_count
operator|+
name|cnt
operator|.
name|v_free_count
operator|>=
name|cnt
operator|.
name|v_pageout_free_min
condition|)
block|{
name|wakeup
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|)
expr_stmt|;
name|vm_pageout_pages_needed
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * wakeup processes that are waiting on memory if we hit a 	 * high water mark. And wakeup scheduler process if we have 	 * lots of memory. this process will swapin processes. 	 */
if|if
condition|(
name|vm_pages_needed
operator|&&
operator|!
name|vm_page_count_min
argument_list|()
condition|)
block|{
name|vm_pages_needed
operator|=
literal|0
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	Turn a cached page into a free page, by changing its attributes.  *	Keep the statistics up-to-date.  *  *	The free page queue must be locked.  */
end_comment

begin_function
specifier|static
name|void
name|vm_page_cache_turn_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
comment|/* Clear PG_CACHED and set PG_FREE. */
name|m
operator|->
name|flags
operator|^=
name|PG_CACHED
operator||
name|PG_FREE
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_CACHED
operator||
name|PG_FREE
operator|)
operator|)
operator|==
name|PG_FREE
argument_list|,
operator|(
literal|"vm_page_cache_free: page %p has inconsistent flags"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|cnt
operator|.
name|v_cache_count
operator|--
expr_stmt|;
name|vm_phys_freecnt_adj
argument_list|(
name|m
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_toq:  *  *	Returns the given page to the free list,  *	disassociating it with any VM object.  *  *	The object must be locked.  The page must be locked if it is managed.  */
end_comment

begin_function
name|void
name|vm_page_free_toq
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_free_toq: freeing mapped page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_free_toq: unmanaged page %p is queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|PCPU_INC
argument_list|(
name|cnt
operator|.
name|v_tfree
argument_list|)
expr_stmt|;
if|if
condition|(
name|VM_PAGE_IS_FREE
argument_list|(
name|m
argument_list|)
condition|)
name|panic
argument_list|(
literal|"vm_page_free: freeing free page %p"
argument_list|,
name|m
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|vm_page_sbusied
argument_list|(
name|m
argument_list|)
condition|)
name|panic
argument_list|(
literal|"vm_page_free: freeing busy page %p"
argument_list|,
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Unqueue, then remove page.  Note that we cannot destroy 	 * the page here because we do not want to call the pager's 	 * callback routine until after we've put the page on the 	 * appropriate free queue. 	 */
name|vm_page_remque
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * If fictitious remove object association and 	 * return, otherwise delay object association removal. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
return|return;
block|}
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|vm_page_undirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_page_free: freeing wired page %p"
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNHOLDFREE
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_free: freeing PG_UNHOLDFREE page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator||=
name|PG_UNHOLDFREE
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Restore the default memory attribute to the page. 		 */
if|if
condition|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|!=
name|VM_MEMATTR_DEFAULT
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
expr_stmt|;
comment|/* 		 * Insert the page into the physical memory allocator's 		 * cache/free page queues. 		 */
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator||=
name|PG_FREE
expr_stmt|;
name|vm_phys_freecnt_adj
argument_list|(
name|m
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
operator|!
name|vm_reserv_free_page
argument_list|(
name|m
argument_list|)
condition|)
else|#
directive|else
if|if
condition|(
name|TRUE
condition|)
endif|#
directive|endif
name|vm_phys_free_pages
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|!=
literal|0
condition|)
operator|++
name|vm_page_zero_count
expr_stmt|;
else|else
name|vm_page_zero_idle_wakeup
argument_list|()
expr_stmt|;
name|vm_page_free_wakeup
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_wire:  *  *	Mark this page as wired down by yet  *	another map, removing it from paging queues  *	as necessary.  *  *	If the page is fictitious, then its wire count must remain one.  *  *	The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_wire
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
comment|/* 	 * Only bump the wire statistics if the page is not already wired, 	 * and only unqueue the page if it is on some queue (if it is unmanaged 	 * it is already off the queues). 	 */
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|1
argument_list|,
operator|(
literal|"vm_page_wire: fictitious page %p's wire count isn't one"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|||
name|m
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_wire: unmanaged page %p is queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vm_page_remque
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
name|m
operator|->
name|wire_count
operator|++
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_wire: wire_count overflow m=%p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_unwire:  *  * Release one wiring of the specified page, potentially enabling it to be  * paged again.  If paging is enabled, then the value of the parameter  * "activate" determines to which queue the page is added.  If "activate" is  * non-zero, then the page is added to the active queue.  Otherwise, it is  * added to the inactive queue.  *  * However, unless the page belongs to an object, it is not enqueued because  * it cannot be paged out.  *  * If a page is fictitious, then its wire count must always be one.  *  * A managed page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_unwire
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|activate
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|1
argument_list|,
operator|(
literal|"vm_page_unwire: fictitious page %p's wire count isn't one"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|m
operator|->
name|wire_count
operator|>
literal|0
condition|)
block|{
name|m
operator|->
name|wire_count
operator|--
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|atomic_subtract_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
operator|||
name|m
operator|->
name|object
operator|==
name|NULL
condition|)
return|return;
if|if
condition|(
operator|!
name|activate
condition|)
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_WINATCFLS
expr_stmt|;
name|vm_page_enqueue
argument_list|(
name|activate
condition|?
name|PQ_ACTIVE
else|:
name|PQ_INACTIVE
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
block|}
else|else
name|panic
argument_list|(
literal|"vm_page_unwire: page %p's wire count is zero"
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Move the specified page to the inactive queue.  *  * Many pages placed on the inactive queue should actually go  * into the cache, but it is difficult to figure out which.  What  * we do instead, if the inactive target is well met, is to put  * clean pages at the head of the inactive queue instead of the tail.  * This will cause them to be moved to the cache more quickly and  * if not actively re-referenced, reclaimed more quickly.  If we just  * stick these pages at the end of the inactive queue, heavy filesystem  * meta-data accesses can cause an unnecessary paging load on memory bound   * processes.  This optimization causes one-time-use metadata to be  * reused more quickly.  *  * Normally athead is 0 resulting in LRU operation.  athead is set  * to 1 if we want this page to be 'as if it were placed in the cache',  * except without unmapping it from the process address space.  *  * The page must be locked.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|_vm_page_deactivate
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|athead
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|int
name|queue
decl_stmt|;
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Ignore if the page is already inactive, unless it is unlikely to be 	 * reactivated. 	 */
if|if
condition|(
operator|(
name|queue
operator|=
name|m
operator|->
name|queue
operator|)
operator|==
name|PQ_INACTIVE
operator|&&
operator|!
name|athead
condition|)
return|return;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|pq
operator|=
operator|&
name|vm_phys_domain
argument_list|(
name|m
argument_list|)
operator|->
name|vmd_pagequeues
index|[
name|PQ_INACTIVE
index|]
expr_stmt|;
comment|/* Avoid multiple acquisitions of the inactive queue lock. */
if|if
condition|(
name|queue
operator|==
name|PQ_INACTIVE
condition|)
block|{
name|vm_pagequeue_lock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|vm_page_dequeue_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|queue
operator|!=
name|PQ_NONE
condition|)
name|vm_page_dequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_WINATCFLS
expr_stmt|;
name|vm_pagequeue_lock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
name|m
operator|->
name|queue
operator|=
name|PQ_INACTIVE
expr_stmt|;
if|if
condition|(
name|athead
condition|)
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|vm_pagequeue_cnt_inc
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|vm_pagequeue_unlock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Move the specified page to the inactive queue.  *  * The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_deactivate
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|_vm_page_deactivate
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_try_to_cache:  *  * Returns 0 on failure, 1 on success  */
end_comment

begin_function
name|int
name|vm_page_try_to_cache
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|wire_count
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
operator|||
name|vm_page_busied
argument_list|(
name|m
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|vm_page_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_page_try_to_free()  *  *	Attempt to free the page.  If we cannot free it, we do nothing.  *	1 is returned on success, 0 on failure.  */
end_comment

begin_function
name|int
name|vm_page_try_to_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|NULL
condition|)
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|wire_count
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
operator|||
name|vm_page_busied
argument_list|(
name|m
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_page_cache  *  * Put the specified page onto the page cache queue (if appropriate).  *  * The object and page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_cache
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|boolean_t
name|cache_was_empty
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_busied
argument_list|(
name|m
argument_list|)
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|wire_count
condition|)
name|panic
argument_list|(
literal|"vm_page_cache: attempting to cache busy page"
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_cache: page %p is mapped"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_cache: page %p is dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|==
literal|0
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_DEFAULT
operator|||
operator|(
name|object
operator|->
name|type
operator|==
name|OBJT_SWAP
operator|&&
operator|!
name|vm_pager_has_page
argument_list|(
name|object
argument_list|,
name|m
operator|->
name|pindex
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
operator|)
condition|)
block|{
comment|/* 		 * Hypothesis: A cache-elgible page belonging to a 		 * default object or swap object but without a backing 		 * store must be zero filled. 		 */
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return;
block|}
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CACHED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_cache: page %p is already cached"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Remove the page from the paging queues. 	 */
name|vm_page_remque
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Remove the page from the object's collection of resident 	 * pages.  	 */
name|vm_radix_remove
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
name|object
operator|->
name|resident_page_count
operator|--
expr_stmt|;
comment|/* 	 * Restore the default memory attribute to the page. 	 */
if|if
condition|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|!=
name|VM_MEMATTR_DEFAULT
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
expr_stmt|;
comment|/* 	 * Insert the page into the object's collection of cached pages 	 * and the physical memory allocator's cache/free page queues. 	 */
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|cache_was_empty
operator|=
name|vm_radix_is_empty
argument_list|(
operator|&
name|object
operator|->
name|cache
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_radix_insert
argument_list|(
operator|&
name|object
operator|->
name|cache
argument_list|,
name|m
argument_list|)
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
operator|&&
name|object
operator|->
name|resident_page_count
operator|==
literal|0
condition|)
name|vdrop
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * The above call to vm_radix_insert() could reclaim the one pre- 	 * existing cached page from this object, resulting in a call to 	 * vdrop(). 	 */
if|if
condition|(
operator|!
name|cache_was_empty
condition|)
name|cache_was_empty
operator|=
name|vm_radix_is_singleton
argument_list|(
operator|&
name|object
operator|->
name|cache
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator||=
name|PG_CACHED
expr_stmt|;
name|cnt
operator|.
name|v_cache_count
operator|++
expr_stmt|;
name|PCPU_INC
argument_list|(
name|cnt
operator|.
name|v_tcached
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
operator|!
name|vm_reserv_free_page
argument_list|(
name|m
argument_list|)
condition|)
block|{
else|#
directive|else
if|if
condition|(
name|TRUE
condition|)
block|{
endif|#
directive|endif
name|vm_phys_set_pool
argument_list|(
name|VM_FREEPOOL_CACHE
argument_list|,
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|vm_phys_free_pages
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|vm_page_free_wakeup
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Increment the vnode's hold count if this is the object's only 	 * cached page.  Decrement the vnode's hold count if this was 	 * the object's only resident page. 	 */
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
block|{
if|if
condition|(
name|cache_was_empty
operator|&&
name|object
operator|->
name|resident_page_count
operator|!=
literal|0
condition|)
name|vhold
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
operator|!
name|cache_was_empty
operator|&&
name|object
operator|->
name|resident_page_count
operator|==
literal|0
condition|)
name|vdrop
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*  * vm_page_advise  *  * 	Deactivate or do nothing, as appropriate.  This routine is used  * 	by madvise() and vop_stdadvise().  *  *	The object and page must be locked.  */
name|void
name|vm_page_advise
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|advice
parameter_list|)
block|{
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|advice
operator|==
name|MADV_FREE
condition|)
comment|/* 		 * Mark the page clean.  This will allow the page to be freed 		 * up by the system.  However, such pages are often reused 		 * quickly by malloc() so we do not do anything that would 		 * cause a page fault if we can help it. 		 * 		 * Specifically, we do not try to actually free the page now 		 * nor do we try to put it in the cache (which would cause a 		 * page fault on reuse). 		 * 		 * But we do make the page as freeable as we can without 		 * actually taking the step of unmapping it. 		 */
name|vm_page_undirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|advice
operator|!=
name|MADV_DONTNEED
condition|)
return|return;
comment|/* 	 * Clear any references to the page.  Otherwise, the page daemon will 	 * immediately reactivate the page. 	 */
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
if|if
condition|(
name|advice
operator|!=
name|MADV_FREE
operator|&&
name|m
operator|->
name|dirty
operator|==
literal|0
operator|&&
name|pmap_is_modified
argument_list|(
name|m
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Place clean pages at the head of the inactive queue rather than the 	 * tail, thus defeating the queue's LRU operation and ensuring that the 	 * page will be reused quickly. 	 */
name|_vm_page_deactivate
argument_list|(
name|m
argument_list|,
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/*  * Grab a page, waiting until we are waken up due to the page  * changing state.  We keep on waiting, if the page continues  * to be in the object.  If the page doesn't exist, first allocate it  * and then conditionally zero it.  *  * This routine may sleep.  *  * The object must be locked on entry.  The lock will, however, be released  * and reacquired if the routine sleeps.  */
name|vm_page_t
name|vm_page_grab
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|allocflags
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|sleep
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|==
literal|0
operator|||
operator|(
name|allocflags
operator|&
name|VM_ALLOC_IGN_SBUSY
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_grab: VM_ALLOC_SBUSY/VM_ALLOC_IGN_SBUSY mismatch"
operator|)
argument_list|)
expr_stmt|;
name|retrylookup
label|:
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|sleep
operator|=
operator|(
name|allocflags
operator|&
name|VM_ALLOC_IGN_SBUSY
operator|)
operator|!=
literal|0
condition|?
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
else|:
name|vm_page_busied
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|sleep
condition|)
block|{
comment|/* 			 * Reference the page before unlocking and 			 * sleeping so that the page daemon is less 			 * likely to reclaim it. 			 */
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_busy_sleep
argument_list|(
name|m
argument_list|,
literal|"pgrbwt"
argument_list|,
operator|(
name|allocflags
operator|&
name|VM_ALLOC_IGN_SBUSY
operator|)
operator|!=
literal|0
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|retrylookup
goto|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
block|{
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_wire
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|allocflags
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
operator|==
literal|0
condition|)
name|vm_page_xbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|!=
literal|0
condition|)
name|vm_page_sbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
block|}
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|allocflags
operator|&
operator|~
name|VM_ALLOC_IGN_SBUSY
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|retrylookup
goto|;
block|}
elseif|else
if|if
condition|(
name|m
operator|->
name|valid
operator|!=
literal|0
condition|)
return|return
operator|(
name|m
operator|)
return|;
if|if
condition|(
name|allocflags
operator|&
name|VM_ALLOC_ZERO
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
comment|/*  * Mapping function for valid or dirty bits in a page.  *  * Inputs are required to range within a page.  */
name|vm_page_bits_t
name|vm_page_bits
parameter_list|(
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|first_bit
decl_stmt|;
name|int
name|last_bit
decl_stmt|;
name|KASSERT
argument_list|(
name|base
operator|+
name|size
operator|<=
name|PAGE_SIZE
argument_list|,
operator|(
literal|"vm_page_bits: illegal base/size %d/%d"
operator|,
name|base
operator|,
name|size
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return
operator|(
literal|0
operator|)
return|;
name|first_bit
operator|=
name|base
operator|>>
name|DEV_BSHIFT
expr_stmt|;
name|last_bit
operator|=
operator|(
name|base
operator|+
name|size
operator|-
literal|1
operator|)
operator|>>
name|DEV_BSHIFT
expr_stmt|;
return|return
operator|(
operator|(
operator|(
name|vm_page_bits_t
operator|)
literal|2
operator|<<
name|last_bit
operator|)
operator|-
operator|(
operator|(
name|vm_page_bits_t
operator|)
literal|1
operator|<<
name|first_bit
operator|)
operator|)
return|;
block|}
comment|/*  *	vm_page_set_valid_range:  *  *	Sets portions of a page valid.  The arguments are expected  *	to be DEV_BSIZE aligned but if they aren't the bitmap is inclusive  *	of any partial chunks touched by the range.  The invalid portion of  *	such chunks will be zeroed.  *  *	(base + size) must be less then or equal to PAGE_SIZE.  */
name|void
name|vm_page_set_valid_range
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|endoff
decl_stmt|,
name|frag
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return;
comment|/* 	 * If the base is not DEV_BSIZE aligned and the valid 	 * bit is clear, we have to zero out a portion of the 	 * first block. 	 */
if|if
condition|(
operator|(
name|frag
operator|=
name|base
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|base
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|base
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|frag
argument_list|,
name|base
operator|-
name|frag
argument_list|)
expr_stmt|;
comment|/* 	 * If the ending offset is not DEV_BSIZE aligned and the  	 * valid bit is clear, we have to zero out a portion of 	 * the last block. 	 */
name|endoff
operator|=
name|base
operator|+
name|size
expr_stmt|;
if|if
condition|(
operator|(
name|frag
operator|=
name|endoff
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|endoff
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|endoff
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|endoff
argument_list|,
name|DEV_BSIZE
operator|-
operator|(
name|endoff
operator|&
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Assert that no previously invalid block that is now being validated 	 * is already dirty.  	 */
name|KASSERT
argument_list|(
operator|(
operator|~
name|m
operator|->
name|valid
operator|&
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
operator|&
name|m
operator|->
name|dirty
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_set_valid_range: page %p is dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Set valid bits inclusive of any overlap. 	 */
name|m
operator|->
name|valid
operator||=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
comment|/*  * Clear the given bits from the specified page's dirty field.  */
specifier|static
name|__inline
name|void
name|vm_page_clear_dirty_mask
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_page_bits_t
name|pagebits
parameter_list|)
block|{
name|uintptr_t
name|addr
decl_stmt|;
if|#
directive|if
name|PAGE_SIZE
operator|<
literal|16384
name|int
name|shift
decl_stmt|;
endif|#
directive|endif
comment|/* 	 * If the object is locked and the page is neither exclusive busy nor 	 * write mapped, then the page's dirty field cannot possibly be 	 * set by a concurrent pmap operation. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|!
name|pmap_page_is_write_mapped
argument_list|(
name|m
argument_list|)
condition|)
name|m
operator|->
name|dirty
operator|&=
operator|~
name|pagebits
expr_stmt|;
else|else
block|{
comment|/* 		 * The pmap layer can call vm_page_dirty() without 		 * holding a distinguished lock.  The combination of 		 * the object's lock and an atomic operation suffice 		 * to guarantee consistency of the page dirty field. 		 * 		 * For PAGE_SIZE == 32768 case, compiler already 		 * properly aligns the dirty field, so no forcible 		 * alignment is needed. Only require existence of 		 * atomic_clear_64 when page size is 32768. 		 */
name|addr
operator|=
operator|(
name|uintptr_t
operator|)
operator|&
name|m
operator|->
name|dirty
expr_stmt|;
if|#
directive|if
name|PAGE_SIZE
operator|==
literal|32768
name|atomic_clear_64
argument_list|(
operator|(
name|uint64_t
operator|*
operator|)
name|addr
argument_list|,
name|pagebits
argument_list|)
expr_stmt|;
elif|#
directive|elif
name|PAGE_SIZE
operator|==
literal|16384
name|atomic_clear_32
argument_list|(
operator|(
name|uint32_t
operator|*
operator|)
name|addr
argument_list|,
name|pagebits
argument_list|)
expr_stmt|;
else|#
directive|else
comment|/* PAGE_SIZE<= 8192 */
comment|/* 		 * Use a trick to perform a 32-bit atomic on the 		 * containing aligned word, to not depend on the existence 		 * of atomic_clear_{8, 16}. 		 */
name|shift
operator|=
name|addr
operator|&
operator|(
sizeof|sizeof
argument_list|(
name|uint32_t
argument_list|)
operator|-
literal|1
operator|)
expr_stmt|;
if|#
directive|if
name|BYTE_ORDER
operator|==
name|BIG_ENDIAN
name|shift
operator|=
operator|(
sizeof|sizeof
argument_list|(
name|uint32_t
argument_list|)
operator|-
sizeof|sizeof
argument_list|(
name|m
operator|->
name|dirty
argument_list|)
operator|-
name|shift
operator|)
operator|*
name|NBBY
expr_stmt|;
else|#
directive|else
name|shift
operator|*=
name|NBBY
expr_stmt|;
endif|#
directive|endif
name|addr
operator|&=
operator|~
operator|(
sizeof|sizeof
argument_list|(
name|uint32_t
argument_list|)
operator|-
literal|1
operator|)
expr_stmt|;
name|atomic_clear_32
argument_list|(
operator|(
name|uint32_t
operator|*
operator|)
name|addr
argument_list|,
name|pagebits
operator|<<
name|shift
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* PAGE_SIZE */
block|}
block|}
comment|/*  *	vm_page_set_validclean:  *  *	Sets portions of a page valid and clean.  The arguments are expected  *	to be DEV_BSIZE aligned but if they aren't the bitmap is inclusive  *	of any partial chunks touched by the range.  The invalid portion of  *	such chunks will be zero'd.  *  *	(base + size) must be less then or equal to PAGE_SIZE.  */
name|void
name|vm_page_set_validclean
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_bits_t
name|oldvalid
decl_stmt|,
name|pagebits
decl_stmt|;
name|int
name|endoff
decl_stmt|,
name|frag
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return;
comment|/* 	 * If the base is not DEV_BSIZE aligned and the valid 	 * bit is clear, we have to zero out a portion of the 	 * first block. 	 */
if|if
condition|(
operator|(
name|frag
operator|=
name|base
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|base
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
operator|(
name|vm_page_bits_t
operator|)
literal|1
operator|<<
operator|(
name|base
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|frag
argument_list|,
name|base
operator|-
name|frag
argument_list|)
expr_stmt|;
comment|/* 	 * If the ending offset is not DEV_BSIZE aligned and the  	 * valid bit is clear, we have to zero out a portion of 	 * the last block. 	 */
name|endoff
operator|=
name|base
operator|+
name|size
expr_stmt|;
if|if
condition|(
operator|(
name|frag
operator|=
name|endoff
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|endoff
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
operator|(
name|vm_page_bits_t
operator|)
literal|1
operator|<<
operator|(
name|endoff
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|endoff
argument_list|,
name|DEV_BSIZE
operator|-
operator|(
name|endoff
operator|&
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Set valid, clear dirty bits.  If validating the entire 	 * page we can safely clear the pmap modify bit.  We also 	 * use this opportunity to clear the VPO_NOSYNC flag.  If a process 	 * takes a write fault on a MAP_NOSYNC memory area the flag will 	 * be set again. 	 * 	 * We set valid bits inclusive of any overlap, but we can only 	 * clear dirty bits for DEV_BSIZE chunks that are fully within 	 * the range. 	 */
name|oldvalid
operator|=
name|m
operator|->
name|valid
expr_stmt|;
name|pagebits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator||=
name|pagebits
expr_stmt|;
if|#
directive|if
literal|0
comment|/* NOT YET */
block|if ((frag = base& (DEV_BSIZE - 1)) != 0) { 		frag = DEV_BSIZE - frag; 		base += frag; 		size -= frag; 		if (size< 0) 			size = 0; 	} 	pagebits = vm_page_bits(base, size& (DEV_BSIZE - 1));
endif|#
directive|endif
if|if
condition|(
name|base
operator|==
literal|0
operator|&&
name|size
operator|==
name|PAGE_SIZE
condition|)
block|{
comment|/* 		 * The page can only be modified within the pmap if it is 		 * mapped, and it can only be mapped if it was previously 		 * fully valid. 		 */
if|if
condition|(
name|oldvalid
operator|==
name|VM_PAGE_BITS_ALL
condition|)
comment|/* 			 * Perform the pmap_clear_modify() first.  Otherwise, 			 * a concurrent pmap operation, such as 			 * pmap_protect(), could clear a modification in the 			 * pmap and set the dirty field on the page before 			 * pmap_clear_modify() had begun and after the dirty 			 * field was cleared here. 			 */
name|pmap_clear_modify
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|dirty
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|oflags
operator|&=
operator|~
name|VPO_NOSYNC
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|oldvalid
operator|!=
name|VM_PAGE_BITS_ALL
condition|)
name|m
operator|->
name|dirty
operator|&=
operator|~
name|pagebits
expr_stmt|;
else|else
name|vm_page_clear_dirty_mask
argument_list|(
name|m
argument_list|,
name|pagebits
argument_list|)
expr_stmt|;
block|}
name|void
name|vm_page_clear_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_clear_dirty_mask
argument_list|(
name|m
argument_list|,
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/*  *	vm_page_set_invalid:  *  *	Invalidates DEV_BSIZE'd chunks within a page.  Both the  *	valid and dirty bits for the effected areas are cleared.  */
name|void
name|vm_page_set_invalid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_bits_t
name|bits
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
operator|&&
name|base
operator|==
literal|0
operator|&&
name|IDX_TO_OFF
argument_list|(
name|m
operator|->
name|pindex
argument_list|)
operator|+
name|size
operator|>=
name|object
operator|->
name|un_pager
operator|.
name|vnp
operator|.
name|vnp_size
condition|)
name|bits
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
else|else
name|bits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|ref_count
operator|!=
literal|0
operator|&&
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|&&
name|bits
operator|!=
literal|0
condition|)
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bits
operator|==
literal|0
operator|&&
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|)
operator|||
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_set_invalid: page %p is mapped"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator|&=
operator|~
name|bits
expr_stmt|;
name|m
operator|->
name|dirty
operator|&=
operator|~
name|bits
expr_stmt|;
block|}
comment|/*  * vm_page_zero_invalid()  *  *	The kernel assumes that the invalid portions of a page contain   *	garbage, but such pages can be mapped into memory by user code.  *	When this occurs, we must zero out the non-valid portions of the  *	page so user code sees what it expects.  *  *	Pages are most often semi-valid when the end of a file is mapped   *	into memory and the file's size is not page aligned.  */
name|void
name|vm_page_zero_invalid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|boolean_t
name|setvalid
parameter_list|)
block|{
name|int
name|b
decl_stmt|;
name|int
name|i
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
comment|/* 	 * Scan the valid bits looking for invalid sections that 	 * must be zeroed.  Invalid sub-DEV_BSIZE'd areas ( where the 	 * valid bit may be set ) have already been zeroed by 	 * vm_page_set_validclean(). 	 */
for|for
control|(
name|b
operator|=
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|PAGE_SIZE
operator|/
name|DEV_BSIZE
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|i
operator|==
operator|(
name|PAGE_SIZE
operator|/
name|DEV_BSIZE
operator|)
operator|||
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
operator|(
name|vm_page_bits_t
operator|)
literal|1
operator|<<
name|i
operator|)
operator|)
condition|)
block|{
if|if
condition|(
name|i
operator|>
name|b
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|b
operator|<<
name|DEV_BSHIFT
argument_list|,
operator|(
name|i
operator|-
name|b
operator|)
operator|<<
name|DEV_BSHIFT
argument_list|)
expr_stmt|;
block|}
name|b
operator|=
name|i
operator|+
literal|1
expr_stmt|;
block|}
block|}
comment|/* 	 * setvalid is TRUE when we can safely set the zero'd areas 	 * as being valid.  We can do this if there are no cache consistancy 	 * issues.  e.g. it is ok to do with UFS, but not ok to do with NFS. 	 */
if|if
condition|(
name|setvalid
condition|)
name|m
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
block|}
comment|/*  *	vm_page_is_valid:  *  *	Is (partial) page valid?  Note that the case where size == 0  *	will return FALSE in the degenerate case where the page is  *	entirely invalid, and TRUE otherwise.  */
name|int
name|vm_page_is_valid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_bits_t
name|bits
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|bits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|->
name|valid
operator|!=
literal|0
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
name|bits
operator|)
operator|==
name|bits
operator|)
return|;
block|}
comment|/*  *	vm_page_ps_is_valid:  *  *	Returns TRUE if the entire (super)page is valid and FALSE otherwise.  */
name|boolean_t
name|vm_page_ps_is_valid
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|npages
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|npages
operator|=
name|atop
argument_list|(
name|pagesizes
index|[
name|m
operator|->
name|psind
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * The physically contiguous pages that make up a superpage, i.e., a 	 * page with a page size index ("psind") greater than zero, will 	 * occupy adjacent entries in vm_page_array[]. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|npages
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|m
index|[
name|i
index|]
operator|.
name|valid
operator|!=
name|VM_PAGE_BITS_ALL
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
comment|/*  * Set the page's dirty bits if the page is modified.  */
name|void
name|vm_page_test_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|!=
name|VM_PAGE_BITS_ALL
operator|&&
name|pmap_is_modified
argument_list|(
name|m
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|void
name|vm_page_lock_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|file
parameter_list|,
name|int
name|line
parameter_list|)
block|{
name|mtx_lock_flags_
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|,
literal|0
argument_list|,
name|file
argument_list|,
name|line
argument_list|)
expr_stmt|;
block|}
name|void
name|vm_page_unlock_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|file
parameter_list|,
name|int
name|line
parameter_list|)
block|{
name|mtx_unlock_flags_
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|,
literal|0
argument_list|,
name|file
argument_list|,
name|line
argument_list|)
expr_stmt|;
block|}
name|int
name|vm_page_trylock_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|file
parameter_list|,
name|int
name|line
parameter_list|)
block|{
return|return
operator|(
name|mtx_trylock_flags_
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|,
literal|0
argument_list|,
name|file
argument_list|,
name|line
argument_list|)
operator|)
return|;
block|}
if|#
directive|if
name|defined
argument_list|(
name|INVARIANTS
argument_list|)
operator|||
name|defined
argument_list|(
name|INVARIANT_SUPPORT
argument_list|)
name|void
name|vm_page_assert_locked_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|file
parameter_list|,
name|int
name|line
parameter_list|)
block|{
name|vm_page_lock_assert_KBI
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|,
name|file
argument_list|,
name|line
argument_list|)
expr_stmt|;
block|}
name|void
name|vm_page_lock_assert_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|a
parameter_list|,
specifier|const
name|char
modifier|*
name|file
parameter_list|,
name|int
name|line
parameter_list|)
block|{
name|mtx_assert_
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|,
name|a
argument_list|,
name|file
argument_list|,
name|line
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
ifdef|#
directive|ifdef
name|INVARIANTS
name|void
name|vm_page_object_lock_assert
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
comment|/* 	 * Certain of the page's fields may only be modified by the 	 * holder of the containing object's lock or the exclusive busy. 	 * holder.  Unfortunately, the holder of the write busy is 	 * not recorded, and thus cannot be checked here. 	 */
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|NULL
operator|&&
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
block|}
name|void
name|vm_page_assert_pga_writeable
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|uint8_t
name|bits
parameter_list|)
block|{
if|if
condition|(
operator|(
name|bits
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
comment|/* 	 * The PGA_WRITEABLE flag can only be set if the page is 	 * managed, is exclusively busied or the object is locked. 	 * Currently, this flag is only set by pmap_enter(). 	 */
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"PGA_WRITEABLE on unmanaged page"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
include|#
directive|include
file|"opt_ddb.h"
ifdef|#
directive|ifdef
name|DDB
include|#
directive|include
file|<sys/kernel.h>
include|#
directive|include
file|<ddb/ddb.h>
name|DB_SHOW_COMMAND
argument_list|(
argument|page
argument_list|,
argument|vm_page_print_page_info
argument_list|)
block|{
name|db_printf
argument_list|(
literal|"cnt.v_free_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_cache_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_cache_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_inactive_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_inactive_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_active_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_active_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_wire_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_wire_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_reserved: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_reserved
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_min: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_min
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_target: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_target
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_cache_min: %d\n"
argument_list|,
name|cnt
operator|.
name|v_cache_min
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_inactive_target: %d\n"
argument_list|,
name|cnt
operator|.
name|v_inactive_target
argument_list|)
expr_stmt|;
block|}
name|DB_SHOW_COMMAND
argument_list|(
argument|pageq
argument_list|,
argument|vm_page_print_pageq_info
argument_list|)
block|{
name|int
name|dom
decl_stmt|;
name|db_printf
argument_list|(
literal|"pq_free %d pq_cache %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_count
argument_list|,
name|cnt
operator|.
name|v_cache_count
argument_list|)
expr_stmt|;
for|for
control|(
name|dom
operator|=
literal|0
init|;
name|dom
operator|<
name|vm_ndomains
condition|;
name|dom
operator|++
control|)
block|{
name|db_printf
argument_list|(
literal|"dom %d page_cnt %d free %d pq_act %d pq_inact %d pass %d\n"
argument_list|,
name|dom
argument_list|,
name|vm_dom
index|[
name|dom
index|]
operator|.
name|vmd_page_count
argument_list|,
name|vm_dom
index|[
name|dom
index|]
operator|.
name|vmd_free_count
argument_list|,
name|vm_dom
index|[
name|dom
index|]
operator|.
name|vmd_pagequeues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pq_cnt
argument_list|,
name|vm_dom
index|[
name|dom
index|]
operator|.
name|vmd_pagequeues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pq_cnt
argument_list|,
name|vm_dom
index|[
name|dom
index|]
operator|.
name|vmd_pass
argument_list|)
expr_stmt|;
block|}
block|}
name|DB_SHOW_COMMAND
argument_list|(
argument|pginfo
argument_list|,
argument|vm_page_print_pginfo
argument_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|boolean_t
name|phys
decl_stmt|;
if|if
condition|(
operator|!
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"show pginfo addr\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|phys
operator|=
name|strchr
argument_list|(
name|modif
argument_list|,
literal|'p'
argument_list|)
operator|!=
name|NULL
expr_stmt|;
if|if
condition|(
name|phys
condition|)
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|addr
argument_list|)
expr_stmt|;
else|else
name|m
operator|=
operator|(
name|vm_page_t
operator|)
name|addr
expr_stmt|;
name|db_printf
argument_list|(
literal|"page %p obj %p pidx 0x%jx phys 0x%jx q %d hold %d wire %d\n"
literal|"  af 0x%x of 0x%x f 0x%x act %d busy %x valid 0x%x dirty 0x%x\n"
argument_list|,
name|m
argument_list|,
name|m
operator|->
name|object
argument_list|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|pindex
argument_list|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|phys_addr
argument_list|,
name|m
operator|->
name|queue
argument_list|,
name|m
operator|->
name|hold_count
argument_list|,
name|m
operator|->
name|wire_count
argument_list|,
name|m
operator|->
name|aflags
argument_list|,
name|m
operator|->
name|oflags
argument_list|,
name|m
operator|->
name|flags
argument_list|,
name|m
operator|->
name|act_count
argument_list|,
name|m
operator|->
name|busy_lock
argument_list|,
name|m
operator|->
name|valid
argument_list|,
name|m
operator|->
name|dirty
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* DDB */
end_comment

end_unit

