begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1991 Regents of the University of California.  * All rights reserved.  * Copyright (c) 1998 Matthew Dillon.  All Rights Reserved.  *  * This code is derived from software contributed to Berkeley by  * The Mach Operating System project at Carnegie-Mellon University.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from: @(#)vm_page.c	7.4 (Berkeley) 5/7/91  */
end_comment

begin_comment
comment|/*-  * Copyright (c) 1987, 1990 Carnegie-Mellon University.  * All rights reserved.  *  * Authors: Avadis Tevanian, Jr., Michael Wayne Young  *  * Permission to use, copy, modify and distribute this software and  * its documentation is hereby granted, provided that both the copyright  * notice and this permission notice appear in all copies of the  * software, derivative works or modified versions, and any portions  * thereof, and that both notices appear in supporting documentation.  *  * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"  * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND  * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.  *  * Carnegie Mellon requests users of this software to return to  *  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU  *  School of Computer Science  *  Carnegie Mellon University  *  Pittsburgh PA 15213-3890  *  * any improvements or extensions that they make and grant Carnegie the  * rights to redistribute these changes.  */
end_comment

begin_comment
comment|/*  *			GENERAL RULES ON VM_PAGE MANIPULATION  *  *	- A page queue lock is required when adding or removing a page from a  *	  page queue regardless of other locks or the busy state of a page.  *  *		* In general, no thread besides the page daemon can acquire or  *		  hold more than one page queue lock at a time.  *  *		* The page daemon can acquire and hold any pair of page queue  *		  locks in any order.  *  *	- The object lock is required when inserting or removing  *	  pages from an object (vm_page_insert() or vm_page_remove()).  *  */
end_comment

begin_comment
comment|/*  *	Resident memory management module.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_vm.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/limits.h>
end_include

begin_include
include|#
directive|include
file|<sys/linker.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mman.h>
end_include

begin_include
include|#
directive|include
file|<sys/msgbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/sbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/pmap.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_phys.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_radix.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_reserv.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma_int.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_comment
comment|/*  *	Associated with page of user-allocatable memory is a  *	page structure.  */
end_comment

begin_decl_stmt
name|struct
name|vm_domain
name|vm_dom
index|[
name|MAXMEMDOM
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mtx_padalign
name|vm_page_queue_free_mtx
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mtx_padalign
name|pa_lock
index|[
name|PA_LOCK_COUNT
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_page_t
name|vm_page_array
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|long
name|vm_page_array_size
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|long
name|first_page
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|vm_page_zero_count
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|boot_pages
init|=
name|UMA_BOOT_PAGES
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|boot_pages
argument_list|,
name|CTLFLAG_RDTUN
operator||
name|CTLFLAG_NOFETCH
argument_list|,
operator|&
name|boot_pages
argument_list|,
literal|0
argument_list|,
literal|"number of pages allocated for bootstrapping the VM system"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pa_tryrelock_restart
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|tryrelock_restart
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pa_tryrelock_restart
argument_list|,
literal|0
argument_list|,
literal|"Number of tryrelock restarts"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
specifier|static
name|TAILQ_HEAD
argument_list|(
argument_list|,
argument|vm_page
argument_list|)
name|blacklist_head
expr_stmt|;
end_expr_stmt

begin_function_decl
specifier|static
name|int
name|sysctl_vm_page_blacklist
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
function_decl|;
end_function_decl

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|page_blacklist
argument_list|,
name|CTLTYPE_STRING
operator||
name|CTLFLAG_RD
operator||
name|CTLFLAG_MPSAFE
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
name|sysctl_vm_page_blacklist
argument_list|,
literal|"A"
argument_list|,
literal|"Blacklist pages"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/* Is the page daemon waiting for free pages? */
end_comment

begin_decl_stmt
specifier|static
name|int
name|vm_pageout_pages_needed
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|uma_zone_t
name|fakepg_zone
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|void
name|vm_page_alloc_check
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_clear_dirty_mask
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_page_bits_t
name|pagebits
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_enqueue
parameter_list|(
name|uint8_t
name|queue
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_free_wakeup
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_init_fakepg
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vm_page_insert_after
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_page_t
name|mpred
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_insert_radixdone
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_page_t
name|mpred
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vm_page_reclaim_run
parameter_list|(
name|int
name|req_class
parameter_list|,
name|u_long
name|npages
parameter_list|,
name|vm_page_t
name|m_run
parameter_list|,
name|vm_paddr_t
name|high
parameter_list|)
function_decl|;
end_function_decl

begin_expr_stmt
name|SYSINIT
argument_list|(
name|vm_page
argument_list|,
name|SI_SUB_VM
argument_list|,
name|SI_ORDER_SECOND
argument_list|,
name|vm_page_init_fakepg
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|void
name|vm_page_init_fakepg
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|fakepg_zone
operator|=
name|uma_zcreate
argument_list|(
literal|"fakepg"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|UMA_ALIGN_PTR
argument_list|,
name|UMA_ZONE_NOFREE
operator||
name|UMA_ZONE_VM
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Make sure that u_long is at least 64 bits when PAGE_SIZE is 32K. */
end_comment

begin_if
if|#
directive|if
name|PAGE_SIZE
operator|==
literal|32768
end_if

begin_ifdef
ifdef|#
directive|ifdef
name|CTASSERT
end_ifdef

begin_expr_stmt
name|CTASSERT
argument_list|(
sizeof|sizeof
argument_list|(
name|u_long
argument_list|)
operator|>=
literal|8
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Try to acquire a physical address lock while a pmap is locked.  If we  * fail to trylock we unlock and lock the pmap directly and cache the  * locked pa in *locked.  The caller should then restart their loop in case  * the virtual to physical mapping has changed.  */
end_comment

begin_function
name|int
name|vm_page_pa_tryrelock
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_paddr_t
modifier|*
name|locked
parameter_list|)
block|{
name|vm_paddr_t
name|lockpa
decl_stmt|;
name|lockpa
operator|=
operator|*
name|locked
expr_stmt|;
operator|*
name|locked
operator|=
name|pa
expr_stmt|;
if|if
condition|(
name|lockpa
condition|)
block|{
name|PA_LOCK_ASSERT
argument_list|(
name|lockpa
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|PA_LOCKPTR
argument_list|(
name|pa
argument_list|)
operator|==
name|PA_LOCKPTR
argument_list|(
name|lockpa
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|PA_UNLOCK
argument_list|(
name|lockpa
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|PA_TRYLOCK
argument_list|(
name|pa
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|pa_tryrelock_restart
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|PA_LOCK
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|EAGAIN
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_set_page_size:  *  *	Sets the page size, perhaps based upon the memory  *	size.  Must be called before any use of page-size  *	dependent functions.  */
end_comment

begin_function
name|void
name|vm_set_page_size
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|vm_cnt
operator|.
name|v_page_size
operator|==
literal|0
condition|)
name|vm_cnt
operator|.
name|v_page_size
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|vm_cnt
operator|.
name|v_page_size
operator|-
literal|1
operator|)
operator|&
name|vm_cnt
operator|.
name|v_page_size
operator|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_set_page_size: page size not a power of two"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_blacklist_next:  *  *	Find the next entry in the provided string of blacklist  *	addresses.  Entries are separated by space, comma, or newline.  *	If an invalid integer is encountered then the rest of the  *	string is skipped.  Updates the list pointer to the next  *	character, or NULL if the string is exhausted or invalid.  */
end_comment

begin_function
specifier|static
name|vm_paddr_t
name|vm_page_blacklist_next
parameter_list|(
name|char
modifier|*
modifier|*
name|list
parameter_list|,
name|char
modifier|*
name|end
parameter_list|)
block|{
name|vm_paddr_t
name|bad
decl_stmt|;
name|char
modifier|*
name|cp
decl_stmt|,
modifier|*
name|pos
decl_stmt|;
if|if
condition|(
name|list
operator|==
name|NULL
operator|||
operator|*
name|list
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|if
condition|(
operator|*
operator|*
name|list
operator|==
literal|'\0'
condition|)
block|{
operator|*
name|list
operator|=
name|NULL
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
comment|/* 	 * If there's no end pointer then the buffer is coming from 	 * the kenv and we know it's null-terminated. 	 */
if|if
condition|(
name|end
operator|==
name|NULL
condition|)
name|end
operator|=
operator|*
name|list
operator|+
name|strlen
argument_list|(
operator|*
name|list
argument_list|)
expr_stmt|;
comment|/* Ensure that strtoq() won't walk off the end */
if|if
condition|(
operator|*
name|end
operator|!=
literal|'\0'
condition|)
block|{
if|if
condition|(
operator|*
name|end
operator|==
literal|'\n'
operator|||
operator|*
name|end
operator|==
literal|' '
operator|||
operator|*
name|end
operator|==
literal|','
condition|)
operator|*
name|end
operator|=
literal|'\0'
expr_stmt|;
else|else
block|{
name|printf
argument_list|(
literal|"Blacklist not terminated, skipping\n"
argument_list|)
expr_stmt|;
operator|*
name|list
operator|=
name|NULL
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
block|}
for|for
control|(
name|pos
operator|=
operator|*
name|list
init|;
operator|*
name|pos
operator|!=
literal|'\0'
condition|;
name|pos
operator|=
name|cp
control|)
block|{
name|bad
operator|=
name|strtoq
argument_list|(
name|pos
argument_list|,
operator|&
name|cp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cp
operator|==
literal|'\0'
operator|||
operator|*
name|cp
operator|==
literal|' '
operator|||
operator|*
name|cp
operator|==
literal|','
operator|||
operator|*
name|cp
operator|==
literal|'\n'
condition|)
block|{
if|if
condition|(
name|bad
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|++
name|cp
operator|<
name|end
condition|)
continue|continue;
else|else
break|break;
block|}
block|}
else|else
break|break;
if|if
condition|(
operator|*
name|cp
operator|==
literal|'\0'
operator|||
operator|++
name|cp
operator|>=
name|end
condition|)
operator|*
name|list
operator|=
name|NULL
expr_stmt|;
else|else
operator|*
name|list
operator|=
name|cp
expr_stmt|;
return|return
operator|(
name|trunc_page
argument_list|(
name|bad
argument_list|)
operator|)
return|;
block|}
name|printf
argument_list|(
literal|"Garbage in RAM blacklist, skipping\n"
argument_list|)
expr_stmt|;
operator|*
name|list
operator|=
name|NULL
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_blacklist_check:  *  *	Iterate through the provided string of blacklist addresses, pulling  *	each entry out of the physical allocator free list and putting it  *	onto a list for reporting via the vm.page_blacklist sysctl.  */
end_comment

begin_function
specifier|static
name|void
name|vm_page_blacklist_check
parameter_list|(
name|char
modifier|*
name|list
parameter_list|,
name|char
modifier|*
name|end
parameter_list|)
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|char
modifier|*
name|next
decl_stmt|;
name|int
name|ret
decl_stmt|;
name|next
operator|=
name|list
expr_stmt|;
while|while
condition|(
name|next
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|pa
operator|=
name|vm_page_blacklist_next
argument_list|(
operator|&
name|next
argument_list|,
name|end
argument_list|)
operator|)
operator|==
literal|0
condition|)
continue|continue;
name|m
operator|=
name|vm_phys_paddr_to_vm_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
continue|continue;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|ret
operator|=
name|vm_phys_unfree_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|ret
operator|==
name|TRUE
condition|)
block|{
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|blacklist_head
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
if|if
condition|(
name|bootverbose
condition|)
name|printf
argument_list|(
literal|"Skipping page with pa 0x%jx\n"
argument_list|,
operator|(
name|uintmax_t
operator|)
name|pa
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_blacklist_load:  *  *	Search for a special module named "ram_blacklist".  It'll be a  *	plain text file provided by the user via the loader directive  *	of the same name.  */
end_comment

begin_function
specifier|static
name|void
name|vm_page_blacklist_load
parameter_list|(
name|char
modifier|*
modifier|*
name|list
parameter_list|,
name|char
modifier|*
modifier|*
name|end
parameter_list|)
block|{
name|void
modifier|*
name|mod
decl_stmt|;
name|u_char
modifier|*
name|ptr
decl_stmt|;
name|u_int
name|len
decl_stmt|;
name|mod
operator|=
name|NULL
expr_stmt|;
name|ptr
operator|=
name|NULL
expr_stmt|;
name|mod
operator|=
name|preload_search_by_type
argument_list|(
literal|"ram_blacklist"
argument_list|)
expr_stmt|;
if|if
condition|(
name|mod
operator|!=
name|NULL
condition|)
block|{
name|ptr
operator|=
name|preload_fetch_addr
argument_list|(
name|mod
argument_list|)
expr_stmt|;
name|len
operator|=
name|preload_fetch_size
argument_list|(
name|mod
argument_list|)
expr_stmt|;
block|}
operator|*
name|list
operator|=
name|ptr
expr_stmt|;
if|if
condition|(
name|ptr
operator|!=
name|NULL
condition|)
operator|*
name|end
operator|=
name|ptr
operator|+
name|len
expr_stmt|;
else|else
operator|*
name|end
operator|=
name|NULL
expr_stmt|;
return|return;
block|}
end_function

begin_function
specifier|static
name|int
name|sysctl_vm_page_blacklist
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|struct
name|sbuf
name|sbuf
decl_stmt|;
name|int
name|error
decl_stmt|,
name|first
decl_stmt|;
name|first
operator|=
literal|1
expr_stmt|;
name|error
operator|=
name|sysctl_wire_old_buffer
argument_list|(
name|req
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
return|return
operator|(
name|error
operator|)
return|;
name|sbuf_new_for_sysctl
argument_list|(
operator|&
name|sbuf
argument_list|,
name|NULL
argument_list|,
literal|128
argument_list|,
name|req
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|m
argument_list|,
argument|&blacklist_head
argument_list|,
argument|listq
argument_list|)
block|{
name|sbuf_printf
argument_list|(
operator|&
name|sbuf
argument_list|,
literal|"%s%#jx"
argument_list|,
name|first
condition|?
literal|""
else|:
literal|","
argument_list|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|phys_addr
argument_list|)
expr_stmt|;
name|first
operator|=
literal|0
expr_stmt|;
block|}
name|error
operator|=
name|sbuf_finish
argument_list|(
operator|&
name|sbuf
argument_list|)
expr_stmt|;
name|sbuf_delete
argument_list|(
operator|&
name|sbuf
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vm_page_domain_init
parameter_list|(
name|struct
name|vm_domain
modifier|*
name|vmd
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|int
name|i
decl_stmt|;
operator|*
name|__DECONST
argument_list|(
name|char
operator|*
operator|*
argument_list|,
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pq_name
argument_list|)
operator|=
literal|"vm inactive pagequeue"
expr_stmt|;
operator|*
name|__DECONST
argument_list|(
name|u_int
operator|*
operator|*
argument_list|,
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pq_vcnt
argument_list|)
operator|=
operator|&
name|vm_cnt
operator|.
name|v_inactive_count
expr_stmt|;
operator|*
name|__DECONST
argument_list|(
name|char
operator|*
operator|*
argument_list|,
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pq_name
argument_list|)
operator|=
literal|"vm active pagequeue"
expr_stmt|;
operator|*
name|__DECONST
argument_list|(
name|u_int
operator|*
operator|*
argument_list|,
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pq_vcnt
argument_list|)
operator|=
operator|&
name|vm_cnt
operator|.
name|v_active_count
expr_stmt|;
operator|*
name|__DECONST
argument_list|(
name|char
operator|*
operator|*
argument_list|,
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|PQ_LAUNDRY
index|]
operator|.
name|pq_name
argument_list|)
operator|=
literal|"vm laundry pagequeue"
expr_stmt|;
operator|*
name|__DECONST
argument_list|(
name|int
operator|*
operator|*
argument_list|,
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|PQ_LAUNDRY
index|]
operator|.
name|pq_vcnt
argument_list|)
operator|=
operator|&
name|vm_cnt
operator|.
name|v_laundry_count
expr_stmt|;
name|vmd
operator|->
name|vmd_page_count
operator|=
literal|0
expr_stmt|;
name|vmd
operator|->
name|vmd_free_count
operator|=
literal|0
expr_stmt|;
name|vmd
operator|->
name|vmd_segs
operator|=
literal|0
expr_stmt|;
name|vmd
operator|->
name|vmd_oom
operator|=
name|FALSE
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PQ_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|pq
operator|=
operator|&
name|vmd
operator|->
name|vmd_pagequeues
index|[
name|i
index|]
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|pq
operator|->
name|pq_mutex
argument_list|,
name|pq
operator|->
name|pq_name
argument_list|,
literal|"vm pagequeue"
argument_list|,
name|MTX_DEF
operator||
name|MTX_DUPOK
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_startup:  *  *	Initializes the resident memory module.  Allocates physical memory for  *	bootstrapping UMA and some data structures that are used to manage  *	physical pages.  Initializes these structures, and populates the free  *	page queues.  */
end_comment

begin_function
name|vm_offset_t
name|vm_page_startup
parameter_list|(
name|vm_offset_t
name|vaddr
parameter_list|)
block|{
name|vm_offset_t
name|mapped
decl_stmt|;
name|vm_paddr_t
name|high_avail
decl_stmt|,
name|low_avail
decl_stmt|,
name|page_range
decl_stmt|,
name|size
decl_stmt|;
name|vm_paddr_t
name|new_end
decl_stmt|;
name|int
name|i
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_paddr_t
name|last_pa
decl_stmt|;
name|char
modifier|*
name|list
decl_stmt|,
modifier|*
name|listend
decl_stmt|;
name|vm_paddr_t
name|end
decl_stmt|;
name|vm_paddr_t
name|biggestsize
decl_stmt|;
name|int
name|biggestone
decl_stmt|;
name|int
name|pages_per_zone
decl_stmt|;
name|biggestsize
operator|=
literal|0
expr_stmt|;
name|biggestone
operator|=
literal|0
expr_stmt|;
name|vaddr
operator|=
name|round_page
argument_list|(
name|vaddr
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|phys_avail
index|[
name|i
index|]
operator|=
name|round_page
argument_list|(
name|phys_avail
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|=
name|trunc_page
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|size
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|size
operator|>
name|biggestsize
condition|)
block|{
name|biggestone
operator|=
name|i
expr_stmt|;
name|biggestsize
operator|=
name|size
expr_stmt|;
block|}
block|}
name|end
operator|=
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
expr_stmt|;
comment|/* 	 * Initialize the page and queue locks. 	 */
name|mtx_init
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
literal|"vm page free queue"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PA_LOCK_COUNT
condition|;
name|i
operator|++
control|)
name|mtx_init
argument_list|(
operator|&
name|pa_lock
index|[
name|i
index|]
argument_list|,
literal|"vm page"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|vm_ndomains
condition|;
name|i
operator|++
control|)
name|vm_page_domain_init
argument_list|(
operator|&
name|vm_dom
index|[
name|i
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * Almost all of the pages needed for bootstrapping UMA are used 	 * for zone structures, so if the number of CPUs results in those 	 * structures taking more than one page each, we set aside more pages 	 * in proportion to the zone structure size. 	 */
name|pages_per_zone
operator|=
name|howmany
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|uma_zone
argument_list|)
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|uma_cache
argument_list|)
operator|*
operator|(
name|mp_maxid
operator|+
literal|1
operator|)
argument_list|,
name|UMA_SLAB_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|pages_per_zone
operator|>
literal|1
condition|)
block|{
comment|/* Reserve more pages so that we don't run out. */
name|boot_pages
operator|=
name|UMA_BOOT_PAGES_ZONES
operator|*
name|pages_per_zone
expr_stmt|;
block|}
comment|/* 	 * Allocate memory for use when boot strapping the kernel memory 	 * allocator. 	 * 	 * CTFLAG_RDTUN doesn't work during the early boot process, so we must 	 * manually fetch the value. 	 */
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.boot_pages"
argument_list|,
operator|&
name|boot_pages
argument_list|)
expr_stmt|;
name|new_end
operator|=
name|end
operator|-
operator|(
name|boot_pages
operator|*
name|UMA_SLAB_SIZE
operator|)
expr_stmt|;
name|new_end
operator|=
name|trunc_page
argument_list|(
name|new_end
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|end
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|mapped
argument_list|,
name|end
operator|-
name|new_end
argument_list|)
expr_stmt|;
name|uma_startup
argument_list|(
operator|(
name|void
operator|*
operator|)
name|mapped
argument_list|,
name|boot_pages
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|__aarch64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__arm__
argument_list|)
operator|||
expr|\
name|defined
argument_list|(
name|__i386__
argument_list|)
operator|||
name|defined
argument_list|(
name|__mips__
argument_list|)
comment|/* 	 * Allocate a bitmap to indicate that a random physical page 	 * needs to be included in a minidump. 	 * 	 * The amd64 port needs this to indicate which direct map pages 	 * need to be dumped, via calls to dump_add_page()/dump_drop_page(). 	 * 	 * However, i386 still needs this workspace internally within the 	 * minidump code.  In theory, they are not needed on i386, but are 	 * included should the sf_buf code decide to use them. 	 */
name|last_pa
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|dump_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
if|if
condition|(
name|dump_avail
index|[
name|i
operator|+
literal|1
index|]
operator|>
name|last_pa
condition|)
name|last_pa
operator|=
name|dump_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
name|page_range
operator|=
name|last_pa
operator|/
name|PAGE_SIZE
expr_stmt|;
name|vm_page_dump_size
operator|=
name|round_page
argument_list|(
name|roundup2
argument_list|(
name|page_range
argument_list|,
name|NBBY
argument_list|)
operator|/
name|NBBY
argument_list|)
expr_stmt|;
name|new_end
operator|-=
name|vm_page_dump_size
expr_stmt|;
name|vm_page_dump
operator|=
operator|(
name|void
operator|*
operator|)
operator|(
name|uintptr_t
operator|)
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|new_end
operator|+
name|vm_page_dump_size
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|vm_page_dump
argument_list|,
name|vm_page_dump_size
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|#
directive|if
name|defined
argument_list|(
name|__aarch64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__mips__
argument_list|)
comment|/* 	 * Include the UMA bootstrap pages and vm_page_dump in a crash dump. 	 * When pmap_map() uses the direct map, they are not automatically  	 * included. 	 */
for|for
control|(
name|pa
operator|=
name|new_end
init|;
name|pa
operator|<
name|end
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|dump_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
operator|=
name|new_end
expr_stmt|;
ifdef|#
directive|ifdef
name|__amd64__
comment|/* 	 * Request that the physical pages underlying the message buffer be 	 * included in a crash dump.  Since the message buffer is accessed 	 * through the direct map, they are not automatically included. 	 */
name|pa
operator|=
name|DMAP_TO_PHYS
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|msgbufp
operator|->
name|msg_ptr
argument_list|)
expr_stmt|;
name|last_pa
operator|=
name|pa
operator|+
name|round_page
argument_list|(
name|msgbufsize
argument_list|)
expr_stmt|;
while|while
condition|(
name|pa
operator|<
name|last_pa
condition|)
block|{
name|dump_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* 	 * Compute the number of pages of memory that will be available for 	 * use, taking into account the overhead of a page structure per page. 	 * In other words, solve 	 *	"available physical memory" - round_page(page_range * 	 *	    sizeof(struct vm_page)) = page_range * PAGE_SIZE  	 * for page_range.   	 */
name|low_avail
operator|=
name|phys_avail
index|[
literal|0
index|]
expr_stmt|;
name|high_avail
operator|=
name|phys_avail
index|[
literal|1
index|]
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|vm_phys_nsegs
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|start
operator|<
name|low_avail
condition|)
name|low_avail
operator|=
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|start
expr_stmt|;
if|if
condition|(
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|end
operator|>
name|high_avail
condition|)
name|high_avail
operator|=
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|end
expr_stmt|;
block|}
comment|/* Skip the first chunk.  It is already accounted for. */
for|for
control|(
name|i
operator|=
literal|2
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
block|{
if|if
condition|(
name|phys_avail
index|[
name|i
index|]
operator|<
name|low_avail
condition|)
name|low_avail
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|>
name|high_avail
condition|)
name|high_avail
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
block|}
name|first_page
operator|=
name|low_avail
operator|/
name|PAGE_SIZE
expr_stmt|;
ifdef|#
directive|ifdef
name|VM_PHYSSEG_SPARSE
name|size
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|vm_phys_nsegs
condition|;
name|i
operator|++
control|)
name|size
operator|+=
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|end
operator|-
name|vm_phys_segs
index|[
name|i
index|]
operator|.
name|start
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
name|size
operator|+=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
name|page_range
operator|=
name|size
operator|/
operator|(
name|PAGE_SIZE
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
operator|)
expr_stmt|;
elif|#
directive|elif
name|defined
argument_list|(
name|VM_PHYSSEG_DENSE
argument_list|)
comment|/* 	 * In the VM_PHYSSEG_DENSE case, the number of pages can account for 	 * the overhead of a page structure per page only if vm_page_array is 	 * allocated from the last physical memory chunk.  Otherwise, we must 	 * allocate page structures representing the physical memory 	 * underlying vm_page_array, even though they will not be used. 	 */
if|if
condition|(
name|new_end
operator|==
name|high_avail
condition|)
name|page_range
operator|=
operator|(
name|high_avail
operator|-
name|low_avail
operator|)
operator|/
operator|(
name|PAGE_SIZE
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
operator|)
expr_stmt|;
else|else
name|page_range
operator|=
name|high_avail
operator|/
name|PAGE_SIZE
operator|-
name|first_page
expr_stmt|;
else|#
directive|else
error|#
directive|error
literal|"Either VM_PHYSSEG_DENSE or VM_PHYSSEG_SPARSE must be defined."
endif|#
directive|endif
name|end
operator|=
name|new_end
expr_stmt|;
comment|/* 	 * Reserve an unmapped guard page to trap access to vm_page_array[-1]. 	 * However, because this page is allocated from KVM, out-of-bounds 	 * accesses using the direct map will not be trapped. 	 */
name|vaddr
operator|+=
name|PAGE_SIZE
expr_stmt|;
comment|/* 	 * Allocate physical memory for the page structures, and map it. 	 */
name|new_end
operator|=
name|trunc_page
argument_list|(
name|end
operator|-
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|end
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|vm_page_array
operator|=
operator|(
name|vm_page_t
operator|)
name|mapped
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
comment|/* 	 * Allocate physical memory for the reservation management system's 	 * data structures, and map it. 	 */
if|if
condition|(
name|high_avail
operator|==
name|end
condition|)
name|high_avail
operator|=
name|new_end
expr_stmt|;
name|new_end
operator|=
name|vm_reserv_startup
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|high_avail
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|#
directive|if
name|defined
argument_list|(
name|__aarch64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__mips__
argument_list|)
comment|/* 	 * Include vm_page_array and vm_reserv_array in a crash dump. 	 */
for|for
control|(
name|pa
operator|=
name|new_end
init|;
name|pa
operator|<
name|end
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|dump_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
operator|=
name|new_end
expr_stmt|;
comment|/* 	 * Add physical memory segments corresponding to the available 	 * physical pages. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
name|vm_phys_add_seg
argument_list|(
name|phys_avail
index|[
name|i
index|]
argument_list|,
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * Clear all of the page structures 	 */
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|vm_page_array
argument_list|,
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|page_range
condition|;
name|i
operator|++
control|)
name|vm_page_array
index|[
name|i
index|]
operator|.
name|order
operator|=
name|VM_NFREEORDER
expr_stmt|;
name|vm_page_array_size
operator|=
name|page_range
expr_stmt|;
comment|/* 	 * Initialize the physical memory allocator. 	 */
name|vm_phys_init
argument_list|()
expr_stmt|;
comment|/* 	 * Add every available physical page that is not blacklisted to 	 * the free lists. 	 */
name|vm_cnt
operator|.
name|v_page_count
operator|=
literal|0
expr_stmt|;
name|vm_cnt
operator|.
name|v_free_count
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|pa
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
name|last_pa
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
while|while
condition|(
name|pa
operator|<
name|last_pa
condition|)
block|{
name|vm_phys_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
name|TAILQ_INIT
argument_list|(
operator|&
name|blacklist_head
argument_list|)
expr_stmt|;
name|vm_page_blacklist_load
argument_list|(
operator|&
name|list
argument_list|,
operator|&
name|listend
argument_list|)
expr_stmt|;
name|vm_page_blacklist_check
argument_list|(
name|list
argument_list|,
name|listend
argument_list|)
expr_stmt|;
name|list
operator|=
name|kern_getenv
argument_list|(
literal|"vm.blacklist"
argument_list|)
expr_stmt|;
name|vm_page_blacklist_check
argument_list|(
name|list
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|freeenv
argument_list|(
name|list
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
comment|/* 	 * Initialize the reservation management system. 	 */
name|vm_reserv_init
argument_list|()
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
name|vaddr
operator|)
return|;
block|}
end_function

begin_function
name|void
name|vm_page_reference
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_busy_downgrade:  *  *	Downgrade an exclusive busy page into a single shared busy page.  */
end_comment

begin_function
name|void
name|vm_page_busy_downgrade
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
name|bool
name|locked
decl_stmt|;
name|vm_page_assert_xbusied
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|locked
operator|=
name|mtx_owned
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
name|x
operator|&=
name|VPB_BIT_WAITERS
expr_stmt|;
if|if
condition|(
name|x
operator|!=
literal|0
operator|&&
operator|!
name|locked
condition|)
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|atomic_cmpset_rel_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|VPB_SINGLE_EXCLUSIVER
operator||
name|x
argument_list|,
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
argument_list|)
condition|)
break|break;
if|if
condition|(
name|x
operator|!=
literal|0
operator|&&
operator|!
name|locked
condition|)
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|x
operator|!=
literal|0
condition|)
block|{
name|wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|locked
condition|)
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_sbusied:  *  *	Return a positive value if the page is shared busied, 0 otherwise.  */
end_comment

begin_function
name|int
name|vm_page_sbusied
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
return|return
operator|(
operator|(
name|x
operator|&
name|VPB_BIT_SHARED
operator|)
operator|!=
literal|0
operator|&&
name|x
operator|!=
name|VPB_UNBUSIED
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_sunbusy:  *  *	Shared unbusy a page.  */
end_comment

begin_function
name|void
name|vm_page_sunbusy
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
name|vm_page_assert_sbusied
argument_list|(
name|m
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
if|if
condition|(
name|VPB_SHARERS
argument_list|(
name|x
argument_list|)
operator|>
literal|1
condition|)
block|{
if|if
condition|(
name|atomic_cmpset_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|x
argument_list|,
name|x
operator|-
name|VPB_ONE_SHARER
argument_list|)
condition|)
break|break;
continue|continue;
block|}
if|if
condition|(
operator|(
name|x
operator|&
name|VPB_BIT_WAITERS
operator|)
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|x
operator|==
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
argument_list|,
operator|(
literal|"vm_page_sunbusy: invalid lock state"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|atomic_cmpset_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
argument_list|,
name|VPB_UNBUSIED
argument_list|)
condition|)
break|break;
continue|continue;
block|}
name|KASSERT
argument_list|(
name|x
operator|==
operator|(
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
operator||
name|VPB_BIT_WAITERS
operator|)
argument_list|,
operator|(
literal|"vm_page_sunbusy: invalid lock state for waiters"
operator|)
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|atomic_cmpset_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|x
argument_list|,
name|VPB_UNBUSIED
argument_list|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_busy_sleep:  *  *	Sleep and release the page lock, using the page pointer as wchan.  *	This is used to implement the hard-path of busying mechanism.  *  *	The given page must be locked.  *  *	If nonshared is true, sleep only if the page is xbusy.  */
end_comment

begin_function
name|void
name|vm_page_busy_sleep
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|wmesg
parameter_list|,
name|bool
name|nonshared
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
if|if
condition|(
name|x
operator|==
name|VPB_UNBUSIED
operator|||
operator|(
name|nonshared
operator|&&
operator|(
name|x
operator|&
name|VPB_BIT_SHARED
operator|)
operator|!=
literal|0
operator|)
operator|||
operator|(
operator|(
name|x
operator|&
name|VPB_BIT_WAITERS
operator|)
operator|==
literal|0
operator|&&
operator|!
name|atomic_cmpset_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|x
argument_list|,
name|x
operator||
name|VPB_BIT_WAITERS
argument_list|)
operator|)
condition|)
block|{
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return;
block|}
name|msleep
argument_list|(
name|m
argument_list|,
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|,
name|PVM
operator||
name|PDROP
argument_list|,
name|wmesg
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_trysbusy:  *  *	Try to shared busy a page.  *	If the operation succeeds 1 is returned otherwise 0.  *	The operation never sleeps.  */
end_comment

begin_function
name|int
name|vm_page_trysbusy
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
if|if
condition|(
operator|(
name|x
operator|&
name|VPB_BIT_SHARED
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|if
condition|(
name|atomic_cmpset_acq_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|x
argument_list|,
name|x
operator|+
name|VPB_ONE_SHARER
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|vm_page_xunbusy_locked
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_assert_xbusied
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|atomic_store_rel_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|VPB_UNBUSIED
argument_list|)
expr_stmt|;
comment|/* There is a waiter, do wakeup() instead of vm_page_flash(). */
name|wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_xunbusy_maybelocked
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|bool
name|lockacq
decl_stmt|;
name|vm_page_assert_xbusied
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Fast path for unbusy.  If it succeeds, we know that there 	 * are no waiters, so we do not need a wakeup. 	 */
if|if
condition|(
name|atomic_cmpset_rel_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|VPB_SINGLE_EXCLUSIVER
argument_list|,
name|VPB_UNBUSIED
argument_list|)
condition|)
return|return;
name|lockacq
operator|=
operator|!
name|mtx_owned
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|lockacq
condition|)
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_xunbusy_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|lockacq
condition|)
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_xunbusy_hard:  *  *	Called after the first try the exclusive unbusy of a page failed.  *	It is assumed that the waiters bit is on.  */
end_comment

begin_function
name|void
name|vm_page_xunbusy_hard
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_assert_xbusied
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_xunbusy_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_flash:  *  *	Wakeup anyone waiting for the page.  *	The ownership bits do not change.  *  *	The given page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_flash
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|u_int
name|x
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|x
operator|=
name|m
operator|->
name|busy_lock
expr_stmt|;
if|if
condition|(
operator|(
name|x
operator|&
name|VPB_BIT_WAITERS
operator|)
operator|==
literal|0
condition|)
return|return;
if|if
condition|(
name|atomic_cmpset_int
argument_list|(
operator|&
name|m
operator|->
name|busy_lock
argument_list|,
name|x
argument_list|,
name|x
operator|&
operator|(
operator|~
name|VPB_BIT_WAITERS
operator|)
argument_list|)
condition|)
break|break;
block|}
name|wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Keep page from being freed by the page daemon  * much of the same effect as wiring, except much lower  * overhead and should be used only for *very* temporary  * holding ("wiring").  */
end_comment

begin_function
name|void
name|vm_page_hold
parameter_list|(
name|vm_page_t
name|mem
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|mem
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mem
operator|->
name|hold_count
operator|++
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_unhold
parameter_list|(
name|vm_page_t
name|mem
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|mem
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mem
operator|->
name|hold_count
operator|>=
literal|1
argument_list|,
operator|(
literal|"vm_page_unhold: hold count< 0!!!"
operator|)
argument_list|)
expr_stmt|;
operator|--
name|mem
operator|->
name|hold_count
expr_stmt|;
if|if
condition|(
name|mem
operator|->
name|hold_count
operator|==
literal|0
operator|&&
operator|(
name|mem
operator|->
name|flags
operator|&
name|PG_UNHOLDFREE
operator|)
operator|!=
literal|0
condition|)
name|vm_page_free_toq
argument_list|(
name|mem
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_unhold_pages:  *  *	Unhold each of the pages that is referenced by the given array.  */
end_comment

begin_function
name|void
name|vm_page_unhold_pages
parameter_list|(
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtx
decl_stmt|,
modifier|*
name|new_mtx
decl_stmt|;
name|mtx
operator|=
name|NULL
expr_stmt|;
for|for
control|(
init|;
name|count
operator|!=
literal|0
condition|;
name|count
operator|--
control|)
block|{
comment|/* 		 * Avoid releasing and reacquiring the same page lock. 		 */
name|new_mtx
operator|=
name|vm_page_lockptr
argument_list|(
operator|*
name|ma
argument_list|)
expr_stmt|;
if|if
condition|(
name|mtx
operator|!=
name|new_mtx
condition|)
block|{
if|if
condition|(
name|mtx
operator|!=
name|NULL
condition|)
name|mtx_unlock
argument_list|(
name|mtx
argument_list|)
expr_stmt|;
name|mtx
operator|=
name|new_mtx
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtx
argument_list|)
expr_stmt|;
block|}
name|vm_page_unhold
argument_list|(
operator|*
name|ma
argument_list|)
expr_stmt|;
name|ma
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|mtx
operator|!=
name|NULL
condition|)
name|mtx_unlock
argument_list|(
name|mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|vm_page_t
name|PHYS_TO_VM_PAGE
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
ifdef|#
directive|ifdef
name|VM_PHYSSEG_SPARSE
name|m
operator|=
name|vm_phys_paddr_to_vm_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
name|m
operator|=
name|vm_phys_fictitious_to_vm_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
elif|#
directive|elif
name|defined
argument_list|(
name|VM_PHYSSEG_DENSE
argument_list|)
name|long
name|pi
decl_stmt|;
name|pi
operator|=
name|atop
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
name|pi
operator|>=
name|first_page
operator|&&
operator|(
name|pi
operator|-
name|first_page
operator|)
operator|<
name|vm_page_array_size
condition|)
block|{
name|m
operator|=
operator|&
name|vm_page_array
index|[
name|pi
operator|-
name|first_page
index|]
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
return|return
operator|(
name|vm_phys_fictitious_to_vm_page
argument_list|(
name|pa
argument_list|)
operator|)
return|;
else|#
directive|else
error|#
directive|error
literal|"Either VM_PHYSSEG_DENSE or VM_PHYSSEG_SPARSE must be defined."
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/*  *	vm_page_getfake:  *  *	Create a fictitious page with the specified physical address and  *	memory attribute.  The memory attribute is the only the machine-  *	dependent aspect of a fictitious page that must be initialized.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_getfake
parameter_list|(
name|vm_paddr_t
name|paddr
parameter_list|,
name|vm_memattr_t
name|memattr
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|uma_zalloc
argument_list|(
name|fakepg_zone
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
name|vm_page_initfake
argument_list|(
name|m
argument_list|,
name|paddr
argument_list|,
name|memattr
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
name|void
name|vm_page_initfake
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_paddr_t
name|paddr
parameter_list|,
name|vm_memattr_t
name|memattr
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * The page's memattr might have changed since the 		 * previous initialization.  Update the pmap to the 		 * new memattr. 		 */
goto|goto
name|memattr
goto|;
block|}
name|m
operator|->
name|phys_addr
operator|=
name|paddr
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_NONE
expr_stmt|;
comment|/* Fictitious pages don't use "segind". */
name|m
operator|->
name|flags
operator|=
name|PG_FICTITIOUS
expr_stmt|;
comment|/* Fictitious pages don't use "order" or "pool". */
name|m
operator|->
name|oflags
operator|=
name|VPO_UNMANAGED
expr_stmt|;
name|m
operator|->
name|busy_lock
operator|=
name|VPB_SINGLE_EXCLUSIVER
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
name|pmap_page_init
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|memattr
label|:
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|memattr
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_putfake:  *  *	Release a fictitious page.  */
end_comment

begin_function
name|void
name|vm_page_putfake
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"managed %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_putfake: bad page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|uma_zfree
argument_list|(
name|fakepg_zone
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_updatefake:  *  *	Update the given fictitious page to the specified physical address and  *	memory attribute.  */
end_comment

begin_function
name|void
name|vm_page_updatefake
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_paddr_t
name|paddr
parameter_list|,
name|vm_memattr_t
name|memattr
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_updatefake: bad page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|phys_addr
operator|=
name|paddr
expr_stmt|;
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|memattr
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_free:  *  *	Free a page.  */
end_comment

begin_function
name|void
name|vm_page_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_zero:  *  *	Free a page to the zerod-pages queue  */
end_comment

begin_function
name|void
name|vm_page_free_zero
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|m
operator|->
name|flags
operator||=
name|PG_ZERO
expr_stmt|;
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Unbusy and handle the page queueing for a page from a getpages request that  * was optionally read ahead or behind.  */
end_comment

begin_function
name|void
name|vm_page_readahead_finish
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
comment|/* We shouldn't put invalid pages on queues. */
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|!=
literal|0
argument_list|,
operator|(
literal|"%s: %p is invalid"
operator|,
name|__func__
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Since the page is not the actually needed one, whether it should 	 * be activated or deactivated is not obvious.  Empirical results 	 * have shown that deactivating the page is usually the best choice, 	 * unless the page is wanted by another thread. 	 */
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|busy_lock
operator|&
name|VPB_BIT_WAITERS
operator|)
operator|!=
literal|0
condition|)
name|vm_page_activate
argument_list|(
name|m
argument_list|)
expr_stmt|;
else|else
name|vm_page_deactivate
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_xunbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_sleep_if_busy:  *  *	Sleep and release the page queues lock if the page is busied.  *	Returns TRUE if the thread slept.  *  *	The given page must be unlocked and object containing it must  *	be locked.  */
end_comment

begin_function
name|int
name|vm_page_sleep_if_busy
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|msg
parameter_list|)
block|{
name|vm_object_t
name|obj
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_busied
argument_list|(
name|m
argument_list|)
condition|)
block|{
comment|/* 		 * The page-specific object must be cached because page 		 * identity can change during the sleep, causing the 		 * re-lock of a different object. 		 * It is assumed that a reference to the object is already 		 * held by the callers. 		 */
name|obj
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
name|vm_page_busy_sleep
argument_list|(
name|m
argument_list|,
name|msg
argument_list|,
name|false
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|obj
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_dirty_KBI:		[ internal use only ]  *  *	Set all bits in the page's dirty field.  *  *	The object containing the specified page must be locked if the  *	call is made from the machine-independent layer.  *  *	See vm_page_clear_dirty_mask().  *  *	This function should only be called by vm_page_dirty().  */
end_comment

begin_function
name|void
name|vm_page_dirty_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
comment|/* Refer to this operation by its public name. */
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
argument_list|,
operator|(
literal|"vm_page_dirty: page is invalid!"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|dirty
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_insert:		[ internal use only ]  *  *	Inserts the given mem entry into the object and object list.  *  *	The object must be locked.  */
end_comment

begin_function
name|int
name|vm_page_insert
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|mpred
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|mpred
operator|=
name|vm_radix_lookup_le
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
return|return
operator|(
name|vm_page_insert_after
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|,
name|mpred
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_insert_after:  *  *	Inserts the page "m" into the specified object at offset "pindex".  *  *	The page "mpred" must immediately precede the offset "pindex" within  *	the specified object.  *  *	The object must be locked.  */
end_comment

begin_function
specifier|static
name|int
name|vm_page_insert_after
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_page_t
name|mpred
parameter_list|)
block|{
name|vm_page_t
name|msucc
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|object
operator|==
name|NULL
argument_list|,
operator|(
literal|"vm_page_insert_after: page already inserted"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpred
operator|!=
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
name|mpred
operator|->
name|object
operator|==
name|object
argument_list|,
operator|(
literal|"vm_page_insert_after: object doesn't contain mpred"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpred
operator|->
name|pindex
operator|<
name|pindex
argument_list|,
operator|(
literal|"vm_page_insert_after: mpred doesn't precede pindex"
operator|)
argument_list|)
expr_stmt|;
name|msucc
operator|=
name|TAILQ_NEXT
argument_list|(
name|mpred
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
else|else
name|msucc
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|)
expr_stmt|;
if|if
condition|(
name|msucc
operator|!=
name|NULL
condition|)
name|KASSERT
argument_list|(
name|msucc
operator|->
name|pindex
operator|>
name|pindex
argument_list|,
operator|(
literal|"vm_page_insert_after: msucc doesn't succeed pindex"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Record the object/offset pair in this page 	 */
name|m
operator|->
name|object
operator|=
name|object
expr_stmt|;
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
comment|/* 	 * Now link into the object's ordered list of backed pages. 	 */
if|if
condition|(
name|vm_radix_insert
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|m
argument_list|)
condition|)
block|{
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|m
operator|->
name|pindex
operator|=
literal|0
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
name|vm_page_insert_radixdone
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|mpred
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_insert_radixdone:  *  *	Complete page "m" insertion into the specified object after the  *	radix trie hooking.  *  *	The page "mpred" must precede the offset "m->pindex" within the  *	specified object.  *  *	The object must be locked.  */
end_comment

begin_function
specifier|static
name|void
name|vm_page_insert_radixdone
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_page_t
name|mpred
parameter_list|)
block|{
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|object
operator|!=
name|NULL
operator|&&
name|m
operator|->
name|object
operator|==
name|object
argument_list|,
operator|(
literal|"vm_page_insert_radixdone: page %p has inconsistent object"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpred
operator|!=
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
name|mpred
operator|->
name|object
operator|==
name|object
argument_list|,
operator|(
literal|"vm_page_insert_after: object doesn't contain mpred"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpred
operator|->
name|pindex
operator|<
name|m
operator|->
name|pindex
argument_list|,
operator|(
literal|"vm_page_insert_after: mpred doesn't precede pindex"
operator|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mpred
operator|!=
name|NULL
condition|)
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|mpred
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
comment|/* 	 * Show that the object has one more resident page. 	 */
name|object
operator|->
name|resident_page_count
operator|++
expr_stmt|;
comment|/* 	 * Hold the vnode until the last page is released. 	 */
if|if
condition|(
name|object
operator|->
name|resident_page_count
operator|==
literal|1
operator|&&
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
name|vhold
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
comment|/* 	 * Since we are inserting a new and possibly dirty page, 	 * update the object's OBJ_MIGHTBEDIRTY flag. 	 */
if|if
condition|(
name|pmap_page_is_write_mapped
argument_list|(
name|m
argument_list|)
condition|)
name|vm_object_set_writeable_dirty
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_remove:  *  *	Removes the specified page from its containing object, but does not  *	invalidate any backing storage.  *  *	The object must be locked.  The page must be locked if it is managed.  */
end_comment

begin_function
name|void
name|vm_page_remove
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|vm_page_t
name|mrem
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|object
operator|=
name|m
operator|->
name|object
operator|)
operator|==
name|NULL
condition|)
return|return;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
name|vm_page_xunbusy_maybelocked
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|mrem
operator|=
name|vm_radix_remove
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mrem
operator|==
name|m
argument_list|,
operator|(
literal|"removed page %p, expected page %p"
operator|,
name|mrem
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Now remove from the object's list of backed pages. 	 */
name|TAILQ_REMOVE
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
comment|/* 	 * And show that the object has one fewer resident page. 	 */
name|object
operator|->
name|resident_page_count
operator|--
expr_stmt|;
comment|/* 	 * The vnode may now be recycled. 	 */
if|if
condition|(
name|object
operator|->
name|resident_page_count
operator|==
literal|0
operator|&&
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
name|vdrop
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_lookup:  *  *	Returns the page associated with the object/offset  *	pair specified; if none is found, NULL is returned.  *  *	The object must be locked.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_lookup
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
return|return
operator|(
name|vm_radix_lookup
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|pindex
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_find_least:  *  *	Returns the page associated with the object with least pindex  *	greater than or equal to the parameter pindex, or NULL.  *  *	The object must be locked.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_find_least
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
name|m
operator|->
name|pindex
operator|<
name|pindex
condition|)
name|m
operator|=
name|vm_radix_lookup_ge
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns the given page's successor (by pindex) within the object if it is  * resident; if none is found, NULL is returned.  *  * The object must be locked.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_next
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_t
name|next
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|MPASS
argument_list|(
name|next
operator|->
name|object
operator|==
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|next
operator|->
name|pindex
operator|!=
name|m
operator|->
name|pindex
operator|+
literal|1
condition|)
name|next
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|next
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns the given page's predecessor (by pindex) within the object if it is  * resident; if none is found, NULL is returned.  *  * The object must be locked.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_prev
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_t
name|prev
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|prev
operator|=
name|TAILQ_PREV
argument_list|(
name|m
argument_list|,
name|pglist
argument_list|,
name|listq
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|MPASS
argument_list|(
name|prev
operator|->
name|object
operator|==
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|prev
operator|->
name|pindex
operator|!=
name|m
operator|->
name|pindex
operator|-
literal|1
condition|)
name|prev
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|prev
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Uses the page mnew as a replacement for an existing page at index  * pindex which must be already present in the object.  *  * The existing page must not be on a paging queue.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_replace
parameter_list|(
name|vm_page_t
name|mnew
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|mold
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mnew
operator|->
name|object
operator|==
name|NULL
argument_list|,
operator|(
literal|"vm_page_replace: page already in object"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * This function mostly follows vm_page_insert() and 	 * vm_page_remove() without the radix, object count and vnode 	 * dance.  Double check such functions for more comments. 	 */
name|mnew
operator|->
name|object
operator|=
name|object
expr_stmt|;
name|mnew
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
name|mold
operator|=
name|vm_radix_replace
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|mnew
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mold
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_replace: mold is on a paging queue"
operator|)
argument_list|)
expr_stmt|;
comment|/* Keep the resident page list in sorted order. */
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|mold
argument_list|,
name|mnew
argument_list|,
name|listq
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|mold
argument_list|,
name|listq
argument_list|)
expr_stmt|;
name|mold
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|vm_page_xunbusy_maybelocked
argument_list|(
name|mold
argument_list|)
expr_stmt|;
comment|/* 	 * The object's resident_page_count does not change because we have 	 * swapped one page for another, but OBJ_MIGHTBEDIRTY. 	 */
if|if
condition|(
name|pmap_page_is_write_mapped
argument_list|(
name|mnew
argument_list|)
condition|)
name|vm_object_set_writeable_dirty
argument_list|(
name|object
argument_list|)
expr_stmt|;
return|return
operator|(
name|mold
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_rename:  *  *	Move the given memory entry from its  *	current object to the specified target object/offset.  *  *	Note: swap associated with the page must be invalidated by the move.  We  *	      have to do this for several reasons:  (1) we aren't freeing the  *	      page, (2) we are dirtying the page, (3) the VM system is probably  *	      moving the page from object A to B, and will then later move  *	      the backing store from A to B and we can't have a conflict.  *  *	Note: we *always* dirty the page.  It is necessary both for the  *	      fact that we moved it, and because we may be invalidating  *	      swap.  *  *	The objects must be locked.  */
end_comment

begin_function
name|int
name|vm_page_rename
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|new_object
parameter_list|,
name|vm_pindex_t
name|new_pindex
parameter_list|)
block|{
name|vm_page_t
name|mpred
decl_stmt|;
name|vm_pindex_t
name|opidx
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|new_object
argument_list|)
expr_stmt|;
name|mpred
operator|=
name|vm_radix_lookup_le
argument_list|(
operator|&
name|new_object
operator|->
name|rtree
argument_list|,
name|new_pindex
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpred
operator|==
name|NULL
operator|||
name|mpred
operator|->
name|pindex
operator|!=
name|new_pindex
argument_list|,
operator|(
literal|"vm_page_rename: pindex already renamed"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Create a custom version of vm_page_insert() which does not depend 	 * by m_prev and can cheat on the implementation aspects of the 	 * function. 	 */
name|opidx
operator|=
name|m
operator|->
name|pindex
expr_stmt|;
name|m
operator|->
name|pindex
operator|=
name|new_pindex
expr_stmt|;
if|if
condition|(
name|vm_radix_insert
argument_list|(
operator|&
name|new_object
operator|->
name|rtree
argument_list|,
name|m
argument_list|)
condition|)
block|{
name|m
operator|->
name|pindex
operator|=
name|opidx
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
comment|/* 	 * The operation cannot fail anymore.  The removal must happen before 	 * the listq iterator is tainted. 	 */
name|m
operator|->
name|pindex
operator|=
name|opidx
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* Return back to the new pindex to complete vm_page_insert(). */
name|m
operator|->
name|pindex
operator|=
name|new_pindex
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|new_object
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_insert_radixdone
argument_list|(
name|m
argument_list|,
name|new_object
argument_list|,
name|mpred
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_alloc:  *  *	Allocate and return a page that is associated with the specified  *	object and offset pair.  By default, this page is exclusive busied.  *  *	The caller must always specify an allocation class.  *  *	allocation classes:  *	VM_ALLOC_NORMAL		normal process request  *	VM_ALLOC_SYSTEM		system *really* needs a page  *	VM_ALLOC_INTERRUPT	interrupt time request  *  *	optional allocation flags:  *	VM_ALLOC_COUNT(number)	the number of additional pages that the caller  *				intends to allocate  *	VM_ALLOC_NOBUSY		do not exclusive busy the page  *	VM_ALLOC_NODUMP		do not include the page in a kernel core dump  *	VM_ALLOC_NOOBJ		page is not associated with an object and  *				should not be exclusive busy  *	VM_ALLOC_SBUSY		shared busy the allocated page  *	VM_ALLOC_WIRED		wire the allocated page  *	VM_ALLOC_ZERO		prefer a zeroed page  *  *	This routine may not sleep.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_alloc
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|req
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|,
name|mpred
decl_stmt|;
name|int
name|flags
decl_stmt|,
name|req_class
decl_stmt|;
name|mpred
operator|=
name|NULL
expr_stmt|;
comment|/* XXX: pacify gcc */
name|KASSERT
argument_list|(
operator|(
name|object
operator|!=
name|NULL
operator|)
operator|==
operator|(
operator|(
name|req
operator|&
name|VM_ALLOC_NOOBJ
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|object
operator|!=
name|NULL
operator|||
operator|(
name|req
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
operator|(
name|req
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
operator|!=
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
argument_list|,
operator|(
literal|"vm_page_alloc: inconsistent object(%p)/req(%x)"
operator|,
name|object
operator|,
name|req
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|__predict_false
argument_list|(
operator|(
name|req
operator|&
name|VM_ALLOC_IFCACHED
operator|)
operator|!=
literal|0
argument_list|)
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|req_class
operator|=
name|req
operator|&
name|VM_ALLOC_CLASS_MASK
expr_stmt|;
comment|/* 	 * The page daemon is allowed to dig deeper into the free page list. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
operator|&&
name|req_class
operator|!=
name|VM_ALLOC_INTERRUPT
condition|)
name|req_class
operator|=
name|VM_ALLOC_SYSTEM
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
name|mpred
operator|=
name|vm_radix_lookup_le
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpred
operator|==
name|NULL
operator|||
name|mpred
operator|->
name|pindex
operator|!=
name|pindex
argument_list|,
operator|(
literal|"vm_page_alloc: pindex already allocated"
operator|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Allocate a page if the number of free pages exceeds the minimum 	 * for the request class. 	 */
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_cnt
operator|.
name|v_free_count
operator|+
name|vm_cnt
operator|.
name|v_cache_count
operator|>
name|vm_cnt
operator|.
name|v_free_reserved
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_SYSTEM
operator|&&
name|vm_cnt
operator|.
name|v_free_count
operator|+
name|vm_cnt
operator|.
name|v_cache_count
operator|>
name|vm_cnt
operator|.
name|v_interrupt_free_min
operator|)
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_INTERRUPT
operator|&&
name|vm_cnt
operator|.
name|v_free_count
operator|+
name|vm_cnt
operator|.
name|v_cache_count
operator|>
literal|0
operator|)
condition|)
block|{
comment|/* 		 * Can we allocate the page from a reservation? 		 */
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
name|object
operator|==
name|NULL
operator|||
operator|(
name|object
operator|->
name|flags
operator|&
operator|(
name|OBJ_COLORED
operator||
name|OBJ_FICTITIOUS
operator|)
operator|)
operator|!=
name|OBJ_COLORED
operator|||
operator|(
name|m
operator|=
name|vm_reserv_alloc_page
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|mpred
argument_list|)
operator|)
operator|==
name|NULL
condition|)
endif|#
directive|endif
block|{
comment|/* 			 * If not, allocate it from the free page queues. 			 */
name|m
operator|=
name|vm_phys_alloc_pages
argument_list|(
name|object
operator|!=
name|NULL
condition|?
name|VM_FREEPOOL_DEFAULT
else|:
name|VM_FREEPOOL_DIRECT
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
name|m
operator|==
name|NULL
operator|&&
name|vm_reserv_reclaim_inactive
argument_list|()
condition|)
block|{
name|m
operator|=
name|vm_phys_alloc_pages
argument_list|(
name|object
operator|!=
name|NULL
condition|?
name|VM_FREEPOOL_DEFAULT
else|:
name|VM_FREEPOOL_DIRECT
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
block|}
else|else
block|{
comment|/* 		 * Not allocatable, give up. 		 */
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
name|max
argument_list|(
operator|(
name|u_int
operator|)
name|req
operator|>>
name|VM_ALLOC_COUNT_SHIFT
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
comment|/* 	 *  At this point we had better have found a good page. 	 */
name|KASSERT
argument_list|(
name|m
operator|!=
name|NULL
argument_list|,
operator|(
literal|"vm_page_alloc: missing page"
operator|)
argument_list|)
expr_stmt|;
name|vm_phys_freecnt_adj
argument_list|(
name|m
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|!=
literal|0
condition|)
name|vm_page_zero_count
operator|--
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|vm_page_alloc_check
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the page.  Only the PG_ZERO flag is inherited. 	 */
name|flags
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_ZERO
operator|)
operator|!=
literal|0
condition|)
name|flags
operator|=
name|PG_ZERO
expr_stmt|;
name|flags
operator|&=
name|m
operator|->
name|flags
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_NODUMP
operator|)
operator|!=
literal|0
condition|)
name|flags
operator||=
name|PG_NODUMP
expr_stmt|;
name|m
operator|->
name|flags
operator|=
name|flags
expr_stmt|;
name|m
operator|->
name|aflags
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|oflags
operator|=
name|object
operator|==
name|NULL
operator|||
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_UNMANAGED
operator|)
operator|!=
literal|0
condition|?
name|VPO_UNMANAGED
else|:
literal|0
expr_stmt|;
name|m
operator|->
name|busy_lock
operator|=
name|VPB_UNBUSIED
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
operator|==
literal|0
condition|)
name|m
operator|->
name|busy_lock
operator|=
name|VPB_SINGLE_EXCLUSIVER
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|!=
literal|0
condition|)
name|m
operator|->
name|busy_lock
operator|=
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|req
operator|&
name|VM_ALLOC_WIRED
condition|)
block|{
comment|/* 		 * The page lock is not required for wiring a page until that 		 * page is inserted into the object. 		 */
name|atomic_add_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
block|}
name|m
operator|->
name|act_count
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|vm_page_insert_after
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|,
name|mpred
argument_list|)
condition|)
block|{
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
if|if
condition|(
name|req
operator|&
name|VM_ALLOC_WIRED
condition|)
block|{
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|m
operator|->
name|object
operator|==
name|NULL
argument_list|,
operator|(
literal|"page %p has object"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|oflags
operator|=
name|VPO_UNMANAGED
expr_stmt|;
name|m
operator|->
name|busy_lock
operator|=
name|VPB_UNBUSIED
expr_stmt|;
comment|/* Don't change PG_ZERO. */
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
comment|/* Ignore device objects; the pager sets "memattr" for them. */
if|if
condition|(
name|object
operator|->
name|memattr
operator|!=
name|VM_MEMATTR_DEFAULT
operator|&&
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|object
operator|->
name|memattr
argument_list|)
expr_stmt|;
block|}
else|else
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
comment|/* 	 * Don't wakeup too often - wakeup the pageout daemon when 	 * we would be nearly out of memory. 	 */
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_alloc_contig:  *  *	Allocate a contiguous set of physical pages of the given size "npages"  *	from the free lists.  All of the physical pages must be at or above  *	the given physical address "low" and below the given physical address  *	"high".  The given value "alignment" determines the alignment of the  *	first physical page in the set.  If the given value "boundary" is  *	non-zero, then the set of physical pages cannot cross any physical  *	address boundary that is a multiple of that value.  Both "alignment"  *	and "boundary" must be a power of two.  *  *	If the specified memory attribute, "memattr", is VM_MEMATTR_DEFAULT,  *	then the memory attribute setting for the physical pages is configured  *	to the object's memory attribute setting.  Otherwise, the memory  *	attribute setting for the physical pages is configured to "memattr",  *	overriding the object's memory attribute setting.  However, if the  *	object's memory attribute setting is not VM_MEMATTR_DEFAULT, then the  *	memory attribute setting for the physical pages cannot be configured  *	to VM_MEMATTR_DEFAULT.  *  *	The specified object may not contain fictitious pages.  *  *	The caller must always specify an allocation class.  *  *	allocation classes:  *	VM_ALLOC_NORMAL		normal process request  *	VM_ALLOC_SYSTEM		system *really* needs a page  *	VM_ALLOC_INTERRUPT	interrupt time request  *  *	optional allocation flags:  *	VM_ALLOC_NOBUSY		do not exclusive busy the page  *	VM_ALLOC_NODUMP		do not include the page in a kernel core dump  *	VM_ALLOC_NOOBJ		page is not associated with an object and  *				should not be exclusive busy  *	VM_ALLOC_SBUSY		shared busy the allocated page  *	VM_ALLOC_WIRED		wire the allocated page  *	VM_ALLOC_ZERO		prefer a zeroed page  *  *	This routine may not sleep.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_alloc_contig
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|req
parameter_list|,
name|u_long
name|npages
parameter_list|,
name|vm_paddr_t
name|low
parameter_list|,
name|vm_paddr_t
name|high
parameter_list|,
name|u_long
name|alignment
parameter_list|,
name|vm_paddr_t
name|boundary
parameter_list|,
name|vm_memattr_t
name|memattr
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|,
name|m_ret
decl_stmt|,
name|mpred
decl_stmt|;
name|u_int
name|busy_lock
decl_stmt|,
name|flags
decl_stmt|,
name|oflags
decl_stmt|;
name|int
name|req_class
decl_stmt|;
name|mpred
operator|=
name|NULL
expr_stmt|;
comment|/* XXX: pacify gcc */
name|KASSERT
argument_list|(
operator|(
name|object
operator|!=
name|NULL
operator|)
operator|==
operator|(
operator|(
name|req
operator|&
name|VM_ALLOC_NOOBJ
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|object
operator|!=
name|NULL
operator|||
operator|(
name|req
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
operator|(
name|req
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
operator|!=
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
argument_list|,
operator|(
literal|"vm_page_alloc_contig: inconsistent object(%p)/req(%x)"
operator|,
name|object
operator|,
name|req
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_FICTITIOUS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_contig: object %p has fictitious pages"
operator|,
name|object
operator|)
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|npages
operator|>
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_contig: npages is zero"
operator|)
argument_list|)
expr_stmt|;
name|req_class
operator|=
name|req
operator|&
name|VM_ALLOC_CLASS_MASK
expr_stmt|;
comment|/* 	 * The page daemon is allowed to dig deeper into the free page list. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
operator|&&
name|req_class
operator|!=
name|VM_ALLOC_INTERRUPT
condition|)
name|req_class
operator|=
name|VM_ALLOC_SYSTEM
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
name|mpred
operator|=
name|vm_radix_lookup_le
argument_list|(
operator|&
name|object
operator|->
name|rtree
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpred
operator|==
name|NULL
operator|||
name|mpred
operator|->
name|pindex
operator|!=
name|pindex
argument_list|,
operator|(
literal|"vm_page_alloc_contig: pindex already allocated"
operator|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Can we allocate the pages without the number of free pages falling 	 * below the lower bound for the allocation class? 	 */
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_cnt
operator|.
name|v_free_count
operator|+
name|vm_cnt
operator|.
name|v_cache_count
operator|>=
name|npages
operator|+
name|vm_cnt
operator|.
name|v_free_reserved
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_SYSTEM
operator|&&
name|vm_cnt
operator|.
name|v_free_count
operator|+
name|vm_cnt
operator|.
name|v_cache_count
operator|>=
name|npages
operator|+
name|vm_cnt
operator|.
name|v_interrupt_free_min
operator|)
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_INTERRUPT
operator|&&
name|vm_cnt
operator|.
name|v_free_count
operator|+
name|vm_cnt
operator|.
name|v_cache_count
operator|>=
name|npages
operator|)
condition|)
block|{
comment|/* 		 * Can we allocate the pages from a reservation? 		 */
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
name|retry
label|:
if|if
condition|(
name|object
operator|==
name|NULL
operator|||
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_COLORED
operator|)
operator|==
literal|0
operator|||
operator|(
name|m_ret
operator|=
name|vm_reserv_alloc_contig
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|npages
argument_list|,
name|low
argument_list|,
name|high
argument_list|,
name|alignment
argument_list|,
name|boundary
argument_list|,
name|mpred
argument_list|)
operator|)
operator|==
name|NULL
condition|)
endif|#
directive|endif
comment|/* 			 * If not, allocate them from the free page queues. 			 */
name|m_ret
operator|=
name|vm_phys_alloc_contig
argument_list|(
name|npages
argument_list|,
name|low
argument_list|,
name|high
argument_list|,
name|alignment
argument_list|,
name|boundary
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
name|npages
argument_list|)
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
if|if
condition|(
name|m_ret
operator|!=
name|NULL
condition|)
block|{
name|vm_phys_freecnt_adj
argument_list|(
name|m_ret
argument_list|,
operator|-
name|npages
argument_list|)
expr_stmt|;
for|for
control|(
name|m
operator|=
name|m_ret
init|;
name|m
operator|<
operator|&
name|m_ret
index|[
name|npages
index|]
condition|;
name|m
operator|++
control|)
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|!=
literal|0
condition|)
name|vm_page_zero_count
operator|--
expr_stmt|;
block|}
else|else
block|{
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
name|vm_reserv_reclaim_contig
argument_list|(
name|npages
argument_list|,
name|low
argument_list|,
name|high
argument_list|,
name|alignment
argument_list|,
name|boundary
argument_list|)
condition|)
goto|goto
name|retry
goto|;
endif|#
directive|endif
block|}
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_ret
operator|==
name|NULL
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
for|for
control|(
name|m
operator|=
name|m_ret
init|;
name|m
operator|<
operator|&
name|m_ret
index|[
name|npages
index|]
condition|;
name|m
operator|++
control|)
name|vm_page_alloc_check
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the pages.  Only the PG_ZERO flag is inherited. 	 */
name|flags
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_ZERO
operator|)
operator|!=
literal|0
condition|)
name|flags
operator|=
name|PG_ZERO
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_NODUMP
operator|)
operator|!=
literal|0
condition|)
name|flags
operator||=
name|PG_NODUMP
expr_stmt|;
name|oflags
operator|=
name|object
operator|==
name|NULL
operator|||
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_UNMANAGED
operator|)
operator|!=
literal|0
condition|?
name|VPO_UNMANAGED
else|:
literal|0
expr_stmt|;
name|busy_lock
operator|=
name|VPB_UNBUSIED
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
operator|==
literal|0
condition|)
name|busy_lock
operator|=
name|VPB_SINGLE_EXCLUSIVER
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|!=
literal|0
condition|)
name|busy_lock
operator|=
name|VPB_SHARERS_WORD
argument_list|(
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
name|atomic_add_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
name|npages
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|object
operator|->
name|memattr
operator|!=
name|VM_MEMATTR_DEFAULT
operator|&&
name|memattr
operator|==
name|VM_MEMATTR_DEFAULT
condition|)
name|memattr
operator|=
name|object
operator|->
name|memattr
expr_stmt|;
block|}
for|for
control|(
name|m
operator|=
name|m_ret
init|;
name|m
operator|<
operator|&
name|m_ret
index|[
name|npages
index|]
condition|;
name|m
operator|++
control|)
block|{
name|m
operator|->
name|aflags
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|flags
operator|=
operator|(
name|m
operator|->
name|flags
operator||
name|PG_NODUMP
operator|)
operator|&
name|flags
expr_stmt|;
name|m
operator|->
name|busy_lock
operator|=
name|busy_lock
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
name|m
operator|->
name|act_count
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|oflags
operator|=
name|oflags
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|vm_page_insert_after
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|,
name|mpred
argument_list|)
condition|)
block|{
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
name|npages
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|object
operator|==
name|NULL
argument_list|,
operator|(
literal|"page %p has object"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|mpred
operator|=
name|m
expr_stmt|;
for|for
control|(
name|m
operator|=
name|m_ret
init|;
name|m
operator|<
operator|&
name|m_ret
index|[
name|npages
index|]
condition|;
name|m
operator|++
control|)
block|{
if|if
condition|(
name|m
operator|<=
name|mpred
operator|&&
operator|(
name|req
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
name|m
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|oflags
operator|=
name|VPO_UNMANAGED
expr_stmt|;
name|m
operator|->
name|busy_lock
operator|=
name|VPB_UNBUSIED
expr_stmt|;
comment|/* Don't change PG_ZERO. */
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|mpred
operator|=
name|m
expr_stmt|;
block|}
else|else
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
if|if
condition|(
name|memattr
operator|!=
name|VM_MEMATTR_DEFAULT
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|memattr
argument_list|)
expr_stmt|;
name|pindex
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|m_ret
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Check a page that has been freshly dequeued from a freelist.  */
end_comment

begin_function
specifier|static
name|void
name|vm_page_alloc_check
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|object
operator|==
name|NULL
argument_list|,
operator|(
literal|"page %p has object"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"page %p has unexpected queue %d"
operator|,
name|m
operator|,
name|m
operator|->
name|queue
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p is wired"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|hold_count
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p is held"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|vm_page_busied
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"page %p is busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p is dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|==
name|VM_MEMATTR_DEFAULT
argument_list|,
operator|(
literal|"page %p has unexpected memattr %d"
operator|,
name|m
operator|,
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|==
literal|0
argument_list|,
operator|(
literal|"free page %p is valid"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * 	vm_page_alloc_freelist:  *  *	Allocate a physical page from the specified free page list.  *  *	The caller must always specify an allocation class.  *  *	allocation classes:  *	VM_ALLOC_NORMAL		normal process request  *	VM_ALLOC_SYSTEM		system *really* needs a page  *	VM_ALLOC_INTERRUPT	interrupt time request  *  *	optional allocation flags:  *	VM_ALLOC_COUNT(number)	the number of additional pages that the caller  *				intends to allocate  *	VM_ALLOC_WIRED		wire the allocated page  *	VM_ALLOC_ZERO		prefer a zeroed page  *  *	This routine may not sleep.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_alloc_freelist
parameter_list|(
name|int
name|flind
parameter_list|,
name|int
name|req
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|u_int
name|flags
decl_stmt|;
name|int
name|req_class
decl_stmt|;
name|req_class
operator|=
name|req
operator|&
name|VM_ALLOC_CLASS_MASK
expr_stmt|;
comment|/* 	 * The page daemon is allowed to dig deeper into the free page list. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
operator|&&
name|req_class
operator|!=
name|VM_ALLOC_INTERRUPT
condition|)
name|req_class
operator|=
name|VM_ALLOC_SYSTEM
expr_stmt|;
comment|/* 	 * Do not allocate reserved pages unless the req has asked for it. 	 */
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_cnt
operator|.
name|v_free_count
operator|+
name|vm_cnt
operator|.
name|v_cache_count
operator|>
name|vm_cnt
operator|.
name|v_free_reserved
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_SYSTEM
operator|&&
name|vm_cnt
operator|.
name|v_free_count
operator|+
name|vm_cnt
operator|.
name|v_cache_count
operator|>
name|vm_cnt
operator|.
name|v_interrupt_free_min
operator|)
operator|||
operator|(
name|req_class
operator|==
name|VM_ALLOC_INTERRUPT
operator|&&
name|vm_cnt
operator|.
name|v_free_count
operator|+
name|vm_cnt
operator|.
name|v_cache_count
operator|>
literal|0
operator|)
condition|)
name|m
operator|=
name|vm_phys_alloc_freelist_pages
argument_list|(
name|flind
argument_list|,
name|VM_FREEPOOL_DIRECT
argument_list|,
literal|0
argument_list|)
expr_stmt|;
else|else
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
name|max
argument_list|(
operator|(
name|u_int
operator|)
name|req
operator|>>
name|VM_ALLOC_COUNT_SHIFT
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|vm_phys_freecnt_adj
argument_list|(
name|m
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|!=
literal|0
condition|)
name|vm_page_zero_count
operator|--
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|vm_page_alloc_check
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the page.  Only the PG_ZERO flag is inherited. 	 */
name|m
operator|->
name|aflags
operator|=
literal|0
expr_stmt|;
name|flags
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_ZERO
operator|)
operator|!=
literal|0
condition|)
name|flags
operator|=
name|PG_ZERO
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
name|flags
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * The page lock is not required for wiring a page that does 		 * not belong to an object. 		 */
name|atomic_add_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
block|}
comment|/* Unmanaged pages don't use "act_count". */
name|m
operator|->
name|oflags
operator|=
name|VPO_UNMANAGED
expr_stmt|;
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|VPSC_ANY
value|0
end_define

begin_comment
comment|/* No restrictions. */
end_comment

begin_define
define|#
directive|define
name|VPSC_NORESERV
value|1
end_define

begin_comment
comment|/* Skip reservations; implies VPSC_NOSUPER. */
end_comment

begin_define
define|#
directive|define
name|VPSC_NOSUPER
value|2
end_define

begin_comment
comment|/* Skip superpages. */
end_comment

begin_comment
comment|/*  *	vm_page_scan_contig:  *  *	Scan vm_page_array[] between the specified entries "m_start" and  *	"m_end" for a run of contiguous physical pages that satisfy the  *	specified conditions, and return the lowest page in the run.  The  *	specified "alignment" determines the alignment of the lowest physical  *	page in the run.  If the specified "boundary" is non-zero, then the  *	run of physical pages cannot span a physical address that is a  *	multiple of "boundary".  *  *	"m_end" is never dereferenced, so it need not point to a vm_page  *	structure within vm_page_array[].  *  *	"npages" must be greater than zero.  "m_start" and "m_end" must not  *	span a hole (or discontiguity) in the physical address space.  Both  *	"alignment" and "boundary" must be a power of two.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_scan_contig
parameter_list|(
name|u_long
name|npages
parameter_list|,
name|vm_page_t
name|m_start
parameter_list|,
name|vm_page_t
name|m_end
parameter_list|,
name|u_long
name|alignment
parameter_list|,
name|vm_paddr_t
name|boundary
parameter_list|,
name|int
name|options
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|m_mtx
decl_stmt|,
modifier|*
name|new_mtx
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|m_run
decl_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
name|int
name|level
decl_stmt|;
endif|#
directive|endif
name|int
name|m_inc
decl_stmt|,
name|order
decl_stmt|,
name|run_ext
decl_stmt|,
name|run_len
decl_stmt|;
name|KASSERT
argument_list|(
name|npages
operator|>
literal|0
argument_list|,
operator|(
literal|"npages is 0"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|powerof2
argument_list|(
name|alignment
argument_list|)
argument_list|,
operator|(
literal|"alignment is not a power of 2"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|powerof2
argument_list|(
name|boundary
argument_list|)
argument_list|,
operator|(
literal|"boundary is not a power of 2"
operator|)
argument_list|)
expr_stmt|;
name|m_run
operator|=
name|NULL
expr_stmt|;
name|run_len
operator|=
literal|0
expr_stmt|;
name|m_mtx
operator|=
name|NULL
expr_stmt|;
for|for
control|(
name|m
operator|=
name|m_start
init|;
name|m
operator|<
name|m_end
operator|&&
name|run_len
operator|<
name|npages
condition|;
name|m
operator|+=
name|m_inc
control|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_MARKER
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p is PG_FICTITIOUS or PG_MARKER"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * If the current page would be the start of a run, check its 		 * physical address against the end, alignment, and boundary 		 * conditions.  If it doesn't satisfy these conditions, either 		 * terminate the scan or advance to the next page that 		 * satisfies the failed condition. 		 */
if|if
condition|(
name|run_len
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|m_run
operator|==
name|NULL
argument_list|,
operator|(
literal|"m_run != NULL"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|+
name|npages
operator|>
name|m_end
condition|)
break|break;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pa
operator|&
operator|(
name|alignment
operator|-
literal|1
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|m_inc
operator|=
name|atop
argument_list|(
name|roundup2
argument_list|(
name|pa
argument_list|,
name|alignment
argument_list|)
operator|-
name|pa
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|rounddown2
argument_list|(
name|pa
operator|^
operator|(
name|pa
operator|+
name|ptoa
argument_list|(
name|npages
argument_list|)
operator|-
literal|1
operator|)
argument_list|,
name|boundary
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|m_inc
operator|=
name|atop
argument_list|(
name|roundup2
argument_list|(
name|pa
argument_list|,
name|boundary
argument_list|)
operator|-
name|pa
argument_list|)
expr_stmt|;
continue|continue;
block|}
block|}
else|else
name|KASSERT
argument_list|(
name|m_run
operator|!=
name|NULL
argument_list|,
operator|(
literal|"m_run == NULL"
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Avoid releasing and reacquiring the same page lock. 		 */
name|new_mtx
operator|=
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_mtx
operator|!=
name|new_mtx
condition|)
block|{
if|if
condition|(
name|m_mtx
operator|!=
name|NULL
condition|)
name|mtx_unlock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
name|m_mtx
operator|=
name|new_mtx
expr_stmt|;
name|mtx_lock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
block|}
name|m_inc
operator|=
literal|1
expr_stmt|;
name|retry
label|:
if|if
condition|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
operator|||
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
name|run_ext
operator|=
literal|0
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
elseif|else
if|if
condition|(
operator|(
name|level
operator|=
name|vm_reserv_level
argument_list|(
name|m
argument_list|)
operator|)
operator|>=
literal|0
operator|&&
operator|(
name|options
operator|&
name|VPSC_NORESERV
operator|)
operator|!=
literal|0
condition|)
block|{
name|run_ext
operator|=
literal|0
expr_stmt|;
comment|/* Advance to the end of the reservation. */
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m_inc
operator|=
name|atop
argument_list|(
name|roundup2
argument_list|(
name|pa
operator|+
literal|1
argument_list|,
name|vm_reserv_size
argument_list|(
name|level
argument_list|)
argument_list|)
operator|-
name|pa
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
elseif|else
if|if
condition|(
operator|(
name|object
operator|=
name|m
operator|->
name|object
operator|)
operator|!=
name|NULL
condition|)
block|{
comment|/* 			 * The page is considered eligible for relocation if 			 * and only if it could be laundered or reclaimed by 			 * the page daemon. 			 */
if|if
condition|(
operator|!
name|VM_OBJECT_TRYRLOCK
argument_list|(
name|object
argument_list|)
condition|)
block|{
name|mtx_unlock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
name|VM_OBJECT_RLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|object
condition|)
block|{
comment|/* 					 * The page may have been freed. 					 */
name|VM_OBJECT_RUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
elseif|else
if|if
condition|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
operator|||
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
name|run_ext
operator|=
literal|0
expr_stmt|;
goto|goto
name|unlock
goto|;
block|}
block|}
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNHOLDFREE
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p is PG_UNHOLDFREE"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* Don't care: PG_NODUMP, PG_ZERO. */
if|if
condition|(
name|object
operator|->
name|type
operator|!=
name|OBJT_DEFAULT
operator|&&
name|object
operator|->
name|type
operator|!=
name|OBJT_SWAP
operator|&&
name|object
operator|->
name|type
operator|!=
name|OBJT_VNODE
condition|)
block|{
name|run_ext
operator|=
literal|0
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
block|}
elseif|else
if|if
condition|(
operator|(
name|options
operator|&
name|VPSC_NOSUPER
operator|)
operator|!=
literal|0
operator|&&
operator|(
name|level
operator|=
name|vm_reserv_level_iffullpop
argument_list|(
name|m
argument_list|)
operator|)
operator|>=
literal|0
condition|)
block|{
name|run_ext
operator|=
literal|0
expr_stmt|;
comment|/* Advance to the end of the superpage. */
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m_inc
operator|=
name|atop
argument_list|(
name|roundup2
argument_list|(
name|pa
operator|+
literal|1
argument_list|,
name|vm_reserv_size
argument_list|(
name|level
argument_list|)
argument_list|)
operator|-
name|pa
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
elseif|else
if|if
condition|(
name|object
operator|->
name|memattr
operator|==
name|VM_MEMATTR_DEFAULT
operator|&&
name|m
operator|->
name|queue
operator|!=
name|PQ_NONE
operator|&&
operator|!
name|vm_page_busied
argument_list|(
name|m
argument_list|)
condition|)
block|{
comment|/* 				 * The page is allocated but eligible for 				 * relocation.  Extend the current run by one 				 * page. 				 */
name|KASSERT
argument_list|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|==
name|VM_MEMATTR_DEFAULT
argument_list|,
operator|(
literal|"page %p has an unexpected memattr"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
operator|(
name|VPO_SWAPINPROG
operator||
name|VPO_SWAPSLEEP
operator||
name|VPO_UNMANAGED
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p has unexpected oflags"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* Don't care: VPO_NOSYNC. */
name|run_ext
operator|=
literal|1
expr_stmt|;
block|}
else|else
name|run_ext
operator|=
literal|0
expr_stmt|;
name|unlock
label|:
name|VM_OBJECT_RUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
block|}
elseif|else
if|if
condition|(
name|level
operator|>=
literal|0
condition|)
block|{
comment|/* 			 * The page is reserved but not yet allocated.  In 			 * other words, it is still free.  Extend the current 			 * run by one page. 			 */
name|run_ext
operator|=
literal|1
expr_stmt|;
endif|#
directive|endif
block|}
elseif|else
if|if
condition|(
operator|(
name|order
operator|=
name|m
operator|->
name|order
operator|)
operator|<
name|VM_NFREEORDER
condition|)
block|{
comment|/* 			 * The page is enqueued in the physical memory 			 * allocator's free page queues.  Moreover, it is the 			 * first page in a power-of-two-sized run of 			 * contiguous free pages.  Add these pages to the end 			 * of the current run, and jump ahead. 			 */
name|run_ext
operator|=
literal|1
operator|<<
name|order
expr_stmt|;
name|m_inc
operator|=
literal|1
operator|<<
name|order
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * Skip the page for one of the following reasons: (1) 			 * It is enqueued in the physical memory allocator's 			 * free page queues.  However, it is not the first 			 * page in a run of contiguous free pages.  (This case 			 * rarely occurs because the scan is performed in 			 * ascending order.) (2) It is not reserved, and it is 			 * transitioning from free to allocated.  (Conversely, 			 * the transition from allocated to free for managed 			 * pages is blocked by the page lock.) (3) It is 			 * allocated but not contained by an object and not 			 * wired, e.g., allocated by Xen's balloon driver. 			 */
name|run_ext
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 		 * Extend or reset the current run of pages. 		 */
if|if
condition|(
name|run_ext
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|run_len
operator|==
literal|0
condition|)
name|m_run
operator|=
name|m
expr_stmt|;
name|run_len
operator|+=
name|run_ext
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|run_len
operator|>
literal|0
condition|)
block|{
name|m_run
operator|=
name|NULL
expr_stmt|;
name|run_len
operator|=
literal|0
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|m_mtx
operator|!=
name|NULL
condition|)
name|mtx_unlock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|run_len
operator|>=
name|npages
condition|)
return|return
operator|(
name|m_run
operator|)
return|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_reclaim_run:  *  *	Try to relocate each of the allocated virtual pages within the  *	specified run of physical pages to a new physical address.  Free the  *	physical pages underlying the relocated virtual pages.  A virtual page  *	is relocatable if and only if it could be laundered or reclaimed by  *	the page daemon.  Whenever possible, a virtual page is relocated to a  *	physical address above "high".  *  *	Returns 0 if every physical page within the run was already free or  *	just freed by a successful relocation.  Otherwise, returns a non-zero  *	value indicating why the last attempt to relocate a virtual page was  *	unsuccessful.  *  *	"req_class" must be an allocation class.  */
end_comment

begin_function
specifier|static
name|int
name|vm_page_reclaim_run
parameter_list|(
name|int
name|req_class
parameter_list|,
name|u_long
name|npages
parameter_list|,
name|vm_page_t
name|m_run
parameter_list|,
name|vm_paddr_t
name|high
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|m_mtx
decl_stmt|,
modifier|*
name|new_mtx
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|m_end
decl_stmt|,
name|m_new
decl_stmt|;
name|int
name|error
decl_stmt|,
name|order
decl_stmt|,
name|req
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|req_class
operator|&
name|VM_ALLOC_CLASS_MASK
operator|)
operator|==
name|req_class
argument_list|,
operator|(
literal|"req_class is not an allocation class"
operator|)
argument_list|)
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|error
operator|=
literal|0
expr_stmt|;
name|m
operator|=
name|m_run
expr_stmt|;
name|m_end
operator|=
name|m_run
operator|+
name|npages
expr_stmt|;
name|m_mtx
operator|=
name|NULL
expr_stmt|;
for|for
control|(
init|;
name|error
operator|==
literal|0
operator|&&
name|m
operator|<
name|m_end
condition|;
name|m
operator|++
control|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_MARKER
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p is PG_FICTITIOUS or PG_MARKER"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Avoid releasing and reacquiring the same page lock. 		 */
name|new_mtx
operator|=
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_mtx
operator|!=
name|new_mtx
condition|)
block|{
if|if
condition|(
name|m_mtx
operator|!=
name|NULL
condition|)
name|mtx_unlock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
name|m_mtx
operator|=
name|new_mtx
expr_stmt|;
name|mtx_lock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
block|}
name|retry
label|:
if|if
condition|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
operator|||
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
name|error
operator|=
name|EBUSY
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|object
operator|=
name|m
operator|->
name|object
operator|)
operator|!=
name|NULL
condition|)
block|{
comment|/* 			 * The page is relocated if and only if it could be 			 * laundered or reclaimed by the page daemon. 			 */
if|if
condition|(
operator|!
name|VM_OBJECT_TRYWLOCK
argument_list|(
name|object
argument_list|)
condition|)
block|{
name|mtx_unlock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|object
condition|)
block|{
comment|/* 					 * The page may have been freed. 					 */
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
elseif|else
if|if
condition|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
operator|||
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
name|error
operator|=
name|EBUSY
expr_stmt|;
goto|goto
name|unlock
goto|;
block|}
block|}
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNHOLDFREE
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p is PG_UNHOLDFREE"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* Don't care: PG_NODUMP, PG_ZERO. */
if|if
condition|(
name|object
operator|->
name|type
operator|!=
name|OBJT_DEFAULT
operator|&&
name|object
operator|->
name|type
operator|!=
name|OBJT_SWAP
operator|&&
name|object
operator|->
name|type
operator|!=
name|OBJT_VNODE
condition|)
name|error
operator|=
name|EINVAL
expr_stmt|;
elseif|else
if|if
condition|(
name|object
operator|->
name|memattr
operator|!=
name|VM_MEMATTR_DEFAULT
condition|)
name|error
operator|=
name|EINVAL
expr_stmt|;
elseif|else
if|if
condition|(
name|m
operator|->
name|queue
operator|!=
name|PQ_NONE
operator|&&
operator|!
name|vm_page_busied
argument_list|(
name|m
argument_list|)
condition|)
block|{
name|KASSERT
argument_list|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|==
name|VM_MEMATTR_DEFAULT
argument_list|,
operator|(
literal|"page %p has an unexpected memattr"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
operator|(
name|VPO_SWAPINPROG
operator||
name|VPO_SWAPSLEEP
operator||
name|VPO_UNMANAGED
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p has unexpected oflags"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* Don't care: VPO_NOSYNC. */
if|if
condition|(
name|m
operator|->
name|valid
operator|!=
literal|0
condition|)
block|{
comment|/* 					 * First, try to allocate a new page 					 * that is above "high".  Failing 					 * that, try to allocate a new page 					 * that is below "m_run".  Allocate 					 * the new page between the end of 					 * "m_run" and "high" only as a last 					 * resort. 					 */
name|req
operator|=
name|req_class
operator||
name|VM_ALLOC_NOOBJ
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_NODUMP
operator|)
operator|!=
literal|0
condition|)
name|req
operator||=
name|VM_ALLOC_NODUMP
expr_stmt|;
if|if
condition|(
name|trunc_page
argument_list|(
name|high
argument_list|)
operator|!=
operator|~
operator|(
name|vm_paddr_t
operator|)
name|PAGE_MASK
condition|)
block|{
name|m_new
operator|=
name|vm_page_alloc_contig
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|req
argument_list|,
literal|1
argument_list|,
name|round_page
argument_list|(
name|high
argument_list|)
argument_list|,
operator|~
operator|(
name|vm_paddr_t
operator|)
literal|0
argument_list|,
name|PAGE_SIZE
argument_list|,
literal|0
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
expr_stmt|;
block|}
else|else
name|m_new
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|m_new
operator|==
name|NULL
condition|)
block|{
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m_run
argument_list|)
expr_stmt|;
name|m_new
operator|=
name|vm_page_alloc_contig
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|req
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
name|pa
operator|-
literal|1
argument_list|,
name|PAGE_SIZE
argument_list|,
literal|0
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|m_new
operator|==
name|NULL
condition|)
block|{
name|pa
operator|+=
name|ptoa
argument_list|(
name|npages
argument_list|)
expr_stmt|;
name|m_new
operator|=
name|vm_page_alloc_contig
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|req
argument_list|,
literal|1
argument_list|,
name|pa
argument_list|,
name|high
argument_list|,
name|PAGE_SIZE
argument_list|,
literal|0
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|m_new
operator|==
name|NULL
condition|)
block|{
name|error
operator|=
name|ENOMEM
expr_stmt|;
goto|goto
name|unlock
goto|;
block|}
name|KASSERT
argument_list|(
name|m_new
operator|->
name|wire_count
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p is wired"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 					 * Replace "m" with the new page.  For 					 * vm_page_replace(), "m" must be busy 					 * and dequeued.  Finally, change "m" 					 * as if vm_page_free() was called. 					 */
if|if
condition|(
name|object
operator|->
name|ref_count
operator|!=
literal|0
condition|)
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m_new
operator|->
name|aflags
operator|=
name|m
operator|->
name|aflags
expr_stmt|;
name|KASSERT
argument_list|(
name|m_new
operator|->
name|oflags
operator|==
name|VPO_UNMANAGED
argument_list|,
operator|(
literal|"page %p is managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m_new
operator|->
name|oflags
operator|=
name|m
operator|->
name|oflags
operator|&
name|VPO_NOSYNC
expr_stmt|;
name|pmap_copy_page
argument_list|(
name|m
argument_list|,
name|m_new
argument_list|)
expr_stmt|;
name|m_new
operator|->
name|valid
operator|=
name|m
operator|->
name|valid
expr_stmt|;
name|m_new
operator|->
name|dirty
operator|=
name|m
operator|->
name|dirty
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|vm_page_xbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remque
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_replace_checked
argument_list|(
name|m_new
argument_list|,
name|object
argument_list|,
name|m
operator|->
name|pindex
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|vm_page_undirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 					 * The new page must be deactivated 					 * before the object is unlocked. 					 */
name|new_mtx
operator|=
name|vm_page_lockptr
argument_list|(
name|m_new
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_mtx
operator|!=
name|new_mtx
condition|)
block|{
name|mtx_unlock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
name|m_mtx
operator|=
name|new_mtx
expr_stmt|;
name|mtx_lock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
block|}
name|vm_page_deactivate
argument_list|(
name|m_new
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|vm_page_remque
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"page %p is dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
name|SLIST_INSERT_HEAD
argument_list|(
operator|&
name|free
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
block|}
else|else
name|error
operator|=
name|EBUSY
expr_stmt|;
name|unlock
label|:
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|order
operator|=
name|m
operator|->
name|order
expr_stmt|;
if|if
condition|(
name|order
operator|<
name|VM_NFREEORDER
condition|)
block|{
comment|/* 				 * The page is enqueued in the physical memory 				 * allocator's free page queues.  Moreover, it 				 * is the first page in a power-of-two-sized 				 * run of contiguous free pages.  Jump ahead 				 * to the last page within that run, and 				 * continue from there. 				 */
name|m
operator|+=
operator|(
literal|1
operator|<<
name|order
operator|)
operator|-
literal|1
expr_stmt|;
block|}
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
elseif|else
if|if
condition|(
name|vm_reserv_is_page_free
argument_list|(
name|m
argument_list|)
condition|)
name|order
operator|=
literal|0
expr_stmt|;
endif|#
directive|endif
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|order
operator|==
name|VM_NFREEORDER
condition|)
name|error
operator|=
name|EINVAL
expr_stmt|;
block|}
block|}
if|if
condition|(
name|m_mtx
operator|!=
name|NULL
condition|)
name|mtx_unlock
argument_list|(
name|m_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|SLIST_FIRST
argument_list|(
operator|&
name|free
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
do|do
block|{
name|SLIST_REMOVE_HEAD
argument_list|(
operator|&
name|free
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
name|vm_phys_freecnt_adj
argument_list|(
name|m
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
operator|!
name|vm_reserv_free_page
argument_list|(
name|m
argument_list|)
condition|)
else|#
directive|else
if|if
condition|(
name|true
condition|)
endif|#
directive|endif
name|vm_phys_free_pages
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
operator|(
name|m
operator|=
name|SLIST_FIRST
argument_list|(
operator|&
name|free
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
do|;
name|vm_page_zero_idle_wakeup
argument_list|()
expr_stmt|;
name|vm_page_free_wakeup
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_define
define|#
directive|define
name|NRUNS
value|16
end_define

begin_expr_stmt
name|CTASSERT
argument_list|(
name|powerof2
argument_list|(
name|NRUNS
argument_list|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_define
define|#
directive|define
name|RUN_INDEX
parameter_list|(
name|count
parameter_list|)
value|((count)& (NRUNS - 1))
end_define

begin_define
define|#
directive|define
name|MIN_RECLAIM
value|8
end_define

begin_comment
comment|/*  *	vm_page_reclaim_contig:  *  *	Reclaim allocated, contiguous physical memory satisfying the specified  *	conditions by relocating the virtual pages using that physical memory.  *	Returns true if reclamation is successful and false otherwise.  Since  *	relocation requires the allocation of physical pages, reclamation may  *	fail due to a shortage of free pages.  When reclamation fails, callers  *	are expected to perform VM_WAIT before retrying a failed allocation  *	operation, e.g., vm_page_alloc_contig().  *  *	The caller must always specify an allocation class through "req".  *  *	allocation classes:  *	VM_ALLOC_NORMAL		normal process request  *	VM_ALLOC_SYSTEM		system *really* needs a page  *	VM_ALLOC_INTERRUPT	interrupt time request  *  *	The optional allocation flags are ignored.  *  *	"npages" must be greater than zero.  Both "alignment" and "boundary"  *	must be a power of two.  */
end_comment

begin_function
name|bool
name|vm_page_reclaim_contig
parameter_list|(
name|int
name|req
parameter_list|,
name|u_long
name|npages
parameter_list|,
name|vm_paddr_t
name|low
parameter_list|,
name|vm_paddr_t
name|high
parameter_list|,
name|u_long
name|alignment
parameter_list|,
name|vm_paddr_t
name|boundary
parameter_list|)
block|{
name|vm_paddr_t
name|curr_low
decl_stmt|;
name|vm_page_t
name|m_run
decl_stmt|,
name|m_runs
index|[
name|NRUNS
index|]
decl_stmt|;
name|u_long
name|count
decl_stmt|,
name|reclaimed
decl_stmt|;
name|int
name|error
decl_stmt|,
name|i
decl_stmt|,
name|options
decl_stmt|,
name|req_class
decl_stmt|;
name|KASSERT
argument_list|(
name|npages
operator|>
literal|0
argument_list|,
operator|(
literal|"npages is 0"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|powerof2
argument_list|(
name|alignment
argument_list|)
argument_list|,
operator|(
literal|"alignment is not a power of 2"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|powerof2
argument_list|(
name|boundary
argument_list|)
argument_list|,
operator|(
literal|"boundary is not a power of 2"
operator|)
argument_list|)
expr_stmt|;
name|req_class
operator|=
name|req
operator|&
name|VM_ALLOC_CLASS_MASK
expr_stmt|;
comment|/* 	 * The page daemon is allowed to dig deeper into the free page list. 	 */
if|if
condition|(
name|curproc
operator|==
name|pageproc
operator|&&
name|req_class
operator|!=
name|VM_ALLOC_INTERRUPT
condition|)
name|req_class
operator|=
name|VM_ALLOC_SYSTEM
expr_stmt|;
comment|/* 	 * Return if the number of free pages cannot satisfy the requested 	 * allocation. 	 */
name|count
operator|=
name|vm_cnt
operator|.
name|v_free_count
operator|+
name|vm_cnt
operator|.
name|v_cache_count
expr_stmt|;
if|if
condition|(
name|count
operator|<
name|npages
operator|+
name|vm_cnt
operator|.
name|v_free_reserved
operator|||
operator|(
name|count
operator|<
name|npages
operator|+
name|vm_cnt
operator|.
name|v_interrupt_free_min
operator|&&
name|req_class
operator|==
name|VM_ALLOC_SYSTEM
operator|)
operator|||
operator|(
name|count
operator|<
name|npages
operator|&&
name|req_class
operator|==
name|VM_ALLOC_INTERRUPT
operator|)
condition|)
return|return
operator|(
name|false
operator|)
return|;
comment|/* 	 * Scan up to three times, relaxing the restrictions ("options") on 	 * the reclamation of reservations and superpages each time. 	 */
for|for
control|(
name|options
operator|=
name|VPSC_NORESERV
init|;
condition|;
control|)
block|{
comment|/* 		 * Find the highest runs that satisfy the given constraints 		 * and restrictions, and record them in "m_runs". 		 */
name|curr_low
operator|=
name|low
expr_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|m_run
operator|=
name|vm_phys_scan_contig
argument_list|(
name|npages
argument_list|,
name|curr_low
argument_list|,
name|high
argument_list|,
name|alignment
argument_list|,
name|boundary
argument_list|,
name|options
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_run
operator|==
name|NULL
condition|)
break|break;
name|curr_low
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m_run
argument_list|)
operator|+
name|ptoa
argument_list|(
name|npages
argument_list|)
expr_stmt|;
name|m_runs
index|[
name|RUN_INDEX
argument_list|(
name|count
argument_list|)
index|]
operator|=
name|m_run
expr_stmt|;
name|count
operator|++
expr_stmt|;
block|}
comment|/* 		 * Reclaim the highest runs in LIFO (descending) order until 		 * the number of reclaimed pages, "reclaimed", is at least 		 * MIN_RECLAIM.  Reset "reclaimed" each time because each 		 * reclamation is idempotent, and runs will (likely) recur 		 * from one scan to the next as restrictions are relaxed. 		 */
name|reclaimed
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|count
operator|>
literal|0
operator|&&
name|i
operator|<
name|NRUNS
condition|;
name|i
operator|++
control|)
block|{
name|count
operator|--
expr_stmt|;
name|m_run
operator|=
name|m_runs
index|[
name|RUN_INDEX
argument_list|(
name|count
argument_list|)
index|]
expr_stmt|;
name|error
operator|=
name|vm_page_reclaim_run
argument_list|(
name|req_class
argument_list|,
name|npages
argument_list|,
name|m_run
argument_list|,
name|high
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|==
literal|0
condition|)
block|{
name|reclaimed
operator|+=
name|npages
expr_stmt|;
if|if
condition|(
name|reclaimed
operator|>=
name|MIN_RECLAIM
condition|)
return|return
operator|(
name|true
operator|)
return|;
block|}
block|}
comment|/* 		 * Either relax the restrictions on the next scan or return if 		 * the last scan had no restrictions. 		 */
if|if
condition|(
name|options
operator|==
name|VPSC_NORESERV
condition|)
name|options
operator|=
name|VPSC_NOSUPER
expr_stmt|;
elseif|else
if|if
condition|(
name|options
operator|==
name|VPSC_NOSUPER
condition|)
name|options
operator|=
name|VPSC_ANY
expr_stmt|;
elseif|else
if|if
condition|(
name|options
operator|==
name|VPSC_ANY
condition|)
return|return
operator|(
name|reclaimed
operator|!=
literal|0
operator|)
return|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_wait:	(also see VM_WAIT macro)  *  *	Sleep until free pages are available for allocation.  *	- Called in various places before memory allocations.  */
end_comment

begin_function
name|void
name|vm_wait
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|curproc
operator|==
name|pageproc
condition|)
block|{
name|vm_pageout_pages_needed
operator|=
literal|1
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PSWP
argument_list|,
literal|"VMWait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|__predict_false
argument_list|(
name|pageproc
operator|==
name|NULL
argument_list|)
condition|)
name|panic
argument_list|(
literal|"vm_wait in early boot"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_pageout_wanted
condition|)
block|{
name|vm_pageout_wanted
operator|=
name|true
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pageout_wanted
argument_list|)
expr_stmt|;
block|}
name|vm_pages_needed
operator|=
name|true
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_free_count
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PVM
argument_list|,
literal|"vmwait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_waitpfault:	(also see VM_WAITPFAULT macro)  *  *	Sleep until free pages are available for allocation.  *	- Called only in vm_fault so that processes page faulting  *	  can be easily tracked.  *	- Sleeps at a lower priority than vm_wait() so that vm_wait()ing  *	  processes will be able to grab memory first.  Do not change  *	  this balance without careful testing first.  */
end_comment

begin_function
name|void
name|vm_waitpfault
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_pageout_wanted
condition|)
block|{
name|vm_pageout_wanted
operator|=
name|true
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pageout_wanted
argument_list|)
expr_stmt|;
block|}
name|vm_pages_needed
operator|=
name|true
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_free_count
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PUSER
argument_list|,
literal|"pfault"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|struct
name|vm_pagequeue
modifier|*
name|vm_page_pagequeue
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
name|vm_page_in_laundry
argument_list|(
name|m
argument_list|)
condition|)
return|return
operator|(
operator|&
name|vm_dom
index|[
literal|0
index|]
operator|.
name|vmd_pagequeues
index|[
name|m
operator|->
name|queue
index|]
operator|)
return|;
else|else
return|return
operator|(
operator|&
name|vm_phys_domain
argument_list|(
name|m
argument_list|)
operator|->
name|vmd_pagequeues
index|[
name|m
operator|->
name|queue
index|]
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_dequeue:  *  *	Remove the given page from its current page queue.  *  *	The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_dequeue
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|<
name|PQ_COUNT
argument_list|,
operator|(
literal|"vm_page_dequeue: page %p is not queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pq
operator|=
name|vm_page_pagequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pagequeue_lock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_NONE
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|vm_pagequeue_cnt_dec
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|vm_pagequeue_unlock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_dequeue_locked:  *  *	Remove the given page from its current page queue.  *  *	The page and page queue must be locked.  */
end_comment

begin_function
name|void
name|vm_page_dequeue_locked
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pq
operator|=
name|vm_page_pagequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pagequeue_assert_locked
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_NONE
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|vm_pagequeue_cnt_dec
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_enqueue:  *  *	Add the given page to the specified page queue.  *  *	The page must be locked.  */
end_comment

begin_function
specifier|static
name|void
name|vm_page_enqueue
parameter_list|(
name|uint8_t
name|queue
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|queue
operator|<
name|PQ_COUNT
argument_list|,
operator|(
literal|"vm_page_enqueue: invalid queue %u request for page %p"
operator|,
name|queue
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|queue
operator|==
name|PQ_LAUNDRY
condition|)
name|pq
operator|=
operator|&
name|vm_dom
index|[
literal|0
index|]
operator|.
name|vmd_pagequeues
index|[
name|queue
index|]
expr_stmt|;
else|else
name|pq
operator|=
operator|&
name|vm_phys_domain
argument_list|(
name|m
argument_list|)
operator|->
name|vmd_pagequeues
index|[
name|queue
index|]
expr_stmt|;
name|vm_pagequeue_lock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|queue
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|vm_pagequeue_cnt_inc
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|vm_pagequeue_unlock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_requeue:  *  *	Move the given page to the tail of its current page queue.  *  *	The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_requeue
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|!=
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_requeue: page %p is not queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pq
operator|=
name|vm_page_pagequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pagequeue_lock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|vm_pagequeue_unlock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_requeue_locked:  *  *	Move the given page to the tail of its current page queue.  *  *	The page queue must be locked.  */
end_comment

begin_function
name|void
name|vm_page_requeue_locked
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|!=
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_requeue_locked: page %p is not queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pq
operator|=
name|vm_page_pagequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pagequeue_assert_locked
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_activate:  *  *	Put the specified page on the active list (if appropriate).  *	Ensure that act_count is at least ACT_INIT but do not otherwise  *	mess with it.  *  *	The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_activate
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|queue
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|queue
operator|=
name|m
operator|->
name|queue
operator|)
operator|!=
name|PQ_ACTIVE
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|<
name|ACT_INIT
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_INIT
expr_stmt|;
if|if
condition|(
name|queue
operator|!=
name|PQ_NONE
condition|)
name|vm_page_dequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_enqueue
argument_list|(
name|PQ_ACTIVE
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
else|else
name|KASSERT
argument_list|(
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_activate: wired page %p is queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|<
name|ACT_INIT
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_INIT
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_wakeup:  *  *	Helper routine for vm_page_free_toq().  This routine is called  *	when a page is added to the free queues.  *  *	The page queues must be locked.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|vm_page_free_wakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * if pageout daemon needs pages, then tell it that there are 	 * some free. 	 */
if|if
condition|(
name|vm_pageout_pages_needed
operator|&&
name|vm_cnt
operator|.
name|v_cache_count
operator|+
name|vm_cnt
operator|.
name|v_free_count
operator|>=
name|vm_cnt
operator|.
name|v_pageout_free_min
condition|)
block|{
name|wakeup
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|)
expr_stmt|;
name|vm_pageout_pages_needed
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * wakeup processes that are waiting on memory if we hit a 	 * high water mark. And wakeup scheduler process if we have 	 * lots of memory. this process will swapin processes. 	 */
if|if
condition|(
name|vm_pages_needed
operator|&&
operator|!
name|vm_page_count_min
argument_list|()
condition|)
block|{
name|vm_pages_needed
operator|=
name|false
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_toq:  *  *	Returns the given page to the free list,  *	disassociating it with any VM object.  *  *	The object must be locked.  The page must be locked if it is managed.  */
end_comment

begin_function
name|void
name|vm_page_free_toq
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_free_toq: freeing mapped page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_free_toq: unmanaged page %p is queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|PCPU_INC
argument_list|(
name|cnt
operator|.
name|v_tfree
argument_list|)
expr_stmt|;
if|if
condition|(
name|vm_page_sbusied
argument_list|(
name|m
argument_list|)
condition|)
name|panic
argument_list|(
literal|"vm_page_free: freeing busy page %p"
argument_list|,
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Unqueue, then remove page.  Note that we cannot destroy 	 * the page here because we do not want to call the pager's 	 * callback routine until after we've put the page on the 	 * appropriate free queue. 	 */
name|vm_page_remque
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * If fictitious remove object association and 	 * return, otherwise delay object association removal. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
return|return;
block|}
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|vm_page_undirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_page_free: freeing wired page %p"
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNHOLDFREE
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_free: freeing PG_UNHOLDFREE page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator||=
name|PG_UNHOLDFREE
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Restore the default memory attribute to the page. 		 */
if|if
condition|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|!=
name|VM_MEMATTR_DEFAULT
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
expr_stmt|;
comment|/* 		 * Insert the page into the physical memory allocator's free 		 * page queues. 		 */
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|vm_phys_freecnt_adj
argument_list|(
name|m
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
operator|!
name|vm_reserv_free_page
argument_list|(
name|m
argument_list|)
condition|)
else|#
directive|else
if|if
condition|(
name|TRUE
condition|)
endif|#
directive|endif
name|vm_phys_free_pages
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|!=
literal|0
condition|)
operator|++
name|vm_page_zero_count
expr_stmt|;
else|else
name|vm_page_zero_idle_wakeup
argument_list|()
expr_stmt|;
name|vm_page_free_wakeup
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_wire:  *  *	Mark this page as wired down by yet  *	another map, removing it from paging queues  *	as necessary.  *  *	If the page is fictitious, then its wire count must remain one.  *  *	The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_wire
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
comment|/* 	 * Only bump the wire statistics if the page is not already wired, 	 * and only unqueue the page if it is on some queue (if it is unmanaged 	 * it is already off the queues). 	 */
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|1
argument_list|,
operator|(
literal|"vm_page_wire: fictitious page %p's wire count isn't one"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|||
name|m
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_wire: unmanaged page %p is queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vm_page_remque
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
name|m
operator|->
name|wire_count
operator|++
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_wire: wire_count overflow m=%p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_unwire:  *  * Release one wiring of the specified page, potentially allowing it to be  * paged out.  Returns TRUE if the number of wirings transitions to zero and  * FALSE otherwise.  *  * Only managed pages belonging to an object can be paged out.  If the number  * of wirings transitions to zero and the page is eligible for page out, then  * the page is added to the specified paging queue (unless PQ_NONE is  * specified).  *  * If a page is fictitious, then its wire count must always be one.  *  * A managed page must be locked.  */
end_comment

begin_function
name|boolean_t
name|vm_page_unwire
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|uint8_t
name|queue
parameter_list|)
block|{
name|KASSERT
argument_list|(
name|queue
operator|<
name|PQ_COUNT
operator|||
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_unwire: invalid queue %u request for page %p"
operator|,
name|queue
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|1
argument_list|,
operator|(
literal|"vm_page_unwire: fictitious page %p's wire count isn't one"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
if|if
condition|(
name|m
operator|->
name|wire_count
operator|>
literal|0
condition|)
block|{
name|m
operator|->
name|wire_count
operator|--
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|&&
name|m
operator|->
name|object
operator|!=
name|NULL
operator|&&
name|queue
operator|!=
name|PQ_NONE
condition|)
name|vm_page_enqueue
argument_list|(
name|queue
argument_list|,
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
else|else
name|panic
argument_list|(
literal|"vm_page_unwire: page %p's wire count is zero"
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Move the specified page to the inactive queue.  *  * Normally, "noreuse" is FALSE, resulting in LRU ordering of the inactive  * queue.  However, setting "noreuse" to TRUE will accelerate the specified  * page's reclamation, but it will not unmap the page from any address space.  * This is implemented by inserting the page near the head of the inactive  * queue, using a marker page to guide FIFO insertion ordering.  *  * The page must be locked.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|_vm_page_deactivate
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|boolean_t
name|noreuse
parameter_list|)
block|{
name|struct
name|vm_pagequeue
modifier|*
name|pq
decl_stmt|;
name|int
name|queue
decl_stmt|;
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Ignore if the page is already inactive, unless it is unlikely to be 	 * reactivated. 	 */
if|if
condition|(
operator|(
name|queue
operator|=
name|m
operator|->
name|queue
operator|)
operator|==
name|PQ_INACTIVE
operator|&&
operator|!
name|noreuse
condition|)
return|return;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|pq
operator|=
operator|&
name|vm_phys_domain
argument_list|(
name|m
argument_list|)
operator|->
name|vmd_pagequeues
index|[
name|PQ_INACTIVE
index|]
expr_stmt|;
comment|/* Avoid multiple acquisitions of the inactive queue lock. */
if|if
condition|(
name|queue
operator|==
name|PQ_INACTIVE
condition|)
block|{
name|vm_pagequeue_lock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|vm_page_dequeue_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|queue
operator|!=
name|PQ_NONE
condition|)
name|vm_page_dequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_pagequeue_lock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
name|m
operator|->
name|queue
operator|=
name|PQ_INACTIVE
expr_stmt|;
if|if
condition|(
name|noreuse
condition|)
name|TAILQ_INSERT_BEFORE
argument_list|(
operator|&
name|vm_phys_domain
argument_list|(
name|m
argument_list|)
operator|->
name|vmd_inacthead
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pq
operator|->
name|pq_pl
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|q
argument_list|)
expr_stmt|;
name|vm_pagequeue_cnt_inc
argument_list|(
name|pq
argument_list|)
expr_stmt|;
name|vm_pagequeue_unlock
argument_list|(
name|pq
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Move the specified page to the inactive queue.  *  * The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_deactivate
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|_vm_page_deactivate
argument_list|(
name|m
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Move the specified page to the inactive queue with the expectation  * that it is unlikely to be reused.  *  * The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_deactivate_noreuse
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|_vm_page_deactivate
argument_list|(
name|m
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_launder  *  * 	Put a page in the laundry.  */
end_comment

begin_function
name|void
name|vm_page_launder
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|queue
decl_stmt|;
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|queue
operator|=
name|m
operator|->
name|queue
operator|)
operator|!=
name|PQ_LAUNDRY
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|queue
operator|!=
name|PQ_NONE
condition|)
name|vm_page_dequeue
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_enqueue
argument_list|(
name|PQ_LAUNDRY
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
else|else
name|KASSERT
argument_list|(
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"wired page %p is queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * vm_page_try_to_free()  *  *	Attempt to free the page.  If we cannot free it, we do nothing.  *	1 is returned on success, 0 on failure.  */
end_comment

begin_function
name|int
name|vm_page_try_to_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|NULL
condition|)
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|wire_count
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
operator|||
name|vm_page_busied
argument_list|(
name|m
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_page_advise  *  * 	Deactivate or do nothing, as appropriate.  *  *	The object and page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_advise
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|advice
parameter_list|)
block|{
name|vm_page_assert_locked
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|advice
operator|==
name|MADV_FREE
condition|)
comment|/* 		 * Mark the page clean.  This will allow the page to be freed 		 * without first paging it out.  MADV_FREE pages are often 		 * quickly reused by malloc(3), so we do not do anything that 		 * would result in a page fault on a later access. 		 */
name|vm_page_undirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|advice
operator|!=
name|MADV_DONTNEED
condition|)
return|return;
comment|/* 	 * Clear any references to the page.  Otherwise, the page daemon will 	 * immediately reactivate the page. 	 */
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
if|if
condition|(
name|advice
operator|!=
name|MADV_FREE
operator|&&
name|m
operator|->
name|dirty
operator|==
literal|0
operator|&&
name|pmap_is_modified
argument_list|(
name|m
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Place clean pages near the head of the inactive queue rather than 	 * the tail, thus defeating the queue's LRU operation and ensuring that 	 * the page will be reused quickly.  Dirty pages not already in the 	 * laundry are moved there. 	 */
if|if
condition|(
name|m
operator|->
name|dirty
operator|==
literal|0
condition|)
name|vm_page_deactivate_noreuse
argument_list|(
name|m
argument_list|)
expr_stmt|;
else|else
name|vm_page_launder
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Grab a page, waiting until we are waken up due to the page  * changing state.  We keep on waiting, if the page continues  * to be in the object.  If the page doesn't exist, first allocate it  * and then conditionally zero it.  *  * This routine may sleep.  *  * The object must be locked on entry.  The lock will, however, be released  * and reacquired if the routine sleeps.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_grab
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|allocflags
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|int
name|sleep
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|==
literal|0
operator|||
operator|(
name|allocflags
operator|&
name|VM_ALLOC_IGN_SBUSY
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_grab: VM_ALLOC_SBUSY/VM_ALLOC_IGN_SBUSY mismatch"
operator|)
argument_list|)
expr_stmt|;
name|retrylookup
label|:
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|sleep
operator|=
operator|(
name|allocflags
operator|&
name|VM_ALLOC_IGN_SBUSY
operator|)
operator|!=
literal|0
condition|?
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
else|:
name|vm_page_busied
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|sleep
condition|)
block|{
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_NOWAIT
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
comment|/* 			 * Reference the page before unlocking and 			 * sleeping so that the page daemon is less 			 * likely to reclaim it. 			 */
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|vm_page_busy_sleep
argument_list|(
name|m
argument_list|,
literal|"pgrbwt"
argument_list|,
operator|(
name|allocflags
operator|&
name|VM_ALLOC_IGN_SBUSY
operator|)
operator|!=
literal|0
argument_list|)
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|retrylookup
goto|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
block|{
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_wire
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|allocflags
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_SBUSY
operator|)
operator|)
operator|==
literal|0
condition|)
name|vm_page_xbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_SBUSY
operator|)
operator|!=
literal|0
condition|)
name|vm_page_sbusy
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
block|}
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|allocflags
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_NOWAIT
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|VM_OBJECT_WUNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|VM_OBJECT_WLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|retrylookup
goto|;
block|}
if|if
condition|(
name|allocflags
operator|&
name|VM_ALLOC_ZERO
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Mapping function for valid or dirty bits in a page.  *  * Inputs are required to range within a page.  */
end_comment

begin_function
name|vm_page_bits_t
name|vm_page_bits
parameter_list|(
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|first_bit
decl_stmt|;
name|int
name|last_bit
decl_stmt|;
name|KASSERT
argument_list|(
name|base
operator|+
name|size
operator|<=
name|PAGE_SIZE
argument_list|,
operator|(
literal|"vm_page_bits: illegal base/size %d/%d"
operator|,
name|base
operator|,
name|size
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return
operator|(
literal|0
operator|)
return|;
name|first_bit
operator|=
name|base
operator|>>
name|DEV_BSHIFT
expr_stmt|;
name|last_bit
operator|=
operator|(
name|base
operator|+
name|size
operator|-
literal|1
operator|)
operator|>>
name|DEV_BSHIFT
expr_stmt|;
return|return
operator|(
operator|(
operator|(
name|vm_page_bits_t
operator|)
literal|2
operator|<<
name|last_bit
operator|)
operator|-
operator|(
operator|(
name|vm_page_bits_t
operator|)
literal|1
operator|<<
name|first_bit
operator|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_set_valid_range:  *  *	Sets portions of a page valid.  The arguments are expected  *	to be DEV_BSIZE aligned but if they aren't the bitmap is inclusive  *	of any partial chunks touched by the range.  The invalid portion of  *	such chunks will be zeroed.  *  *	(base + size) must be less then or equal to PAGE_SIZE.  */
end_comment

begin_function
name|void
name|vm_page_set_valid_range
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|endoff
decl_stmt|,
name|frag
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return;
comment|/* 	 * If the base is not DEV_BSIZE aligned and the valid 	 * bit is clear, we have to zero out a portion of the 	 * first block. 	 */
if|if
condition|(
operator|(
name|frag
operator|=
name|rounddown2
argument_list|(
name|base
argument_list|,
name|DEV_BSIZE
argument_list|)
operator|)
operator|!=
name|base
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|base
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|frag
argument_list|,
name|base
operator|-
name|frag
argument_list|)
expr_stmt|;
comment|/* 	 * If the ending offset is not DEV_BSIZE aligned and the 	 * valid bit is clear, we have to zero out a portion of 	 * the last block. 	 */
name|endoff
operator|=
name|base
operator|+
name|size
expr_stmt|;
if|if
condition|(
operator|(
name|frag
operator|=
name|rounddown2
argument_list|(
name|endoff
argument_list|,
name|DEV_BSIZE
argument_list|)
operator|)
operator|!=
name|endoff
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|endoff
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|endoff
argument_list|,
name|DEV_BSIZE
operator|-
operator|(
name|endoff
operator|&
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Assert that no previously invalid block that is now being validated 	 * is already dirty. 	 */
name|KASSERT
argument_list|(
operator|(
operator|~
name|m
operator|->
name|valid
operator|&
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
operator|&
name|m
operator|->
name|dirty
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_set_valid_range: page %p is dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Set valid bits inclusive of any overlap. 	 */
name|m
operator|->
name|valid
operator||=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Clear the given bits from the specified page's dirty field.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|vm_page_clear_dirty_mask
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_page_bits_t
name|pagebits
parameter_list|)
block|{
name|uintptr_t
name|addr
decl_stmt|;
if|#
directive|if
name|PAGE_SIZE
operator|<
literal|16384
name|int
name|shift
decl_stmt|;
endif|#
directive|endif
comment|/* 	 * If the object is locked and the page is neither exclusive busy nor 	 * write mapped, then the page's dirty field cannot possibly be 	 * set by a concurrent pmap operation. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|!
name|pmap_page_is_write_mapped
argument_list|(
name|m
argument_list|)
condition|)
name|m
operator|->
name|dirty
operator|&=
operator|~
name|pagebits
expr_stmt|;
else|else
block|{
comment|/* 		 * The pmap layer can call vm_page_dirty() without 		 * holding a distinguished lock.  The combination of 		 * the object's lock and an atomic operation suffice 		 * to guarantee consistency of the page dirty field. 		 * 		 * For PAGE_SIZE == 32768 case, compiler already 		 * properly aligns the dirty field, so no forcible 		 * alignment is needed. Only require existence of 		 * atomic_clear_64 when page size is 32768. 		 */
name|addr
operator|=
operator|(
name|uintptr_t
operator|)
operator|&
name|m
operator|->
name|dirty
expr_stmt|;
if|#
directive|if
name|PAGE_SIZE
operator|==
literal|32768
name|atomic_clear_64
argument_list|(
operator|(
name|uint64_t
operator|*
operator|)
name|addr
argument_list|,
name|pagebits
argument_list|)
expr_stmt|;
elif|#
directive|elif
name|PAGE_SIZE
operator|==
literal|16384
name|atomic_clear_32
argument_list|(
operator|(
name|uint32_t
operator|*
operator|)
name|addr
argument_list|,
name|pagebits
argument_list|)
expr_stmt|;
else|#
directive|else
comment|/* PAGE_SIZE<= 8192 */
comment|/* 		 * Use a trick to perform a 32-bit atomic on the 		 * containing aligned word, to not depend on the existence 		 * of atomic_clear_{8, 16}. 		 */
name|shift
operator|=
name|addr
operator|&
operator|(
sizeof|sizeof
argument_list|(
name|uint32_t
argument_list|)
operator|-
literal|1
operator|)
expr_stmt|;
if|#
directive|if
name|BYTE_ORDER
operator|==
name|BIG_ENDIAN
name|shift
operator|=
operator|(
sizeof|sizeof
argument_list|(
name|uint32_t
argument_list|)
operator|-
sizeof|sizeof
argument_list|(
name|m
operator|->
name|dirty
argument_list|)
operator|-
name|shift
operator|)
operator|*
name|NBBY
expr_stmt|;
else|#
directive|else
name|shift
operator|*=
name|NBBY
expr_stmt|;
endif|#
directive|endif
name|addr
operator|&=
operator|~
operator|(
sizeof|sizeof
argument_list|(
name|uint32_t
argument_list|)
operator|-
literal|1
operator|)
expr_stmt|;
name|atomic_clear_32
argument_list|(
operator|(
name|uint32_t
operator|*
operator|)
name|addr
argument_list|,
name|pagebits
operator|<<
name|shift
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* PAGE_SIZE */
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_set_validclean:  *  *	Sets portions of a page valid and clean.  The arguments are expected  *	to be DEV_BSIZE aligned but if they aren't the bitmap is inclusive  *	of any partial chunks touched by the range.  The invalid portion of  *	such chunks will be zero'd.  *  *	(base + size) must be less then or equal to PAGE_SIZE.  */
end_comment

begin_function
name|void
name|vm_page_set_validclean
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_bits_t
name|oldvalid
decl_stmt|,
name|pagebits
decl_stmt|;
name|int
name|endoff
decl_stmt|,
name|frag
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return;
comment|/* 	 * If the base is not DEV_BSIZE aligned and the valid 	 * bit is clear, we have to zero out a portion of the 	 * first block. 	 */
if|if
condition|(
operator|(
name|frag
operator|=
name|rounddown2
argument_list|(
name|base
argument_list|,
name|DEV_BSIZE
argument_list|)
operator|)
operator|!=
name|base
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
operator|(
name|vm_page_bits_t
operator|)
literal|1
operator|<<
operator|(
name|base
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|frag
argument_list|,
name|base
operator|-
name|frag
argument_list|)
expr_stmt|;
comment|/* 	 * If the ending offset is not DEV_BSIZE aligned and the 	 * valid bit is clear, we have to zero out a portion of 	 * the last block. 	 */
name|endoff
operator|=
name|base
operator|+
name|size
expr_stmt|;
if|if
condition|(
operator|(
name|frag
operator|=
name|rounddown2
argument_list|(
name|endoff
argument_list|,
name|DEV_BSIZE
argument_list|)
operator|)
operator|!=
name|endoff
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
operator|(
name|vm_page_bits_t
operator|)
literal|1
operator|<<
operator|(
name|endoff
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|endoff
argument_list|,
name|DEV_BSIZE
operator|-
operator|(
name|endoff
operator|&
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Set valid, clear dirty bits.  If validating the entire 	 * page we can safely clear the pmap modify bit.  We also 	 * use this opportunity to clear the VPO_NOSYNC flag.  If a process 	 * takes a write fault on a MAP_NOSYNC memory area the flag will 	 * be set again. 	 * 	 * We set valid bits inclusive of any overlap, but we can only 	 * clear dirty bits for DEV_BSIZE chunks that are fully within 	 * the range. 	 */
name|oldvalid
operator|=
name|m
operator|->
name|valid
expr_stmt|;
name|pagebits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator||=
name|pagebits
expr_stmt|;
if|#
directive|if
literal|0
comment|/* NOT YET */
block|if ((frag = base& (DEV_BSIZE - 1)) != 0) { 		frag = DEV_BSIZE - frag; 		base += frag; 		size -= frag; 		if (size< 0) 			size = 0; 	} 	pagebits = vm_page_bits(base, size& (DEV_BSIZE - 1));
endif|#
directive|endif
if|if
condition|(
name|base
operator|==
literal|0
operator|&&
name|size
operator|==
name|PAGE_SIZE
condition|)
block|{
comment|/* 		 * The page can only be modified within the pmap if it is 		 * mapped, and it can only be mapped if it was previously 		 * fully valid. 		 */
if|if
condition|(
name|oldvalid
operator|==
name|VM_PAGE_BITS_ALL
condition|)
comment|/* 			 * Perform the pmap_clear_modify() first.  Otherwise, 			 * a concurrent pmap operation, such as 			 * pmap_protect(), could clear a modification in the 			 * pmap and set the dirty field on the page before 			 * pmap_clear_modify() had begun and after the dirty 			 * field was cleared here. 			 */
name|pmap_clear_modify
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|dirty
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|oflags
operator|&=
operator|~
name|VPO_NOSYNC
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|oldvalid
operator|!=
name|VM_PAGE_BITS_ALL
condition|)
name|m
operator|->
name|dirty
operator|&=
operator|~
name|pagebits
expr_stmt|;
else|else
name|vm_page_clear_dirty_mask
argument_list|(
name|m
argument_list|,
name|pagebits
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_clear_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_clear_dirty_mask
argument_list|(
name|m
argument_list|,
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_set_invalid:  *  *	Invalidates DEV_BSIZE'd chunks within a page.  Both the  *	valid and dirty bits for the effected areas are cleared.  */
end_comment

begin_function
name|void
name|vm_page_set_invalid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_bits_t
name|bits
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
operator|&&
name|base
operator|==
literal|0
operator|&&
name|IDX_TO_OFF
argument_list|(
name|m
operator|->
name|pindex
argument_list|)
operator|+
name|size
operator|>=
name|object
operator|->
name|un_pager
operator|.
name|vnp
operator|.
name|vnp_size
condition|)
name|bits
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
else|else
name|bits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|ref_count
operator|!=
literal|0
operator|&&
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|&&
name|bits
operator|!=
literal|0
condition|)
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|bits
operator|==
literal|0
operator|&&
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|)
operator|||
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_set_invalid: page %p is mapped"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator|&=
operator|~
name|bits
expr_stmt|;
name|m
operator|->
name|dirty
operator|&=
operator|~
name|bits
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_zero_invalid()  *  *	The kernel assumes that the invalid portions of a page contain  *	garbage, but such pages can be mapped into memory by user code.  *	When this occurs, we must zero out the non-valid portions of the  *	page so user code sees what it expects.  *  *	Pages are most often semi-valid when the end of a file is mapped  *	into memory and the file's size is not page aligned.  */
end_comment

begin_function
name|void
name|vm_page_zero_invalid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|boolean_t
name|setvalid
parameter_list|)
block|{
name|int
name|b
decl_stmt|;
name|int
name|i
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
comment|/* 	 * Scan the valid bits looking for invalid sections that 	 * must be zeroed.  Invalid sub-DEV_BSIZE'd areas ( where the 	 * valid bit may be set ) have already been zeroed by 	 * vm_page_set_validclean(). 	 */
for|for
control|(
name|b
operator|=
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|PAGE_SIZE
operator|/
name|DEV_BSIZE
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|i
operator|==
operator|(
name|PAGE_SIZE
operator|/
name|DEV_BSIZE
operator|)
operator|||
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
operator|(
name|vm_page_bits_t
operator|)
literal|1
operator|<<
name|i
operator|)
operator|)
condition|)
block|{
if|if
condition|(
name|i
operator|>
name|b
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|b
operator|<<
name|DEV_BSHIFT
argument_list|,
operator|(
name|i
operator|-
name|b
operator|)
operator|<<
name|DEV_BSHIFT
argument_list|)
expr_stmt|;
block|}
name|b
operator|=
name|i
operator|+
literal|1
expr_stmt|;
block|}
block|}
comment|/* 	 * setvalid is TRUE when we can safely set the zero'd areas 	 * as being valid.  We can do this if there are no cache consistancy 	 * issues.  e.g. it is ok to do with UFS, but not ok to do with NFS. 	 */
if|if
condition|(
name|setvalid
condition|)
name|m
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_is_valid:  *  *	Is (partial) page valid?  Note that the case where size == 0  *	will return FALSE in the degenerate case where the page is  *	entirely invalid, and TRUE otherwise.  */
end_comment

begin_function
name|int
name|vm_page_is_valid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_bits_t
name|bits
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|bits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|->
name|valid
operator|!=
literal|0
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
name|bits
operator|)
operator|==
name|bits
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_ps_is_valid:  *  *	Returns TRUE if the entire (super)page is valid and FALSE otherwise.  */
end_comment

begin_function
name|boolean_t
name|vm_page_ps_is_valid
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|npages
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|npages
operator|=
name|atop
argument_list|(
name|pagesizes
index|[
name|m
operator|->
name|psind
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * The physically contiguous pages that make up a superpage, i.e., a 	 * page with a page size index ("psind") greater than zero, will 	 * occupy adjacent entries in vm_page_array[]. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|npages
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|m
index|[
name|i
index|]
operator|.
name|valid
operator|!=
name|VM_PAGE_BITS_ALL
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Set the page's dirty bits if the page is modified.  */
end_comment

begin_function
name|void
name|vm_page_test_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|!=
name|VM_PAGE_BITS_ALL
operator|&&
name|pmap_is_modified
argument_list|(
name|m
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_lock_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|file
parameter_list|,
name|int
name|line
parameter_list|)
block|{
name|mtx_lock_flags_
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|,
literal|0
argument_list|,
name|file
argument_list|,
name|line
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_unlock_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|file
parameter_list|,
name|int
name|line
parameter_list|)
block|{
name|mtx_unlock_flags_
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|,
literal|0
argument_list|,
name|file
argument_list|,
name|line
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|int
name|vm_page_trylock_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|file
parameter_list|,
name|int
name|line
parameter_list|)
block|{
return|return
operator|(
name|mtx_trylock_flags_
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|,
literal|0
argument_list|,
name|file
argument_list|,
name|line
argument_list|)
operator|)
return|;
block|}
end_function

begin_if
if|#
directive|if
name|defined
argument_list|(
name|INVARIANTS
argument_list|)
operator|||
name|defined
argument_list|(
name|INVARIANT_SUPPORT
argument_list|)
end_if

begin_function
name|void
name|vm_page_assert_locked_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|file
parameter_list|,
name|int
name|line
parameter_list|)
block|{
name|vm_page_lock_assert_KBI
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|,
name|file
argument_list|,
name|line
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_lock_assert_KBI
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|a
parameter_list|,
specifier|const
name|char
modifier|*
name|file
parameter_list|,
name|int
name|line
parameter_list|)
block|{
name|mtx_assert_
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|,
name|a
argument_list|,
name|file
argument_list|,
name|line
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|INVARIANTS
end_ifdef

begin_function
name|void
name|vm_page_object_lock_assert
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
comment|/* 	 * Certain of the page's fields may only be modified by the 	 * holder of the containing object's lock or the exclusive busy. 	 * holder.  Unfortunately, the holder of the write busy is 	 * not recorded, and thus cannot be checked here. 	 */
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|NULL
operator|&&
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_assert_pga_writeable
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|uint8_t
name|bits
parameter_list|)
block|{
if|if
condition|(
operator|(
name|bits
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
comment|/* 	 * The PGA_WRITEABLE flag can only be set if the page is 	 * managed, is exclusively busied or the object is locked. 	 * Currently, this flag is only set by pmap_enter(). 	 */
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"PGA_WRITEABLE on unmanaged page"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|"opt_ddb.h"
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DDB
end_ifdef

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<ddb/ddb.h>
end_include

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|page
argument_list|,
argument|vm_page_print_page_info
argument_list|)
end_macro

begin_block
block|{
name|db_printf
argument_list|(
literal|"vm_cnt.v_free_count: %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"vm_cnt.v_cache_count: %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_cache_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"vm_cnt.v_inactive_count: %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_inactive_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"vm_cnt.v_active_count: %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_active_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"vm_cnt.v_laundry_count: %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_laundry_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"vm_cnt.v_wire_count: %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_wire_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"vm_cnt.v_free_reserved: %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_free_reserved
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"vm_cnt.v_free_min: %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_free_min
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"vm_cnt.v_free_target: %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_free_target
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"vm_cnt.v_inactive_target: %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_inactive_target
argument_list|)
expr_stmt|;
block|}
end_block

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|pageq
argument_list|,
argument|vm_page_print_pageq_info
argument_list|)
end_macro

begin_block
block|{
name|int
name|dom
decl_stmt|;
name|db_printf
argument_list|(
literal|"pq_free %d pq_cache %d\n"
argument_list|,
name|vm_cnt
operator|.
name|v_free_count
argument_list|,
name|vm_cnt
operator|.
name|v_cache_count
argument_list|)
expr_stmt|;
for|for
control|(
name|dom
operator|=
literal|0
init|;
name|dom
operator|<
name|vm_ndomains
condition|;
name|dom
operator|++
control|)
block|{
name|db_printf
argument_list|(
literal|"dom %d page_cnt %d free %d pq_act %d pq_inact %d pq_laund %d\n"
argument_list|,
name|dom
argument_list|,
name|vm_dom
index|[
name|dom
index|]
operator|.
name|vmd_page_count
argument_list|,
name|vm_dom
index|[
name|dom
index|]
operator|.
name|vmd_free_count
argument_list|,
name|vm_dom
index|[
name|dom
index|]
operator|.
name|vmd_pagequeues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|pq_cnt
argument_list|,
name|vm_dom
index|[
name|dom
index|]
operator|.
name|vmd_pagequeues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pq_cnt
argument_list|,
name|vm_dom
index|[
name|dom
index|]
operator|.
name|vmd_pagequeues
index|[
name|PQ_LAUNDRY
index|]
operator|.
name|pq_cnt
argument_list|)
expr_stmt|;
block|}
block|}
end_block

begin_macro
name|DB_SHOW_COMMAND
argument_list|(
argument|pginfo
argument_list|,
argument|vm_page_print_pginfo
argument_list|)
end_macro

begin_block
block|{
name|vm_page_t
name|m
decl_stmt|;
name|boolean_t
name|phys
decl_stmt|;
if|if
condition|(
operator|!
name|have_addr
condition|)
block|{
name|db_printf
argument_list|(
literal|"show pginfo addr\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|phys
operator|=
name|strchr
argument_list|(
name|modif
argument_list|,
literal|'p'
argument_list|)
operator|!=
name|NULL
expr_stmt|;
if|if
condition|(
name|phys
condition|)
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|addr
argument_list|)
expr_stmt|;
else|else
name|m
operator|=
operator|(
name|vm_page_t
operator|)
name|addr
expr_stmt|;
name|db_printf
argument_list|(
literal|"page %p obj %p pidx 0x%jx phys 0x%jx q %d hold %d wire %d\n"
literal|"  af 0x%x of 0x%x f 0x%x act %d busy %x valid 0x%x dirty 0x%x\n"
argument_list|,
name|m
argument_list|,
name|m
operator|->
name|object
argument_list|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|pindex
argument_list|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|phys_addr
argument_list|,
name|m
operator|->
name|queue
argument_list|,
name|m
operator|->
name|hold_count
argument_list|,
name|m
operator|->
name|wire_count
argument_list|,
name|m
operator|->
name|aflags
argument_list|,
name|m
operator|->
name|oflags
argument_list|,
name|m
operator|->
name|flags
argument_list|,
name|m
operator|->
name|act_count
argument_list|,
name|m
operator|->
name|busy_lock
argument_list|,
name|m
operator|->
name|valid
argument_list|,
name|m
operator|->
name|dirty
argument_list|)
expr_stmt|;
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* DDB */
end_comment

end_unit

