begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1991 Regents of the University of California.  * All rights reserved.  * Copyright (c) 1998 Matthew Dillon.  All Rights Reserved.  *  * This code is derived from software contributed to Berkeley by  * The Mach Operating System project at Carnegie-Mellon University.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from: @(#)vm_page.c	7.4 (Berkeley) 5/7/91  */
end_comment

begin_comment
comment|/*-  * Copyright (c) 1987, 1990 Carnegie-Mellon University.  * All rights reserved.  *  * Authors: Avadis Tevanian, Jr., Michael Wayne Young  *  * Permission to use, copy, modify and distribute this software and  * its documentation is hereby granted, provided that both the copyright  * notice and this permission notice appear in all copies of the  * software, derivative works or modified versions, and any portions  * thereof, and that both notices appear in supporting documentation.  *  * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"  * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND  * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.  *  * Carnegie Mellon requests users of this software to return to  *  *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU  *  School of Computer Science  *  Carnegie Mellon University  *  Pittsburgh PA 15213-3890  *  * any improvements or extensions that they make and grant Carnegie the  * rights to redistribute these changes.  */
end_comment

begin_comment
comment|/*  *			GENERAL RULES ON VM_PAGE MANIPULATION  *  *	- a pageq mutex is required when adding or removing a page from a  *	  page queue (vm_page_queue[]), regardless of other mutexes or the  *	  busy state of a page.  *  *	- a hash chain mutex is required when associating or disassociating  *	  a page from the VM PAGE CACHE hash table (vm_page_buckets),  *	  regardless of other mutexes or the busy state of a page.  *  *	- either a hash chain mutex OR a busied page is required in order  *	  to modify the page flags.  A hash chain mutex must be obtained in  *	  order to busy a page.  A page's flags cannot be modified by a  *	  hash chain mutex if the page is marked busy.  *  *	- The object memq mutex is held when inserting or removing  *	  pages from an object (vm_page_insert() or vm_page_remove()).  This  *	  is different from the object's main mutex.  *  *	Generally speaking, you have to be aware of side effects when running  *	vm_page ops.  A vm_page_lookup() will return with the hash chain  *	locked, whether it was able to lookup the page or not.  vm_page_free(),  *	vm_page_cache(), vm_page_activate(), and a number of other routines  *	will release the hash chain mutex for you.  Intermediate manipulation  *	routines such as vm_page_flag_set() expect the hash chain to be held  *	on entry and the hash chain will remain held on return.  *  *	pageq scanning can only occur with the pageq in question locked.  *	We have a known bottleneck with the active queue, but the cache  *	and free queues are actually arrays already.   */
end_comment

begin_comment
comment|/*  *	Resident memory management module.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|"opt_vm.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/limits.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/msgbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/pmap.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_phys.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_reserv.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma_int.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_comment
comment|/*  *	Associated with page of user-allocatable memory is a  *	page structure.  */
end_comment

begin_decl_stmt
name|struct
name|vpgqueues
name|vm_page_queues
index|[
name|PQ_COUNT
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|vpglocks
name|vm_page_queue_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|vpglocks
name|vm_page_queue_free_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|vpglocks
name|pa_lock
index|[
name|PA_LOCK_COUNT
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_page_t
name|vm_page_array
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|vm_page_array_size
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|long
name|first_page
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|vm_page_zero_count
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|boot_pages
init|=
name|UMA_BOOT_PAGES
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"vm.boot_pages"
argument_list|,
operator|&
name|boot_pages
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|boot_pages
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|boot_pages
argument_list|,
literal|0
argument_list|,
literal|"number of pages allocated for bootstrapping the VM system"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pa_tryrelock_restart
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|tryrelock_restart
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pa_tryrelock_restart
argument_list|,
literal|0
argument_list|,
literal|"Number of tryrelock restarts"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|uma_zone_t
name|fakepg_zone
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|void
name|vm_page_clear_dirty_mask
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|pagebits
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_queue_remove
parameter_list|(
name|int
name|queue
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_enqueue
parameter_list|(
name|int
name|queue
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vm_page_init_fakepg
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
function_decl|;
end_function_decl

begin_expr_stmt
name|SYSINIT
argument_list|(
name|vm_page
argument_list|,
name|SI_SUB_VM
argument_list|,
name|SI_ORDER_SECOND
argument_list|,
name|vm_page_init_fakepg
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|void
name|vm_page_init_fakepg
parameter_list|(
name|void
modifier|*
name|dummy
parameter_list|)
block|{
name|fakepg_zone
operator|=
name|uma_zcreate
argument_list|(
literal|"fakepg"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|UMA_ALIGN_PTR
argument_list|,
name|UMA_ZONE_NOFREE
operator||
name|UMA_ZONE_VM
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Make sure that u_long is at least 64 bits when PAGE_SIZE is 32K. */
end_comment

begin_if
if|#
directive|if
name|PAGE_SIZE
operator|==
literal|32768
end_if

begin_ifdef
ifdef|#
directive|ifdef
name|CTASSERT
end_ifdef

begin_expr_stmt
name|CTASSERT
argument_list|(
sizeof|sizeof
argument_list|(
name|u_long
argument_list|)
operator|>=
literal|8
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Try to acquire a physical address lock while a pmap is locked.  If we  * fail to trylock we unlock and lock the pmap directly and cache the  * locked pa in *locked.  The caller should then restart their loop in case  * the virtual to physical mapping has changed.  */
end_comment

begin_function
name|int
name|vm_page_pa_tryrelock
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_paddr_t
modifier|*
name|locked
parameter_list|)
block|{
name|vm_paddr_t
name|lockpa
decl_stmt|;
name|lockpa
operator|=
operator|*
name|locked
expr_stmt|;
operator|*
name|locked
operator|=
name|pa
expr_stmt|;
if|if
condition|(
name|lockpa
condition|)
block|{
name|PA_LOCK_ASSERT
argument_list|(
name|lockpa
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|PA_LOCKPTR
argument_list|(
name|pa
argument_list|)
operator|==
name|PA_LOCKPTR
argument_list|(
name|lockpa
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|PA_UNLOCK
argument_list|(
name|lockpa
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|PA_TRYLOCK
argument_list|(
name|pa
argument_list|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|pa_tryrelock_restart
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|PA_LOCK
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|EAGAIN
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_set_page_size:  *  *	Sets the page size, perhaps based upon the memory  *	size.  Must be called before any use of page-size  *	dependent functions.  */
end_comment

begin_function
name|void
name|vm_set_page_size
parameter_list|(
name|void
parameter_list|)
block|{
if|if
condition|(
name|cnt
operator|.
name|v_page_size
operator|==
literal|0
condition|)
name|cnt
operator|.
name|v_page_size
operator|=
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|cnt
operator|.
name|v_page_size
operator|-
literal|1
operator|)
operator|&
name|cnt
operator|.
name|v_page_size
operator|)
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_set_page_size: page size not a power of two"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_blacklist_lookup:  *  *	See if a physical address in this page has been listed  *	in the blacklist tunable.  Entries in the tunable are  *	separated by spaces or commas.  If an invalid integer is  *	encountered then the rest of the string is skipped.  */
end_comment

begin_function
specifier|static
name|int
name|vm_page_blacklist_lookup
parameter_list|(
name|char
modifier|*
name|list
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|vm_paddr_t
name|bad
decl_stmt|;
name|char
modifier|*
name|cp
decl_stmt|,
modifier|*
name|pos
decl_stmt|;
for|for
control|(
name|pos
operator|=
name|list
init|;
operator|*
name|pos
operator|!=
literal|'\0'
condition|;
name|pos
operator|=
name|cp
control|)
block|{
name|bad
operator|=
name|strtoq
argument_list|(
name|pos
argument_list|,
operator|&
name|cp
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cp
operator|!=
literal|'\0'
condition|)
block|{
if|if
condition|(
operator|*
name|cp
operator|==
literal|' '
operator|||
operator|*
name|cp
operator|==
literal|','
condition|)
block|{
name|cp
operator|++
expr_stmt|;
if|if
condition|(
name|cp
operator|==
name|pos
condition|)
continue|continue;
block|}
else|else
break|break;
block|}
if|if
condition|(
name|pa
operator|==
name|trunc_page
argument_list|(
name|bad
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_startup:  *  *	Initializes the resident memory module.  *  *	Allocates memory for the page cells, and  *	for the object/offset-to-page hash table headers.  *	Each page cell is initialized and placed on the free list.  */
end_comment

begin_function
name|vm_offset_t
name|vm_page_startup
parameter_list|(
name|vm_offset_t
name|vaddr
parameter_list|)
block|{
name|vm_offset_t
name|mapped
decl_stmt|;
name|vm_paddr_t
name|page_range
decl_stmt|;
name|vm_paddr_t
name|new_end
decl_stmt|;
name|int
name|i
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_paddr_t
name|last_pa
decl_stmt|;
name|char
modifier|*
name|list
decl_stmt|;
comment|/* the biggest memory array is the second group of pages */
name|vm_paddr_t
name|end
decl_stmt|;
name|vm_paddr_t
name|biggestsize
decl_stmt|;
name|vm_paddr_t
name|low_water
decl_stmt|,
name|high_water
decl_stmt|;
name|int
name|biggestone
decl_stmt|;
name|biggestsize
operator|=
literal|0
expr_stmt|;
name|biggestone
operator|=
literal|0
expr_stmt|;
name|vaddr
operator|=
name|round_page
argument_list|(
name|vaddr
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|phys_avail
index|[
name|i
index|]
operator|=
name|round_page
argument_list|(
name|phys_avail
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|=
name|trunc_page
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
name|low_water
operator|=
name|phys_avail
index|[
literal|0
index|]
expr_stmt|;
name|high_water
operator|=
name|phys_avail
index|[
literal|1
index|]
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|vm_paddr_t
name|size
init|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|size
operator|>
name|biggestsize
condition|)
block|{
name|biggestone
operator|=
name|i
expr_stmt|;
name|biggestsize
operator|=
name|size
expr_stmt|;
block|}
if|if
condition|(
name|phys_avail
index|[
name|i
index|]
operator|<
name|low_water
condition|)
name|low_water
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|>
name|high_water
condition|)
name|high_water
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|XEN
name|low_water
operator|=
literal|0
expr_stmt|;
endif|#
directive|endif
name|end
operator|=
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
expr_stmt|;
comment|/* 	 * Initialize the locks. 	 */
name|mtx_init
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
literal|"vm page queue mutex"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
operator||
name|MTX_RECURSE
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
literal|"vm page queue free mutex"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* Setup page locks. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PA_LOCK_COUNT
condition|;
name|i
operator|++
control|)
name|mtx_init
argument_list|(
operator|&
name|pa_lock
index|[
name|i
index|]
operator|.
name|data
argument_list|,
literal|"page lock"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the queue headers for the hold queue, the active queue, 	 * and the inactive queue. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PQ_COUNT
condition|;
name|i
operator|++
control|)
name|TAILQ_INIT
argument_list|(
operator|&
name|vm_page_queues
index|[
name|i
index|]
operator|.
name|pl
argument_list|)
expr_stmt|;
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|cnt
operator|=
operator|&
name|cnt
operator|.
name|v_inactive_count
expr_stmt|;
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|cnt
operator|=
operator|&
name|cnt
operator|.
name|v_active_count
expr_stmt|;
name|vm_page_queues
index|[
name|PQ_HOLD
index|]
operator|.
name|cnt
operator|=
operator|&
name|cnt
operator|.
name|v_active_count
expr_stmt|;
comment|/* 	 * Allocate memory for use when boot strapping the kernel memory 	 * allocator. 	 */
name|new_end
operator|=
name|end
operator|-
operator|(
name|boot_pages
operator|*
name|UMA_SLAB_SIZE
operator|)
expr_stmt|;
name|new_end
operator|=
name|trunc_page
argument_list|(
name|new_end
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|end
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|mapped
argument_list|,
name|end
operator|-
name|new_end
argument_list|)
expr_stmt|;
name|uma_startup
argument_list|(
operator|(
name|void
operator|*
operator|)
name|mapped
argument_list|,
name|boot_pages
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__i386__
argument_list|)
operator|||
name|defined
argument_list|(
name|__arm__
argument_list|)
operator|||
expr|\
name|defined
argument_list|(
name|__mips__
argument_list|)
comment|/* 	 * Allocate a bitmap to indicate that a random physical page 	 * needs to be included in a minidump. 	 * 	 * The amd64 port needs this to indicate which direct map pages 	 * need to be dumped, via calls to dump_add_page()/dump_drop_page(). 	 * 	 * However, i386 still needs this workspace internally within the 	 * minidump code.  In theory, they are not needed on i386, but are 	 * included should the sf_buf code decide to use them. 	 */
name|last_pa
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|dump_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
if|if
condition|(
name|dump_avail
index|[
name|i
operator|+
literal|1
index|]
operator|>
name|last_pa
condition|)
name|last_pa
operator|=
name|dump_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
name|page_range
operator|=
name|last_pa
operator|/
name|PAGE_SIZE
expr_stmt|;
name|vm_page_dump_size
operator|=
name|round_page
argument_list|(
name|roundup2
argument_list|(
name|page_range
argument_list|,
name|NBBY
argument_list|)
operator|/
name|NBBY
argument_list|)
expr_stmt|;
name|new_end
operator|-=
name|vm_page_dump_size
expr_stmt|;
name|vm_page_dump
operator|=
operator|(
name|void
operator|*
operator|)
operator|(
name|uintptr_t
operator|)
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|new_end
operator|+
name|vm_page_dump_size
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|vm_page_dump
argument_list|,
name|vm_page_dump_size
argument_list|)
expr_stmt|;
endif|#
directive|endif
ifdef|#
directive|ifdef
name|__amd64__
comment|/* 	 * Request that the physical pages underlying the message buffer be 	 * included in a crash dump.  Since the message buffer is accessed 	 * through the direct map, they are not automatically included. 	 */
name|pa
operator|=
name|DMAP_TO_PHYS
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|msgbufp
operator|->
name|msg_ptr
argument_list|)
expr_stmt|;
name|last_pa
operator|=
name|pa
operator|+
name|round_page
argument_list|(
name|msgbufsize
argument_list|)
expr_stmt|;
while|while
condition|(
name|pa
operator|<
name|last_pa
condition|)
block|{
name|dump_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* 	 * Compute the number of pages of memory that will be available for 	 * use (taking into account the overhead of a page structure per 	 * page). 	 */
name|first_page
operator|=
name|low_water
operator|/
name|PAGE_SIZE
expr_stmt|;
ifdef|#
directive|ifdef
name|VM_PHYSSEG_SPARSE
name|page_range
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
name|page_range
operator|+=
name|atop
argument_list|(
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|-
name|phys_avail
index|[
name|i
index|]
argument_list|)
expr_stmt|;
elif|#
directive|elif
name|defined
argument_list|(
name|VM_PHYSSEG_DENSE
argument_list|)
name|page_range
operator|=
name|high_water
operator|/
name|PAGE_SIZE
operator|-
name|first_page
expr_stmt|;
else|#
directive|else
error|#
directive|error
literal|"Either VM_PHYSSEG_DENSE or VM_PHYSSEG_SPARSE must be defined."
endif|#
directive|endif
name|end
operator|=
name|new_end
expr_stmt|;
comment|/* 	 * Reserve an unmapped guard page to trap access to vm_page_array[-1]. 	 */
name|vaddr
operator|+=
name|PAGE_SIZE
expr_stmt|;
comment|/* 	 * Initialize the mem entry structures now, and put them in the free 	 * queue. 	 */
name|new_end
operator|=
name|trunc_page
argument_list|(
name|end
operator|-
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|)
expr_stmt|;
name|mapped
operator|=
name|pmap_map
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|end
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|vm_page_array
operator|=
operator|(
name|vm_page_t
operator|)
name|mapped
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
comment|/* 	 * Allocate memory for the reservation management system's data 	 * structures. 	 */
name|new_end
operator|=
name|vm_reserv_startup
argument_list|(
operator|&
name|vaddr
argument_list|,
name|new_end
argument_list|,
name|high_water
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|#
directive|if
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__mips__
argument_list|)
comment|/* 	 * pmap_map on amd64 and mips can come out of the direct-map, not kvm 	 * like i386, so the pages must be tracked for a crashdump to include 	 * this data.  This includes the vm_page_array and the early UMA 	 * bootstrap pages. 	 */
for|for
control|(
name|pa
operator|=
name|new_end
init|;
name|pa
operator|<
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
name|dump_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|phys_avail
index|[
name|biggestone
operator|+
literal|1
index|]
operator|=
name|new_end
expr_stmt|;
comment|/* 	 * Clear all of the page structures 	 */
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|vm_page_array
argument_list|,
name|page_range
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|vm_page
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|page_range
condition|;
name|i
operator|++
control|)
name|vm_page_array
index|[
name|i
index|]
operator|.
name|order
operator|=
name|VM_NFREEORDER
expr_stmt|;
name|vm_page_array_size
operator|=
name|page_range
expr_stmt|;
comment|/* 	 * Initialize the physical memory allocator. 	 */
name|vm_phys_init
argument_list|()
expr_stmt|;
comment|/* 	 * Add every available physical page that is not blacklisted to 	 * the free lists. 	 */
name|cnt
operator|.
name|v_page_count
operator|=
literal|0
expr_stmt|;
name|cnt
operator|.
name|v_free_count
operator|=
literal|0
expr_stmt|;
name|list
operator|=
name|getenv
argument_list|(
literal|"vm.blacklist"
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
operator|!=
literal|0
condition|;
name|i
operator|+=
literal|2
control|)
block|{
name|pa
operator|=
name|phys_avail
index|[
name|i
index|]
expr_stmt|;
name|last_pa
operator|=
name|phys_avail
index|[
name|i
operator|+
literal|1
index|]
expr_stmt|;
while|while
condition|(
name|pa
operator|<
name|last_pa
condition|)
block|{
if|if
condition|(
name|list
operator|!=
name|NULL
operator|&&
name|vm_page_blacklist_lookup
argument_list|(
name|list
argument_list|,
name|pa
argument_list|)
condition|)
name|printf
argument_list|(
literal|"Skipping page with pa 0x%jx\n"
argument_list|,
operator|(
name|uintmax_t
operator|)
name|pa
argument_list|)
expr_stmt|;
else|else
name|vm_phys_add_page
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|pa
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
name|freeenv
argument_list|(
name|list
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
comment|/* 	 * Initialize the reservation management system. 	 */
name|vm_reserv_init
argument_list|()
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
name|vaddr
operator|)
return|;
block|}
end_function

begin_function
name|void
name|vm_page_flag_set
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|unsigned
name|short
name|bits
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * The PG_WRITEABLE flag can only be set if the page is managed and 	 * VPO_BUSY.  Currently, this flag is only set by pmap_enter(). 	 */
name|KASSERT
argument_list|(
operator|(
name|bits
operator|&
name|PG_WRITEABLE
operator|)
operator|==
literal|0
operator|||
operator|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_UNMANAGED
operator||
name|PG_FICTITIOUS
operator|)
operator|)
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|!=
literal|0
operator|)
argument_list|,
operator|(
literal|"PG_WRITEABLE and !VPO_BUSY"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator||=
name|bits
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_flag_clear
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|unsigned
name|short
name|bits
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * The PG_REFERENCED flag can only be cleared if the object 	 * containing the page is locked. 	 */
name|KASSERT
argument_list|(
operator|(
name|bits
operator|&
name|PG_REFERENCED
operator|)
operator|==
literal|0
operator|||
name|VM_OBJECT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
argument_list|,
operator|(
literal|"PG_REFERENCED and !VM_OBJECT_LOCKED"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator|&=
operator|~
name|bits
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_busy
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_busy: page already busy!!!"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|oflags
operator||=
name|VPO_BUSY
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *      vm_page_flash:  *  *      wakeup anyone waiting for the page.  */
end_comment

begin_function
name|void
name|vm_page_flash
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|oflags
operator|&
name|VPO_WANTED
condition|)
block|{
name|m
operator|->
name|oflags
operator|&=
operator|~
name|VPO_WANTED
expr_stmt|;
name|wakeup
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *      vm_page_wakeup:  *  *      clear the VPO_BUSY flag and wakeup anyone waiting for the  *      page.  *  */
end_comment

begin_function
name|void
name|vm_page_wakeup
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
argument_list|,
operator|(
literal|"vm_page_wakeup: page not busy!!!"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|oflags
operator|&=
operator|~
name|VPO_BUSY
expr_stmt|;
name|vm_page_flash
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_io_start
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|m
operator|->
name|busy
operator|++
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_io_finish
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|busy
operator|>
literal|0
argument_list|,
operator|(
literal|"vm_page_io_finish: page %p is not busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|busy
operator|--
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|busy
operator|==
literal|0
condition|)
name|vm_page_flash
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Keep page from being freed by the page daemon  * much of the same effect as wiring, except much lower  * overhead and should be used only for *very* temporary  * holding ("wiring").  */
end_comment

begin_function
name|void
name|vm_page_hold
parameter_list|(
name|vm_page_t
name|mem
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|mem
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mem
operator|->
name|hold_count
operator|++
expr_stmt|;
block|}
end_function

begin_function
name|void
name|vm_page_unhold
parameter_list|(
name|vm_page_t
name|mem
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|mem
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
operator|--
name|mem
operator|->
name|hold_count
expr_stmt|;
name|KASSERT
argument_list|(
name|mem
operator|->
name|hold_count
operator|>=
literal|0
argument_list|,
operator|(
literal|"vm_page_unhold: hold count< 0!!!"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|mem
operator|->
name|hold_count
operator|==
literal|0
operator|&&
name|mem
operator|->
name|queue
operator|==
name|PQ_HOLD
condition|)
name|vm_page_free_toq
argument_list|(
name|mem
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_unhold_pages:  *  *	Unhold each of the pages that is referenced by the given array.  */
end_comment

begin_function
name|void
name|vm_page_unhold_pages
parameter_list|(
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|struct
name|mtx
modifier|*
name|mtx
decl_stmt|,
modifier|*
name|new_mtx
decl_stmt|;
name|mtx
operator|=
name|NULL
expr_stmt|;
for|for
control|(
init|;
name|count
operator|!=
literal|0
condition|;
name|count
operator|--
control|)
block|{
comment|/* 		 * Avoid releasing and reacquiring the same page lock. 		 */
name|new_mtx
operator|=
name|vm_page_lockptr
argument_list|(
operator|*
name|ma
argument_list|)
expr_stmt|;
if|if
condition|(
name|mtx
operator|!=
name|new_mtx
condition|)
block|{
if|if
condition|(
name|mtx
operator|!=
name|NULL
condition|)
name|mtx_unlock
argument_list|(
name|mtx
argument_list|)
expr_stmt|;
name|mtx
operator|=
name|new_mtx
expr_stmt|;
name|mtx_lock
argument_list|(
name|mtx
argument_list|)
expr_stmt|;
block|}
name|vm_page_unhold
argument_list|(
operator|*
name|ma
argument_list|)
expr_stmt|;
name|ma
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|mtx
operator|!=
name|NULL
condition|)
name|mtx_unlock
argument_list|(
name|mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_getfake:  *  *	Create a fictitious page with the specified physical address and  *	memory attribute.  The memory attribute is the only the machine-  *	dependent aspect of a fictitious page that must be initialized.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_getfake
parameter_list|(
name|vm_paddr_t
name|paddr
parameter_list|,
name|vm_memattr_t
name|memattr
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|m
operator|=
name|uma_zalloc
argument_list|(
name|fakepg_zone
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
name|m
operator|->
name|phys_addr
operator|=
name|paddr
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_NONE
expr_stmt|;
comment|/* Fictitious pages don't use "segind". */
name|m
operator|->
name|flags
operator|=
name|PG_FICTITIOUS
expr_stmt|;
comment|/* Fictitious pages don't use "order" or "pool". */
name|m
operator|->
name|oflags
operator|=
name|VPO_BUSY
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|memattr
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_putfake:  *  *	Release a fictitious page.  */
end_comment

begin_function
name|void
name|vm_page_putfake
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_putfake: bad page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|uma_zfree
argument_list|(
name|fakepg_zone
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_updatefake:  *  *	Update the given fictitious page to the specified physical address and  *	memory attribute.  */
end_comment

begin_function
name|void
name|vm_page_updatefake
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_paddr_t
name|paddr
parameter_list|,
name|vm_memattr_t
name|memattr
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_updatefake: bad page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|phys_addr
operator|=
name|paddr
expr_stmt|;
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|memattr
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_free:  *  *	Free a page.  */
end_comment

begin_function
name|void
name|vm_page_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_zero:  *  *	Free a page to the zerod-pages queue  */
end_comment

begin_function
name|void
name|vm_page_free_zero
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|m
operator|->
name|flags
operator||=
name|PG_ZERO
expr_stmt|;
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_sleep:  *  *	Sleep and release the page and page queues locks.  *  *	The object containing the given page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_sleep
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
specifier|const
name|char
modifier|*
name|msg
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|mtx_owned
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|)
condition|)
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
if|if
condition|(
name|mtx_owned
argument_list|(
name|vm_page_lockptr
argument_list|(
name|m
argument_list|)
argument_list|)
condition|)
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * It's possible that while we sleep, the page will get 	 * unbusied and freed.  If we are holding the object 	 * lock, we will assume we hold a reference to the object 	 * such that even if m->object changes, we can re-lock 	 * it. 	 */
name|m
operator|->
name|oflags
operator||=
name|VPO_WANTED
expr_stmt|;
name|msleep
argument_list|(
name|m
argument_list|,
name|VM_OBJECT_MTX
argument_list|(
name|m
operator|->
name|object
argument_list|)
argument_list|,
name|PVM
argument_list|,
name|msg
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_dirty:  *  *	Set all bits in the page's dirty field.  *  *	The object containing the specified page must be locked if the call is  *	made from the machine-independent layer.  If, however, the call is  *	made from the pmap layer, then the page queues lock may be required.  *	See vm_page_clear_dirty_mask().  */
end_comment

begin_function
name|void
name|vm_page_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CACHED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_dirty: page in cache!"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|VM_PAGE_IS_FREE
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_dirty: page is free!"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
argument_list|,
operator|(
literal|"vm_page_dirty: page is invalid!"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|dirty
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_splay:  *  *	Implements Sleator and Tarjan's top-down splay algorithm.  Returns  *	the vm_page containing the given pindex.  If, however, that  *	pindex is not found in the vm_object, returns a vm_page that is  *	adjacent to the pindex, coming before or after it.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_splay
parameter_list|(
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_page_t
name|root
parameter_list|)
block|{
name|struct
name|vm_page
name|dummy
decl_stmt|;
name|vm_page_t
name|lefttreemax
decl_stmt|,
name|righttreemin
decl_stmt|,
name|y
decl_stmt|;
if|if
condition|(
name|root
operator|==
name|NULL
condition|)
return|return
operator|(
name|root
operator|)
return|;
name|lefttreemax
operator|=
name|righttreemin
operator|=
operator|&
name|dummy
expr_stmt|;
for|for
control|(
init|;
condition|;
name|root
operator|=
name|y
control|)
block|{
if|if
condition|(
name|pindex
operator|<
name|root
operator|->
name|pindex
condition|)
block|{
if|if
condition|(
operator|(
name|y
operator|=
name|root
operator|->
name|left
operator|)
operator|==
name|NULL
condition|)
break|break;
if|if
condition|(
name|pindex
operator|<
name|y
operator|->
name|pindex
condition|)
block|{
comment|/* Rotate right. */
name|root
operator|->
name|left
operator|=
name|y
operator|->
name|right
expr_stmt|;
name|y
operator|->
name|right
operator|=
name|root
expr_stmt|;
name|root
operator|=
name|y
expr_stmt|;
if|if
condition|(
operator|(
name|y
operator|=
name|root
operator|->
name|left
operator|)
operator|==
name|NULL
condition|)
break|break;
block|}
comment|/* Link into the new root's right tree. */
name|righttreemin
operator|->
name|left
operator|=
name|root
expr_stmt|;
name|righttreemin
operator|=
name|root
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pindex
operator|>
name|root
operator|->
name|pindex
condition|)
block|{
if|if
condition|(
operator|(
name|y
operator|=
name|root
operator|->
name|right
operator|)
operator|==
name|NULL
condition|)
break|break;
if|if
condition|(
name|pindex
operator|>
name|y
operator|->
name|pindex
condition|)
block|{
comment|/* Rotate left. */
name|root
operator|->
name|right
operator|=
name|y
operator|->
name|left
expr_stmt|;
name|y
operator|->
name|left
operator|=
name|root
expr_stmt|;
name|root
operator|=
name|y
expr_stmt|;
if|if
condition|(
operator|(
name|y
operator|=
name|root
operator|->
name|right
operator|)
operator|==
name|NULL
condition|)
break|break;
block|}
comment|/* Link into the new root's left tree. */
name|lefttreemax
operator|->
name|right
operator|=
name|root
expr_stmt|;
name|lefttreemax
operator|=
name|root
expr_stmt|;
block|}
else|else
break|break;
block|}
comment|/* Assemble the new root. */
name|lefttreemax
operator|->
name|right
operator|=
name|root
operator|->
name|left
expr_stmt|;
name|righttreemin
operator|->
name|left
operator|=
name|root
operator|->
name|right
expr_stmt|;
name|root
operator|->
name|left
operator|=
name|dummy
operator|.
name|right
expr_stmt|;
name|root
operator|->
name|right
operator|=
name|dummy
operator|.
name|left
expr_stmt|;
return|return
operator|(
name|root
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_insert:		[ internal use only ]  *  *	Inserts the given mem entry into the object and object list.  *  *	The pagetables are not updated but will presumably fault the page  *	in if necessary, or if a kernel page the caller will at some point  *	enter the page into the kernel's pmap.  We are not allowed to block  *	here so we *can't* do this anyway.  *  *	The object and page must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_insert
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|root
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|NULL
condition|)
name|panic
argument_list|(
literal|"vm_page_insert: page already inserted"
argument_list|)
expr_stmt|;
comment|/* 	 * Record the object/offset pair in this page 	 */
name|m
operator|->
name|object
operator|=
name|object
expr_stmt|;
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
comment|/* 	 * Now link into the object's ordered list of backed pages. 	 */
name|root
operator|=
name|object
operator|->
name|root
expr_stmt|;
if|if
condition|(
name|root
operator|==
name|NULL
condition|)
block|{
name|m
operator|->
name|left
operator|=
name|NULL
expr_stmt|;
name|m
operator|->
name|right
operator|=
name|NULL
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|root
operator|=
name|vm_page_splay
argument_list|(
name|pindex
argument_list|,
name|root
argument_list|)
expr_stmt|;
if|if
condition|(
name|pindex
operator|<
name|root
operator|->
name|pindex
condition|)
block|{
name|m
operator|->
name|left
operator|=
name|root
operator|->
name|left
expr_stmt|;
name|m
operator|->
name|right
operator|=
name|root
expr_stmt|;
name|root
operator|->
name|left
operator|=
name|NULL
expr_stmt|;
name|TAILQ_INSERT_BEFORE
argument_list|(
name|root
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pindex
operator|==
name|root
operator|->
name|pindex
condition|)
name|panic
argument_list|(
literal|"vm_page_insert: offset already allocated"
argument_list|)
expr_stmt|;
else|else
block|{
name|m
operator|->
name|right
operator|=
name|root
operator|->
name|right
expr_stmt|;
name|m
operator|->
name|left
operator|=
name|root
expr_stmt|;
name|root
operator|->
name|right
operator|=
name|NULL
expr_stmt|;
name|TAILQ_INSERT_AFTER
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|root
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
block|}
name|object
operator|->
name|root
operator|=
name|m
expr_stmt|;
comment|/* 	 * show that the object has one more resident page. 	 */
name|object
operator|->
name|resident_page_count
operator|++
expr_stmt|;
comment|/* 	 * Hold the vnode until the last page is released. 	 */
if|if
condition|(
name|object
operator|->
name|resident_page_count
operator|==
literal|1
operator|&&
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
name|vhold
argument_list|(
operator|(
expr|struct
name|vnode
operator|*
operator|)
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
comment|/* 	 * Since we are inserting a new and possibly dirty page, 	 * update the object's OBJ_MIGHTBEDIRTY flag. 	 */
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_WRITEABLE
condition|)
name|vm_object_set_writeable_dirty
argument_list|(
name|object
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_remove:  *				NOTE: used by device pager as well -wfj  *  *	Removes the given mem entry from the object/offset-page  *	table and the object page list, but do not invalidate/terminate  *	the backing store.  *  *	The object and page must be locked.  *	The underlying pmap entry (if any) is NOT removed here.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_remove
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|vm_page_t
name|root
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|object
operator|=
name|m
operator|->
name|object
operator|)
operator|==
name|NULL
condition|)
return|return;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
condition|)
block|{
name|m
operator|->
name|oflags
operator|&=
operator|~
name|VPO_BUSY
expr_stmt|;
name|vm_page_flash
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Now remove from the object's list of backed pages. 	 */
if|if
condition|(
name|m
operator|!=
name|object
operator|->
name|root
condition|)
name|vm_page_splay
argument_list|(
name|m
operator|->
name|pindex
argument_list|,
name|object
operator|->
name|root
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|left
operator|==
name|NULL
condition|)
name|root
operator|=
name|m
operator|->
name|right
expr_stmt|;
else|else
block|{
name|root
operator|=
name|vm_page_splay
argument_list|(
name|m
operator|->
name|pindex
argument_list|,
name|m
operator|->
name|left
argument_list|)
expr_stmt|;
name|root
operator|->
name|right
operator|=
name|m
operator|->
name|right
expr_stmt|;
block|}
name|object
operator|->
name|root
operator|=
name|root
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
comment|/* 	 * And show that the object has one fewer resident page. 	 */
name|object
operator|->
name|resident_page_count
operator|--
expr_stmt|;
comment|/* 	 * The vnode may now be recycled. 	 */
if|if
condition|(
name|object
operator|->
name|resident_page_count
operator|==
literal|0
operator|&&
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
name|vdrop
argument_list|(
operator|(
expr|struct
name|vnode
operator|*
operator|)
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_lookup:  *  *	Returns the page associated with the object/offset  *	pair specified; if none is found, NULL is returned.  *  *	The object must be locked.  *	This routine may not block.  *	This is a critical path routine  */
end_comment

begin_function
name|vm_page_t
name|vm_page_lookup
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|object
operator|->
name|root
operator|)
operator|!=
name|NULL
operator|&&
name|m
operator|->
name|pindex
operator|!=
name|pindex
condition|)
block|{
name|m
operator|=
name|vm_page_splay
argument_list|(
name|pindex
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|object
operator|->
name|root
operator|=
name|m
operator|)
operator|->
name|pindex
operator|!=
name|pindex
condition|)
name|m
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_find_least:  *  *	Returns the page associated with the object with least pindex  *	greater than or equal to the parameter pindex, or NULL.  *  *	The object must be locked.  *	The routine may not block.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_find_least
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|pindex
operator|<
name|pindex
condition|)
block|{
name|m
operator|=
name|vm_page_splay
argument_list|(
name|pindex
argument_list|,
name|object
operator|->
name|root
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|object
operator|->
name|root
operator|=
name|m
operator|)
operator|->
name|pindex
operator|<
name|pindex
condition|)
name|m
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns the given page's successor (by pindex) within the object if it is  * resident; if none is found, NULL is returned.  *  * The object must be locked.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_next
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_t
name|next
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|next
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
name|next
operator|->
name|pindex
operator|!=
name|m
operator|->
name|pindex
operator|+
literal|1
condition|)
name|next
operator|=
name|NULL
expr_stmt|;
return|return
operator|(
name|next
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns the given page's predecessor (by pindex) within the object if it is  * resident; if none is found, NULL is returned.  *  * The object must be locked.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_prev
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_t
name|prev
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|prev
operator|=
name|TAILQ_PREV
argument_list|(
name|m
argument_list|,
name|pglist
argument_list|,
name|listq
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
name|prev
operator|->
name|pindex
operator|!=
name|m
operator|->
name|pindex
operator|-
literal|1
condition|)
name|prev
operator|=
name|NULL
expr_stmt|;
return|return
operator|(
name|prev
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_rename:  *  *	Move the given memory entry from its  *	current object to the specified target object/offset.  *  *	The object must be locked.  *	This routine may not block.  *  *	Note: swap associated with the page must be invalidated by the move.  We  *	      have to do this for several reasons:  (1) we aren't freeing the  *	      page, (2) we are dirtying the page, (3) the VM system is probably  *	      moving the page from object A to B, and will then later move  *	      the backing store from A to B and we can't have a conflict.  *  *	Note: we *always* dirty the page.  It is necessary both for the  *	      fact that we moved it, and because we may be invalidating  *	      swap.  If the page is on the cache, we have to deactivate it  *	      or vm_page_dirty() will panic.  Dirty pages are not allowed  *	      on the cache.  */
end_comment

begin_function
name|void
name|vm_page_rename
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_object_t
name|new_object
parameter_list|,
name|vm_pindex_t
name|new_pindex
parameter_list|)
block|{
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|new_object
argument_list|,
name|new_pindex
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Convert all of the given object's cached pages that have a  *	pindex within the given range into free pages.  If the value  *	zero is given for "end", then the range's upper bound is  *	infinity.  If the given object is backed by a vnode and it  *	transitions from having one or more cached pages to none, the  *	vnode's hold count is reduced.   */
end_comment

begin_function
name|void
name|vm_page_cache_free
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|start
parameter_list|,
name|vm_pindex_t
name|end
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|,
name|m_next
decl_stmt|;
name|boolean_t
name|empty
decl_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|__predict_false
argument_list|(
name|object
operator|->
name|cache
operator|==
name|NULL
argument_list|)
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return;
block|}
name|m
operator|=
name|object
operator|->
name|cache
operator|=
name|vm_page_splay
argument_list|(
name|start
argument_list|,
name|object
operator|->
name|cache
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|pindex
operator|<
name|start
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|right
operator|==
name|NULL
condition|)
name|m
operator|=
name|NULL
expr_stmt|;
else|else
block|{
name|m_next
operator|=
name|vm_page_splay
argument_list|(
name|start
argument_list|,
name|m
operator|->
name|right
argument_list|)
expr_stmt|;
name|m_next
operator|->
name|left
operator|=
name|m
expr_stmt|;
name|m
operator|->
name|right
operator|=
name|NULL
expr_stmt|;
name|m
operator|=
name|object
operator|->
name|cache
operator|=
name|m_next
expr_stmt|;
block|}
block|}
comment|/* 	 * At this point, "m" is either (1) a reference to the page 	 * with the least pindex that is greater than or equal to 	 * "start" or (2) NULL. 	 */
for|for
control|(
init|;
name|m
operator|!=
name|NULL
operator|&&
operator|(
name|m
operator|->
name|pindex
operator|<
name|end
operator|||
name|end
operator|==
literal|0
operator|)
condition|;
name|m
operator|=
name|m_next
control|)
block|{
comment|/* 		 * Find "m"'s successor and remove "m" from the 		 * object's cache. 		 */
if|if
condition|(
name|m
operator|->
name|right
operator|==
name|NULL
condition|)
block|{
name|object
operator|->
name|cache
operator|=
name|m
operator|->
name|left
expr_stmt|;
name|m_next
operator|=
name|NULL
expr_stmt|;
block|}
else|else
block|{
name|m_next
operator|=
name|vm_page_splay
argument_list|(
name|start
argument_list|,
name|m
operator|->
name|right
argument_list|)
expr_stmt|;
name|m_next
operator|->
name|left
operator|=
name|m
operator|->
name|left
expr_stmt|;
name|object
operator|->
name|cache
operator|=
name|m_next
expr_stmt|;
block|}
comment|/* Convert "m" to a free page. */
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
comment|/* Clear PG_CACHED and set PG_FREE. */
name|m
operator|->
name|flags
operator|^=
name|PG_CACHED
operator||
name|PG_FREE
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_CACHED
operator||
name|PG_FREE
operator|)
operator|)
operator|==
name|PG_FREE
argument_list|,
operator|(
literal|"vm_page_cache_free: page %p has inconsistent flags"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|cnt
operator|.
name|v_cache_count
operator|--
expr_stmt|;
name|cnt
operator|.
name|v_free_count
operator|++
expr_stmt|;
block|}
name|empty
operator|=
name|object
operator|->
name|cache
operator|==
name|NULL
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
operator|&&
name|empty
condition|)
name|vdrop
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Returns the cached page that is associated with the given  *	object and offset.  If, however, none exists, returns NULL.  *  *	The free page queue must be locked.  */
end_comment

begin_function
specifier|static
specifier|inline
name|vm_page_t
name|vm_page_cache_lookup
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|object
operator|->
name|cache
operator|)
operator|!=
name|NULL
operator|&&
name|m
operator|->
name|pindex
operator|!=
name|pindex
condition|)
block|{
name|m
operator|=
name|vm_page_splay
argument_list|(
name|pindex
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|object
operator|->
name|cache
operator|=
name|m
operator|)
operator|->
name|pindex
operator|!=
name|pindex
condition|)
name|m
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Remove the given cached page from its containing object's  *	collection of cached pages.  *  *	The free page queue must be locked.  */
end_comment

begin_function
name|void
name|vm_page_cache_remove
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|vm_page_t
name|root
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CACHED
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_cache_remove: page %p is not cached"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
if|if
condition|(
name|m
operator|!=
name|object
operator|->
name|cache
condition|)
block|{
name|root
operator|=
name|vm_page_splay
argument_list|(
name|m
operator|->
name|pindex
argument_list|,
name|object
operator|->
name|cache
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|root
operator|==
name|m
argument_list|,
operator|(
literal|"vm_page_cache_remove: page %p is not cached in object %p"
operator|,
name|m
operator|,
name|object
operator|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|m
operator|->
name|left
operator|==
name|NULL
condition|)
name|root
operator|=
name|m
operator|->
name|right
expr_stmt|;
elseif|else
if|if
condition|(
name|m
operator|->
name|right
operator|==
name|NULL
condition|)
name|root
operator|=
name|m
operator|->
name|left
expr_stmt|;
else|else
block|{
name|root
operator|=
name|vm_page_splay
argument_list|(
name|m
operator|->
name|pindex
argument_list|,
name|m
operator|->
name|left
argument_list|)
expr_stmt|;
name|root
operator|->
name|right
operator|=
name|m
operator|->
name|right
expr_stmt|;
block|}
name|object
operator|->
name|cache
operator|=
name|root
expr_stmt|;
name|m
operator|->
name|object
operator|=
name|NULL
expr_stmt|;
name|cnt
operator|.
name|v_cache_count
operator|--
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Transfer all of the cached pages with offset greater than or  *	equal to 'offidxstart' from the original object's cache to the  *	new object's cache.  However, any cached pages with offset  *	greater than or equal to the new object's size are kept in the  *	original object.  Initially, the new object's cache must be  *	empty.  Offset 'offidxstart' in the original object must  *	correspond to offset zero in the new object.  *  *	The new object must be locked.  */
end_comment

begin_function
name|void
name|vm_page_cache_transfer
parameter_list|(
name|vm_object_t
name|orig_object
parameter_list|,
name|vm_pindex_t
name|offidxstart
parameter_list|,
name|vm_object_t
name|new_object
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|,
name|m_next
decl_stmt|;
comment|/* 	 * Insertion into an object's collection of cached pages 	 * requires the object to be locked.  In contrast, removal does 	 * not. 	 */
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|new_object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|new_object
operator|->
name|cache
operator|==
name|NULL
argument_list|,
operator|(
literal|"vm_page_cache_transfer: object %p has cached pages"
operator|,
name|new_object
operator|)
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|=
name|orig_object
operator|->
name|cache
operator|)
operator|!=
name|NULL
condition|)
block|{
comment|/* 		 * Transfer all of the pages with offset greater than or 		 * equal to 'offidxstart' from the original object's 		 * cache to the new object's cache. 		 */
name|m
operator|=
name|vm_page_splay
argument_list|(
name|offidxstart
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|pindex
operator|<
name|offidxstart
condition|)
block|{
name|orig_object
operator|->
name|cache
operator|=
name|m
expr_stmt|;
name|new_object
operator|->
name|cache
operator|=
name|m
operator|->
name|right
expr_stmt|;
name|m
operator|->
name|right
operator|=
name|NULL
expr_stmt|;
block|}
else|else
block|{
name|orig_object
operator|->
name|cache
operator|=
name|m
operator|->
name|left
expr_stmt|;
name|new_object
operator|->
name|cache
operator|=
name|m
expr_stmt|;
name|m
operator|->
name|left
operator|=
name|NULL
expr_stmt|;
block|}
while|while
condition|(
operator|(
name|m
operator|=
name|new_object
operator|->
name|cache
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|pindex
operator|-
name|offidxstart
operator|)
operator|>=
name|new_object
operator|->
name|size
condition|)
block|{
comment|/* 				 * Return all of the cached pages with 				 * offset greater than or equal to the 				 * new object's size to the original 				 * object's cache.  				 */
name|new_object
operator|->
name|cache
operator|=
name|m
operator|->
name|left
expr_stmt|;
name|m
operator|->
name|left
operator|=
name|orig_object
operator|->
name|cache
expr_stmt|;
name|orig_object
operator|->
name|cache
operator|=
name|m
expr_stmt|;
break|break;
block|}
name|m_next
operator|=
name|vm_page_splay
argument_list|(
name|m
operator|->
name|pindex
argument_list|,
name|m
operator|->
name|right
argument_list|)
expr_stmt|;
comment|/* Update the page's object and offset. */
name|m
operator|->
name|object
operator|=
name|new_object
expr_stmt|;
name|m
operator|->
name|pindex
operator|-=
name|offidxstart
expr_stmt|;
if|if
condition|(
name|m_next
operator|==
name|NULL
condition|)
break|break;
name|m
operator|->
name|right
operator|=
name|NULL
expr_stmt|;
name|m_next
operator|->
name|left
operator|=
name|m
expr_stmt|;
name|new_object
operator|->
name|cache
operator|=
name|m_next
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|new_object
operator|->
name|cache
operator|==
name|NULL
operator|||
name|new_object
operator|->
name|type
operator|==
name|OBJT_SWAP
argument_list|,
operator|(
literal|"vm_page_cache_transfer: object %p's type is incompatible"
literal|" with cached pages"
operator|,
name|new_object
operator|)
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_alloc:  *  *	Allocate and return a memory cell associated  *	with this VM object/offset pair.  *  *	The caller must always specify an allocation class.  *  *	allocation classes:  *	VM_ALLOC_NORMAL		normal process request  *	VM_ALLOC_SYSTEM		system *really* needs a page  *	VM_ALLOC_INTERRUPT	interrupt time request  *  *	optional allocation flags:  *	VM_ALLOC_ZERO		prefer a zeroed page  *	VM_ALLOC_WIRED		wire the allocated page  *	VM_ALLOC_NOOBJ		page is not associated with a vm object  *	VM_ALLOC_NOBUSY		do not set the page busy  *	VM_ALLOC_IFCACHED	return page only if it is cached  *	VM_ALLOC_IFNOTCACHED	return NULL, do not reactivate if the page  *				is cached  *  *	This routine may not sleep.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_alloc
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|req
parameter_list|)
block|{
name|struct
name|vnode
modifier|*
name|vp
init|=
name|NULL
decl_stmt|;
name|vm_object_t
name|m_object
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|flags
decl_stmt|,
name|page_req
decl_stmt|;
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_NOOBJ
operator|)
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|object
operator|!=
name|NULL
argument_list|,
operator|(
literal|"vm_page_alloc: NULL object."
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
block|}
name|page_req
operator|=
name|req
operator|&
name|VM_ALLOC_CLASS_MASK
expr_stmt|;
comment|/* 	 * The pager is allowed to eat deeper into the free page list. 	 */
if|if
condition|(
operator|(
name|curproc
operator|==
name|pageproc
operator|)
operator|&&
operator|(
name|page_req
operator|!=
name|VM_ALLOC_INTERRUPT
operator|)
condition|)
name|page_req
operator|=
name|VM_ALLOC_SYSTEM
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
name|cnt
operator|.
name|v_free_reserved
operator|||
operator|(
name|page_req
operator|==
name|VM_ALLOC_SYSTEM
operator|&&
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
name|cnt
operator|.
name|v_interrupt_free_min
operator|)
operator|||
operator|(
name|page_req
operator|==
name|VM_ALLOC_INTERRUPT
operator|&&
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
literal|0
operator|)
condition|)
block|{
comment|/* 		 * Allocate from the free queue if the number of free pages 		 * exceeds the minimum for the request class. 		 */
if|if
condition|(
name|object
operator|!=
name|NULL
operator|&&
operator|(
name|m
operator|=
name|vm_page_cache_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_IFNOTCACHED
operator|)
operator|!=
literal|0
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
if|if
condition|(
name|vm_phys_unfree_page
argument_list|(
name|m
argument_list|)
condition|)
name|vm_phys_set_pool
argument_list|(
name|VM_FREEPOOL_DEFAULT
argument_list|,
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
elseif|else
if|if
condition|(
operator|!
name|vm_reserv_reactivate_page
argument_list|(
name|m
argument_list|)
condition|)
else|#
directive|else
else|else
endif|#
directive|endif
name|panic
argument_list|(
literal|"vm_page_alloc: cache page %p is missing"
literal|" from the free queue"
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|req
operator|&
name|VM_ALLOC_IFCACHED
operator|)
operator|!=
literal|0
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
block|}
elseif|else
if|if
condition|(
name|object
operator|==
name|NULL
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_DEVICE
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_SG
operator|||
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_COLORED
operator|)
operator|==
literal|0
operator|||
operator|(
name|m
operator|=
name|vm_reserv_alloc_page
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
else|#
directive|else
block|}
else|else
block|{
endif|#
directive|endif
name|m
operator|=
name|vm_phys_alloc_pages
argument_list|(
name|object
operator|!=
name|NULL
condition|?
name|VM_FREEPOOL_DEFAULT
else|:
name|VM_FREEPOOL_DIRECT
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
name|m
operator|==
name|NULL
operator|&&
name|vm_reserv_reclaim_inactive
argument_list|()
condition|)
block|{
name|m
operator|=
name|vm_phys_alloc_pages
argument_list|(
name|object
operator|!=
name|NULL
condition|?
name|VM_FREEPOOL_DEFAULT
else|:
name|VM_FREEPOOL_DIRECT
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
block|}
block|}
else|else
block|{
comment|/* 		 * Not allocatable, give up. 		 */
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_pageout_deficit
argument_list|,
name|MAX
argument_list|(
operator|(
name|u_int
operator|)
name|req
operator|>>
name|VM_ALLOC_COUNT_SHIFT
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
comment|/* 	 *  At this point we had better have found a good page. 	 */
name|KASSERT
argument_list|(
name|m
operator|!=
name|NULL
argument_list|,
operator|(
literal|"vm_page_alloc: missing page"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_alloc: page %p has unexpected queue %d"
operator|,
name|m
operator|,
name|m
operator|->
name|queue
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: page %p is wired"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|hold_count
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: page %p is held"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|busy
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: page %p is busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: page %p is dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|==
name|VM_MEMATTR_DEFAULT
argument_list|,
operator|(
literal|"vm_page_alloc: page %p has unexpected memattr %d"
operator|,
name|m
operator|,
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CACHED
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: cached page %p is invalid"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|==
name|object
operator|&&
name|m
operator|->
name|pindex
operator|==
name|pindex
condition|)
name|cnt
operator|.
name|v_reactivated
operator|++
expr_stmt|;
else|else
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|m_object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|vm_page_cache_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_object
operator|->
name|type
operator|==
name|OBJT_VNODE
operator|&&
name|m_object
operator|->
name|cache
operator|==
name|NULL
condition|)
name|vp
operator|=
name|m_object
operator|->
name|handle
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
name|VM_PAGE_IS_FREE
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_alloc: page %p is not free"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc: free page %p is valid"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|cnt
operator|.
name|v_free_count
operator|--
expr_stmt|;
block|}
comment|/* 	 * Only the PG_ZERO flag is inherited.  The PG_CACHED or PG_FREE flag 	 * must be cleared before the free page queues lock is released. 	 */
name|flags
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
condition|)
block|{
name|vm_page_zero_count
operator|--
expr_stmt|;
if|if
condition|(
name|req
operator|&
name|VM_ALLOC_ZERO
condition|)
name|flags
operator|=
name|PG_ZERO
expr_stmt|;
block|}
if|if
condition|(
name|object
operator|==
name|NULL
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_PHYS
condition|)
name|flags
operator||=
name|PG_UNMANAGED
expr_stmt|;
name|m
operator|->
name|flags
operator|=
name|flags
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|req
operator|&
operator|(
name|VM_ALLOC_NOBUSY
operator||
name|VM_ALLOC_NOOBJ
operator|)
condition|)
name|m
operator|->
name|oflags
operator|=
literal|0
expr_stmt|;
else|else
name|m
operator|->
name|oflags
operator|=
name|VPO_BUSY
expr_stmt|;
if|if
condition|(
name|req
operator|&
name|VM_ALLOC_WIRED
condition|)
block|{
comment|/* 		 * The page lock is not required for wiring a page until that 		 * page is inserted into the object. 		 */
name|atomic_add_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
block|}
name|m
operator|->
name|act_count
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|object
operator|!=
name|NULL
condition|)
block|{
comment|/* Ignore device objects; the pager sets "memattr" for them. */
if|if
condition|(
name|object
operator|->
name|memattr
operator|!=
name|VM_MEMATTR_DEFAULT
operator|&&
name|object
operator|->
name|type
operator|!=
name|OBJT_DEVICE
operator|&&
name|object
operator|->
name|type
operator|!=
name|OBJT_SG
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|object
operator|->
name|memattr
argument_list|)
expr_stmt|;
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
block|}
else|else
name|m
operator|->
name|pindex
operator|=
name|pindex
expr_stmt|;
comment|/* 	 * The following call to vdrop() must come after the above call 	 * to vm_page_insert() in case both affect the same object and 	 * vnode.  Otherwise, the affected vnode's hold count could 	 * temporarily become zero. 	 */
if|if
condition|(
name|vp
operator|!=
name|NULL
condition|)
name|vdrop
argument_list|(
name|vp
argument_list|)
expr_stmt|;
comment|/* 	 * Don't wakeup too often - wakeup the pageout daemon when 	 * we would be nearly out of memory. 	 */
if|if
condition|(
name|vm_paging_needed
argument_list|()
condition|)
name|pagedaemon_wakeup
argument_list|()
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Initialize a page that has been freshly dequeued from a freelist.  * The caller has to drop the vnode returned, if it is not NULL.  *  * To be called with vm_page_queue_free_mtx held.  */
end_comment

begin_function
name|struct
name|vnode
modifier|*
name|vm_page_alloc_init
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vnode
modifier|*
name|drop
decl_stmt|;
name|vm_object_t
name|m_object
decl_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p has unexpected queue %d"
operator|,
name|m
operator|,
name|m
operator|->
name|queue
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p is wired"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|hold_count
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p is held"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|busy
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p is busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|dirty
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p is dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|==
name|VM_MEMATTR_DEFAULT
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p has unexpected memattr %d"
operator|,
name|m
operator|,
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|)
argument_list|)
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|drop
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CACHED
operator|)
operator|!=
literal|0
condition|)
block|{
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|m_object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|vm_page_cache_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_object
operator|->
name|type
operator|==
name|OBJT_VNODE
operator|&&
name|m_object
operator|->
name|cache
operator|==
name|NULL
condition|)
name|drop
operator|=
name|m_object
operator|->
name|handle
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
name|VM_PAGE_IS_FREE
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_alloc_init: page %p is not free"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|valid
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_alloc_init: free page %p is valid"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|cnt
operator|.
name|v_free_count
operator|--
expr_stmt|;
block|}
if|if
condition|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
condition|)
name|vm_page_zero_count
operator|--
expr_stmt|;
comment|/* Don't clear the PG_ZERO flag; we'll need it later. */
name|m
operator|->
name|flags
operator|=
name|PG_UNMANAGED
operator||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
expr_stmt|;
name|m
operator|->
name|oflags
operator|=
literal|0
expr_stmt|;
comment|/* Unmanaged pages don't use "act_count". */
return|return
operator|(
name|drop
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * 	vm_page_alloc_freelist:  *   *	Allocate a page from the specified freelist.  *	Only the ALLOC_CLASS values in req are honored, other request flags  *	are ignored.  */
end_comment

begin_function
name|vm_page_t
name|vm_page_alloc_freelist
parameter_list|(
name|int
name|flind
parameter_list|,
name|int
name|req
parameter_list|)
block|{
name|struct
name|vnode
modifier|*
name|drop
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|int
name|page_req
decl_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
name|page_req
operator|=
name|req
operator|&
name|VM_ALLOC_CLASS_MASK
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Do not allocate reserved pages unless the req has asked for it. 	 */
if|if
condition|(
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
name|cnt
operator|.
name|v_free_reserved
operator|||
operator|(
name|page_req
operator|==
name|VM_ALLOC_SYSTEM
operator|&&
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
name|cnt
operator|.
name|v_interrupt_free_min
operator|)
operator|||
operator|(
name|page_req
operator|==
name|VM_ALLOC_INTERRUPT
operator|&&
name|cnt
operator|.
name|v_free_count
operator|+
name|cnt
operator|.
name|v_cache_count
operator|>
literal|0
operator|)
condition|)
block|{
name|m
operator|=
name|vm_phys_alloc_freelist_pages
argument_list|(
name|flind
argument_list|,
name|VM_FREEPOOL_DIRECT
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|drop
operator|=
name|vm_page_alloc_init
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|drop
condition|)
name|vdrop
argument_list|(
name|drop
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	vm_wait:	(also see VM_WAIT macro)  *  *	Block until free pages are available for allocation  *	- Called in various places before memory allocations.  */
end_comment

begin_function
name|void
name|vm_wait
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|curproc
operator|==
name|pageproc
condition|)
block|{
name|vm_pageout_pages_needed
operator|=
literal|1
expr_stmt|;
name|msleep
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PSWP
argument_list|,
literal|"VMWait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|vm_pages_needed
condition|)
block|{
name|vm_pages_needed
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pages_needed
argument_list|)
expr_stmt|;
block|}
name|msleep
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PVM
argument_list|,
literal|"vmwait"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_waitpfault:	(also see VM_WAITPFAULT macro)  *  *	Block until free pages are available for allocation  *	- Called only in vm_fault so that processes page faulting  *	  can be easily tracked.  *	- Sleeps at a lower priority than vm_wait() so that vm_wait()ing  *	  processes will be able to grab memory first.  Do not change  *	  this balance without careful testing first.  */
end_comment

begin_function
name|void
name|vm_waitpfault
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_pages_needed
condition|)
block|{
name|vm_pages_needed
operator|=
literal|1
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|vm_pages_needed
argument_list|)
expr_stmt|;
block|}
name|msleep
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|,
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|PDROP
operator||
name|PUSER
argument_list|,
literal|"pfault"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_requeue:  *  *	Move the given page to the tail of its present page queue.  *  *	The page queues must be locked.  */
end_comment

begin_function
name|void
name|vm_page_requeue
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vpgqueues
modifier|*
name|vpq
decl_stmt|;
name|int
name|queue
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|queue
operator|=
name|m
operator|->
name|queue
expr_stmt|;
name|KASSERT
argument_list|(
name|queue
operator|!=
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_requeue: page %p is not queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|vpq
operator|=
operator|&
name|vm_page_queues
index|[
name|queue
index|]
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|vpq
operator|->
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|vpq
operator|->
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_queue_remove:  *  *	Remove the given page from the specified queue.  *  *	The page and page queues must be locked.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|vm_page_queue_remove
parameter_list|(
name|int
name|queue
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vpgqueues
modifier|*
name|pq
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pq
operator|=
operator|&
name|vm_page_queues
index|[
name|queue
index|]
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pq
operator|->
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
operator|(
operator|*
name|pq
operator|->
name|cnt
operator|)
operator|--
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_pageq_remove:  *  *	Remove a page from its queue.  *  *	The given page must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_pageq_remove
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|queue
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|queue
operator|=
name|m
operator|->
name|queue
operator|)
operator|!=
name|PQ_NONE
condition|)
block|{
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_NONE
expr_stmt|;
name|vm_page_queue_remove
argument_list|(
name|queue
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_enqueue:  *  *	Add the given page to the specified queue.  *  *	The page queues must be locked.  */
end_comment

begin_function
specifier|static
name|void
name|vm_page_enqueue
parameter_list|(
name|int
name|queue
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|vpgqueues
modifier|*
name|vpq
decl_stmt|;
name|vpq
operator|=
operator|&
name|vm_page_queues
index|[
name|queue
index|]
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|queue
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|vpq
operator|->
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
operator|++
operator|*
name|vpq
operator|->
name|cnt
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	vm_page_activate:  *  *	Put the specified page on the active list (if appropriate).  *	Ensure that act_count is at least ACT_INIT but do not otherwise  *	mess with it.  *  *	The page must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_activate
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|queue
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|queue
operator|=
name|m
operator|->
name|queue
operator|)
operator|!=
name|PQ_ACTIVE
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|<
name|ACT_INIT
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_INIT
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
if|if
condition|(
name|queue
operator|!=
name|PQ_NONE
condition|)
name|vm_page_queue_remove
argument_list|(
name|queue
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|vm_page_enqueue
argument_list|(
name|PQ_ACTIVE
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
else|else
name|KASSERT
argument_list|(
name|queue
operator|==
name|PQ_NONE
argument_list|,
operator|(
literal|"vm_page_activate: wired page %p is queued"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|<
name|ACT_INIT
condition|)
name|m
operator|->
name|act_count
operator|=
name|ACT_INIT
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_wakeup:  *  *	Helper routine for vm_page_free_toq() and vm_page_cache().  This  *	routine is called when a page has been added to the cache or free  *	queues.  *  *	The page queues must be locked.  *	This routine may not block.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|vm_page_free_wakeup
parameter_list|(
name|void
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * if pageout daemon needs pages, then tell it that there are 	 * some free. 	 */
if|if
condition|(
name|vm_pageout_pages_needed
operator|&&
name|cnt
operator|.
name|v_cache_count
operator|+
name|cnt
operator|.
name|v_free_count
operator|>=
name|cnt
operator|.
name|v_pageout_free_min
condition|)
block|{
name|wakeup
argument_list|(
operator|&
name|vm_pageout_pages_needed
argument_list|)
expr_stmt|;
name|vm_pageout_pages_needed
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * wakeup processes that are waiting on memory if we hit a 	 * high water mark. And wakeup scheduler process if we have 	 * lots of memory. this process will swapin processes. 	 */
if|if
condition|(
name|vm_pages_needed
operator|&&
operator|!
name|vm_page_count_min
argument_list|()
condition|)
block|{
name|vm_pages_needed
operator|=
literal|0
expr_stmt|;
name|wakeup
argument_list|(
operator|&
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_free_toq:  *  *	Returns the given page to the free list,  *	disassociating it with any VM object.  *  *	Object and page must be locked prior to entry.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_free_toq
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_free_toq: freeing mapped page %p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
name|PCPU_INC
argument_list|(
name|cnt
operator|.
name|v_tfree
argument_list|)
expr_stmt|;
if|if
condition|(
name|VM_PAGE_IS_FREE
argument_list|(
name|m
argument_list|)
condition|)
name|panic
argument_list|(
literal|"vm_page_free: freeing free page %p"
argument_list|,
name|m
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|m
operator|->
name|busy
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_page_free: freeing busy page %p"
argument_list|,
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * unqueue, then remove page.  Note that we cannot destroy 	 * the page here because we do not want to call the pager's 	 * callback routine until after we've put the page on the 	 * appropriate free queue. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_pageq_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * If fictitious remove object association and 	 * return, otherwise delay object association removal. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
return|return;
block|}
name|m
operator|->
name|valid
operator|=
literal|0
expr_stmt|;
name|vm_page_undirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_page_free: freeing wired page %p"
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|hold_count
operator|!=
literal|0
condition|)
block|{
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_enqueue
argument_list|(
name|PQ_HOLD
argument_list|,
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Restore the default memory attribute to the page. 		 */
if|if
condition|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|!=
name|VM_MEMATTR_DEFAULT
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
expr_stmt|;
comment|/* 		 * Insert the page into the physical memory allocator's 		 * cache/free page queues. 		 */
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator||=
name|PG_FREE
expr_stmt|;
name|cnt
operator|.
name|v_free_count
operator|++
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
operator|!
name|vm_reserv_free_page
argument_list|(
name|m
argument_list|)
condition|)
else|#
directive|else
if|if
condition|(
name|TRUE
condition|)
endif|#
directive|endif
name|vm_phys_free_pages
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|!=
literal|0
condition|)
operator|++
name|vm_page_zero_count
expr_stmt|;
else|else
name|vm_page_zero_idle_wakeup
argument_list|()
expr_stmt|;
name|vm_page_free_wakeup
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	vm_page_wire:  *  *	Mark this page as wired down by yet  *	another map, removing it from paging queues  *	as necessary.  *  *	If the page is fictitious, then its wire count must remain one.  *  *	The page must be locked.  *	This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_wire
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
comment|/* 	 * Only bump the wire statistics if the page is not already wired, 	 * and only unqueue the page if it is on some queue (if it is unmanaged 	 * it is already off the queues). 	 */
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|1
argument_list|,
operator|(
literal|"vm_page_wire: fictitious page %p's wire count isn't one"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_pageq_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
name|m
operator|->
name|wire_count
operator|++
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_wire: wire_count overflow m=%p"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_unwire:  *  * Release one wiring of the specified page, potentially enabling it to be  * paged again.  If paging is enabled, then the value of the parameter  * "activate" determines to which queue the page is added.  If "activate" is  * non-zero, then the page is added to the active queue.  Otherwise, it is  * added to the inactive queue.  *  * However, unless the page belongs to an object, it is not enqueued because  * it cannot be paged out.  *  * If a page is fictitious, then its wire count must alway be one.  *  * A managed page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_unwire
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|activate
parameter_list|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|m
operator|->
name|wire_count
operator|==
literal|1
argument_list|,
operator|(
literal|"vm_page_unwire: fictitious page %p's wire count isn't one"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|m
operator|->
name|wire_count
operator|>
literal|0
condition|)
block|{
name|m
operator|->
name|wire_count
operator|--
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|atomic_subtract_int
argument_list|(
operator|&
name|cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|!=
literal|0
operator|||
name|m
operator|->
name|object
operator|==
name|NULL
condition|)
return|return;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
if|if
condition|(
name|activate
condition|)
name|vm_page_enqueue
argument_list|(
name|PQ_ACTIVE
argument_list|,
name|m
argument_list|)
expr_stmt|;
else|else
block|{
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WINATCFLS
argument_list|)
expr_stmt|;
name|vm_page_enqueue
argument_list|(
name|PQ_INACTIVE
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
block|}
else|else
name|panic
argument_list|(
literal|"vm_page_unwire: page %p's wire count is zero"
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Move the specified page to the inactive queue.  *  * Many pages placed on the inactive queue should actually go  * into the cache, but it is difficult to figure out which.  What  * we do instead, if the inactive target is well met, is to put  * clean pages at the head of the inactive queue instead of the tail.  * This will cause them to be moved to the cache more quickly and  * if not actively re-referenced, reclaimed more quickly.  If we just  * stick these pages at the end of the inactive queue, heavy filesystem  * meta-data accesses can cause an unnecessary paging load on memory bound   * processes.  This optimization causes one-time-use metadata to be  * reused more quickly.  *  * Normally athead is 0 resulting in LRU operation.  athead is set  * to 1 if we want this page to be 'as if it were placed in the cache',  * except without unmapping it from the process address space.  *  * This routine may not block.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|_vm_page_deactivate
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|athead
parameter_list|)
block|{
name|int
name|queue
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Ignore if already inactive. 	 */
if|if
condition|(
operator|(
name|queue
operator|=
name|m
operator|->
name|queue
operator|)
operator|==
name|PQ_INACTIVE
condition|)
return|return;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_WINATCFLS
argument_list|)
expr_stmt|;
if|if
condition|(
name|queue
operator|!=
name|PQ_NONE
condition|)
name|vm_page_queue_remove
argument_list|(
name|queue
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|athead
condition|)
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
else|else
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|pl
argument_list|,
name|m
argument_list|,
name|pageq
argument_list|)
expr_stmt|;
name|m
operator|->
name|queue
operator|=
name|PQ_INACTIVE
expr_stmt|;
name|cnt
operator|.
name|v_inactive_count
operator|++
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Move the specified page to the inactive queue.  *  * The page must be locked.  */
end_comment

begin_function
name|void
name|vm_page_deactivate
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|_vm_page_deactivate
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * vm_page_try_to_cache:  *  * Returns 0 on failure, 1 on success  */
end_comment

begin_function
name|int
name|vm_page_try_to_cache
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|busy
operator|||
name|m
operator|->
name|wire_count
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|vm_page_cache
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_page_try_to_free()  *  *	Attempt to free the page.  If we cannot free it, we do nothing.  *	1 is returned on success, 0 on failure.  */
end_comment

begin_function
name|int
name|vm_page_try_to_free
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|NULL
condition|)
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|busy
operator|||
name|m
operator|->
name|wire_count
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|||
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * vm_page_cache  *  * Put the specified page onto the page cache queue (if appropriate).  *  * This routine may not block.  */
end_comment

begin_function
name|void
name|vm_page_cache
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_object_t
name|object
decl_stmt|;
name|vm_page_t
name|root
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_UNMANAGED
operator|)
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|||
name|m
operator|->
name|busy
operator|||
name|m
operator|->
name|hold_count
operator|||
name|m
operator|->
name|wire_count
condition|)
name|panic
argument_list|(
literal|"vm_page_cache: attempting to cache busy page"
argument_list|)
expr_stmt|;
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"vm_page_cache: page %p is dirty"
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|==
literal|0
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_DEFAULT
operator|||
operator|(
name|object
operator|->
name|type
operator|==
name|OBJT_SWAP
operator|&&
operator|!
name|vm_pager_has_page
argument_list|(
name|object
argument_list|,
name|m
operator|->
name|pindex
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|)
operator|)
condition|)
block|{
comment|/* 		 * Hypothesis: A cache-elgible page belonging to a 		 * default object or swap object but without a backing 		 * store must be zero filled. 		 */
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return;
block|}
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_CACHED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_cache: page %p is already cached"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|PCPU_INC
argument_list|(
name|cnt
operator|.
name|v_tcached
argument_list|)
expr_stmt|;
comment|/* 	 * Remove the page from the paging queues. 	 */
name|vm_pageq_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Remove the page from the object's collection of resident 	 * pages.  	 */
if|if
condition|(
name|m
operator|!=
name|object
operator|->
name|root
condition|)
name|vm_page_splay
argument_list|(
name|m
operator|->
name|pindex
argument_list|,
name|object
operator|->
name|root
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|left
operator|==
name|NULL
condition|)
name|root
operator|=
name|m
operator|->
name|right
expr_stmt|;
else|else
block|{
name|root
operator|=
name|vm_page_splay
argument_list|(
name|m
operator|->
name|pindex
argument_list|,
name|m
operator|->
name|left
argument_list|)
expr_stmt|;
name|root
operator|->
name|right
operator|=
name|m
operator|->
name|right
expr_stmt|;
block|}
name|object
operator|->
name|root
operator|=
name|root
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|object
operator|->
name|memq
argument_list|,
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
name|object
operator|->
name|resident_page_count
operator|--
expr_stmt|;
comment|/* 	 * Restore the default memory attribute to the page. 	 */
if|if
condition|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
operator|!=
name|VM_MEMATTR_DEFAULT
condition|)
name|pmap_page_set_memattr
argument_list|(
name|m
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
expr_stmt|;
comment|/* 	 * Insert the page into the object's collection of cached pages 	 * and the physical memory allocator's cache/free page queues. 	 */
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
name|m
operator|->
name|flags
operator||=
name|PG_CACHED
expr_stmt|;
name|cnt
operator|.
name|v_cache_count
operator|++
expr_stmt|;
name|root
operator|=
name|object
operator|->
name|cache
expr_stmt|;
if|if
condition|(
name|root
operator|==
name|NULL
condition|)
block|{
name|m
operator|->
name|left
operator|=
name|NULL
expr_stmt|;
name|m
operator|->
name|right
operator|=
name|NULL
expr_stmt|;
block|}
else|else
block|{
name|root
operator|=
name|vm_page_splay
argument_list|(
name|m
operator|->
name|pindex
argument_list|,
name|root
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|pindex
operator|<
name|root
operator|->
name|pindex
condition|)
block|{
name|m
operator|->
name|left
operator|=
name|root
operator|->
name|left
expr_stmt|;
name|m
operator|->
name|right
operator|=
name|root
expr_stmt|;
name|root
operator|->
name|left
operator|=
name|NULL
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|__predict_false
argument_list|(
name|m
operator|->
name|pindex
operator|==
name|root
operator|->
name|pindex
argument_list|)
condition|)
name|panic
argument_list|(
literal|"vm_page_cache: offset already cached"
argument_list|)
expr_stmt|;
else|else
block|{
name|m
operator|->
name|right
operator|=
name|root
operator|->
name|right
expr_stmt|;
name|m
operator|->
name|left
operator|=
name|root
expr_stmt|;
name|root
operator|->
name|right
operator|=
name|NULL
expr_stmt|;
block|}
block|}
name|object
operator|->
name|cache
operator|=
name|m
expr_stmt|;
if|#
directive|if
name|VM_NRESERVLEVEL
operator|>
literal|0
if|if
condition|(
operator|!
name|vm_reserv_free_page
argument_list|(
name|m
argument_list|)
condition|)
block|{
else|#
directive|else
if|if
condition|(
name|TRUE
condition|)
block|{
endif|#
directive|endif
name|vm_phys_set_pool
argument_list|(
name|VM_FREEPOOL_CACHE
argument_list|,
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|vm_phys_free_pages
argument_list|(
name|m
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|vm_page_free_wakeup
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|vm_page_queue_free_mtx
argument_list|)
expr_stmt|;
comment|/* 	 * Increment the vnode's hold count if this is the object's only 	 * cached page.  Decrement the vnode's hold count if this was 	 * the object's only resident page. 	 */
if|if
condition|(
name|object
operator|->
name|type
operator|==
name|OBJT_VNODE
condition|)
block|{
if|if
condition|(
name|root
operator|==
name|NULL
operator|&&
name|object
operator|->
name|resident_page_count
operator|!=
literal|0
condition|)
name|vhold
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|root
operator|!=
name|NULL
operator|&&
name|object
operator|->
name|resident_page_count
operator|==
literal|0
condition|)
name|vdrop
argument_list|(
name|object
operator|->
name|handle
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*  * vm_page_dontneed  *  *	Cache, deactivate, or do nothing as appropriate.  This routine  *	is typically used by madvise() MADV_DONTNEED.  *  *	Generally speaking we want to move the page into the cache so  *	it gets reused quickly.  However, this can result in a silly syndrome  *	due to the page recycling too quickly.  Small objects will not be  *	fully cached.  On the otherhand, if we move the page to the inactive  *	queue we wind up with a problem whereby very large objects   *	unnecessarily blow away our inactive and cache queues.  *  *	The solution is to move the pages based on a fixed weighting.  We  *	either leave them alone, deactivate them, or move them to the cache,  *	where moving them to the cache has the highest weighting.  *	By forcing some pages into other queues we eventually force the  *	system to balance the queues, potentially recovering other unrelated  *	space from active.  The idea is to not force this to happen too  *	often.  */
name|void
name|vm_page_dontneed
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|dnw
decl_stmt|;
name|int
name|head
decl_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|dnw
operator|=
name|PCPU_GET
argument_list|(
name|dnweight
argument_list|)
expr_stmt|;
name|PCPU_INC
argument_list|(
name|dnweight
argument_list|)
expr_stmt|;
comment|/* 	 * Occasionally leave the page alone. 	 */
if|if
condition|(
operator|(
name|dnw
operator|&
literal|0x01F0
operator|)
operator|==
literal|0
operator|||
name|m
operator|->
name|queue
operator|==
name|PQ_INACTIVE
condition|)
block|{
if|if
condition|(
name|m
operator|->
name|act_count
operator|>=
name|ACT_INIT
condition|)
operator|--
name|m
operator|->
name|act_count
expr_stmt|;
return|return;
block|}
comment|/* 	 * Clear any references to the page.  Otherwise, the page daemon will 	 * immediately reactivate the page. 	 * 	 * Perform the pmap_clear_reference() first.  Otherwise, a concurrent 	 * pmap operation, such as pmap_remove(), could clear a reference in 	 * the pmap and set PG_REFERENCED on the page before the 	 * pmap_clear_reference() had completed.  Consequently, the page would 	 * appear referenced based upon an old reference that occurred before 	 * this function ran. 	 */
name|pmap_clear_reference
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_flag_clear
argument_list|(
name|m
argument_list|,
name|PG_REFERENCED
argument_list|)
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|==
literal|0
operator|&&
name|pmap_is_modified
argument_list|(
name|m
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|||
operator|(
name|dnw
operator|&
literal|0x0070
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 		 * Deactivate the page 3 times out of 32. 		 */
name|head
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Cache the page 28 times out of every 32.  Note that 		 * the page is deactivated instead of cached, but placed 		 * at the head of the queue instead of the tail. 		 */
name|head
operator|=
literal|1
expr_stmt|;
block|}
name|_vm_page_deactivate
argument_list|(
name|m
argument_list|,
name|head
argument_list|)
expr_stmt|;
block|}
comment|/*  * Grab a page, waiting until we are waken up due to the page  * changing state.  We keep on waiting, if the page continues  * to be in the object.  If the page doesn't exist, first allocate it  * and then conditionally zero it.  *  * The caller must always specify the VM_ALLOC_RETRY flag.  This is intended  * to facilitate its eventual removal.  *  * This routine may block.  */
name|vm_page_t
name|vm_page_grab
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|int
name|allocflags
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_RETRY
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_grab: VM_ALLOC_RETRY is required"
operator|)
argument_list|)
expr_stmt|;
name|retrylookup
label|:
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|!=
literal|0
operator|||
operator|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_IGN_SBUSY
operator|)
operator|==
literal|0
operator|&&
name|m
operator|->
name|busy
operator|!=
literal|0
operator|)
condition|)
block|{
comment|/* 			 * Reference the page before unlocking and 			 * sleeping so that the page daemon is less 			 * likely to reclaim it. 			 */
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|vm_page_flag_set
argument_list|(
name|m
argument_list|,
name|PG_REFERENCED
argument_list|)
expr_stmt|;
name|vm_page_sleep
argument_list|(
name|m
argument_list|,
literal|"pgrbwt"
argument_list|)
expr_stmt|;
goto|goto
name|retrylookup
goto|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_WIRED
operator|)
operator|!=
literal|0
condition|)
block|{
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_wire
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|allocflags
operator|&
name|VM_ALLOC_NOBUSY
operator|)
operator|==
literal|0
condition|)
name|vm_page_busy
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
block|}
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|allocflags
operator|&
operator|~
operator|(
name|VM_ALLOC_RETRY
operator||
name|VM_ALLOC_IGN_SBUSY
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|VM_OBJECT_LOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
goto|goto
name|retrylookup
goto|;
block|}
elseif|else
if|if
condition|(
name|m
operator|->
name|valid
operator|!=
literal|0
condition|)
return|return
operator|(
name|m
operator|)
return|;
if|if
condition|(
name|allocflags
operator|&
name|VM_ALLOC_ZERO
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
comment|/*  * Mapping function for valid bits or for dirty bits in  * a page.  May not block.  *  * Inputs are required to range within a page.  */
name|int
name|vm_page_bits
parameter_list|(
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|first_bit
decl_stmt|;
name|int
name|last_bit
decl_stmt|;
name|KASSERT
argument_list|(
name|base
operator|+
name|size
operator|<=
name|PAGE_SIZE
argument_list|,
operator|(
literal|"vm_page_bits: illegal base/size %d/%d"
operator|,
name|base
operator|,
name|size
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return
operator|(
literal|0
operator|)
return|;
name|first_bit
operator|=
name|base
operator|>>
name|DEV_BSHIFT
expr_stmt|;
name|last_bit
operator|=
operator|(
name|base
operator|+
name|size
operator|-
literal|1
operator|)
operator|>>
name|DEV_BSHIFT
expr_stmt|;
return|return
operator|(
operator|(
literal|2
operator|<<
name|last_bit
operator|)
operator|-
operator|(
literal|1
operator|<<
name|first_bit
operator|)
operator|)
return|;
block|}
comment|/*  *	vm_page_set_valid:  *  *	Sets portions of a page valid.  The arguments are expected  *	to be DEV_BSIZE aligned but if they aren't the bitmap is inclusive  *	of any partial chunks touched by the range.  The invalid portion of  *	such chunks will be zeroed.  *  *	(base + size) must be less then or equal to PAGE_SIZE.  */
name|void
name|vm_page_set_valid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|endoff
decl_stmt|,
name|frag
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return;
comment|/* 	 * If the base is not DEV_BSIZE aligned and the valid 	 * bit is clear, we have to zero out a portion of the 	 * first block. 	 */
if|if
condition|(
operator|(
name|frag
operator|=
name|base
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|base
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|base
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|frag
argument_list|,
name|base
operator|-
name|frag
argument_list|)
expr_stmt|;
comment|/* 	 * If the ending offset is not DEV_BSIZE aligned and the  	 * valid bit is clear, we have to zero out a portion of 	 * the last block. 	 */
name|endoff
operator|=
name|base
operator|+
name|size
expr_stmt|;
if|if
condition|(
operator|(
name|frag
operator|=
name|endoff
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|endoff
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|endoff
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|endoff
argument_list|,
name|DEV_BSIZE
operator|-
operator|(
name|endoff
operator|&
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Assert that no previously invalid block that is now being validated 	 * is already dirty.  	 */
name|KASSERT
argument_list|(
operator|(
operator|~
name|m
operator|->
name|valid
operator|&
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
operator|&
name|m
operator|->
name|dirty
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_set_valid: page %p is dirty"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Set valid bits inclusive of any overlap. 	 */
name|m
operator|->
name|valid
operator||=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
comment|/*  * Clear the given bits from the specified page's dirty field.  */
specifier|static
name|__inline
name|void
name|vm_page_clear_dirty_mask
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|pagebits
parameter_list|)
block|{
comment|/* 	 * If the object is locked and the page is neither VPO_BUSY nor 	 * PG_WRITEABLE, then the page's dirty field cannot possibly be 	 * set by a concurrent pmap operation.  	 */
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_WRITEABLE
operator|)
operator|==
literal|0
condition|)
name|m
operator|->
name|dirty
operator|&=
operator|~
name|pagebits
expr_stmt|;
else|else
block|{
if|#
directive|if
name|defined
argument_list|(
name|__amd64__
argument_list|)
operator|||
name|defined
argument_list|(
name|__i386__
argument_list|)
operator|||
name|defined
argument_list|(
name|__ia64__
argument_list|)
comment|/* 		 * On the aforementioned architectures, the page queues lock 		 * is not required by the following read-modify-write 		 * operation.  The combination of the object's lock and an 		 * atomic operation suffice.  Moreover, the pmap layer on 		 * these architectures can call vm_page_dirty() without 		 * holding the page queues lock. 		 */
if|#
directive|if
name|PAGE_SIZE
operator|==
literal|4096
name|atomic_clear_char
argument_list|(
operator|&
name|m
operator|->
name|dirty
argument_list|,
name|pagebits
argument_list|)
expr_stmt|;
elif|#
directive|elif
name|PAGE_SIZE
operator|==
literal|8192
name|atomic_clear_short
argument_list|(
operator|&
name|m
operator|->
name|dirty
argument_list|,
name|pagebits
argument_list|)
expr_stmt|;
elif|#
directive|elif
name|PAGE_SIZE
operator|==
literal|16384
name|atomic_clear_int
argument_list|(
operator|&
name|m
operator|->
name|dirty
argument_list|,
name|pagebits
argument_list|)
expr_stmt|;
else|#
directive|else
error|#
directive|error
literal|"PAGE_SIZE is not supported."
endif|#
directive|endif
else|#
directive|else
comment|/* 		 * Otherwise, the page queues lock is required to ensure that 		 * a concurrent pmap operation does not set the page's dirty 		 * field during the following read-modify-write operation. 		 */
name|vm_page_lock_queues
argument_list|()
expr_stmt|;
name|m
operator|->
name|dirty
operator|&=
operator|~
name|pagebits
expr_stmt|;
name|vm_page_unlock_queues
argument_list|()
expr_stmt|;
endif|#
directive|endif
block|}
block|}
comment|/*  *	vm_page_set_validclean:  *  *	Sets portions of a page valid and clean.  The arguments are expected  *	to be DEV_BSIZE aligned but if they aren't the bitmap is inclusive  *	of any partial chunks touched by the range.  The invalid portion of  *	such chunks will be zero'd.  *  *	This routine may not block.  *  *	(base + size) must be less then or equal to PAGE_SIZE.  */
name|void
name|vm_page_set_validclean
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|u_long
name|oldvalid
decl_stmt|;
name|int
name|endoff
decl_stmt|,
name|frag
decl_stmt|,
name|pagebits
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|size
operator|==
literal|0
condition|)
comment|/* handle degenerate case */
return|return;
comment|/* 	 * If the base is not DEV_BSIZE aligned and the valid 	 * bit is clear, we have to zero out a portion of the 	 * first block. 	 */
if|if
condition|(
operator|(
name|frag
operator|=
name|base
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|base
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|base
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|frag
argument_list|,
name|base
operator|-
name|frag
argument_list|)
expr_stmt|;
comment|/* 	 * If the ending offset is not DEV_BSIZE aligned and the  	 * valid bit is clear, we have to zero out a portion of 	 * the last block. 	 */
name|endoff
operator|=
name|base
operator|+
name|size
expr_stmt|;
if|if
condition|(
operator|(
name|frag
operator|=
name|endoff
operator|&
operator|~
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
operator|!=
name|endoff
operator|&&
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
operator|(
name|endoff
operator|>>
name|DEV_BSHIFT
operator|)
operator|)
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|endoff
argument_list|,
name|DEV_BSIZE
operator|-
operator|(
name|endoff
operator|&
operator|(
name|DEV_BSIZE
operator|-
literal|1
operator|)
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Set valid, clear dirty bits.  If validating the entire 	 * page we can safely clear the pmap modify bit.  We also 	 * use this opportunity to clear the VPO_NOSYNC flag.  If a process 	 * takes a write fault on a MAP_NOSYNC memory area the flag will 	 * be set again. 	 * 	 * We set valid bits inclusive of any overlap, but we can only 	 * clear dirty bits for DEV_BSIZE chunks that are fully within 	 * the range. 	 */
name|oldvalid
operator|=
name|m
operator|->
name|valid
expr_stmt|;
name|pagebits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator||=
name|pagebits
expr_stmt|;
if|#
directive|if
literal|0
comment|/* NOT YET */
block|if ((frag = base& (DEV_BSIZE - 1)) != 0) { 		frag = DEV_BSIZE - frag; 		base += frag; 		size -= frag; 		if (size< 0) 			size = 0; 	} 	pagebits = vm_page_bits(base, size& (DEV_BSIZE - 1));
endif|#
directive|endif
if|if
condition|(
name|base
operator|==
literal|0
operator|&&
name|size
operator|==
name|PAGE_SIZE
condition|)
block|{
comment|/* 		 * The page can only be modified within the pmap if it is 		 * mapped, and it can only be mapped if it was previously 		 * fully valid. 		 */
if|if
condition|(
name|oldvalid
operator|==
name|VM_PAGE_BITS_ALL
condition|)
comment|/* 			 * Perform the pmap_clear_modify() first.  Otherwise, 			 * a concurrent pmap operation, such as 			 * pmap_protect(), could clear a modification in the 			 * pmap and set the dirty field on the page before 			 * pmap_clear_modify() had begun and after the dirty 			 * field was cleared here. 			 */
name|pmap_clear_modify
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|m
operator|->
name|dirty
operator|=
literal|0
expr_stmt|;
name|m
operator|->
name|oflags
operator|&=
operator|~
name|VPO_NOSYNC
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|oldvalid
operator|!=
name|VM_PAGE_BITS_ALL
condition|)
name|m
operator|->
name|dirty
operator|&=
operator|~
name|pagebits
expr_stmt|;
else|else
name|vm_page_clear_dirty_mask
argument_list|(
name|m
argument_list|,
name|pagebits
argument_list|)
expr_stmt|;
block|}
name|void
name|vm_page_clear_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|vm_page_clear_dirty_mask
argument_list|(
name|m
argument_list|,
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/*  *	vm_page_set_invalid:  *  *	Invalidates DEV_BSIZE'd chunks within a page.  Both the  *	valid and dirty bits for the effected areas are cleared.  *  *	May not block.  */
name|void
name|vm_page_set_invalid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|bits
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"vm_page_set_invalid: page %p is busy"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|bits
operator|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
operator|&&
name|bits
operator|!=
literal|0
condition|)
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|pmap_page_is_mapped
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"vm_page_set_invalid: page %p is mapped"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|valid
operator|&=
operator|~
name|bits
expr_stmt|;
name|m
operator|->
name|dirty
operator|&=
operator|~
name|bits
expr_stmt|;
block|}
comment|/*  * vm_page_zero_invalid()  *  *	The kernel assumes that the invalid portions of a page contain   *	garbage, but such pages can be mapped into memory by user code.  *	When this occurs, we must zero out the non-valid portions of the  *	page so user code sees what it expects.  *  *	Pages are most often semi-valid when the end of a file is mapped   *	into memory and the file's size is not page aligned.  */
name|void
name|vm_page_zero_invalid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|boolean_t
name|setvalid
parameter_list|)
block|{
name|int
name|b
decl_stmt|;
name|int
name|i
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Scan the valid bits looking for invalid sections that 	 * must be zerod.  Invalid sub-DEV_BSIZE'd areas ( where the 	 * valid bit may be set ) have already been zerod by 	 * vm_page_set_validclean(). 	 */
for|for
control|(
name|b
operator|=
name|i
operator|=
literal|0
init|;
name|i
operator|<=
name|PAGE_SIZE
operator|/
name|DEV_BSIZE
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|i
operator|==
operator|(
name|PAGE_SIZE
operator|/
name|DEV_BSIZE
operator|)
operator|||
operator|(
name|m
operator|->
name|valid
operator|&
operator|(
literal|1
operator|<<
name|i
operator|)
operator|)
condition|)
block|{
if|if
condition|(
name|i
operator|>
name|b
condition|)
block|{
name|pmap_zero_page_area
argument_list|(
name|m
argument_list|,
name|b
operator|<<
name|DEV_BSHIFT
argument_list|,
operator|(
name|i
operator|-
name|b
operator|)
operator|<<
name|DEV_BSHIFT
argument_list|)
expr_stmt|;
block|}
name|b
operator|=
name|i
operator|+
literal|1
expr_stmt|;
block|}
block|}
comment|/* 	 * setvalid is TRUE when we can safely set the zero'd areas 	 * as being valid.  We can do this if there are no cache consistancy 	 * issues.  e.g. it is ok to do with UFS, but not ok to do with NFS. 	 */
if|if
condition|(
name|setvalid
condition|)
name|m
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
block|}
comment|/*  *	vm_page_is_valid:  *  *	Is (partial) page valid?  Note that the case where size == 0  *	will return FALSE in the degenerate case where the page is  *	entirely invalid, and TRUE otherwise.  *  *	May not block.  */
name|int
name|vm_page_is_valid
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|base
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|int
name|bits
init|=
name|vm_page_bits
argument_list|(
name|base
argument_list|,
name|size
argument_list|)
decl_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|valid
operator|&&
operator|(
operator|(
name|m
operator|->
name|valid
operator|&
name|bits
operator|)
operator|==
name|bits
operator|)
condition|)
return|return
literal|1
return|;
else|else
return|return
literal|0
return|;
block|}
comment|/*  * update dirty bits from pmap/mmu.  May not block.  */
name|void
name|vm_page_test_dirty
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|dirty
operator|!=
name|VM_PAGE_BITS_ALL
operator|&&
name|pmap_is_modified
argument_list|(
name|m
argument_list|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|int
name|so_zerocp_fullpage
init|=
literal|0
decl_stmt|;
comment|/*  *	Replace the given page with a copy.  The copied page assumes  *	the portion of the given page's "wire_count" that is not the  *	responsibility of this copy-on-write mechanism.  *  *	The object containing the given page must have a non-zero  *	paging-in-progress count and be locked.  */
name|void
name|vm_page_cowfault
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_t
name|mnew
decl_stmt|;
name|vm_object_t
name|object
decl_stmt|;
name|vm_pindex_t
name|pindex
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|vm_page_queue_mtx
argument_list|,
name|MA_NOTOWNED
argument_list|)
expr_stmt|;
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|object
operator|=
name|m
operator|->
name|object
expr_stmt|;
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|object
operator|->
name|paging_in_progress
operator|!=
literal|0
argument_list|,
operator|(
literal|"vm_page_cowfault: object %p's paging-in-progress count is zero."
operator|,
name|object
operator|)
argument_list|)
expr_stmt|;
name|pindex
operator|=
name|m
operator|->
name|pindex
expr_stmt|;
name|retry_alloc
label|:
name|pmap_remove_all
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_remove
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|mnew
operator|=
name|vm_page_alloc
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOBUSY
argument_list|)
expr_stmt|;
if|if
condition|(
name|mnew
operator|==
name|NULL
condition|)
block|{
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|VM_OBJECT_LOCK
argument_list|(
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
condition|)
block|{
name|vm_page_lock
argument_list|(
name|m
argument_list|)
expr_stmt|;
goto|goto
name|retry_alloc
goto|;
block|}
else|else
block|{
comment|/* 			 * Page disappeared during the wait. 			 */
return|return;
block|}
block|}
if|if
condition|(
name|m
operator|->
name|cow
operator|==
literal|0
condition|)
block|{
comment|/*  		 * check to see if we raced with an xmit complete when  		 * waiting to allocate a page.  If so, put things back  		 * the way they were  		 */
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|vm_page_lock
argument_list|(
name|mnew
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|mnew
argument_list|)
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|mnew
argument_list|)
expr_stmt|;
name|vm_page_insert
argument_list|(
name|m
argument_list|,
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* clear COW& copy page */
if|if
condition|(
operator|!
name|so_zerocp_fullpage
condition|)
name|pmap_copy_page
argument_list|(
name|m
argument_list|,
name|mnew
argument_list|)
expr_stmt|;
name|mnew
operator|->
name|valid
operator|=
name|VM_PAGE_BITS_ALL
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|mnew
argument_list|)
expr_stmt|;
name|mnew
operator|->
name|wire_count
operator|=
name|m
operator|->
name|wire_count
operator|-
name|m
operator|->
name|cow
expr_stmt|;
name|m
operator|->
name|wire_count
operator|=
name|m
operator|->
name|cow
expr_stmt|;
name|vm_page_unlock
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
name|void
name|vm_page_cowclear
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|cow
condition|)
block|{
name|m
operator|->
name|cow
operator|--
expr_stmt|;
comment|/*  		 * let vm_fault add back write permission  lazily 		 */
block|}
comment|/* 	 *  sf_buf_free() will free the page, so we needn't do it here 	 */
block|}
name|int
name|vm_page_cowsetup
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_page_lock_assert
argument_list|(
name|m
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
operator|(
name|PG_FICTITIOUS
operator||
name|PG_UNMANAGED
operator|)
operator|)
operator|!=
literal|0
operator|||
name|m
operator|->
name|cow
operator|==
name|USHRT_MAX
operator|-
literal|1
operator|||
operator|!
name|VM_OBJECT_TRYLOCK
argument_list|(
name|m
operator|->
name|object
argument_list|)
condition|)
return|return
operator|(
name|EBUSY
operator|)
return|;
name|m
operator|->
name|cow
operator|++
expr_stmt|;
name|pmap_remove_write
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|VM_OBJECT_UNLOCK
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
ifdef|#
directive|ifdef
name|INVARIANTS
name|void
name|vm_page_object_lock_assert
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
comment|/* 	 * Certain of the page's fields may only be modified by the 	 * holder of the containing object's lock or the setter of the 	 * page's VPO_BUSY flag.  Unfortunately, the setter of the 	 * VPO_BUSY flag is not recorded, and thus cannot be checked 	 * here. 	 */
if|if
condition|(
name|m
operator|->
name|object
operator|!=
name|NULL
operator|&&
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_BUSY
operator|)
operator|==
literal|0
condition|)
name|VM_OBJECT_LOCK_ASSERT
argument_list|(
name|m
operator|->
name|object
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
include|#
directive|include
file|"opt_ddb.h"
ifdef|#
directive|ifdef
name|DDB
include|#
directive|include
file|<sys/kernel.h>
include|#
directive|include
file|<ddb/ddb.h>
name|DB_SHOW_COMMAND
argument_list|(
argument|page
argument_list|,
argument|vm_page_print_page_info
argument_list|)
block|{
name|db_printf
argument_list|(
literal|"cnt.v_free_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_cache_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_cache_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_inactive_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_inactive_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_active_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_active_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_wire_count: %d\n"
argument_list|,
name|cnt
operator|.
name|v_wire_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_reserved: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_reserved
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_min: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_min
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_free_target: %d\n"
argument_list|,
name|cnt
operator|.
name|v_free_target
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_cache_min: %d\n"
argument_list|,
name|cnt
operator|.
name|v_cache_min
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"cnt.v_inactive_target: %d\n"
argument_list|,
name|cnt
operator|.
name|v_inactive_target
argument_list|)
expr_stmt|;
block|}
name|DB_SHOW_COMMAND
argument_list|(
argument|pageq
argument_list|,
argument|vm_page_print_pageq_info
argument_list|)
block|{
name|db_printf
argument_list|(
literal|"PQ_FREE:"
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|" %d"
argument_list|,
name|cnt
operator|.
name|v_free_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"PQ_CACHE:"
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|" %d"
argument_list|,
name|cnt
operator|.
name|v_cache_count
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
name|db_printf
argument_list|(
literal|"PQ_ACTIVE: %d, PQ_INACTIVE: %d\n"
argument_list|,
operator|*
name|vm_page_queues
index|[
name|PQ_ACTIVE
index|]
operator|.
name|cnt
argument_list|,
operator|*
name|vm_page_queues
index|[
name|PQ_INACTIVE
index|]
operator|.
name|cnt
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* DDB */
end_comment

end_unit

