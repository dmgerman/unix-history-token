begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/* Copyright (c) 2001 Wolfram Gloger Copyright (c) 2006 Cavium networks  Permission to use, copy, modify, distribute, and sell this software and its documentation for any purpose is hereby granted without fee, provided that (i) the above copyright notices and this permission notice appear in all copies of the software and related documentation, and (ii) the name of Wolfram Gloger may not be used in any advertising or publicity relating to the software.  THE SOFTWARE IS PROVIDED "AS-IS" AND WITHOUT WARRANTY OF ANY KIND, EXPRESS, IMPLIED OR OTHERWISE, INCLUDING WITHOUT LIMITATION, ANY WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.  IN NO EVENT SHALL WOLFRAM GLOGER BE LIABLE FOR ANY SPECIAL, INCIDENTAL, INDIRECT OR CONSEQUENTIAL DAMAGES OF ANY KIND, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER OR NOT ADVISED OF THE POSSIBILITY OF DAMAGE, AND ON ANY THEORY OF LIABILITY, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. */
end_comment

begin_comment
comment|/*   This is a version (aka ptmalloc2) of malloc/free/realloc written by   Doug Lea and adapted to multiple threads/arenas by Wolfram Gloger.  * Version ptmalloc2-20011215   $Id: malloc.c 30481 2007-12-05 21:46:59Z rfranz $   based on:   VERSION 2.7.1pre1 Sat May 12 07:41:21 2001  Doug Lea  (dl at gee)     Note: There may be an updated version of this malloc obtainable at            http://www.malloc.de/malloc/ptmalloc2.tar.gz          Check before installing!  * Quickstart    In order to compile this implementation, a Makefile is provided with   the ptmalloc2 distribution, which has pre-defined targets for some   popular systems (e.g. "make posix" for Posix threads).  All that is   typically required with regard to compiler flags is the selection of   the thread package via defining one out of USE_PTHREADS, USE_THR or   USE_SPROC.  Check the thread-m.h file for what effects this has.   Many/most systems will additionally require USE_TSD_DATA_HACK to be   defined, so this is the default for "make posix".  * Why use this malloc?    This is not the fastest, most space-conserving, most portable, or   most tunable malloc ever written. However it is among the fastest   while also being among the most space-conserving, portable and tunable.   Consistent balance across these factors results in a good general-purpose   allocator for malloc-intensive programs.    The main properties of the algorithms are:   * For large (>= 512 bytes) requests, it is a pure best-fit allocator,     with ties normally decided via FIFO (i.e. least recently used).   * For small (<= 64 bytes by default) requests, it is a caching     allocator, that maintains pools of quickly recycled chunks.   * In between, and for combinations of large and small requests, it does     the best it can trying to meet both goals at once.   * For very large requests (>= 128KB by default), it relies on system     memory mapping facilities, if supported.    For a longer but slightly out of date high-level description, see      http://gee.cs.oswego.edu/dl/html/malloc.html    You may already by default be using a C library containing a malloc   that is  based on some version of this malloc (for example in   linux). You might still want to use the one in this file in order to   customize settings or to avoid overheads associated with library   versions.  * Contents, described in more detail in "description of public routines" below.    Standard (ANSI/SVID/...)  functions:     malloc(size_t n);     calloc(size_t n_elements, size_t element_size);     free(Void_t* p);     realloc(Void_t* p, size_t n);     memalign(size_t alignment, size_t n);     valloc(size_t n);     mallinfo()     mallopt(int parameter_number, int parameter_value)    Additional functions:     independent_calloc(size_t n_elements, size_t size, Void_t* chunks[]);     independent_comalloc(size_t n_elements, size_t sizes[], Void_t* chunks[]);     pvalloc(size_t n);     cfree(Void_t* p);     malloc_trim(size_t pad);     malloc_usable_size(Void_t* p);     malloc_stats();  * Vital statistics:    Supported pointer representation:       4 or 8 bytes   Supported size_t  representation:       4 or 8 bytes        Note that size_t is allowed to be 4 bytes even if pointers are 8.        You can adjust this by defining INTERNAL_SIZE_T    Alignment:                              2 * sizeof(size_t) (default)        (i.e., 8 byte alignment with 4byte size_t). This suffices for        nearly all current machines and C compilers. However, you can        define MALLOC_ALIGNMENT to be wider than this if necessary.    Minimum overhead per allocated chunk:   4 or 8 bytes        Each malloced chunk has a hidden word of overhead holding size        and status information.    Minimum allocated size: 4-byte ptrs:  16 bytes    (including 4 overhead)                           8-byte ptrs:  24/32 bytes (including, 4/8 overhead)         When a chunk is freed, 12 (for 4byte ptrs) or 20 (for 8 byte        ptrs but 4 byte size) or 24 (for 8/8) additional bytes are        needed; 4 (8) for a trailing size field and 8 (16) bytes for        free list pointers. Thus, the minimum allocatable size is        16/24/32 bytes.         Even a request for zero bytes (i.e., malloc(0)) returns a        pointer to something of the minimum allocatable size.         The maximum overhead wastage (i.e., number of extra bytes        allocated than were requested in malloc) is less than or equal        to the minimum size, except for requests>= mmap_threshold that        are serviced via mmap(), where the worst case wastage is 2 *        sizeof(size_t) bytes plus the remainder from a system page (the        minimal mmap unit); typically 4096 or 8192 bytes.    Maximum allocated size:  4-byte size_t: 2^32 minus about two pages                            8-byte size_t: 2^64 minus about two pages         It is assumed that (possibly signed) size_t values suffice to        represent chunk sizes. `Possibly signed' is due to the fact        that `size_t' may be defined on a system as either a signed or        an unsigned type. The ISO C standard says that it must be        unsigned, but a few systems are known not to adhere to this.        Additionally, even when size_t is unsigned, sbrk (which is by        default used to obtain memory from system) accepts signed        arguments, and may not be able to handle size_t-wide arguments        with negative sign bit.  Generally, values that would        appear as negative after accounting for overhead and alignment        are supported only via mmap(), which does not have this        limitation.         Requests for sizes outside the allowed range will perform an optional        failure action and then return null. (Requests may also        also fail because a system is out of memory.)    Thread-safety: thread-safe unless NO_THREADS is defined    Compliance: I believe it is compliant with the 1997 Single Unix Specification        (See http://www.opennc.org). Also SVID/XPG, ANSI C, and probably        others as well.  * Synopsis of compile-time options:      People have reported using previous versions of this malloc on all     versions of Unix, sometimes by tweaking some of the defines     below. It has been tested most extensively on Solaris and     Linux. It is also reported to work on WIN32 platforms.     People also report using it in stand-alone embedded systems.      The implementation is in straight, hand-tuned ANSI C.  It is not     at all modular. (Sorry!)  It uses a lot of macros.  To be at all     usable, this code should be compiled using an optimizing compiler     (for example gcc -O3) that can simplify expressions and control     paths. (FAQ: some macros import variables as arguments rather than     declare locals because people reported that some debuggers     otherwise get confused.)      OPTION                     DEFAULT VALUE      Compilation Environment options:      __STD_C                    derived from C compiler defines     WIN32                      NOT defined     HAVE_MEMCPY                defined     USE_MEMCPY                 1 if HAVE_MEMCPY is defined     HAVE_MMAP                  defined as 1     MMAP_CLEARS                1     HAVE_MREMAP                0 unless linux defined     USE_ARENAS                 the same as HAVE_MMAP     malloc_getpagesize         derived from system #includes, or 4096 if not     HAVE_USR_INCLUDE_MALLOC_H  NOT defined     LACKS_UNISTD_H             NOT defined unless WIN32     LACKS_SYS_PARAM_H          NOT defined unless WIN32     LACKS_SYS_MMAN_H           NOT defined unless WIN32      Changing default word sizes:      INTERNAL_SIZE_T            size_t     MALLOC_ALIGNMENT           2 * sizeof(INTERNAL_SIZE_T)      Configuration and functionality options:      USE_DL_PREFIX              NOT defined     USE_PUBLIC_MALLOC_WRAPPERS NOT defined     USE_MALLOC_LOCK            NOT defined     MALLOC_DEBUG               NOT defined     REALLOC_ZERO_BYTES_FREES   1     MALLOC_FAILURE_ACTION      errno = ENOMEM, if __STD_C defined, else no-op     TRIM_FASTBINS              0     FIRST_SORTED_BIN_SIZE      512      Options for customizing MORECORE:      MORECORE                   sbrk     MORECORE_FAILURE           -1     MORECORE_CONTIGUOUS        1     MORECORE_CANNOT_TRIM       NOT defined     MORECORE_CLEARS            1     MMAP_AS_MORECORE_SIZE      (1024 * 1024)      Tuning options that are also dynamically changeable via mallopt:      DEFAULT_MXFAST             64     DEFAULT_TRIM_THRESHOLD     128 * 1024     DEFAULT_TOP_PAD            0     DEFAULT_MMAP_THRESHOLD     128 * 1024     DEFAULT_MMAP_MAX           65536      There are several other #defined constants and macros that you     probably don't want to touch unless you are extending or adapting malloc.  */
end_comment

begin_comment
comment|/*   __STD_C should be nonzero if using ANSI-standard C compiler, a C++   compiler, or a C compiler sufficiently close to ANSI to get away   with it. */
end_comment

begin_include
include|#
directive|include
file|"cvmx-config.h"
end_include

begin_include
include|#
directive|include
file|"cvmx.h"
end_include

begin_include
include|#
directive|include
file|"cvmx-spinlock.h"
end_include

begin_include
include|#
directive|include
file|"cvmx-malloc.h"
end_include

begin_ifndef
ifndef|#
directive|ifndef
name|__STD_C
end_ifndef

begin_if
if|#
directive|if
name|defined
argument_list|(
name|__STDC__
argument_list|)
operator|||
name|defined
argument_list|(
name|__cplusplus
argument_list|)
end_if

begin_define
define|#
directive|define
name|__STD_C
value|1
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|__STD_C
value|0
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*__STD_C*/
end_comment

begin_comment
comment|/*   Void_t* is the pointer type that malloc should say it returns */
end_comment

begin_ifndef
ifndef|#
directive|ifndef
name|Void_t
end_ifndef

begin_if
if|#
directive|if
literal|1
end_if

begin_define
define|#
directive|define
name|Void_t
value|void
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|Void_t
value|char
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*Void_t*/
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|__cplusplus
end_ifdef

begin_extern
extern|extern
literal|"C"
block|{
endif|#
directive|endif
comment|/* define LACKS_UNISTD_H if your system does not have a<unistd.h>. */
comment|/* #define  LACKS_UNISTD_H */
ifndef|#
directive|ifndef
name|LACKS_UNISTD_H
include|#
directive|include
file|<unistd.h>
endif|#
directive|endif
comment|/* define LACKS_SYS_PARAM_H if your system does not have a<sys/param.h>. */
comment|/* #define  LACKS_SYS_PARAM_H */
include|#
directive|include
file|<stdio.h>
comment|/* needed for malloc_stats */
include|#
directive|include
file|<errno.h>
comment|/* needed for optional MALLOC_FAILURE_ACTION */
comment|/*   Debugging:    Because freed chunks may be overwritten with bookkeeping fields, this   malloc will often die when freed memory is overwritten by user   programs.  This can be very effective (albeit in an annoying way)   in helping track down dangling pointers.    If you compile with -DMALLOC_DEBUG, a number of assertion checks are   enabled that will catch more memory errors. You probably won't be   able to make much sense of the actual assertion errors, but they   should help you locate incorrectly overwritten memory.  The checking   is fairly extensive, and will slow down execution   noticeably. Calling malloc_stats or mallinfo with MALLOC_DEBUG set   will attempt to check every non-mmapped allocated and free chunk in   the course of computing the summmaries. (By nature, mmapped regions   cannot be checked very much automatically.)    Setting MALLOC_DEBUG may also be helpful if you are trying to modify   this code. The assertions in the check routines spell out in more   detail the assumptions and invariants underlying the algorithms.    Setting MALLOC_DEBUG does NOT provide an automated mechanism for   checking that all accesses to malloced memory stay within their   bounds. However, there are several add-ons and adaptations of this   or other mallocs available that do this. */
define|#
directive|define
name|MALLOC_DEBUG
value|1
if|#
directive|if
name|MALLOC_DEBUG
include|#
directive|include
file|<assert.h>
else|#
directive|else
define|#
directive|define
name|assert
parameter_list|(
name|x
parameter_list|)
value|((void)0)
endif|#
directive|endif
comment|/*   INTERNAL_SIZE_T is the word-size used for internal bookkeeping   of chunk sizes.    The default version is the same as size_t.    While not strictly necessary, it is best to define this as an   unsigned type, even if size_t is a signed type. This may avoid some   artificial size limitations on some systems.    On a 64-bit machine, you may be able to reduce malloc overhead by   defining INTERNAL_SIZE_T to be a 32 bit `unsigned int' at the   expense of not being able to handle more than 2^32 of malloced   space. If this limitation is acceptable, you are encouraged to set   this unless you are on a platform requiring 16byte alignments. In   this case the alignment requirements turn out to negate any   potential advantages of decreasing size_t word size.    Implementors: Beware of the possible combinations of:      - INTERNAL_SIZE_T might be signed or unsigned, might be 32 or 64 bits,        and might be the same width as int or as long      - size_t might have different width and signedness as INTERNAL_SIZE_T      - int and long might be 32 or 64 bits, and might be the same width   To deal with this, most comparisons and difference computations   among INTERNAL_SIZE_Ts should cast them to unsigned long, being   aware of the fact that casting an unsigned int to a wider long does   not sign-extend. (This also makes checking for negative numbers   awkward.) Some of these casts result in harmless compiler warnings   on some systems. */
ifndef|#
directive|ifndef
name|INTERNAL_SIZE_T
define|#
directive|define
name|INTERNAL_SIZE_T
value|size_t
endif|#
directive|endif
comment|/* The corresponding word size */
define|#
directive|define
name|SIZE_SZ
value|(sizeof(INTERNAL_SIZE_T))
comment|/*   MALLOC_ALIGNMENT is the minimum alignment for malloc'ed chunks.   It must be a power of two at least 2 * SIZE_SZ, even on machines   for which smaller alignments would suffice. It may be defined as   larger than this though. Note however that code and data structures   are optimized for the case of 8-byte alignment. */
ifndef|#
directive|ifndef
name|MALLOC_ALIGNMENT
define|#
directive|define
name|MALLOC_ALIGNMENT
value|(2 * SIZE_SZ)
endif|#
directive|endif
comment|/* The corresponding bit mask value */
define|#
directive|define
name|MALLOC_ALIGN_MASK
value|(MALLOC_ALIGNMENT - 1)
comment|/*   REALLOC_ZERO_BYTES_FREES should be set if a call to   realloc with zero bytes should be the same as a call to free.   This is required by the C standard. Otherwise, since this malloc   returns a unique pointer for malloc(0), so does realloc(p, 0). */
ifndef|#
directive|ifndef
name|REALLOC_ZERO_BYTES_FREES
define|#
directive|define
name|REALLOC_ZERO_BYTES_FREES
value|1
endif|#
directive|endif
comment|/*   TRIM_FASTBINS controls whether free() of a very small chunk can   immediately lead to trimming. Setting to true (1) can reduce memory   footprint, but will almost always slow down programs that use a lot   of small chunks.    Define this only if you are willing to give up some speed to more   aggressively reduce system-level memory footprint when releasing   memory in programs that use many small chunks.  You can get   essentially the same effect by setting MXFAST to 0, but this can   lead to even greater slowdowns in programs using many small chunks.   TRIM_FASTBINS is an in-between compile-time option, that disables   only those chunks bordering topmost memory from being placed in   fastbins. */
ifndef|#
directive|ifndef
name|TRIM_FASTBINS
define|#
directive|define
name|TRIM_FASTBINS
value|0
endif|#
directive|endif
comment|/*   USE_DL_PREFIX will prefix all public routines with the string 'dl'.   This is necessary when you only want to use this malloc in one part   of a program, using your regular system malloc elsewhere. */
define|#
directive|define
name|USE_DL_PREFIX
comment|/*    Two-phase name translation.    All of the actual routines are given mangled names.    When wrappers are used, they become the public callable versions.    When DL_PREFIX is used, the callable names are prefixed. */
ifdef|#
directive|ifdef
name|USE_DL_PREFIX
define|#
directive|define
name|public_cALLOc
value|cvmx_calloc
define|#
directive|define
name|public_fREe
value|cvmx_free
define|#
directive|define
name|public_cFREe
value|dlcfree
define|#
directive|define
name|public_mALLOc
value|cvmx_malloc
define|#
directive|define
name|public_mEMALIGn
value|cvmx_memalign
define|#
directive|define
name|public_rEALLOc
value|cvmx_realloc
define|#
directive|define
name|public_vALLOc
value|dlvalloc
define|#
directive|define
name|public_pVALLOc
value|dlpvalloc
define|#
directive|define
name|public_mALLINFo
value|dlmallinfo
define|#
directive|define
name|public_mALLOPt
value|dlmallopt
define|#
directive|define
name|public_mTRIm
value|dlmalloc_trim
define|#
directive|define
name|public_mSTATs
value|dlmalloc_stats
define|#
directive|define
name|public_mUSABLe
value|dlmalloc_usable_size
define|#
directive|define
name|public_iCALLOc
value|dlindependent_calloc
define|#
directive|define
name|public_iCOMALLOc
value|dlindependent_comalloc
define|#
directive|define
name|public_gET_STATe
value|dlget_state
define|#
directive|define
name|public_sET_STATe
value|dlset_state
else|#
directive|else
comment|/* USE_DL_PREFIX */
ifdef|#
directive|ifdef
name|_LIBC
error|#
directive|error
error|_LIBC defined and should not be
comment|/* Special defines for the GNU C library.  */
define|#
directive|define
name|public_cALLOc
value|__libc_calloc
define|#
directive|define
name|public_fREe
value|__libc_free
define|#
directive|define
name|public_cFREe
value|__libc_cfree
define|#
directive|define
name|public_mALLOc
value|__libc_malloc
define|#
directive|define
name|public_mEMALIGn
value|__libc_memalign
define|#
directive|define
name|public_rEALLOc
value|__libc_realloc
define|#
directive|define
name|public_vALLOc
value|__libc_valloc
define|#
directive|define
name|public_pVALLOc
value|__libc_pvalloc
define|#
directive|define
name|public_mALLINFo
value|__libc_mallinfo
define|#
directive|define
name|public_mALLOPt
value|__libc_mallopt
define|#
directive|define
name|public_mTRIm
value|__malloc_trim
define|#
directive|define
name|public_mSTATs
value|__malloc_stats
define|#
directive|define
name|public_mUSABLe
value|__malloc_usable_size
define|#
directive|define
name|public_iCALLOc
value|__libc_independent_calloc
define|#
directive|define
name|public_iCOMALLOc
value|__libc_independent_comalloc
define|#
directive|define
name|public_gET_STATe
value|__malloc_get_state
define|#
directive|define
name|public_sET_STATe
value|__malloc_set_state
define|#
directive|define
name|malloc_getpagesize
value|__getpagesize()
define|#
directive|define
name|open
value|__open
define|#
directive|define
name|mmap
value|__mmap
define|#
directive|define
name|munmap
value|__munmap
define|#
directive|define
name|mremap
value|__mremap
define|#
directive|define
name|mprotect
value|__mprotect
define|#
directive|define
name|MORECORE
value|(*__morecore)
define|#
directive|define
name|MORECORE_FAILURE
value|0
name|Void_t
modifier|*
name|__default_morecore
parameter_list|(
name|ptrdiff_t
parameter_list|)
function_decl|;
name|Void_t
modifier|*
function_decl|(
modifier|*
name|__morecore
function_decl|)
parameter_list|(
name|ptrdiff_t
parameter_list|)
init|=
name|__default_morecore
function_decl|;
else|#
directive|else
comment|/* !_LIBC */
define|#
directive|define
name|public_cALLOc
value|calloc
define|#
directive|define
name|public_fREe
value|free
define|#
directive|define
name|public_cFREe
value|cfree
define|#
directive|define
name|public_mALLOc
value|malloc
define|#
directive|define
name|public_mEMALIGn
value|memalign
define|#
directive|define
name|public_rEALLOc
value|realloc
define|#
directive|define
name|public_vALLOc
value|valloc
define|#
directive|define
name|public_pVALLOc
value|pvalloc
define|#
directive|define
name|public_mALLINFo
value|mallinfo
define|#
directive|define
name|public_mALLOPt
value|mallopt
define|#
directive|define
name|public_mTRIm
value|malloc_trim
define|#
directive|define
name|public_mSTATs
value|malloc_stats
define|#
directive|define
name|public_mUSABLe
value|malloc_usable_size
define|#
directive|define
name|public_iCALLOc
value|independent_calloc
define|#
directive|define
name|public_iCOMALLOc
value|independent_comalloc
define|#
directive|define
name|public_gET_STATe
value|malloc_get_state
define|#
directive|define
name|public_sET_STATe
value|malloc_set_state
endif|#
directive|endif
comment|/* _LIBC */
endif|#
directive|endif
comment|/* USE_DL_PREFIX */
comment|/*   HAVE_MEMCPY should be defined if you are not otherwise using   ANSI STD C, but still have memcpy and memset in your C library   and want to use them in calloc and realloc. Otherwise simple   macro versions are defined below.    USE_MEMCPY should be defined as 1 if you actually want to   have memset and memcpy called. People report that the macro   versions are faster than libc versions on some systems.    Even if USE_MEMCPY is set to 1, loops to copy/clear small chunks   (of<= 36 bytes) are manually unrolled in realloc and calloc. */
define|#
directive|define
name|HAVE_MEMCPY
ifndef|#
directive|ifndef
name|USE_MEMCPY
ifdef|#
directive|ifdef
name|HAVE_MEMCPY
define|#
directive|define
name|USE_MEMCPY
value|1
else|#
directive|else
define|#
directive|define
name|USE_MEMCPY
value|0
endif|#
directive|endif
endif|#
directive|endif
if|#
directive|if
operator|(
name|__STD_C
operator|||
name|defined
argument_list|(
name|HAVE_MEMCPY
argument_list|)
operator|)
ifdef|#
directive|ifdef
name|WIN32
comment|/* On Win32 memset and memcpy are already declared in windows.h */
else|#
directive|else
if|#
directive|if
name|__STD_C
name|void
modifier|*
name|memset
parameter_list|(
name|void
modifier|*
parameter_list|,
name|int
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
name|void
modifier|*
name|memcpy
parameter_list|(
name|void
modifier|*
parameter_list|,
specifier|const
name|void
modifier|*
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
else|#
directive|else
name|Void_t
modifier|*
name|memset
parameter_list|()
function_decl|;
name|Void_t
modifier|*
name|memcpy
parameter_list|()
function_decl|;
endif|#
directive|endif
endif|#
directive|endif
endif|#
directive|endif
comment|/*   MALLOC_FAILURE_ACTION is the action to take before "return 0" when   malloc fails to be able to return memory, either because memory is   exhausted or because of illegal arguments.    By default, sets errno if running on STD_C platform, else does nothing. */
ifndef|#
directive|ifndef
name|MALLOC_FAILURE_ACTION
if|#
directive|if
name|__STD_C
define|#
directive|define
name|MALLOC_FAILURE_ACTION
define|\
value|errno = ENOMEM;
else|#
directive|else
define|#
directive|define
name|MALLOC_FAILURE_ACTION
endif|#
directive|endif
endif|#
directive|endif
comment|/*   MORECORE-related declarations. By default, rely on sbrk */
ifdef|#
directive|ifdef
name|LACKS_UNISTD_H
if|#
directive|if
operator|!
name|defined
argument_list|(
name|__FreeBSD__
argument_list|)
operator|&&
operator|!
name|defined
argument_list|(
name|__OpenBSD__
argument_list|)
operator|&&
operator|!
name|defined
argument_list|(
name|__NetBSD__
argument_list|)
if|#
directive|if
name|__STD_C
specifier|extern
name|Void_t
modifier|*
name|sbrk
parameter_list|(
name|ptrdiff_t
parameter_list|)
function_decl|;
else|#
directive|else
specifier|extern
name|Void_t
modifier|*
name|sbrk
parameter_list|()
function_decl|;
endif|#
directive|endif
endif|#
directive|endif
endif|#
directive|endif
comment|/*   MORECORE is the name of the routine to call to obtain more memory   from the system.  See below for general guidance on writing   alternative MORECORE functions, as well as a version for WIN32 and a   sample version for pre-OSX macos. */
undef|#
directive|undef
name|MORECORE
comment|// not supported
ifndef|#
directive|ifndef
name|MORECORE
define|#
directive|define
name|MORECORE
value|notsupported
endif|#
directive|endif
comment|/*   MORECORE_FAILURE is the value returned upon failure of MORECORE   as well as mmap. Since it cannot be an otherwise valid memory address,   and must reflect values of standard sys calls, you probably ought not   try to redefine it. */
ifndef|#
directive|ifndef
name|MORECORE_FAILURE
define|#
directive|define
name|MORECORE_FAILURE
value|(-1)
endif|#
directive|endif
comment|/*   If MORECORE_CONTIGUOUS is true, take advantage of fact that   consecutive calls to MORECORE with positive arguments always return   contiguous increasing addresses.  This is true of unix sbrk.  Even   if not defined, when regions happen to be contiguous, malloc will   permit allocations spanning regions obtained from different   calls. But defining this when applicable enables some stronger   consistency checks and space efficiencies. */
ifndef|#
directive|ifndef
name|MORECORE_CONTIGUOUS
define|#
directive|define
name|MORECORE_CONTIGUOUS
value|0
endif|#
directive|endif
comment|/*   Define MORECORE_CANNOT_TRIM if your version of MORECORE   cannot release space back to the system when given negative   arguments. This is generally necessary only if you are using   a hand-crafted MORECORE function that cannot handle negative arguments. */
define|#
directive|define
name|MORECORE_CANNOT_TRIM
value|1
comment|/*  MORECORE_CLEARS           (default 1)      The degree to which the routine mapped to MORECORE zeroes out      memory: never (0), only for newly allocated space (1) or always      (2).  The distinction between (1) and (2) is necessary because on      some systems, if the application first decrements and then      increments the break value, the contents of the reallocated space      are unspecified. */
ifndef|#
directive|ifndef
name|MORECORE_CLEARS
define|#
directive|define
name|MORECORE_CLEARS
value|0
endif|#
directive|endif
comment|/*   Define HAVE_MMAP as true to optionally make malloc() use mmap() to   allocate very large blocks.  These will be returned to the   operating system immediately after a free(). Also, if mmap   is available, it is used as a backup strategy in cases where   MORECORE fails to provide space from system.    This malloc is best tuned to work with mmap for large requests.   If you do not have mmap, operations involving very large chunks (1MB   or so) may be slower than you'd like. */
undef|#
directive|undef
name|HAVE_MMAP
ifndef|#
directive|ifndef
name|HAVE_MMAP
define|#
directive|define
name|HAVE_MMAP
value|0
comment|/*    Standard unix mmap using /dev/zero clears memory so calloc doesn't    need to. */
ifndef|#
directive|ifndef
name|MMAP_CLEARS
define|#
directive|define
name|MMAP_CLEARS
value|0
endif|#
directive|endif
else|#
directive|else
comment|/* no mmap */
ifndef|#
directive|ifndef
name|MMAP_CLEARS
define|#
directive|define
name|MMAP_CLEARS
value|0
endif|#
directive|endif
endif|#
directive|endif
comment|/*    MMAP_AS_MORECORE_SIZE is the minimum mmap size argument to use if    sbrk fails, and mmap is used as a backup (which is done only if    HAVE_MMAP).  The value must be a multiple of page size.  This    backup strategy generally applies only when systems have "holes" in    address space, so sbrk cannot perform contiguous expansion, but    there is still space available on system.  On systems for which    this is known to be useful (i.e. most linux kernels), this occurs    only when programs allocate huge amounts of memory.  Between this,    and the fact that mmap regions tend to be limited, the size should    be large, to avoid too many mmap calls and thus avoid running out    of kernel resources. */
ifndef|#
directive|ifndef
name|MMAP_AS_MORECORE_SIZE
define|#
directive|define
name|MMAP_AS_MORECORE_SIZE
value|(1024 * 1024)
endif|#
directive|endif
comment|/*   Define HAVE_MREMAP to make realloc() use mremap() to re-allocate   large blocks.  This is currently only possible on Linux with   kernel versions newer than 1.3.77. */
undef|#
directive|undef
name|linux
ifndef|#
directive|ifndef
name|HAVE_MREMAP
ifdef|#
directive|ifdef
name|linux
define|#
directive|define
name|HAVE_MREMAP
value|1
else|#
directive|else
define|#
directive|define
name|HAVE_MREMAP
value|0
endif|#
directive|endif
endif|#
directive|endif
comment|/* HAVE_MMAP */
comment|/* Define USE_ARENAS to enable support for multiple `arenas'.  These    are allocated using mmap(), are necessary for threads and    occasionally useful to overcome address space limitations affecting    sbrk(). */
ifndef|#
directive|ifndef
name|USE_ARENAS
define|#
directive|define
name|USE_ARENAS
value|1
comment|// we 'manually' mmap the arenas.....
endif|#
directive|endif
comment|/*   The system page size. To the extent possible, this malloc manages   memory from the system in page-size units.  Note that this value is   cached during initialization into a field of malloc_state. So even   if malloc_getpagesize is a function, it is only called once.    The following mechanics for getpagesize were adapted from bsd/gnu   getpagesize.h. If none of the system-probes here apply, a value of   4096 is used, which should be OK: If they don't apply, then using   the actual value probably doesn't impact performance. */
define|#
directive|define
name|malloc_getpagesize
value|(4096)
ifndef|#
directive|ifndef
name|malloc_getpagesize
ifndef|#
directive|ifndef
name|LACKS_UNISTD_H
include|#
directive|include
file|<unistd.h>
endif|#
directive|endif
ifdef|#
directive|ifdef
name|_SC_PAGESIZE
comment|/* some SVR4 systems omit an underscore */
ifndef|#
directive|ifndef
name|_SC_PAGE_SIZE
define|#
directive|define
name|_SC_PAGE_SIZE
value|_SC_PAGESIZE
endif|#
directive|endif
endif|#
directive|endif
ifdef|#
directive|ifdef
name|_SC_PAGE_SIZE
define|#
directive|define
name|malloc_getpagesize
value|sysconf(_SC_PAGE_SIZE)
else|#
directive|else
if|#
directive|if
name|defined
argument_list|(
name|BSD
argument_list|)
operator|||
name|defined
argument_list|(
name|DGUX
argument_list|)
operator|||
name|defined
argument_list|(
name|HAVE_GETPAGESIZE
argument_list|)
specifier|extern
name|size_t
name|getpagesize
parameter_list|()
function_decl|;
define|#
directive|define
name|malloc_getpagesize
value|getpagesize()
else|#
directive|else
ifdef|#
directive|ifdef
name|WIN32
comment|/* use supplied emulation of getpagesize */
define|#
directive|define
name|malloc_getpagesize
value|getpagesize()
else|#
directive|else
ifndef|#
directive|ifndef
name|LACKS_SYS_PARAM_H
include|#
directive|include
file|<sys/param.h>
endif|#
directive|endif
ifdef|#
directive|ifdef
name|EXEC_PAGESIZE
define|#
directive|define
name|malloc_getpagesize
value|EXEC_PAGESIZE
else|#
directive|else
ifdef|#
directive|ifdef
name|NBPG
ifndef|#
directive|ifndef
name|CLSIZE
define|#
directive|define
name|malloc_getpagesize
value|NBPG
else|#
directive|else
define|#
directive|define
name|malloc_getpagesize
value|(NBPG * CLSIZE)
endif|#
directive|endif
else|#
directive|else
ifdef|#
directive|ifdef
name|NBPC
define|#
directive|define
name|malloc_getpagesize
value|NBPC
else|#
directive|else
ifdef|#
directive|ifdef
name|PAGESIZE
define|#
directive|define
name|malloc_getpagesize
value|PAGESIZE
else|#
directive|else
comment|/* just guess */
define|#
directive|define
name|malloc_getpagesize
value|(4096)
endif|#
directive|endif
endif|#
directive|endif
endif|#
directive|endif
endif|#
directive|endif
endif|#
directive|endif
endif|#
directive|endif
endif|#
directive|endif
endif|#
directive|endif
comment|/*   This version of malloc supports the standard SVID/XPG mallinfo   routine that returns a struct containing usage properties and   statistics. It should work on any SVID/XPG compliant system that has   a /usr/include/malloc.h defining struct mallinfo. (If you'd like to   install such a thing yourself, cut out the preliminary declarations   as described above and below and save them in a malloc.h file. But   there's no compelling reason to bother to do this.)    The main declaration needed is the mallinfo struct that is returned   (by-copy) by mallinfo().  The SVID/XPG malloinfo struct contains a   bunch of fields that are not even meaningful in this version of   malloc.  These fields are are instead filled by mallinfo() with   other numbers that might be of interest.    HAVE_USR_INCLUDE_MALLOC_H should be set if you have a   /usr/include/malloc.h file that includes a declaration of struct   mallinfo.  If so, it is included; else an SVID2/XPG2 compliant   version is declared below.  These must be precisely the same for   mallinfo() to work.  The original SVID version of this struct,   defined on most systems with mallinfo, declares all fields as   ints. But some others define as unsigned long. If your system   defines the fields using a type of different width than listed here,   you must #include your system version and #define   HAVE_USR_INCLUDE_MALLOC_H. */
comment|/* #define HAVE_USR_INCLUDE_MALLOC_H */
ifdef|#
directive|ifdef
name|HAVE_USR_INCLUDE_MALLOC_H
include|#
directive|include
file|"/usr/include/malloc.h"
endif|#
directive|endif
comment|/* ---------- description of public routines ------------ */
comment|/*   malloc(size_t n)   Returns a pointer to a newly allocated chunk of at least n bytes, or null   if no space is available. Additionally, on failure, errno is   set to ENOMEM on ANSI C systems.    If n is zero, malloc returns a minumum-sized chunk. (The minimum   size is 16 bytes on most 32bit systems, and 24 or 32 bytes on 64bit   systems.)  On most systems, size_t is an unsigned type, so calls   with negative arguments are interpreted as requests for huge amounts   of space, which will often fail. The maximum supported value of n   differs across systems, but is in all cases less than the maximum   representable value of a size_t. */
if|#
directive|if
name|__STD_C
name|Void_t
modifier|*
name|public_mALLOc
parameter_list|(
name|cvmx_arena_list_t
name|arena_list
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
else|#
directive|else
name|Void_t
modifier|*
name|public_mALLOc
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   free(Void_t* p)   Releases the chunk of memory pointed to by p, that had been previously   allocated using malloc or a related routine such as realloc.   It has no effect if p is null. It can have arbitrary (i.e., bad!)   effects if p has already been freed.    Unless disabled (using mallopt), freeing very large spaces will   when possible, automatically trigger operations that give   back unused memory to the system, thus reducing program footprint. */
if|#
directive|if
name|__STD_C
name|void
name|public_fREe
parameter_list|(
name|Void_t
modifier|*
parameter_list|)
function_decl|;
else|#
directive|else
name|void
name|public_fREe
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   calloc(size_t n_elements, size_t element_size);   Returns a pointer to n_elements * element_size bytes, with all locations   set to zero. */
if|#
directive|if
name|__STD_C
name|Void_t
modifier|*
name|public_cALLOc
parameter_list|(
name|cvmx_arena_list_t
name|arena_list
parameter_list|,
name|size_t
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
else|#
directive|else
name|Void_t
modifier|*
name|public_cALLOc
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   realloc(Void_t* p, size_t n)   Returns a pointer to a chunk of size n that contains the same data   as does chunk p up to the minimum of (n, p's size) bytes, or null   if no space is available.    The returned pointer may or may not be the same as p. The algorithm   prefers extending p when possible, otherwise it employs the   equivalent of a malloc-copy-free sequence.    If p is null, realloc is equivalent to malloc.    If space is not available, realloc returns null, errno is set (if on   ANSI) and p is NOT freed.    if n is for fewer bytes than already held by p, the newly unused   space is lopped off and freed if possible.  Unless the #define   REALLOC_ZERO_BYTES_FREES is set, realloc with a size argument of   zero (re)allocates a minimum-sized chunk.    Large chunks that were internally obtained via mmap will always   be reallocated using malloc-copy-free sequences unless   the system supports MREMAP (currently only linux).    The old unix realloc convention of allowing the last-free'd chunk   to be used as an argument to realloc is not supported. */
if|#
directive|if
name|__STD_C
name|Void_t
modifier|*
name|public_rEALLOc
parameter_list|(
name|cvmx_arena_list_t
name|arena_list
parameter_list|,
name|Void_t
modifier|*
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
else|#
directive|else
name|Void_t
modifier|*
name|public_rEALLOc
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   memalign(size_t alignment, size_t n);   Returns a pointer to a newly allocated chunk of n bytes, aligned   in accord with the alignment argument.    The alignment argument should be a power of two. If the argument is   not a power of two, the nearest greater power is used.   8-byte alignment is guaranteed by normal malloc calls, so don't   bother calling memalign with an argument of 8 or less.    Overreliance on memalign is a sure way to fragment space. */
if|#
directive|if
name|__STD_C
name|Void_t
modifier|*
name|public_mEMALIGn
parameter_list|(
name|cvmx_arena_list_t
name|arena_list
parameter_list|,
name|size_t
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
else|#
directive|else
name|Void_t
modifier|*
name|public_mEMALIGn
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   valloc(size_t n);   Equivalent to memalign(pagesize, n), where pagesize is the page   size of the system. If the pagesize is unknown, 4096 is used. */
if|#
directive|if
name|__STD_C
name|Void_t
modifier|*
name|public_vALLOc
parameter_list|(
name|size_t
parameter_list|)
function_decl|;
else|#
directive|else
name|Void_t
modifier|*
name|public_vALLOc
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   mallopt(int parameter_number, int parameter_value)   Sets tunable parameters The format is to provide a   (parameter-number, parameter-value) pair.  mallopt then sets the   corresponding parameter to the argument value if it can (i.e., so   long as the value is meaningful), and returns 1 if successful else   0.  SVID/XPG/ANSI defines four standard param numbers for mallopt,   normally defined in malloc.h.  Only one of these (M_MXFAST) is used   in this malloc. The others (M_NLBLKS, M_GRAIN, M_KEEP) don't apply,   so setting them has no effect. But this malloc also supports four   other options in mallopt. See below for details.  Briefly, supported   parameters are as follows (listed defaults are for "typical"   configurations).    Symbol            param #   default    allowed param values   M_MXFAST          1         64         0-80  (0 disables fastbins)   M_TRIM_THRESHOLD -1         128*1024   any   (-1U disables trimming)   M_TOP_PAD        -2         0          any   M_MMAP_THRESHOLD -3         128*1024   any   (or 0 if no MMAP support)   M_MMAP_MAX       -4         65536      any   (0 disables use of mmap) */
if|#
directive|if
name|__STD_C
name|int
name|public_mALLOPt
parameter_list|(
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
else|#
directive|else
name|int
name|public_mALLOPt
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   mallinfo()   Returns (by copy) a struct containing various summary statistics:    arena:     current total non-mmapped bytes allocated from system   ordblks:   the number of free chunks   smblks:    the number of fastbin blocks (i.e., small chunks that                have been freed but not use resused or consolidated)   hblks:     current number of mmapped regions   hblkhd:    total bytes held in mmapped regions   usmblks:   the maximum total allocated space. This will be greater                 than current total if trimming has occurred.   fsmblks:   total bytes held in fastbin blocks   uordblks:  current total allocated space (normal or mmapped)   fordblks:  total free space   keepcost:  the maximum number of bytes that could ideally be released                back to system via malloc_trim. ("ideally" means that                it ignores page restrictions etc.)    Because these fields are ints, but internal bookkeeping may   be kept as longs, the reported values may wrap around zero and   thus be inaccurate. */
if|#
directive|if
name|__STD_C
name|struct
name|mallinfo
name|public_mALLINFo
parameter_list|(
name|void
parameter_list|)
function_decl|;
else|#
directive|else
name|struct
name|mallinfo
name|public_mALLINFo
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   independent_calloc(size_t n_elements, size_t element_size, Void_t* chunks[]);    independent_calloc is similar to calloc, but instead of returning a   single cleared space, it returns an array of pointers to n_elements   independent elements that can hold contents of size elem_size, each   of which starts out cleared, and can be independently freed,   realloc'ed etc. The elements are guaranteed to be adjacently   allocated (this is not guaranteed to occur with multiple callocs or   mallocs), which may also improve cache locality in some   applications.    The "chunks" argument is optional (i.e., may be null, which is   probably the most typical usage). If it is null, the returned array   is itself dynamically allocated and should also be freed when it is   no longer needed. Otherwise, the chunks array must be of at least   n_elements in length. It is filled in with the pointers to the   chunks.    In either case, independent_calloc returns this pointer array, or   null if the allocation failed.  If n_elements is zero and "chunks"   is null, it returns a chunk representing an array with zero elements   (which should be freed if not wanted).    Each element must be individually freed when it is no longer   needed. If you'd like to instead be able to free all at once, you   should instead use regular calloc and assign pointers into this   space to represent elements.  (In this case though, you cannot   independently free elements.)    independent_calloc simplifies and speeds up implementations of many   kinds of pools.  It may also be useful when constructing large data   structures that initially have a fixed number of fixed-sized nodes,   but the number is not known at compile time, and some of the nodes   may later need to be freed. For example:    struct Node { int item; struct Node* next; };    struct Node* build_list() {     struct Node** pool;     int n = read_number_of_nodes_needed();     if (n<= 0) return 0;     pool = (struct Node**)(independent_calloc(n, sizeof(struct Node), 0);     if (pool == 0) die();     // organize into a linked list...     struct Node* first = pool[0];     for (i = 0; i< n-1; ++i)       pool[i]->next = pool[i+1];     free(pool);     // Can now free the array (or not, if it is needed later)     return first;   } */
if|#
directive|if
name|__STD_C
name|Void_t
modifier|*
modifier|*
name|public_iCALLOc
parameter_list|(
name|size_t
parameter_list|,
name|size_t
parameter_list|,
name|Void_t
modifier|*
modifier|*
parameter_list|)
function_decl|;
else|#
directive|else
name|Void_t
modifier|*
modifier|*
name|public_iCALLOc
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   independent_comalloc(size_t n_elements, size_t sizes[], Void_t* chunks[]);    independent_comalloc allocates, all at once, a set of n_elements   chunks with sizes indicated in the "sizes" array.    It returns   an array of pointers to these elements, each of which can be   independently freed, realloc'ed etc. The elements are guaranteed to   be adjacently allocated (this is not guaranteed to occur with   multiple callocs or mallocs), which may also improve cache locality   in some applications.    The "chunks" argument is optional (i.e., may be null). If it is null   the returned array is itself dynamically allocated and should also   be freed when it is no longer needed. Otherwise, the chunks array   must be of at least n_elements in length. It is filled in with the   pointers to the chunks.    In either case, independent_comalloc returns this pointer array, or   null if the allocation failed.  If n_elements is zero and chunks is   null, it returns a chunk representing an array with zero elements   (which should be freed if not wanted).    Each element must be individually freed when it is no longer   needed. If you'd like to instead be able to free all at once, you   should instead use a single regular malloc, and assign pointers at   particular offsets in the aggregate space. (In this case though, you   cannot independently free elements.)    independent_comallac differs from independent_calloc in that each   element may have a different size, and also that it does not   automatically clear elements.    independent_comalloc can be used to speed up allocation in cases   where several structs or objects must always be allocated at the   same time.  For example:    struct Head { ... }   struct Foot { ... }    void send_message(char* msg) {     int msglen = strlen(msg);     size_t sizes[3] = { sizeof(struct Head), msglen, sizeof(struct Foot) };     void* chunks[3];     if (independent_comalloc(3, sizes, chunks) == 0)       die();     struct Head* head = (struct Head*)(chunks[0]);     char*        body = (char*)(chunks[1]);     struct Foot* foot = (struct Foot*)(chunks[2]);     // ...   }    In general though, independent_comalloc is worth using only for   larger values of n_elements. For small values, you probably won't   detect enough difference from series of malloc calls to bother.    Overuse of independent_comalloc can increase overall memory usage,   since it cannot reuse existing noncontiguous small chunks that   might be available for some of the elements. */
if|#
directive|if
name|__STD_C
name|Void_t
modifier|*
modifier|*
name|public_iCOMALLOc
parameter_list|(
name|size_t
parameter_list|,
name|size_t
modifier|*
parameter_list|,
name|Void_t
modifier|*
modifier|*
parameter_list|)
function_decl|;
else|#
directive|else
name|Void_t
modifier|*
modifier|*
name|public_iCOMALLOc
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   pvalloc(size_t n);   Equivalent to valloc(minimum-page-that-holds(n)), that is,   round up n to nearest pagesize.  */
if|#
directive|if
name|__STD_C
name|Void_t
modifier|*
name|public_pVALLOc
parameter_list|(
name|size_t
parameter_list|)
function_decl|;
else|#
directive|else
name|Void_t
modifier|*
name|public_pVALLOc
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   cfree(Void_t* p);   Equivalent to free(p).    cfree is needed/defined on some systems that pair it with calloc,   for odd historical reasons (such as: cfree is used in example   code in the first edition of K&R). */
if|#
directive|if
name|__STD_C
name|void
name|public_cFREe
parameter_list|(
name|Void_t
modifier|*
parameter_list|)
function_decl|;
else|#
directive|else
name|void
name|public_cFREe
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   malloc_trim(size_t pad);    If possible, gives memory back to the system (via negative   arguments to sbrk) if there is unused memory at the `high' end of   the malloc pool. You can call this after freeing large blocks of   memory to potentially reduce the system-level memory requirements   of a program. However, it cannot guarantee to reduce memory. Under   some allocation patterns, some large free blocks of memory will be   locked between two used chunks, so they cannot be given back to   the system.    The `pad' argument to malloc_trim represents the amount of free   trailing space to leave untrimmed. If this argument is zero,   only the minimum amount of memory to maintain internal data   structures will be left (one page or less). Non-zero arguments   can be supplied to maintain enough trailing space to service   future expected allocations without having to re-obtain memory   from the system.    Malloc_trim returns 1 if it actually released any memory, else 0.   On systems that do not support "negative sbrks", it will always   rreturn 0. */
if|#
directive|if
name|__STD_C
name|int
name|public_mTRIm
parameter_list|(
name|size_t
parameter_list|)
function_decl|;
else|#
directive|else
name|int
name|public_mTRIm
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   malloc_usable_size(Void_t* p);    Returns the number of bytes you can actually use in   an allocated chunk, which may be more than you requested (although   often not) due to alignment and minimum size constraints.   You can use this many bytes without worrying about   overwriting other allocated objects. This is not a particularly great   programming practice. malloc_usable_size can be more useful in   debugging and assertions, for example:    p = malloc(n);   assert(malloc_usable_size(p)>= 256);  */
if|#
directive|if
name|__STD_C
name|size_t
name|public_mUSABLe
parameter_list|(
name|Void_t
modifier|*
parameter_list|)
function_decl|;
else|#
directive|else
name|size_t
name|public_mUSABLe
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   malloc_stats();   Prints on stderr the amount of space obtained from the system (both   via sbrk and mmap), the maximum amount (which may be more than   current if malloc_trim and/or munmap got called), and the current   number of bytes allocated via malloc (or realloc, etc) but not yet   freed. Note that this is the number of bytes allocated, not the   number requested. It will be larger than the number requested   because of alignment and bookkeeping overhead. Because it includes   alignment wastage as being in use, this figure may be greater than   zero even when no user-level chunks are allocated.    The reported current and maximum system memory can be inaccurate if   a program makes other calls to system memory allocation functions   (normally sbrk) outside of malloc.    malloc_stats prints only the most commonly interesting statistics.   More information can be obtained by calling mallinfo.  */
if|#
directive|if
name|__STD_C
name|void
name|public_mSTATs
parameter_list|(
name|void
parameter_list|)
function_decl|;
else|#
directive|else
name|void
name|public_mSTATs
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   malloc_get_state(void);    Returns the state of all malloc variables in an opaque data   structure. */
if|#
directive|if
name|__STD_C
name|Void_t
modifier|*
name|public_gET_STATe
parameter_list|(
name|void
parameter_list|)
function_decl|;
else|#
directive|else
name|Void_t
modifier|*
name|public_gET_STATe
parameter_list|()
function_decl|;
endif|#
directive|endif
comment|/*   malloc_set_state(Void_t* state);    Restore the state of all malloc variables from data obtained with   malloc_get_state(). */
if|#
directive|if
name|__STD_C
name|int
name|public_sET_STATe
parameter_list|(
name|Void_t
modifier|*
parameter_list|)
function_decl|;
else|#
directive|else
name|int
name|public_sET_STATe
parameter_list|()
function_decl|;
endif|#
directive|endif
ifdef|#
directive|ifdef
name|_LIBC
comment|/*   posix_memalign(void **memptr, size_t alignment, size_t size);    POSIX wrapper like memalign(), checking for validity of size. */
name|int
name|__posix_memalign
parameter_list|(
name|void
modifier|*
modifier|*
parameter_list|,
name|size_t
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
endif|#
directive|endif
comment|/* mallopt tuning options */
comment|/*   M_MXFAST is the maximum request size used for "fastbins", special bins   that hold returned chunks without consolidating their spaces. This   enables future requests for chunks of the same size to be handled   very quickly, but can increase fragmentation, and thus increase the   overall memory footprint of a program.    This malloc manages fastbins very conservatively yet still   efficiently, so fragmentation is rarely a problem for values less   than or equal to the default.  The maximum supported value of MXFAST   is 80. You wouldn't want it any higher than this anyway.  Fastbins   are designed especially for use with many small structs, objects or   strings -- the default handles structs/objects/arrays with sizes up   to 8 4byte fields, or small strings representing words, tokens,   etc. Using fastbins for larger objects normally worsens   fragmentation without improving speed.    M_MXFAST is set in REQUEST size units. It is internally used in   chunksize units, which adds padding and alignment.  You can reduce   M_MXFAST to 0 to disable all use of fastbins.  This causes the malloc   algorithm to be a closer approximation of fifo-best-fit in all cases,   not just for larger requests, but will generally cause it to be   slower. */
comment|/* M_MXFAST is a standard SVID/XPG tuning option, usually listed in malloc.h */
ifndef|#
directive|ifndef
name|M_MXFAST
define|#
directive|define
name|M_MXFAST
value|1
endif|#
directive|endif
ifndef|#
directive|ifndef
name|DEFAULT_MXFAST
define|#
directive|define
name|DEFAULT_MXFAST
value|64
endif|#
directive|endif
comment|/*   M_TRIM_THRESHOLD is the maximum amount of unused top-most memory   to keep before releasing via malloc_trim in free().    Automatic trimming is mainly useful in long-lived programs.   Because trimming via sbrk can be slow on some systems, and can   sometimes be wasteful (in cases where programs immediately   afterward allocate more large chunks) the value should be high   enough so that your overall system performance would improve by   releasing this much memory.    The trim threshold and the mmap control parameters (see below)   can be traded off with one another. Trimming and mmapping are   two different ways of releasing unused memory back to the   system. Between these two, it is often possible to keep   system-level demands of a long-lived program down to a bare   minimum. For example, in one test suite of sessions measuring   the XF86 X server on Linux, using a trim threshold of 128K and a   mmap threshold of 192K led to near-minimal long term resource   consumption.    If you are using this malloc in a long-lived program, it should   pay to experiment with these values.  As a rough guide, you   might set to a value close to the average size of a process   (program) running on your system.  Releasing this much memory   would allow such a process to run in memory.  Generally, it's   worth it to tune for trimming rather tham memory mapping when a   program undergoes phases where several large chunks are   allocated and released in ways that can reuse each other's   storage, perhaps mixed with phases where there are no such   chunks at all.  And in well-behaved long-lived programs,   controlling release of large blocks via trimming versus mapping   is usually faster.    However, in most programs, these parameters serve mainly as   protection against the system-level effects of carrying around   massive amounts of unneeded memory. Since frequent calls to   sbrk, mmap, and munmap otherwise degrade performance, the default   parameters are set to relatively high values that serve only as   safeguards.    The trim value It must be greater than page size to have any useful   effect.  To disable trimming completely, you can set to   (unsigned long)(-1)    Trim settings interact with fastbin (MXFAST) settings: Unless   TRIM_FASTBINS is defined, automatic trimming never takes place upon   freeing a chunk with size less than or equal to MXFAST. Trimming is   instead delayed until subsequent freeing of larger chunks. However,   you can still force an attempted trim by calling malloc_trim.    Also, trimming is not generally possible in cases where   the main arena is obtained via mmap.    Note that the trick some people use of mallocing a huge space and   then freeing it at program startup, in an attempt to reserve system   memory, doesn't have the intended effect under automatic trimming,   since that memory will immediately be returned to the system. */
define|#
directive|define
name|M_TRIM_THRESHOLD
value|-1
ifndef|#
directive|ifndef
name|DEFAULT_TRIM_THRESHOLD
define|#
directive|define
name|DEFAULT_TRIM_THRESHOLD
value|(128 * 1024)
endif|#
directive|endif
comment|/*   M_TOP_PAD is the amount of extra `padding' space to allocate or   retain whenever sbrk is called. It is used in two ways internally:    * When sbrk is called to extend the top of the arena to satisfy   a new malloc request, this much padding is added to the sbrk   request.    * When malloc_trim is called automatically from free(),   it is used as the `pad' argument.    In both cases, the actual amount of padding is rounded   so that the end of the arena is always a system page boundary.    The main reason for using padding is to avoid calling sbrk so   often. Having even a small pad greatly reduces the likelihood   that nearly every malloc request during program start-up (or   after trimming) will invoke sbrk, which needlessly wastes   time.    Automatic rounding-up to page-size units is normally sufficient   to avoid measurable overhead, so the default is 0.  However, in   systems where sbrk is relatively slow, it can pay to increase   this value, at the expense of carrying around more memory than   the program needs. */
define|#
directive|define
name|M_TOP_PAD
value|-2
ifndef|#
directive|ifndef
name|DEFAULT_TOP_PAD
define|#
directive|define
name|DEFAULT_TOP_PAD
value|(0)
endif|#
directive|endif
comment|/*   M_MMAP_THRESHOLD is the request size threshold for using mmap()   to service a request. Requests of at least this size that cannot   be allocated using already-existing space will be serviced via mmap.   (If enough normal freed space already exists it is used instead.)    Using mmap segregates relatively large chunks of memory so that   they can be individually obtained and released from the host   system. A request serviced through mmap is never reused by any   other request (at least not directly; the system may just so   happen to remap successive requests to the same locations).    Segregating space in this way has the benefits that:     1. Mmapped space can ALWAYS be individually released back       to the system, which helps keep the system level memory       demands of a long-lived program low.    2. Mapped memory can never become `locked' between       other chunks, as can happen with normally allocated chunks, which       means that even trimming via malloc_trim would not release them.    3. On some systems with "holes" in address spaces, mmap can obtain       memory that sbrk cannot.    However, it has the disadvantages that:     1. The space cannot be reclaimed, consolidated, and then       used to service later requests, as happens with normal chunks.    2. It can lead to more wastage because of mmap page alignment       requirements    3. It causes malloc performance to be more dependent on host       system memory management support routines which may vary in       implementation quality and may impose arbitrary       limitations. Generally, servicing a request via normal       malloc steps is faster than going through a system's mmap.    The advantages of mmap nearly always outweigh disadvantages for   "large" chunks, but the value of "large" varies across systems.  The   default is an empirically derived value that works well in most   systems. */
define|#
directive|define
name|M_MMAP_THRESHOLD
value|-3
ifndef|#
directive|ifndef
name|DEFAULT_MMAP_THRESHOLD
define|#
directive|define
name|DEFAULT_MMAP_THRESHOLD
value|(128 * 1024)
endif|#
directive|endif
comment|/*   M_MMAP_MAX is the maximum number of requests to simultaneously   service using mmap. This parameter exists because   some systems have a limited number of internal tables for   use by mmap, and using more than a few of them may degrade   performance.    The default is set to a value that serves only as a safeguard.   Setting to 0 disables use of mmap for servicing large requests.  If   HAVE_MMAP is not set, the default value is 0, and attempts to set it   to non-zero values in mallopt will fail. */
define|#
directive|define
name|M_MMAP_MAX
value|-4
ifndef|#
directive|ifndef
name|DEFAULT_MMAP_MAX
if|#
directive|if
name|HAVE_MMAP
define|#
directive|define
name|DEFAULT_MMAP_MAX
value|(65536)
else|#
directive|else
define|#
directive|define
name|DEFAULT_MMAP_MAX
value|(0)
endif|#
directive|endif
endif|#
directive|endif
ifdef|#
directive|ifdef
name|__cplusplus
block|}
end_extern

begin_empty_stmt
empty_stmt|;
end_empty_stmt

begin_comment
comment|/* end of extern "C" */
end_comment

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|<cvmx-spinlock.h>
end_include

begin_include
include|#
directive|include
file|"malloc.h"
end_include

begin_include
include|#
directive|include
file|"thread-m.h"
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DEBUG_PRINTS
end_ifdef

begin_define
define|#
directive|define
name|debug_printf
value|printf
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|debug_printf
parameter_list|(
name|format
parameter_list|,
name|args
modifier|...
parameter_list|)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifndef
ifndef|#
directive|ifndef
name|BOUNDED_N
end_ifndef

begin_define
define|#
directive|define
name|BOUNDED_N
parameter_list|(
name|ptr
parameter_list|,
name|sz
parameter_list|)
value|(ptr)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifndef
ifndef|#
directive|ifndef
name|RETURN_ADDRESS
end_ifndef

begin_define
define|#
directive|define
name|RETURN_ADDRESS
parameter_list|(
name|X_
parameter_list|)
value|(NULL)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* On some platforms we can compile internal, not exported functions better.    Let the environment provide a macro and define it to be empty if it    is not available.  */
end_comment

begin_ifndef
ifndef|#
directive|ifndef
name|internal_function
end_ifndef

begin_define
define|#
directive|define
name|internal_function
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* Forward declarations.  */
end_comment

begin_struct_decl
struct_decl|struct
name|malloc_chunk
struct_decl|;
end_struct_decl

begin_typedef
typedef|typedef
name|struct
name|malloc_chunk
modifier|*
name|mchunkptr
typedef|;
end_typedef

begin_comment
comment|/* Internal routines.  */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|_int_malloc
parameter_list|(
name|mstate
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|_int_free
parameter_list|(
name|mstate
parameter_list|,
name|Void_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|_int_realloc
parameter_list|(
name|mstate
parameter_list|,
name|Void_t
modifier|*
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|_int_memalign
parameter_list|(
name|mstate
parameter_list|,
name|size_t
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|_int_valloc
parameter_list|(
name|mstate
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|_int_pvalloc
parameter_list|(
name|mstate
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|cALLOc
parameter_list|(
name|cvmx_arena_list_t
name|arena_list
parameter_list|,
name|size_t
parameter_list|,
name|size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
modifier|*
name|_int_icalloc
parameter_list|(
name|mstate
parameter_list|,
name|size_t
parameter_list|,
name|size_t
parameter_list|,
name|Void_t
modifier|*
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
modifier|*
name|_int_icomalloc
parameter_list|(
name|mstate
parameter_list|,
name|size_t
parameter_list|,
name|size_t
modifier|*
parameter_list|,
name|Void_t
modifier|*
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|mTRIm
parameter_list|(
name|size_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|size_t
name|mUSABLe
parameter_list|(
name|Void_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mSTATs
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|mALLOPt
parameter_list|(
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|mallinfo
name|mALLINFo
parameter_list|(
name|mstate
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|internal_function
name|mem2mem_check
parameter_list|(
name|Void_t
modifier|*
name|p
parameter_list|,
name|size_t
name|sz
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|internal_function
name|top_check
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|internal_function
name|munmap_chunk
parameter_list|(
name|mchunkptr
name|p
parameter_list|)
function_decl|;
end_function_decl

begin_if
if|#
directive|if
name|HAVE_MREMAP
end_if

begin_function_decl
specifier|static
name|mchunkptr
name|internal_function
name|mremap_chunk
parameter_list|(
name|mchunkptr
name|p
parameter_list|,
name|size_t
name|new_size
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|malloc_check
parameter_list|(
name|size_t
name|sz
parameter_list|,
specifier|const
name|Void_t
modifier|*
name|caller
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|free_check
parameter_list|(
name|Void_t
modifier|*
name|mem
parameter_list|,
specifier|const
name|Void_t
modifier|*
name|caller
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|realloc_check
parameter_list|(
name|Void_t
modifier|*
name|oldmem
parameter_list|,
name|size_t
name|bytes
parameter_list|,
specifier|const
name|Void_t
modifier|*
name|caller
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|memalign_check
parameter_list|(
name|size_t
name|alignment
parameter_list|,
name|size_t
name|bytes
parameter_list|,
specifier|const
name|Void_t
modifier|*
name|caller
parameter_list|)
function_decl|;
end_function_decl

begin_ifndef
ifndef|#
directive|ifndef
name|NO_THREADS
end_ifndef

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|malloc_starter
parameter_list|(
name|size_t
name|sz
parameter_list|,
specifier|const
name|Void_t
modifier|*
name|caller
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|free_starter
parameter_list|(
name|Void_t
modifier|*
name|mem
parameter_list|,
specifier|const
name|Void_t
modifier|*
name|caller
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|malloc_atfork
parameter_list|(
name|size_t
name|sz
parameter_list|,
specifier|const
name|Void_t
modifier|*
name|caller
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|free_atfork
parameter_list|(
name|Void_t
modifier|*
name|mem
parameter_list|,
specifier|const
name|Void_t
modifier|*
name|caller
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_else
else|#
directive|else
end_else

begin_function_decl
name|Void_t
modifier|*
name|_int_malloc
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
name|void
name|_int_free
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
name|Void_t
modifier|*
name|_int_realloc
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
name|Void_t
modifier|*
name|_int_memalign
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
name|Void_t
modifier|*
name|_int_valloc
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
name|Void_t
modifier|*
name|_int_pvalloc
parameter_list|()
function_decl|;
end_function_decl

begin_comment
comment|/*static Void_t*  cALLOc();*/
end_comment

begin_function_decl
specifier|static
name|Void_t
modifier|*
modifier|*
name|_int_icalloc
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
modifier|*
name|_int_icomalloc
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|mTRIm
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|size_t
name|mUSABLe
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|mSTATs
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|mALLOPt
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|mallinfo
name|mALLINFo
parameter_list|()
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* ------------- Optional versions of memcopy ---------------- */
end_comment

begin_if
if|#
directive|if
name|USE_MEMCPY
end_if

begin_comment
comment|/*   Note: memcpy is ONLY invoked with non-overlapping regions,   so the (usually slower) memmove is not needed. */
end_comment

begin_define
define|#
directive|define
name|MALLOC_COPY
parameter_list|(
name|dest
parameter_list|,
name|src
parameter_list|,
name|nbytes
parameter_list|)
value|memcpy(dest, src, nbytes)
end_define

begin_define
define|#
directive|define
name|MALLOC_ZERO
parameter_list|(
name|dest
parameter_list|,
name|nbytes
parameter_list|)
value|memset(dest, 0,   nbytes)
end_define

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* !USE_MEMCPY */
end_comment

begin_comment
comment|/* Use Duff's device for good zeroing/copying performance. */
end_comment

begin_define
define|#
directive|define
name|MALLOC_ZERO
parameter_list|(
name|charp
parameter_list|,
name|nbytes
parameter_list|)
define|\
value|do {                                                                          \   INTERNAL_SIZE_T* mzp = (INTERNAL_SIZE_T*)(charp);                           \   unsigned long mctmp = (nbytes)/sizeof(INTERNAL_SIZE_T);                     \   long mcn;                                                                   \   if (mctmp< 8) mcn = 0; else { mcn = (mctmp-1)/8; mctmp %= 8; }             \   switch (mctmp) {                                                            \     case 0: for(;;) { *mzp++ = 0;                                             \     case 7:           *mzp++ = 0;                                             \     case 6:           *mzp++ = 0;                                             \     case 5:           *mzp++ = 0;                                             \     case 4:           *mzp++ = 0;                                             \     case 3:           *mzp++ = 0;                                             \     case 2:           *mzp++ = 0;                                             \     case 1:           *mzp++ = 0; if(mcn<= 0) break; mcn--; }                \   }                                                                           \ } while(0)
end_define

begin_define
define|#
directive|define
name|MALLOC_COPY
parameter_list|(
name|dest
parameter_list|,
name|src
parameter_list|,
name|nbytes
parameter_list|)
define|\
value|do {                                                                          \   INTERNAL_SIZE_T* mcsrc = (INTERNAL_SIZE_T*) src;                            \   INTERNAL_SIZE_T* mcdst = (INTERNAL_SIZE_T*) dest;                           \   unsigned long mctmp = (nbytes)/sizeof(INTERNAL_SIZE_T);                     \   long mcn;                                                                   \   if (mctmp< 8) mcn = 0; else { mcn = (mctmp-1)/8; mctmp %= 8; }             \   switch (mctmp) {                                                            \     case 0: for(;;) { *mcdst++ = *mcsrc++;                                    \     case 7:           *mcdst++ = *mcsrc++;                                    \     case 6:           *mcdst++ = *mcsrc++;                                    \     case 5:           *mcdst++ = *mcsrc++;                                    \     case 4:           *mcdst++ = *mcsrc++;                                    \     case 3:           *mcdst++ = *mcsrc++;                                    \     case 2:           *mcdst++ = *mcsrc++;                                    \     case 1:           *mcdst++ = *mcsrc++; if(mcn<= 0) break; mcn--; }       \   }                                                                           \ } while(0)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* ------------------ MMAP support ------------------  */
end_comment

begin_if
if|#
directive|if
name|HAVE_MMAP
end_if

begin_include
include|#
directive|include
file|<fcntl.h>
end_include

begin_ifndef
ifndef|#
directive|ifndef
name|LACKS_SYS_MMAN_H
end_ifndef

begin_include
include|#
directive|include
file|<sys/mman.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAP_ANONYMOUS
argument_list|)
operator|&&
name|defined
argument_list|(
name|MAP_ANON
argument_list|)
end_if

begin_define
define|#
directive|define
name|MAP_ANONYMOUS
value|MAP_ANON
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|MAP_FAILED
argument_list|)
end_if

begin_define
define|#
directive|define
name|MAP_FAILED
value|((char*)-1)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifndef
ifndef|#
directive|ifndef
name|MAP_NORESERVE
end_ifndef

begin_ifdef
ifdef|#
directive|ifdef
name|MAP_AUTORESRV
end_ifdef

begin_define
define|#
directive|define
name|MAP_NORESERVE
value|MAP_AUTORESRV
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|MAP_NORESERVE
value|0
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*    Nearly all versions of mmap support MAP_ANONYMOUS,    so the following is unlikely to be needed, but is    supplied just in case. */
end_comment

begin_ifndef
ifndef|#
directive|ifndef
name|MAP_ANONYMOUS
end_ifndef

begin_decl_stmt
specifier|static
name|int
name|dev_zero_fd
init|=
operator|-
literal|1
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Cached file descriptor for /dev/zero. */
end_comment

begin_define
define|#
directive|define
name|MMAP
parameter_list|(
name|addr
parameter_list|,
name|size
parameter_list|,
name|prot
parameter_list|,
name|flags
parameter_list|)
value|((dev_zero_fd< 0) ? \  (dev_zero_fd = open("/dev/zero", O_RDWR), \   mmap((addr), (size), (prot), (flags), dev_zero_fd, 0)) : \    mmap((addr), (size), (prot), (flags), dev_zero_fd, 0))
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|MMAP
parameter_list|(
name|addr
parameter_list|,
name|size
parameter_list|,
name|prot
parameter_list|,
name|flags
parameter_list|)
define|\
value|(mmap((addr), (size), (prot), (flags)|MAP_ANONYMOUS, -1, 0))
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* HAVE_MMAP */
end_comment

begin_comment
comment|/*   -----------------------  Chunk representations ----------------------- */
end_comment

begin_comment
comment|/*   This struct declaration is misleading (but accurate and necessary).   It declares a "view" into memory allowing access to necessary   fields at known offsets from a given base. See explanation below. */
end_comment

begin_struct
struct|struct
name|malloc_chunk
block|{
name|INTERNAL_SIZE_T
name|prev_size
decl_stmt|;
comment|/* Size of previous chunk (if free).  */
name|INTERNAL_SIZE_T
name|size
decl_stmt|;
comment|/* Size in bytes, including overhead. */
name|mstate
name|arena_ptr
decl_stmt|;
comment|/* ptr to arena chunk belongs to */
name|struct
name|malloc_chunk
modifier|*
name|fd
decl_stmt|;
comment|/* double links -- used only if free. */
name|struct
name|malloc_chunk
modifier|*
name|bk
decl_stmt|;
block|}
struct|;
end_struct

begin_comment
comment|/*    malloc_chunk details:      (The following includes lightly edited explanations by Colin Plumb.)      Chunks of memory are maintained using a `boundary tag' method as     described in e.g., Knuth or Standish.  (See the paper by Paul     Wilson ftp://ftp.cs.utexas.edu/pub/garbage/allocsrv.ps for a     survey of such techniques.)  Sizes of free chunks are stored both     in the front of each chunk and at the end.  This makes     consolidating fragmented chunks into bigger chunks very fast.  The     size fields also hold bits representing whether chunks are free or     in use.      An allocated chunk looks like this:       chunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+             |             Size of previous chunk, if allocated            | |             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+             |             Size of chunk, in bytes                         |P|       mem-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+             |             User data starts here...                          .             .                                                               .             .             (malloc_usable_space() bytes)                     .             .                                                               | nextchunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+             |             Size of chunk                                     |             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+       Where "chunk" is the front of the chunk for the purpose of most of     the malloc code, but "mem" is the pointer that is returned to the     user.  "Nextchunk" is the beginning of the next contiguous chunk.      Chunks always begin on even word boundries, so the mem portion     (which is returned to the user) is also on an even word boundary, and     thus at least double-word aligned.      Free chunks are stored in circular doubly-linked lists, and look like this:      chunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+             |             Size of previous chunk                            |             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+     `head:' |             Size of chunk, in bytes                         |P|       mem-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+             |             Forward pointer to next chunk in list             |             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+             |             Back pointer to previous chunk in list            |             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+             |             Unused space (may be 0 bytes long)                .             .                                                               .             .                                                               | nextchunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+     `foot:' |             Size of chunk, in bytes                           |             +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+      The P (PREV_INUSE) bit, stored in the unused low-order bit of the     chunk size (which is always a multiple of two words), is an in-use     bit for the *previous* chunk.  If that bit is *clear*, then the     word before the current chunk size contains the previous chunk     size, and can be used to find the front of the previous chunk.     The very first chunk allocated always has this bit set,     preventing access to non-existent (or non-owned) memory. If     prev_inuse is set for any given chunk, then you CANNOT determine     the size of the previous chunk, and might even get a memory     addressing fault when trying to do so.      Note that the `foot' of the current chunk is actually represented     as the prev_size of the NEXT chunk. This makes it easier to     deal with alignments etc but can be very confusing when trying     to extend or adapt this code.      The two exceptions to all this are       1. The special chunk `top' doesn't bother using the         trailing size field since there is no next contiguous chunk         that would have to index off it. After initialization, `top'         is forced to always exist.  If it would become less than         MINSIZE bytes long, it is replenished.       2. Chunks allocated via mmap, which have the second-lowest-order         bit (IS_MMAPPED) set in their size fields.  Because they are         allocated one-by-one, each must contain its own trailing size field.  */
end_comment

begin_comment
comment|/*   ---------- Size and alignment checks and conversions ---------- */
end_comment

begin_comment
comment|/* conversion from malloc headers to user pointers, and back */
end_comment

begin_comment
comment|/* Added size for pointer to make room for arena_ptr */
end_comment

begin_define
define|#
directive|define
name|chunk2mem
parameter_list|(
name|p
parameter_list|)
value|((Void_t*)((char*)(p) + 2*SIZE_SZ + sizeof(void *)))
end_define

begin_define
define|#
directive|define
name|mem2chunk
parameter_list|(
name|mem
parameter_list|)
value|((mchunkptr)((char*)(mem) - 2*SIZE_SZ - sizeof(void *)))
end_define

begin_comment
comment|/* The smallest possible chunk */
end_comment

begin_define
define|#
directive|define
name|MIN_CHUNK_SIZE
value|(sizeof(struct malloc_chunk))
end_define

begin_comment
comment|/* The smallest size we can malloc is an aligned minimal chunk */
end_comment

begin_define
define|#
directive|define
name|MINSIZE
define|\
value|(unsigned long)(((MIN_CHUNK_SIZE+MALLOC_ALIGN_MASK)& ~MALLOC_ALIGN_MASK))
end_define

begin_comment
comment|/* Check if m has acceptable alignment */
end_comment

begin_define
define|#
directive|define
name|aligned_OK
parameter_list|(
name|m
parameter_list|)
value|(((unsigned long)((m))& (MALLOC_ALIGN_MASK)) == 0)
end_define

begin_comment
comment|/*    Check if a request is so large that it would wrap around zero when    padded and aligned. To simplify some other code, the bound is made    low enough so that adding MINSIZE will also not wrap around zero. */
end_comment

begin_define
define|#
directive|define
name|REQUEST_OUT_OF_RANGE
parameter_list|(
name|req
parameter_list|)
define|\
value|((unsigned long)(req)>=                                        \    (unsigned long)(INTERNAL_SIZE_T)(-2 * MINSIZE))
end_define

begin_comment
comment|/* pad request bytes into a usable size -- internal version */
end_comment

begin_comment
comment|/* prev_size field of next chunk is overwritten with data ** when in use.  NOTE - last SIZE_SZ of arena must be left ** unused for last chunk to use */
end_comment

begin_comment
comment|/* Added sizeof(void *) to make room for arena_ptr */
end_comment

begin_define
define|#
directive|define
name|request2size
parameter_list|(
name|req
parameter_list|)
define|\
value|(((req) + sizeof(void *) + SIZE_SZ + MALLOC_ALIGN_MASK< MINSIZE)  ?             \    MINSIZE :                                                      \    ((req) + sizeof(void *) + SIZE_SZ + MALLOC_ALIGN_MASK)& ~MALLOC_ALIGN_MASK)
end_define

begin_comment
comment|/*  Same, except also perform argument check */
end_comment

begin_define
define|#
directive|define
name|checked_request2size
parameter_list|(
name|req
parameter_list|,
name|sz
parameter_list|)
define|\
value|if (REQUEST_OUT_OF_RANGE(req)) {                                \     MALLOC_FAILURE_ACTION;                                        \     return 0;                                                     \   }                                                               \   (sz) = request2size(req);
end_define

begin_comment
comment|/*   --------------- Physical chunk operations --------------- */
end_comment

begin_comment
comment|/* size field is or'ed with PREV_INUSE when previous adjacent chunk in use */
end_comment

begin_define
define|#
directive|define
name|PREV_INUSE
value|0x1
end_define

begin_comment
comment|/* extract inuse bit of previous chunk */
end_comment

begin_define
define|#
directive|define
name|prev_inuse
parameter_list|(
name|p
parameter_list|)
value|((p)->size& PREV_INUSE)
end_define

begin_comment
comment|/* size field is or'ed with IS_MMAPPED if the chunk was obtained with mmap() */
end_comment

begin_define
define|#
directive|define
name|IS_MMAPPED
value|0x2
end_define

begin_comment
comment|/* check for mmap()'ed chunk */
end_comment

begin_define
define|#
directive|define
name|chunk_is_mmapped
parameter_list|(
name|p
parameter_list|)
value|((p)->size& IS_MMAPPED)
end_define

begin_comment
comment|/*   Bits to mask off when extracting size    Note: IS_MMAPPED is intentionally not masked off from size field in   macros for which mmapped chunks should never be seen. This should   cause helpful core dumps to occur if it is tried by accident by   people extending or adapting this malloc. */
end_comment

begin_define
define|#
directive|define
name|SIZE_BITS
value|(PREV_INUSE|IS_MMAPPED)
end_define

begin_comment
comment|/* Get size, ignoring use bits */
end_comment

begin_define
define|#
directive|define
name|chunksize
parameter_list|(
name|p
parameter_list|)
value|((p)->size& ~(SIZE_BITS))
end_define

begin_comment
comment|/* Ptr to next physical malloc_chunk. */
end_comment

begin_define
define|#
directive|define
name|next_chunk
parameter_list|(
name|p
parameter_list|)
value|((mchunkptr)( ((char*)(p)) + ((p)->size& ~SIZE_BITS) ))
end_define

begin_comment
comment|/* Ptr to previous physical malloc_chunk */
end_comment

begin_define
define|#
directive|define
name|prev_chunk
parameter_list|(
name|p
parameter_list|)
value|((mchunkptr)( ((char*)(p)) - ((p)->prev_size) ))
end_define

begin_comment
comment|/* Treat space at ptr + offset as a chunk */
end_comment

begin_define
define|#
directive|define
name|chunk_at_offset
parameter_list|(
name|p
parameter_list|,
name|s
parameter_list|)
value|((mchunkptr)(((char*)(p)) + (s)))
end_define

begin_comment
comment|/* extract p's inuse bit */
end_comment

begin_define
define|#
directive|define
name|inuse
parameter_list|(
name|p
parameter_list|)
define|\
value|((((mchunkptr)(((char*)(p))+((p)->size& ~SIZE_BITS)))->size)& PREV_INUSE)
end_define

begin_comment
comment|/* set/clear chunk as being inuse without otherwise disturbing */
end_comment

begin_define
define|#
directive|define
name|set_inuse
parameter_list|(
name|p
parameter_list|)
define|\
value|((mchunkptr)(((char*)(p)) + ((p)->size& ~SIZE_BITS)))->size |= PREV_INUSE
end_define

begin_define
define|#
directive|define
name|clear_inuse
parameter_list|(
name|p
parameter_list|)
define|\
value|((mchunkptr)(((char*)(p)) + ((p)->size& ~SIZE_BITS)))->size&= ~(PREV_INUSE)
end_define

begin_comment
comment|/* check/set/clear inuse bits in known places */
end_comment

begin_define
define|#
directive|define
name|inuse_bit_at_offset
parameter_list|(
name|p
parameter_list|,
name|s
parameter_list|)
define|\
value|(((mchunkptr)(((char*)(p)) + (s)))->size& PREV_INUSE)
end_define

begin_define
define|#
directive|define
name|set_inuse_bit_at_offset
parameter_list|(
name|p
parameter_list|,
name|s
parameter_list|)
define|\
value|(((mchunkptr)(((char*)(p)) + (s)))->size |= PREV_INUSE)
end_define

begin_define
define|#
directive|define
name|clear_inuse_bit_at_offset
parameter_list|(
name|p
parameter_list|,
name|s
parameter_list|)
define|\
value|(((mchunkptr)(((char*)(p)) + (s)))->size&= ~(PREV_INUSE))
end_define

begin_comment
comment|/* Set size at head, without disturbing its use bit */
end_comment

begin_define
define|#
directive|define
name|set_head_size
parameter_list|(
name|p
parameter_list|,
name|s
parameter_list|)
value|((p)->size = (((p)->size& SIZE_BITS) | (s)))
end_define

begin_comment
comment|/* Set size/use field */
end_comment

begin_define
define|#
directive|define
name|set_head
parameter_list|(
name|p
parameter_list|,
name|s
parameter_list|)
value|((p)->size = (s))
end_define

begin_comment
comment|/* Set size at footer (only when chunk is not in use) */
end_comment

begin_define
define|#
directive|define
name|set_foot
parameter_list|(
name|p
parameter_list|,
name|s
parameter_list|)
value|(((mchunkptr)((char*)(p) + (s)))->prev_size = (s))
end_define

begin_comment
comment|/*   -------------------- Internal data structures --------------------     All internal state is held in an instance of malloc_state defined    below. There are no other static variables, except in two optional    cases:    * If USE_MALLOC_LOCK is defined, the mALLOC_MUTEx declared above.    * If HAVE_MMAP is true, but mmap doesn't support      MAP_ANONYMOUS, a dummy file descriptor for mmap.     Beware of lots of tricks that minimize the total bookkeeping space    requirements. The result is a little over 1K bytes (for 4byte    pointers and size_t.) */
end_comment

begin_comment
comment|/*   Bins      An array of bin headers for free chunks. Each bin is doubly     linked.  The bins are approximately proportionally (log) spaced.     There are a lot of these bins (128). This may look excessive, but     works very well in practice.  Most bins hold sizes that are     unusual as malloc request sizes, but are more usual for fragments     and consolidated sets of chunks, which is what these bins hold, so     they can be found quickly.  All procedures maintain the invariant     that no consolidated chunk physically borders another one, so each     chunk in a list is known to be preceeded and followed by either     inuse chunks or the ends of memory.      Chunks in bins are kept in size order, with ties going to the     approximately least recently used chunk. Ordering isn't needed     for the small bins, which all contain the same-sized chunks, but     facilitates best-fit allocation for larger chunks. These lists     are just sequential. Keeping them in order almost never requires     enough traversal to warrant using fancier ordered data     structures.      Chunks of the same size are linked with the most     recently freed at the front, and allocations are taken from the     back.  This results in LRU (FIFO) allocation order, which tends     to give each chunk an equal opportunity to be consolidated with     adjacent freed chunks, resulting in larger free chunks and less     fragmentation.      To simplify use in double-linked lists, each bin header acts     as a malloc_chunk. This avoids special-casing for headers.     But to conserve space and improve locality, we allocate     only the fd/bk pointers of bins, and then use repositioning tricks     to treat these as the fields of a malloc_chunk*. */
end_comment

begin_typedef
typedef|typedef
name|struct
name|malloc_chunk
modifier|*
name|mbinptr
typedef|;
end_typedef

begin_comment
comment|/* addressing -- note that bin_at(0) does not exist */
end_comment

begin_define
define|#
directive|define
name|bin_at
parameter_list|(
name|m
parameter_list|,
name|i
parameter_list|)
value|((mbinptr)((char*)&((m)->bins[(i)<<1]) - (SIZE_SZ<<1)))
end_define

begin_comment
comment|/* analog of ++bin */
end_comment

begin_define
define|#
directive|define
name|next_bin
parameter_list|(
name|b
parameter_list|)
value|((mbinptr)((char*)(b) + (sizeof(mchunkptr)<<1)))
end_define

begin_comment
comment|/* Reminders about list directionality within bins */
end_comment

begin_define
define|#
directive|define
name|first
parameter_list|(
name|b
parameter_list|)
value|((b)->fd)
end_define

begin_define
define|#
directive|define
name|last
parameter_list|(
name|b
parameter_list|)
value|((b)->bk)
end_define

begin_comment
comment|/* Take a chunk off a bin list */
end_comment

begin_define
define|#
directive|define
name|unlink
parameter_list|(
name|P
parameter_list|,
name|BK
parameter_list|,
name|FD
parameter_list|)
value|{                                            \   FD = P->fd;                                                          \   BK = P->bk;                                                          \   FD->bk = BK;                                                         \   BK->fd = FD;                                                         \ }
end_define

begin_comment
comment|/*   Indexing      Bins for sizes< 512 bytes contain chunks of all the same size, spaced     8 bytes apart. Larger bins are approximately logarithmically spaced:      64 bins of size       8     32 bins of size      64     16 bins of size     512      8 bins of size    4096      4 bins of size   32768      2 bins of size  262144      1 bin  of size what's left      There is actually a little bit of slop in the numbers in bin_index     for the sake of speed. This makes no difference elsewhere.      The bins top out around 1MB because we expect to service large     requests via mmap. */
end_comment

begin_define
define|#
directive|define
name|NBINS
value|128
end_define

begin_define
define|#
directive|define
name|NSMALLBINS
value|64
end_define

begin_define
define|#
directive|define
name|SMALLBIN_WIDTH
value|8
end_define

begin_define
define|#
directive|define
name|MIN_LARGE_SIZE
value|512
end_define

begin_define
define|#
directive|define
name|in_smallbin_range
parameter_list|(
name|sz
parameter_list|)
define|\
value|((unsigned long)(sz)< (unsigned long)MIN_LARGE_SIZE)
end_define

begin_define
define|#
directive|define
name|smallbin_index
parameter_list|(
name|sz
parameter_list|)
value|(((unsigned)(sz))>> 3)
end_define

begin_define
define|#
directive|define
name|largebin_index
parameter_list|(
name|sz
parameter_list|)
define|\
value|(((((unsigned long)(sz))>>  6)<= 32)?  56 + (((unsigned long)(sz))>>  6): \  ((((unsigned long)(sz))>>  9)<= 20)?  91 + (((unsigned long)(sz))>>  9): \  ((((unsigned long)(sz))>> 12)<= 10)? 110 + (((unsigned long)(sz))>> 12): \  ((((unsigned long)(sz))>> 15)<=  4)? 119 + (((unsigned long)(sz))>> 15): \  ((((unsigned long)(sz))>> 18)<=  2)? 124 + (((unsigned long)(sz))>> 18): \                                         126)
end_define

begin_define
define|#
directive|define
name|bin_index
parameter_list|(
name|sz
parameter_list|)
define|\
value|((in_smallbin_range(sz)) ? smallbin_index(sz) : largebin_index(sz))
end_define

begin_comment
comment|/*   FIRST_SORTED_BIN_SIZE is the chunk size corresponding to the   first bin that is maintained in sorted order. This must   be the smallest size corresponding to a given bin.    Normally, this should be MIN_LARGE_SIZE. But you can weaken   best fit guarantees to sometimes speed up malloc by increasing value.   Doing this means that malloc may choose a chunk that is    non-best-fitting by up to the width of the bin.    Some useful cutoff values:       512 - all bins sorted      2560 - leaves bins<=     64 bytes wide unsorted       12288 - leaves bins<=    512 bytes wide unsorted     65536 - leaves bins<=   4096 bytes wide unsorted    262144 - leaves bins<=  32768 bytes wide unsorted        -1 - no bins sorted (not recommended!) */
end_comment

begin_define
define|#
directive|define
name|FIRST_SORTED_BIN_SIZE
value|MIN_LARGE_SIZE
end_define

begin_comment
comment|/* #define FIRST_SORTED_BIN_SIZE 65536 */
end_comment

begin_comment
comment|/*   Unsorted chunks      All remainders from chunk splits, as well as all returned chunks,     are first placed in the "unsorted" bin. They are then placed     in regular bins after malloc gives them ONE chance to be used before     binning. So, basically, the unsorted_chunks list acts as a queue,     with chunks being placed on it in free (and malloc_consolidate),     and taken off (to be either used or placed in bins) in malloc.      The NON_MAIN_ARENA flag is never set for unsorted chunks, so it     does not have to be taken into account in size comparisons. */
end_comment

begin_comment
comment|/* The otherwise unindexable 1-bin is used to hold unsorted chunks. */
end_comment

begin_define
define|#
directive|define
name|unsorted_chunks
parameter_list|(
name|M
parameter_list|)
value|(bin_at(M, 1))
end_define

begin_comment
comment|/*   Top      The top-most available chunk (i.e., the one bordering the end of     available memory) is treated specially. It is never included in     any bin, is used only if no other chunk is available, and is     released back to the system if it is very large (see     M_TRIM_THRESHOLD).  Because top initially     points to its own bin with initial zero size, thus forcing     extension on the first malloc request, we avoid having any special     code in malloc to check whether it even exists yet. But we still     need to do so when getting memory from system, so we make     initial_top treat the bin as a legal but unusable chunk during the     interval between initialization and the first call to     sYSMALLOc. (This is somewhat delicate, since it relies on     the 2 preceding words to be zero during this interval as well.) */
end_comment

begin_comment
comment|/* Conveniently, the unsorted bin can be used as dummy top on first call */
end_comment

begin_define
define|#
directive|define
name|initial_top
parameter_list|(
name|M
parameter_list|)
value|(unsorted_chunks(M))
end_define

begin_comment
comment|/*   Binmap      To help compensate for the large number of bins, a one-level index     structure is used for bin-by-bin searching.  `binmap' is a     bitvector recording whether bins are definitely empty so they can     be skipped over during during traversals.  The bits are NOT always     cleared as soon as bins are empty, but instead only     when they are noticed to be empty during traversal in malloc. */
end_comment

begin_comment
comment|/* Conservatively use 32 bits per map word, even if on 64bit system */
end_comment

begin_define
define|#
directive|define
name|BINMAPSHIFT
value|5
end_define

begin_define
define|#
directive|define
name|BITSPERMAP
value|(1U<< BINMAPSHIFT)
end_define

begin_define
define|#
directive|define
name|BINMAPSIZE
value|(NBINS / BITSPERMAP)
end_define

begin_define
define|#
directive|define
name|idx2block
parameter_list|(
name|i
parameter_list|)
value|((i)>> BINMAPSHIFT)
end_define

begin_define
define|#
directive|define
name|idx2bit
parameter_list|(
name|i
parameter_list|)
value|((1U<< ((i)& ((1U<< BINMAPSHIFT)-1))))
end_define

begin_define
define|#
directive|define
name|mark_bin
parameter_list|(
name|m
parameter_list|,
name|i
parameter_list|)
value|((m)->binmap[idx2block(i)] |=  idx2bit(i))
end_define

begin_define
define|#
directive|define
name|unmark_bin
parameter_list|(
name|m
parameter_list|,
name|i
parameter_list|)
value|((m)->binmap[idx2block(i)]&= ~(idx2bit(i)))
end_define

begin_define
define|#
directive|define
name|get_binmap
parameter_list|(
name|m
parameter_list|,
name|i
parameter_list|)
value|((m)->binmap[idx2block(i)]&   idx2bit(i))
end_define

begin_comment
comment|/*   Fastbins      An array of lists holding recently freed small chunks.  Fastbins     are not doubly linked.  It is faster to single-link them, and     since chunks are never removed from the middles of these lists,     double linking is not necessary. Also, unlike regular bins, they     are not even processed in FIFO order (they use faster LIFO) since     ordering doesn't much matter in the transient contexts in which     fastbins are normally used.      Chunks in fastbins keep their inuse bit set, so they cannot     be consolidated with other free chunks. malloc_consolidate     releases all chunks in fastbins and consolidates them with     other free chunks. */
end_comment

begin_typedef
typedef|typedef
name|struct
name|malloc_chunk
modifier|*
name|mfastbinptr
typedef|;
end_typedef

begin_comment
comment|/* offset 2 to use otherwise unindexable first 2 bins */
end_comment

begin_define
define|#
directive|define
name|fastbin_index
parameter_list|(
name|sz
parameter_list|)
value|((int)((((unsigned int)(sz))>> 3) - 2))
end_define

begin_comment
comment|/* The maximum fastbin request size we support */
end_comment

begin_define
define|#
directive|define
name|MAX_FAST_SIZE
value|80
end_define

begin_define
define|#
directive|define
name|NFASTBINS
value|(fastbin_index(request2size(MAX_FAST_SIZE))+1)
end_define

begin_comment
comment|/*   FASTBIN_CONSOLIDATION_THRESHOLD is the size of a chunk in free()   that triggers automatic consolidation of possibly-surrounding   fastbin chunks. This is a heuristic, so the exact value should not   matter too much. It is defined at half the default trim threshold as a   compromise heuristic to only attempt consolidation if it is likely   to lead to trimming. However, it is not dynamically tunable, since   consolidation reduces fragmentation surrounding large chunks even   if trimming is not used. */
end_comment

begin_define
define|#
directive|define
name|FASTBIN_CONSOLIDATION_THRESHOLD
value|(65536UL)
end_define

begin_comment
comment|/*   Since the lowest 2 bits in max_fast don't matter in size comparisons,   they are used as flags. */
end_comment

begin_comment
comment|/*   FASTCHUNKS_BIT held in max_fast indicates that there are probably   some fastbin chunks. It is set true on entering a chunk into any   fastbin, and cleared only in malloc_consolidate.    The truth value is inverted so that have_fastchunks will be true   upon startup (since statics are zero-filled), simplifying   initialization checks. */
end_comment

begin_define
define|#
directive|define
name|FASTCHUNKS_BIT
value|(1U)
end_define

begin_define
define|#
directive|define
name|have_fastchunks
parameter_list|(
name|M
parameter_list|)
value|(((M)->max_fast&  FASTCHUNKS_BIT) == 0)
end_define

begin_define
define|#
directive|define
name|clear_fastchunks
parameter_list|(
name|M
parameter_list|)
value|((M)->max_fast |=  FASTCHUNKS_BIT)
end_define

begin_define
define|#
directive|define
name|set_fastchunks
parameter_list|(
name|M
parameter_list|)
value|((M)->max_fast&= ~FASTCHUNKS_BIT)
end_define

begin_comment
comment|/*   NONCONTIGUOUS_BIT indicates that MORECORE does not return contiguous   regions.  Otherwise, contiguity is exploited in merging together,   when possible, results from consecutive MORECORE calls.    The initial value comes from MORECORE_CONTIGUOUS, but is   changed dynamically if mmap is ever used as an sbrk substitute. */
end_comment

begin_define
define|#
directive|define
name|NONCONTIGUOUS_BIT
value|(2U)
end_define

begin_define
define|#
directive|define
name|contiguous
parameter_list|(
name|M
parameter_list|)
value|(((M)->max_fast&  NONCONTIGUOUS_BIT) == 0)
end_define

begin_define
define|#
directive|define
name|noncontiguous
parameter_list|(
name|M
parameter_list|)
value|(((M)->max_fast&  NONCONTIGUOUS_BIT) != 0)
end_define

begin_define
define|#
directive|define
name|set_noncontiguous
parameter_list|(
name|M
parameter_list|)
value|((M)->max_fast |=  NONCONTIGUOUS_BIT)
end_define

begin_define
define|#
directive|define
name|set_contiguous
parameter_list|(
name|M
parameter_list|)
value|((M)->max_fast&= ~NONCONTIGUOUS_BIT)
end_define

begin_comment
comment|/*    Set value of max_fast.    Use impossibly small value if 0.    Precondition: there are no existing fastbin chunks.    Setting the value clears fastchunk bit but preserves noncontiguous bit. */
end_comment

begin_define
define|#
directive|define
name|set_max_fast
parameter_list|(
name|M
parameter_list|,
name|s
parameter_list|)
define|\
value|(M)->max_fast = (((s) == 0)? SMALLBIN_WIDTH: request2size(s)) | \   FASTCHUNKS_BIT | \   ((M)->max_fast&  NONCONTIGUOUS_BIT)
end_define

begin_comment
comment|/*    ----------- Internal state representation and initialization ----------- */
end_comment

begin_struct
struct|struct
name|malloc_state
block|{
comment|/* Serialize access.  */
name|mutex_t
name|mutex
decl_stmt|;
comment|/* Statistics for locking.  Only used if THREAD_STATS is defined.  */
name|long
name|stat_lock_direct
decl_stmt|,
name|stat_lock_loop
decl_stmt|,
name|stat_lock_wait
decl_stmt|;
name|long
name|pad0_
index|[
literal|1
index|]
decl_stmt|;
comment|/* try to give the mutex its own cacheline */
comment|/* The maximum chunk size to be eligible for fastbin */
name|INTERNAL_SIZE_T
name|max_fast
decl_stmt|;
comment|/* low 2 bits used as flags */
comment|/* Fastbins */
name|mfastbinptr
name|fastbins
index|[
name|NFASTBINS
index|]
decl_stmt|;
comment|/* Base of the topmost chunk -- not otherwise kept in a bin */
name|mchunkptr
name|top
decl_stmt|;
comment|/* The remainder from the most recent split of a small request */
name|mchunkptr
name|last_remainder
decl_stmt|;
comment|/* Normal bins packed as described above */
name|mchunkptr
name|bins
index|[
name|NBINS
operator|*
literal|2
index|]
decl_stmt|;
comment|/* Bitmap of bins */
name|unsigned
name|int
name|binmap
index|[
name|BINMAPSIZE
index|]
decl_stmt|;
comment|/* Linked list */
name|struct
name|malloc_state
modifier|*
name|next
decl_stmt|;
comment|/* Memory allocated from the system in this arena.  */
name|INTERNAL_SIZE_T
name|system_mem
decl_stmt|;
name|INTERNAL_SIZE_T
name|max_system_mem
decl_stmt|;
block|}
struct|;
end_struct

begin_struct
struct|struct
name|malloc_par
block|{
comment|/* Tunable parameters */
name|unsigned
name|long
name|trim_threshold
decl_stmt|;
name|INTERNAL_SIZE_T
name|top_pad
decl_stmt|;
name|INTERNAL_SIZE_T
name|mmap_threshold
decl_stmt|;
comment|/* Memory map support */
name|int
name|n_mmaps
decl_stmt|;
name|int
name|n_mmaps_max
decl_stmt|;
name|int
name|max_n_mmaps
decl_stmt|;
comment|/* Cache malloc_getpagesize */
name|unsigned
name|int
name|pagesize
decl_stmt|;
comment|/* Statistics */
name|INTERNAL_SIZE_T
name|mmapped_mem
decl_stmt|;
comment|/*INTERNAL_SIZE_T  sbrked_mem;*/
comment|/*INTERNAL_SIZE_T  max_sbrked_mem;*/
name|INTERNAL_SIZE_T
name|max_mmapped_mem
decl_stmt|;
name|INTERNAL_SIZE_T
name|max_total_mem
decl_stmt|;
comment|/* only kept for NO_THREADS */
comment|/* First address handed out by MORECORE/sbrk.  */
name|char
modifier|*
name|sbrk_base
decl_stmt|;
block|}
struct|;
end_struct

begin_comment
comment|/* There are several instances of this struct ("arenas") in this    malloc.  If you are adapting this malloc in a way that does NOT use    a static or mmapped malloc_state, you MUST explicitly zero-fill it    before using. This malloc relies on the property that malloc_state    is initialized to all zeroes (as is true of C statics).  */
end_comment

begin_comment
comment|/*   Initialize a malloc_state struct.    This is called only from within malloc_consolidate, which needs   be called in the same contexts anyway.  It is never called directly   outside of malloc_consolidate because some optimizing compilers try   to inline it at all call points, which turns out not to be an   optimization at all. (Inlining it in malloc_consolidate is fine though.) */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function
specifier|static
name|void
name|malloc_init_state
parameter_list|(
name|mstate
name|av
parameter_list|)
else|#
directive|else
function|static void malloc_init_state
parameter_list|(
name|av
parameter_list|)
name|mstate
name|av
decl_stmt|;
endif|#
directive|endif
block|{
name|int
name|i
decl_stmt|;
name|mbinptr
name|bin
decl_stmt|;
comment|/* Establish circular links for normal bins */
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|NBINS
condition|;
operator|++
name|i
control|)
block|{
name|bin
operator|=
name|bin_at
argument_list|(
name|av
argument_list|,
name|i
argument_list|)
expr_stmt|;
name|bin
operator|->
name|fd
operator|=
name|bin
operator|->
name|bk
operator|=
name|bin
expr_stmt|;
block|}
name|set_noncontiguous
argument_list|(
name|av
argument_list|)
expr_stmt|;
name|set_max_fast
argument_list|(
name|av
argument_list|,
name|DEFAULT_MXFAST
argument_list|)
expr_stmt|;
name|av
operator|->
name|top
operator|=
name|initial_top
argument_list|(
name|av
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*    Other internal utilities operating on mstates */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|sYSMALLOc
parameter_list|(
name|INTERNAL_SIZE_T
parameter_list|,
name|mstate
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|malloc_consolidate
parameter_list|(
name|mstate
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|//static Void_t** iALLOc(mstate, size_t, size_t*, int, Void_t**);
end_comment

begin_else
else|#
directive|else
end_else

begin_function_decl
specifier|static
name|Void_t
modifier|*
name|sYSMALLOc
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|malloc_consolidate
parameter_list|()
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|Void_t
modifier|*
modifier|*
name|iALLOc
parameter_list|()
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* ------------------- Support for multiple arenas -------------------- */
end_comment

begin_include
include|#
directive|include
file|"arena.c"
end_include

begin_comment
comment|/*   Debugging support    These routines make a number of assertions about the states   of data structures that should be true at all times. If any   are not true, it's very likely that a user program has somehow   trashed memory. (It's also possible that there is a coding error   in malloc. In which case, please report it!) */
end_comment

begin_if
if|#
directive|if
operator|!
name|MALLOC_DEBUG
end_if

begin_define
define|#
directive|define
name|check_chunk
parameter_list|(
name|A
parameter_list|,
name|P
parameter_list|)
end_define

begin_define
define|#
directive|define
name|check_free_chunk
parameter_list|(
name|A
parameter_list|,
name|P
parameter_list|)
end_define

begin_define
define|#
directive|define
name|check_inuse_chunk
parameter_list|(
name|A
parameter_list|,
name|P
parameter_list|)
end_define

begin_define
define|#
directive|define
name|check_remalloced_chunk
parameter_list|(
name|A
parameter_list|,
name|P
parameter_list|,
name|N
parameter_list|)
end_define

begin_define
define|#
directive|define
name|check_malloced_chunk
parameter_list|(
name|A
parameter_list|,
name|P
parameter_list|,
name|N
parameter_list|)
end_define

begin_define
define|#
directive|define
name|check_malloc_state
parameter_list|(
name|A
parameter_list|)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|check_chunk
parameter_list|(
name|A
parameter_list|,
name|P
parameter_list|)
value|do_check_chunk(A,P)
end_define

begin_define
define|#
directive|define
name|check_free_chunk
parameter_list|(
name|A
parameter_list|,
name|P
parameter_list|)
value|do_check_free_chunk(A,P)
end_define

begin_define
define|#
directive|define
name|check_inuse_chunk
parameter_list|(
name|A
parameter_list|,
name|P
parameter_list|)
value|do_check_inuse_chunk(A,P)
end_define

begin_define
define|#
directive|define
name|check_remalloced_chunk
parameter_list|(
name|A
parameter_list|,
name|P
parameter_list|,
name|N
parameter_list|)
value|do_check_remalloced_chunk(A,P,N)
end_define

begin_define
define|#
directive|define
name|check_malloced_chunk
parameter_list|(
name|A
parameter_list|,
name|P
parameter_list|,
name|N
parameter_list|)
value|do_check_malloced_chunk(A,P,N)
end_define

begin_define
define|#
directive|define
name|check_malloc_state
parameter_list|(
name|A
parameter_list|)
value|do_check_malloc_state(A)
end_define

begin_comment
comment|/*   Properties of all chunks */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function
specifier|static
name|void
name|do_check_chunk
parameter_list|(
name|mstate
name|av
parameter_list|,
name|mchunkptr
name|p
parameter_list|)
else|#
directive|else
function|static void do_check_chunk
parameter_list|(
name|av
parameter_list|,
name|p
parameter_list|)
name|mstate
name|av
decl_stmt|;
name|mchunkptr
name|p
decl_stmt|;
endif|#
directive|endif
block|{
name|unsigned
name|long
name|sz
init|=
name|chunksize
argument_list|(
name|p
argument_list|)
decl_stmt|;
comment|/* min and max possible addresses assuming contiguous allocation */
name|char
modifier|*
name|max_address
init|=
operator|(
name|char
operator|*
operator|)
operator|(
name|av
operator|->
name|top
operator|)
operator|+
name|chunksize
argument_list|(
name|av
operator|->
name|top
argument_list|)
decl_stmt|;
name|char
modifier|*
name|min_address
init|=
name|max_address
operator|-
name|av
operator|->
name|system_mem
decl_stmt|;
if|if
condition|(
operator|!
name|chunk_is_mmapped
argument_list|(
name|p
argument_list|)
condition|)
block|{
comment|/* Has legal address ... */
if|if
condition|(
name|p
operator|!=
name|av
operator|->
name|top
condition|)
block|{
if|if
condition|(
name|contiguous
argument_list|(
name|av
argument_list|)
condition|)
block|{
name|assert
argument_list|(
operator|(
operator|(
name|char
operator|*
operator|)
name|p
operator|)
operator|>=
name|min_address
argument_list|)
expr_stmt|;
name|assert
argument_list|(
operator|(
operator|(
name|char
operator|*
operator|)
name|p
operator|+
name|sz
operator|)
operator|<=
operator|(
operator|(
name|char
operator|*
operator|)
operator|(
name|av
operator|->
name|top
operator|)
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|/* top size is always at least MINSIZE */
name|assert
argument_list|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|sz
argument_list|)
operator|>=
name|MINSIZE
argument_list|)
expr_stmt|;
comment|/* top predecessor always marked inuse */
name|assert
argument_list|(
name|prev_inuse
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|#
directive|if
name|HAVE_MMAP
comment|/* address is outside main heap  */
if|if
condition|(
name|contiguous
argument_list|(
name|av
argument_list|)
operator|&&
name|av
operator|->
name|top
operator|!=
name|initial_top
argument_list|(
name|av
argument_list|)
condition|)
block|{
name|assert
argument_list|(
operator|(
operator|(
name|char
operator|*
operator|)
name|p
operator|)
operator|<
name|min_address
operator|||
operator|(
operator|(
name|char
operator|*
operator|)
name|p
operator|)
operator|>
name|max_address
argument_list|)
expr_stmt|;
block|}
comment|/* chunk is page-aligned */
name|assert
argument_list|(
operator|(
operator|(
name|p
operator|->
name|prev_size
operator|+
name|sz
operator|)
operator|&
operator|(
name|mp_
operator|.
name|pagesize
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
argument_list|)
expr_stmt|;
comment|/* mem is aligned */
name|assert
argument_list|(
name|aligned_OK
argument_list|(
name|chunk2mem
argument_list|(
name|p
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
else|#
directive|else
comment|/* force an appropriate assert violation if debug set */
name|assert
argument_list|(
operator|!
name|chunk_is_mmapped
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
block|}
end_function

begin_comment
comment|/*   Properties of free chunks */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function
specifier|static
name|void
name|do_check_free_chunk
parameter_list|(
name|mstate
name|av
parameter_list|,
name|mchunkptr
name|p
parameter_list|)
else|#
directive|else
function|static void do_check_free_chunk
parameter_list|(
name|av
parameter_list|,
name|p
parameter_list|)
name|mstate
name|av
decl_stmt|;
name|mchunkptr
name|p
decl_stmt|;
endif|#
directive|endif
block|{
name|INTERNAL_SIZE_T
name|sz
init|=
name|p
operator|->
name|size
operator|&
operator|~
operator|(
name|PREV_INUSE
operator|)
decl_stmt|;
name|mchunkptr
name|next
init|=
name|chunk_at_offset
argument_list|(
name|p
argument_list|,
name|sz
argument_list|)
decl_stmt|;
name|do_check_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|)
expr_stmt|;
comment|/* Chunk must claim to be free ... */
name|assert
argument_list|(
operator|!
name|inuse
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
name|assert
argument_list|(
operator|!
name|chunk_is_mmapped
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Unless a special marker, must have OK fields */
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|sz
argument_list|)
operator|>=
name|MINSIZE
condition|)
block|{
name|assert
argument_list|(
operator|(
name|sz
operator|&
name|MALLOC_ALIGN_MASK
operator|)
operator|==
literal|0
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|aligned_OK
argument_list|(
name|chunk2mem
argument_list|(
name|p
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
comment|/* ... matching footer field */
name|assert
argument_list|(
name|next
operator|->
name|prev_size
operator|==
name|sz
argument_list|)
expr_stmt|;
comment|/* ... and is fully consolidated */
name|assert
argument_list|(
name|prev_inuse
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|next
operator|==
name|av
operator|->
name|top
operator|||
name|inuse
argument_list|(
name|next
argument_list|)
argument_list|)
expr_stmt|;
comment|/* ... and has minimally sane links */
name|assert
argument_list|(
name|p
operator|->
name|fd
operator|->
name|bk
operator|==
name|p
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|p
operator|->
name|bk
operator|->
name|fd
operator|==
name|p
argument_list|)
expr_stmt|;
block|}
else|else
comment|/* markers are always of size SIZE_SZ */
name|assert
argument_list|(
name|sz
operator|==
name|SIZE_SZ
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*   Properties of inuse chunks */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function
specifier|static
name|void
name|do_check_inuse_chunk
parameter_list|(
name|mstate
name|av
parameter_list|,
name|mchunkptr
name|p
parameter_list|)
else|#
directive|else
function|static void do_check_inuse_chunk
parameter_list|(
name|av
parameter_list|,
name|p
parameter_list|)
name|mstate
name|av
decl_stmt|;
name|mchunkptr
name|p
decl_stmt|;
endif|#
directive|endif
block|{
name|mchunkptr
name|next
decl_stmt|;
name|do_check_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|av
operator|==
name|arena_for_chunk
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|chunk_is_mmapped
argument_list|(
name|p
argument_list|)
condition|)
return|return;
comment|/* mmapped chunks have no next/prev */
comment|/* Check whether it claims to be in use ... */
name|assert
argument_list|(
name|inuse
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
name|next
operator|=
name|next_chunk
argument_list|(
name|p
argument_list|)
expr_stmt|;
comment|/* ... and is surrounded by OK chunks.     Since more things can be checked with free chunks than inuse ones,     if an inuse chunk borders them and debug is on, it's worth doing them.   */
if|if
condition|(
operator|!
name|prev_inuse
argument_list|(
name|p
argument_list|)
condition|)
block|{
comment|/* Note that we cannot even look at prev unless it is not inuse */
name|mchunkptr
name|prv
init|=
name|prev_chunk
argument_list|(
name|p
argument_list|)
decl_stmt|;
name|assert
argument_list|(
name|next_chunk
argument_list|(
name|prv
argument_list|)
operator|==
name|p
argument_list|)
expr_stmt|;
name|do_check_free_chunk
argument_list|(
name|av
argument_list|,
name|prv
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|next
operator|==
name|av
operator|->
name|top
condition|)
block|{
name|assert
argument_list|(
name|prev_inuse
argument_list|(
name|next
argument_list|)
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|chunksize
argument_list|(
name|next
argument_list|)
operator|>=
name|MINSIZE
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|inuse
argument_list|(
name|next
argument_list|)
condition|)
name|do_check_free_chunk
argument_list|(
name|av
argument_list|,
name|next
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*   Properties of chunks recycled from fastbins */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function
specifier|static
name|void
name|do_check_remalloced_chunk
parameter_list|(
name|mstate
name|av
parameter_list|,
name|mchunkptr
name|p
parameter_list|,
name|INTERNAL_SIZE_T
name|s
parameter_list|)
else|#
directive|else
function|static void do_check_remalloced_chunk
parameter_list|(
name|av
parameter_list|,
name|p
parameter_list|,
name|s
parameter_list|)
name|mstate
name|av
decl_stmt|;
name|mchunkptr
name|p
decl_stmt|;
name|INTERNAL_SIZE_T
name|s
decl_stmt|;
endif|#
directive|endif
block|{
name|INTERNAL_SIZE_T
name|sz
init|=
name|p
operator|->
name|size
operator|&
operator|~
operator|(
name|PREV_INUSE
operator|)
decl_stmt|;
if|if
condition|(
operator|!
name|chunk_is_mmapped
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|assert
argument_list|(
name|av
operator|==
name|arena_for_chunk
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|do_check_inuse_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|)
expr_stmt|;
comment|/* Legal size ... */
name|assert
argument_list|(
operator|(
name|sz
operator|&
name|MALLOC_ALIGN_MASK
operator|)
operator|==
literal|0
argument_list|)
expr_stmt|;
name|assert
argument_list|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|sz
argument_list|)
operator|>=
name|MINSIZE
argument_list|)
expr_stmt|;
comment|/* ... and alignment */
name|assert
argument_list|(
name|aligned_OK
argument_list|(
name|chunk2mem
argument_list|(
name|p
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
comment|/* chunk is less than MINSIZE more than request */
name|assert
argument_list|(
call|(
name|long
call|)
argument_list|(
name|sz
argument_list|)
operator|-
call|(
name|long
call|)
argument_list|(
name|s
argument_list|)
operator|>=
literal|0
argument_list|)
expr_stmt|;
name|assert
argument_list|(
call|(
name|long
call|)
argument_list|(
name|sz
argument_list|)
operator|-
call|(
name|long
call|)
argument_list|(
name|s
operator|+
name|MINSIZE
argument_list|)
operator|<
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*   Properties of nonrecycled chunks at the point they are malloced */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function
specifier|static
name|void
name|do_check_malloced_chunk
parameter_list|(
name|mstate
name|av
parameter_list|,
name|mchunkptr
name|p
parameter_list|,
name|INTERNAL_SIZE_T
name|s
parameter_list|)
else|#
directive|else
function|static void do_check_malloced_chunk
parameter_list|(
name|av
parameter_list|,
name|p
parameter_list|,
name|s
parameter_list|)
name|mstate
name|av
decl_stmt|;
name|mchunkptr
name|p
decl_stmt|;
name|INTERNAL_SIZE_T
name|s
decl_stmt|;
endif|#
directive|endif
block|{
comment|/* same as recycled case ... */
name|do_check_remalloced_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|,
name|s
argument_list|)
expr_stmt|;
comment|/*     ... plus,  must obey implementation invariant that prev_inuse is     always true of any allocated chunk; i.e., that each allocated     chunk borders either a previously allocated and still in-use     chunk, or the base of its memory arena. This is ensured     by making all allocations from the the `lowest' part of any found     chunk.  This does not necessarily hold however for chunks     recycled via fastbins.   */
name|assert
argument_list|(
name|prev_inuse
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*   Properties of malloc_state.    This may be useful for debugging malloc, as well as detecting user   programmer errors that somehow write into malloc_state.    If you are extending or experimenting with this malloc, you can   probably figure out how to hack this routine to print out or   display chunk addresses, sizes, bins, and other instrumentation. */
end_comment

begin_function
specifier|static
name|void
name|do_check_malloc_state
parameter_list|(
name|mstate
name|av
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|mchunkptr
name|p
decl_stmt|;
name|mchunkptr
name|q
decl_stmt|;
name|mbinptr
name|b
decl_stmt|;
name|unsigned
name|int
name|binbit
decl_stmt|;
name|int
name|empty
decl_stmt|;
name|unsigned
name|int
name|idx
decl_stmt|;
name|INTERNAL_SIZE_T
name|size
decl_stmt|;
name|unsigned
name|long
name|total
init|=
literal|0
decl_stmt|;
name|int
name|max_fast_bin
decl_stmt|;
comment|/* internal size_t must be no wider than pointer type */
name|assert
argument_list|(
sizeof|sizeof
argument_list|(
name|INTERNAL_SIZE_T
argument_list|)
operator|<=
sizeof|sizeof
argument_list|(
name|char
operator|*
argument_list|)
argument_list|)
expr_stmt|;
comment|/* alignment is a power of 2 */
name|assert
argument_list|(
operator|(
name|MALLOC_ALIGNMENT
operator|&
operator|(
name|MALLOC_ALIGNMENT
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
argument_list|)
expr_stmt|;
comment|/* cannot run remaining checks until fully initialized */
if|if
condition|(
name|av
operator|->
name|top
operator|==
literal|0
operator|||
name|av
operator|->
name|top
operator|==
name|initial_top
argument_list|(
name|av
argument_list|)
condition|)
return|return;
comment|/* properties of fastbins */
comment|/* max_fast is in allowed range */
name|assert
argument_list|(
operator|(
name|av
operator|->
name|max_fast
operator|&
operator|~
literal|1
operator|)
operator|<=
name|request2size
argument_list|(
name|MAX_FAST_SIZE
argument_list|)
argument_list|)
expr_stmt|;
name|max_fast_bin
operator|=
name|fastbin_index
argument_list|(
name|av
operator|->
name|max_fast
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NFASTBINS
condition|;
operator|++
name|i
control|)
block|{
name|p
operator|=
name|av
operator|->
name|fastbins
index|[
name|i
index|]
expr_stmt|;
comment|/* all bins past max_fast are empty */
if|if
condition|(
name|i
operator|>
name|max_fast_bin
condition|)
name|assert
argument_list|(
name|p
operator|==
literal|0
argument_list|)
expr_stmt|;
while|while
condition|(
name|p
operator|!=
literal|0
condition|)
block|{
comment|/* each chunk claims to be inuse */
name|do_check_inuse_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|)
expr_stmt|;
name|total
operator|+=
name|chunksize
argument_list|(
name|p
argument_list|)
expr_stmt|;
comment|/* chunk belongs in this bin */
name|assert
argument_list|(
name|fastbin_index
argument_list|(
name|chunksize
argument_list|(
name|p
argument_list|)
argument_list|)
operator|==
name|i
argument_list|)
expr_stmt|;
name|p
operator|=
name|p
operator|->
name|fd
expr_stmt|;
block|}
block|}
if|if
condition|(
name|total
operator|!=
literal|0
condition|)
name|assert
argument_list|(
name|have_fastchunks
argument_list|(
name|av
argument_list|)
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
operator|!
name|have_fastchunks
argument_list|(
name|av
argument_list|)
condition|)
name|assert
argument_list|(
name|total
operator|==
literal|0
argument_list|)
expr_stmt|;
comment|/* check normal bins */
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|NBINS
condition|;
operator|++
name|i
control|)
block|{
name|b
operator|=
name|bin_at
argument_list|(
name|av
argument_list|,
name|i
argument_list|)
expr_stmt|;
comment|/* binmap is accurate (except for bin 1 == unsorted_chunks) */
if|if
condition|(
name|i
operator|>=
literal|2
condition|)
block|{
name|binbit
operator|=
name|get_binmap
argument_list|(
name|av
argument_list|,
name|i
argument_list|)
expr_stmt|;
name|empty
operator|=
name|last
argument_list|(
name|b
argument_list|)
operator|==
name|b
expr_stmt|;
if|if
condition|(
operator|!
name|binbit
condition|)
name|assert
argument_list|(
name|empty
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
operator|!
name|empty
condition|)
name|assert
argument_list|(
name|binbit
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|p
operator|=
name|last
argument_list|(
name|b
argument_list|)
init|;
name|p
operator|!=
name|b
condition|;
name|p
operator|=
name|p
operator|->
name|bk
control|)
block|{
comment|/* each chunk claims to be free */
name|do_check_free_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|)
expr_stmt|;
name|size
operator|=
name|chunksize
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|total
operator|+=
name|size
expr_stmt|;
if|if
condition|(
name|i
operator|>=
literal|2
condition|)
block|{
comment|/* chunk belongs in bin */
name|idx
operator|=
name|bin_index
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|idx
operator|==
operator|(
name|unsigned
name|int
operator|)
name|i
argument_list|)
expr_stmt|;
comment|/* lists are sorted */
if|if
condition|(
operator|(
name|unsigned
name|long
operator|)
name|size
operator|>=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|FIRST_SORTED_BIN_SIZE
argument_list|)
condition|)
block|{
name|assert
argument_list|(
name|p
operator|->
name|bk
operator|==
name|b
operator|||
operator|(
name|unsigned
name|long
operator|)
name|chunksize
argument_list|(
name|p
operator|->
name|bk
argument_list|)
operator|>=
operator|(
name|unsigned
name|long
operator|)
name|chunksize
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* chunk is followed by a legal chain of inuse chunks */
for|for
control|(
name|q
operator|=
name|next_chunk
argument_list|(
name|p
argument_list|)
init|;
operator|(
name|q
operator|!=
name|av
operator|->
name|top
operator|&&
name|inuse
argument_list|(
name|q
argument_list|)
operator|&&
call|(
name|unsigned
name|long
call|)
argument_list|(
name|chunksize
argument_list|(
name|q
argument_list|)
argument_list|)
operator|>=
name|MINSIZE
operator|)
condition|;
name|q
operator|=
name|next_chunk
argument_list|(
name|q
argument_list|)
control|)
name|do_check_inuse_chunk
argument_list|(
name|av
argument_list|,
name|q
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* top chunk is OK */
name|check_chunk
argument_list|(
name|av
argument_list|,
name|av
operator|->
name|top
argument_list|)
expr_stmt|;
comment|/* sanity checks for statistics */
name|assert
argument_list|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|av
operator|->
name|system_mem
argument_list|)
operator|<=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|av
operator|->
name|max_system_mem
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* ----------- Routines dealing with system allocation -------------- */
end_comment

begin_comment
comment|/* No system allocation routines supported */
end_comment

begin_comment
comment|/*------------------------ Public wrappers. --------------------------------*/
end_comment

begin_undef
undef|#
directive|undef
name|DEBUG_MALLOC
end_undef

begin_function
name|Void_t
modifier|*
name|public_mALLOc
parameter_list|(
name|cvmx_arena_list_t
name|arena_list
parameter_list|,
name|size_t
name|bytes
parameter_list|)
block|{
name|mstate
name|ar_ptr
decl_stmt|,
name|orig_ar_ptr
decl_stmt|;
name|Void_t
modifier|*
name|victim
init|=
name|NULL
decl_stmt|;
specifier|static
name|mstate
name|debug_prev_ar
decl_stmt|;
comment|// debug only!
ifdef|#
directive|ifdef
name|DEBUG_MALLOC
name|int
name|arena_cnt
init|=
literal|0
decl_stmt|;
endif|#
directive|endif
name|ar_ptr
operator|=
name|arena_list
expr_stmt|;
if|if
condition|(
operator|!
name|ar_ptr
condition|)
block|{
return|return
operator|(
name|NULL
operator|)
return|;
block|}
if|if
condition|(
name|debug_prev_ar
operator|!=
name|ar_ptr
condition|)
block|{
name|debug_printf
argument_list|(
literal|"New arena: %p\n"
argument_list|,
name|ar_ptr
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|CVMX_SPINLOCK_DEBUG
name|cvmx_dprintf
argument_list|(
literal|"lock wait count for arena: %p is %ld\n"
argument_list|,
name|ar_ptr
argument_list|,
name|ar_ptr
operator|->
name|mutex
operator|.
name|wait_cnt
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|debug_prev_ar
operator|=
name|ar_ptr
expr_stmt|;
block|}
name|orig_ar_ptr
operator|=
name|ar_ptr
expr_stmt|;
comment|// try to get an arena without contention
do|do
block|{
ifdef|#
directive|ifdef
name|DEBUG_MALLOC
name|arena_cnt
operator|++
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
operator|!
name|mutex_trylock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
condition|)
block|{
comment|// we locked it
name|victim
operator|=
name|_int_malloc
argument_list|(
name|ar_ptr
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|mutex_unlock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
if|if
condition|(
name|victim
condition|)
block|{
break|break;
block|}
block|}
name|ar_ptr
operator|=
name|ar_ptr
operator|->
name|next
expr_stmt|;
block|}
do|while
condition|(
name|ar_ptr
operator|!=
name|orig_ar_ptr
condition|)
do|;
comment|// we couldn't get the memory without contention, so try all
comment|// arenas.  SLOW!
if|if
condition|(
operator|!
name|victim
condition|)
block|{
name|ar_ptr
operator|=
name|orig_ar_ptr
expr_stmt|;
do|do
block|{
ifdef|#
directive|ifdef
name|DEBUG_MALLOC
name|arena_cnt
operator|++
expr_stmt|;
endif|#
directive|endif
name|mutex_lock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
name|victim
operator|=
name|_int_malloc
argument_list|(
name|ar_ptr
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|mutex_unlock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
if|if
condition|(
name|victim
condition|)
block|{
break|break;
block|}
name|ar_ptr
operator|=
name|ar_ptr
operator|->
name|next
expr_stmt|;
block|}
do|while
condition|(
name|ar_ptr
operator|!=
name|orig_ar_ptr
condition|)
do|;
block|}
name|assert
argument_list|(
operator|!
name|victim
operator|||
name|chunk_is_mmapped
argument_list|(
name|mem2chunk
argument_list|(
name|victim
argument_list|)
argument_list|)
operator|||
name|ar_ptr
operator|==
name|arena_for_chunk
argument_list|(
name|mem2chunk
argument_list|(
name|victim
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|DEBUG_MALLOC
if|if
condition|(
operator|!
name|victim
condition|)
block|{
name|cvmx_dprintf
argument_list|(
literal|"Malloc failed: size: %ld, arena_cnt: %d\n"
argument_list|,
name|bytes
argument_list|,
name|arena_cnt
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
name|debug_printf
argument_list|(
literal|"cvmx_malloc(%ld) = %p\n"
argument_list|,
name|bytes
argument_list|,
name|victim
argument_list|)
expr_stmt|;
comment|// remember which arena we last used.....
name|tsd_setspecific
argument_list|(
name|arena_key
argument_list|,
operator|(
name|Void_t
operator|*
operator|)
name|ar_ptr
argument_list|)
expr_stmt|;
return|return
name|victim
return|;
block|}
end_function

begin_function
name|void
name|public_fREe
parameter_list|(
name|Void_t
modifier|*
name|mem
parameter_list|)
block|{
name|mstate
name|ar_ptr
decl_stmt|;
name|mchunkptr
name|p
decl_stmt|;
comment|/* chunk corresponding to mem */
name|debug_printf
argument_list|(
literal|"cvmx_free(%p)\n"
argument_list|,
name|mem
argument_list|)
expr_stmt|;
if|if
condition|(
name|mem
operator|==
literal|0
condition|)
comment|/* free(0) has no effect */
return|return;
name|p
operator|=
name|mem2chunk
argument_list|(
name|mem
argument_list|)
expr_stmt|;
name|ar_ptr
operator|=
name|arena_for_chunk
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|ar_ptr
argument_list|)
expr_stmt|;
if|#
directive|if
name|THREAD_STATS
if|if
condition|(
operator|!
name|mutex_trylock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
condition|)
operator|++
operator|(
name|ar_ptr
operator|->
name|stat_lock_direct
operator|)
expr_stmt|;
else|else
block|{
operator|(
name|void
operator|)
name|mutex_lock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
operator|++
operator|(
name|ar_ptr
operator|->
name|stat_lock_wait
operator|)
expr_stmt|;
block|}
else|#
directive|else
operator|(
name|void
operator|)
name|mutex_lock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|_int_free
argument_list|(
name|ar_ptr
argument_list|,
name|mem
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|mutex_unlock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|Void_t
modifier|*
name|public_rEALLOc
parameter_list|(
name|cvmx_arena_list_t
name|arena_list
parameter_list|,
name|Void_t
modifier|*
name|oldmem
parameter_list|,
name|size_t
name|bytes
parameter_list|)
block|{
name|mstate
name|ar_ptr
decl_stmt|;
name|INTERNAL_SIZE_T
name|nb
decl_stmt|;
comment|/* padded request size */
name|mchunkptr
name|oldp
decl_stmt|;
comment|/* chunk corresponding to oldmem */
name|INTERNAL_SIZE_T
name|oldsize
decl_stmt|;
comment|/* its size */
name|Void_t
modifier|*
name|newp
decl_stmt|;
comment|/* chunk to return */
if|#
directive|if
name|REALLOC_ZERO_BYTES_FREES
if|if
condition|(
name|bytes
operator|==
literal|0
operator|&&
name|oldmem
operator|!=
name|NULL
condition|)
block|{
name|public_fREe
argument_list|(
name|oldmem
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
endif|#
directive|endif
comment|/* realloc of null is supposed to be same as malloc */
if|if
condition|(
name|oldmem
operator|==
literal|0
condition|)
return|return
name|public_mALLOc
argument_list|(
name|arena_list
argument_list|,
name|bytes
argument_list|)
return|;
name|oldp
operator|=
name|mem2chunk
argument_list|(
name|oldmem
argument_list|)
expr_stmt|;
name|oldsize
operator|=
name|chunksize
argument_list|(
name|oldp
argument_list|)
expr_stmt|;
name|checked_request2size
argument_list|(
name|bytes
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|ar_ptr
operator|=
name|arena_for_chunk
argument_list|(
name|oldp
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|mutex_lock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
name|newp
operator|=
name|_int_realloc
argument_list|(
name|ar_ptr
argument_list|,
name|oldmem
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|mutex_unlock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
name|assert
argument_list|(
operator|!
name|newp
operator|||
name|chunk_is_mmapped
argument_list|(
name|mem2chunk
argument_list|(
name|newp
argument_list|)
argument_list|)
operator|||
name|ar_ptr
operator|==
name|arena_for_chunk
argument_list|(
name|mem2chunk
argument_list|(
name|newp
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|newp
return|;
block|}
end_function

begin_undef
undef|#
directive|undef
name|DEBUG_MEMALIGN
end_undef

begin_function
name|Void_t
modifier|*
name|public_mEMALIGn
parameter_list|(
name|cvmx_arena_list_t
name|arena_list
parameter_list|,
name|size_t
name|alignment
parameter_list|,
name|size_t
name|bytes
parameter_list|)
block|{
name|mstate
name|ar_ptr
decl_stmt|,
name|orig_ar_ptr
decl_stmt|;
name|Void_t
modifier|*
name|p
init|=
name|NULL
decl_stmt|;
ifdef|#
directive|ifdef
name|DEBUG_MEMALIGN
name|int
name|arena_cnt
init|=
literal|0
decl_stmt|;
endif|#
directive|endif
comment|/* If need less alignment than we give anyway, just relay to malloc */
if|if
condition|(
name|alignment
operator|<=
name|MALLOC_ALIGNMENT
condition|)
return|return
name|public_mALLOc
argument_list|(
name|arena_list
argument_list|,
name|bytes
argument_list|)
return|;
comment|/* Otherwise, ensure that it is at least a minimum chunk size */
if|if
condition|(
name|alignment
operator|<
name|MINSIZE
condition|)
name|alignment
operator|=
name|MINSIZE
expr_stmt|;
name|ar_ptr
operator|=
name|arena_list
expr_stmt|;
if|if
condition|(
operator|!
name|ar_ptr
condition|)
block|{
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|orig_ar_ptr
operator|=
name|ar_ptr
expr_stmt|;
comment|// try to get an arena without contention
do|do
block|{
ifdef|#
directive|ifdef
name|DEBUG_MEMALIGN
name|arena_cnt
operator|++
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
operator|!
name|mutex_trylock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
condition|)
block|{
comment|// we locked it
name|p
operator|=
name|_int_memalign
argument_list|(
name|ar_ptr
argument_list|,
name|alignment
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|mutex_unlock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
condition|)
block|{
break|break;
block|}
block|}
name|ar_ptr
operator|=
name|ar_ptr
operator|->
name|next
expr_stmt|;
block|}
do|while
condition|(
name|ar_ptr
operator|!=
name|orig_ar_ptr
condition|)
do|;
comment|// we couldn't get the memory without contention, so try all
comment|// arenas.  SLOW!
if|if
condition|(
operator|!
name|p
condition|)
block|{
ifdef|#
directive|ifdef
name|DEBUG_MEMALIGN
name|arena_cnt
operator|++
expr_stmt|;
endif|#
directive|endif
name|ar_ptr
operator|=
name|orig_ar_ptr
expr_stmt|;
do|do
block|{
name|mutex_lock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
name|p
operator|=
name|_int_memalign
argument_list|(
name|ar_ptr
argument_list|,
name|alignment
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|mutex_unlock
argument_list|(
operator|&
name|ar_ptr
operator|->
name|mutex
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
condition|)
block|{
break|break;
block|}
name|ar_ptr
operator|=
name|ar_ptr
operator|->
name|next
expr_stmt|;
block|}
do|while
condition|(
name|ar_ptr
operator|!=
name|orig_ar_ptr
condition|)
do|;
block|}
if|if
condition|(
name|p
condition|)
block|{
name|assert
argument_list|(
name|ar_ptr
operator|==
name|arena_for_chunk
argument_list|(
name|mem2chunk
argument_list|(
name|p
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
ifdef|#
directive|ifdef
name|DEBUG_MEMALIGN
name|cvmx_dprintf
argument_list|(
literal|"Memalign failed: align: 0x%x, size: %ld, arena_cnt: %ld\n"
argument_list|,
name|alignment
argument_list|,
name|bytes
argument_list|,
name|arena_cnt
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
name|assert
argument_list|(
operator|!
name|p
operator|||
name|ar_ptr
operator|==
name|arena_for_chunk
argument_list|(
name|mem2chunk
argument_list|(
name|p
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|p
return|;
block|}
end_function

begin_function
name|Void_t
modifier|*
name|public_cALLOc
parameter_list|(
name|cvmx_arena_list_t
name|arena_list
parameter_list|,
name|size_t
name|n
parameter_list|,
name|size_t
name|elem_size
parameter_list|)
block|{
name|mstate
name|av
decl_stmt|;
name|mchunkptr
name|oldtop
decl_stmt|,
name|p
decl_stmt|;
name|INTERNAL_SIZE_T
name|sz
decl_stmt|,
name|csz
decl_stmt|,
name|oldtopsize
decl_stmt|;
name|Void_t
modifier|*
name|mem
decl_stmt|;
name|unsigned
name|long
name|clearsize
decl_stmt|;
name|unsigned
name|long
name|nclears
decl_stmt|;
name|INTERNAL_SIZE_T
modifier|*
name|d
decl_stmt|;
comment|/* FIXME: check for overflow on multiplication.  */
name|sz
operator|=
name|n
operator|*
name|elem_size
expr_stmt|;
name|mem
operator|=
name|public_mALLOc
argument_list|(
name|arena_list
argument_list|,
name|sz
argument_list|)
expr_stmt|;
if|if
condition|(
name|mem
condition|)
block|{
name|memset
argument_list|(
name|mem
argument_list|,
literal|0
argument_list|,
name|sz
argument_list|)
expr_stmt|;
block|}
return|return
name|mem
return|;
block|}
end_function

begin_ifndef
ifndef|#
directive|ifndef
name|_LIBC
end_ifndef

begin_function
name|void
name|public_cFREe
parameter_list|(
name|Void_t
modifier|*
name|m
parameter_list|)
block|{
name|public_fREe
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* _LIBC */
end_comment

begin_comment
comment|/*   ------------------------------ malloc ------------------------------ */
end_comment

begin_function
specifier|static
name|Void_t
modifier|*
name|_int_malloc
parameter_list|(
name|mstate
name|av
parameter_list|,
name|size_t
name|bytes
parameter_list|)
block|{
name|INTERNAL_SIZE_T
name|nb
decl_stmt|;
comment|/* normalized request size */
name|unsigned
name|int
name|idx
decl_stmt|;
comment|/* associated bin index */
name|mbinptr
name|bin
decl_stmt|;
comment|/* associated bin */
name|mfastbinptr
modifier|*
name|fb
decl_stmt|;
comment|/* associated fastbin */
name|mchunkptr
name|victim
decl_stmt|;
comment|/* inspected/selected chunk */
name|INTERNAL_SIZE_T
name|size
decl_stmt|;
comment|/* its size */
name|int
name|victim_index
decl_stmt|;
comment|/* its bin index */
name|mchunkptr
name|remainder
decl_stmt|;
comment|/* remainder from a split */
name|unsigned
name|long
name|remainder_size
decl_stmt|;
comment|/* its size */
name|unsigned
name|int
name|block
decl_stmt|;
comment|/* bit map traverser */
name|unsigned
name|int
name|bit
decl_stmt|;
comment|/* bit map traverser */
name|unsigned
name|int
name|map
decl_stmt|;
comment|/* current word of binmap */
name|mchunkptr
name|fwd
decl_stmt|;
comment|/* misc temp for linking */
name|mchunkptr
name|bck
decl_stmt|;
comment|/* misc temp for linking */
comment|/*     Convert request size to internal form by adding SIZE_SZ bytes     overhead plus possibly more to obtain necessary alignment and/or     to obtain a size of at least MINSIZE, the smallest allocatable     size. Also, checked_request2size traps (returning 0) request sizes     that are so large that they wrap around zero when padded and     aligned.   */
name|checked_request2size
argument_list|(
name|bytes
argument_list|,
name|nb
argument_list|)
expr_stmt|;
comment|/*     If the size qualifies as a fastbin, first check corresponding bin.     This code is safe to execute even if av is not yet initialized, so we     can try it without checking, which saves some time on this fast path.   */
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|nb
argument_list|)
operator|<=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|av
operator|->
name|max_fast
argument_list|)
condition|)
block|{
name|fb
operator|=
operator|&
operator|(
name|av
operator|->
name|fastbins
index|[
operator|(
name|fastbin_index
argument_list|(
name|nb
argument_list|)
operator|)
index|]
operator|)
expr_stmt|;
if|if
condition|(
operator|(
name|victim
operator|=
operator|*
name|fb
operator|)
operator|!=
literal|0
condition|)
block|{
operator|*
name|fb
operator|=
name|victim
operator|->
name|fd
expr_stmt|;
name|check_remalloced_chunk
argument_list|(
name|av
argument_list|,
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|victim
argument_list|,
name|av
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|victim
argument_list|)
return|;
block|}
block|}
comment|/*     If a small request, check regular bin.  Since these "smallbins"     hold one size each, no searching within bins is necessary.     (For a large request, we need to wait until unsorted chunks are     processed to find best fit. But for small ones, fits are exact     anyway, so we can check now, which is faster.)   */
if|if
condition|(
name|in_smallbin_range
argument_list|(
name|nb
argument_list|)
condition|)
block|{
name|idx
operator|=
name|smallbin_index
argument_list|(
name|nb
argument_list|)
expr_stmt|;
name|bin
operator|=
name|bin_at
argument_list|(
name|av
argument_list|,
name|idx
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|victim
operator|=
name|last
argument_list|(
name|bin
argument_list|)
operator|)
operator|!=
name|bin
condition|)
block|{
if|if
condition|(
name|victim
operator|==
literal|0
condition|)
comment|/* initialization check */
name|malloc_consolidate
argument_list|(
name|av
argument_list|)
expr_stmt|;
else|else
block|{
name|bck
operator|=
name|victim
operator|->
name|bk
expr_stmt|;
name|set_inuse_bit_at_offset
argument_list|(
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|bin
operator|->
name|bk
operator|=
name|bck
expr_stmt|;
name|bck
operator|->
name|fd
operator|=
name|bin
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|victim
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_malloced_chunk
argument_list|(
name|av
argument_list|,
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|victim
argument_list|)
return|;
block|}
block|}
block|}
comment|/*      If this is a large request, consolidate fastbins before continuing.      While it might look excessive to kill all fastbins before      even seeing if there is space available, this avoids      fragmentation problems normally associated with fastbins.      Also, in practice, programs tend to have runs of either small or      large requests, but less often mixtures, so consolidation is not      invoked all that often in most programs. And the programs that      it is called frequently in otherwise tend to fragment.   */
else|else
block|{
name|idx
operator|=
name|largebin_index
argument_list|(
name|nb
argument_list|)
expr_stmt|;
if|if
condition|(
name|have_fastchunks
argument_list|(
name|av
argument_list|)
condition|)
name|malloc_consolidate
argument_list|(
name|av
argument_list|)
expr_stmt|;
block|}
comment|/*     Process recently freed or remaindered chunks, taking one only if     it is exact fit, or, if this a small request, the chunk is remainder from     the most recent non-exact fit.  Place other traversed chunks in     bins.  Note that this step is the only place in any routine where     chunks are placed in bins.      The outer loop here is needed because we might not realize until     near the end of malloc that we should have consolidated, so must     do so and retry. This happens at most once, and only when we would     otherwise need to expand memory to service a "small" request.   */
for|for
control|(
init|;
condition|;
control|)
block|{
while|while
condition|(
operator|(
name|victim
operator|=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
operator|->
name|bk
operator|)
operator|!=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
condition|)
block|{
name|bck
operator|=
name|victim
operator|->
name|bk
expr_stmt|;
name|size
operator|=
name|chunksize
argument_list|(
name|victim
argument_list|)
expr_stmt|;
comment|/*          If a small request, try to use last remainder if it is the          only chunk in unsorted bin.  This helps promote locality for          runs of consecutive small requests. This is the only          exception to best-fit, and applies only when there is          no exact fit for a small chunk.       */
if|if
condition|(
name|in_smallbin_range
argument_list|(
name|nb
argument_list|)
operator|&&
name|bck
operator|==
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
operator|&&
name|victim
operator|==
name|av
operator|->
name|last_remainder
operator|&&
call|(
name|unsigned
name|long
call|)
argument_list|(
name|size
argument_list|)
operator|>
call|(
name|unsigned
name|long
call|)
argument_list|(
name|nb
operator|+
name|MINSIZE
argument_list|)
condition|)
block|{
comment|/* split and reattach remainder */
name|remainder_size
operator|=
name|size
operator|-
name|nb
expr_stmt|;
name|remainder
operator|=
name|chunk_at_offset
argument_list|(
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
operator|->
name|bk
operator|=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
operator|->
name|fd
operator|=
name|remainder
expr_stmt|;
name|av
operator|->
name|last_remainder
operator|=
name|remainder
expr_stmt|;
name|remainder
operator|->
name|bk
operator|=
name|remainder
operator|->
name|fd
operator|=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
expr_stmt|;
name|set_head
argument_list|(
name|victim
argument_list|,
name|nb
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_head
argument_list|(
name|remainder
argument_list|,
name|remainder_size
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_foot
argument_list|(
name|remainder
argument_list|,
name|remainder_size
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|victim
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_malloced_chunk
argument_list|(
name|av
argument_list|,
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|victim
argument_list|)
return|;
block|}
comment|/* remove from unsorted list */
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
operator|->
name|bk
operator|=
name|bck
expr_stmt|;
name|bck
operator|->
name|fd
operator|=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
expr_stmt|;
comment|/* Take now instead of binning if exact fit */
if|if
condition|(
name|size
operator|==
name|nb
condition|)
block|{
name|set_inuse_bit_at_offset
argument_list|(
name|victim
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|victim
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_malloced_chunk
argument_list|(
name|av
argument_list|,
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|victim
argument_list|)
return|;
block|}
comment|/* place chunk in bin */
if|if
condition|(
name|in_smallbin_range
argument_list|(
name|size
argument_list|)
condition|)
block|{
name|victim_index
operator|=
name|smallbin_index
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|bck
operator|=
name|bin_at
argument_list|(
name|av
argument_list|,
name|victim_index
argument_list|)
expr_stmt|;
name|fwd
operator|=
name|bck
operator|->
name|fd
expr_stmt|;
block|}
else|else
block|{
name|victim_index
operator|=
name|largebin_index
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|bck
operator|=
name|bin_at
argument_list|(
name|av
argument_list|,
name|victim_index
argument_list|)
expr_stmt|;
name|fwd
operator|=
name|bck
operator|->
name|fd
expr_stmt|;
if|if
condition|(
name|fwd
operator|!=
name|bck
condition|)
block|{
comment|/* if smaller than smallest, place first */
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|size
argument_list|)
operator|<
call|(
name|unsigned
name|long
call|)
argument_list|(
name|bck
operator|->
name|bk
operator|->
name|size
argument_list|)
condition|)
block|{
name|fwd
operator|=
name|bck
expr_stmt|;
name|bck
operator|=
name|bck
operator|->
name|bk
expr_stmt|;
block|}
elseif|else
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|size
argument_list|)
operator|>=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|FIRST_SORTED_BIN_SIZE
argument_list|)
condition|)
block|{
comment|/* maintain large bins in sorted order */
name|size
operator||=
name|PREV_INUSE
expr_stmt|;
comment|/* Or with inuse bit to speed comparisons */
while|while
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|size
argument_list|)
operator|<
call|(
name|unsigned
name|long
call|)
argument_list|(
name|fwd
operator|->
name|size
argument_list|)
condition|)
block|{
name|fwd
operator|=
name|fwd
operator|->
name|fd
expr_stmt|;
block|}
name|bck
operator|=
name|fwd
operator|->
name|bk
expr_stmt|;
block|}
block|}
block|}
name|mark_bin
argument_list|(
name|av
argument_list|,
name|victim_index
argument_list|)
expr_stmt|;
name|victim
operator|->
name|bk
operator|=
name|bck
expr_stmt|;
name|victim
operator|->
name|fd
operator|=
name|fwd
expr_stmt|;
name|fwd
operator|->
name|bk
operator|=
name|victim
expr_stmt|;
name|bck
operator|->
name|fd
operator|=
name|victim
expr_stmt|;
block|}
comment|/*       If a large request, scan through the chunks of current bin in       sorted order to find smallest that fits.  This is the only step       where an unbounded number of chunks might be scanned without doing       anything useful with them. However the lists tend to be short.     */
if|if
condition|(
operator|!
name|in_smallbin_range
argument_list|(
name|nb
argument_list|)
condition|)
block|{
name|bin
operator|=
name|bin_at
argument_list|(
name|av
argument_list|,
name|idx
argument_list|)
expr_stmt|;
for|for
control|(
name|victim
operator|=
name|last
argument_list|(
name|bin
argument_list|)
init|;
name|victim
operator|!=
name|bin
condition|;
name|victim
operator|=
name|victim
operator|->
name|bk
control|)
block|{
name|size
operator|=
name|chunksize
argument_list|(
name|victim
argument_list|)
expr_stmt|;
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|size
argument_list|)
operator|>=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|nb
argument_list|)
condition|)
block|{
name|remainder_size
operator|=
name|size
operator|-
name|nb
expr_stmt|;
name|unlink
argument_list|(
name|victim
argument_list|,
name|bck
argument_list|,
name|fwd
argument_list|)
expr_stmt|;
comment|/* Exhaust */
if|if
condition|(
name|remainder_size
operator|<
name|MINSIZE
condition|)
block|{
name|set_inuse_bit_at_offset
argument_list|(
name|victim
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|victim
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_malloced_chunk
argument_list|(
name|av
argument_list|,
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|victim
argument_list|)
return|;
block|}
comment|/* Split */
else|else
block|{
name|remainder
operator|=
name|chunk_at_offset
argument_list|(
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
operator|->
name|bk
operator|=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
operator|->
name|fd
operator|=
name|remainder
expr_stmt|;
name|remainder
operator|->
name|bk
operator|=
name|remainder
operator|->
name|fd
operator|=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
expr_stmt|;
name|set_head
argument_list|(
name|victim
argument_list|,
name|nb
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_head
argument_list|(
name|remainder
argument_list|,
name|remainder_size
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_foot
argument_list|(
name|remainder
argument_list|,
name|remainder_size
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|victim
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_malloced_chunk
argument_list|(
name|av
argument_list|,
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|victim
argument_list|)
return|;
block|}
block|}
block|}
block|}
comment|/*       Search for a chunk by scanning bins, starting with next largest       bin. This search is strictly by best-fit; i.e., the smallest       (with ties going to approximately the least recently used) chunk       that fits is selected.        The bitmap avoids needing to check that most blocks are nonempty.       The particular case of skipping all bins during warm-up phases       when no chunks have been returned yet is faster than it might look.     */
operator|++
name|idx
expr_stmt|;
name|bin
operator|=
name|bin_at
argument_list|(
name|av
argument_list|,
name|idx
argument_list|)
expr_stmt|;
name|block
operator|=
name|idx2block
argument_list|(
name|idx
argument_list|)
expr_stmt|;
name|map
operator|=
name|av
operator|->
name|binmap
index|[
name|block
index|]
expr_stmt|;
name|bit
operator|=
name|idx2bit
argument_list|(
name|idx
argument_list|)
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
comment|/* Skip rest of block if there are no more set bits in this block.  */
if|if
condition|(
name|bit
operator|>
name|map
operator|||
name|bit
operator|==
literal|0
condition|)
block|{
do|do
block|{
if|if
condition|(
operator|++
name|block
operator|>=
name|BINMAPSIZE
condition|)
comment|/* out of bins */
goto|goto
name|use_top
goto|;
block|}
do|while
condition|(
operator|(
name|map
operator|=
name|av
operator|->
name|binmap
index|[
name|block
index|]
operator|)
operator|==
literal|0
condition|)
do|;
name|bin
operator|=
name|bin_at
argument_list|(
name|av
argument_list|,
operator|(
name|block
operator|<<
name|BINMAPSHIFT
operator|)
argument_list|)
expr_stmt|;
name|bit
operator|=
literal|1
expr_stmt|;
block|}
comment|/* Advance to bin with set bit. There must be one. */
while|while
condition|(
operator|(
name|bit
operator|&
name|map
operator|)
operator|==
literal|0
condition|)
block|{
name|bin
operator|=
name|next_bin
argument_list|(
name|bin
argument_list|)
expr_stmt|;
name|bit
operator|<<=
literal|1
expr_stmt|;
name|assert
argument_list|(
name|bit
operator|!=
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/* Inspect the bin. It is likely to be non-empty */
name|victim
operator|=
name|last
argument_list|(
name|bin
argument_list|)
expr_stmt|;
comment|/*  If a false alarm (empty bin), clear the bit. */
if|if
condition|(
name|victim
operator|==
name|bin
condition|)
block|{
name|av
operator|->
name|binmap
index|[
name|block
index|]
operator|=
name|map
operator|&=
operator|~
name|bit
expr_stmt|;
comment|/* Write through */
name|bin
operator|=
name|next_bin
argument_list|(
name|bin
argument_list|)
expr_stmt|;
name|bit
operator|<<=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|size
operator|=
name|chunksize
argument_list|(
name|victim
argument_list|)
expr_stmt|;
comment|/*  We know the first chunk in this bin is big enough to use. */
name|assert
argument_list|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|size
argument_list|)
operator|>=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|nb
argument_list|)
argument_list|)
expr_stmt|;
name|remainder_size
operator|=
name|size
operator|-
name|nb
expr_stmt|;
comment|/* unlink */
name|bck
operator|=
name|victim
operator|->
name|bk
expr_stmt|;
name|bin
operator|->
name|bk
operator|=
name|bck
expr_stmt|;
name|bck
operator|->
name|fd
operator|=
name|bin
expr_stmt|;
comment|/* Exhaust */
if|if
condition|(
name|remainder_size
operator|<
name|MINSIZE
condition|)
block|{
name|set_inuse_bit_at_offset
argument_list|(
name|victim
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|victim
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_malloced_chunk
argument_list|(
name|av
argument_list|,
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|victim
argument_list|)
return|;
block|}
comment|/* Split */
else|else
block|{
name|remainder
operator|=
name|chunk_at_offset
argument_list|(
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
operator|->
name|bk
operator|=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
operator|->
name|fd
operator|=
name|remainder
expr_stmt|;
name|remainder
operator|->
name|bk
operator|=
name|remainder
operator|->
name|fd
operator|=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
expr_stmt|;
comment|/* advertise as last remainder */
if|if
condition|(
name|in_smallbin_range
argument_list|(
name|nb
argument_list|)
condition|)
name|av
operator|->
name|last_remainder
operator|=
name|remainder
expr_stmt|;
name|set_head
argument_list|(
name|victim
argument_list|,
name|nb
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_head
argument_list|(
name|remainder
argument_list|,
name|remainder_size
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_foot
argument_list|(
name|remainder
argument_list|,
name|remainder_size
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|victim
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_malloced_chunk
argument_list|(
name|av
argument_list|,
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|victim
argument_list|)
return|;
block|}
block|}
block|}
name|use_top
label|:
comment|/*       If large enough, split off the chunk bordering the end of memory       (held in av->top). Note that this is in accord with the best-fit       search rule.  In effect, av->top is treated as larger (and thus       less well fitting) than any other available chunk since it can       be extended to be as large as necessary (up to system       limitations).        We require that av->top always exists (i.e., has size>=       MINSIZE) after initialization, so if it would otherwise be       exhuasted by current request, it is replenished. (The main       reason for ensuring it exists is that we may need MINSIZE space       to put in fenceposts in sysmalloc.)     */
name|victim
operator|=
name|av
operator|->
name|top
expr_stmt|;
name|size
operator|=
name|chunksize
argument_list|(
name|victim
argument_list|)
expr_stmt|;
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|size
argument_list|)
operator|>=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|nb
operator|+
name|MINSIZE
argument_list|)
condition|)
block|{
name|remainder_size
operator|=
name|size
operator|-
name|nb
expr_stmt|;
name|remainder
operator|=
name|chunk_at_offset
argument_list|(
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|av
operator|->
name|top
operator|=
name|remainder
expr_stmt|;
name|set_head
argument_list|(
name|victim
argument_list|,
name|nb
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_head
argument_list|(
name|remainder
argument_list|,
name|remainder_size
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|victim
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_malloced_chunk
argument_list|(
name|av
argument_list|,
name|victim
argument_list|,
name|nb
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|victim
argument_list|)
return|;
block|}
comment|/*       If there is space available in fastbins, consolidate and retry,       to possibly avoid expanding memory. This can occur only if nb is       in smallbin range so we didn't consolidate upon entry.     */
elseif|else
if|if
condition|(
name|have_fastchunks
argument_list|(
name|av
argument_list|)
condition|)
block|{
name|assert
argument_list|(
name|in_smallbin_range
argument_list|(
name|nb
argument_list|)
argument_list|)
expr_stmt|;
name|malloc_consolidate
argument_list|(
name|av
argument_list|)
expr_stmt|;
name|idx
operator|=
name|smallbin_index
argument_list|(
name|nb
argument_list|)
expr_stmt|;
comment|/* restore original bin index */
block|}
comment|/*        Otherwise, relay to handle system-dependent cases     */
else|else
return|return
operator|(
name|NULL
operator|)
return|;
comment|// sysmalloc not supported
block|}
block|}
end_function

begin_comment
comment|/*   ------------------------------ free ------------------------------ */
end_comment

begin_function
specifier|static
name|void
name|_int_free
parameter_list|(
name|mstate
name|av
parameter_list|,
name|Void_t
modifier|*
name|mem
parameter_list|)
block|{
name|mchunkptr
name|p
decl_stmt|;
comment|/* chunk corresponding to mem */
name|INTERNAL_SIZE_T
name|size
decl_stmt|;
comment|/* its size */
name|mfastbinptr
modifier|*
name|fb
decl_stmt|;
comment|/* associated fastbin */
name|mchunkptr
name|nextchunk
decl_stmt|;
comment|/* next contiguous chunk */
name|INTERNAL_SIZE_T
name|nextsize
decl_stmt|;
comment|/* its size */
name|int
name|nextinuse
decl_stmt|;
comment|/* true if nextchunk is used */
name|INTERNAL_SIZE_T
name|prevsize
decl_stmt|;
comment|/* size of previous contiguous chunk */
name|mchunkptr
name|bck
decl_stmt|;
comment|/* misc temp for linking */
name|mchunkptr
name|fwd
decl_stmt|;
comment|/* misc temp for linking */
comment|/* free(0) has no effect */
if|if
condition|(
name|mem
operator|!=
literal|0
condition|)
block|{
name|p
operator|=
name|mem2chunk
argument_list|(
name|mem
argument_list|)
expr_stmt|;
name|size
operator|=
name|chunksize
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|check_inuse_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|)
expr_stmt|;
comment|/*       If eligible, place chunk on a fastbin so it can be found       and used quickly in malloc.     */
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|size
argument_list|)
operator|<=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|av
operator|->
name|max_fast
argument_list|)
if|#
directive|if
name|TRIM_FASTBINS
comment|/*            If TRIM_FASTBINS set, don't place chunks            bordering top into fastbins         */
operator|&&
operator|(
name|chunk_at_offset
argument_list|(
name|p
argument_list|,
name|size
argument_list|)
operator|!=
name|av
operator|->
name|top
operator|)
endif|#
directive|endif
condition|)
block|{
name|set_fastchunks
argument_list|(
name|av
argument_list|)
expr_stmt|;
name|fb
operator|=
operator|&
operator|(
name|av
operator|->
name|fastbins
index|[
name|fastbin_index
argument_list|(
name|size
argument_list|)
index|]
operator|)
expr_stmt|;
name|p
operator|->
name|fd
operator|=
operator|*
name|fb
expr_stmt|;
operator|*
name|fb
operator|=
name|p
expr_stmt|;
block|}
comment|/*        Consolidate other non-mmapped chunks as they arrive.     */
elseif|else
if|if
condition|(
operator|!
name|chunk_is_mmapped
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|nextchunk
operator|=
name|chunk_at_offset
argument_list|(
name|p
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|nextsize
operator|=
name|chunksize
argument_list|(
name|nextchunk
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|nextsize
operator|>
literal|0
argument_list|)
expr_stmt|;
comment|/* consolidate backward */
if|if
condition|(
operator|!
name|prev_inuse
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|prevsize
operator|=
name|p
operator|->
name|prev_size
expr_stmt|;
name|size
operator|+=
name|prevsize
expr_stmt|;
name|p
operator|=
name|chunk_at_offset
argument_list|(
name|p
argument_list|,
operator|-
operator|(
operator|(
name|long
operator|)
name|prevsize
operator|)
argument_list|)
expr_stmt|;
name|unlink
argument_list|(
name|p
argument_list|,
name|bck
argument_list|,
name|fwd
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|nextchunk
operator|!=
name|av
operator|->
name|top
condition|)
block|{
comment|/* get and clear inuse bit */
name|nextinuse
operator|=
name|inuse_bit_at_offset
argument_list|(
name|nextchunk
argument_list|,
name|nextsize
argument_list|)
expr_stmt|;
comment|/* consolidate forward */
if|if
condition|(
operator|!
name|nextinuse
condition|)
block|{
name|unlink
argument_list|(
name|nextchunk
argument_list|,
name|bck
argument_list|,
name|fwd
argument_list|)
expr_stmt|;
name|size
operator|+=
name|nextsize
expr_stmt|;
block|}
else|else
name|clear_inuse_bit_at_offset
argument_list|(
name|nextchunk
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|/*           Place the chunk in unsorted chunk list. Chunks are           not placed into regular bins until after they have           been given one chance to be used in malloc.         */
name|bck
operator|=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
expr_stmt|;
name|fwd
operator|=
name|bck
operator|->
name|fd
expr_stmt|;
name|p
operator|->
name|bk
operator|=
name|bck
expr_stmt|;
name|p
operator|->
name|fd
operator|=
name|fwd
expr_stmt|;
name|bck
operator|->
name|fd
operator|=
name|p
expr_stmt|;
name|fwd
operator|->
name|bk
operator|=
name|p
expr_stmt|;
name|set_head
argument_list|(
name|p
argument_list|,
name|size
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_foot
argument_list|(
name|p
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|check_free_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
comment|/*          If the chunk borders the current high end of memory,          consolidate into top       */
else|else
block|{
name|size
operator|+=
name|nextsize
expr_stmt|;
name|set_head
argument_list|(
name|p
argument_list|,
name|size
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|av
operator|->
name|top
operator|=
name|p
expr_stmt|;
name|check_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
comment|/*         If freeing a large space, consolidate possibly-surrounding         chunks. Then, if the total unused topmost memory exceeds trim         threshold, ask malloc_trim to reduce top.          Unless max_fast is 0, we don't know if there are fastbins         bordering top, so we cannot tell for sure whether threshold         has been reached unless fastbins are consolidated.  But we         don't want to consolidate on each free.  As a compromise,         consolidation is performed if FASTBIN_CONSOLIDATION_THRESHOLD         is reached.       */
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|size
argument_list|)
operator|>=
name|FASTBIN_CONSOLIDATION_THRESHOLD
condition|)
block|{
if|if
condition|(
name|have_fastchunks
argument_list|(
name|av
argument_list|)
condition|)
name|malloc_consolidate
argument_list|(
name|av
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_function

begin_comment
comment|/*   ------------------------- malloc_consolidate -------------------------    malloc_consolidate is a specialized version of free() that tears   down chunks held in fastbins.  Free itself cannot be used for this   purpose since, among other things, it might place chunks back onto   fastbins.  So, instead, we need to use a minor variant of the same   code.    Also, because this routine needs to be called the first time through   malloc anyway, it turns out to be the perfect place to trigger   initialization code. */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function
specifier|static
name|void
name|malloc_consolidate
parameter_list|(
name|mstate
name|av
parameter_list|)
else|#
directive|else
function|static void malloc_consolidate
parameter_list|(
name|av
parameter_list|)
name|mstate
name|av
decl_stmt|;
endif|#
directive|endif
block|{
name|mfastbinptr
modifier|*
name|fb
decl_stmt|;
comment|/* current fastbin being consolidated */
name|mfastbinptr
modifier|*
name|maxfb
decl_stmt|;
comment|/* last fastbin (for loop control) */
name|mchunkptr
name|p
decl_stmt|;
comment|/* current chunk being consolidated */
name|mchunkptr
name|nextp
decl_stmt|;
comment|/* next chunk to consolidate */
name|mchunkptr
name|unsorted_bin
decl_stmt|;
comment|/* bin header */
name|mchunkptr
name|first_unsorted
decl_stmt|;
comment|/* chunk to link to */
comment|/* These have same use as in free() */
name|mchunkptr
name|nextchunk
decl_stmt|;
name|INTERNAL_SIZE_T
name|size
decl_stmt|;
name|INTERNAL_SIZE_T
name|nextsize
decl_stmt|;
name|INTERNAL_SIZE_T
name|prevsize
decl_stmt|;
name|int
name|nextinuse
decl_stmt|;
name|mchunkptr
name|bck
decl_stmt|;
name|mchunkptr
name|fwd
decl_stmt|;
comment|/*     If max_fast is 0, we know that av hasn't     yet been initialized, in which case do so below   */
if|if
condition|(
name|av
operator|->
name|max_fast
operator|!=
literal|0
condition|)
block|{
name|clear_fastchunks
argument_list|(
name|av
argument_list|)
expr_stmt|;
name|unsorted_bin
operator|=
name|unsorted_chunks
argument_list|(
name|av
argument_list|)
expr_stmt|;
comment|/*       Remove each chunk from fast bin and consolidate it, placing it       then in unsorted bin. Among other reasons for doing this,       placing in unsorted bin avoids needing to calculate actual bins       until malloc is sure that chunks aren't immediately going to be       reused anyway.     */
name|maxfb
operator|=
operator|&
operator|(
name|av
operator|->
name|fastbins
index|[
name|fastbin_index
argument_list|(
name|av
operator|->
name|max_fast
argument_list|)
index|]
operator|)
expr_stmt|;
name|fb
operator|=
operator|&
operator|(
name|av
operator|->
name|fastbins
index|[
literal|0
index|]
operator|)
expr_stmt|;
do|do
block|{
if|if
condition|(
operator|(
name|p
operator|=
operator|*
name|fb
operator|)
operator|!=
literal|0
condition|)
block|{
operator|*
name|fb
operator|=
literal|0
expr_stmt|;
do|do
block|{
name|check_inuse_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|)
expr_stmt|;
name|nextp
operator|=
name|p
operator|->
name|fd
expr_stmt|;
comment|/* Slightly streamlined version of consolidation code in free() */
name|size
operator|=
name|p
operator|->
name|size
operator|&
operator|~
operator|(
name|PREV_INUSE
operator|)
expr_stmt|;
name|nextchunk
operator|=
name|chunk_at_offset
argument_list|(
name|p
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|nextsize
operator|=
name|chunksize
argument_list|(
name|nextchunk
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|prev_inuse
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|prevsize
operator|=
name|p
operator|->
name|prev_size
expr_stmt|;
name|size
operator|+=
name|prevsize
expr_stmt|;
name|p
operator|=
name|chunk_at_offset
argument_list|(
name|p
argument_list|,
operator|-
operator|(
operator|(
name|long
operator|)
name|prevsize
operator|)
argument_list|)
expr_stmt|;
name|unlink
argument_list|(
name|p
argument_list|,
name|bck
argument_list|,
name|fwd
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|nextchunk
operator|!=
name|av
operator|->
name|top
condition|)
block|{
name|nextinuse
operator|=
name|inuse_bit_at_offset
argument_list|(
name|nextchunk
argument_list|,
name|nextsize
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|nextinuse
condition|)
block|{
name|size
operator|+=
name|nextsize
expr_stmt|;
name|unlink
argument_list|(
name|nextchunk
argument_list|,
name|bck
argument_list|,
name|fwd
argument_list|)
expr_stmt|;
block|}
else|else
name|clear_inuse_bit_at_offset
argument_list|(
name|nextchunk
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|first_unsorted
operator|=
name|unsorted_bin
operator|->
name|fd
expr_stmt|;
name|unsorted_bin
operator|->
name|fd
operator|=
name|p
expr_stmt|;
name|first_unsorted
operator|->
name|bk
operator|=
name|p
expr_stmt|;
name|set_head
argument_list|(
name|p
argument_list|,
name|size
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|p
operator|->
name|bk
operator|=
name|unsorted_bin
expr_stmt|;
name|p
operator|->
name|fd
operator|=
name|first_unsorted
expr_stmt|;
name|set_foot
argument_list|(
name|p
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|size
operator|+=
name|nextsize
expr_stmt|;
name|set_head
argument_list|(
name|p
argument_list|,
name|size
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|av
operator|->
name|top
operator|=
name|p
expr_stmt|;
block|}
block|}
do|while
condition|(
operator|(
name|p
operator|=
name|nextp
operator|)
operator|!=
literal|0
condition|)
do|;
block|}
block|}
do|while
condition|(
name|fb
operator|++
operator|!=
name|maxfb
condition|)
do|;
block|}
else|else
block|{
name|malloc_init_state
argument_list|(
name|av
argument_list|)
expr_stmt|;
name|check_malloc_state
argument_list|(
name|av
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*   ------------------------------ realloc ------------------------------ */
end_comment

begin_function
specifier|static
name|Void_t
modifier|*
name|_int_realloc
parameter_list|(
name|mstate
name|av
parameter_list|,
name|Void_t
modifier|*
name|oldmem
parameter_list|,
name|size_t
name|bytes
parameter_list|)
block|{
name|INTERNAL_SIZE_T
name|nb
decl_stmt|;
comment|/* padded request size */
name|mchunkptr
name|oldp
decl_stmt|;
comment|/* chunk corresponding to oldmem */
name|INTERNAL_SIZE_T
name|oldsize
decl_stmt|;
comment|/* its size */
name|mchunkptr
name|newp
decl_stmt|;
comment|/* chunk to return */
name|INTERNAL_SIZE_T
name|newsize
decl_stmt|;
comment|/* its size */
name|Void_t
modifier|*
name|newmem
decl_stmt|;
comment|/* corresponding user mem */
name|mchunkptr
name|next
decl_stmt|;
comment|/* next contiguous chunk after oldp */
name|mchunkptr
name|remainder
decl_stmt|;
comment|/* extra space at end of newp */
name|unsigned
name|long
name|remainder_size
decl_stmt|;
comment|/* its size */
name|mchunkptr
name|bck
decl_stmt|;
comment|/* misc temp for linking */
name|mchunkptr
name|fwd
decl_stmt|;
comment|/* misc temp for linking */
name|unsigned
name|long
name|copysize
decl_stmt|;
comment|/* bytes to copy */
name|unsigned
name|int
name|ncopies
decl_stmt|;
comment|/* INTERNAL_SIZE_T words to copy */
name|INTERNAL_SIZE_T
modifier|*
name|s
decl_stmt|;
comment|/* copy source */
name|INTERNAL_SIZE_T
modifier|*
name|d
decl_stmt|;
comment|/* copy destination */
if|#
directive|if
name|REALLOC_ZERO_BYTES_FREES
if|if
condition|(
name|bytes
operator|==
literal|0
condition|)
block|{
name|_int_free
argument_list|(
name|av
argument_list|,
name|oldmem
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
endif|#
directive|endif
comment|/* realloc of null is supposed to be same as malloc */
if|if
condition|(
name|oldmem
operator|==
literal|0
condition|)
return|return
name|_int_malloc
argument_list|(
name|av
argument_list|,
name|bytes
argument_list|)
return|;
name|checked_request2size
argument_list|(
name|bytes
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|oldp
operator|=
name|mem2chunk
argument_list|(
name|oldmem
argument_list|)
expr_stmt|;
name|oldsize
operator|=
name|chunksize
argument_list|(
name|oldp
argument_list|)
expr_stmt|;
name|check_inuse_chunk
argument_list|(
name|av
argument_list|,
name|oldp
argument_list|)
expr_stmt|;
comment|// force to act like not mmapped
if|if
condition|(
literal|1
condition|)
block|{
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|oldsize
argument_list|)
operator|>=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|nb
argument_list|)
condition|)
block|{
comment|/* already big enough; split below */
name|newp
operator|=
name|oldp
expr_stmt|;
name|newsize
operator|=
name|oldsize
expr_stmt|;
block|}
else|else
block|{
name|next
operator|=
name|chunk_at_offset
argument_list|(
name|oldp
argument_list|,
name|oldsize
argument_list|)
expr_stmt|;
comment|/* Try to expand forward into top */
if|if
condition|(
name|next
operator|==
name|av
operator|->
name|top
operator|&&
call|(
name|unsigned
name|long
call|)
argument_list|(
name|newsize
operator|=
name|oldsize
operator|+
name|chunksize
argument_list|(
name|next
argument_list|)
argument_list|)
operator|>=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|nb
operator|+
name|MINSIZE
argument_list|)
condition|)
block|{
name|set_head_size
argument_list|(
name|oldp
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|av
operator|->
name|top
operator|=
name|chunk_at_offset
argument_list|(
name|oldp
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|set_head
argument_list|(
name|av
operator|->
name|top
argument_list|,
operator|(
name|newsize
operator|-
name|nb
operator|)
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|check_inuse_chunk
argument_list|(
name|av
argument_list|,
name|oldp
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|oldp
argument_list|,
name|av
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|oldp
argument_list|)
return|;
block|}
comment|/* Try to expand forward into next chunk;  split off remainder below */
elseif|else
if|if
condition|(
name|next
operator|!=
name|av
operator|->
name|top
operator|&&
operator|!
name|inuse
argument_list|(
name|next
argument_list|)
operator|&&
call|(
name|unsigned
name|long
call|)
argument_list|(
name|newsize
operator|=
name|oldsize
operator|+
name|chunksize
argument_list|(
name|next
argument_list|)
argument_list|)
operator|>=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|nb
argument_list|)
condition|)
block|{
name|newp
operator|=
name|oldp
expr_stmt|;
name|unlink
argument_list|(
name|next
argument_list|,
name|bck
argument_list|,
name|fwd
argument_list|)
expr_stmt|;
block|}
comment|/* allocate, copy, free */
else|else
block|{
name|newmem
operator|=
name|_int_malloc
argument_list|(
name|av
argument_list|,
name|nb
operator|-
name|MALLOC_ALIGN_MASK
argument_list|)
expr_stmt|;
if|if
condition|(
name|newmem
operator|==
literal|0
condition|)
return|return
literal|0
return|;
comment|/* propagate failure */
name|newp
operator|=
name|mem2chunk
argument_list|(
name|newmem
argument_list|)
expr_stmt|;
name|newsize
operator|=
name|chunksize
argument_list|(
name|newp
argument_list|)
expr_stmt|;
comment|/*           Avoid copy if newp is next chunk after oldp.         */
if|if
condition|(
name|newp
operator|==
name|next
condition|)
block|{
name|newsize
operator|+=
name|oldsize
expr_stmt|;
name|newp
operator|=
name|oldp
expr_stmt|;
block|}
else|else
block|{
comment|/*             Unroll copy of<= 36 bytes (72 if 8byte sizes)             We know that contents have an odd number of             INTERNAL_SIZE_T-sized words; minimally 3.           */
name|copysize
operator|=
name|oldsize
operator|-
name|SIZE_SZ
expr_stmt|;
name|s
operator|=
operator|(
name|INTERNAL_SIZE_T
operator|*
operator|)
operator|(
name|oldmem
operator|)
expr_stmt|;
name|d
operator|=
operator|(
name|INTERNAL_SIZE_T
operator|*
operator|)
operator|(
name|newmem
operator|)
expr_stmt|;
name|ncopies
operator|=
name|copysize
operator|/
sizeof|sizeof
argument_list|(
name|INTERNAL_SIZE_T
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|ncopies
operator|>=
literal|3
argument_list|)
expr_stmt|;
if|if
condition|(
name|ncopies
operator|>
literal|9
condition|)
name|MALLOC_COPY
argument_list|(
name|d
argument_list|,
name|s
argument_list|,
name|copysize
argument_list|)
expr_stmt|;
else|else
block|{
operator|*
operator|(
name|d
operator|+
literal|0
operator|)
operator|=
operator|*
operator|(
name|s
operator|+
literal|0
operator|)
expr_stmt|;
operator|*
operator|(
name|d
operator|+
literal|1
operator|)
operator|=
operator|*
operator|(
name|s
operator|+
literal|1
operator|)
expr_stmt|;
operator|*
operator|(
name|d
operator|+
literal|2
operator|)
operator|=
operator|*
operator|(
name|s
operator|+
literal|2
operator|)
expr_stmt|;
if|if
condition|(
name|ncopies
operator|>
literal|4
condition|)
block|{
operator|*
operator|(
name|d
operator|+
literal|3
operator|)
operator|=
operator|*
operator|(
name|s
operator|+
literal|3
operator|)
expr_stmt|;
operator|*
operator|(
name|d
operator|+
literal|4
operator|)
operator|=
operator|*
operator|(
name|s
operator|+
literal|4
operator|)
expr_stmt|;
if|if
condition|(
name|ncopies
operator|>
literal|6
condition|)
block|{
operator|*
operator|(
name|d
operator|+
literal|5
operator|)
operator|=
operator|*
operator|(
name|s
operator|+
literal|5
operator|)
expr_stmt|;
operator|*
operator|(
name|d
operator|+
literal|6
operator|)
operator|=
operator|*
operator|(
name|s
operator|+
literal|6
operator|)
expr_stmt|;
if|if
condition|(
name|ncopies
operator|>
literal|8
condition|)
block|{
operator|*
operator|(
name|d
operator|+
literal|7
operator|)
operator|=
operator|*
operator|(
name|s
operator|+
literal|7
operator|)
expr_stmt|;
operator|*
operator|(
name|d
operator|+
literal|8
operator|)
operator|=
operator|*
operator|(
name|s
operator|+
literal|8
operator|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|_int_free
argument_list|(
name|av
argument_list|,
name|oldmem
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|newp
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_inuse_chunk
argument_list|(
name|av
argument_list|,
name|newp
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|newp
argument_list|)
return|;
block|}
block|}
block|}
comment|/* If possible, free extra space in old or extended chunk */
name|assert
argument_list|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|newsize
argument_list|)
operator|>=
call|(
name|unsigned
name|long
call|)
argument_list|(
name|nb
argument_list|)
argument_list|)
expr_stmt|;
name|remainder_size
operator|=
name|newsize
operator|-
name|nb
expr_stmt|;
if|if
condition|(
name|remainder_size
operator|<
name|MINSIZE
condition|)
block|{
comment|/* not enough extra to split off */
name|set_head_size
argument_list|(
name|newp
argument_list|,
name|newsize
argument_list|)
expr_stmt|;
name|set_inuse_bit_at_offset
argument_list|(
name|newp
argument_list|,
name|newsize
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* split remainder */
name|remainder
operator|=
name|chunk_at_offset
argument_list|(
name|newp
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|set_head_size
argument_list|(
name|newp
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|set_head
argument_list|(
name|remainder
argument_list|,
name|remainder_size
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
comment|/* Mark remainder as inuse so free() won't complain */
name|set_inuse_bit_at_offset
argument_list|(
name|remainder
argument_list|,
name|remainder_size
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|remainder
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|_int_free
argument_list|(
name|av
argument_list|,
name|chunk2mem
argument_list|(
name|remainder
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|set_arena_for_chunk
argument_list|(
name|newp
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_inuse_chunk
argument_list|(
name|av
argument_list|,
name|newp
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|newp
argument_list|)
return|;
block|}
comment|/*     Handle mmap cases   */
else|else
block|{
comment|/* If !HAVE_MMAP, but chunk_is_mmapped, user must have overwritten mem */
name|check_malloc_state
argument_list|(
name|av
argument_list|)
expr_stmt|;
name|MALLOC_FAILURE_ACTION
expr_stmt|;
return|return
literal|0
return|;
block|}
block|}
end_function

begin_comment
comment|/*   ------------------------------ memalign ------------------------------ */
end_comment

begin_function
specifier|static
name|Void_t
modifier|*
name|_int_memalign
parameter_list|(
name|mstate
name|av
parameter_list|,
name|size_t
name|alignment
parameter_list|,
name|size_t
name|bytes
parameter_list|)
block|{
name|INTERNAL_SIZE_T
name|nb
decl_stmt|;
comment|/* padded  request size */
name|char
modifier|*
name|m
decl_stmt|;
comment|/* memory returned by malloc call */
name|mchunkptr
name|p
decl_stmt|;
comment|/* corresponding chunk */
name|char
modifier|*
name|brk
decl_stmt|;
comment|/* alignment point within p */
name|mchunkptr
name|newp
decl_stmt|;
comment|/* chunk to return */
name|INTERNAL_SIZE_T
name|newsize
decl_stmt|;
comment|/* its size */
name|INTERNAL_SIZE_T
name|leadsize
decl_stmt|;
comment|/* leading space before alignment point */
name|mchunkptr
name|remainder
decl_stmt|;
comment|/* spare room at end to split off */
name|unsigned
name|long
name|remainder_size
decl_stmt|;
comment|/* its size */
name|INTERNAL_SIZE_T
name|size
decl_stmt|;
comment|/* If need less alignment than we give anyway, just relay to malloc */
if|if
condition|(
name|alignment
operator|<=
name|MALLOC_ALIGNMENT
condition|)
return|return
name|_int_malloc
argument_list|(
name|av
argument_list|,
name|bytes
argument_list|)
return|;
comment|/* Otherwise, ensure that it is at least a minimum chunk size */
if|if
condition|(
name|alignment
operator|<
name|MINSIZE
condition|)
name|alignment
operator|=
name|MINSIZE
expr_stmt|;
comment|/* Make sure alignment is power of 2 (in case MINSIZE is not).  */
if|if
condition|(
operator|(
name|alignment
operator|&
operator|(
name|alignment
operator|-
literal|1
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|size_t
name|a
init|=
name|MALLOC_ALIGNMENT
operator|*
literal|2
decl_stmt|;
while|while
condition|(
operator|(
name|unsigned
name|long
operator|)
name|a
operator|<
operator|(
name|unsigned
name|long
operator|)
name|alignment
condition|)
name|a
operator|<<=
literal|1
expr_stmt|;
name|alignment
operator|=
name|a
expr_stmt|;
block|}
name|checked_request2size
argument_list|(
name|bytes
argument_list|,
name|nb
argument_list|)
expr_stmt|;
comment|/*     Strategy: find a spot within that chunk that meets the alignment     request, and then possibly free the leading and trailing space.   */
comment|/* Call malloc with worst case padding to hit alignment. */
name|m
operator|=
operator|(
name|char
operator|*
operator|)
operator|(
name|_int_malloc
argument_list|(
name|av
argument_list|,
name|nb
operator|+
name|alignment
operator|+
name|MINSIZE
argument_list|)
operator|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
literal|0
condition|)
return|return
literal|0
return|;
comment|/* propagate failure */
name|p
operator|=
name|mem2chunk
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|m
argument_list|)
operator|)
operator|%
name|alignment
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* misaligned */
comment|/*       Find an aligned spot inside chunk.  Since we need to give back       leading space in a chunk of at least MINSIZE, if the first       calculation places us at a spot with less than MINSIZE leader,       we can move to the next aligned spot -- we've allocated enough       total room so that this is always possible.     */
name|brk
operator|=
operator|(
name|char
operator|*
operator|)
name|mem2chunk
argument_list|(
operator|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|m
operator|+
name|alignment
operator|-
literal|1
argument_list|)
operator|)
operator|&
operator|-
operator|(
operator|(
name|signed
name|long
operator|)
name|alignment
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|brk
operator|-
operator|(
name|char
operator|*
operator|)
operator|(
name|p
operator|)
argument_list|)
operator|<
name|MINSIZE
condition|)
name|brk
operator|+=
name|alignment
expr_stmt|;
name|newp
operator|=
operator|(
name|mchunkptr
operator|)
name|brk
expr_stmt|;
name|leadsize
operator|=
name|brk
operator|-
operator|(
name|char
operator|*
operator|)
operator|(
name|p
operator|)
expr_stmt|;
name|newsize
operator|=
name|chunksize
argument_list|(
name|p
argument_list|)
operator|-
name|leadsize
expr_stmt|;
comment|/* For mmapped chunks, just adjust offset */
if|if
condition|(
name|chunk_is_mmapped
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|newp
operator|->
name|prev_size
operator|=
name|p
operator|->
name|prev_size
operator|+
name|leadsize
expr_stmt|;
name|set_head
argument_list|(
name|newp
argument_list|,
name|newsize
operator||
name|IS_MMAPPED
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|newp
argument_list|,
name|av
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|newp
argument_list|)
return|;
block|}
comment|/* Otherwise, give back leader, use the rest */
name|set_head
argument_list|(
name|newp
argument_list|,
name|newsize
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_inuse_bit_at_offset
argument_list|(
name|newp
argument_list|,
name|newsize
argument_list|)
expr_stmt|;
name|set_head_size
argument_list|(
name|p
argument_list|,
name|leadsize
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|p
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|_int_free
argument_list|(
name|av
argument_list|,
name|chunk2mem
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
name|p
operator|=
name|newp
expr_stmt|;
name|assert
argument_list|(
name|newsize
operator|>=
name|nb
operator|&&
operator|(
operator|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|chunk2mem
argument_list|(
name|p
argument_list|)
argument_list|)
operator|)
operator|%
name|alignment
operator|)
operator|==
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/* Also give back spare room at the end */
if|if
condition|(
operator|!
name|chunk_is_mmapped
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|size
operator|=
name|chunksize
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
call|(
name|unsigned
name|long
call|)
argument_list|(
name|size
argument_list|)
operator|>
call|(
name|unsigned
name|long
call|)
argument_list|(
name|nb
operator|+
name|MINSIZE
argument_list|)
condition|)
block|{
name|remainder_size
operator|=
name|size
operator|-
name|nb
expr_stmt|;
name|remainder
operator|=
name|chunk_at_offset
argument_list|(
name|p
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|set_head
argument_list|(
name|remainder
argument_list|,
name|remainder_size
operator||
name|PREV_INUSE
argument_list|)
expr_stmt|;
name|set_head_size
argument_list|(
name|p
argument_list|,
name|nb
argument_list|)
expr_stmt|;
name|set_arena_for_chunk
argument_list|(
name|remainder
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|_int_free
argument_list|(
name|av
argument_list|,
name|chunk2mem
argument_list|(
name|remainder
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|set_arena_for_chunk
argument_list|(
name|p
argument_list|,
name|av
argument_list|)
expr_stmt|;
name|check_inuse_chunk
argument_list|(
name|av
argument_list|,
name|p
argument_list|)
expr_stmt|;
return|return
name|chunk2mem
argument_list|(
name|p
argument_list|)
return|;
block|}
end_function

begin_if
if|#
directive|if
literal|1
end_if

begin_comment
comment|/*   ------------------------------ calloc ------------------------------ */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function
name|Void_t
modifier|*
name|cALLOc
parameter_list|(
name|cvmx_arena_list_t
name|arena_list
parameter_list|,
name|size_t
name|n_elements
parameter_list|,
name|size_t
name|elem_size
parameter_list|)
else|#
directive|else
function|Void_t* cALLOc
parameter_list|(
name|n_elements
parameter_list|,
name|elem_size
parameter_list|)
name|size_t
name|n_elements
decl_stmt|;
name|size_t
name|elem_size
decl_stmt|;
endif|#
directive|endif
block|{
name|mchunkptr
name|p
decl_stmt|;
name|unsigned
name|long
name|clearsize
decl_stmt|;
name|unsigned
name|long
name|nclears
decl_stmt|;
name|INTERNAL_SIZE_T
modifier|*
name|d
decl_stmt|;
name|Void_t
modifier|*
name|mem
init|=
name|public_mALLOc
argument_list|(
name|arena_list
argument_list|,
name|n_elements
operator|*
name|elem_size
argument_list|)
decl_stmt|;
if|if
condition|(
name|mem
operator|!=
literal|0
condition|)
block|{
name|p
operator|=
name|mem2chunk
argument_list|(
name|mem
argument_list|)
expr_stmt|;
block|{
comment|/*         Unroll clear of<= 36 bytes (72 if 8byte sizes)         We know that contents have an odd number of         INTERNAL_SIZE_T-sized words; minimally 3.       */
name|d
operator|=
operator|(
name|INTERNAL_SIZE_T
operator|*
operator|)
name|mem
expr_stmt|;
name|clearsize
operator|=
name|chunksize
argument_list|(
name|p
argument_list|)
operator|-
name|SIZE_SZ
expr_stmt|;
name|nclears
operator|=
name|clearsize
operator|/
sizeof|sizeof
argument_list|(
name|INTERNAL_SIZE_T
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|nclears
operator|>=
literal|3
argument_list|)
expr_stmt|;
if|if
condition|(
name|nclears
operator|>
literal|9
condition|)
name|MALLOC_ZERO
argument_list|(
name|d
argument_list|,
name|clearsize
argument_list|)
expr_stmt|;
else|else
block|{
operator|*
operator|(
name|d
operator|+
literal|0
operator|)
operator|=
literal|0
expr_stmt|;
operator|*
operator|(
name|d
operator|+
literal|1
operator|)
operator|=
literal|0
expr_stmt|;
operator|*
operator|(
name|d
operator|+
literal|2
operator|)
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|nclears
operator|>
literal|4
condition|)
block|{
operator|*
operator|(
name|d
operator|+
literal|3
operator|)
operator|=
literal|0
expr_stmt|;
operator|*
operator|(
name|d
operator|+
literal|4
operator|)
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|nclears
operator|>
literal|6
condition|)
block|{
operator|*
operator|(
name|d
operator|+
literal|5
operator|)
operator|=
literal|0
expr_stmt|;
operator|*
operator|(
name|d
operator|+
literal|6
operator|)
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|nclears
operator|>
literal|8
condition|)
block|{
operator|*
operator|(
name|d
operator|+
literal|7
operator|)
operator|=
literal|0
expr_stmt|;
operator|*
operator|(
name|d
operator|+
literal|8
operator|)
operator|=
literal|0
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
block|}
return|return
name|mem
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*   ------------------------- malloc_usable_size ------------------------- */
end_comment

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_function
name|size_t
name|mUSABLe
parameter_list|(
name|Void_t
modifier|*
name|mem
parameter_list|)
else|#
directive|else
function|size_t mUSABLe
parameter_list|(
name|mem
parameter_list|)
name|Void_t
modifier|*
name|mem
decl_stmt|;
endif|#
directive|endif
block|{
name|mchunkptr
name|p
decl_stmt|;
if|if
condition|(
name|mem
operator|!=
literal|0
condition|)
block|{
name|p
operator|=
name|mem2chunk
argument_list|(
name|mem
argument_list|)
expr_stmt|;
if|if
condition|(
name|chunk_is_mmapped
argument_list|(
name|p
argument_list|)
condition|)
return|return
name|chunksize
argument_list|(
name|p
argument_list|)
operator|-
literal|3
operator|*
name|SIZE_SZ
return|;
comment|/* updated size for adding arena_ptr */
elseif|else
if|if
condition|(
name|inuse
argument_list|(
name|p
argument_list|)
condition|)
return|return
name|chunksize
argument_list|(
name|p
argument_list|)
operator|-
literal|2
operator|*
name|SIZE_SZ
return|;
comment|/* updated size for adding arena_ptr */
block|}
return|return
literal|0
return|;
block|}
end_function

begin_comment
comment|/*   ------------------------------ mallinfo ------------------------------ */
end_comment

begin_function
name|struct
name|mallinfo
name|mALLINFo
parameter_list|(
name|mstate
name|av
parameter_list|)
block|{
name|struct
name|mallinfo
name|mi
decl_stmt|;
name|int
name|i
decl_stmt|;
name|mbinptr
name|b
decl_stmt|;
name|mchunkptr
name|p
decl_stmt|;
name|INTERNAL_SIZE_T
name|avail
decl_stmt|;
name|INTERNAL_SIZE_T
name|fastavail
decl_stmt|;
name|int
name|nblocks
decl_stmt|;
name|int
name|nfastblocks
decl_stmt|;
comment|/* Ensure initialization */
if|if
condition|(
name|av
operator|->
name|top
operator|==
literal|0
condition|)
name|malloc_consolidate
argument_list|(
name|av
argument_list|)
expr_stmt|;
name|check_malloc_state
argument_list|(
name|av
argument_list|)
expr_stmt|;
comment|/* Account for top */
name|avail
operator|=
name|chunksize
argument_list|(
name|av
operator|->
name|top
argument_list|)
expr_stmt|;
name|nblocks
operator|=
literal|1
expr_stmt|;
comment|/* top always exists */
comment|/* traverse fastbins */
name|nfastblocks
operator|=
literal|0
expr_stmt|;
name|fastavail
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NFASTBINS
condition|;
operator|++
name|i
control|)
block|{
for|for
control|(
name|p
operator|=
name|av
operator|->
name|fastbins
index|[
name|i
index|]
init|;
name|p
operator|!=
literal|0
condition|;
name|p
operator|=
name|p
operator|->
name|fd
control|)
block|{
operator|++
name|nfastblocks
expr_stmt|;
name|fastavail
operator|+=
name|chunksize
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
block|}
name|avail
operator|+=
name|fastavail
expr_stmt|;
comment|/* traverse regular bins */
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|NBINS
condition|;
operator|++
name|i
control|)
block|{
name|b
operator|=
name|bin_at
argument_list|(
name|av
argument_list|,
name|i
argument_list|)
expr_stmt|;
for|for
control|(
name|p
operator|=
name|last
argument_list|(
name|b
argument_list|)
init|;
name|p
operator|!=
name|b
condition|;
name|p
operator|=
name|p
operator|->
name|bk
control|)
block|{
operator|++
name|nblocks
expr_stmt|;
name|avail
operator|+=
name|chunksize
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
block|}
name|mi
operator|.
name|smblks
operator|=
name|nfastblocks
expr_stmt|;
name|mi
operator|.
name|ordblks
operator|=
name|nblocks
expr_stmt|;
name|mi
operator|.
name|fordblks
operator|=
name|avail
expr_stmt|;
name|mi
operator|.
name|uordblks
operator|=
name|av
operator|->
name|system_mem
operator|-
name|avail
expr_stmt|;
name|mi
operator|.
name|arena
operator|=
name|av
operator|->
name|system_mem
expr_stmt|;
name|mi
operator|.
name|fsmblks
operator|=
name|fastavail
expr_stmt|;
name|mi
operator|.
name|keepcost
operator|=
name|chunksize
argument_list|(
name|av
operator|->
name|top
argument_list|)
expr_stmt|;
return|return
name|mi
return|;
block|}
end_function

begin_comment
comment|/*   ------------------------------ malloc_stats ------------------------------ */
end_comment

begin_function
name|void
name|mSTATs
parameter_list|()
block|{ }
end_function

begin_comment
comment|/*   ------------------------------ mallopt ------------------------------ */
end_comment

begin_if
if|#
directive|if
literal|0
end_if

begin_if
if|#
directive|if
name|__STD_C
end_if

begin_else
unit|int mALLOPt(int param_number, int value)
else|#
directive|else
end_else

begin_endif
unit|int mALLOPt(param_number, value) int param_number; int value;
endif|#
directive|endif
end_endif

begin_endif
unit|{ }
endif|#
directive|endif
end_endif

begin_comment
comment|/*   -------------------- Alternative MORECORE functions -------------------- */
end_comment

begin_comment
comment|/*   General Requirements for MORECORE.    The MORECORE function must have the following properties:    If MORECORE_CONTIGUOUS is false:      * MORECORE must allocate in multiples of pagesize. It will       only be called with arguments that are multiples of pagesize.      * MORECORE(0) must return an address that is at least       MALLOC_ALIGNMENT aligned. (Page-aligning always suffices.)    else (i.e. If MORECORE_CONTIGUOUS is true):      * Consecutive calls to MORECORE with positive arguments       return increasing addresses, indicating that space has been       contiguously extended.      * MORECORE need not allocate in multiples of pagesize.       Calls to MORECORE need not have args of multiples of pagesize.      * MORECORE need not page-align.    In either case:      * MORECORE may allocate more memory than requested. (Or even less,       but this will generally result in a malloc failure.)      * MORECORE must not allocate memory when given argument zero, but       instead return one past the end address of memory from previous       nonzero call. This malloc does NOT call MORECORE(0)       until at least one call with positive arguments is made, so       the initial value returned is not important.      * Even though consecutive calls to MORECORE need not return contiguous       addresses, it must be OK for malloc'ed chunks to span multiple       regions in those cases where they do happen to be contiguous.      * MORECORE need not handle negative arguments -- it may instead       just return MORECORE_FAILURE when given negative arguments.       Negative arguments are always multiples of pagesize. MORECORE       must not misinterpret negative args as large positive unsigned       args. You can suppress all such calls from even occurring by defining       MORECORE_CANNOT_TRIM,    There is some variation across systems about the type of the   argument to sbrk/MORECORE. If size_t is unsigned, then it cannot   actually be size_t, because sbrk supports negative args, so it is   normally the signed type of the same width as size_t (sometimes   declared as "intptr_t", and sometimes "ptrdiff_t").  It doesn't much   matter though. Internally, we use "long" as arguments, which should   work across all reasonable possibilities.    Additionally, if MORECORE ever returns failure for a positive   request, and HAVE_MMAP is true, then mmap is used as a noncontiguous   system allocator. This is a useful backup strategy for systems with   holes in address spaces -- in this case sbrk cannot contiguously   expand the heap, but mmap may be able to map noncontiguous space.    If you'd like mmap to ALWAYS be used, you can define MORECORE to be   a function that always returns MORECORE_FAILURE.    If you are using this malloc with something other than sbrk (or its   emulation) to supply memory regions, you probably want to set   MORECORE_CONTIGUOUS as false.  As an example, here is a custom   allocator kindly contributed for pre-OSX macOS.  It uses virtually   but not necessarily physically contiguous non-paged memory (locked   in, present and won't get swapped out).  You can use it by   uncommenting this section, adding some #includes, and setting up the   appropriate defines above:        #define MORECORE osMoreCore       #define MORECORE_CONTIGUOUS 0    There is also a shutdown routine that should somehow be called for   cleanup upon program exit.    #define MAX_POOL_ENTRIES 100   #define MINIMUM_MORECORE_SIZE  (64 * 1024)   static int next_os_pool;   void *our_os_pools[MAX_POOL_ENTRIES];    void *osMoreCore(int size)   {     void *ptr = 0;     static void *sbrk_top = 0;      if (size> 0)     {       if (size< MINIMUM_MORECORE_SIZE)          size = MINIMUM_MORECORE_SIZE;       if (CurrentExecutionLevel() == kTaskLevel)          ptr = PoolAllocateResident(size + RM_PAGE_SIZE, 0);       if (ptr == 0)       {         return (void *) MORECORE_FAILURE;       }       // save ptrs so they can be freed during cleanup       our_os_pools[next_os_pool] = ptr;       next_os_pool++;       ptr = (void *) ((((unsigned long) ptr) + RM_PAGE_MASK)& ~RM_PAGE_MASK);       sbrk_top = (char *) ptr + size;       return ptr;     }     else if (size< 0)     {       // we don't currently support shrink behavior       return (void *) MORECORE_FAILURE;     }     else     {       return sbrk_top;     }   }    // cleanup any allocated memory pools   // called as last thing before shutting down driver    void osCleanupMem(void)   {     void **ptr;      for (ptr = our_os_pools; ptr<&our_os_pools[MAX_POOL_ENTRIES]; ptr++)       if (*ptr)       {          PoolDeallocate(*ptr);          *ptr = 0;       }   }  */
end_comment

begin_comment
comment|/* ------------------------------------------------------------ History:  [see ftp://g.oswego.edu/pub/misc/malloc.c for the history of dlmalloc]  */
end_comment

end_unit

