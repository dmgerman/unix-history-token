begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2009-2011 Spectra Logic Corporation  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions, and the following disclaimer,  *    without modification.  * 2. Redistributions in binary form must reproduce at minimum a disclaimer  *    substantially similar to the "NO WARRANTY" disclaimer below  *    ("Disclaimer") and any redistribution must be conditioned upon  *    including a substantially similar Disclaimer requirement for further  *    binary redistribution.  *  * NO WARRANTY  * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS  * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT  * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR  * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT  * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,  * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING  * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE  * POSSIBILITY OF SUCH DAMAGES.  *  * Authors: Justin T. Gibbs     (Spectra Logic Corporation)  *          Ken Merry           (Spectra Logic Corporation)  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/**  * \file blkback.c  *  * \brief Device driver supporting the vending of block storage from  *        a FreeBSD domain to other domains.  */
end_comment

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/bio.h>
end_include

begin_include
include|#
directive|include
file|<sys/bus.h>
end_include

begin_include
include|#
directive|include
file|<sys/conf.h>
end_include

begin_include
include|#
directive|include
file|<sys/devicestat.h>
end_include

begin_include
include|#
directive|include
file|<sys/disk.h>
end_include

begin_include
include|#
directive|include
file|<sys/fcntl.h>
end_include

begin_include
include|#
directive|include
file|<sys/filedesc.h>
end_include

begin_include
include|#
directive|include
file|<sys/kdb.h>
end_include

begin_include
include|#
directive|include
file|<sys/module.h>
end_include

begin_include
include|#
directive|include
file|<sys/namei.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/rman.h>
end_include

begin_include
include|#
directive|include
file|<sys/taskqueue.h>
end_include

begin_include
include|#
directive|include
file|<sys/types.h>
end_include

begin_include
include|#
directive|include
file|<sys/vnode.h>
end_include

begin_include
include|#
directive|include
file|<sys/mount.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/bitstring.h>
end_include

begin_include
include|#
directive|include
file|<geom/geom.h>
end_include

begin_include
include|#
directive|include
file|<machine/_inttypes.h>
end_include

begin_include
include|#
directive|include
file|<machine/xen/xen-os.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<xen/blkif.h>
end_include

begin_include
include|#
directive|include
file|<xen/evtchn.h>
end_include

begin_include
include|#
directive|include
file|<xen/gnttab.h>
end_include

begin_include
include|#
directive|include
file|<xen/xen_intr.h>
end_include

begin_include
include|#
directive|include
file|<xen/interface/event_channel.h>
end_include

begin_include
include|#
directive|include
file|<xen/interface/grant_table.h>
end_include

begin_include
include|#
directive|include
file|<xen/xenbus/xenbusvar.h>
end_include

begin_comment
comment|/*--------------------------- Compile-time Tunables --------------------------*/
end_comment

begin_comment
comment|/**  * The maximum number of outstanding request blocks (request headers plus  * additional segment blocks) we will allow in a negotiated block-front/back  * communication channel.  */
end_comment

begin_define
define|#
directive|define
name|XBB_MAX_REQUESTS
value|256
end_define

begin_comment
comment|/**  * \brief Define to force all I/O to be performed on memory owned by the  *        backend device, with a copy-in/out to the remote domain's memory.  *  * \note  This option is currently required when this driver's domain is  *        operating in HVM mode on a system using an IOMMU.  *  * This driver uses Xen's grant table API to gain access to the memory of  * the remote domains it serves.  When our domain is operating in PV mode,  * the grant table mechanism directly updates our domain's page table entries  * to point to the physical pages of the remote domain.  This scheme guarantees  * that blkback and the backing devices it uses can safely perform DMA  * operations to satisfy requests.  In HVM mode, Xen may use a HW IOMMU to  * insure that our domain cannot DMA to pages owned by another domain.  As  * of Xen 4.0, IOMMU mappings for HVM guests are not updated via the grant  * table API.  For this reason, in HVM mode, we must bounce all requests into  * memory that is mapped into our domain at domain startup and thus has  * valid IOMMU mappings.  */
end_comment

begin_define
define|#
directive|define
name|XBB_USE_BOUNCE_BUFFERS
end_define

begin_comment
comment|/**  * \brief Define to enable rudimentary request logging to the console.  */
end_comment

begin_undef
undef|#
directive|undef
name|XBB_DEBUG
end_undef

begin_comment
comment|/*---------------------------------- Macros ----------------------------------*/
end_comment

begin_comment
comment|/**  * Custom malloc type for all driver allocations.  */
end_comment

begin_expr_stmt
specifier|static
name|MALLOC_DEFINE
argument_list|(
name|M_XENBLOCKBACK
argument_list|,
literal|"xbbd"
argument_list|,
literal|"Xen Block Back Driver Data"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|XBB_DEBUG
end_ifdef

begin_define
define|#
directive|define
name|DPRINTF
parameter_list|(
name|fmt
parameter_list|,
name|args
modifier|...
parameter_list|)
define|\
value|printf("xbb(%s:%d): " fmt, __FUNCTION__, __LINE__, ##args)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|DPRINTF
parameter_list|(
name|fmt
parameter_list|,
name|args
modifier|...
parameter_list|)
value|do {} while(0)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/**  * The maximum mapped region size per request we will allow in a negotiated  * block-front/back communication channel.  */
end_comment

begin_define
define|#
directive|define
name|XBB_MAX_REQUEST_SIZE
define|\
value|MIN(MAXPHYS, BLKIF_MAX_SEGMENTS_PER_REQUEST * PAGE_SIZE)
end_define

begin_comment
comment|/**  * The maximum number of segments (within a request header and accompanying  * segment blocks) per request we will allow in a negotiated block-front/back  * communication channel.  */
end_comment

begin_define
define|#
directive|define
name|XBB_MAX_SEGMENTS_PER_REQUEST
define|\
value|(MIN(UIO_MAXIOV,				\ 	     MIN(BLKIF_MAX_SEGMENTS_PER_REQUEST,	\ 		 (XBB_MAX_REQUEST_SIZE / PAGE_SIZE) + 1)))
end_define

begin_comment
comment|/**  * The maximum number of shared memory ring pages we will allow in a  * negotiated block-front/back communication channel.  Allow enough  * ring space for all requests to be XBB_MAX_REQUEST_SIZE'd.  */
end_comment

begin_define
define|#
directive|define
name|XBB_MAX_RING_PAGES
define|\
value|BLKIF_RING_PAGES(BLKIF_SEGS_TO_BLOCKS(XBB_MAX_SEGMENTS_PER_REQUEST) \ 		       * XBB_MAX_REQUESTS)
end_define

begin_comment
comment|/**  * The maximum number of ring pages that we can allow per request list.  * We limit this to the maximum number of segments per request, because  * that is already a reasonable number of segments to aggregate.  This  * number should never be smaller than XBB_MAX_SEGMENTS_PER_REQUEST,  * because that would leave situations where we can't dispatch even one  * large request.  */
end_comment

begin_define
define|#
directive|define
name|XBB_MAX_SEGMENTS_PER_REQLIST
value|XBB_MAX_SEGMENTS_PER_REQUEST
end_define

begin_comment
comment|/*--------------------------- Forward Declarations ---------------------------*/
end_comment

begin_struct_decl
struct_decl|struct
name|xbb_softc
struct_decl|;
end_struct_decl

begin_struct_decl
struct_decl|struct
name|xbb_xen_req
struct_decl|;
end_struct_decl

begin_function_decl
specifier|static
name|void
name|xbb_attach_failed
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|int
name|err
parameter_list|,
specifier|const
name|char
modifier|*
name|fmt
parameter_list|,
modifier|...
parameter_list|)
function_decl|__attribute__
parameter_list|(
function_decl|(format
parameter_list|(
name|printf
parameter_list|,
function_decl|3
operator|,
function_decl|4
end_function_decl

begin_empty_stmt
unit|)))
empty_stmt|;
end_empty_stmt

begin_function_decl
specifier|static
name|int
name|xbb_shutdown
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|xbb_detach
parameter_list|(
name|device_t
name|dev
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*------------------------------ Data Structures -----------------------------*/
end_comment

begin_expr_stmt
name|STAILQ_HEAD
argument_list|(
name|xbb_xen_req_list
argument_list|,
name|xbb_xen_req
argument_list|)
expr_stmt|;
end_expr_stmt

begin_typedef
typedef|typedef
enum|enum
block|{
name|XBB_REQLIST_NONE
init|=
literal|0x00
block|,
name|XBB_REQLIST_MAPPED
init|=
literal|0x01
block|}
name|xbb_reqlist_flags
typedef|;
end_typedef

begin_struct
struct|struct
name|xbb_xen_reqlist
block|{
comment|/** 	 * Back reference to the parent block back instance for this 	 * request.  Used during bio_done handling. 	 */
name|struct
name|xbb_softc
modifier|*
name|xbb
decl_stmt|;
comment|/** 	 * BLKIF_OP code for this request. 	 */
name|int
name|operation
decl_stmt|;
comment|/** 	 * Set to BLKIF_RSP_* to indicate request status. 	 * 	 * This field allows an error status to be recorded even if the 	 * delivery of this status must be deferred.  Deferred reporting 	 * is necessary, for example, when an error is detected during 	 * completion processing of one bio when other bios for this 	 * request are still outstanding. 	 */
name|int
name|status
decl_stmt|;
comment|/** 	 * Number of 512 byte sectors not transferred. 	 */
name|int
name|residual_512b_sectors
decl_stmt|;
comment|/** 	 * Starting sector number of the first request in the list. 	 */
name|off_t
name|starting_sector_number
decl_stmt|;
comment|/** 	 * If we're going to coalesce, the next contiguous sector would be 	 * this one. 	 */
name|off_t
name|next_contig_sector
decl_stmt|;
comment|/** 	 * Number of child requests in the list. 	 */
name|int
name|num_children
decl_stmt|;
comment|/** 	 * Number of I/O requests dispatched to the backend. 	 */
name|int
name|pendcnt
decl_stmt|;
comment|/** 	 * Total number of segments for requests in the list. 	 */
name|int
name|nr_segments
decl_stmt|;
comment|/** 	 * Flags for this particular request list. 	 */
name|xbb_reqlist_flags
name|flags
decl_stmt|;
comment|/** 	 * Kernel virtual address space reserved for this request 	 * list structure and used to map the remote domain's pages for 	 * this I/O, into our domain's address space. 	 */
name|uint8_t
modifier|*
name|kva
decl_stmt|;
comment|/** 	 * Base, psuedo-physical address, corresponding to the start 	 * of this request's kva region. 	 */
name|uint64_t
name|gnt_base
decl_stmt|;
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
comment|/** 	 * Pre-allocated domain local memory used to proxy remote 	 * domain memory during I/O operations. 	 */
name|uint8_t
modifier|*
name|bounce
decl_stmt|;
endif|#
directive|endif
comment|/** 	 * Array of grant handles (one per page) used to map this request. 	 */
name|grant_handle_t
modifier|*
name|gnt_handles
decl_stmt|;
comment|/** 	 * Device statistics request ordering type (ordered or simple). 	 */
name|devstat_tag_type
name|ds_tag_type
decl_stmt|;
comment|/** 	 * Device statistics request type (read, write, no_data). 	 */
name|devstat_trans_flags
name|ds_trans_type
decl_stmt|;
comment|/** 	 * The start time for this request. 	 */
name|struct
name|bintime
name|ds_t0
decl_stmt|;
comment|/** 	 * Linked list of contiguous requests with the same operation type. 	 */
name|struct
name|xbb_xen_req_list
name|contig_req_list
decl_stmt|;
comment|/** 	 * Linked list links used to aggregate idle requests in the 	 * request list free pool (xbb->reqlist_free_stailq) and pending 	 * requests waiting for execution (xbb->reqlist_pending_stailq). 	 */
name|STAILQ_ENTRY
argument_list|(
argument|xbb_xen_reqlist
argument_list|)
name|links
expr_stmt|;
block|}
struct|;
end_struct

begin_expr_stmt
name|STAILQ_HEAD
argument_list|(
name|xbb_xen_reqlist_list
argument_list|,
name|xbb_xen_reqlist
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/**  * \brief Object tracking an in-flight I/O from a Xen VBD consumer.  */
end_comment

begin_struct
struct|struct
name|xbb_xen_req
block|{
comment|/** 	 * Linked list links used to aggregate requests into a reqlist 	 * and to store them in the request free pool. 	 */
name|STAILQ_ENTRY
argument_list|(
argument|xbb_xen_req
argument_list|)
name|links
expr_stmt|;
comment|/** 	 * The remote domain's identifier for this I/O request. 	 */
name|uint64_t
name|id
decl_stmt|;
comment|/** 	 * The number of pages currently mapped for this request. 	 */
name|int
name|nr_pages
decl_stmt|;
comment|/** 	 * The number of 512 byte sectors comprising this requests. 	 */
name|int
name|nr_512b_sectors
decl_stmt|;
comment|/** 	 * The number of struct bio requests still outstanding for this 	 * request on the backend device.  This field is only used for	 	 * device (rather than file) backed I/O. 	 */
name|int
name|pendcnt
decl_stmt|;
comment|/** 	 * BLKIF_OP code for this request. 	 */
name|int
name|operation
decl_stmt|;
comment|/** 	 * Storage used for non-native ring requests. 	 */
name|blkif_request_t
name|ring_req_storage
decl_stmt|;
comment|/** 	 * Pointer to the Xen request in the ring. 	 */
name|blkif_request_t
modifier|*
name|ring_req
decl_stmt|;
comment|/** 	 * Consumer index for this request. 	 */
name|RING_IDX
name|req_ring_idx
decl_stmt|;
comment|/** 	 * The start time for this request. 	 */
name|struct
name|bintime
name|ds_t0
decl_stmt|;
comment|/** 	 * Pointer back to our parent request list. 	 */
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
decl_stmt|;
block|}
struct|;
end_struct

begin_expr_stmt
name|SLIST_HEAD
argument_list|(
name|xbb_xen_req_slist
argument_list|,
name|xbb_xen_req
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/**  * \brief Configuration data for the shared memory request ring  *        used to communicate with the front-end client of this  *        this driver.  */
end_comment

begin_struct
struct|struct
name|xbb_ring_config
block|{
comment|/** KVA address where ring memory is mapped. */
name|vm_offset_t
name|va
decl_stmt|;
comment|/** The pseudo-physical address where ring memory is mapped.*/
name|uint64_t
name|gnt_addr
decl_stmt|;
comment|/** 	 * Grant table handles, one per-ring page, returned by the 	 * hyperpervisor upon mapping of the ring and required to 	 * unmap it when a connection is torn down. 	 */
name|grant_handle_t
name|handle
index|[
name|XBB_MAX_RING_PAGES
index|]
decl_stmt|;
comment|/** 	 * The device bus address returned by the hypervisor when 	 * mapping the ring and required to unmap it when a connection 	 * is torn down. 	 */
name|uint64_t
name|bus_addr
index|[
name|XBB_MAX_RING_PAGES
index|]
decl_stmt|;
comment|/** The number of ring pages mapped for the current connection. */
name|u_int
name|ring_pages
decl_stmt|;
comment|/** 	 * The grant references, one per-ring page, supplied by the 	 * front-end, allowing us to reference the ring pages in the 	 * front-end's domain and to map these pages into our own domain. 	 */
name|grant_ref_t
name|ring_ref
index|[
name|XBB_MAX_RING_PAGES
index|]
decl_stmt|;
comment|/** The interrupt driven even channel used to signal ring events. */
name|evtchn_port_t
name|evtchn
decl_stmt|;
block|}
struct|;
end_struct

begin_comment
comment|/**  * Per-instance connection state flags.  */
end_comment

begin_typedef
typedef|typedef
enum|enum
block|{
comment|/** 	 * The front-end requested a read-only mount of the 	 * back-end device/file. 	 */
name|XBBF_READ_ONLY
init|=
literal|0x01
block|,
comment|/** Communication with the front-end has been established. */
name|XBBF_RING_CONNECTED
init|=
literal|0x02
block|,
comment|/** 	 * Front-end requests exist in the ring and are waiting for 	 * xbb_xen_req objects to free up. 	 */
name|XBBF_RESOURCE_SHORTAGE
init|=
literal|0x04
block|,
comment|/** Connection teardown in progress. */
name|XBBF_SHUTDOWN
init|=
literal|0x08
block|,
comment|/** A thread is already performing shutdown processing. */
name|XBBF_IN_SHUTDOWN
init|=
literal|0x10
block|}
name|xbb_flag_t
typedef|;
end_typedef

begin_comment
comment|/** Backend device type.  */
end_comment

begin_typedef
typedef|typedef
enum|enum
block|{
comment|/** Backend type unknown. */
name|XBB_TYPE_NONE
init|=
literal|0x00
block|,
comment|/** 	 * Backend type disk (access via cdev switch 	 * strategy routine). 	 */
name|XBB_TYPE_DISK
init|=
literal|0x01
block|,
comment|/** Backend type file (access vnode operations.). */
name|XBB_TYPE_FILE
init|=
literal|0x02
block|}
name|xbb_type
typedef|;
end_typedef

begin_comment
comment|/**  * \brief Structure used to memoize information about a per-request  *        scatter-gather list.  *  * The chief benefit of using this data structure is it avoids having  * to reparse the possibly discontiguous S/G list in the original  * request.  Due to the way that the mapping of the memory backing an  * I/O transaction is handled by Xen, a second pass is unavoidable.  * At least this way the second walk is a simple array traversal.  *  * \note A single Scatter/Gather element in the block interface covers  *       at most 1 machine page.  In this context a sector (blkif  *       nomenclature, not what I'd choose) is a 512b aligned unit  *       of mapping within the machine page referenced by an S/G  *       element.  */
end_comment

begin_struct
struct|struct
name|xbb_sg
block|{
comment|/** The number of 512b data chunks mapped in this S/G element. */
name|int16_t
name|nsect
decl_stmt|;
comment|/** 	 * The index (0 based) of the first 512b data chunk mapped 	 * in this S/G element. 	 */
name|uint8_t
name|first_sect
decl_stmt|;
comment|/** 	 * The index (0 based) of the last 512b data chunk mapped 	 * in this S/G element. 	 */
name|uint8_t
name|last_sect
decl_stmt|;
block|}
struct|;
end_struct

begin_comment
comment|/**  * Character device backend specific configuration data.  */
end_comment

begin_struct
struct|struct
name|xbb_dev_data
block|{
comment|/** Cdev used for device backend access.  */
name|struct
name|cdev
modifier|*
name|cdev
decl_stmt|;
comment|/** Cdev switch used for device backend access.  */
name|struct
name|cdevsw
modifier|*
name|csw
decl_stmt|;
comment|/** Used to hold a reference on opened cdev backend devices. */
name|int
name|dev_ref
decl_stmt|;
block|}
struct|;
end_struct

begin_comment
comment|/**  * File backend specific configuration data.  */
end_comment

begin_struct
struct|struct
name|xbb_file_data
block|{
comment|/** Credentials to use for vnode backed (file based) I/O. */
name|struct
name|ucred
modifier|*
name|cred
decl_stmt|;
comment|/** 	 * \brief Array of io vectors used to process file based I/O. 	 * 	 * Only a single file based request is outstanding per-xbb instance, 	 * so we only need one of these. 	 */
name|struct
name|iovec
name|xiovecs
index|[
name|XBB_MAX_SEGMENTS_PER_REQLIST
index|]
decl_stmt|;
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
comment|/** 	 * \brief Array of io vectors used to handle bouncing of file reads. 	 * 	 * Vnode operations are free to modify uio data during their 	 * exectuion.  In the case of a read with bounce buffering active, 	 * we need some of the data from the original uio in order to 	 * bounce-out the read data.  This array serves as the temporary 	 * storage for this saved data. 	 */
name|struct
name|iovec
name|saved_xiovecs
index|[
name|XBB_MAX_SEGMENTS_PER_REQLIST
index|]
decl_stmt|;
comment|/** 	 * \brief Array of memoized bounce buffer kva offsets used 	 *        in the file based backend. 	 * 	 * Due to the way that the mapping of the memory backing an 	 * I/O transaction is handled by Xen, a second pass through 	 * the request sg elements is unavoidable. We memoize the computed 	 * bounce address here to reduce the cost of the second walk. 	 */
name|void
modifier|*
name|xiovecs_vaddr
index|[
name|XBB_MAX_SEGMENTS_PER_REQLIST
index|]
decl_stmt|;
endif|#
directive|endif
comment|/* XBB_USE_BOUNCE_BUFFERS */
block|}
struct|;
end_struct

begin_comment
comment|/**  * Collection of backend type specific data.  */
end_comment

begin_union
union|union
name|xbb_backend_data
block|{
name|struct
name|xbb_dev_data
name|dev
decl_stmt|;
name|struct
name|xbb_file_data
name|file
decl_stmt|;
block|}
union|;
end_union

begin_comment
comment|/**  * Function signature of backend specific I/O handlers.  */
end_comment

begin_typedef
typedef|typedef
name|int
function_decl|(
modifier|*
name|xbb_dispatch_t
function_decl|)
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|,
name|int
name|operation
parameter_list|,
name|int
name|flags
parameter_list|)
function_decl|;
end_typedef

begin_comment
comment|/**  * Per-instance configuration data.  */
end_comment

begin_struct
struct|struct
name|xbb_softc
block|{
comment|/** 	 * Task-queue used to process I/O requests. 	 */
name|struct
name|taskqueue
modifier|*
name|io_taskqueue
decl_stmt|;
comment|/** 	 * Single "run the request queue" task enqueued 	 * on io_taskqueue. 	 */
name|struct
name|task
name|io_task
decl_stmt|;
comment|/** Device type for this instance. */
name|xbb_type
name|device_type
decl_stmt|;
comment|/** NewBus device corresponding to this instance. */
name|device_t
name|dev
decl_stmt|;
comment|/** Backend specific dispatch routine for this instance. */
name|xbb_dispatch_t
name|dispatch_io
decl_stmt|;
comment|/** The number of requests outstanding on the backend device/file. */
name|int
name|active_request_count
decl_stmt|;
comment|/** Free pool of request tracking structures. */
name|struct
name|xbb_xen_req_list
name|request_free_stailq
decl_stmt|;
comment|/** Array, sized at connection time, of request tracking structures. */
name|struct
name|xbb_xen_req
modifier|*
name|requests
decl_stmt|;
comment|/** Free pool of request list structures. */
name|struct
name|xbb_xen_reqlist_list
name|reqlist_free_stailq
decl_stmt|;
comment|/** List of pending request lists awaiting execution. */
name|struct
name|xbb_xen_reqlist_list
name|reqlist_pending_stailq
decl_stmt|;
comment|/** Array, sized at connection time, of request list structures. */
name|struct
name|xbb_xen_reqlist
modifier|*
name|request_lists
decl_stmt|;
comment|/** 	 * Global pool of kva used for mapping remote domain ring 	 * and I/O transaction data. 	 */
name|vm_offset_t
name|kva
decl_stmt|;
comment|/** Psuedo-physical address corresponding to kva. */
name|uint64_t
name|gnt_base_addr
decl_stmt|;
comment|/** The size of the global kva pool. */
name|int
name|kva_size
decl_stmt|;
comment|/** The size of the KVA area used for request lists. */
name|int
name|reqlist_kva_size
decl_stmt|;
comment|/** The number of pages of KVA used for request lists */
name|int
name|reqlist_kva_pages
decl_stmt|;
comment|/** Bitmap of free KVA pages */
name|bitstr_t
modifier|*
name|kva_free
decl_stmt|;
comment|/** 	 * \brief Cached value of the front-end's domain id. 	 *  	 * This value is used at once for each mapped page in 	 * a transaction.  We cache it to avoid incuring the 	 * cost of an ivar access every time this is needed. 	 */
name|domid_t
name|otherend_id
decl_stmt|;
comment|/** 	 * \brief The blkif protocol abi in effect. 	 * 	 * There are situations where the back and front ends can 	 * have a different, native abi (e.g. intel x86_64 and 	 * 32bit x86 domains on the same machine).  The back-end 	 * always accomodates the front-end's native abi.  That 	 * value is pulled from the XenStore and recorded here. 	 */
name|int
name|abi
decl_stmt|;
comment|/** 	 * \brief The maximum number of requests and request lists allowed 	 *        to be in flight at a time. 	 * 	 * This value is negotiated via the XenStore. 	 */
name|u_int
name|max_requests
decl_stmt|;
comment|/** 	 * \brief The maximum number of segments (1 page per segment) 	 *	  that can be mapped by a request. 	 * 	 * This value is negotiated via the XenStore. 	 */
name|u_int
name|max_request_segments
decl_stmt|;
comment|/** 	 * \brief Maximum number of segments per request list. 	 * 	 * This value is derived from and will generally be larger than 	 * max_request_segments. 	 */
name|u_int
name|max_reqlist_segments
decl_stmt|;
comment|/** 	 * The maximum size of any request to this back-end 	 * device. 	 * 	 * This value is negotiated via the XenStore. 	 */
name|u_int
name|max_request_size
decl_stmt|;
comment|/** 	 * The maximum size of any request list.  This is derived directly 	 * from max_reqlist_segments. 	 */
name|u_int
name|max_reqlist_size
decl_stmt|;
comment|/** Various configuration and state bit flags. */
name|xbb_flag_t
name|flags
decl_stmt|;
comment|/** Ring mapping and interrupt configuration data. */
name|struct
name|xbb_ring_config
name|ring_config
decl_stmt|;
comment|/** Runtime, cross-abi safe, structures for ring access. */
name|blkif_back_rings_t
name|rings
decl_stmt|;
comment|/** IRQ mapping for the communication ring event channel. */
name|int
name|irq
decl_stmt|;
comment|/** 	 * \brief Backend access mode flags (e.g. write, or read-only). 	 * 	 * This value is passed to us by the front-end via the XenStore. 	 */
name|char
modifier|*
name|dev_mode
decl_stmt|;
comment|/** 	 * \brief Backend device type (e.g. "disk", "cdrom", "floppy"). 	 * 	 * This value is passed to us by the front-end via the XenStore. 	 * Currently unused. 	 */
name|char
modifier|*
name|dev_type
decl_stmt|;
comment|/** 	 * \brief Backend device/file identifier. 	 * 	 * This value is passed to us by the front-end via the XenStore. 	 * We expect this to be a POSIX path indicating the file or 	 * device to open. 	 */
name|char
modifier|*
name|dev_name
decl_stmt|;
comment|/** 	 * Vnode corresponding to the backend device node or file 	 * we are acessing. 	 */
name|struct
name|vnode
modifier|*
name|vn
decl_stmt|;
name|union
name|xbb_backend_data
name|backend
decl_stmt|;
comment|/** The native sector size of the backend. */
name|u_int
name|sector_size
decl_stmt|;
comment|/** log2 of sector_size.  */
name|u_int
name|sector_size_shift
decl_stmt|;
comment|/** Size in bytes of the backend device or file.  */
name|off_t
name|media_size
decl_stmt|;
comment|/** 	 * \brief media_size expressed in terms of the backend native 	 *	  sector size. 	 * 	 * (e.g. xbb->media_size>> xbb->sector_size_shift). 	 */
name|uint64_t
name|media_num_sectors
decl_stmt|;
comment|/** 	 * \brief Array of memoized scatter gather data computed during the 	 *	  conversion of blkif ring requests to internal xbb_xen_req 	 *	  structures. 	 * 	 * Ring processing is serialized so we only need one of these. 	 */
name|struct
name|xbb_sg
name|xbb_sgs
index|[
name|XBB_MAX_SEGMENTS_PER_REQLIST
index|]
decl_stmt|;
comment|/** 	 * Temporary grant table map used in xbb_dispatch_io().  When 	 * XBB_MAX_SEGMENTS_PER_REQLIST gets large, keeping this on the 	 * stack could cause a stack overflow. 	 */
name|struct
name|gnttab_map_grant_ref
name|maps
index|[
name|XBB_MAX_SEGMENTS_PER_REQLIST
index|]
decl_stmt|;
comment|/** Mutex protecting per-instance data. */
name|struct
name|mtx
name|lock
decl_stmt|;
ifdef|#
directive|ifdef
name|XENHVM
comment|/** 	 * Resource representing allocated physical address space 	 * associated with our per-instance kva region. 	 */
name|struct
name|resource
modifier|*
name|pseudo_phys_res
decl_stmt|;
comment|/** Resource id for allocated physical address space. */
name|int
name|pseudo_phys_res_id
decl_stmt|;
endif|#
directive|endif
comment|/** 	 * I/O statistics from BlockBack dispatch down.  These are 	 * coalesced requests, and we start them right before execution. 	 */
name|struct
name|devstat
modifier|*
name|xbb_stats
decl_stmt|;
comment|/** 	 * I/O statistics coming into BlockBack.  These are the requests as 	 * we get them from BlockFront.  They are started as soon as we 	 * receive a request, and completed when the I/O is complete. 	 */
name|struct
name|devstat
modifier|*
name|xbb_stats_in
decl_stmt|;
comment|/** Disable sending flush to the backend */
name|int
name|disable_flush
decl_stmt|;
comment|/** Send a real flush for every N flush requests */
name|int
name|flush_interval
decl_stmt|;
comment|/** Count of flush requests in the interval */
name|int
name|flush_count
decl_stmt|;
comment|/** Don't coalesce requests if this is set */
name|int
name|no_coalesce_reqs
decl_stmt|;
comment|/** Number of requests we have received */
name|uint64_t
name|reqs_received
decl_stmt|;
comment|/** Number of requests we have completed*/
name|uint64_t
name|reqs_completed
decl_stmt|;
comment|/** How many forced dispatches (i.e. without coalescing) have happend */
name|uint64_t
name|forced_dispatch
decl_stmt|;
comment|/** How many normal dispatches have happend */
name|uint64_t
name|normal_dispatch
decl_stmt|;
comment|/** How many total dispatches have happend */
name|uint64_t
name|total_dispatch
decl_stmt|;
comment|/** How many times we have run out of KVA */
name|uint64_t
name|kva_shortages
decl_stmt|;
comment|/** How many times we have run out of request structures */
name|uint64_t
name|request_shortages
decl_stmt|;
block|}
struct|;
end_struct

begin_comment
comment|/*---------------------------- Request Processing ----------------------------*/
end_comment

begin_comment
comment|/**  * Allocate an internal transaction tracking structure from the free pool.  *  * \param xbb  Per-instance xbb configuration structure.  *  * \return  On success, a pointer to the allocated xbb_xen_req structure.  *          Otherwise NULL.  */
end_comment

begin_function
specifier|static
specifier|inline
name|struct
name|xbb_xen_req
modifier|*
name|xbb_get_req
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|struct
name|xbb_xen_req
modifier|*
name|req
decl_stmt|;
name|req
operator|=
name|NULL
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|req
operator|=
name|STAILQ_FIRST
argument_list|(
operator|&
name|xbb
operator|->
name|request_free_stailq
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|STAILQ_REMOVE_HEAD
argument_list|(
operator|&
name|xbb
operator|->
name|request_free_stailq
argument_list|,
name|links
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|active_request_count
operator|++
expr_stmt|;
block|}
return|return
operator|(
name|req
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Return an allocated transaction tracking structure to the free pool.  *  * \param xbb  Per-instance xbb configuration structure.  * \param req  The request structure to free.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|xbb_release_req
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|struct
name|xbb_xen_req
modifier|*
name|req
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|STAILQ_INSERT_HEAD
argument_list|(
operator|&
name|xbb
operator|->
name|request_free_stailq
argument_list|,
name|req
argument_list|,
name|links
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|active_request_count
operator|--
expr_stmt|;
name|KASSERT
argument_list|(
name|xbb
operator|->
name|active_request_count
operator|>=
literal|0
argument_list|,
operator|(
literal|"xbb_release_req: negative active count"
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Return an xbb_xen_req_list of allocated xbb_xen_reqs to the free pool.  *  * \param xbb	    Per-instance xbb configuration structure.  * \param req_list  The list of requests to free.  * \param nreqs	    The number of items in the list.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|xbb_release_reqs
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|struct
name|xbb_xen_req_list
modifier|*
name|req_list
parameter_list|,
name|int
name|nreqs
parameter_list|)
block|{
name|mtx_assert
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|STAILQ_CONCAT
argument_list|(
operator|&
name|xbb
operator|->
name|request_free_stailq
argument_list|,
name|req_list
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|active_request_count
operator|-=
name|nreqs
expr_stmt|;
name|KASSERT
argument_list|(
name|xbb
operator|->
name|active_request_count
operator|>=
literal|0
argument_list|,
operator|(
literal|"xbb_release_reqs: negative active count"
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Given a page index and 512b sector offset within that page,  * calculate an offset into a request's kva region.  *  * \param reqlist The request structure whose kva region will be accessed.  * \param pagenr  The page index used to compute the kva offset.  * \param sector  The 512b sector index used to compute the page relative  *                kva offset.  *  * \return  The computed global KVA offset.  */
end_comment

begin_function
specifier|static
specifier|inline
name|uint8_t
modifier|*
name|xbb_reqlist_vaddr
parameter_list|(
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|,
name|int
name|pagenr
parameter_list|,
name|int
name|sector
parameter_list|)
block|{
return|return
operator|(
name|reqlist
operator|->
name|kva
operator|+
operator|(
name|PAGE_SIZE
operator|*
name|pagenr
operator|)
operator|+
operator|(
name|sector
operator|<<
literal|9
operator|)
operator|)
return|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
end_ifdef

begin_comment
comment|/**  * Given a page index and 512b sector offset within that page,  * calculate an offset into a request's local bounce memory region.  *  * \param reqlist The request structure whose bounce region will be accessed.  * \param pagenr  The page index used to compute the bounce offset.  * \param sector  The 512b sector index used to compute the page relative  *                bounce offset.  *  * \return  The computed global bounce buffer address.  */
end_comment

begin_function
specifier|static
specifier|inline
name|uint8_t
modifier|*
name|xbb_reqlist_bounce_addr
parameter_list|(
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|,
name|int
name|pagenr
parameter_list|,
name|int
name|sector
parameter_list|)
block|{
return|return
operator|(
name|reqlist
operator|->
name|bounce
operator|+
operator|(
name|PAGE_SIZE
operator|*
name|pagenr
operator|)
operator|+
operator|(
name|sector
operator|<<
literal|9
operator|)
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/**  * Given a page number and 512b sector offset within that page,  * calculate an offset into the request's memory region that the  * underlying backend device/file should use for I/O.  *  * \param reqlist The request structure whose I/O region will be accessed.  * \param pagenr  The page index used to compute the I/O offset.  * \param sector  The 512b sector index used to compute the page relative  *                I/O offset.  *  * \return  The computed global I/O address.  *  * Depending on configuration, this will either be a local bounce buffer  * or a pointer to the memory mapped in from the front-end domain for  * this request.  */
end_comment

begin_function
specifier|static
specifier|inline
name|uint8_t
modifier|*
name|xbb_reqlist_ioaddr
parameter_list|(
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|,
name|int
name|pagenr
parameter_list|,
name|int
name|sector
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
return|return
operator|(
name|xbb_reqlist_bounce_addr
argument_list|(
name|reqlist
argument_list|,
name|pagenr
argument_list|,
name|sector
argument_list|)
operator|)
return|;
else|#
directive|else
return|return
operator|(
name|xbb_reqlist_vaddr
argument_list|(
name|reqlist
argument_list|,
name|pagenr
argument_list|,
name|sector
argument_list|)
operator|)
return|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/**  * Given a page index and 512b sector offset within that page, calculate  * an offset into the local psuedo-physical address space used to map a  * front-end's request data into a request.  *  * \param reqlist The request list structure whose pseudo-physical region  *                will be accessed.  * \param pagenr  The page index used to compute the pseudo-physical offset.  * \param sector  The 512b sector index used to compute the page relative  *                pseudo-physical offset.  *  * \return  The computed global pseudo-phsyical address.  *  * Depending on configuration, this will either be a local bounce buffer  * or a pointer to the memory mapped in from the front-end domain for  * this request.  */
end_comment

begin_function
specifier|static
specifier|inline
name|uintptr_t
name|xbb_get_gntaddr
parameter_list|(
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|,
name|int
name|pagenr
parameter_list|,
name|int
name|sector
parameter_list|)
block|{
name|struct
name|xbb_softc
modifier|*
name|xbb
decl_stmt|;
name|xbb
operator|=
name|reqlist
operator|->
name|xbb
expr_stmt|;
return|return
operator|(
call|(
name|uintptr_t
call|)
argument_list|(
name|xbb
operator|->
name|gnt_base_addr
operator|+
call|(
name|uintptr_t
call|)
argument_list|(
name|reqlist
operator|->
name|kva
operator|-
name|xbb
operator|->
name|kva
argument_list|)
operator|+
operator|(
name|PAGE_SIZE
operator|*
name|pagenr
operator|)
operator|+
operator|(
name|sector
operator|<<
literal|9
operator|)
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Get Kernel Virtual Address space for mapping requests.  *  * \param xbb         Per-instance xbb configuration structure.  * \param nr_pages    Number of pages needed.  * \param check_only  If set, check for free KVA but don't allocate it.  * \param have_lock   If set, xbb lock is already held.  *  * \return  On success, a pointer to the allocated KVA region.  Otherwise NULL.  *  * Note:  This should be unnecessary once we have either chaining or  * scatter/gather support for struct bio.  At that point we'll be able to  * put multiple addresses and lengths in one bio/bio chain and won't need  * to map everything into one virtual segment.  */
end_comment

begin_function
specifier|static
name|uint8_t
modifier|*
name|xbb_get_kva
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|int
name|nr_pages
parameter_list|)
block|{
name|intptr_t
name|first_clear
decl_stmt|,
name|num_clear
decl_stmt|;
name|uint8_t
modifier|*
name|free_kva
decl_stmt|;
name|int
name|i
decl_stmt|;
name|KASSERT
argument_list|(
name|nr_pages
operator|!=
literal|0
argument_list|,
operator|(
literal|"xbb_get_kva of zero length"
operator|)
argument_list|)
expr_stmt|;
name|first_clear
operator|=
literal|0
expr_stmt|;
name|free_kva
operator|=
name|NULL
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
comment|/* 	 * Look for the first available page.  If there are none, we're done. 	 */
name|bit_ffc
argument_list|(
name|xbb
operator|->
name|kva_free
argument_list|,
name|xbb
operator|->
name|reqlist_kva_pages
argument_list|,
operator|&
name|first_clear
argument_list|)
expr_stmt|;
if|if
condition|(
name|first_clear
operator|==
operator|-
literal|1
condition|)
goto|goto
name|bailout
goto|;
comment|/* 	 * Starting at the first available page, look for consecutive free 	 * pages that will satisfy the user's request. 	 */
for|for
control|(
name|i
operator|=
name|first_clear
operator|,
name|num_clear
operator|=
literal|0
init|;
name|i
operator|<
name|xbb
operator|->
name|reqlist_kva_pages
condition|;
name|i
operator|++
control|)
block|{
comment|/* 		 * If this is true, the page is used, so we have to reset 		 * the number of clear pages and the first clear page 		 * (since it pointed to a region with an insufficient number 		 * of clear pages). 		 */
if|if
condition|(
name|bit_test
argument_list|(
name|xbb
operator|->
name|kva_free
argument_list|,
name|i
argument_list|)
condition|)
block|{
name|num_clear
operator|=
literal|0
expr_stmt|;
name|first_clear
operator|=
operator|-
literal|1
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|first_clear
operator|==
operator|-
literal|1
condition|)
name|first_clear
operator|=
name|i
expr_stmt|;
comment|/* 		 * If this is true, we've found a large enough free region 		 * to satisfy the request. 		 */
if|if
condition|(
operator|++
name|num_clear
operator|==
name|nr_pages
condition|)
block|{
name|bit_nset
argument_list|(
name|xbb
operator|->
name|kva_free
argument_list|,
name|first_clear
argument_list|,
name|first_clear
operator|+
name|nr_pages
operator|-
literal|1
argument_list|)
expr_stmt|;
name|free_kva
operator|=
name|xbb
operator|->
name|kva
operator|+
operator|(
name|uint8_t
operator|*
operator|)
operator|(
name|first_clear
operator|*
name|PAGE_SIZE
operator|)
expr_stmt|;
name|KASSERT
argument_list|(
name|free_kva
operator|>=
operator|(
name|uint8_t
operator|*
operator|)
name|xbb
operator|->
name|kva
operator|&&
name|free_kva
operator|+
operator|(
name|nr_pages
operator|*
name|PAGE_SIZE
operator|)
operator|<=
operator|(
name|uint8_t
operator|*
operator|)
name|xbb
operator|->
name|ring_config
operator|.
name|va
argument_list|,
operator|(
literal|"Free KVA %p len %d out of range, "
literal|"kva = %#jx, ring VA = %#jx\n"
operator|,
name|free_kva
operator|,
name|nr_pages
operator|*
name|PAGE_SIZE
operator|,
operator|(
name|uintmax_t
operator|)
name|xbb
operator|->
name|kva
operator|,
operator|(
name|uintmax_t
operator|)
name|xbb
operator|->
name|ring_config
operator|.
name|va
operator|)
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
name|bailout
label|:
if|if
condition|(
name|free_kva
operator|==
name|NULL
condition|)
block|{
name|xbb
operator|->
name|flags
operator||=
name|XBBF_RESOURCE_SHORTAGE
expr_stmt|;
name|xbb
operator|->
name|kva_shortages
operator|++
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|free_kva
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Free allocated KVA.  *  * \param xbb	    Per-instance xbb configuration structure.  * \param kva_ptr   Pointer to allocated KVA region.    * \param nr_pages  Number of pages in the KVA region.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_free_kva
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|uint8_t
modifier|*
name|kva_ptr
parameter_list|,
name|int
name|nr_pages
parameter_list|)
block|{
name|intptr_t
name|start_page
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|start_page
operator|=
call|(
name|intptr_t
call|)
argument_list|(
name|kva_ptr
operator|-
name|xbb
operator|->
name|kva
argument_list|)
operator|>>
name|PAGE_SHIFT
expr_stmt|;
name|bit_nclear
argument_list|(
name|xbb
operator|->
name|kva_free
argument_list|,
name|start_page
argument_list|,
name|start_page
operator|+
name|nr_pages
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Unmap the front-end pages associated with this I/O request.  *  * \param req  The request structure to unmap.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_unmap_reqlist
parameter_list|(
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|)
block|{
name|struct
name|gnttab_unmap_grant_ref
name|unmap
index|[
name|XBB_MAX_SEGMENTS_PER_REQLIST
index|]
decl_stmt|;
name|u_int
name|i
decl_stmt|;
name|u_int
name|invcount
decl_stmt|;
name|int
name|error
decl_stmt|;
name|invcount
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|reqlist
operator|->
name|nr_segments
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|reqlist
operator|->
name|gnt_handles
index|[
name|i
index|]
operator|==
name|GRANT_REF_INVALID
condition|)
continue|continue;
name|unmap
index|[
name|invcount
index|]
operator|.
name|host_addr
operator|=
name|xbb_get_gntaddr
argument_list|(
name|reqlist
argument_list|,
name|i
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|unmap
index|[
name|invcount
index|]
operator|.
name|dev_bus_addr
operator|=
literal|0
expr_stmt|;
name|unmap
index|[
name|invcount
index|]
operator|.
name|handle
operator|=
name|reqlist
operator|->
name|gnt_handles
index|[
name|i
index|]
expr_stmt|;
name|reqlist
operator|->
name|gnt_handles
index|[
name|i
index|]
operator|=
name|GRANT_REF_INVALID
expr_stmt|;
name|invcount
operator|++
expr_stmt|;
block|}
name|error
operator|=
name|HYPERVISOR_grant_table_op
argument_list|(
name|GNTTABOP_unmap_grant_ref
argument_list|,
name|unmap
argument_list|,
name|invcount
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|error
operator|==
literal|0
argument_list|,
operator|(
literal|"Grant table operation failed"
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Allocate an internal transaction tracking structure from the free pool.  *  * \param xbb  Per-instance xbb configuration structure.  *  * \return  On success, a pointer to the allocated xbb_xen_reqlist structure.  *          Otherwise NULL.  */
end_comment

begin_function
specifier|static
specifier|inline
name|struct
name|xbb_xen_reqlist
modifier|*
name|xbb_get_reqlist
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
decl_stmt|;
name|reqlist
operator|=
name|NULL
expr_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|reqlist
operator|=
name|STAILQ_FIRST
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_free_stailq
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|STAILQ_REMOVE_HEAD
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_free_stailq
argument_list|,
name|links
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|flags
operator|=
name|XBB_REQLIST_NONE
expr_stmt|;
name|reqlist
operator|->
name|kva
operator|=
name|NULL
expr_stmt|;
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_OKAY
expr_stmt|;
name|reqlist
operator|->
name|residual_512b_sectors
operator|=
literal|0
expr_stmt|;
name|reqlist
operator|->
name|num_children
operator|=
literal|0
expr_stmt|;
name|reqlist
operator|->
name|nr_segments
operator|=
literal|0
expr_stmt|;
name|STAILQ_INIT
argument_list|(
operator|&
name|reqlist
operator|->
name|contig_req_list
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|reqlist
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Return an allocated transaction tracking structure to the free pool.  *  * \param xbb        Per-instance xbb configuration structure.  * \param req        The request list structure to free.  * \param wakeup     If set, wakeup the work thread if freeing this reqlist  *                   during a resource shortage condition.  */
end_comment

begin_function
specifier|static
specifier|inline
name|void
name|xbb_release_reqlist
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|,
name|int
name|wakeup
parameter_list|)
block|{
name|mtx_lock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|wakeup
condition|)
block|{
name|wakeup
operator|=
name|xbb
operator|->
name|flags
operator|&
name|XBBF_RESOURCE_SHORTAGE
expr_stmt|;
name|xbb
operator|->
name|flags
operator|&=
operator|~
name|XBBF_RESOURCE_SHORTAGE
expr_stmt|;
block|}
if|if
condition|(
name|reqlist
operator|->
name|kva
operator|!=
name|NULL
condition|)
name|xbb_free_kva
argument_list|(
name|xbb
argument_list|,
name|reqlist
operator|->
name|kva
argument_list|,
name|reqlist
operator|->
name|nr_segments
argument_list|)
expr_stmt|;
name|xbb_release_reqs
argument_list|(
name|xbb
argument_list|,
operator|&
name|reqlist
operator|->
name|contig_req_list
argument_list|,
name|reqlist
operator|->
name|num_children
argument_list|)
expr_stmt|;
name|STAILQ_INSERT_TAIL
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_free_stailq
argument_list|,
name|reqlist
argument_list|,
name|links
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|xbb
operator|->
name|flags
operator|&
name|XBBF_SHUTDOWN
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * Shutdown is in progress.  See if we can 		 * progress further now that one more request 		 * has completed and been returned to the 		 * free pool. 		 */
name|xbb_shutdown
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|wakeup
operator|!=
literal|0
condition|)
name|taskqueue_enqueue
argument_list|(
name|xbb
operator|->
name|io_taskqueue
argument_list|,
operator|&
name|xbb
operator|->
name|io_task
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Request resources and do basic request setup.  *  * \param xbb          Per-instance xbb configuration structure.  * \param reqlist      Pointer to reqlist pointer.  * \param ring_req     Pointer to a block ring request.  * \param ring_index   The ring index of this request.  *  * \return  0 for success, non-zero for failure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_get_resources
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|struct
name|xbb_xen_reqlist
modifier|*
modifier|*
name|reqlist
parameter_list|,
name|blkif_request_t
modifier|*
name|ring_req
parameter_list|,
name|RING_IDX
name|ring_idx
parameter_list|)
block|{
name|struct
name|xbb_xen_reqlist
modifier|*
name|nreqlist
decl_stmt|;
name|struct
name|xbb_xen_req
modifier|*
name|nreq
decl_stmt|;
name|nreqlist
operator|=
name|NULL
expr_stmt|;
name|nreq
operator|=
name|NULL
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
comment|/* 	 * We don't allow new resources to be allocated if we're in the 	 * process of shutting down. 	 */
if|if
condition|(
operator|(
name|xbb
operator|->
name|flags
operator|&
name|XBBF_SHUTDOWN
operator|)
operator|!=
literal|0
condition|)
block|{
name|mtx_unlock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
comment|/* 	 * Allocate a reqlist if the caller doesn't have one already. 	 */
if|if
condition|(
operator|*
name|reqlist
operator|==
name|NULL
condition|)
block|{
name|nreqlist
operator|=
name|xbb_get_reqlist
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
if|if
condition|(
name|nreqlist
operator|==
name|NULL
condition|)
goto|goto
name|bailout_error
goto|;
block|}
comment|/* We always allocate a request. */
name|nreq
operator|=
name|xbb_get_req
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
if|if
condition|(
name|nreq
operator|==
name|NULL
condition|)
goto|goto
name|bailout_error
goto|;
name|mtx_unlock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|reqlist
operator|==
name|NULL
condition|)
block|{
operator|*
name|reqlist
operator|=
name|nreqlist
expr_stmt|;
name|nreqlist
operator|->
name|operation
operator|=
name|ring_req
operator|->
name|operation
expr_stmt|;
name|nreqlist
operator|->
name|starting_sector_number
operator|=
name|ring_req
operator|->
name|sector_number
expr_stmt|;
name|STAILQ_INSERT_TAIL
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_pending_stailq
argument_list|,
name|nreqlist
argument_list|,
name|links
argument_list|)
expr_stmt|;
block|}
name|nreq
operator|->
name|reqlist
operator|=
operator|*
name|reqlist
expr_stmt|;
name|nreq
operator|->
name|req_ring_idx
operator|=
name|ring_idx
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|abi
operator|!=
name|BLKIF_PROTOCOL_NATIVE
condition|)
block|{
name|bcopy
argument_list|(
name|ring_req
argument_list|,
operator|&
name|nreq
operator|->
name|ring_req_storage
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|ring_req
argument_list|)
argument_list|)
expr_stmt|;
name|nreq
operator|->
name|ring_req
operator|=
operator|&
name|nreq
operator|->
name|ring_req_storage
expr_stmt|;
block|}
else|else
block|{
name|nreq
operator|->
name|ring_req
operator|=
name|ring_req
expr_stmt|;
block|}
name|binuptime
argument_list|(
operator|&
name|nreq
operator|->
name|ds_t0
argument_list|)
expr_stmt|;
name|devstat_start_transaction
argument_list|(
name|xbb
operator|->
name|xbb_stats_in
argument_list|,
operator|&
name|nreq
operator|->
name|ds_t0
argument_list|)
expr_stmt|;
name|STAILQ_INSERT_TAIL
argument_list|(
operator|&
operator|(
operator|*
name|reqlist
operator|)
operator|->
name|contig_req_list
argument_list|,
name|nreq
argument_list|,
name|links
argument_list|)
expr_stmt|;
operator|(
operator|*
name|reqlist
operator|)
operator|->
name|num_children
operator|++
expr_stmt|;
operator|(
operator|*
name|reqlist
operator|)
operator|->
name|nr_segments
operator|+=
name|ring_req
operator|->
name|nr_segments
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
name|bailout_error
label|:
comment|/* 	 * We're out of resources, so set the shortage flag.  The next time 	 * a request is released, we'll try waking up the work thread to 	 * see if we can allocate more resources. 	 */
name|xbb
operator|->
name|flags
operator||=
name|XBBF_RESOURCE_SHORTAGE
expr_stmt|;
name|xbb
operator|->
name|request_shortages
operator|++
expr_stmt|;
if|if
condition|(
name|nreq
operator|!=
name|NULL
condition|)
name|xbb_release_req
argument_list|(
name|xbb
argument_list|,
name|nreq
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|nreqlist
operator|!=
name|NULL
condition|)
name|xbb_release_reqlist
argument_list|(
name|xbb
argument_list|,
name|nreqlist
argument_list|,
comment|/*wakeup*/
literal|0
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Create and transmit a response to a blkif request.  *   * \param xbb     Per-instance xbb configuration structure.  * \param req     The request structure to which to respond.  * \param status  The status code to report.  See BLKIF_RSP_*  *                in sys/xen/interface/io/blkif.h.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_send_response
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|struct
name|xbb_xen_req
modifier|*
name|req
parameter_list|,
name|int
name|status
parameter_list|)
block|{
name|blkif_response_t
modifier|*
name|resp
decl_stmt|;
name|int
name|more_to_do
decl_stmt|;
name|int
name|notify
decl_stmt|;
name|more_to_do
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Place on the response ring for the relevant domain. 	 * For now, only the spacing between entries is different 	 * in the different ABIs, not the response entry layout. 	 */
name|mtx_lock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|xbb
operator|->
name|abi
condition|)
block|{
case|case
name|BLKIF_PROTOCOL_NATIVE
case|:
name|resp
operator|=
name|RING_GET_RESPONSE
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|native
argument_list|,
name|xbb
operator|->
name|rings
operator|.
name|native
operator|.
name|rsp_prod_pvt
argument_list|)
expr_stmt|;
break|break;
case|case
name|BLKIF_PROTOCOL_X86_32
case|:
name|resp
operator|=
operator|(
name|blkif_response_t
operator|*
operator|)
name|RING_GET_RESPONSE
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|x86_32
argument_list|,
name|xbb
operator|->
name|rings
operator|.
name|x86_32
operator|.
name|rsp_prod_pvt
argument_list|)
expr_stmt|;
break|break;
case|case
name|BLKIF_PROTOCOL_X86_64
case|:
name|resp
operator|=
operator|(
name|blkif_response_t
operator|*
operator|)
name|RING_GET_RESPONSE
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|x86_64
argument_list|,
name|xbb
operator|->
name|rings
operator|.
name|x86_64
operator|.
name|rsp_prod_pvt
argument_list|)
expr_stmt|;
break|break;
default|default:
name|panic
argument_list|(
literal|"Unexpected blkif protocol ABI."
argument_list|)
expr_stmt|;
block|}
name|resp
operator|->
name|id
operator|=
name|req
operator|->
name|id
expr_stmt|;
name|resp
operator|->
name|operation
operator|=
name|req
operator|->
name|operation
expr_stmt|;
name|resp
operator|->
name|status
operator|=
name|status
expr_stmt|;
name|xbb
operator|->
name|rings
operator|.
name|common
operator|.
name|rsp_prod_pvt
operator|+=
name|BLKIF_SEGS_TO_BLOCKS
argument_list|(
name|req
operator|->
name|nr_pages
argument_list|)
expr_stmt|;
name|RING_PUSH_RESPONSES_AND_CHECK_NOTIFY
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|common
argument_list|,
name|notify
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|rings
operator|.
name|common
operator|.
name|rsp_prod_pvt
operator|==
name|xbb
operator|->
name|rings
operator|.
name|common
operator|.
name|req_cons
condition|)
block|{
comment|/* 		 * Tail check for pending requests. Allows frontend to avoid 		 * notifications if requests are already in flight (lower 		 * overheads and promotes batching). 		 */
name|RING_FINAL_CHECK_FOR_REQUESTS
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|common
argument_list|,
name|more_to_do
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|RING_HAS_UNCONSUMED_REQUESTS
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|common
argument_list|)
condition|)
block|{
name|more_to_do
operator|=
literal|1
expr_stmt|;
block|}
name|xbb
operator|->
name|reqs_completed
operator|++
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|more_to_do
condition|)
name|taskqueue_enqueue
argument_list|(
name|xbb
operator|->
name|io_taskqueue
argument_list|,
operator|&
name|xbb
operator|->
name|io_task
argument_list|)
expr_stmt|;
if|if
condition|(
name|notify
condition|)
name|notify_remote_via_irq
argument_list|(
name|xbb
operator|->
name|irq
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Complete a request list.  *  * \param xbb        Per-instance xbb configuration structure.  * \param reqlist    Allocated internal request list structure.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_complete_reqlist
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|)
block|{
name|struct
name|xbb_xen_req
modifier|*
name|nreq
decl_stmt|;
name|off_t
name|sectors_sent
decl_stmt|;
name|sectors_sent
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|reqlist
operator|->
name|flags
operator|&
name|XBB_REQLIST_MAPPED
condition|)
name|xbb_unmap_reqlist
argument_list|(
name|reqlist
argument_list|)
expr_stmt|;
comment|/* 	 * All I/O is done, send the response.  A lock should not be 	 * necessary here because the request list is complete, and 	 * therefore this is the only context accessing this request 	 * right now.  The functions we call do their own locking if 	 * necessary. 	 */
name|STAILQ_FOREACH
argument_list|(
argument|nreq
argument_list|,
argument|&reqlist->contig_req_list
argument_list|,
argument|links
argument_list|)
block|{
name|off_t
name|cur_sectors_sent
decl_stmt|;
name|xbb_send_response
argument_list|(
name|xbb
argument_list|,
name|nreq
argument_list|,
name|reqlist
operator|->
name|status
argument_list|)
expr_stmt|;
comment|/* We don't report bytes sent if there is an error. */
if|if
condition|(
name|reqlist
operator|->
name|status
operator|==
name|BLKIF_RSP_OKAY
condition|)
name|cur_sectors_sent
operator|=
name|nreq
operator|->
name|nr_512b_sectors
expr_stmt|;
else|else
name|cur_sectors_sent
operator|=
literal|0
expr_stmt|;
name|sectors_sent
operator|+=
name|cur_sectors_sent
expr_stmt|;
name|devstat_end_transaction
argument_list|(
name|xbb
operator|->
name|xbb_stats_in
argument_list|,
comment|/*bytes*/
name|cur_sectors_sent
operator|<<
literal|9
argument_list|,
name|reqlist
operator|->
name|ds_tag_type
argument_list|,
name|reqlist
operator|->
name|ds_trans_type
argument_list|,
comment|/*now*/
name|NULL
argument_list|,
comment|/*then*/
operator|&
name|nreq
operator|->
name|ds_t0
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Take out any sectors not sent.  If we wind up negative (which 	 * might happen if an error is reported as well as a residual), just 	 * report 0 sectors sent. 	 */
name|sectors_sent
operator|-=
name|reqlist
operator|->
name|residual_512b_sectors
expr_stmt|;
if|if
condition|(
name|sectors_sent
operator|<
literal|0
condition|)
name|sectors_sent
operator|=
literal|0
expr_stmt|;
name|devstat_end_transaction
argument_list|(
name|xbb
operator|->
name|xbb_stats
argument_list|,
comment|/*bytes*/
name|sectors_sent
operator|<<
literal|9
argument_list|,
name|reqlist
operator|->
name|ds_tag_type
argument_list|,
name|reqlist
operator|->
name|ds_trans_type
argument_list|,
comment|/*now*/
name|NULL
argument_list|,
comment|/*then*/
operator|&
name|reqlist
operator|->
name|ds_t0
argument_list|)
expr_stmt|;
name|xbb_release_reqlist
argument_list|(
name|xbb
argument_list|,
name|reqlist
argument_list|,
comment|/*wakeup*/
literal|1
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Completion handler for buffer I/O requests issued by the device  * backend driver.  *  * \param bio  The buffer I/O request on which to perform completion  *             processing.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_bio_done
parameter_list|(
name|struct
name|bio
modifier|*
name|bio
parameter_list|)
block|{
name|struct
name|xbb_softc
modifier|*
name|xbb
decl_stmt|;
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
decl_stmt|;
name|reqlist
operator|=
name|bio
operator|->
name|bio_caller1
expr_stmt|;
name|xbb
operator|=
name|reqlist
operator|->
name|xbb
expr_stmt|;
name|reqlist
operator|->
name|residual_512b_sectors
operator|+=
name|bio
operator|->
name|bio_resid
operator|>>
literal|9
expr_stmt|;
comment|/* 	 * This is a bit imprecise.  With aggregated I/O a single 	 * request list can contain multiple front-end requests and 	 * a multiple bios may point to a single request.  By carefully 	 * walking the request list, we could map residuals and errors 	 * back to the original front-end request, but the interface 	 * isn't sufficiently rich for us to properly report the error. 	 * So, we just treat the entire request list as having failed if an 	 * error occurs on any part.  And, if an error occurs, we treat 	 * the amount of data transferred as 0. 	 * 	 * For residuals, we report it on the overall aggregated device, 	 * but not on the individual requests, since we don't currently 	 * do the work to determine which front-end request to which the 	 * residual applies. 	 */
if|if
condition|(
name|bio
operator|->
name|bio_error
condition|)
block|{
name|DPRINTF
argument_list|(
literal|"BIO returned error %d for operation on device %s\n"
argument_list|,
name|bio
operator|->
name|bio_error
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_ERROR
expr_stmt|;
if|if
condition|(
name|bio
operator|->
name|bio_error
operator|==
name|ENXIO
operator|&&
name|xenbus_get_state
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
operator|==
name|XenbusStateConnected
condition|)
block|{
comment|/* 			 * Backend device has disappeared.  Signal the 			 * front-end that we (the device proxy) want to 			 * go away. 			 */
name|xenbus_set_state
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|XenbusStateClosing
argument_list|)
expr_stmt|;
block|}
block|}
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
if|if
condition|(
name|bio
operator|->
name|bio_cmd
operator|==
name|BIO_READ
condition|)
block|{
name|vm_offset_t
name|kva_offset
decl_stmt|;
name|kva_offset
operator|=
operator|(
name|vm_offset_t
operator|)
name|bio
operator|->
name|bio_data
operator|-
operator|(
name|vm_offset_t
operator|)
name|reqlist
operator|->
name|bounce
expr_stmt|;
name|memcpy
argument_list|(
operator|(
name|uint8_t
operator|*
operator|)
name|reqlist
operator|->
name|kva
operator|+
name|kva_offset
argument_list|,
name|bio
operator|->
name|bio_data
argument_list|,
name|bio
operator|->
name|bio_bcount
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* XBB_USE_BOUNCE_BUFFERS */
comment|/* 	 * Decrement the pending count for the request list.  When we're 	 * done with the requests, send status back for all of them. 	 */
if|if
condition|(
name|atomic_fetchadd_int
argument_list|(
operator|&
name|reqlist
operator|->
name|pendcnt
argument_list|,
operator|-
literal|1
argument_list|)
operator|==
literal|1
condition|)
name|xbb_complete_reqlist
argument_list|(
name|xbb
argument_list|,
name|reqlist
argument_list|)
expr_stmt|;
name|g_destroy_bio
argument_list|(
name|bio
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Parse a blkif request into an internal request structure and send  * it to the backend for processing.  *  * \param xbb       Per-instance xbb configuration structure.  * \param reqlist   Allocated internal request list structure.  *  * \return          On success, 0.  For resource shortages, non-zero.  *    * This routine performs the backend common aspects of request parsing  * including compiling an internal request structure, parsing the S/G  * list and any secondary ring requests in which they may reside, and  * the mapping of front-end I/O pages into our domain.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_dispatch_io
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|)
block|{
name|struct
name|xbb_sg
modifier|*
name|xbb_sg
decl_stmt|;
name|struct
name|gnttab_map_grant_ref
modifier|*
name|map
decl_stmt|;
name|struct
name|blkif_request_segment
modifier|*
name|sg
decl_stmt|;
name|struct
name|blkif_request_segment
modifier|*
name|last_block_sg
decl_stmt|;
name|struct
name|xbb_xen_req
modifier|*
name|nreq
decl_stmt|;
name|u_int
name|nseg
decl_stmt|;
name|u_int
name|seg_idx
decl_stmt|;
name|u_int
name|block_segs
decl_stmt|;
name|int
name|nr_sects
decl_stmt|;
name|int
name|total_sects
decl_stmt|;
name|int
name|operation
decl_stmt|;
name|uint8_t
name|bio_flags
decl_stmt|;
name|int
name|error
decl_stmt|;
name|reqlist
operator|->
name|ds_tag_type
operator|=
name|DEVSTAT_TAG_SIMPLE
expr_stmt|;
name|bio_flags
operator|=
literal|0
expr_stmt|;
name|total_sects
operator|=
literal|0
expr_stmt|;
name|nr_sects
operator|=
literal|0
expr_stmt|;
comment|/* 	 * First determine whether we have enough free KVA to satisfy this 	 * request list.  If not, tell xbb_run_queue() so it can go to 	 * sleep until we have more KVA. 	 */
name|reqlist
operator|->
name|kva
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|reqlist
operator|->
name|nr_segments
operator|!=
literal|0
condition|)
block|{
name|reqlist
operator|->
name|kva
operator|=
name|xbb_get_kva
argument_list|(
name|xbb
argument_list|,
name|reqlist
operator|->
name|nr_segments
argument_list|)
expr_stmt|;
if|if
condition|(
name|reqlist
operator|->
name|kva
operator|==
name|NULL
condition|)
block|{
comment|/* 			 * If we're out of KVA, return ENOMEM. 			 */
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
block|}
name|binuptime
argument_list|(
operator|&
name|reqlist
operator|->
name|ds_t0
argument_list|)
expr_stmt|;
name|devstat_start_transaction
argument_list|(
name|xbb
operator|->
name|xbb_stats
argument_list|,
operator|&
name|reqlist
operator|->
name|ds_t0
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|reqlist
operator|->
name|operation
condition|)
block|{
case|case
name|BLKIF_OP_WRITE_BARRIER
case|:
name|bio_flags
operator||=
name|BIO_ORDERED
expr_stmt|;
name|reqlist
operator|->
name|ds_tag_type
operator|=
name|DEVSTAT_TAG_ORDERED
expr_stmt|;
comment|/* FALLTHROUGH */
case|case
name|BLKIF_OP_WRITE
case|:
name|operation
operator|=
name|BIO_WRITE
expr_stmt|;
name|reqlist
operator|->
name|ds_trans_type
operator|=
name|DEVSTAT_WRITE
expr_stmt|;
if|if
condition|(
operator|(
name|xbb
operator|->
name|flags
operator|&
name|XBBF_READ_ONLY
operator|)
operator|!=
literal|0
condition|)
block|{
name|DPRINTF
argument_list|(
literal|"Attempt to write to read only device %s\n"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_ERROR
expr_stmt|;
goto|goto
name|send_response
goto|;
block|}
break|break;
case|case
name|BLKIF_OP_READ
case|:
name|operation
operator|=
name|BIO_READ
expr_stmt|;
name|reqlist
operator|->
name|ds_trans_type
operator|=
name|DEVSTAT_READ
expr_stmt|;
break|break;
case|case
name|BLKIF_OP_FLUSH_DISKCACHE
case|:
comment|/* 		 * If this is true, the user has requested that we disable 		 * flush support.  So we just complete the requests 		 * successfully. 		 */
if|if
condition|(
name|xbb
operator|->
name|disable_flush
operator|!=
literal|0
condition|)
block|{
goto|goto
name|send_response
goto|;
block|}
comment|/* 		 * The user has requested that we only send a real flush 		 * for every N flush requests.  So keep count, and either 		 * complete the request immediately or queue it for the 		 * backend. 		 */
if|if
condition|(
name|xbb
operator|->
name|flush_interval
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|++
operator|(
name|xbb
operator|->
name|flush_count
operator|)
operator|<
name|xbb
operator|->
name|flush_interval
condition|)
block|{
goto|goto
name|send_response
goto|;
block|}
else|else
name|xbb
operator|->
name|flush_count
operator|=
literal|0
expr_stmt|;
block|}
name|operation
operator|=
name|BIO_FLUSH
expr_stmt|;
name|reqlist
operator|->
name|ds_tag_type
operator|=
name|DEVSTAT_TAG_ORDERED
expr_stmt|;
name|reqlist
operator|->
name|ds_trans_type
operator|=
name|DEVSTAT_NO_DATA
expr_stmt|;
goto|goto
name|do_dispatch
goto|;
comment|/*NOTREACHED*/
default|default:
name|DPRINTF
argument_list|(
literal|"error: unknown block io operation [%d]\n"
argument_list|,
name|reqlist
operator|->
name|operation
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_ERROR
expr_stmt|;
goto|goto
name|send_response
goto|;
block|}
name|reqlist
operator|->
name|xbb
operator|=
name|xbb
expr_stmt|;
name|xbb_sg
operator|=
name|xbb
operator|->
name|xbb_sgs
expr_stmt|;
name|map
operator|=
name|xbb
operator|->
name|maps
expr_stmt|;
name|seg_idx
operator|=
literal|0
expr_stmt|;
name|STAILQ_FOREACH
argument_list|(
argument|nreq
argument_list|,
argument|&reqlist->contig_req_list
argument_list|,
argument|links
argument_list|)
block|{
name|blkif_request_t
modifier|*
name|ring_req
decl_stmt|;
name|RING_IDX
name|req_ring_idx
decl_stmt|;
name|u_int
name|req_seg_idx
decl_stmt|;
name|ring_req
operator|=
name|nreq
operator|->
name|ring_req
expr_stmt|;
name|req_ring_idx
operator|=
name|nreq
operator|->
name|req_ring_idx
expr_stmt|;
name|nr_sects
operator|=
literal|0
expr_stmt|;
name|nseg
operator|=
name|ring_req
operator|->
name|nr_segments
expr_stmt|;
name|nreq
operator|->
name|id
operator|=
name|ring_req
operator|->
name|id
expr_stmt|;
name|nreq
operator|->
name|nr_pages
operator|=
name|nseg
expr_stmt|;
name|nreq
operator|->
name|nr_512b_sectors
operator|=
literal|0
expr_stmt|;
name|req_seg_idx
operator|=
literal|0
expr_stmt|;
name|sg
operator|=
name|NULL
expr_stmt|;
comment|/* Check that number of segments is sane. */
if|if
condition|(
name|unlikely
argument_list|(
name|nseg
operator|==
literal|0
argument_list|)
operator|||
name|unlikely
argument_list|(
name|nseg
operator|>
name|xbb
operator|->
name|max_request_segments
argument_list|)
condition|)
block|{
name|DPRINTF
argument_list|(
literal|"Bad number of segments in request (%d)\n"
argument_list|,
name|nseg
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_ERROR
expr_stmt|;
goto|goto
name|send_response
goto|;
block|}
name|block_segs
operator|=
name|MIN
argument_list|(
name|nreq
operator|->
name|nr_pages
argument_list|,
name|BLKIF_MAX_SEGMENTS_PER_HEADER_BLOCK
argument_list|)
expr_stmt|;
name|sg
operator|=
name|ring_req
operator|->
name|seg
expr_stmt|;
name|last_block_sg
operator|=
name|sg
operator|+
name|block_segs
expr_stmt|;
while|while
condition|(
literal|1
condition|)
block|{
while|while
condition|(
name|sg
operator|<
name|last_block_sg
condition|)
block|{
name|KASSERT
argument_list|(
name|seg_idx
operator|<
name|XBB_MAX_SEGMENTS_PER_REQLIST
argument_list|,
operator|(
literal|"seg_idx %d is too large, max "
literal|"segs %d\n"
operator|,
name|seg_idx
operator|,
name|XBB_MAX_SEGMENTS_PER_REQLIST
operator|)
argument_list|)
expr_stmt|;
name|xbb_sg
operator|->
name|first_sect
operator|=
name|sg
operator|->
name|first_sect
expr_stmt|;
name|xbb_sg
operator|->
name|last_sect
operator|=
name|sg
operator|->
name|last_sect
expr_stmt|;
name|xbb_sg
operator|->
name|nsect
operator|=
call|(
name|int8_t
call|)
argument_list|(
name|sg
operator|->
name|last_sect
operator|-
name|sg
operator|->
name|first_sect
operator|+
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|sg
operator|->
name|last_sect
operator|>=
operator|(
name|PAGE_SIZE
operator|>>
literal|9
operator|)
operator|)
operator|||
operator|(
name|xbb_sg
operator|->
name|nsect
operator|<=
literal|0
operator|)
condition|)
block|{
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_ERROR
expr_stmt|;
goto|goto
name|send_response
goto|;
block|}
name|nr_sects
operator|+=
name|xbb_sg
operator|->
name|nsect
expr_stmt|;
name|map
operator|->
name|host_addr
operator|=
name|xbb_get_gntaddr
argument_list|(
name|reqlist
argument_list|,
name|seg_idx
argument_list|,
comment|/*sector*/
literal|0
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|map
operator|->
name|host_addr
operator|+
name|PAGE_SIZE
operator|<=
name|xbb
operator|->
name|ring_config
operator|.
name|gnt_addr
argument_list|,
operator|(
literal|"Host address %#jx len %d overlaps "
literal|"ring address %#jx\n"
operator|,
operator|(
name|uintmax_t
operator|)
name|map
operator|->
name|host_addr
operator|,
name|PAGE_SIZE
operator|,
operator|(
name|uintmax_t
operator|)
name|xbb
operator|->
name|ring_config
operator|.
name|gnt_addr
operator|)
argument_list|)
expr_stmt|;
name|map
operator|->
name|flags
operator|=
name|GNTMAP_host_map
expr_stmt|;
name|map
operator|->
name|ref
operator|=
name|sg
operator|->
name|gref
expr_stmt|;
name|map
operator|->
name|dom
operator|=
name|xbb
operator|->
name|otherend_id
expr_stmt|;
if|if
condition|(
name|operation
operator|==
name|BIO_WRITE
condition|)
name|map
operator|->
name|flags
operator||=
name|GNTMAP_readonly
expr_stmt|;
name|sg
operator|++
expr_stmt|;
name|map
operator|++
expr_stmt|;
name|xbb_sg
operator|++
expr_stmt|;
name|seg_idx
operator|++
expr_stmt|;
name|req_seg_idx
operator|++
expr_stmt|;
block|}
name|block_segs
operator|=
name|MIN
argument_list|(
name|nseg
operator|-
name|req_seg_idx
argument_list|,
name|BLKIF_MAX_SEGMENTS_PER_SEGMENT_BLOCK
argument_list|)
expr_stmt|;
if|if
condition|(
name|block_segs
operator|==
literal|0
condition|)
break|break;
comment|/* 			 * Fetch the next request block full of SG elements. 			 * For now, only the spacing between entries is 			 * different in the different ABIs, not the sg entry 			 * layout. 			 */
name|req_ring_idx
operator|++
expr_stmt|;
switch|switch
condition|(
name|xbb
operator|->
name|abi
condition|)
block|{
case|case
name|BLKIF_PROTOCOL_NATIVE
case|:
name|sg
operator|=
name|BLKRING_GET_SG_REQUEST
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|native
argument_list|,
name|req_ring_idx
argument_list|)
expr_stmt|;
break|break;
case|case
name|BLKIF_PROTOCOL_X86_32
case|:
block|{
name|sg
operator|=
name|BLKRING_GET_SG_REQUEST
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|x86_32
argument_list|,
name|req_ring_idx
argument_list|)
expr_stmt|;
break|break;
block|}
case|case
name|BLKIF_PROTOCOL_X86_64
case|:
block|{
name|sg
operator|=
name|BLKRING_GET_SG_REQUEST
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|x86_64
argument_list|,
name|req_ring_idx
argument_list|)
expr_stmt|;
break|break;
block|}
default|default:
name|panic
argument_list|(
literal|"Unexpected blkif protocol ABI."
argument_list|)
expr_stmt|;
comment|/* NOTREACHED */
block|}
name|last_block_sg
operator|=
name|sg
operator|+
name|block_segs
expr_stmt|;
block|}
comment|/* Convert to the disk's sector size */
name|nreq
operator|->
name|nr_512b_sectors
operator|=
name|nr_sects
expr_stmt|;
name|nr_sects
operator|=
operator|(
name|nr_sects
operator|<<
literal|9
operator|)
operator|>>
name|xbb
operator|->
name|sector_size_shift
expr_stmt|;
name|total_sects
operator|+=
name|nr_sects
expr_stmt|;
if|if
condition|(
operator|(
name|nreq
operator|->
name|nr_512b_sectors
operator|&
operator|(
operator|(
name|xbb
operator|->
name|sector_size
operator|>>
literal|9
operator|)
operator|-
literal|1
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|device_printf
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
literal|"%s: I/O size (%d) is not "
literal|"a multiple of the backing store sector "
literal|"size (%d)\n"
argument_list|,
name|__func__
argument_list|,
name|nreq
operator|->
name|nr_512b_sectors
operator|<<
literal|9
argument_list|,
name|xbb
operator|->
name|sector_size
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_ERROR
expr_stmt|;
goto|goto
name|send_response
goto|;
block|}
block|}
name|error
operator|=
name|HYPERVISOR_grant_table_op
argument_list|(
name|GNTTABOP_map_grant_ref
argument_list|,
name|xbb
operator|->
name|maps
argument_list|,
name|reqlist
operator|->
name|nr_segments
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"Grant table operation failed (%d)"
argument_list|,
name|error
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|flags
operator||=
name|XBB_REQLIST_MAPPED
expr_stmt|;
for|for
control|(
name|seg_idx
operator|=
literal|0
operator|,
name|map
operator|=
name|xbb
operator|->
name|maps
init|;
name|seg_idx
operator|<
name|reqlist
operator|->
name|nr_segments
condition|;
name|seg_idx
operator|++
operator|,
name|map
operator|++
control|)
block|{
if|if
condition|(
name|unlikely
argument_list|(
name|map
operator|->
name|status
operator|!=
literal|0
argument_list|)
condition|)
block|{
name|DPRINTF
argument_list|(
literal|"invalid buffer -- could not remap "
literal|"it (%d)\n"
argument_list|,
name|map
operator|->
name|status
argument_list|)
expr_stmt|;
name|DPRINTF
argument_list|(
literal|"Mapping(%d): Host Addr 0x%lx, flags "
literal|"0x%x ref 0x%x, dom %d\n"
argument_list|,
name|seg_idx
argument_list|,
name|map
operator|->
name|host_addr
argument_list|,
name|map
operator|->
name|flags
argument_list|,
name|map
operator|->
name|ref
argument_list|,
name|map
operator|->
name|dom
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_ERROR
expr_stmt|;
goto|goto
name|send_response
goto|;
block|}
name|reqlist
operator|->
name|gnt_handles
index|[
name|seg_idx
index|]
operator|=
name|map
operator|->
name|handle
expr_stmt|;
block|}
if|if
condition|(
name|reqlist
operator|->
name|starting_sector_number
operator|+
name|total_sects
operator|>
name|xbb
operator|->
name|media_num_sectors
condition|)
block|{
name|DPRINTF
argument_list|(
literal|"%s of [%"
name|PRIu64
literal|",%"
name|PRIu64
literal|"] "
literal|"extends past end of device %s\n"
argument_list|,
name|operation
operator|==
name|BIO_READ
condition|?
literal|"read"
else|:
literal|"write"
argument_list|,
name|reqlist
operator|->
name|starting_sector_number
argument_list|,
name|reqlist
operator|->
name|starting_sector_number
operator|+
name|total_sects
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_ERROR
expr_stmt|;
goto|goto
name|send_response
goto|;
block|}
name|do_dispatch
label|:
name|error
operator|=
name|xbb
operator|->
name|dispatch_io
argument_list|(
name|xbb
argument_list|,
name|reqlist
argument_list|,
name|operation
argument_list|,
name|bio_flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_ERROR
expr_stmt|;
goto|goto
name|send_response
goto|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
name|send_response
label|:
name|xbb_complete_reqlist
argument_list|(
name|xbb
argument_list|,
name|reqlist
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|int
name|xbb_count_sects
parameter_list|(
name|blkif_request_t
modifier|*
name|ring_req
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|int
name|cur_size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|ring_req
operator|->
name|nr_segments
condition|;
name|i
operator|++
control|)
block|{
name|int
name|nsect
decl_stmt|;
name|nsect
operator|=
call|(
name|int8_t
call|)
argument_list|(
name|ring_req
operator|->
name|seg
index|[
name|i
index|]
operator|.
name|last_sect
operator|-
name|ring_req
operator|->
name|seg
index|[
name|i
index|]
operator|.
name|first_sect
operator|+
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|nsect
operator|<=
literal|0
condition|)
break|break;
name|cur_size
operator|+=
name|nsect
expr_stmt|;
block|}
return|return
operator|(
name|cur_size
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Process incoming requests from the shared communication ring in response  * to a signal on the ring's event channel.  *  * \param context  Callback argument registerd during task initialization -  *                 the xbb_softc for this instance.  * \param pending  The number of taskqueue_enqueue events that have  *                 occurred since this handler was last run.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_run_queue
parameter_list|(
name|void
modifier|*
name|context
parameter_list|,
name|int
name|pending
parameter_list|)
block|{
name|struct
name|xbb_softc
modifier|*
name|xbb
decl_stmt|;
name|blkif_back_rings_t
modifier|*
name|rings
decl_stmt|;
name|RING_IDX
name|rp
decl_stmt|;
name|uint64_t
name|cur_sector
decl_stmt|;
name|int
name|cur_operation
decl_stmt|;
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
decl_stmt|;
name|xbb
operator|=
operator|(
expr|struct
name|xbb_softc
operator|*
operator|)
name|context
expr_stmt|;
name|rings
operator|=
operator|&
name|xbb
operator|->
name|rings
expr_stmt|;
comment|/* 	 * Work gather and dispatch loop.  Note that we have a bias here 	 * towards gathering I/O sent by blockfront.  We first gather up 	 * everything in the ring, as long as we have resources.  Then we 	 * dispatch one request, and then attempt to gather up any 	 * additional requests that have come in while we were dispatching 	 * the request. 	 * 	 * This allows us to get a clearer picture (via devstat) of how 	 * many requests blockfront is queueing to us at any given time. 	 */
for|for
control|(
init|;
condition|;
control|)
block|{
name|int
name|retval
decl_stmt|;
comment|/* 		 * Initialize reqlist to the last element in the pending 		 * queue, if there is one.  This allows us to add more 		 * requests to that request list, if we have room. 		 */
name|reqlist
operator|=
name|STAILQ_LAST
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_pending_stailq
argument_list|,
name|xbb_xen_reqlist
argument_list|,
name|links
argument_list|)
expr_stmt|;
if|if
condition|(
name|reqlist
operator|!=
name|NULL
condition|)
block|{
name|cur_sector
operator|=
name|reqlist
operator|->
name|next_contig_sector
expr_stmt|;
name|cur_operation
operator|=
name|reqlist
operator|->
name|operation
expr_stmt|;
block|}
else|else
block|{
name|cur_operation
operator|=
literal|0
expr_stmt|;
name|cur_sector
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 		 * Cache req_prod to avoid accessing a cache line shared 		 * with the frontend. 		 */
name|rp
operator|=
name|rings
operator|->
name|common
operator|.
name|sring
operator|->
name|req_prod
expr_stmt|;
comment|/* Ensure we see queued requests up to 'rp'. */
name|rmb
argument_list|()
expr_stmt|;
comment|/** 		 * Run so long as there is work to consume and the generation 		 * of a response will not overflow the ring. 		 * 		 * @note There's a 1 to 1 relationship between requests and 		 *       responses, so an overflow should never occur.  This 		 *       test is to protect our domain from digesting bogus 		 *       data.  Shouldn't we log this? 		 */
while|while
condition|(
name|rings
operator|->
name|common
operator|.
name|req_cons
operator|!=
name|rp
operator|&&
name|RING_REQUEST_CONS_OVERFLOW
argument_list|(
operator|&
name|rings
operator|->
name|common
argument_list|,
name|rings
operator|->
name|common
operator|.
name|req_cons
argument_list|)
operator|==
literal|0
condition|)
block|{
name|blkif_request_t
name|ring_req_storage
decl_stmt|;
name|blkif_request_t
modifier|*
name|ring_req
decl_stmt|;
name|int
name|cur_size
decl_stmt|;
switch|switch
condition|(
name|xbb
operator|->
name|abi
condition|)
block|{
case|case
name|BLKIF_PROTOCOL_NATIVE
case|:
name|ring_req
operator|=
name|RING_GET_REQUEST
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|native
argument_list|,
name|rings
operator|->
name|common
operator|.
name|req_cons
argument_list|)
expr_stmt|;
break|break;
case|case
name|BLKIF_PROTOCOL_X86_32
case|:
block|{
name|struct
name|blkif_x86_32_request
modifier|*
name|ring_req32
decl_stmt|;
name|ring_req32
operator|=
name|RING_GET_REQUEST
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|x86_32
argument_list|,
name|rings
operator|->
name|common
operator|.
name|req_cons
argument_list|)
expr_stmt|;
name|blkif_get_x86_32_req
argument_list|(
operator|&
name|ring_req_storage
argument_list|,
name|ring_req32
argument_list|)
expr_stmt|;
name|ring_req
operator|=
operator|&
name|ring_req_storage
expr_stmt|;
break|break;
block|}
case|case
name|BLKIF_PROTOCOL_X86_64
case|:
block|{
name|struct
name|blkif_x86_64_request
modifier|*
name|ring_req64
decl_stmt|;
name|ring_req64
operator|=
name|RING_GET_REQUEST
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|x86_64
argument_list|,
name|rings
operator|->
name|common
operator|.
name|req_cons
argument_list|)
expr_stmt|;
name|blkif_get_x86_64_req
argument_list|(
operator|&
name|ring_req_storage
argument_list|,
name|ring_req64
argument_list|)
expr_stmt|;
name|ring_req
operator|=
operator|&
name|ring_req_storage
expr_stmt|;
break|break;
block|}
default|default:
name|panic
argument_list|(
literal|"Unexpected blkif protocol ABI."
argument_list|)
expr_stmt|;
comment|/* NOTREACHED */
block|}
comment|/* 			 * Check for situations that would require closing 			 * off this I/O for further coalescing: 			 *  - Coalescing is turned off. 			 *  - Current I/O is out of sequence with the previous 			 *    I/O. 			 *  - Coalesced I/O would be too large. 			 */
if|if
condition|(
operator|(
name|reqlist
operator|!=
name|NULL
operator|)
operator|&&
operator|(
operator|(
name|xbb
operator|->
name|no_coalesce_reqs
operator|!=
literal|0
operator|)
operator|||
operator|(
operator|(
name|xbb
operator|->
name|no_coalesce_reqs
operator|==
literal|0
operator|)
operator|&&
operator|(
operator|(
name|ring_req
operator|->
name|sector_number
operator|!=
name|cur_sector
operator|)
operator|||
operator|(
name|ring_req
operator|->
name|operation
operator|!=
name|cur_operation
operator|)
operator|||
operator|(
operator|(
name|ring_req
operator|->
name|nr_segments
operator|+
name|reqlist
operator|->
name|nr_segments
operator|)
operator|>
name|xbb
operator|->
name|max_reqlist_segments
operator|)
operator|)
operator|)
operator|)
condition|)
block|{
name|reqlist
operator|=
name|NULL
expr_stmt|;
block|}
comment|/* 			 * Grab and check for all resources in one shot. 			 * If we can't get all of the resources we need, 			 * the shortage is noted and the thread will get 			 * woken up when more resources are available. 			 */
name|retval
operator|=
name|xbb_get_resources
argument_list|(
name|xbb
argument_list|,
operator|&
name|reqlist
argument_list|,
name|ring_req
argument_list|,
name|xbb
operator|->
name|rings
operator|.
name|common
operator|.
name|req_cons
argument_list|)
expr_stmt|;
if|if
condition|(
name|retval
operator|!=
literal|0
condition|)
block|{
comment|/* 				 * Resource shortage has been recorded. 				 * We'll be scheduled to run once a request 				 * object frees up due to a completion. 				 */
break|break;
block|}
comment|/* 			 * Signify that	we can overwrite this request with 			 * a response by incrementing our consumer index. 			 * The response won't be generated until after 			 * we've already consumed all necessary data out 			 * of the version of the request in the ring buffer 			 * (for native mode).  We must update the consumer 			 * index  before issueing back-end I/O so there is 			 * no possibility that it will complete and a 			 * response be generated before we make room in  			 * the queue for that response. 			 */
name|xbb
operator|->
name|rings
operator|.
name|common
operator|.
name|req_cons
operator|+=
name|BLKIF_SEGS_TO_BLOCKS
argument_list|(
name|ring_req
operator|->
name|nr_segments
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|reqs_received
operator|++
expr_stmt|;
name|cur_size
operator|=
name|xbb_count_sects
argument_list|(
name|ring_req
argument_list|)
expr_stmt|;
name|cur_sector
operator|=
name|ring_req
operator|->
name|sector_number
operator|+
name|cur_size
expr_stmt|;
name|reqlist
operator|->
name|next_contig_sector
operator|=
name|cur_sector
expr_stmt|;
name|cur_operation
operator|=
name|ring_req
operator|->
name|operation
expr_stmt|;
block|}
comment|/* Check for I/O to dispatch */
name|reqlist
operator|=
name|STAILQ_FIRST
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_pending_stailq
argument_list|)
expr_stmt|;
if|if
condition|(
name|reqlist
operator|==
name|NULL
condition|)
block|{
comment|/* 			 * We're out of work to do, put the task queue to 			 * sleep. 			 */
break|break;
block|}
comment|/* 		 * Grab the first request off the queue and attempt 		 * to dispatch it. 		 */
name|STAILQ_REMOVE_HEAD
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_pending_stailq
argument_list|,
name|links
argument_list|)
expr_stmt|;
name|retval
operator|=
name|xbb_dispatch_io
argument_list|(
name|xbb
argument_list|,
name|reqlist
argument_list|)
expr_stmt|;
if|if
condition|(
name|retval
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * xbb_dispatch_io() returns non-zero only when 			 * there is a resource shortage.  If that's the 			 * case, re-queue this request on the head of the 			 * queue, and go to sleep until we have more 			 * resources. 			 */
name|STAILQ_INSERT_HEAD
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_pending_stailq
argument_list|,
name|reqlist
argument_list|,
name|links
argument_list|)
expr_stmt|;
break|break;
block|}
else|else
block|{
comment|/* 			 * If we still have anything on the queue after 			 * removing the head entry, that is because we 			 * met one of the criteria to create a new 			 * request list (outlined above), and we'll call 			 * that a forced dispatch for statistical purposes. 			 * 			 * Otherwise, if there is only one element on the 			 * queue, we coalesced everything available on 			 * the ring and we'll call that a normal dispatch. 			 */
name|reqlist
operator|=
name|STAILQ_FIRST
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_pending_stailq
argument_list|)
expr_stmt|;
if|if
condition|(
name|reqlist
operator|!=
name|NULL
condition|)
name|xbb
operator|->
name|forced_dispatch
operator|++
expr_stmt|;
else|else
name|xbb
operator|->
name|normal_dispatch
operator|++
expr_stmt|;
name|xbb
operator|->
name|total_dispatch
operator|++
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/**  * Interrupt handler bound to the shared ring's event channel.  *  * \param arg  Callback argument registerd during event channel  *             binding - the xbb_softc for this instance.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_intr
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|struct
name|xbb_softc
modifier|*
name|xbb
decl_stmt|;
comment|/* Defer to kernel thread. */
name|xbb
operator|=
operator|(
expr|struct
name|xbb_softc
operator|*
operator|)
name|arg
expr_stmt|;
name|taskqueue_enqueue
argument_list|(
name|xbb
operator|->
name|io_taskqueue
argument_list|,
operator|&
name|xbb
operator|->
name|io_task
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*----------------------------- Backend Handlers -----------------------------*/
end_comment

begin_comment
comment|/**  * Backend handler for character device access.  *  * \param xbb        Per-instance xbb configuration structure.  * \param reqlist    Allocated internal request list structure.  * \param operation  BIO_* I/O operation code.  * \param bio_flags  Additional bio_flag data to pass to any generated  *                   bios (e.g. BIO_ORDERED)..  *  * \return  0 for success, errno codes for failure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_dispatch_dev
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|,
name|int
name|operation
parameter_list|,
name|int
name|bio_flags
parameter_list|)
block|{
name|struct
name|xbb_dev_data
modifier|*
name|dev_data
decl_stmt|;
name|struct
name|bio
modifier|*
name|bios
index|[
name|XBB_MAX_SEGMENTS_PER_REQLIST
index|]
decl_stmt|;
name|struct
name|xbb_xen_req
modifier|*
name|nreq
decl_stmt|;
name|off_t
name|bio_offset
decl_stmt|;
name|struct
name|bio
modifier|*
name|bio
decl_stmt|;
name|struct
name|xbb_sg
modifier|*
name|xbb_sg
decl_stmt|;
name|u_int
name|nbio
decl_stmt|;
name|u_int
name|bio_idx
decl_stmt|;
name|u_int
name|nseg
decl_stmt|;
name|u_int
name|seg_idx
decl_stmt|;
name|int
name|error
decl_stmt|;
name|dev_data
operator|=
operator|&
name|xbb
operator|->
name|backend
operator|.
name|dev
expr_stmt|;
name|bio_offset
operator|=
operator|(
name|off_t
operator|)
name|reqlist
operator|->
name|starting_sector_number
operator|<<
name|xbb
operator|->
name|sector_size_shift
expr_stmt|;
name|error
operator|=
literal|0
expr_stmt|;
name|nbio
operator|=
literal|0
expr_stmt|;
name|bio_idx
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|operation
operator|==
name|BIO_FLUSH
condition|)
block|{
name|nreq
operator|=
name|STAILQ_FIRST
argument_list|(
operator|&
name|reqlist
operator|->
name|contig_req_list
argument_list|)
expr_stmt|;
name|bio
operator|=
name|g_new_bio
argument_list|()
expr_stmt|;
if|if
condition|(
name|unlikely
argument_list|(
name|bio
operator|==
name|NULL
argument_list|)
condition|)
block|{
name|DPRINTF
argument_list|(
literal|"Unable to allocate bio for BIO_FLUSH\n"
argument_list|)
expr_stmt|;
name|error
operator|=
name|ENOMEM
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|bio
operator|->
name|bio_cmd
operator|=
name|BIO_FLUSH
expr_stmt|;
name|bio
operator|->
name|bio_flags
operator||=
name|BIO_ORDERED
expr_stmt|;
name|bio
operator|->
name|bio_dev
operator|=
name|dev_data
operator|->
name|cdev
expr_stmt|;
name|bio
operator|->
name|bio_offset
operator|=
literal|0
expr_stmt|;
name|bio
operator|->
name|bio_data
operator|=
literal|0
expr_stmt|;
name|bio
operator|->
name|bio_done
operator|=
name|xbb_bio_done
expr_stmt|;
name|bio
operator|->
name|bio_caller1
operator|=
name|nreq
expr_stmt|;
name|bio
operator|->
name|bio_pblkno
operator|=
literal|0
expr_stmt|;
name|nreq
operator|->
name|pendcnt
operator|=
literal|1
expr_stmt|;
call|(
modifier|*
name|dev_data
operator|->
name|csw
operator|->
name|d_strategy
call|)
argument_list|(
name|bio
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|xbb_sg
operator|=
name|xbb
operator|->
name|xbb_sgs
expr_stmt|;
name|bio
operator|=
name|NULL
expr_stmt|;
name|nseg
operator|=
name|reqlist
operator|->
name|nr_segments
expr_stmt|;
for|for
control|(
name|seg_idx
operator|=
literal|0
init|;
name|seg_idx
operator|<
name|nseg
condition|;
name|seg_idx
operator|++
operator|,
name|xbb_sg
operator|++
control|)
block|{
comment|/* 		 * KVA will not be contiguous, so any additional 		 * I/O will need to be represented in a new bio. 		 */
if|if
condition|(
operator|(
name|bio
operator|!=
name|NULL
operator|)
operator|&&
operator|(
name|xbb_sg
operator|->
name|first_sect
operator|!=
literal|0
operator|)
condition|)
block|{
if|if
condition|(
operator|(
name|bio
operator|->
name|bio_length
operator|&
operator|(
name|xbb
operator|->
name|sector_size
operator|-
literal|1
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"%s: Discontiguous I/O request "
literal|"from domain %d ends on "
literal|"non-sector boundary\n"
argument_list|,
name|__func__
argument_list|,
name|xbb
operator|->
name|otherend_id
argument_list|)
expr_stmt|;
name|error
operator|=
name|EINVAL
expr_stmt|;
goto|goto
name|fail_free_bios
goto|;
block|}
name|bio
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|bio
operator|==
name|NULL
condition|)
block|{
comment|/* 			 * Make sure that the start of this bio is 			 * aligned to a device sector. 			 */
if|if
condition|(
operator|(
name|bio_offset
operator|&
operator|(
name|xbb
operator|->
name|sector_size
operator|-
literal|1
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"%s: Misaligned I/O request "
literal|"from domain %d\n"
argument_list|,
name|__func__
argument_list|,
name|xbb
operator|->
name|otherend_id
argument_list|)
expr_stmt|;
name|error
operator|=
name|EINVAL
expr_stmt|;
goto|goto
name|fail_free_bios
goto|;
block|}
name|bio
operator|=
name|bios
index|[
name|nbio
operator|++
index|]
operator|=
name|g_new_bio
argument_list|()
expr_stmt|;
if|if
condition|(
name|unlikely
argument_list|(
name|bio
operator|==
name|NULL
argument_list|)
condition|)
block|{
name|error
operator|=
name|ENOMEM
expr_stmt|;
goto|goto
name|fail_free_bios
goto|;
block|}
name|bio
operator|->
name|bio_cmd
operator|=
name|operation
expr_stmt|;
name|bio
operator|->
name|bio_flags
operator||=
name|bio_flags
expr_stmt|;
name|bio
operator|->
name|bio_dev
operator|=
name|dev_data
operator|->
name|cdev
expr_stmt|;
name|bio
operator|->
name|bio_offset
operator|=
name|bio_offset
expr_stmt|;
name|bio
operator|->
name|bio_data
operator|=
name|xbb_reqlist_ioaddr
argument_list|(
name|reqlist
argument_list|,
name|seg_idx
argument_list|,
name|xbb_sg
operator|->
name|first_sect
argument_list|)
expr_stmt|;
name|bio
operator|->
name|bio_done
operator|=
name|xbb_bio_done
expr_stmt|;
name|bio
operator|->
name|bio_caller1
operator|=
name|reqlist
expr_stmt|;
name|bio
operator|->
name|bio_pblkno
operator|=
name|bio_offset
operator|>>
name|xbb
operator|->
name|sector_size_shift
expr_stmt|;
block|}
name|bio
operator|->
name|bio_length
operator|+=
name|xbb_sg
operator|->
name|nsect
operator|<<
literal|9
expr_stmt|;
name|bio
operator|->
name|bio_bcount
operator|=
name|bio
operator|->
name|bio_length
expr_stmt|;
name|bio_offset
operator|+=
name|xbb_sg
operator|->
name|nsect
operator|<<
literal|9
expr_stmt|;
if|if
condition|(
name|xbb_sg
operator|->
name|last_sect
operator|!=
operator|(
name|PAGE_SIZE
operator|-
literal|512
operator|)
operator|>>
literal|9
condition|)
block|{
if|if
condition|(
operator|(
name|bio
operator|->
name|bio_length
operator|&
operator|(
name|xbb
operator|->
name|sector_size
operator|-
literal|1
operator|)
operator|)
operator|!=
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"%s: Discontiguous I/O request "
literal|"from domain %d ends on "
literal|"non-sector boundary\n"
argument_list|,
name|__func__
argument_list|,
name|xbb
operator|->
name|otherend_id
argument_list|)
expr_stmt|;
name|error
operator|=
name|EINVAL
expr_stmt|;
goto|goto
name|fail_free_bios
goto|;
block|}
comment|/* 			 * KVA will not be contiguous, so any additional 			 * I/O will need to be represented in a new bio. 			 */
name|bio
operator|=
name|NULL
expr_stmt|;
block|}
block|}
name|reqlist
operator|->
name|pendcnt
operator|=
name|nbio
expr_stmt|;
for|for
control|(
name|bio_idx
operator|=
literal|0
init|;
name|bio_idx
operator|<
name|nbio
condition|;
name|bio_idx
operator|++
control|)
block|{
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
name|vm_offset_t
name|kva_offset
decl_stmt|;
name|kva_offset
operator|=
operator|(
name|vm_offset_t
operator|)
name|bios
index|[
name|bio_idx
index|]
operator|->
name|bio_data
operator|-
operator|(
name|vm_offset_t
operator|)
name|reqlist
operator|->
name|bounce
expr_stmt|;
if|if
condition|(
name|operation
operator|==
name|BIO_WRITE
condition|)
block|{
name|memcpy
argument_list|(
name|bios
index|[
name|bio_idx
index|]
operator|->
name|bio_data
argument_list|,
operator|(
name|uint8_t
operator|*
operator|)
name|reqlist
operator|->
name|kva
operator|+
name|kva_offset
argument_list|,
name|bios
index|[
name|bio_idx
index|]
operator|->
name|bio_bcount
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
call|(
modifier|*
name|dev_data
operator|->
name|csw
operator|->
name|d_strategy
call|)
argument_list|(
name|bios
index|[
name|bio_idx
index|]
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|error
operator|)
return|;
name|fail_free_bios
label|:
for|for
control|(
name|bio_idx
operator|=
literal|0
init|;
name|bio_idx
operator|<
operator|(
name|nbio
operator|-
literal|1
operator|)
condition|;
name|bio_idx
operator|++
control|)
name|g_destroy_bio
argument_list|(
name|bios
index|[
name|bio_idx
index|]
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Backend handler for file access.  *  * \param xbb        Per-instance xbb configuration structure.  * \param reqlist    Allocated internal request list.  * \param operation  BIO_* I/O operation code.  * \param flags      Additional bio_flag data to pass to any generated bios  *                   (e.g. BIO_ORDERED)..  *  * \return  0 for success, errno codes for failure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_dispatch_file
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
parameter_list|,
name|int
name|operation
parameter_list|,
name|int
name|flags
parameter_list|)
block|{
name|struct
name|xbb_file_data
modifier|*
name|file_data
decl_stmt|;
name|u_int
name|seg_idx
decl_stmt|;
name|u_int
name|nseg
decl_stmt|;
name|off_t
name|sectors_sent
decl_stmt|;
name|struct
name|uio
name|xuio
decl_stmt|;
name|struct
name|xbb_sg
modifier|*
name|xbb_sg
decl_stmt|;
name|struct
name|iovec
modifier|*
name|xiovec
decl_stmt|;
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
name|void
modifier|*
modifier|*
name|p_vaddr
decl_stmt|;
name|int
name|saved_uio_iovcnt
decl_stmt|;
endif|#
directive|endif
comment|/* XBB_USE_BOUNCE_BUFFERS */
name|int
name|vfs_is_locked
decl_stmt|;
name|int
name|error
decl_stmt|;
name|file_data
operator|=
operator|&
name|xbb
operator|->
name|backend
operator|.
name|file
expr_stmt|;
name|sectors_sent
operator|=
literal|0
expr_stmt|;
name|error
operator|=
literal|0
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|xuio
argument_list|,
sizeof|sizeof
argument_list|(
name|xuio
argument_list|)
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|operation
condition|)
block|{
case|case
name|BIO_READ
case|:
name|xuio
operator|.
name|uio_rw
operator|=
name|UIO_READ
expr_stmt|;
break|break;
case|case
name|BIO_WRITE
case|:
name|xuio
operator|.
name|uio_rw
operator|=
name|UIO_WRITE
expr_stmt|;
break|break;
case|case
name|BIO_FLUSH
case|:
block|{
name|struct
name|mount
modifier|*
name|mountpoint
decl_stmt|;
name|vfs_is_locked
operator|=
name|VFS_LOCK_GIANT
argument_list|(
name|xbb
operator|->
name|vn
operator|->
name|v_mount
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|vn_start_write
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
operator|&
name|mountpoint
argument_list|,
name|V_WAIT
argument_list|)
expr_stmt|;
name|vn_lock
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_RETRY
argument_list|)
expr_stmt|;
name|error
operator|=
name|VOP_FSYNC
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
name|MNT_WAIT
argument_list|,
name|curthread
argument_list|)
expr_stmt|;
name|VOP_UNLOCK
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|vn_finished_write
argument_list|(
name|mountpoint
argument_list|)
expr_stmt|;
name|VFS_UNLOCK_GIANT
argument_list|(
name|vfs_is_locked
argument_list|)
expr_stmt|;
goto|goto
name|bailout_send_response
goto|;
comment|/* NOTREACHED */
block|}
default|default:
name|panic
argument_list|(
literal|"invalid operation %d"
argument_list|,
name|operation
argument_list|)
expr_stmt|;
comment|/* NOTREACHED */
block|}
name|xuio
operator|.
name|uio_offset
operator|=
operator|(
name|vm_offset_t
operator|)
name|reqlist
operator|->
name|starting_sector_number
operator|<<
name|xbb
operator|->
name|sector_size_shift
expr_stmt|;
name|xuio
operator|.
name|uio_segflg
operator|=
name|UIO_SYSSPACE
expr_stmt|;
name|xuio
operator|.
name|uio_iov
operator|=
name|file_data
operator|->
name|xiovecs
expr_stmt|;
name|xuio
operator|.
name|uio_iovcnt
operator|=
literal|0
expr_stmt|;
name|xbb_sg
operator|=
name|xbb
operator|->
name|xbb_sgs
expr_stmt|;
name|nseg
operator|=
name|reqlist
operator|->
name|nr_segments
expr_stmt|;
for|for
control|(
name|xiovec
operator|=
name|NULL
operator|,
name|seg_idx
operator|=
literal|0
init|;
name|seg_idx
operator|<
name|nseg
condition|;
name|seg_idx
operator|++
operator|,
name|xbb_sg
operator|++
control|)
block|{
comment|/* 		 * If the first sector is not 0, the KVA will 		 * not be contiguous and we'll need to go on 		 * to another segment. 		 */
if|if
condition|(
name|xbb_sg
operator|->
name|first_sect
operator|!=
literal|0
condition|)
name|xiovec
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|xiovec
operator|==
name|NULL
condition|)
block|{
name|xiovec
operator|=
operator|&
name|file_data
operator|->
name|xiovecs
index|[
name|xuio
operator|.
name|uio_iovcnt
index|]
expr_stmt|;
name|xiovec
operator|->
name|iov_base
operator|=
name|xbb_reqlist_ioaddr
argument_list|(
name|reqlist
argument_list|,
name|seg_idx
argument_list|,
name|xbb_sg
operator|->
name|first_sect
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
comment|/* 			 * Store the address of the incoming 			 * buffer at this particular offset 			 * as well, so we can do the copy 			 * later without having to do more 			 * work to recalculate this address. 		 	 */
name|p_vaddr
operator|=
operator|&
name|file_data
operator|->
name|xiovecs_vaddr
index|[
name|xuio
operator|.
name|uio_iovcnt
index|]
expr_stmt|;
operator|*
name|p_vaddr
operator|=
name|xbb_reqlist_vaddr
argument_list|(
name|reqlist
argument_list|,
name|seg_idx
argument_list|,
name|xbb_sg
operator|->
name|first_sect
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* XBB_USE_BOUNCE_BUFFERS */
name|xiovec
operator|->
name|iov_len
operator|=
literal|0
expr_stmt|;
name|xuio
operator|.
name|uio_iovcnt
operator|++
expr_stmt|;
block|}
name|xiovec
operator|->
name|iov_len
operator|+=
name|xbb_sg
operator|->
name|nsect
operator|<<
literal|9
expr_stmt|;
name|xuio
operator|.
name|uio_resid
operator|+=
name|xbb_sg
operator|->
name|nsect
operator|<<
literal|9
expr_stmt|;
comment|/* 		 * If the last sector is not the full page 		 * size count, the next segment will not be 		 * contiguous in KVA and we need a new iovec. 		 */
if|if
condition|(
name|xbb_sg
operator|->
name|last_sect
operator|!=
operator|(
name|PAGE_SIZE
operator|-
literal|512
operator|)
operator|>>
literal|9
condition|)
name|xiovec
operator|=
name|NULL
expr_stmt|;
block|}
name|xuio
operator|.
name|uio_td
operator|=
name|curthread
expr_stmt|;
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
name|saved_uio_iovcnt
operator|=
name|xuio
operator|.
name|uio_iovcnt
expr_stmt|;
if|if
condition|(
name|operation
operator|==
name|BIO_WRITE
condition|)
block|{
comment|/* Copy the write data to the local buffer. */
for|for
control|(
name|seg_idx
operator|=
literal|0
operator|,
name|p_vaddr
operator|=
name|file_data
operator|->
name|xiovecs_vaddr
operator|,
name|xiovec
operator|=
name|xuio
operator|.
name|uio_iov
init|;
name|seg_idx
operator|<
name|xuio
operator|.
name|uio_iovcnt
condition|;
name|seg_idx
operator|++
operator|,
name|xiovec
operator|++
operator|,
name|p_vaddr
operator|++
control|)
block|{
name|memcpy
argument_list|(
name|xiovec
operator|->
name|iov_base
argument_list|,
operator|*
name|p_vaddr
argument_list|,
name|xiovec
operator|->
name|iov_len
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|/* 		 * We only need to save off the iovecs in the case of a 		 * read, because the copy for the read happens after the 		 * VOP_READ().  (The uio will get modified in that call 		 * sequence.) 		 */
name|memcpy
argument_list|(
name|file_data
operator|->
name|saved_xiovecs
argument_list|,
name|xuio
operator|.
name|uio_iov
argument_list|,
name|xuio
operator|.
name|uio_iovcnt
operator|*
sizeof|sizeof
argument_list|(
name|xuio
operator|.
name|uio_iov
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* XBB_USE_BOUNCE_BUFFERS */
name|vfs_is_locked
operator|=
name|VFS_LOCK_GIANT
argument_list|(
name|xbb
operator|->
name|vn
operator|->
name|v_mount
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|operation
condition|)
block|{
case|case
name|BIO_READ
case|:
name|vn_lock
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_RETRY
argument_list|)
expr_stmt|;
comment|/* 		 * UFS pays attention to IO_DIRECT for reads.  If the 		 * DIRECTIO option is configured into the kernel, it calls 		 * ffs_rawread().  But that only works for single-segment 		 * uios with user space addresses.  In our case, with a 		 * kernel uio, it still reads into the buffer cache, but it 		 * will just try to release the buffer from the cache later 		 * on in ffs_read(). 		 * 		 * ZFS does not pay attention to IO_DIRECT for reads. 		 * 		 * UFS does not pay attention to IO_SYNC for reads. 		 * 		 * ZFS pays attention to IO_SYNC (which translates into the 		 * Solaris define FRSYNC for zfs_read()) for reads.  It 		 * attempts to sync the file before reading. 		 * 		 * So, to attempt to provide some barrier semantics in the 		 * BIO_ORDERED case, set both IO_DIRECT and IO_SYNC.   		 */
name|error
operator|=
name|VOP_READ
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
operator|&
name|xuio
argument_list|,
operator|(
name|flags
operator|&
name|BIO_ORDERED
operator|)
condition|?
operator|(
name|IO_DIRECT
operator||
name|IO_SYNC
operator|)
else|:
literal|0
argument_list|,
name|file_data
operator|->
name|cred
argument_list|)
expr_stmt|;
name|VOP_UNLOCK
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
literal|0
argument_list|)
expr_stmt|;
break|break;
case|case
name|BIO_WRITE
case|:
block|{
name|struct
name|mount
modifier|*
name|mountpoint
decl_stmt|;
operator|(
name|void
operator|)
name|vn_start_write
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
operator|&
name|mountpoint
argument_list|,
name|V_WAIT
argument_list|)
expr_stmt|;
name|vn_lock
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
name|LK_EXCLUSIVE
operator||
name|LK_RETRY
argument_list|)
expr_stmt|;
comment|/* 		 * UFS pays attention to IO_DIRECT for writes.  The write 		 * is done asynchronously.  (Normally the write would just 		 * get put into cache. 		 * 		 * UFS pays attention to IO_SYNC for writes.  It will 		 * attempt to write the buffer out synchronously if that 		 * flag is set. 		 * 		 * ZFS does not pay attention to IO_DIRECT for writes. 		 * 		 * ZFS pays attention to IO_SYNC (a.k.a. FSYNC or FRSYNC) 		 * for writes.  It will flush the transaction from the 		 * cache before returning. 		 * 		 * So if we've got the BIO_ORDERED flag set, we want 		 * IO_SYNC in either the UFS or ZFS case. 		 */
name|error
operator|=
name|VOP_WRITE
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
operator|&
name|xuio
argument_list|,
operator|(
name|flags
operator|&
name|BIO_ORDERED
operator|)
condition|?
name|IO_SYNC
else|:
literal|0
argument_list|,
name|file_data
operator|->
name|cred
argument_list|)
expr_stmt|;
name|VOP_UNLOCK
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|vn_finished_write
argument_list|(
name|mountpoint
argument_list|)
expr_stmt|;
break|break;
block|}
default|default:
name|panic
argument_list|(
literal|"invalid operation %d"
argument_list|,
name|operation
argument_list|)
expr_stmt|;
comment|/* NOTREACHED */
block|}
name|VFS_UNLOCK_GIANT
argument_list|(
name|vfs_is_locked
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
comment|/* We only need to copy here for read operations */
if|if
condition|(
name|operation
operator|==
name|BIO_READ
condition|)
block|{
for|for
control|(
name|seg_idx
operator|=
literal|0
operator|,
name|p_vaddr
operator|=
name|file_data
operator|->
name|xiovecs_vaddr
operator|,
name|xiovec
operator|=
name|file_data
operator|->
name|saved_xiovecs
init|;
name|seg_idx
operator|<
name|saved_uio_iovcnt
condition|;
name|seg_idx
operator|++
operator|,
name|xiovec
operator|++
operator|,
name|p_vaddr
operator|++
control|)
block|{
comment|/* 			 * Note that we have to use the copy of the  			 * io vector we made above.  uiomove() modifies 			 * the uio and its referenced vector as uiomove 			 * performs the copy, so we can't rely on any 			 * state from the original uio. 			 */
name|memcpy
argument_list|(
operator|*
name|p_vaddr
argument_list|,
name|xiovec
operator|->
name|iov_base
argument_list|,
name|xiovec
operator|->
name|iov_len
argument_list|)
expr_stmt|;
block|}
block|}
endif|#
directive|endif
comment|/* XBB_USE_BOUNCE_BUFFERS */
name|bailout_send_response
label|:
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
name|reqlist
operator|->
name|status
operator|=
name|BLKIF_RSP_ERROR
expr_stmt|;
name|xbb_complete_reqlist
argument_list|(
name|xbb
argument_list|,
name|reqlist
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*--------------------------- Backend Configuration --------------------------*/
end_comment

begin_comment
comment|/**  * Close and cleanup any backend device/file specific state for this  * block back instance.   *  * \param xbb  Per-instance xbb configuration structure.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_close_backend
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|DROP_GIANT
argument_list|()
expr_stmt|;
name|DPRINTF
argument_list|(
literal|"closing dev=%s\n"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|vn
condition|)
block|{
name|int
name|flags
init|=
name|FREAD
decl_stmt|;
name|int
name|vfs_is_locked
init|=
literal|0
decl_stmt|;
if|if
condition|(
operator|(
name|xbb
operator|->
name|flags
operator|&
name|XBBF_READ_ONLY
operator|)
operator|==
literal|0
condition|)
name|flags
operator||=
name|FWRITE
expr_stmt|;
switch|switch
condition|(
name|xbb
operator|->
name|device_type
condition|)
block|{
case|case
name|XBB_TYPE_DISK
case|:
if|if
condition|(
name|xbb
operator|->
name|backend
operator|.
name|dev
operator|.
name|csw
condition|)
block|{
name|dev_relthread
argument_list|(
name|xbb
operator|->
name|backend
operator|.
name|dev
operator|.
name|cdev
argument_list|,
name|xbb
operator|->
name|backend
operator|.
name|dev
operator|.
name|dev_ref
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|backend
operator|.
name|dev
operator|.
name|csw
operator|=
name|NULL
expr_stmt|;
name|xbb
operator|->
name|backend
operator|.
name|dev
operator|.
name|cdev
operator|=
name|NULL
expr_stmt|;
block|}
break|break;
case|case
name|XBB_TYPE_FILE
case|:
name|vfs_is_locked
operator|=
name|VFS_LOCK_GIANT
argument_list|(
name|xbb
operator|->
name|vn
operator|->
name|v_mount
argument_list|)
expr_stmt|;
break|break;
case|case
name|XBB_TYPE_NONE
case|:
default|default:
name|panic
argument_list|(
literal|"Unexpected backend type."
argument_list|)
expr_stmt|;
break|break;
block|}
operator|(
name|void
operator|)
name|vn_close
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
name|flags
argument_list|,
name|NOCRED
argument_list|,
name|curthread
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|vn
operator|=
name|NULL
expr_stmt|;
switch|switch
condition|(
name|xbb
operator|->
name|device_type
condition|)
block|{
case|case
name|XBB_TYPE_DISK
case|:
break|break;
case|case
name|XBB_TYPE_FILE
case|:
name|VFS_UNLOCK_GIANT
argument_list|(
name|vfs_is_locked
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|backend
operator|.
name|file
operator|.
name|cred
operator|!=
name|NULL
condition|)
block|{
name|crfree
argument_list|(
name|xbb
operator|->
name|backend
operator|.
name|file
operator|.
name|cred
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|backend
operator|.
name|file
operator|.
name|cred
operator|=
name|NULL
expr_stmt|;
block|}
break|break;
case|case
name|XBB_TYPE_NONE
case|:
default|default:
name|panic
argument_list|(
literal|"Unexpected backend type."
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
name|PICKUP_GIANT
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Open a character device to be used for backend I/O.  *  * \param xbb  Per-instance xbb configuration structure.  *  * \return  0 for success, errno codes for failure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_open_dev
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|struct
name|vattr
name|vattr
decl_stmt|;
name|struct
name|cdev
modifier|*
name|dev
decl_stmt|;
name|struct
name|cdevsw
modifier|*
name|devsw
decl_stmt|;
name|int
name|error
decl_stmt|;
name|xbb
operator|->
name|device_type
operator|=
name|XBB_TYPE_DISK
expr_stmt|;
name|xbb
operator|->
name|dispatch_io
operator|=
name|xbb_dispatch_dev
expr_stmt|;
name|xbb
operator|->
name|backend
operator|.
name|dev
operator|.
name|cdev
operator|=
name|xbb
operator|->
name|vn
operator|->
name|v_rdev
expr_stmt|;
name|xbb
operator|->
name|backend
operator|.
name|dev
operator|.
name|csw
operator|=
name|dev_refthread
argument_list|(
name|xbb
operator|->
name|backend
operator|.
name|dev
operator|.
name|cdev
argument_list|,
operator|&
name|xbb
operator|->
name|backend
operator|.
name|dev
operator|.
name|dev_ref
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|backend
operator|.
name|dev
operator|.
name|csw
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"Unable to retrieve device switch"
argument_list|)
expr_stmt|;
name|error
operator|=
name|VOP_GETATTR
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
operator|&
name|vattr
argument_list|,
name|NOCRED
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"error getting "
literal|"vnode attributes for device %s"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|dev
operator|=
name|xbb
operator|->
name|vn
operator|->
name|v_rdev
expr_stmt|;
name|devsw
operator|=
name|dev
operator|->
name|si_devsw
expr_stmt|;
if|if
condition|(
operator|!
name|devsw
operator|->
name|d_ioctl
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|ENODEV
argument_list|,
literal|"no d_ioctl for "
literal|"device %s!"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENODEV
operator|)
return|;
block|}
name|error
operator|=
name|devsw
operator|->
name|d_ioctl
argument_list|(
name|dev
argument_list|,
name|DIOCGSECTORSIZE
argument_list|,
operator|(
name|caddr_t
operator|)
operator|&
name|xbb
operator|->
name|sector_size
argument_list|,
name|FREAD
argument_list|,
name|curthread
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"error calling ioctl DIOCGSECTORSIZE "
literal|"for device %s"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|error
operator|=
name|devsw
operator|->
name|d_ioctl
argument_list|(
name|dev
argument_list|,
name|DIOCGMEDIASIZE
argument_list|,
operator|(
name|caddr_t
operator|)
operator|&
name|xbb
operator|->
name|media_size
argument_list|,
name|FREAD
argument_list|,
name|curthread
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"error calling ioctl DIOCGMEDIASIZE "
literal|"for device %s"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Open a file to be used for backend I/O.  *  * \param xbb  Per-instance xbb configuration structure.  *  * \return  0 for success, errno codes for failure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_open_file
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|struct
name|xbb_file_data
modifier|*
name|file_data
decl_stmt|;
name|struct
name|vattr
name|vattr
decl_stmt|;
name|int
name|error
decl_stmt|;
name|file_data
operator|=
operator|&
name|xbb
operator|->
name|backend
operator|.
name|file
expr_stmt|;
name|xbb
operator|->
name|device_type
operator|=
name|XBB_TYPE_FILE
expr_stmt|;
name|xbb
operator|->
name|dispatch_io
operator|=
name|xbb_dispatch_file
expr_stmt|;
name|error
operator|=
name|VOP_GETATTR
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
operator|&
name|vattr
argument_list|,
name|curthread
operator|->
name|td_ucred
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"error calling VOP_GETATTR()"
literal|"for file %s"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
comment|/* 	 * Verify that we have the ability to upgrade to exclusive 	 * access on this file so we can trap errors at open instead 	 * of reporting them during first access. 	 */
if|if
condition|(
name|VOP_ISLOCKED
argument_list|(
name|xbb
operator|->
name|vn
argument_list|)
operator|!=
name|LK_EXCLUSIVE
condition|)
block|{
name|vn_lock
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
name|LK_UPGRADE
operator||
name|LK_RETRY
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|vn
operator|->
name|v_iflag
operator|&
name|VI_DOOMED
condition|)
block|{
name|error
operator|=
name|EBADF
expr_stmt|;
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"error locking file %s"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
block|}
name|file_data
operator|->
name|cred
operator|=
name|crhold
argument_list|(
name|curthread
operator|->
name|td_ucred
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|media_size
operator|=
name|vattr
operator|.
name|va_size
expr_stmt|;
comment|/* 	 * XXX KDM vattr.va_blocksize may be larger than 512 bytes here. 	 * With ZFS, it is 131072 bytes.  Block sizes that large don't work 	 * with disklabel and UFS on FreeBSD at least.  Large block sizes 	 * may not work with other OSes as well.  So just export a sector 	 * size of 512 bytes, which should work with any OS or 	 * application.  Since our backing is a file, any block size will 	 * work fine for the backing store. 	 */
if|#
directive|if
literal|0
block|xbb->sector_size = vattr.va_blocksize;
endif|#
directive|endif
name|xbb
operator|->
name|sector_size
operator|=
literal|512
expr_stmt|;
comment|/* 	 * Sanity check.  The media size has to be at least one 	 * sector long. 	 */
if|if
condition|(
name|xbb
operator|->
name|media_size
operator|<
name|xbb
operator|->
name|sector_size
condition|)
block|{
name|error
operator|=
name|EINVAL
expr_stmt|;
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"file %s size %ju< block size %u"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|,
operator|(
name|uintmax_t
operator|)
name|xbb
operator|->
name|media_size
argument_list|,
name|xbb
operator|->
name|sector_size
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Open the backend provider for this connection.  *  * \param xbb  Per-instance xbb configuration structure.  *  * \return  0 for success, errno codes for failure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_open_backend
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|struct
name|nameidata
name|nd
decl_stmt|;
name|int
name|flags
decl_stmt|;
name|int
name|error
decl_stmt|;
name|int
name|vfs_is_locked
decl_stmt|;
name|flags
operator|=
name|FREAD
expr_stmt|;
name|error
operator|=
literal|0
expr_stmt|;
name|DPRINTF
argument_list|(
literal|"opening dev=%s\n"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
if|if
condition|(
name|rootvnode
operator|==
name|NULL
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|ENOENT
argument_list|,
literal|"Root file system not mounted"
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENOENT
operator|)
return|;
block|}
if|if
condition|(
operator|(
name|xbb
operator|->
name|flags
operator|&
name|XBBF_READ_ONLY
operator|)
operator|==
literal|0
condition|)
name|flags
operator||=
name|FWRITE
expr_stmt|;
if|if
condition|(
operator|!
name|curthread
operator|->
name|td_proc
operator|->
name|p_fd
operator|->
name|fd_cdir
condition|)
block|{
name|curthread
operator|->
name|td_proc
operator|->
name|p_fd
operator|->
name|fd_cdir
operator|=
name|rootvnode
expr_stmt|;
name|VREF
argument_list|(
name|rootvnode
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|curthread
operator|->
name|td_proc
operator|->
name|p_fd
operator|->
name|fd_rdir
condition|)
block|{
name|curthread
operator|->
name|td_proc
operator|->
name|p_fd
operator|->
name|fd_rdir
operator|=
name|rootvnode
expr_stmt|;
name|VREF
argument_list|(
name|rootvnode
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|curthread
operator|->
name|td_proc
operator|->
name|p_fd
operator|->
name|fd_jdir
condition|)
block|{
name|curthread
operator|->
name|td_proc
operator|->
name|p_fd
operator|->
name|fd_jdir
operator|=
name|rootvnode
expr_stmt|;
name|VREF
argument_list|(
name|rootvnode
argument_list|)
expr_stmt|;
block|}
name|again
label|:
name|NDINIT
argument_list|(
operator|&
name|nd
argument_list|,
name|LOOKUP
argument_list|,
name|FOLLOW
argument_list|,
name|UIO_SYSSPACE
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|,
name|curthread
argument_list|)
expr_stmt|;
name|error
operator|=
name|vn_open
argument_list|(
operator|&
name|nd
argument_list|,
operator|&
name|flags
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
comment|/* 		 * This is the only reasonable guess we can make as far as 		 * path if the user doesn't give us a fully qualified path. 		 * If they want to specify a file, they need to specify the 		 * full path. 		 */
if|if
condition|(
name|xbb
operator|->
name|dev_name
index|[
literal|0
index|]
operator|!=
literal|'/'
condition|)
block|{
name|char
modifier|*
name|dev_path
init|=
literal|"/dev/"
decl_stmt|;
name|char
modifier|*
name|dev_name
decl_stmt|;
comment|/* Try adding device path at beginning of name */
name|dev_name
operator|=
name|malloc
argument_list|(
name|strlen
argument_list|(
name|xbb
operator|->
name|dev_name
argument_list|)
operator|+
name|strlen
argument_list|(
name|dev_path
argument_list|)
operator|+
literal|1
argument_list|,
name|M_XENBLOCKBACK
argument_list|,
name|M_NOWAIT
argument_list|)
expr_stmt|;
if|if
condition|(
name|dev_name
condition|)
block|{
name|sprintf
argument_list|(
name|dev_name
argument_list|,
literal|"%s%s"
argument_list|,
name|dev_path
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|xbb
operator|->
name|dev_name
argument_list|,
name|M_XENBLOCKBACK
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|dev_name
operator|=
name|dev_name
expr_stmt|;
goto|goto
name|again
goto|;
block|}
block|}
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"error opening device %s"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|vfs_is_locked
operator|=
name|NDHASGIANT
argument_list|(
operator|&
name|nd
argument_list|)
expr_stmt|;
name|NDFREE
argument_list|(
operator|&
name|nd
argument_list|,
name|NDF_ONLY_PNBUF
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|vn
operator|=
name|nd
operator|.
name|ni_vp
expr_stmt|;
comment|/* We only support disks and files. */
if|if
condition|(
name|vn_isdisk
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
operator|&
name|error
argument_list|)
condition|)
block|{
name|error
operator|=
name|xbb_open_dev
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|xbb
operator|->
name|vn
operator|->
name|v_type
operator|==
name|VREG
condition|)
block|{
name|error
operator|=
name|xbb_open_file
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|error
operator|=
name|EINVAL
expr_stmt|;
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"%s is not a disk "
literal|"or file"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
block|}
name|VOP_UNLOCK
argument_list|(
name|xbb
operator|->
name|vn
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|VFS_UNLOCK_GIANT
argument_list|(
name|vfs_is_locked
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|xbb_close_backend
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|xbb
operator|->
name|sector_size_shift
operator|=
name|fls
argument_list|(
name|xbb
operator|->
name|sector_size
argument_list|)
operator|-
literal|1
expr_stmt|;
name|xbb
operator|->
name|media_num_sectors
operator|=
name|xbb
operator|->
name|media_size
operator|>>
name|xbb
operator|->
name|sector_size_shift
expr_stmt|;
name|DPRINTF
argument_list|(
literal|"opened %s=%s sector_size=%u media_size=%"
name|PRId64
literal|"\n"
argument_list|,
operator|(
name|xbb
operator|->
name|device_type
operator|==
name|XBB_TYPE_DISK
operator|)
condition|?
literal|"dev"
else|:
literal|"file"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|,
name|xbb
operator|->
name|sector_size
argument_list|,
name|xbb
operator|->
name|media_size
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*------------------------ Inter-Domain Communication ------------------------*/
end_comment

begin_comment
comment|/**  * Free dynamically allocated KVA or pseudo-physical address allocations.  *  * \param xbb  Per-instance xbb configuration structure.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_free_communication_mem
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
if|if
condition|(
name|xbb
operator|->
name|kva
operator|!=
literal|0
condition|)
block|{
ifndef|#
directive|ifndef
name|XENHVM
name|kmem_free
argument_list|(
name|kernel_map
argument_list|,
name|xbb
operator|->
name|kva
argument_list|,
name|xbb
operator|->
name|kva_size
argument_list|)
expr_stmt|;
else|#
directive|else
if|if
condition|(
name|xbb
operator|->
name|pseudo_phys_res
operator|!=
name|NULL
condition|)
block|{
name|bus_release_resource
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|SYS_RES_MEMORY
argument_list|,
name|xbb
operator|->
name|pseudo_phys_res_id
argument_list|,
name|xbb
operator|->
name|pseudo_phys_res
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|pseudo_phys_res
operator|=
name|NULL
expr_stmt|;
block|}
endif|#
directive|endif
block|}
name|xbb
operator|->
name|kva
operator|=
literal|0
expr_stmt|;
name|xbb
operator|->
name|gnt_base_addr
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|kva_free
operator|!=
name|NULL
condition|)
block|{
name|free
argument_list|(
name|xbb
operator|->
name|kva_free
argument_list|,
name|M_XENBLOCKBACK
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|kva_free
operator|=
name|NULL
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**  * Cleanup all inter-domain communication mechanisms.  *  * \param xbb  Per-instance xbb configuration structure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_disconnect
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|struct
name|gnttab_unmap_grant_ref
name|ops
index|[
name|XBB_MAX_RING_PAGES
index|]
decl_stmt|;
name|struct
name|gnttab_unmap_grant_ref
modifier|*
name|op
decl_stmt|;
name|u_int
name|ring_idx
decl_stmt|;
name|int
name|error
decl_stmt|;
name|DPRINTF
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|xbb
operator|->
name|flags
operator|&
name|XBBF_RING_CONNECTED
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|if
condition|(
name|xbb
operator|->
name|irq
operator|!=
literal|0
condition|)
block|{
name|unbind_from_irqhandler
argument_list|(
name|xbb
operator|->
name|irq
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|irq
operator|=
literal|0
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
name|taskqueue_drain
argument_list|(
name|xbb
operator|->
name|io_taskqueue
argument_list|,
operator|&
name|xbb
operator|->
name|io_task
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
comment|/* 	 * No new interrupts can generate work, but we must wait 	 * for all currently active requests to drain. 	 */
if|if
condition|(
name|xbb
operator|->
name|active_request_count
operator|!=
literal|0
condition|)
return|return
operator|(
name|EAGAIN
operator|)
return|;
for|for
control|(
name|ring_idx
operator|=
literal|0
operator|,
name|op
operator|=
name|ops
init|;
name|ring_idx
operator|<
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
condition|;
name|ring_idx
operator|++
operator|,
name|op
operator|++
control|)
block|{
name|op
operator|->
name|host_addr
operator|=
name|xbb
operator|->
name|ring_config
operator|.
name|gnt_addr
operator|+
operator|(
name|ring_idx
operator|*
name|PAGE_SIZE
operator|)
expr_stmt|;
name|op
operator|->
name|dev_bus_addr
operator|=
name|xbb
operator|->
name|ring_config
operator|.
name|bus_addr
index|[
name|ring_idx
index|]
expr_stmt|;
name|op
operator|->
name|handle
operator|=
name|xbb
operator|->
name|ring_config
operator|.
name|handle
index|[
name|ring_idx
index|]
expr_stmt|;
block|}
name|error
operator|=
name|HYPERVISOR_grant_table_op
argument_list|(
name|GNTTABOP_unmap_grant_ref
argument_list|,
name|ops
argument_list|,
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"Grant table op failed (%d)"
argument_list|,
name|error
argument_list|)
expr_stmt|;
name|xbb_free_communication_mem
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|requests
operator|!=
name|NULL
condition|)
block|{
name|free
argument_list|(
name|xbb
operator|->
name|requests
argument_list|,
name|M_XENBLOCKBACK
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|requests
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|xbb
operator|->
name|request_lists
operator|!=
name|NULL
condition|)
block|{
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* There is one request list for ever allocated request. */
for|for
control|(
name|i
operator|=
literal|0
operator|,
name|reqlist
operator|=
name|xbb
operator|->
name|request_lists
init|;
name|i
operator|<
name|xbb
operator|->
name|max_requests
condition|;
name|i
operator|++
operator|,
name|reqlist
operator|++
control|)
block|{
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
if|if
condition|(
name|reqlist
operator|->
name|bounce
operator|!=
name|NULL
condition|)
block|{
name|free
argument_list|(
name|reqlist
operator|->
name|bounce
argument_list|,
name|M_XENBLOCKBACK
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|bounce
operator|=
name|NULL
expr_stmt|;
block|}
endif|#
directive|endif
if|if
condition|(
name|reqlist
operator|->
name|gnt_handles
operator|!=
name|NULL
condition|)
block|{
name|free
argument_list|(
name|reqlist
operator|->
name|gnt_handles
argument_list|,
name|M_XENBLOCKBACK
argument_list|)
expr_stmt|;
name|reqlist
operator|->
name|gnt_handles
operator|=
name|NULL
expr_stmt|;
block|}
block|}
name|free
argument_list|(
name|xbb
operator|->
name|request_lists
argument_list|,
name|M_XENBLOCKBACK
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|request_lists
operator|=
name|NULL
expr_stmt|;
block|}
name|xbb
operator|->
name|flags
operator|&=
operator|~
name|XBBF_RING_CONNECTED
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Map shared memory ring into domain local address space, initialize  * ring control structures, and bind an interrupt to the event channel  * used to notify us of ring changes.  *  * \param xbb  Per-instance xbb configuration structure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_connect_ring
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|struct
name|gnttab_map_grant_ref
name|gnts
index|[
name|XBB_MAX_RING_PAGES
index|]
decl_stmt|;
name|struct
name|gnttab_map_grant_ref
modifier|*
name|gnt
decl_stmt|;
name|u_int
name|ring_idx
decl_stmt|;
name|int
name|error
decl_stmt|;
if|if
condition|(
operator|(
name|xbb
operator|->
name|flags
operator|&
name|XBBF_RING_CONNECTED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* 	 * Kva for our ring is at the tail of the region of kva allocated 	 * by xbb_alloc_communication_mem(). 	 */
name|xbb
operator|->
name|ring_config
operator|.
name|va
operator|=
name|xbb
operator|->
name|kva
operator|+
operator|(
name|xbb
operator|->
name|kva_size
operator|-
operator|(
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
operator|*
name|PAGE_SIZE
operator|)
operator|)
expr_stmt|;
name|xbb
operator|->
name|ring_config
operator|.
name|gnt_addr
operator|=
name|xbb
operator|->
name|gnt_base_addr
operator|+
operator|(
name|xbb
operator|->
name|kva_size
operator|-
operator|(
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
operator|*
name|PAGE_SIZE
operator|)
operator|)
expr_stmt|;
for|for
control|(
name|ring_idx
operator|=
literal|0
operator|,
name|gnt
operator|=
name|gnts
init|;
name|ring_idx
operator|<
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
condition|;
name|ring_idx
operator|++
operator|,
name|gnt
operator|++
control|)
block|{
name|gnt
operator|->
name|host_addr
operator|=
name|xbb
operator|->
name|ring_config
operator|.
name|gnt_addr
operator|+
operator|(
name|ring_idx
operator|*
name|PAGE_SIZE
operator|)
expr_stmt|;
name|gnt
operator|->
name|flags
operator|=
name|GNTMAP_host_map
expr_stmt|;
name|gnt
operator|->
name|ref
operator|=
name|xbb
operator|->
name|ring_config
operator|.
name|ring_ref
index|[
name|ring_idx
index|]
expr_stmt|;
name|gnt
operator|->
name|dom
operator|=
name|xbb
operator|->
name|otherend_id
expr_stmt|;
block|}
name|error
operator|=
name|HYPERVISOR_grant_table_op
argument_list|(
name|GNTTABOP_map_grant_ref
argument_list|,
name|gnts
argument_list|,
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
name|panic
argument_list|(
literal|"blkback: Ring page grant table op failed (%d)"
argument_list|,
name|error
argument_list|)
expr_stmt|;
for|for
control|(
name|ring_idx
operator|=
literal|0
operator|,
name|gnt
operator|=
name|gnts
init|;
name|ring_idx
operator|<
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
condition|;
name|ring_idx
operator|++
operator|,
name|gnt
operator|++
control|)
block|{
if|if
condition|(
name|gnt
operator|->
name|status
operator|!=
literal|0
condition|)
block|{
name|xbb
operator|->
name|ring_config
operator|.
name|va
operator|=
literal|0
expr_stmt|;
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|EACCES
argument_list|,
literal|"Ring shared page mapping failed. "
literal|"Status %d."
argument_list|,
name|gnt
operator|->
name|status
argument_list|)
expr_stmt|;
return|return
operator|(
name|EACCES
operator|)
return|;
block|}
name|xbb
operator|->
name|ring_config
operator|.
name|handle
index|[
name|ring_idx
index|]
operator|=
name|gnt
operator|->
name|handle
expr_stmt|;
name|xbb
operator|->
name|ring_config
operator|.
name|bus_addr
index|[
name|ring_idx
index|]
operator|=
name|gnt
operator|->
name|dev_bus_addr
expr_stmt|;
block|}
comment|/* Initialize the ring based on ABI. */
switch|switch
condition|(
name|xbb
operator|->
name|abi
condition|)
block|{
case|case
name|BLKIF_PROTOCOL_NATIVE
case|:
block|{
name|blkif_sring_t
modifier|*
name|sring
decl_stmt|;
name|sring
operator|=
operator|(
name|blkif_sring_t
operator|*
operator|)
name|xbb
operator|->
name|ring_config
operator|.
name|va
expr_stmt|;
name|BACK_RING_INIT
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|native
argument_list|,
name|sring
argument_list|,
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
break|break;
block|}
case|case
name|BLKIF_PROTOCOL_X86_32
case|:
block|{
name|blkif_x86_32_sring_t
modifier|*
name|sring_x86_32
decl_stmt|;
name|sring_x86_32
operator|=
operator|(
name|blkif_x86_32_sring_t
operator|*
operator|)
name|xbb
operator|->
name|ring_config
operator|.
name|va
expr_stmt|;
name|BACK_RING_INIT
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|x86_32
argument_list|,
name|sring_x86_32
argument_list|,
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
break|break;
block|}
case|case
name|BLKIF_PROTOCOL_X86_64
case|:
block|{
name|blkif_x86_64_sring_t
modifier|*
name|sring_x86_64
decl_stmt|;
name|sring_x86_64
operator|=
operator|(
name|blkif_x86_64_sring_t
operator|*
operator|)
name|xbb
operator|->
name|ring_config
operator|.
name|va
expr_stmt|;
name|BACK_RING_INIT
argument_list|(
operator|&
name|xbb
operator|->
name|rings
operator|.
name|x86_64
argument_list|,
name|sring_x86_64
argument_list|,
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
break|break;
block|}
default|default:
name|panic
argument_list|(
literal|"Unexpected blkif protocol ABI."
argument_list|)
expr_stmt|;
block|}
name|xbb
operator|->
name|flags
operator||=
name|XBBF_RING_CONNECTED
expr_stmt|;
name|error
operator|=
name|bind_interdomain_evtchn_to_irqhandler
argument_list|(
name|xbb
operator|->
name|otherend_id
argument_list|,
name|xbb
operator|->
name|ring_config
operator|.
name|evtchn
argument_list|,
name|device_get_nameunit
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
name|xbb_intr
argument_list|,
comment|/*arg*/
name|xbb
argument_list|,
name|INTR_TYPE_BIO
operator||
name|INTR_MPSAFE
argument_list|,
operator|&
name|xbb
operator|->
name|irq
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
operator|(
name|void
operator|)
name|xbb_disconnect
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"binding event channel"
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|DPRINTF
argument_list|(
literal|"rings connected!\n"
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
end_function

begin_comment
comment|/* Needed to make bit_alloc() macro work */
end_comment

begin_define
define|#
directive|define
name|calloc
parameter_list|(
name|count
parameter_list|,
name|size
parameter_list|)
value|malloc((count)*(size), M_XENBLOCKBACK,	\ 				   M_NOWAIT|M_ZERO);
end_define

begin_comment
comment|/**  * Size KVA and pseudo-physical address allocations based on negotiated  * values for the size and number of I/O requests, and the size of our  * communication ring.  *  * \param xbb  Per-instance xbb configuration structure.  *  * These address spaces are used to dynamically map pages in the  * front-end's domain into our own.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_alloc_communication_mem
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|xbb
operator|->
name|reqlist_kva_pages
operator|=
name|xbb
operator|->
name|max_requests
operator|*
name|xbb
operator|->
name|max_request_segments
expr_stmt|;
name|xbb
operator|->
name|reqlist_kva_size
operator|=
name|xbb
operator|->
name|reqlist_kva_pages
operator|*
name|PAGE_SIZE
expr_stmt|;
name|xbb
operator|->
name|kva_size
operator|=
name|xbb
operator|->
name|reqlist_kva_size
operator|+
operator|(
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
operator|*
name|PAGE_SIZE
operator|)
expr_stmt|;
name|xbb
operator|->
name|kva_free
operator|=
name|bit_alloc
argument_list|(
name|xbb
operator|->
name|reqlist_kva_pages
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|kva_free
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
name|DPRINTF
argument_list|(
literal|"%s: kva_size = %d, reqlist_kva_size = %d\n"
argument_list|,
name|device_get_nameunit
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
name|xbb
operator|->
name|kva_size
argument_list|,
name|xbb
operator|->
name|reqlist_kva_size
argument_list|)
expr_stmt|;
ifndef|#
directive|ifndef
name|XENHVM
name|xbb
operator|->
name|kva
operator|=
name|kmem_alloc_nofault
argument_list|(
name|kernel_map
argument_list|,
name|xbb
operator|->
name|kva_size
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|kva
operator|==
literal|0
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
name|xbb
operator|->
name|gnt_base_addr
operator|=
name|xbb
operator|->
name|kva
expr_stmt|;
else|#
directive|else
comment|/* XENHVM */
comment|/* 	 * Reserve a range of pseudo physical memory that we can map 	 * into kva.  These pages will only be backed by machine 	 * pages ("real memory") during the lifetime of front-end requests 	 * via grant table operations. 	 */
name|xbb
operator|->
name|pseudo_phys_res_id
operator|=
literal|0
expr_stmt|;
name|xbb
operator|->
name|pseudo_phys_res
operator|=
name|bus_alloc_resource
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|SYS_RES_MEMORY
argument_list|,
operator|&
name|xbb
operator|->
name|pseudo_phys_res_id
argument_list|,
literal|0
argument_list|,
operator|~
literal|0
argument_list|,
name|xbb
operator|->
name|kva_size
argument_list|,
name|RF_ACTIVE
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|pseudo_phys_res
operator|==
name|NULL
condition|)
block|{
name|xbb
operator|->
name|kva
operator|=
literal|0
expr_stmt|;
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
name|xbb
operator|->
name|kva
operator|=
operator|(
name|vm_offset_t
operator|)
name|rman_get_virtual
argument_list|(
name|xbb
operator|->
name|pseudo_phys_res
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|gnt_base_addr
operator|=
name|rman_get_start
argument_list|(
name|xbb
operator|->
name|pseudo_phys_res
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* XENHVM */
name|DPRINTF
argument_list|(
literal|"%s: kva: %#jx, gnt_base_addr: %#jx\n"
argument_list|,
name|device_get_nameunit
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
operator|(
name|uintmax_t
operator|)
name|xbb
operator|->
name|kva
argument_list|,
operator|(
name|uintmax_t
operator|)
name|xbb
operator|->
name|gnt_base_addr
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Collect front-end information from the XenStore.  *  * \param xbb  Per-instance xbb configuration structure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_collect_frontend_info
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|char
name|protocol_abi
index|[
literal|64
index|]
decl_stmt|;
specifier|const
name|char
modifier|*
name|otherend_path
decl_stmt|;
name|int
name|error
decl_stmt|;
name|u_int
name|ring_idx
decl_stmt|;
name|otherend_path
operator|=
name|xenbus_get_otherend_path
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
expr_stmt|;
comment|/* 	 * Protocol defaults valid even if all negotiation fails. 	 */
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
operator|=
literal|1
expr_stmt|;
name|xbb
operator|->
name|max_requests
operator|=
name|BLKIF_MAX_RING_REQUESTS
argument_list|(
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|max_request_segments
operator|=
name|BLKIF_MAX_SEGMENTS_PER_HEADER_BLOCK
expr_stmt|;
name|xbb
operator|->
name|max_request_size
operator|=
name|xbb
operator|->
name|max_request_segments
operator|*
name|PAGE_SIZE
expr_stmt|;
comment|/* 	 * Mandatory data (used in all versions of the protocol) first. 	 */
name|error
operator|=
name|xs_gather
argument_list|(
name|XST_NIL
argument_list|,
name|otherend_path
argument_list|,
literal|"ring-ref"
argument_list|,
literal|"%"
name|PRIu32
argument_list|,
operator|&
name|xbb
operator|->
name|ring_config
operator|.
name|ring_ref
index|[
literal|0
index|]
argument_list|,
literal|"event-channel"
argument_list|,
literal|"%"
name|PRIu32
argument_list|,
operator|&
name|xbb
operator|->
name|ring_config
operator|.
name|evtchn
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"Unable to retrieve ring information from "
literal|"frontend %s.  Unable to connect."
argument_list|,
name|xenbus_get_otherend_path
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
comment|/* 	 * These fields are initialized to legacy protocol defaults 	 * so we only need to fail if reading the updated value succeeds 	 * and the new value is outside of its allowed range. 	 * 	 * \note xs_gather() returns on the first encountered error, so 	 *       we must use independant calls in order to guarantee 	 *       we don't miss information in a sparsly populated front-end 	 *       tree. 	 */
operator|(
name|void
operator|)
name|xs_scanf
argument_list|(
name|XST_NIL
argument_list|,
name|otherend_path
argument_list|,
literal|"ring-pages"
argument_list|,
name|NULL
argument_list|,
literal|"%u"
argument_list|,
operator|&
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|xs_scanf
argument_list|(
name|XST_NIL
argument_list|,
name|otherend_path
argument_list|,
literal|"max-requests"
argument_list|,
name|NULL
argument_list|,
literal|"%u"
argument_list|,
operator|&
name|xbb
operator|->
name|max_requests
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|xs_scanf
argument_list|(
name|XST_NIL
argument_list|,
name|otherend_path
argument_list|,
literal|"max-request-segments"
argument_list|,
name|NULL
argument_list|,
literal|"%u"
argument_list|,
operator|&
name|xbb
operator|->
name|max_request_segments
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|xs_scanf
argument_list|(
name|XST_NIL
argument_list|,
name|otherend_path
argument_list|,
literal|"max-request-size"
argument_list|,
name|NULL
argument_list|,
literal|"%u"
argument_list|,
operator|&
name|xbb
operator|->
name|max_request_size
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
operator|>
name|XBB_MAX_RING_PAGES
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|EINVAL
argument_list|,
literal|"Front-end specificed ring-pages of %u "
literal|"exceeds backend limit of %zu.  "
literal|"Unable to connect."
argument_list|,
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
argument_list|,
name|XBB_MAX_RING_PAGES
argument_list|)
expr_stmt|;
return|return
operator|(
name|EINVAL
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|xbb
operator|->
name|max_requests
operator|>
name|XBB_MAX_REQUESTS
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|EINVAL
argument_list|,
literal|"Front-end specificed max_requests of %u "
literal|"exceeds backend limit of %u.  "
literal|"Unable to connect."
argument_list|,
name|xbb
operator|->
name|max_requests
argument_list|,
name|XBB_MAX_REQUESTS
argument_list|)
expr_stmt|;
return|return
operator|(
name|EINVAL
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|xbb
operator|->
name|max_request_segments
operator|>
name|XBB_MAX_SEGMENTS_PER_REQUEST
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|EINVAL
argument_list|,
literal|"Front-end specificed max_requests_segments "
literal|"of %u exceeds backend limit of %u.  "
literal|"Unable to connect."
argument_list|,
name|xbb
operator|->
name|max_request_segments
argument_list|,
name|XBB_MAX_SEGMENTS_PER_REQUEST
argument_list|)
expr_stmt|;
return|return
operator|(
name|EINVAL
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|xbb
operator|->
name|max_request_size
operator|>
name|XBB_MAX_REQUEST_SIZE
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|EINVAL
argument_list|,
literal|"Front-end specificed max_request_size "
literal|"of %u exceeds backend limit of %u.  "
literal|"Unable to connect."
argument_list|,
name|xbb
operator|->
name|max_request_size
argument_list|,
name|XBB_MAX_REQUEST_SIZE
argument_list|)
expr_stmt|;
return|return
operator|(
name|EINVAL
operator|)
return|;
block|}
comment|/* If using a multi-page ring, pull in the remaining references. */
for|for
control|(
name|ring_idx
operator|=
literal|1
init|;
name|ring_idx
operator|<
name|xbb
operator|->
name|ring_config
operator|.
name|ring_pages
condition|;
name|ring_idx
operator|++
control|)
block|{
name|char
name|ring_ref_name
index|[]
init|=
literal|"ring_refXX"
decl_stmt|;
name|snprintf
argument_list|(
name|ring_ref_name
argument_list|,
sizeof|sizeof
argument_list|(
name|ring_ref_name
argument_list|)
argument_list|,
literal|"ring-ref%u"
argument_list|,
name|ring_idx
argument_list|)
expr_stmt|;
name|error
operator|=
name|xs_scanf
argument_list|(
name|XST_NIL
argument_list|,
name|otherend_path
argument_list|,
name|ring_ref_name
argument_list|,
name|NULL
argument_list|,
literal|"%"
name|PRIu32
argument_list|,
operator|&
name|xbb
operator|->
name|ring_config
operator|.
name|ring_ref
index|[
name|ring_idx
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"Failed to retriev grant reference "
literal|"for page %u of shared ring.  Unable "
literal|"to connect."
argument_list|,
name|ring_idx
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
block|}
name|error
operator|=
name|xs_gather
argument_list|(
name|XST_NIL
argument_list|,
name|otherend_path
argument_list|,
literal|"protocol"
argument_list|,
literal|"%63s"
argument_list|,
name|protocol_abi
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
operator|||
operator|!
name|strcmp
argument_list|(
name|protocol_abi
argument_list|,
name|XEN_IO_PROTO_ABI_NATIVE
argument_list|)
condition|)
block|{
comment|/* 		 * Assume native if the frontend has not 		 * published ABI data or it has published and 		 * matches our own ABI. 		 */
name|xbb
operator|->
name|abi
operator|=
name|BLKIF_PROTOCOL_NATIVE
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|strcmp
argument_list|(
name|protocol_abi
argument_list|,
name|XEN_IO_PROTO_ABI_X86_32
argument_list|)
condition|)
block|{
name|xbb
operator|->
name|abi
operator|=
name|BLKIF_PROTOCOL_X86_32
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|strcmp
argument_list|(
name|protocol_abi
argument_list|,
name|XEN_IO_PROTO_ABI_X86_64
argument_list|)
condition|)
block|{
name|xbb
operator|->
name|abi
operator|=
name|BLKIF_PROTOCOL_X86_64
expr_stmt|;
block|}
else|else
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|EINVAL
argument_list|,
literal|"Unknown protocol ABI (%s) published by "
literal|"frontend.  Unable to connect."
argument_list|,
name|protocol_abi
argument_list|)
expr_stmt|;
return|return
operator|(
name|EINVAL
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Allocate per-request data structures given request size and number  * information negotiated with the front-end.  *  * \param xbb  Per-instance xbb configuration structure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_alloc_requests
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|struct
name|xbb_xen_req
modifier|*
name|req
decl_stmt|;
name|struct
name|xbb_xen_req
modifier|*
name|last_req
decl_stmt|;
comment|/* 	 * Allocate request book keeping datastructures. 	 */
name|xbb
operator|->
name|requests
operator|=
name|malloc
argument_list|(
name|xbb
operator|->
name|max_requests
operator|*
sizeof|sizeof
argument_list|(
operator|*
name|xbb
operator|->
name|requests
argument_list|)
argument_list|,
name|M_XENBLOCKBACK
argument_list|,
name|M_NOWAIT
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|requests
operator|==
name|NULL
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|ENOMEM
argument_list|,
literal|"Unable to allocate request structures"
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
name|req
operator|=
name|xbb
operator|->
name|requests
expr_stmt|;
name|last_req
operator|=
operator|&
name|xbb
operator|->
name|requests
index|[
name|xbb
operator|->
name|max_requests
operator|-
literal|1
index|]
expr_stmt|;
name|STAILQ_INIT
argument_list|(
operator|&
name|xbb
operator|->
name|request_free_stailq
argument_list|)
expr_stmt|;
while|while
condition|(
name|req
operator|<=
name|last_req
condition|)
block|{
name|STAILQ_INSERT_TAIL
argument_list|(
operator|&
name|xbb
operator|->
name|request_free_stailq
argument_list|,
name|req
argument_list|,
name|links
argument_list|)
expr_stmt|;
name|req
operator|++
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|xbb_alloc_request_lists
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|struct
name|xbb_xen_reqlist
modifier|*
name|reqlist
decl_stmt|;
comment|/* 	 * If no requests can be merged, we need 1 request list per 	 * in flight request. 	 */
name|xbb
operator|->
name|request_lists
operator|=
name|malloc
argument_list|(
name|xbb
operator|->
name|max_requests
operator|*
sizeof|sizeof
argument_list|(
operator|*
name|xbb
operator|->
name|request_lists
argument_list|)
argument_list|,
name|M_XENBLOCKBACK
argument_list|,
name|M_NOWAIT
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|request_lists
operator|==
name|NULL
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|ENOMEM
argument_list|,
literal|"Unable to allocate request list structures"
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
name|STAILQ_INIT
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_free_stailq
argument_list|)
expr_stmt|;
name|STAILQ_INIT
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_pending_stailq
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|xbb
operator|->
name|max_requests
condition|;
name|i
operator|++
control|)
block|{
name|int
name|seg
decl_stmt|;
name|reqlist
operator|=
operator|&
name|xbb
operator|->
name|request_lists
index|[
name|i
index|]
expr_stmt|;
name|reqlist
operator|->
name|xbb
operator|=
name|xbb
expr_stmt|;
ifdef|#
directive|ifdef
name|XBB_USE_BOUNCE_BUFFERS
name|reqlist
operator|->
name|bounce
operator|=
name|malloc
argument_list|(
name|xbb
operator|->
name|max_reqlist_size
argument_list|,
name|M_XENBLOCKBACK
argument_list|,
name|M_NOWAIT
argument_list|)
expr_stmt|;
if|if
condition|(
name|reqlist
operator|->
name|bounce
operator|==
name|NULL
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|ENOMEM
argument_list|,
literal|"Unable to allocate request "
literal|"bounce buffers"
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
endif|#
directive|endif
comment|/* XBB_USE_BOUNCE_BUFFERS */
name|reqlist
operator|->
name|gnt_handles
operator|=
name|malloc
argument_list|(
name|xbb
operator|->
name|max_reqlist_segments
operator|*
sizeof|sizeof
argument_list|(
operator|*
name|reqlist
operator|->
name|gnt_handles
argument_list|)
argument_list|,
name|M_XENBLOCKBACK
argument_list|,
name|M_NOWAIT
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|reqlist
operator|->
name|gnt_handles
operator|==
name|NULL
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|ENOMEM
argument_list|,
literal|"Unable to allocate request "
literal|"grant references"
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
for|for
control|(
name|seg
operator|=
literal|0
init|;
name|seg
operator|<
name|xbb
operator|->
name|max_reqlist_segments
condition|;
name|seg
operator|++
control|)
name|reqlist
operator|->
name|gnt_handles
index|[
name|seg
index|]
operator|=
name|GRANT_REF_INVALID
expr_stmt|;
name|STAILQ_INSERT_TAIL
argument_list|(
operator|&
name|xbb
operator|->
name|reqlist_free_stailq
argument_list|,
name|reqlist
argument_list|,
name|links
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Supply information about the physical device to the frontend  * via XenBus.  *  * \param xbb  Per-instance xbb configuration structure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_publish_backend_info
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|struct
name|xs_transaction
name|xst
decl_stmt|;
specifier|const
name|char
modifier|*
name|our_path
decl_stmt|;
specifier|const
name|char
modifier|*
name|leaf
decl_stmt|;
name|int
name|error
decl_stmt|;
name|our_path
operator|=
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
expr_stmt|;
while|while
condition|(
literal|1
condition|)
block|{
name|error
operator|=
name|xs_transaction_start
argument_list|(
operator|&
name|xst
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"Error publishing backend info "
literal|"(start transaction)"
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|leaf
operator|=
literal|"sectors"
expr_stmt|;
name|error
operator|=
name|xs_printf
argument_list|(
name|xst
argument_list|,
name|our_path
argument_list|,
name|leaf
argument_list|,
literal|"%"
name|PRIu64
argument_list|,
name|xbb
operator|->
name|media_num_sectors
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
break|break;
comment|/* XXX Support all VBD attributes here. */
name|leaf
operator|=
literal|"info"
expr_stmt|;
name|error
operator|=
name|xs_printf
argument_list|(
name|xst
argument_list|,
name|our_path
argument_list|,
name|leaf
argument_list|,
literal|"%u"
argument_list|,
name|xbb
operator|->
name|flags
operator|&
name|XBBF_READ_ONLY
condition|?
name|VDISK_READONLY
else|:
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
break|break;
name|leaf
operator|=
literal|"sector-size"
expr_stmt|;
name|error
operator|=
name|xs_printf
argument_list|(
name|xst
argument_list|,
name|our_path
argument_list|,
name|leaf
argument_list|,
literal|"%u"
argument_list|,
name|xbb
operator|->
name|sector_size
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
break|break;
name|error
operator|=
name|xs_transaction_end
argument_list|(
name|xst
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|==
literal|0
condition|)
block|{
return|return
operator|(
literal|0
operator|)
return|;
block|}
elseif|else
if|if
condition|(
name|error
operator|!=
name|EAGAIN
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"ending transaction"
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
block|}
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"writing %s/%s"
argument_list|,
name|our_path
argument_list|,
name|leaf
argument_list|)
expr_stmt|;
name|xs_transaction_end
argument_list|(
name|xst
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Connect to our blkfront peer now that it has completed publishing  * its configuration into the XenStore.  *  * \param xbb  Per-instance xbb configuration structure.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_connect
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
if|if
condition|(
name|xenbus_get_state
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
operator|==
name|XenbusStateConnected
condition|)
return|return;
if|if
condition|(
name|xbb_collect_frontend_info
argument_list|(
name|xbb
argument_list|)
operator|!=
literal|0
condition|)
return|return;
name|xbb
operator|->
name|flags
operator|&=
operator|~
name|XBBF_SHUTDOWN
expr_stmt|;
comment|/* 	 * We limit the maximum number of reqlist segments to the maximum 	 * number of segments in the ring, or our absolute maximum, 	 * whichever is smaller. 	 */
name|xbb
operator|->
name|max_reqlist_segments
operator|=
name|MIN
argument_list|(
name|xbb
operator|->
name|max_request_segments
operator|*
name|xbb
operator|->
name|max_requests
argument_list|,
name|XBB_MAX_SEGMENTS_PER_REQLIST
argument_list|)
expr_stmt|;
comment|/* 	 * The maximum size is simply a function of the number of segments 	 * we can handle. 	 */
name|xbb
operator|->
name|max_reqlist_size
operator|=
name|xbb
operator|->
name|max_reqlist_segments
operator|*
name|PAGE_SIZE
expr_stmt|;
comment|/* Allocate resources whose size depends on front-end configuration. */
name|error
operator|=
name|xbb_alloc_communication_mem
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|error
argument_list|,
literal|"Unable to allocate communication memory"
argument_list|)
expr_stmt|;
return|return;
block|}
name|error
operator|=
name|xbb_alloc_requests
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
comment|/* Specific errors are reported by xbb_alloc_requests(). */
return|return;
block|}
name|error
operator|=
name|xbb_alloc_request_lists
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
comment|/* Specific errors are reported by xbb_alloc_request_lists(). */
return|return;
block|}
comment|/* 	 * Connect communication channel. 	 */
name|error
operator|=
name|xbb_connect_ring
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
comment|/* Specific errors are reported by xbb_connect_ring(). */
return|return;
block|}
if|if
condition|(
name|xbb_publish_backend_info
argument_list|(
name|xbb
argument_list|)
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * If we can't publish our data, we cannot participate 		 * in this connection, and waiting for a front-end state 		 * change will not help the situation. 		 */
operator|(
name|void
operator|)
name|xbb_disconnect
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* Ready for I/O. */
name|xenbus_set_state
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|XenbusStateConnected
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*-------------------------- Device Teardown Support -------------------------*/
end_comment

begin_comment
comment|/**  * Perform device shutdown functions.  *  * \param xbb  Per-instance xbb configuration structure.  *  * Mark this instance as shutting down, wait for any active I/O on the  * backend device/file to drain, disconnect from the front-end, and notify  * any waiters (e.g. a thread invoking our detach method) that detach can  * now proceed.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_shutdown
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
name|DPRINTF
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
comment|/* 	 * Due to the need to drop our mutex during some 	 * xenbus operations, it is possible for two threads 	 * to attempt to close out shutdown processing at 	 * the same time.  Tell the caller that hits this 	 * race to try back later.  	 */
if|if
condition|(
operator|(
name|xbb
operator|->
name|flags
operator|&
name|XBBF_IN_SHUTDOWN
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|EAGAIN
operator|)
return|;
name|DPRINTF
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
comment|/* Indicate shutdown is in progress. */
name|xbb
operator|->
name|flags
operator||=
name|XBBF_SHUTDOWN
expr_stmt|;
comment|/* Disconnect from the front-end. */
name|error
operator|=
name|xbb_disconnect
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
comment|/* 		 * Requests still outstanding.  We'll be called again 		 * once they complete. 		 */
name|KASSERT
argument_list|(
name|error
operator|==
name|EAGAIN
argument_list|,
operator|(
literal|"%s: Unexpected xbb_disconnect() failure %d"
operator|,
name|__func__
operator|,
name|error
operator|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|DPRINTF
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|flags
operator||=
name|XBBF_IN_SHUTDOWN
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|xenbus_get_state
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
operator|<
name|XenbusStateClosing
condition|)
name|xenbus_set_state
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|XenbusStateClosing
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|flags
operator|&=
operator|~
name|XBBF_IN_SHUTDOWN
expr_stmt|;
comment|/* Indicate to xbb_detach() that is it safe to proceed. */
name|wakeup
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Report an attach time error to the console and Xen, and cleanup  * this instance by forcing immediate detach processing.  *  * \param xbb  Per-instance xbb configuration structure.  * \param err  Errno describing the error.  * \param fmt  Printf style format and arguments  */
end_comment

begin_function
specifier|static
name|void
name|xbb_attach_failed
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|,
name|int
name|err
parameter_list|,
specifier|const
name|char
modifier|*
name|fmt
parameter_list|,
modifier|...
parameter_list|)
block|{
name|va_list
name|ap
decl_stmt|;
name|va_list
name|ap_hotplug
decl_stmt|;
name|va_start
argument_list|(
name|ap
argument_list|,
name|fmt
argument_list|)
expr_stmt|;
name|va_copy
argument_list|(
name|ap_hotplug
argument_list|,
name|ap
argument_list|)
expr_stmt|;
name|xs_vprintf
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"hotplug-error"
argument_list|,
name|fmt
argument_list|,
name|ap_hotplug
argument_list|)
expr_stmt|;
name|va_end
argument_list|(
name|ap_hotplug
argument_list|)
expr_stmt|;
name|xs_printf
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"hotplug-status"
argument_list|,
literal|"error"
argument_list|)
expr_stmt|;
name|xenbus_dev_vfatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|err
argument_list|,
name|fmt
argument_list|,
name|ap
argument_list|)
expr_stmt|;
name|va_end
argument_list|(
name|ap
argument_list|)
expr_stmt|;
name|xs_printf
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"online"
argument_list|,
literal|"0"
argument_list|)
expr_stmt|;
name|xbb_detach
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*---------------------------- NewBus Entrypoints ----------------------------*/
end_comment

begin_comment
comment|/**  * Inspect a XenBus device and claim it if is of the appropriate type.  *   * \param dev  NewBus device object representing a candidate XenBus device.  *  * \return  0 for success, errno codes for failure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_probe
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
if|if
condition|(
operator|!
name|strcmp
argument_list|(
name|xenbus_get_type
argument_list|(
name|dev
argument_list|)
argument_list|,
literal|"vbd"
argument_list|)
condition|)
block|{
name|device_set_desc
argument_list|(
name|dev
argument_list|,
literal|"Backend Virtual Block Device"
argument_list|)
expr_stmt|;
name|device_quiet
argument_list|(
name|dev
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
return|return
operator|(
name|ENXIO
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Setup sysctl variables to control various Block Back parameters.  *  * \param xbb  Xen Block Back softc.  *  */
end_comment

begin_function
specifier|static
name|void
name|xbb_setup_sysctl
parameter_list|(
name|struct
name|xbb_softc
modifier|*
name|xbb
parameter_list|)
block|{
name|struct
name|sysctl_ctx_list
modifier|*
name|sysctl_ctx
init|=
name|NULL
decl_stmt|;
name|struct
name|sysctl_oid
modifier|*
name|sysctl_tree
init|=
name|NULL
decl_stmt|;
name|sysctl_ctx
operator|=
name|device_get_sysctl_ctx
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
expr_stmt|;
if|if
condition|(
name|sysctl_ctx
operator|==
name|NULL
condition|)
return|return;
name|sysctl_tree
operator|=
name|device_get_sysctl_tree
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
expr_stmt|;
if|if
condition|(
name|sysctl_tree
operator|==
name|NULL
condition|)
return|return;
name|SYSCTL_ADD_INT
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"disable_flush"
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|xbb
operator|->
name|disable_flush
argument_list|,
literal|0
argument_list|,
literal|"fake the flush command"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_INT
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"flush_interval"
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|xbb
operator|->
name|flush_interval
argument_list|,
literal|0
argument_list|,
literal|"send a real flush for N flush requests"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_INT
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"no_coalesce_reqs"
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|xbb
operator|->
name|no_coalesce_reqs
argument_list|,
literal|0
argument_list|,
literal|"Don't coalesce contiguous requests"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_UQUAD
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"reqs_received"
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|xbb
operator|->
name|reqs_received
argument_list|,
literal|"how many I/O requests we have received"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_UQUAD
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"reqs_completed"
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|xbb
operator|->
name|reqs_completed
argument_list|,
literal|"how many I/O requests have been completed"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_UQUAD
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"forced_dispatch"
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|xbb
operator|->
name|forced_dispatch
argument_list|,
literal|"how many I/O dispatches were forced"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_UQUAD
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"normal_dispatch"
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|xbb
operator|->
name|normal_dispatch
argument_list|,
literal|"how many I/O dispatches were normal"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_UQUAD
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"total_dispatch"
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|xbb
operator|->
name|total_dispatch
argument_list|,
literal|"total number of I/O dispatches"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_UQUAD
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"kva_shortages"
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|xbb
operator|->
name|kva_shortages
argument_list|,
literal|"how many times we have run out of KVA"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_UQUAD
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"request_shortages"
argument_list|,
name|CTLFLAG_RW
argument_list|,
operator|&
name|xbb
operator|->
name|request_shortages
argument_list|,
literal|"how many times we have run out of requests"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_UINT
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"max_requests"
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|xbb
operator|->
name|max_requests
argument_list|,
literal|0
argument_list|,
literal|"maximum outstanding requests (negotiated)"
argument_list|)
expr_stmt|;
name|SYSCTL_ADD_UINT
argument_list|(
name|sysctl_ctx
argument_list|,
name|SYSCTL_CHILDREN
argument_list|(
name|sysctl_tree
argument_list|)
argument_list|,
name|OID_AUTO
argument_list|,
literal|"max_request_segments"
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|xbb
operator|->
name|max_request_segments
argument_list|,
literal|0
argument_list|,
literal|"maximum number of pages per requests (negotiated)"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**  * Attach to a XenBus device that has been claimed by our probe routine.  *  * \param dev  NewBus device object representing this Xen Block Back instance.  *  * \return  0 for success, errno codes for failure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_attach
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
name|struct
name|xbb_softc
modifier|*
name|xbb
decl_stmt|;
name|int
name|error
decl_stmt|;
name|DPRINTF
argument_list|(
literal|"Attaching to %s\n"
argument_list|,
name|xenbus_get_node
argument_list|(
name|dev
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Basic initialization. 	 * After this block it is safe to call xbb_detach() 	 * to clean up any allocated data for this instance. 	 */
name|xbb
operator|=
name|device_get_softc
argument_list|(
name|dev
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|dev
operator|=
name|dev
expr_stmt|;
name|xbb
operator|->
name|otherend_id
operator|=
name|xenbus_get_otherend_id
argument_list|(
name|dev
argument_list|)
expr_stmt|;
name|TASK_INIT
argument_list|(
operator|&
name|xbb
operator|->
name|io_task
argument_list|,
comment|/*priority*/
literal|0
argument_list|,
name|xbb_run_queue
argument_list|,
name|xbb
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|,
name|device_get_nameunit
argument_list|(
name|dev
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
comment|/* 	 * Publish protocol capabilities for consumption by the 	 * front-end. 	 */
name|error
operator|=
name|xs_printf
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"feature-barrier"
argument_list|,
literal|"1"
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|xbb_attach_failed
argument_list|(
name|xbb
argument_list|,
name|error
argument_list|,
literal|"writing %s/feature-barrier"
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|error
operator|=
name|xs_printf
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"feature-flush-cache"
argument_list|,
literal|"1"
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|xbb_attach_failed
argument_list|(
name|xbb
argument_list|,
name|error
argument_list|,
literal|"writing %s/feature-flush-cache"
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|error
operator|=
name|xs_printf
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"max-ring-pages"
argument_list|,
literal|"%zu"
argument_list|,
name|XBB_MAX_RING_PAGES
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|xbb_attach_failed
argument_list|(
name|xbb
argument_list|,
name|error
argument_list|,
literal|"writing %s/max-ring-pages"
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|error
operator|=
name|xs_printf
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"max-requests"
argument_list|,
literal|"%u"
argument_list|,
name|XBB_MAX_REQUESTS
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|xbb_attach_failed
argument_list|(
name|xbb
argument_list|,
name|error
argument_list|,
literal|"writing %s/max-requests"
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|error
operator|=
name|xs_printf
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"max-request-segments"
argument_list|,
literal|"%u"
argument_list|,
name|XBB_MAX_SEGMENTS_PER_REQUEST
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|xbb_attach_failed
argument_list|(
name|xbb
argument_list|,
name|error
argument_list|,
literal|"writing %s/max-request-segments"
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
name|error
operator|=
name|xs_printf
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"max-request-size"
argument_list|,
literal|"%u"
argument_list|,
name|XBB_MAX_REQUEST_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|xbb_attach_failed
argument_list|(
name|xbb
argument_list|,
name|error
argument_list|,
literal|"writing %s/max-request-size"
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
comment|/* Collect physical device information. */
name|error
operator|=
name|xs_gather
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_otherend_path
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"device-type"
argument_list|,
name|NULL
argument_list|,
operator|&
name|xbb
operator|->
name|dev_type
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
name|xbb
operator|->
name|dev_type
operator|=
name|NULL
expr_stmt|;
name|error
operator|=
name|xs_gather
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|dev
argument_list|)
argument_list|,
literal|"mode"
argument_list|,
name|NULL
argument_list|,
operator|&
name|xbb
operator|->
name|dev_mode
argument_list|,
literal|"params"
argument_list|,
name|NULL
argument_list|,
operator|&
name|xbb
operator|->
name|dev_name
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|xbb_attach_failed
argument_list|(
name|xbb
argument_list|,
name|error
argument_list|,
literal|"reading backend fields at %s"
argument_list|,
name|xenbus_get_node
argument_list|(
name|dev
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENXIO
operator|)
return|;
block|}
comment|/* Parse fopen style mode flags. */
if|if
condition|(
name|strchr
argument_list|(
name|xbb
operator|->
name|dev_mode
argument_list|,
literal|'w'
argument_list|)
operator|==
name|NULL
condition|)
name|xbb
operator|->
name|flags
operator||=
name|XBBF_READ_ONLY
expr_stmt|;
comment|/* 	 * Verify the physical device is present and can support 	 * the desired I/O mode. 	 */
name|DROP_GIANT
argument_list|()
expr_stmt|;
name|error
operator|=
name|xbb_open_backend
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
name|PICKUP_GIANT
argument_list|()
expr_stmt|;
if|if
condition|(
name|error
operator|!=
literal|0
condition|)
block|{
name|xbb_attach_failed
argument_list|(
name|xbb
argument_list|,
name|error
argument_list|,
literal|"Unable to open %s"
argument_list|,
name|xbb
operator|->
name|dev_name
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENXIO
operator|)
return|;
block|}
comment|/* Use devstat(9) for recording statistics. */
name|xbb
operator|->
name|xbb_stats
operator|=
name|devstat_new_entry
argument_list|(
literal|"xbb"
argument_list|,
name|device_get_unit
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
name|xbb
operator|->
name|sector_size
argument_list|,
name|DEVSTAT_ALL_SUPPORTED
argument_list|,
name|DEVSTAT_TYPE_DIRECT
operator||
name|DEVSTAT_TYPE_IF_OTHER
argument_list|,
name|DEVSTAT_PRIORITY_OTHER
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|xbb_stats_in
operator|=
name|devstat_new_entry
argument_list|(
literal|"xbbi"
argument_list|,
name|device_get_unit
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
name|xbb
operator|->
name|sector_size
argument_list|,
name|DEVSTAT_ALL_SUPPORTED
argument_list|,
name|DEVSTAT_TYPE_DIRECT
operator||
name|DEVSTAT_TYPE_IF_OTHER
argument_list|,
name|DEVSTAT_PRIORITY_OTHER
argument_list|)
expr_stmt|;
comment|/* 	 * Setup sysctl variables. 	 */
name|xbb_setup_sysctl
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
comment|/* 	 * Create a taskqueue for doing work that must occur from a 	 * thread context. 	 */
name|xbb
operator|->
name|io_taskqueue
operator|=
name|taskqueue_create
argument_list|(
name|device_get_nameunit
argument_list|(
name|dev
argument_list|)
argument_list|,
name|M_NOWAIT
argument_list|,
name|taskqueue_thread_enqueue
argument_list|,
comment|/*context*/
operator|&
name|xbb
operator|->
name|io_taskqueue
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|io_taskqueue
operator|==
name|NULL
condition|)
block|{
name|xbb_attach_failed
argument_list|(
name|xbb
argument_list|,
name|error
argument_list|,
literal|"Unable to create taskqueue"
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
name|taskqueue_start_threads
argument_list|(
operator|&
name|xbb
operator|->
name|io_taskqueue
argument_list|,
comment|/*num threads*/
literal|1
argument_list|,
comment|/*priority*/
name|PWAIT
argument_list|,
comment|/*thread name*/
literal|"%s taskq"
argument_list|,
name|device_get_nameunit
argument_list|(
name|dev
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Update hot-plug status to satisfy xend. */
name|error
operator|=
name|xs_printf
argument_list|(
name|XST_NIL
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|,
literal|"hotplug-status"
argument_list|,
literal|"connected"
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|xbb_attach_failed
argument_list|(
name|xbb
argument_list|,
name|error
argument_list|,
literal|"writing %s/hotplug-status"
argument_list|,
name|xenbus_get_node
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
comment|/* Tell the front end that we are ready to connect. */
name|xenbus_set_state
argument_list|(
name|dev
argument_list|,
name|XenbusStateInitWait
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Detach from a block back device instance.  *  * \param dev  NewBus device object representing this Xen Block Back instance.  *  * \return  0 for success, errno codes for failure.  *   * \note A block back device may be detached at any time in its life-cycle,  *       including part way through the attach process.  For this reason,  *       initialization order and the intialization state checks in this  *       routine must be carefully coupled so that attach time failures  *       are gracefully handled.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_detach
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
name|struct
name|xbb_softc
modifier|*
name|xbb
decl_stmt|;
name|DPRINTF
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
name|xbb
operator|=
name|device_get_softc
argument_list|(
name|dev
argument_list|)
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
while|while
condition|(
name|xbb_shutdown
argument_list|(
name|xbb
argument_list|)
operator|==
name|EAGAIN
condition|)
block|{
name|msleep
argument_list|(
name|xbb
argument_list|,
operator|&
name|xbb
operator|->
name|lock
argument_list|,
comment|/*wakeup prio unchanged*/
literal|0
argument_list|,
literal|"xbb_shutdown"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
name|DPRINTF
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|io_taskqueue
operator|!=
name|NULL
condition|)
name|taskqueue_free
argument_list|(
name|xbb
operator|->
name|io_taskqueue
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|xbb_stats
operator|!=
name|NULL
condition|)
name|devstat_remove_entry
argument_list|(
name|xbb
operator|->
name|xbb_stats
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|xbb_stats_in
operator|!=
name|NULL
condition|)
name|devstat_remove_entry
argument_list|(
name|xbb
operator|->
name|xbb_stats_in
argument_list|)
expr_stmt|;
name|xbb_close_backend
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
if|if
condition|(
name|xbb
operator|->
name|dev_mode
operator|!=
name|NULL
condition|)
block|{
name|free
argument_list|(
name|xbb
operator|->
name|dev_mode
argument_list|,
name|M_XENBUS
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|dev_mode
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|xbb
operator|->
name|dev_type
operator|!=
name|NULL
condition|)
block|{
name|free
argument_list|(
name|xbb
operator|->
name|dev_type
argument_list|,
name|M_XENBUS
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|dev_type
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|xbb
operator|->
name|dev_name
operator|!=
name|NULL
condition|)
block|{
name|free
argument_list|(
name|xbb
operator|->
name|dev_name
argument_list|,
name|M_XENBUS
argument_list|)
expr_stmt|;
name|xbb
operator|->
name|dev_name
operator|=
name|NULL
expr_stmt|;
block|}
name|mtx_destroy
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Prepare this block back device for suspension of this VM.  *   * \param dev  NewBus device object representing this Xen Block Back instance.  *  * \return  0 for success, errno codes for failure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_suspend
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
ifdef|#
directive|ifdef
name|NOT_YET
name|struct
name|xbb_softc
modifier|*
name|sc
init|=
name|device_get_softc
argument_list|(
name|dev
argument_list|)
decl_stmt|;
comment|/* Prevent new requests being issued until we fix things up. */
name|mtx_lock
argument_list|(
operator|&
name|sc
operator|->
name|xb_io_lock
argument_list|)
expr_stmt|;
name|sc
operator|->
name|connected
operator|=
name|BLKIF_STATE_SUSPENDED
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|sc
operator|->
name|xb_io_lock
argument_list|)
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Perform any processing required to recover from a suspended state.  *   * \param dev  NewBus device object representing this Xen Block Back instance.  *  * \return  0 for success, errno codes for failure.  */
end_comment

begin_function
specifier|static
name|int
name|xbb_resume
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/**  * Handle state changes expressed via the XenStore by our front-end peer.  *  * \param dev             NewBus device object representing this Xen  *                        Block Back instance.  * \param frontend_state  The new state of the front-end.  *  * \return  0 for success, errno codes for failure.  */
end_comment

begin_function
specifier|static
name|void
name|xbb_frontend_changed
parameter_list|(
name|device_t
name|dev
parameter_list|,
name|XenbusState
name|frontend_state
parameter_list|)
block|{
name|struct
name|xbb_softc
modifier|*
name|xbb
init|=
name|device_get_softc
argument_list|(
name|dev
argument_list|)
decl_stmt|;
name|DPRINTF
argument_list|(
literal|"frontend_state=%s, xbb_state=%s\n"
argument_list|,
name|xenbus_strstate
argument_list|(
name|frontend_state
argument_list|)
argument_list|,
name|xenbus_strstate
argument_list|(
name|xenbus_get_state
argument_list|(
name|xbb
operator|->
name|dev
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
switch|switch
condition|(
name|frontend_state
condition|)
block|{
case|case
name|XenbusStateInitialising
case|:
break|break;
case|case
name|XenbusStateInitialised
case|:
case|case
name|XenbusStateConnected
case|:
name|xbb_connect
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
break|break;
case|case
name|XenbusStateClosing
case|:
case|case
name|XenbusStateClosed
case|:
name|mtx_lock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
name|xbb_shutdown
argument_list|(
name|xbb
argument_list|)
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|xbb
operator|->
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|frontend_state
operator|==
name|XenbusStateClosed
condition|)
name|xenbus_set_state
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|XenbusStateClosed
argument_list|)
expr_stmt|;
break|break;
default|default:
name|xenbus_dev_fatal
argument_list|(
name|xbb
operator|->
name|dev
argument_list|,
name|EINVAL
argument_list|,
literal|"saw state %d at frontend"
argument_list|,
name|frontend_state
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
end_function

begin_comment
comment|/*---------------------------- NewBus Registration ---------------------------*/
end_comment

begin_decl_stmt
specifier|static
name|device_method_t
name|xbb_methods
index|[]
init|=
block|{
comment|/* Device interface */
name|DEVMETHOD
argument_list|(
name|device_probe
argument_list|,
name|xbb_probe
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|device_attach
argument_list|,
name|xbb_attach
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|device_detach
argument_list|,
name|xbb_detach
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|device_shutdown
argument_list|,
name|bus_generic_shutdown
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|device_suspend
argument_list|,
name|xbb_suspend
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|device_resume
argument_list|,
name|xbb_resume
argument_list|)
block|,
comment|/* Xenbus interface */
name|DEVMETHOD
argument_list|(
name|xenbus_otherend_changed
argument_list|,
name|xbb_frontend_changed
argument_list|)
block|,
block|{
literal|0
block|,
literal|0
block|}
block|}
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|driver_t
name|xbb_driver
init|=
block|{
literal|"xbbd"
block|,
name|xbb_methods
block|,
sizeof|sizeof
argument_list|(
expr|struct
name|xbb_softc
argument_list|)
block|, }
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|devclass_t
name|xbb_devclass
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|DRIVER_MODULE
argument_list|(
name|xbbd
argument_list|,
name|xenbusb_back
argument_list|,
name|xbb_driver
argument_list|,
name|xbb_devclass
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
end_expr_stmt

end_unit

