begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 2011, Bryan Venteicher<bryanv@FreeBSD.org>  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice unmodified, this list of conditions, and the following  *    disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR  * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES  * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,  * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT  * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,  * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY  * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF  * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.  */
end_comment

begin_comment
comment|/* Driver for VirtIO network devices. */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/sockio.h>
end_include

begin_include
include|#
directive|include
file|<sys/mbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/module.h>
end_include

begin_include
include|#
directive|include
file|<sys/socket.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/random.h>
end_include

begin_include
include|#
directive|include
file|<sys/sglist.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/taskqueue.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_include
include|#
directive|include
file|<net/ethernet.h>
end_include

begin_include
include|#
directive|include
file|<net/if.h>
end_include

begin_include
include|#
directive|include
file|<net/if_arp.h>
end_include

begin_include
include|#
directive|include
file|<net/if_dl.h>
end_include

begin_include
include|#
directive|include
file|<net/if_types.h>
end_include

begin_include
include|#
directive|include
file|<net/if_media.h>
end_include

begin_include
include|#
directive|include
file|<net/if_vlan_var.h>
end_include

begin_include
include|#
directive|include
file|<net/bpf.h>
end_include

begin_include
include|#
directive|include
file|<netinet/in_systm.h>
end_include

begin_include
include|#
directive|include
file|<netinet/in.h>
end_include

begin_include
include|#
directive|include
file|<netinet/ip.h>
end_include

begin_include
include|#
directive|include
file|<netinet/ip6.h>
end_include

begin_include
include|#
directive|include
file|<netinet6/ip6_var.h>
end_include

begin_include
include|#
directive|include
file|<netinet/udp.h>
end_include

begin_include
include|#
directive|include
file|<netinet/tcp.h>
end_include

begin_include
include|#
directive|include
file|<netinet/sctp.h>
end_include

begin_include
include|#
directive|include
file|<machine/bus.h>
end_include

begin_include
include|#
directive|include
file|<machine/resource.h>
end_include

begin_include
include|#
directive|include
file|<sys/bus.h>
end_include

begin_include
include|#
directive|include
file|<sys/rman.h>
end_include

begin_include
include|#
directive|include
file|<dev/virtio/virtio.h>
end_include

begin_include
include|#
directive|include
file|<dev/virtio/virtqueue.h>
end_include

begin_include
include|#
directive|include
file|<dev/virtio/network/virtio_net.h>
end_include

begin_include
include|#
directive|include
file|<dev/virtio/network/if_vtnetvar.h>
end_include

begin_include
include|#
directive|include
file|"virtio_if.h"
end_include

begin_include
include|#
directive|include
file|"opt_inet.h"
end_include

begin_include
include|#
directive|include
file|"opt_inet6.h"
end_include

begin_function_decl
specifier|static
name|int
name|vtnet_modevent
parameter_list|(
name|module_t
parameter_list|,
name|int
parameter_list|,
name|void
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_probe
parameter_list|(
name|device_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_attach
parameter_list|(
name|device_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_detach
parameter_list|(
name|device_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_suspend
parameter_list|(
name|device_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_resume
parameter_list|(
name|device_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_shutdown
parameter_list|(
name|device_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_attach_completed
parameter_list|(
name|device_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_config_change
parameter_list|(
name|device_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_negotiate_features
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_setup_features
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_init_rxq
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_init_txq
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_alloc_rxtx_queues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_free_rxtx_queues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_alloc_rx_filters
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_free_rx_filters
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_alloc_virtqueues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_setup_interface
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_change_mtu
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_ioctl
parameter_list|(
name|struct
name|ifnet
modifier|*
parameter_list|,
name|u_long
parameter_list|,
name|caddr_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_rxq_populate
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rxq_free_mbufs
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|mbuf
modifier|*
name|vtnet_rx_alloc_buf
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|int
parameter_list|,
name|struct
name|mbuf
modifier|*
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_rxq_replace_lro_nomgr_buf
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_rxq_replace_buf
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_rxq_enqueue_buf
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_rxq_new_buf
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_rxq_csum
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|,
name|struct
name|virtio_net_hdr
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rxq_discard_merged_bufs
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rxq_discard_buf
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_rxq_merged_eof
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rxq_input
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|,
name|struct
name|virtio_net_hdr
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_rxq_eof
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rx_vq_intr
parameter_list|(
name|void
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rxq_tq_intr
parameter_list|(
name|void
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_txq_free_mbufs
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_txq_offload_ctx
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|,
name|int
modifier|*
parameter_list|,
name|int
modifier|*
parameter_list|,
name|int
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_txq_offload_tso
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|,
name|struct
name|virtio_net_hdr
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|struct
name|mbuf
modifier|*
name|vtnet_txq_offload
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|,
name|struct
name|virtio_net_hdr
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_txq_enqueue_buf
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
modifier|*
parameter_list|,
name|struct
name|vtnet_tx_header
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_txq_encap
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_ifdef
ifdef|#
directive|ifdef
name|VTNET_LEGACY_TX
end_ifdef

begin_function_decl
specifier|static
name|void
name|vtnet_start_locked
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|,
name|struct
name|ifnet
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_start
parameter_list|(
name|struct
name|ifnet
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_else
else|#
directive|else
end_else

begin_function_decl
specifier|static
name|int
name|vtnet_txq_mq_start_locked
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_txq_mq_start
parameter_list|(
name|struct
name|ifnet
modifier|*
parameter_list|,
name|struct
name|mbuf
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_txq_tq_deferred
parameter_list|(
name|void
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_function_decl
specifier|static
name|void
name|vtnet_txq_tq_intr
parameter_list|(
name|void
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_txq_eof
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_tx_vq_intr
parameter_list|(
name|void
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_tx_start_all
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_ifndef
ifndef|#
directive|ifndef
name|VTNET_LEGACY_TX
end_ifndef

begin_function_decl
specifier|static
name|void
name|vtnet_qflush
parameter_list|(
name|struct
name|ifnet
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_function_decl
specifier|static
name|int
name|vtnet_watchdog
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rxq_accum_stats
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|,
name|struct
name|vtnet_rxq_stats
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_txq_accum_stats
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|,
name|struct
name|vtnet_txq_stats
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_accumulate_stats
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_tick
parameter_list|(
name|void
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_start_taskqueues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_free_taskqueues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_drain_taskqueues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_drain_rxtx_queues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_stop_rendezvous
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_stop
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_virtio_reinit
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_init_rx_filters
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_init_rx_queues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_init_tx_queues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_init_rxtx_queues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_set_active_vq_pairs
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_reinit
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_init_locked
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_init
parameter_list|(
name|void
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_free_ctrl_vq
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_exec_ctrl_cmd
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|void
modifier|*
parameter_list|,
name|struct
name|sglist
modifier|*
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_ctrl_mac_cmd
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|uint8_t
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_ctrl_mq_cmd
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|uint16_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_ctrl_rx_cmd
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_set_promisc
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_set_allmulti
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_attach_disable_promisc
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rx_filter
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rx_filter_mac
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_exec_vlan_filter
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|int
parameter_list|,
name|uint16_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rx_filter_vlan
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_update_vlan_filter
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
name|int
parameter_list|,
name|uint16_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_register_vlan
parameter_list|(
name|void
modifier|*
parameter_list|,
name|struct
name|ifnet
modifier|*
parameter_list|,
name|uint16_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_unregister_vlan
parameter_list|(
name|void
modifier|*
parameter_list|,
name|struct
name|ifnet
modifier|*
parameter_list|,
name|uint16_t
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_is_link_up
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_update_link_status
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_ifmedia_upd
parameter_list|(
name|struct
name|ifnet
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_ifmedia_sts
parameter_list|(
name|struct
name|ifnet
modifier|*
parameter_list|,
name|struct
name|ifmediareq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_get_hwaddr
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_set_hwaddr
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_vlan_tag_remove
parameter_list|(
name|struct
name|mbuf
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_setup_rxq_sysctl
parameter_list|(
name|struct
name|sysctl_ctx_list
modifier|*
parameter_list|,
name|struct
name|sysctl_oid_list
modifier|*
parameter_list|,
name|struct
name|vtnet_rxq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_setup_txq_sysctl
parameter_list|(
name|struct
name|sysctl_ctx_list
modifier|*
parameter_list|,
name|struct
name|sysctl_oid_list
modifier|*
parameter_list|,
name|struct
name|vtnet_txq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_setup_queue_sysctl
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_setup_sysctl
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_rxq_enable_intr
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_rxq_disable_intr
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_txq_enable_intr
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_txq_disable_intr
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_enable_rx_interrupts
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_enable_tx_interrupts
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_enable_interrupts
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_disable_rx_interrupts
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_disable_tx_interrupts
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|vtnet_disable_interrupts
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|vtnet_tunable_int
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
parameter_list|,
specifier|const
name|char
modifier|*
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/* Tunables. */
end_comment

begin_decl_stmt
specifier|static
name|int
name|vtnet_csum_disable
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"hw.vtnet.csum_disable"
argument_list|,
operator|&
name|vtnet_csum_disable
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|vtnet_tso_disable
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"hw.vtnet.tso_disable"
argument_list|,
operator|&
name|vtnet_tso_disable
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|vtnet_lro_disable
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"hw.vtnet.lro_disable"
argument_list|,
operator|&
name|vtnet_lro_disable
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|vtnet_mq_disable
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"hw.vtnet.mq_disable"
argument_list|,
operator|&
name|vtnet_mq_disable
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|vtnet_mq_max_pairs
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"hw.vtnet.mq_max_pairs"
argument_list|,
operator|&
name|vtnet_mq_max_pairs
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|vtnet_rx_process_limit
init|=
literal|512
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|TUNABLE_INT
argument_list|(
literal|"hw.vtnet.rx_process_limit"
argument_list|,
operator|&
name|vtnet_rx_process_limit
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Reducing the number of transmit completed interrupts can improve  * performance. To do so, the define below keeps the Tx vq interrupt  * disabled and adds calls to vtnet_txeof() in the start and watchdog  * paths. The price to pay for this is the m_free'ing of transmitted  * mbufs may be delayed until the watchdog fires.  *  * BMV: Reintroduce this later as a run-time option, if it makes  * sense after the EVENT_IDX feature is supported.  *  * #define VTNET_TX_INTR_MODERATION  */
end_comment

begin_decl_stmt
specifier|static
name|uma_zone_t
name|vtnet_tx_header_zone
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|virtio_feature_desc
name|vtnet_feature_desc
index|[]
init|=
block|{
block|{
name|VIRTIO_NET_F_CSUM
block|,
literal|"TxChecksum"
block|}
block|,
block|{
name|VIRTIO_NET_F_GUEST_CSUM
block|,
literal|"RxChecksum"
block|}
block|,
block|{
name|VIRTIO_NET_F_MAC
block|,
literal|"MacAddress"
block|}
block|,
block|{
name|VIRTIO_NET_F_GSO
block|,
literal|"TxAllGSO"
block|}
block|,
block|{
name|VIRTIO_NET_F_GUEST_TSO4
block|,
literal|"RxTSOv4"
block|}
block|,
block|{
name|VIRTIO_NET_F_GUEST_TSO6
block|,
literal|"RxTSOv6"
block|}
block|,
block|{
name|VIRTIO_NET_F_GUEST_ECN
block|,
literal|"RxECN"
block|}
block|,
block|{
name|VIRTIO_NET_F_GUEST_UFO
block|,
literal|"RxUFO"
block|}
block|,
block|{
name|VIRTIO_NET_F_HOST_TSO4
block|,
literal|"TxTSOv4"
block|}
block|,
block|{
name|VIRTIO_NET_F_HOST_TSO6
block|,
literal|"TxTSOv6"
block|}
block|,
block|{
name|VIRTIO_NET_F_HOST_ECN
block|,
literal|"TxTSOECN"
block|}
block|,
block|{
name|VIRTIO_NET_F_HOST_UFO
block|,
literal|"TxUFO"
block|}
block|,
block|{
name|VIRTIO_NET_F_MRG_RXBUF
block|,
literal|"MrgRxBuf"
block|}
block|,
block|{
name|VIRTIO_NET_F_STATUS
block|,
literal|"Status"
block|}
block|,
block|{
name|VIRTIO_NET_F_CTRL_VQ
block|,
literal|"ControlVq"
block|}
block|,
block|{
name|VIRTIO_NET_F_CTRL_RX
block|,
literal|"RxMode"
block|}
block|,
block|{
name|VIRTIO_NET_F_CTRL_VLAN
block|,
literal|"VLanFilter"
block|}
block|,
block|{
name|VIRTIO_NET_F_CTRL_RX_EXTRA
block|,
literal|"RxModeExtra"
block|}
block|,
block|{
name|VIRTIO_NET_F_GUEST_ANNOUNCE
block|,
literal|"GuestAnnounce"
block|}
block|,
block|{
name|VIRTIO_NET_F_MQ
block|,
literal|"Multiqueue"
block|}
block|,
block|{
name|VIRTIO_NET_F_CTRL_MAC_ADDR
block|,
literal|"SetMacAddress"
block|}
block|,
block|{
literal|0
block|,
name|NULL
block|}
block|}
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|device_method_t
name|vtnet_methods
index|[]
init|=
block|{
comment|/* Device methods. */
name|DEVMETHOD
argument_list|(
name|device_probe
argument_list|,
name|vtnet_probe
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|device_attach
argument_list|,
name|vtnet_attach
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|device_detach
argument_list|,
name|vtnet_detach
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|device_suspend
argument_list|,
name|vtnet_suspend
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|device_resume
argument_list|,
name|vtnet_resume
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|device_shutdown
argument_list|,
name|vtnet_shutdown
argument_list|)
block|,
comment|/* VirtIO methods. */
name|DEVMETHOD
argument_list|(
name|virtio_attach_completed
argument_list|,
name|vtnet_attach_completed
argument_list|)
block|,
name|DEVMETHOD
argument_list|(
name|virtio_config_change
argument_list|,
name|vtnet_config_change
argument_list|)
block|,
name|DEVMETHOD_END
block|}
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|driver_t
name|vtnet_driver
init|=
block|{
literal|"vtnet"
block|,
name|vtnet_methods
block|,
expr|sizeof
operator|(
expr|struct
name|vtnet_softc
operator|)
block|}
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|devclass_t
name|vtnet_devclass
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|DRIVER_MODULE
argument_list|(
name|vtnet
argument_list|,
name|virtio_pci
argument_list|,
name|vtnet_driver
argument_list|,
name|vtnet_devclass
argument_list|,
name|vtnet_modevent
argument_list|,
literal|0
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|MODULE_VERSION
argument_list|(
name|vtnet
argument_list|,
literal|1
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|MODULE_DEPEND
argument_list|(
name|vtnet
argument_list|,
name|virtio
argument_list|,
literal|1
argument_list|,
literal|1
argument_list|,
literal|1
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|vtnet_modevent
parameter_list|(
name|module_t
name|mod
parameter_list|,
name|int
name|type
parameter_list|,
name|void
modifier|*
name|unused
parameter_list|)
block|{
name|int
name|error
decl_stmt|;
name|error
operator|=
literal|0
expr_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|MOD_LOAD
case|:
name|vtnet_tx_header_zone
operator|=
name|uma_zcreate
argument_list|(
literal|"vtnet_tx_hdr"
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|vtnet_tx_header
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
break|break;
case|case
name|MOD_QUIESCE
case|:
case|case
name|MOD_UNLOAD
case|:
if|if
condition|(
name|uma_zone_get_cur
argument_list|(
name|vtnet_tx_header_zone
argument_list|)
operator|>
literal|0
condition|)
name|error
operator|=
name|EBUSY
expr_stmt|;
elseif|else
if|if
condition|(
name|type
operator|==
name|MOD_UNLOAD
condition|)
block|{
name|uma_zdestroy
argument_list|(
name|vtnet_tx_header_zone
argument_list|)
expr_stmt|;
name|vtnet_tx_header_zone
operator|=
name|NULL
expr_stmt|;
block|}
break|break;
case|case
name|MOD_SHUTDOWN
case|:
break|break;
default|default:
name|error
operator|=
name|EOPNOTSUPP
expr_stmt|;
break|break;
block|}
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_probe
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
if|if
condition|(
name|virtio_get_device_type
argument_list|(
name|dev
argument_list|)
operator|!=
name|VIRTIO_ID_NETWORK
condition|)
return|return
operator|(
name|ENXIO
operator|)
return|;
name|device_set_desc
argument_list|(
name|dev
argument_list|,
literal|"VirtIO Networking Adapter"
argument_list|)
expr_stmt|;
return|return
operator|(
name|BUS_PROBE_DEFAULT
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_attach
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|int
name|error
decl_stmt|;
name|sc
operator|=
name|device_get_softc
argument_list|(
name|dev
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_dev
operator|=
name|dev
expr_stmt|;
comment|/* Register our feature descriptions. */
name|virtio_set_feature_desc
argument_list|(
name|dev
argument_list|,
name|vtnet_feature_desc
argument_list|)
expr_stmt|;
name|VTNET_CORE_LOCK_INIT
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|callout_init_mtx
argument_list|(
operator|&
name|sc
operator|->
name|vtnet_tick_ch
argument_list|,
name|VTNET_CORE_MTX
argument_list|(
name|sc
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|vtnet_setup_sysctl
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|vtnet_setup_features
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|error
operator|=
name|vtnet_alloc_rx_filters
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|device_printf
argument_list|(
name|dev
argument_list|,
literal|"cannot allocate Rx filters\n"
argument_list|)
expr_stmt|;
goto|goto
name|fail
goto|;
block|}
name|error
operator|=
name|vtnet_alloc_rxtx_queues
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|device_printf
argument_list|(
name|dev
argument_list|,
literal|"cannot allocate queues\n"
argument_list|)
expr_stmt|;
goto|goto
name|fail
goto|;
block|}
name|error
operator|=
name|vtnet_alloc_virtqueues
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|device_printf
argument_list|(
name|dev
argument_list|,
literal|"cannot allocate virtqueues\n"
argument_list|)
expr_stmt|;
goto|goto
name|fail
goto|;
block|}
name|error
operator|=
name|vtnet_setup_interface
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|device_printf
argument_list|(
name|dev
argument_list|,
literal|"cannot setup interface\n"
argument_list|)
expr_stmt|;
goto|goto
name|fail
goto|;
block|}
name|error
operator|=
name|virtio_setup_intr
argument_list|(
name|dev
argument_list|,
name|INTR_TYPE_NET
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
name|device_printf
argument_list|(
name|dev
argument_list|,
literal|"cannot setup virtqueue interrupts\n"
argument_list|)
expr_stmt|;
comment|/* BMV: This will crash if during boot! */
name|ether_ifdetach
argument_list|(
name|sc
operator|->
name|vtnet_ifp
argument_list|)
expr_stmt|;
goto|goto
name|fail
goto|;
block|}
name|vtnet_start_taskqueues
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|fail
label|:
if|if
condition|(
name|error
condition|)
name|vtnet_detach
argument_list|(
name|dev
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_detach
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|struct
name|ifnet
modifier|*
name|ifp
decl_stmt|;
name|sc
operator|=
name|device_get_softc
argument_list|(
name|dev
argument_list|)
expr_stmt|;
name|ifp
operator|=
name|sc
operator|->
name|vtnet_ifp
expr_stmt|;
if|if
condition|(
name|device_is_attached
argument_list|(
name|dev
argument_list|)
condition|)
block|{
name|VTNET_CORE_LOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|vtnet_stop
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|VTNET_CORE_UNLOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|callout_drain
argument_list|(
operator|&
name|sc
operator|->
name|vtnet_tick_ch
argument_list|)
expr_stmt|;
name|vtnet_drain_taskqueues
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|ether_ifdetach
argument_list|(
name|ifp
argument_list|)
expr_stmt|;
block|}
name|vtnet_free_taskqueues
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|sc
operator|->
name|vtnet_vlan_attach
operator|!=
name|NULL
condition|)
block|{
name|EVENTHANDLER_DEREGISTER
argument_list|(
name|vlan_config
argument_list|,
name|sc
operator|->
name|vtnet_vlan_attach
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_vlan_attach
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|sc
operator|->
name|vtnet_vlan_detach
operator|!=
name|NULL
condition|)
block|{
name|EVENTHANDLER_DEREGISTER
argument_list|(
name|vlan_unconfg
argument_list|,
name|sc
operator|->
name|vtnet_vlan_detach
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_vlan_detach
operator|=
name|NULL
expr_stmt|;
block|}
name|ifmedia_removeall
argument_list|(
operator|&
name|sc
operator|->
name|vtnet_media
argument_list|)
expr_stmt|;
if|if
condition|(
name|ifp
operator|!=
name|NULL
condition|)
block|{
name|if_free
argument_list|(
name|ifp
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_ifp
operator|=
name|NULL
expr_stmt|;
block|}
name|vtnet_free_rxtx_queues
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|vtnet_free_rx_filters
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|sc
operator|->
name|vtnet_ctrl_vq
operator|!=
name|NULL
condition|)
name|vtnet_free_ctrl_vq
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|VTNET_CORE_LOCK_DESTROY
argument_list|(
name|sc
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_suspend
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|sc
operator|=
name|device_get_softc
argument_list|(
name|dev
argument_list|)
expr_stmt|;
name|VTNET_CORE_LOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|vtnet_stop
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_SUSPENDED
expr_stmt|;
name|VTNET_CORE_UNLOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_resume
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|struct
name|ifnet
modifier|*
name|ifp
decl_stmt|;
name|sc
operator|=
name|device_get_softc
argument_list|(
name|dev
argument_list|)
expr_stmt|;
name|ifp
operator|=
name|sc
operator|->
name|vtnet_ifp
expr_stmt|;
name|VTNET_CORE_LOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|ifp
operator|->
name|if_flags
operator|&
name|IFF_UP
condition|)
name|vtnet_init_locked
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_flags
operator|&=
operator|~
name|VTNET_FLAG_SUSPENDED
expr_stmt|;
name|VTNET_CORE_UNLOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_shutdown
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
comment|/* 	 * Suspend already does all of what we need to 	 * do here; we just never expect to be resumed. 	 */
return|return
operator|(
name|vtnet_suspend
argument_list|(
name|dev
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_attach_completed
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
name|vtnet_attach_disable_promisc
argument_list|(
name|device_get_softc
argument_list|(
name|dev
argument_list|)
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_config_change
parameter_list|(
name|device_t
name|dev
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|sc
operator|=
name|device_get_softc
argument_list|(
name|dev
argument_list|)
expr_stmt|;
name|VTNET_CORE_LOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|vtnet_update_link_status
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|sc
operator|->
name|vtnet_link_active
operator|!=
literal|0
condition|)
name|vtnet_tx_start_all
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|VTNET_CORE_UNLOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vtnet_negotiate_features
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|)
block|{
name|device_t
name|dev
decl_stmt|;
name|uint64_t
name|mask
decl_stmt|,
name|features
decl_stmt|;
name|dev
operator|=
name|sc
operator|->
name|vtnet_dev
expr_stmt|;
name|mask
operator|=
literal|0
expr_stmt|;
comment|/* 	 * TSO and LRO are only available when their corresponding checksum 	 * offload feature is also negotiated. 	 */
if|if
condition|(
name|vtnet_tunable_int
argument_list|(
name|sc
argument_list|,
literal|"csum_disable"
argument_list|,
name|vtnet_csum_disable
argument_list|)
condition|)
block|{
name|mask
operator||=
name|VIRTIO_NET_F_CSUM
operator||
name|VIRTIO_NET_F_GUEST_CSUM
expr_stmt|;
name|mask
operator||=
name|VTNET_TSO_FEATURES
operator||
name|VTNET_LRO_FEATURES
expr_stmt|;
block|}
if|if
condition|(
name|vtnet_tunable_int
argument_list|(
name|sc
argument_list|,
literal|"tso_disable"
argument_list|,
name|vtnet_tso_disable
argument_list|)
condition|)
name|mask
operator||=
name|VTNET_TSO_FEATURES
expr_stmt|;
if|if
condition|(
name|vtnet_tunable_int
argument_list|(
name|sc
argument_list|,
literal|"lro_disable"
argument_list|,
name|vtnet_lro_disable
argument_list|)
condition|)
name|mask
operator||=
name|VTNET_LRO_FEATURES
expr_stmt|;
if|if
condition|(
name|vtnet_tunable_int
argument_list|(
name|sc
argument_list|,
literal|"mq_disable"
argument_list|,
name|vtnet_mq_disable
argument_list|)
condition|)
name|mask
operator||=
name|VIRTIO_NET_F_MQ
expr_stmt|;
ifdef|#
directive|ifdef
name|VTNET_LEGACY_TX
name|mask
operator||=
name|VIRTIO_NET_F_MQ
expr_stmt|;
endif|#
directive|endif
name|features
operator|=
name|VTNET_FEATURES
operator|&
operator|~
name|mask
expr_stmt|;
name|sc
operator|->
name|vtnet_features
operator|=
name|virtio_negotiate_features
argument_list|(
name|dev
argument_list|,
name|features
argument_list|)
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VTNET_LRO_FEATURES
argument_list|)
operator|==
literal|0
condition|)
return|return;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_MRG_RXBUF
argument_list|)
condition|)
return|return;
comment|/* 	 * LRO without mergeable buffers requires special care. This is not 	 * ideal because every receive buffer must be large enough to hold 	 * the maximum TCP packet, the Ethernet header, and the header. This 	 * requires up to 34 descriptors with MCLBYTES clusters. If we do 	 * not have indirect descriptors, LRO is disabled since the virtqueue 	 * will not contain very many receive buffers. 	 */
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_RING_F_INDIRECT_DESC
argument_list|)
operator|==
literal|0
condition|)
block|{
name|device_printf
argument_list|(
name|dev
argument_list|,
literal|"LRO disabled due to both mergeable buffers and indirect "
literal|"descriptors not negotiated\n"
argument_list|)
expr_stmt|;
name|features
operator|&=
operator|~
name|VTNET_LRO_FEATURES
expr_stmt|;
name|sc
operator|->
name|vtnet_features
operator|=
name|virtio_negotiate_features
argument_list|(
name|dev
argument_list|,
name|features
argument_list|)
expr_stmt|;
block|}
else|else
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_LRO_NOMRG
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vtnet_setup_features
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|)
block|{
name|device_t
name|dev
decl_stmt|;
name|int
name|max_pairs
decl_stmt|,
name|max
decl_stmt|;
name|dev
operator|=
name|sc
operator|->
name|vtnet_dev
expr_stmt|;
name|vtnet_negotiate_features
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_MAC
argument_list|)
condition|)
block|{
comment|/* This feature should always be negotiated. */
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_MAC
expr_stmt|;
block|}
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_MRG_RXBUF
argument_list|)
condition|)
block|{
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_MRG_RXBUFS
expr_stmt|;
name|sc
operator|->
name|vtnet_hdr_size
operator|=
sizeof|sizeof
argument_list|(
expr|struct
name|virtio_net_hdr_mrg_rxbuf
argument_list|)
expr_stmt|;
block|}
else|else
name|sc
operator|->
name|vtnet_hdr_size
operator|=
sizeof|sizeof
argument_list|(
expr|struct
name|virtio_net_hdr
argument_list|)
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_CTRL_VQ
argument_list|)
condition|)
block|{
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_CTRL_VQ
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_CTRL_RX
argument_list|)
condition|)
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_CTRL_RX
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_CTRL_VLAN
argument_list|)
condition|)
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_VLAN_FILTER
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_CTRL_MAC_ADDR
argument_list|)
condition|)
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_CTRL_MAC
expr_stmt|;
block|}
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_MQ
argument_list|)
operator|&&
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_CTRL_VQ
condition|)
block|{
name|max_pairs
operator|=
name|virtio_read_dev_config_2
argument_list|(
name|dev
argument_list|,
name|offsetof
argument_list|(
expr|struct
name|virtio_net_config
argument_list|,
name|max_virtqueue_pairs
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|max_pairs
operator|<
name|VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MIN
operator|||
name|max_pairs
operator|>
name|VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MAX
condition|)
name|max_pairs
operator|=
literal|1
expr_stmt|;
block|}
else|else
name|max_pairs
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|max_pairs
operator|>
literal|1
condition|)
block|{
comment|/* 		 * Limit the maximum number of queue pairs to the number of 		 * CPUs or the configured maximum. The actual number of 		 * queues that get used may be less. 		 */
name|max
operator|=
name|vtnet_tunable_int
argument_list|(
name|sc
argument_list|,
literal|"mq_max_pairs"
argument_list|,
name|vtnet_mq_max_pairs
argument_list|)
expr_stmt|;
if|if
condition|(
name|max
operator|>
literal|0
operator|&&
name|max_pairs
operator|>
name|max
condition|)
name|max_pairs
operator|=
name|max
expr_stmt|;
if|if
condition|(
name|max_pairs
operator|>
name|mp_ncpus
condition|)
name|max_pairs
operator|=
name|mp_ncpus
expr_stmt|;
if|if
condition|(
name|max_pairs
operator|>
name|VTNET_MAX_QUEUE_PAIRS
condition|)
name|max_pairs
operator|=
name|VTNET_MAX_QUEUE_PAIRS
expr_stmt|;
if|if
condition|(
name|max_pairs
operator|>
literal|1
condition|)
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_MULTIQ
expr_stmt|;
block|}
name|sc
operator|->
name|vtnet_max_vq_pairs
operator|=
name|max_pairs
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_init_rxq
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|,
name|int
name|id
parameter_list|)
block|{
name|struct
name|vtnet_rxq
modifier|*
name|rxq
decl_stmt|;
name|rxq
operator|=
operator|&
name|sc
operator|->
name|vtnet_rxqs
index|[
name|id
index|]
expr_stmt|;
name|snprintf
argument_list|(
name|rxq
operator|->
name|vtnrx_name
argument_list|,
sizeof|sizeof
argument_list|(
name|rxq
operator|->
name|vtnrx_name
argument_list|)
argument_list|,
literal|"%s-rx%d"
argument_list|,
name|device_get_nameunit
argument_list|(
name|sc
operator|->
name|vtnet_dev
argument_list|)
argument_list|,
name|id
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|rxq
operator|->
name|vtnrx_mtx
argument_list|,
name|rxq
operator|->
name|vtnrx_name
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|rxq
operator|->
name|vtnrx_sc
operator|=
name|sc
expr_stmt|;
name|rxq
operator|->
name|vtnrx_id
operator|=
name|id
expr_stmt|;
name|TASK_INIT
argument_list|(
operator|&
name|rxq
operator|->
name|vtnrx_intrtask
argument_list|,
literal|0
argument_list|,
name|vtnet_rxq_tq_intr
argument_list|,
name|rxq
argument_list|)
expr_stmt|;
name|rxq
operator|->
name|vtnrx_tq
operator|=
name|taskqueue_create
argument_list|(
name|rxq
operator|->
name|vtnrx_name
argument_list|,
name|M_NOWAIT
argument_list|,
name|taskqueue_thread_enqueue
argument_list|,
operator|&
name|rxq
operator|->
name|vtnrx_tq
argument_list|)
expr_stmt|;
return|return
operator|(
name|rxq
operator|->
name|vtnrx_tq
operator|==
name|NULL
condition|?
name|ENOMEM
else|:
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_init_txq
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|,
name|int
name|id
parameter_list|)
block|{
name|struct
name|vtnet_txq
modifier|*
name|txq
decl_stmt|;
name|txq
operator|=
operator|&
name|sc
operator|->
name|vtnet_txqs
index|[
name|id
index|]
expr_stmt|;
name|snprintf
argument_list|(
name|txq
operator|->
name|vtntx_name
argument_list|,
sizeof|sizeof
argument_list|(
name|txq
operator|->
name|vtntx_name
argument_list|)
argument_list|,
literal|"%s-tx%d"
argument_list|,
name|device_get_nameunit
argument_list|(
name|sc
operator|->
name|vtnet_dev
argument_list|)
argument_list|,
name|id
argument_list|)
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|txq
operator|->
name|vtntx_mtx
argument_list|,
name|txq
operator|->
name|vtntx_name
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|txq
operator|->
name|vtntx_sc
operator|=
name|sc
expr_stmt|;
name|txq
operator|->
name|vtntx_id
operator|=
name|id
expr_stmt|;
ifndef|#
directive|ifndef
name|VTNET_LEGACY_TX
name|txq
operator|->
name|vtntx_br
operator|=
name|buf_ring_alloc
argument_list|(
name|VTNET_DEFAULT_BUFRING_SIZE
argument_list|,
name|M_DEVBUF
argument_list|,
name|M_NOWAIT
argument_list|,
operator|&
name|txq
operator|->
name|vtntx_mtx
argument_list|)
expr_stmt|;
if|if
condition|(
name|txq
operator|->
name|vtntx_br
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
name|TASK_INIT
argument_list|(
operator|&
name|txq
operator|->
name|vtntx_defrtask
argument_list|,
literal|0
argument_list|,
name|vtnet_txq_tq_deferred
argument_list|,
name|txq
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|TASK_INIT
argument_list|(
operator|&
name|txq
operator|->
name|vtntx_intrtask
argument_list|,
literal|0
argument_list|,
name|vtnet_txq_tq_intr
argument_list|,
name|txq
argument_list|)
expr_stmt|;
name|txq
operator|->
name|vtntx_tq
operator|=
name|taskqueue_create
argument_list|(
name|txq
operator|->
name|vtntx_name
argument_list|,
name|M_NOWAIT
argument_list|,
name|taskqueue_thread_enqueue
argument_list|,
operator|&
name|txq
operator|->
name|vtntx_tq
argument_list|)
expr_stmt|;
if|if
condition|(
name|txq
operator|->
name|vtntx_tq
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_alloc_rxtx_queues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|)
block|{
name|int
name|i
decl_stmt|,
name|npairs
decl_stmt|,
name|error
decl_stmt|;
name|npairs
operator|=
name|sc
operator|->
name|vtnet_max_vq_pairs
expr_stmt|;
name|sc
operator|->
name|vtnet_rxqs
operator|=
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|vtnet_rxq
argument_list|)
operator|*
name|npairs
argument_list|,
name|M_DEVBUF
argument_list|,
name|M_NOWAIT
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_txqs
operator|=
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|vtnet_txq
argument_list|)
operator|*
name|npairs
argument_list|,
name|M_DEVBUF
argument_list|,
name|M_NOWAIT
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|sc
operator|->
name|vtnet_rxqs
operator|==
name|NULL
operator|||
name|sc
operator|->
name|vtnet_txqs
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|npairs
condition|;
name|i
operator|++
control|)
block|{
name|error
operator|=
name|vtnet_init_rxq
argument_list|(
name|sc
argument_list|,
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
return|return
operator|(
name|error
operator|)
return|;
name|error
operator|=
name|vtnet_init_txq
argument_list|(
name|sc
argument_list|,
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
return|return
operator|(
name|error
operator|)
return|;
block|}
name|vtnet_setup_queue_sysctl
argument_list|(
name|sc
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vtnet_destroy_rxq
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
name|rxq
parameter_list|)
block|{
name|rxq
operator|->
name|vtnrx_sc
operator|=
name|NULL
expr_stmt|;
name|rxq
operator|->
name|vtnrx_id
operator|=
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|mtx_initialized
argument_list|(
operator|&
name|rxq
operator|->
name|vtnrx_mtx
argument_list|)
operator|!=
literal|0
condition|)
name|mtx_destroy
argument_list|(
operator|&
name|rxq
operator|->
name|vtnrx_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vtnet_destroy_txq
parameter_list|(
name|struct
name|vtnet_txq
modifier|*
name|txq
parameter_list|)
block|{
name|txq
operator|->
name|vtntx_sc
operator|=
name|NULL
expr_stmt|;
name|txq
operator|->
name|vtntx_id
operator|=
operator|-
literal|1
expr_stmt|;
ifndef|#
directive|ifndef
name|VTNET_LEGACY_TX
if|if
condition|(
name|txq
operator|->
name|vtntx_br
operator|!=
name|NULL
condition|)
block|{
name|buf_ring_free
argument_list|(
name|txq
operator|->
name|vtntx_br
argument_list|,
name|M_DEVBUF
argument_list|)
expr_stmt|;
name|txq
operator|->
name|vtntx_br
operator|=
name|NULL
expr_stmt|;
block|}
endif|#
directive|endif
if|if
condition|(
name|mtx_initialized
argument_list|(
operator|&
name|txq
operator|->
name|vtntx_mtx
argument_list|)
operator|!=
literal|0
condition|)
name|mtx_destroy
argument_list|(
operator|&
name|txq
operator|->
name|vtntx_mtx
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|vtnet_free_rxtx_queues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
if|if
condition|(
name|sc
operator|->
name|vtnet_rxqs
operator|!=
name|NULL
condition|)
block|{
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|sc
operator|->
name|vtnet_max_vq_pairs
condition|;
name|i
operator|++
control|)
name|vtnet_destroy_rxq
argument_list|(
operator|&
name|sc
operator|->
name|vtnet_rxqs
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|sc
operator|->
name|vtnet_rxqs
argument_list|,
name|M_DEVBUF
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_rxqs
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|sc
operator|->
name|vtnet_txqs
operator|!=
name|NULL
condition|)
block|{
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|sc
operator|->
name|vtnet_max_vq_pairs
condition|;
name|i
operator|++
control|)
name|vtnet_destroy_txq
argument_list|(
operator|&
name|sc
operator|->
name|vtnet_txqs
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|sc
operator|->
name|vtnet_txqs
argument_list|,
name|M_DEVBUF
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_txqs
operator|=
name|NULL
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_alloc_rx_filters
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|)
block|{
if|if
condition|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_CTRL_RX
condition|)
block|{
name|sc
operator|->
name|vtnet_mac_filter
operator|=
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|vtnet_mac_filter
argument_list|)
argument_list|,
name|M_DEVBUF
argument_list|,
name|M_NOWAIT
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|sc
operator|->
name|vtnet_mac_filter
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
if|if
condition|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_VLAN_FILTER
condition|)
block|{
name|sc
operator|->
name|vtnet_vlan_filter
operator|=
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
name|uint32_t
argument_list|)
operator|*
name|VTNET_VLAN_FILTER_NWORDS
argument_list|,
name|M_DEVBUF
argument_list|,
name|M_NOWAIT
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|sc
operator|->
name|vtnet_vlan_filter
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vtnet_free_rx_filters
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|)
block|{
if|if
condition|(
name|sc
operator|->
name|vtnet_mac_filter
operator|!=
name|NULL
condition|)
block|{
name|free
argument_list|(
name|sc
operator|->
name|vtnet_mac_filter
argument_list|,
name|M_DEVBUF
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_mac_filter
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|sc
operator|->
name|vtnet_vlan_filter
operator|!=
name|NULL
condition|)
block|{
name|free
argument_list|(
name|sc
operator|->
name|vtnet_vlan_filter
argument_list|,
name|M_DEVBUF
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_vlan_filter
operator|=
name|NULL
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_alloc_virtqueues
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|)
block|{
name|device_t
name|dev
decl_stmt|;
name|struct
name|vq_alloc_info
modifier|*
name|info
decl_stmt|;
name|struct
name|vtnet_rxq
modifier|*
name|rxq
decl_stmt|;
name|struct
name|vtnet_txq
modifier|*
name|txq
decl_stmt|;
name|int
name|i
decl_stmt|,
name|idx
decl_stmt|,
name|flags
decl_stmt|,
name|nvqs
decl_stmt|,
name|rxsegs
decl_stmt|,
name|error
decl_stmt|;
name|dev
operator|=
name|sc
operator|->
name|vtnet_dev
expr_stmt|;
name|flags
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Indirect descriptors are not needed for the Rx virtqueue when 	 * mergeable buffers are negotiated. The header is placed inline 	 * with the data, not in a separate descriptor, and mbuf clusters 	 * are always physically contiguous. 	 */
if|if
condition|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_MRG_RXBUFS
condition|)
name|rxsegs
operator|=
literal|0
expr_stmt|;
elseif|else
if|if
condition|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_LRO_NOMRG
condition|)
name|rxsegs
operator|=
name|VTNET_MAX_RX_SEGS
expr_stmt|;
else|else
name|rxsegs
operator|=
name|VTNET_MIN_RX_SEGS
expr_stmt|;
name|nvqs
operator|=
name|sc
operator|->
name|vtnet_max_vq_pairs
operator|*
literal|2
expr_stmt|;
if|if
condition|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_CTRL_VQ
condition|)
name|nvqs
operator|++
expr_stmt|;
name|info
operator|=
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|vq_alloc_info
argument_list|)
operator|*
name|nvqs
argument_list|,
name|M_TEMP
argument_list|,
name|M_NOWAIT
argument_list|)
expr_stmt|;
if|if
condition|(
name|info
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOMEM
operator|)
return|;
for|for
control|(
name|i
operator|=
literal|0
operator|,
name|idx
operator|=
literal|0
init|;
name|i
operator|<
name|sc
operator|->
name|vtnet_max_vq_pairs
condition|;
name|i
operator|++
operator|,
name|idx
operator|+=
literal|2
control|)
block|{
name|rxq
operator|=
operator|&
name|sc
operator|->
name|vtnet_rxqs
index|[
name|i
index|]
expr_stmt|;
name|VQ_ALLOC_INFO_INIT
argument_list|(
operator|&
name|info
index|[
name|idx
index|]
argument_list|,
name|rxsegs
argument_list|,
name|vtnet_rx_vq_intr
argument_list|,
name|rxq
argument_list|,
operator|&
name|rxq
operator|->
name|vtnrx_vq
argument_list|,
literal|"%s-%d rx"
argument_list|,
name|device_get_nameunit
argument_list|(
name|dev
argument_list|)
argument_list|,
name|rxq
operator|->
name|vtnrx_id
argument_list|)
expr_stmt|;
name|txq
operator|=
operator|&
name|sc
operator|->
name|vtnet_txqs
index|[
name|i
index|]
expr_stmt|;
name|VQ_ALLOC_INFO_INIT
argument_list|(
operator|&
name|info
index|[
name|idx
operator|+
literal|1
index|]
argument_list|,
name|VTNET_MAX_TX_SEGS
argument_list|,
name|vtnet_tx_vq_intr
argument_list|,
name|txq
argument_list|,
operator|&
name|txq
operator|->
name|vtntx_vq
argument_list|,
literal|"%s-%d tx"
argument_list|,
name|device_get_nameunit
argument_list|(
name|dev
argument_list|)
argument_list|,
name|txq
operator|->
name|vtntx_id
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_CTRL_VQ
condition|)
block|{
name|VQ_ALLOC_INFO_INIT
argument_list|(
operator|&
name|info
index|[
name|idx
index|]
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
operator|&
name|sc
operator|->
name|vtnet_ctrl_vq
argument_list|,
literal|"%s ctrl"
argument_list|,
name|device_get_nameunit
argument_list|(
name|dev
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Enable interrupt binding if this is multiqueue. This only matters 	 * when per-vq MSIX is available. 	 */
if|if
condition|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_MULTIQ
condition|)
name|flags
operator||=
literal|0
expr_stmt|;
name|error
operator|=
name|virtio_alloc_virtqueues
argument_list|(
name|dev
argument_list|,
name|flags
argument_list|,
name|nvqs
argument_list|,
name|info
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|info
argument_list|,
name|M_TEMP
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_setup_interface
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|)
block|{
name|device_t
name|dev
decl_stmt|;
name|struct
name|ifnet
modifier|*
name|ifp
decl_stmt|;
name|int
name|limit
decl_stmt|;
name|dev
operator|=
name|sc
operator|->
name|vtnet_dev
expr_stmt|;
name|ifp
operator|=
name|sc
operator|->
name|vtnet_ifp
operator|=
name|if_alloc
argument_list|(
name|IFT_ETHER
argument_list|)
expr_stmt|;
if|if
condition|(
name|ifp
operator|==
name|NULL
condition|)
block|{
name|device_printf
argument_list|(
name|dev
argument_list|,
literal|"cannot allocate ifnet structure\n"
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENOSPC
operator|)
return|;
block|}
name|if_initname
argument_list|(
name|ifp
argument_list|,
name|device_get_name
argument_list|(
name|dev
argument_list|)
argument_list|,
name|device_get_unit
argument_list|(
name|dev
argument_list|)
argument_list|)
expr_stmt|;
name|if_initbaudrate
argument_list|(
name|ifp
argument_list|,
name|IF_Gbps
argument_list|(
literal|10
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Approx. */
name|ifp
operator|->
name|if_softc
operator|=
name|sc
expr_stmt|;
name|ifp
operator|->
name|if_flags
operator|=
name|IFF_BROADCAST
operator||
name|IFF_SIMPLEX
operator||
name|IFF_MULTICAST
expr_stmt|;
name|ifp
operator|->
name|if_init
operator|=
name|vtnet_init
expr_stmt|;
name|ifp
operator|->
name|if_ioctl
operator|=
name|vtnet_ioctl
expr_stmt|;
ifndef|#
directive|ifndef
name|VTNET_LEGACY_TX
name|ifp
operator|->
name|if_transmit
operator|=
name|vtnet_txq_mq_start
expr_stmt|;
name|ifp
operator|->
name|if_qflush
operator|=
name|vtnet_qflush
expr_stmt|;
else|#
directive|else
name|struct
name|virtqueue
modifier|*
name|vq
init|=
name|sc
operator|->
name|vtnet_txqs
index|[
literal|0
index|]
operator|.
name|vtntx_vq
decl_stmt|;
name|ifp
operator|->
name|if_start
operator|=
name|vtnet_start
expr_stmt|;
name|IFQ_SET_MAXLEN
argument_list|(
operator|&
name|ifp
operator|->
name|if_snd
argument_list|,
name|virtqueue_size
argument_list|(
name|vq
argument_list|)
operator|-
literal|1
argument_list|)
expr_stmt|;
name|ifp
operator|->
name|if_snd
operator|.
name|ifq_drv_maxlen
operator|=
name|virtqueue_size
argument_list|(
name|vq
argument_list|)
operator|-
literal|1
expr_stmt|;
name|IFQ_SET_READY
argument_list|(
operator|&
name|ifp
operator|->
name|if_snd
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|ifmedia_init
argument_list|(
operator|&
name|sc
operator|->
name|vtnet_media
argument_list|,
name|IFM_IMASK
argument_list|,
name|vtnet_ifmedia_upd
argument_list|,
name|vtnet_ifmedia_sts
argument_list|)
expr_stmt|;
name|ifmedia_add
argument_list|(
operator|&
name|sc
operator|->
name|vtnet_media
argument_list|,
name|VTNET_MEDIATYPE
argument_list|,
literal|0
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|ifmedia_set
argument_list|(
operator|&
name|sc
operator|->
name|vtnet_media
argument_list|,
name|VTNET_MEDIATYPE
argument_list|)
expr_stmt|;
comment|/* Read (or generate) the MAC address for the adapter. */
name|vtnet_get_hwaddr
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|ether_ifattach
argument_list|(
name|ifp
argument_list|,
name|sc
operator|->
name|vtnet_hwaddr
argument_list|)
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_STATUS
argument_list|)
condition|)
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_LINKSTATE
expr_stmt|;
comment|/* Tell the upper layer(s) we support long frames. */
name|ifp
operator|->
name|if_data
operator|.
name|ifi_hdrlen
operator|=
sizeof|sizeof
argument_list|(
expr|struct
name|ether_vlan_header
argument_list|)
expr_stmt|;
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_JUMBO_MTU
operator||
name|IFCAP_VLAN_MTU
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_CSUM
argument_list|)
condition|)
block|{
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_TXCSUM
operator||
name|IFCAP_TXCSUM_IPV6
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_GSO
argument_list|)
condition|)
block|{
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_TSO4
operator||
name|IFCAP_TSO6
expr_stmt|;
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_TSO_ECN
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_HOST_TSO4
argument_list|)
condition|)
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_TSO4
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_HOST_TSO6
argument_list|)
condition|)
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_TSO6
expr_stmt|;
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_HOST_ECN
argument_list|)
condition|)
name|sc
operator|->
name|vtnet_flags
operator||=
name|VTNET_FLAG_TSO_ECN
expr_stmt|;
block|}
if|if
condition|(
name|ifp
operator|->
name|if_capabilities
operator|&
name|IFCAP_TSO
condition|)
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_VLAN_HWTSO
expr_stmt|;
block|}
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_GUEST_CSUM
argument_list|)
condition|)
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_RXCSUM
operator||
name|IFCAP_RXCSUM_IPV6
expr_stmt|;
if|if
condition|(
name|ifp
operator|->
name|if_capabilities
operator|&
name|IFCAP_HWCSUM
condition|)
block|{
comment|/* 		 * VirtIO does not support VLAN tagging, but we can fake 		 * it by inserting and removing the 802.1Q header during 		 * transmit and receive. We are then able to do checksum 		 * offloading of VLAN frames. 		 */
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_VLAN_HWTAGGING
operator||
name|IFCAP_VLAN_HWCSUM
expr_stmt|;
block|}
name|ifp
operator|->
name|if_capenable
operator|=
name|ifp
operator|->
name|if_capabilities
expr_stmt|;
comment|/* 	 * Capabilities after here are not enabled by default. 	 */
if|if
condition|(
name|ifp
operator|->
name|if_capabilities
operator|&
name|IFCAP_RXCSUM
condition|)
block|{
if|if
condition|(
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_GUEST_TSO4
argument_list|)
operator|||
name|virtio_with_feature
argument_list|(
name|dev
argument_list|,
name|VIRTIO_NET_F_GUEST_TSO6
argument_list|)
condition|)
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_LRO
expr_stmt|;
block|}
if|if
condition|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_VLAN_FILTER
condition|)
block|{
name|ifp
operator|->
name|if_capabilities
operator||=
name|IFCAP_VLAN_HWFILTER
expr_stmt|;
name|sc
operator|->
name|vtnet_vlan_attach
operator|=
name|EVENTHANDLER_REGISTER
argument_list|(
name|vlan_config
argument_list|,
name|vtnet_register_vlan
argument_list|,
name|sc
argument_list|,
name|EVENTHANDLER_PRI_FIRST
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_vlan_detach
operator|=
name|EVENTHANDLER_REGISTER
argument_list|(
name|vlan_unconfig
argument_list|,
name|vtnet_unregister_vlan
argument_list|,
name|sc
argument_list|,
name|EVENTHANDLER_PRI_FIRST
argument_list|)
expr_stmt|;
block|}
name|limit
operator|=
name|vtnet_tunable_int
argument_list|(
name|sc
argument_list|,
literal|"rx_process_limit"
argument_list|,
name|vtnet_rx_process_limit
argument_list|)
expr_stmt|;
if|if
condition|(
name|limit
operator|<
literal|0
condition|)
name|limit
operator|=
name|INT_MAX
expr_stmt|;
name|sc
operator|->
name|vtnet_rx_process_limit
operator|=
name|limit
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_change_mtu
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|,
name|int
name|new_mtu
parameter_list|)
block|{
name|struct
name|ifnet
modifier|*
name|ifp
decl_stmt|;
name|int
name|frame_size
decl_stmt|,
name|clsize
decl_stmt|;
name|ifp
operator|=
name|sc
operator|->
name|vtnet_ifp
expr_stmt|;
if|if
condition|(
name|new_mtu
operator|<
name|ETHERMIN
operator|||
name|new_mtu
operator|>
name|VTNET_MAX_MTU
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|frame_size
operator|=
name|sc
operator|->
name|vtnet_hdr_size
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|ether_vlan_header
argument_list|)
operator|+
name|new_mtu
expr_stmt|;
comment|/* 	 * Based on the new MTU (and hence frame size) determine which 	 * cluster size is most appropriate for the receive queues. 	 */
if|if
condition|(
name|frame_size
operator|<=
name|MCLBYTES
condition|)
block|{
name|clsize
operator|=
name|MCLBYTES
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_MRG_RXBUFS
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* Avoid going past 9K jumbos. */
if|if
condition|(
name|frame_size
operator|>
name|MJUM9BYTES
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|clsize
operator|=
name|MJUM9BYTES
expr_stmt|;
block|}
else|else
name|clsize
operator|=
name|MJUMPAGESIZE
expr_stmt|;
name|ifp
operator|->
name|if_mtu
operator|=
name|new_mtu
expr_stmt|;
name|sc
operator|->
name|vtnet_rx_new_clsize
operator|=
name|clsize
expr_stmt|;
if|if
condition|(
name|ifp
operator|->
name|if_drv_flags
operator|&
name|IFF_DRV_RUNNING
condition|)
block|{
name|ifp
operator|->
name|if_drv_flags
operator|&=
operator|~
name|IFF_DRV_RUNNING
expr_stmt|;
name|vtnet_init_locked
argument_list|(
name|sc
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_ioctl
parameter_list|(
name|struct
name|ifnet
modifier|*
name|ifp
parameter_list|,
name|u_long
name|cmd
parameter_list|,
name|caddr_t
name|data
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|struct
name|ifreq
modifier|*
name|ifr
decl_stmt|;
name|int
name|reinit
decl_stmt|,
name|mask
decl_stmt|,
name|error
decl_stmt|;
name|sc
operator|=
name|ifp
operator|->
name|if_softc
expr_stmt|;
name|ifr
operator|=
operator|(
expr|struct
name|ifreq
operator|*
operator|)
name|data
expr_stmt|;
name|error
operator|=
literal|0
expr_stmt|;
switch|switch
condition|(
name|cmd
condition|)
block|{
case|case
name|SIOCSIFMTU
case|:
if|if
condition|(
name|ifp
operator|->
name|if_mtu
operator|!=
name|ifr
operator|->
name|ifr_mtu
condition|)
block|{
name|VTNET_CORE_LOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|error
operator|=
name|vtnet_change_mtu
argument_list|(
name|sc
argument_list|,
name|ifr
operator|->
name|ifr_mtu
argument_list|)
expr_stmt|;
name|VTNET_CORE_UNLOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|SIOCSIFFLAGS
case|:
name|VTNET_CORE_LOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|ifp
operator|->
name|if_flags
operator|&
name|IFF_UP
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|ifp
operator|->
name|if_drv_flags
operator|&
name|IFF_DRV_RUNNING
condition|)
name|vtnet_stop
argument_list|(
name|sc
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ifp
operator|->
name|if_drv_flags
operator|&
name|IFF_DRV_RUNNING
condition|)
block|{
if|if
condition|(
operator|(
name|ifp
operator|->
name|if_flags
operator|^
name|sc
operator|->
name|vtnet_if_flags
operator|)
operator|&
operator|(
name|IFF_PROMISC
operator||
name|IFF_ALLMULTI
operator|)
condition|)
block|{
if|if
condition|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_CTRL_RX
condition|)
name|vtnet_rx_filter
argument_list|(
name|sc
argument_list|)
expr_stmt|;
else|else
name|error
operator|=
name|ENOTSUP
expr_stmt|;
block|}
block|}
else|else
name|vtnet_init_locked
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
operator|==
literal|0
condition|)
name|sc
operator|->
name|vtnet_if_flags
operator|=
name|ifp
operator|->
name|if_flags
expr_stmt|;
name|VTNET_CORE_UNLOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
break|break;
case|case
name|SIOCADDMULTI
case|:
case|case
name|SIOCDELMULTI
case|:
if|if
condition|(
operator|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_CTRL_RX
operator|)
operator|==
literal|0
condition|)
break|break;
name|VTNET_CORE_LOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
if|if
condition|(
name|ifp
operator|->
name|if_drv_flags
operator|&
name|IFF_DRV_RUNNING
condition|)
name|vtnet_rx_filter_mac
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|VTNET_CORE_UNLOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
break|break;
case|case
name|SIOCSIFMEDIA
case|:
case|case
name|SIOCGIFMEDIA
case|:
name|error
operator|=
name|ifmedia_ioctl
argument_list|(
name|ifp
argument_list|,
name|ifr
argument_list|,
operator|&
name|sc
operator|->
name|vtnet_media
argument_list|,
name|cmd
argument_list|)
expr_stmt|;
break|break;
case|case
name|SIOCSIFCAP
case|:
name|VTNET_CORE_LOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|mask
operator|=
name|ifr
operator|->
name|ifr_reqcap
operator|^
name|ifp
operator|->
name|if_capenable
expr_stmt|;
if|if
condition|(
name|mask
operator|&
name|IFCAP_TXCSUM
condition|)
name|ifp
operator|->
name|if_capenable
operator|^=
name|IFCAP_TXCSUM
expr_stmt|;
if|if
condition|(
name|mask
operator|&
name|IFCAP_TXCSUM_IPV6
condition|)
name|ifp
operator|->
name|if_capenable
operator|^=
name|IFCAP_TXCSUM_IPV6
expr_stmt|;
if|if
condition|(
name|mask
operator|&
name|IFCAP_TSO4
condition|)
name|ifp
operator|->
name|if_capenable
operator|^=
name|IFCAP_TSO4
expr_stmt|;
if|if
condition|(
name|mask
operator|&
name|IFCAP_TSO6
condition|)
name|ifp
operator|->
name|if_capenable
operator|^=
name|IFCAP_TSO6
expr_stmt|;
if|if
condition|(
name|mask
operator|&
operator|(
name|IFCAP_RXCSUM
operator||
name|IFCAP_RXCSUM_IPV6
operator||
name|IFCAP_LRO
operator||
name|IFCAP_VLAN_HWFILTER
operator|)
condition|)
block|{
comment|/* These Rx features require us to renegotiate. */
name|reinit
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|mask
operator|&
name|IFCAP_RXCSUM
condition|)
name|ifp
operator|->
name|if_capenable
operator|^=
name|IFCAP_RXCSUM
expr_stmt|;
if|if
condition|(
name|mask
operator|&
name|IFCAP_RXCSUM_IPV6
condition|)
name|ifp
operator|->
name|if_capenable
operator|^=
name|IFCAP_RXCSUM_IPV6
expr_stmt|;
if|if
condition|(
name|mask
operator|&
name|IFCAP_LRO
condition|)
name|ifp
operator|->
name|if_capenable
operator|^=
name|IFCAP_LRO
expr_stmt|;
if|if
condition|(
name|mask
operator|&
name|IFCAP_VLAN_HWFILTER
condition|)
name|ifp
operator|->
name|if_capenable
operator|^=
name|IFCAP_VLAN_HWFILTER
expr_stmt|;
block|}
else|else
name|reinit
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|mask
operator|&
name|IFCAP_VLAN_HWTSO
condition|)
name|ifp
operator|->
name|if_capenable
operator|^=
name|IFCAP_VLAN_HWTSO
expr_stmt|;
if|if
condition|(
name|mask
operator|&
name|IFCAP_VLAN_HWTAGGING
condition|)
name|ifp
operator|->
name|if_capenable
operator|^=
name|IFCAP_VLAN_HWTAGGING
expr_stmt|;
if|if
condition|(
name|reinit
operator|&&
operator|(
name|ifp
operator|->
name|if_drv_flags
operator|&
name|IFF_DRV_RUNNING
operator|)
condition|)
block|{
name|ifp
operator|->
name|if_drv_flags
operator|&=
operator|~
name|IFF_DRV_RUNNING
expr_stmt|;
name|vtnet_init_locked
argument_list|(
name|sc
argument_list|)
expr_stmt|;
block|}
name|VTNET_CORE_UNLOCK
argument_list|(
name|sc
argument_list|)
expr_stmt|;
name|VLAN_CAPABILITIES
argument_list|(
name|ifp
argument_list|)
expr_stmt|;
break|break;
default|default:
name|error
operator|=
name|ether_ioctl
argument_list|(
name|ifp
argument_list|,
name|cmd
argument_list|,
name|data
argument_list|)
expr_stmt|;
break|break;
block|}
name|VTNET_CORE_LOCK_ASSERT_NOTOWNED
argument_list|(
name|sc
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_rxq_populate
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
name|rxq
parameter_list|)
block|{
name|struct
name|virtqueue
modifier|*
name|vq
decl_stmt|;
name|int
name|nbufs
decl_stmt|,
name|error
decl_stmt|;
name|vq
operator|=
name|rxq
operator|->
name|vtnrx_vq
expr_stmt|;
name|error
operator|=
name|ENOSPC
expr_stmt|;
for|for
control|(
name|nbufs
operator|=
literal|0
init|;
operator|!
name|virtqueue_full
argument_list|(
name|vq
argument_list|)
condition|;
name|nbufs
operator|++
control|)
block|{
name|error
operator|=
name|vtnet_rxq_new_buf
argument_list|(
name|rxq
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
break|break;
block|}
if|if
condition|(
name|nbufs
operator|>
literal|0
condition|)
block|{
name|virtqueue_notify
argument_list|(
name|vq
argument_list|)
expr_stmt|;
comment|/* 		 * EMSGSIZE signifies the virtqueue did not have enough 		 * entries available to hold the last mbuf. This is not 		 * an error. 		 */
if|if
condition|(
name|error
operator|==
name|EMSGSIZE
condition|)
name|error
operator|=
literal|0
expr_stmt|;
block|}
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|vtnet_rxq_free_mbufs
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
name|rxq
parameter_list|)
block|{
name|struct
name|virtqueue
modifier|*
name|vq
decl_stmt|;
name|struct
name|mbuf
modifier|*
name|m
decl_stmt|;
name|int
name|last
decl_stmt|;
name|vq
operator|=
name|rxq
operator|->
name|vtnrx_vq
expr_stmt|;
name|last
operator|=
literal|0
expr_stmt|;
while|while
condition|(
operator|(
name|m
operator|=
name|virtqueue_drain
argument_list|(
name|vq
argument_list|,
operator|&
name|last
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
name|m_freem
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|virtqueue_empty
argument_list|(
name|vq
argument_list|)
argument_list|,
operator|(
literal|"%s: mbufs remaining in rx queue %p"
operator|,
name|__func__
operator|,
name|rxq
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|struct
name|mbuf
modifier|*
name|vtnet_rx_alloc_buf
parameter_list|(
name|struct
name|vtnet_softc
modifier|*
name|sc
parameter_list|,
name|int
name|nbufs
parameter_list|,
name|struct
name|mbuf
modifier|*
modifier|*
name|m_tailp
parameter_list|)
block|{
name|struct
name|mbuf
modifier|*
name|m_head
decl_stmt|,
modifier|*
name|m_tail
decl_stmt|,
modifier|*
name|m
decl_stmt|;
name|int
name|i
decl_stmt|,
name|clsize
decl_stmt|;
name|clsize
operator|=
name|sc
operator|->
name|vtnet_rx_clsize
expr_stmt|;
name|KASSERT
argument_list|(
name|nbufs
operator|==
literal|1
operator|||
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_LRO_NOMRG
argument_list|,
operator|(
literal|"%s: chained mbuf %d request without LRO_NOMRG"
operator|,
name|__func__
operator|,
name|nbufs
operator|)
argument_list|)
expr_stmt|;
name|m_head
operator|=
name|m_getjcl
argument_list|(
name|M_NOWAIT
argument_list|,
name|MT_DATA
argument_list|,
name|M_PKTHDR
argument_list|,
name|clsize
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_head
operator|==
name|NULL
condition|)
goto|goto
name|fail
goto|;
name|m_head
operator|->
name|m_len
operator|=
name|clsize
expr_stmt|;
name|m_tail
operator|=
name|m_head
expr_stmt|;
comment|/* Allocate the rest of the chain. */
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|nbufs
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|m_getjcl
argument_list|(
name|M_NOWAIT
argument_list|,
name|MT_DATA
argument_list|,
literal|0
argument_list|,
name|clsize
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
goto|goto
name|fail
goto|;
name|m
operator|->
name|m_len
operator|=
name|clsize
expr_stmt|;
name|m_tail
operator|->
name|m_next
operator|=
name|m
expr_stmt|;
name|m_tail
operator|=
name|m
expr_stmt|;
block|}
if|if
condition|(
name|m_tailp
operator|!=
name|NULL
condition|)
operator|*
name|m_tailp
operator|=
name|m_tail
expr_stmt|;
return|return
operator|(
name|m_head
operator|)
return|;
name|fail
label|:
name|sc
operator|->
name|vtnet_stats
operator|.
name|mbuf_alloc_failed
operator|++
expr_stmt|;
name|m_freem
argument_list|(
name|m_head
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Slow path for when LRO without mergeable buffers is negotiated.  */
end_comment

begin_function
specifier|static
name|int
name|vtnet_rxq_replace_lro_nomgr_buf
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
name|rxq
parameter_list|,
name|struct
name|mbuf
modifier|*
name|m0
parameter_list|,
name|int
name|len0
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|struct
name|mbuf
modifier|*
name|m
decl_stmt|,
modifier|*
name|m_prev
decl_stmt|;
name|struct
name|mbuf
modifier|*
name|m_new
decl_stmt|,
modifier|*
name|m_tail
decl_stmt|;
name|int
name|len
decl_stmt|,
name|clsize
decl_stmt|,
name|nreplace
decl_stmt|,
name|error
decl_stmt|;
name|sc
operator|=
name|rxq
operator|->
name|vtnrx_sc
expr_stmt|;
name|clsize
operator|=
name|sc
operator|->
name|vtnet_rx_clsize
expr_stmt|;
name|m_prev
operator|=
name|NULL
expr_stmt|;
name|m_tail
operator|=
name|NULL
expr_stmt|;
name|nreplace
operator|=
literal|0
expr_stmt|;
name|m
operator|=
name|m0
expr_stmt|;
name|len
operator|=
name|len0
expr_stmt|;
comment|/* 	 * Since these mbuf chains are so large, we avoid allocating an 	 * entire replacement chain if possible. When the received frame 	 * did not consume the entire chain, the unused mbufs are moved 	 * to the replacement chain. 	 */
while|while
condition|(
name|len
operator|>
literal|0
condition|)
block|{
comment|/* 		 * Something is seriously wrong if we received a frame 		 * larger than the chain. Drop it. 		 */
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
block|{
name|sc
operator|->
name|vtnet_stats
operator|.
name|rx_frame_too_large
operator|++
expr_stmt|;
return|return
operator|(
name|EMSGSIZE
operator|)
return|;
block|}
comment|/* We always allocate the same cluster size. */
name|KASSERT
argument_list|(
name|m
operator|->
name|m_len
operator|==
name|clsize
argument_list|,
operator|(
literal|"%s: mbuf size %d is not the cluster size %d"
operator|,
name|__func__
operator|,
name|m
operator|->
name|m_len
operator|,
name|clsize
operator|)
argument_list|)
expr_stmt|;
name|m
operator|->
name|m_len
operator|=
name|MIN
argument_list|(
name|m
operator|->
name|m_len
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|len
operator|-=
name|m
operator|->
name|m_len
expr_stmt|;
name|m_prev
operator|=
name|m
expr_stmt|;
name|m
operator|=
name|m
operator|->
name|m_next
expr_stmt|;
name|nreplace
operator|++
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|nreplace
operator|<=
name|sc
operator|->
name|vtnet_rx_nmbufs
argument_list|,
operator|(
literal|"%s: too many replacement mbufs %d max %d"
operator|,
name|__func__
operator|,
name|nreplace
operator|,
name|sc
operator|->
name|vtnet_rx_nmbufs
operator|)
argument_list|)
expr_stmt|;
name|m_new
operator|=
name|vtnet_rx_alloc_buf
argument_list|(
name|sc
argument_list|,
name|nreplace
argument_list|,
operator|&
name|m_tail
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_new
operator|==
name|NULL
condition|)
block|{
name|m_prev
operator|->
name|m_len
operator|=
name|clsize
expr_stmt|;
return|return
operator|(
name|ENOBUFS
operator|)
return|;
block|}
comment|/* 	 * Move any unused mbufs from the received chain onto the end 	 * of the new chain. 	 */
if|if
condition|(
name|m_prev
operator|->
name|m_next
operator|!=
name|NULL
condition|)
block|{
name|m_tail
operator|->
name|m_next
operator|=
name|m_prev
operator|->
name|m_next
expr_stmt|;
name|m_prev
operator|->
name|m_next
operator|=
name|NULL
expr_stmt|;
block|}
name|error
operator|=
name|vtnet_rxq_enqueue_buf
argument_list|(
name|rxq
argument_list|,
name|m_new
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
comment|/* 		 * BAD! We could not enqueue the replacement mbuf chain. We 		 * must restore the m0 chain to the original state if it was 		 * modified so we can subsequently discard it. 		 * 		 * NOTE: The replacement is suppose to be an identical copy 		 * to the one just dequeued so this is an unexpected error. 		 */
name|sc
operator|->
name|vtnet_stats
operator|.
name|rx_enq_replacement_failed
operator|++
expr_stmt|;
if|if
condition|(
name|m_tail
operator|->
name|m_next
operator|!=
name|NULL
condition|)
block|{
name|m_prev
operator|->
name|m_next
operator|=
name|m_tail
operator|->
name|m_next
expr_stmt|;
name|m_tail
operator|->
name|m_next
operator|=
name|NULL
expr_stmt|;
block|}
name|m_prev
operator|->
name|m_len
operator|=
name|clsize
expr_stmt|;
name|m_freem
argument_list|(
name|m_new
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_rxq_replace_buf
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
name|rxq
parameter_list|,
name|struct
name|mbuf
modifier|*
name|m
parameter_list|,
name|int
name|len
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|struct
name|mbuf
modifier|*
name|m_new
decl_stmt|;
name|int
name|error
decl_stmt|;
name|sc
operator|=
name|rxq
operator|->
name|vtnrx_sc
expr_stmt|;
name|KASSERT
argument_list|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_LRO_NOMRG
operator|||
name|m
operator|->
name|m_next
operator|==
name|NULL
argument_list|,
operator|(
literal|"%s: chained mbuf without LRO_NOMRG"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|m_next
operator|==
name|NULL
condition|)
block|{
comment|/* Fast-path for the common case of just one mbuf. */
if|if
condition|(
name|m
operator|->
name|m_len
operator|<
name|len
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|m_new
operator|=
name|vtnet_rx_alloc_buf
argument_list|(
name|sc
argument_list|,
literal|1
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|m_new
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOBUFS
operator|)
return|;
name|error
operator|=
name|vtnet_rxq_enqueue_buf
argument_list|(
name|rxq
argument_list|,
name|m_new
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
block|{
comment|/* 			 * The new mbuf is suppose to be an identical 			 * copy of the one just dequeued so this is an 			 * unexpected error. 			 */
name|m_freem
argument_list|(
name|m_new
argument_list|)
expr_stmt|;
name|sc
operator|->
name|vtnet_stats
operator|.
name|rx_enq_replacement_failed
operator|++
expr_stmt|;
block|}
else|else
name|m
operator|->
name|m_len
operator|=
name|len
expr_stmt|;
block|}
else|else
name|error
operator|=
name|vtnet_rxq_replace_lro_nomgr_buf
argument_list|(
name|rxq
argument_list|,
name|m
argument_list|,
name|len
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_rxq_enqueue_buf
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
name|rxq
parameter_list|,
name|struct
name|mbuf
modifier|*
name|m
parameter_list|)
block|{
name|struct
name|sglist
name|sg
decl_stmt|;
name|struct
name|sglist_seg
name|segs
index|[
name|VTNET_MAX_RX_SEGS
index|]
decl_stmt|;
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|struct
name|vtnet_rx_header
modifier|*
name|rxhdr
decl_stmt|;
name|uint8_t
modifier|*
name|mdata
decl_stmt|;
name|int
name|offset
decl_stmt|,
name|error
decl_stmt|;
name|sc
operator|=
name|rxq
operator|->
name|vtnrx_sc
expr_stmt|;
name|mdata
operator|=
name|mtod
argument_list|(
name|m
argument_list|,
name|uint8_t
operator|*
argument_list|)
expr_stmt|;
name|VTNET_RXQ_LOCK_ASSERT
argument_list|(
name|rxq
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_LRO_NOMRG
operator|||
name|m
operator|->
name|m_next
operator|==
name|NULL
argument_list|,
operator|(
literal|"%s: chained mbuf without LRO_NOMRG"
operator|,
name|__func__
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|m_len
operator|==
name|sc
operator|->
name|vtnet_rx_clsize
argument_list|,
operator|(
literal|"%s: unexpected cluster size %d/%d"
operator|,
name|__func__
operator|,
name|m
operator|->
name|m_len
operator|,
name|sc
operator|->
name|vtnet_rx_clsize
operator|)
argument_list|)
expr_stmt|;
name|sglist_init
argument_list|(
operator|&
name|sg
argument_list|,
name|VTNET_MAX_RX_SEGS
argument_list|,
name|segs
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|sc
operator|->
name|vtnet_flags
operator|&
name|VTNET_FLAG_MRG_RXBUFS
operator|)
operator|==
literal|0
condition|)
block|{
name|MPASS
argument_list|(
name|sc
operator|->
name|vtnet_hdr_size
operator|==
sizeof|sizeof
argument_list|(
expr|struct
name|virtio_net_hdr
argument_list|)
argument_list|)
expr_stmt|;
name|rxhdr
operator|=
operator|(
expr|struct
name|vtnet_rx_header
operator|*
operator|)
name|mdata
expr_stmt|;
name|sglist_append
argument_list|(
operator|&
name|sg
argument_list|,
operator|&
name|rxhdr
operator|->
name|vrh_hdr
argument_list|,
name|sc
operator|->
name|vtnet_hdr_size
argument_list|)
expr_stmt|;
name|offset
operator|=
sizeof|sizeof
argument_list|(
expr|struct
name|vtnet_rx_header
argument_list|)
expr_stmt|;
block|}
else|else
name|offset
operator|=
literal|0
expr_stmt|;
name|sglist_append
argument_list|(
operator|&
name|sg
argument_list|,
name|mdata
operator|+
name|offset
argument_list|,
name|m
operator|->
name|m_len
operator|-
name|offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|m_next
operator|!=
name|NULL
condition|)
block|{
name|error
operator|=
name|sglist_append_mbuf
argument_list|(
operator|&
name|sg
argument_list|,
name|m
operator|->
name|m_next
argument_list|)
expr_stmt|;
name|MPASS
argument_list|(
name|error
operator|==
literal|0
argument_list|)
expr_stmt|;
block|}
name|error
operator|=
name|virtqueue_enqueue
argument_list|(
name|rxq
operator|->
name|vtnrx_vq
argument_list|,
name|m
argument_list|,
operator|&
name|sg
argument_list|,
literal|0
argument_list|,
name|sg
operator|.
name|sg_nseg
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_rxq_new_buf
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
name|rxq
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|struct
name|mbuf
modifier|*
name|m
decl_stmt|;
name|int
name|error
decl_stmt|;
name|sc
operator|=
name|rxq
operator|->
name|vtnrx_sc
expr_stmt|;
name|m
operator|=
name|vtnet_rx_alloc_buf
argument_list|(
name|sc
argument_list|,
name|sc
operator|->
name|vtnet_rx_nmbufs
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
return|return
operator|(
name|ENOBUFS
operator|)
return|;
name|error
operator|=
name|vtnet_rxq_enqueue_buf
argument_list|(
name|rxq
argument_list|,
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|error
condition|)
name|m_freem
argument_list|(
name|m
argument_list|)
expr_stmt|;
return|return
operator|(
name|error
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Use the checksum offset in the VirtIO header to set the  * correct CSUM_* flags.  */
end_comment

begin_function
specifier|static
name|int
name|vtnet_rxq_csum_by_offset
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
name|rxq
parameter_list|,
name|struct
name|mbuf
modifier|*
name|m
parameter_list|,
name|uint16_t
name|eth_type
parameter_list|,
name|int
name|ip_start
parameter_list|,
name|struct
name|virtio_net_hdr
modifier|*
name|hdr
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|INET
argument_list|)
operator|||
name|defined
argument_list|(
name|INET6
argument_list|)
name|int
name|offset
init|=
name|hdr
operator|->
name|csum_start
operator|+
name|hdr
operator|->
name|csum_offset
decl_stmt|;
endif|#
directive|endif
name|sc
operator|=
name|rxq
operator|->
name|vtnrx_sc
expr_stmt|;
comment|/* Only do a basic sanity check on the offset. */
switch|switch
condition|(
name|eth_type
condition|)
block|{
if|#
directive|if
name|defined
argument_list|(
name|INET
argument_list|)
case|case
name|ETHERTYPE_IP
case|:
if|if
condition|(
name|__predict_false
argument_list|(
name|offset
operator|<
name|ip_start
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|ip
argument_list|)
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
break|break;
endif|#
directive|endif
if|#
directive|if
name|defined
argument_list|(
name|INET6
argument_list|)
case|case
name|ETHERTYPE_IPV6
case|:
if|if
condition|(
name|__predict_false
argument_list|(
name|offset
operator|<
name|ip_start
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|ip6_hdr
argument_list|)
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
break|break;
endif|#
directive|endif
default|default:
name|sc
operator|->
name|vtnet_stats
operator|.
name|rx_csum_bad_ethtype
operator|++
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
comment|/* 	 * Use the offset to determine the appropriate CSUM_* flags. This is 	 * a bit dirty, but we can get by with it since the checksum offsets 	 * happen to be different. We assume the host host does not do IPv4 	 * header checksum offloading. 	 */
switch|switch
condition|(
name|hdr
operator|->
name|csum_offset
condition|)
block|{
case|case
name|offsetof
argument_list|(
expr|struct
name|udphdr
argument_list|,
name|uh_sum
argument_list|)
case|:
case|case
name|offsetof
argument_list|(
expr|struct
name|tcphdr
argument_list|,
name|th_sum
argument_list|)
case|:
name|m
operator|->
name|m_pkthdr
operator|.
name|csum_flags
operator||=
name|CSUM_DATA_VALID
operator||
name|CSUM_PSEUDO_HDR
expr_stmt|;
name|m
operator|->
name|m_pkthdr
operator|.
name|csum_data
operator|=
literal|0xFFFF
expr_stmt|;
break|break;
case|case
name|offsetof
argument_list|(
expr|struct
name|sctphdr
argument_list|,
name|checksum
argument_list|)
case|:
name|m
operator|->
name|m_pkthdr
operator|.
name|csum_flags
operator||=
name|CSUM_SCTP_VALID
expr_stmt|;
break|break;
default|default:
name|sc
operator|->
name|vtnet_stats
operator|.
name|rx_csum_bad_offset
operator|++
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|int
name|vtnet_rxq_csum_by_parse
parameter_list|(
name|struct
name|vtnet_rxq
modifier|*
name|rxq
parameter_list|,
name|struct
name|mbuf
modifier|*
name|m
parameter_list|,
name|uint16_t
name|eth_type
parameter_list|,
name|int
name|ip_start
parameter_list|,
name|struct
name|virtio_net_hdr
modifier|*
name|hdr
parameter_list|)
block|{
name|struct
name|vtnet_softc
modifier|*
name|sc
decl_stmt|;
name|int
name|offset
decl_stmt|,
name|proto
decl_stmt|;
name|sc
operator|=
name|rxq
operator|->
name|vtnrx_sc
expr_stmt|;
switch|switch
condition|(
name|eth_type
condition|)
block|{
if|#
directive|if
name|defined
argument_list|(
name|INET
argument_list|)
case|case
name|ETHERTYPE_IP
case|:
block|{
name|struct
name|ip
modifier|*
name|ip
decl_stmt|;
if|if
condition|(
name|__predict_false
argument_list|(
name|m
operator|->
name|m_len
operator|<
name|ip_start
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|ip
argument_list|)
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|ip
operator|=
operator|(
expr|struct
name|ip
operator|*
operator|)
operator|(
name|m
operator|->
name|m_data
operator|+
name|ip_start
operator|)
expr_stmt|;
name|proto
operator|=
name|ip
operator|->
name|ip_p
expr_stmt|;
name|offset
operator|=
name|ip_start
operator|+
operator|(
name|ip
operator|->
name|ip_hl
operator|<<
literal|2
operator|)
expr_stmt|;
break|break;
block|}
endif|#
directive|endif
if|#
directive|if
name|defined
argument_list|(
name|INET6
argument_list|)
case|case
name|ETHERTYPE_IPV6
case|:
if|if
condition|(
name|__predict_false
argument_list|(
name|m
operator|->
name|m_len
operator|<
name|ip_start
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|ip6_hdr
argument_list|)
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|offset
operator|=
name|ip6_lasthdr
argument_list|(
name|m
argument_list|,
name|ip_start
argument_list|,
name|IPPROTO_IPV6
argument_list|,
operator|&
name|proto
argument_list|)
expr_stmt|;
if|if
condition|(
name|__predict_false
argument_list|(
name|offset
operator|<
literal|0
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
break|break;
endif|#
directive|endif
default|default:
name|sc
operator|->
name|vtnet_stats
operator|.
name|rx_csum_bad_ethtype
operator|++
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
switch|switch
condition|(
name|proto
condition|)
block|{
case|case
name|IPPROTO_TCP
case|:
if|if
condition|(
name|__predict_false
argument_list|(
name|m
operator|->
name|m_len
operator|<
name|offset
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|tcphdr
argument_list|)
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|m
operator|->
name|m_pkthdr
operator|.
name|csum_flags
operator||=
name|CSUM_DATA_VALID
operator||
name|CSUM_PSEUDO_HDR
expr_stmt|;
name|m
operator|->
name|m_pkthdr
operator|.
name|csum_data
operator|=
literal|0xFFFF
expr_stmt|;
break|break;
case|case
name|IPPROTO_UDP
case|:
if|if
condition|(
name|__predict_false
argument_list|(
name|m
operator|->
name|m_len
operator|<
name|offset
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|udphdr
argument_list|)
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|m
operator|->
name|m_pkthdr
operator|.
name|csum_flags
operator||=
name|CSUM_DATA_VALID
operator||
name|CSUM_PSEUDO_HDR
expr_stmt|;
name|m
operator|->
name|m_pkthdr
operator|.
name|csum_data
operator|=
literal|0xFFFF
expr_stmt|;
break|break;
case|case
name|IPPROTO_SCTP
case|:
if|if
condition|(
name|__predict_false
argument_list|(
name|m
operator|->
name|m_len
operator|<
name|offset
operator|+
sizeof|sizeof
argument_list|(
expr|struct
name|sctphdr
argument_list|)
argument_list|)
condition|)
return|return
operator|(
literal|1
operator|)
return|;
name|m
operator|->
name|m_pkthdr
operator|.
name|csum_flags
operator||=
name|CSUM_SCTP_VALID
expr_stmt|;
break|break;
default|default:
end_function

begin_comment
comment|/* 		 * For the remaining protocols, FreeBSD does not support 		 * checksum offloading, so the checksum will be recomputed. 		 */
end_comment

begin_if
if|#
directive|if
literal|0
end_if

unit|if_printf(sc->vtnet_ifp, "cksum offload of unsupported " 		    "protocol eth_type=%#x proto=%d csum_start=%d 		    "csum_offset=%d\n", __func__, eth_type, proto, 		    hdr->csum_start, hdr->csum_offset); #endif 		break; 	}  	return (0); }  /*  * Set the appropriate CSUM_* flags. Unfortunately, the information  * provided is not directly useful to us. The VirtIO header gives the  * offset of the checksum, which is all Linux needs, but this is not  * how FreeBSD does things. We are forced to peek inside the packet  * a bit.  *  * It would be nice if VirtIO gave us the L4 protocol or if FreeBSD  * could accept the offsets and let the stack figure it out.  */ static int vtnet_rxq_csum(struct vtnet_rxq *rxq, struct mbuf *m,     struct virtio_net_hdr *hdr) { 	struct ether_header *eh; 	struct ether_vlan_header *evh; 	uint16_t eth_type; 	int offset, error;  	eh = mtod(m, struct ether_header *); 	eth_type = ntohs(eh->ether_type); 	if (eth_type == ETHERTYPE_VLAN) { 		/* BMV: We should handle nested VLAN tags too. */ 		evh = mtod(m, struct ether_vlan_header *); 		eth_type = ntohs(evh->evl_proto); 		offset = sizeof(struct ether_vlan_header); 	} else 		offset = sizeof(struct ether_header);  	if (hdr->flags& VIRTIO_NET_HDR_F_NEEDS_CSUM) 		error = vtnet_rxq_csum_by_offset(rxq, m, eth_type, offset, hdr); 	else 		error = vtnet_rxq_csum_by_parse(rxq, m, eth_type, offset, hdr);  	return (error); }  static void vtnet_rxq_discard_merged_bufs(struct vtnet_rxq *rxq, int nbufs) { 	struct mbuf *m;  	while (--nbufs> 0) { 		m = virtqueue_dequeue(rxq->vtnrx_vq, NULL); 		if (m == NULL) 			break; 		vtnet_rxq_discard_buf(rxq, m); 	} }  static void vtnet_rxq_discard_buf(struct vtnet_rxq *rxq, struct mbuf *m) { 	int error;  	/* 	 * Requeue the discarded mbuf. This should always be successful 	 * since it was just dequeued. 	 */ 	error = vtnet_rxq_enqueue_buf(rxq, m); 	KASSERT(error == 0, 	    ("%s: cannot requeue discarded mbuf %d", __func__, error)); }  static int vtnet_rxq_merged_eof(struct vtnet_rxq *rxq, struct mbuf *m_head, int nbufs) { 	struct vtnet_softc *sc; 	struct ifnet *ifp; 	struct virtqueue *vq; 	struct mbuf *m, *m_tail; 	int len;  	sc = rxq->vtnrx_sc; 	vq = rxq->vtnrx_vq; 	ifp = sc->vtnet_ifp; 	m_tail = m_head;  	while (--nbufs> 0) { 		m = virtqueue_dequeue(vq,&len); 		if (m == NULL) { 			rxq->vtnrx_stats.vrxs_ierrors++; 			goto fail; 		}  		if (vtnet_rxq_new_buf(rxq) != 0) { 			rxq->vtnrx_stats.vrxs_iqdrops++; 			vtnet_rxq_discard_buf(rxq, m); 			if (nbufs> 1) 				vtnet_rxq_discard_merged_bufs(rxq, nbufs); 			goto fail; 		}  		if (m->m_len< len) 			len = m->m_len;  		m->m_len = len; 		m->m_flags&= ~M_PKTHDR;  		m_head->m_pkthdr.len += len; 		m_tail->m_next = m; 		m_tail = m; 	}  	return (0);  fail: 	sc->vtnet_stats.rx_mergeable_failed++; 	m_freem(m_head);  	return (1); }  static void vtnet_rxq_input(struct vtnet_rxq *rxq, struct mbuf *m,     struct virtio_net_hdr *hdr) { 	struct vtnet_softc *sc; 	struct ifnet *ifp; 	struct ether_header *eh;  	sc = rxq->vtnrx_sc; 	ifp = sc->vtnet_ifp;  	if (ifp->if_capenable& IFCAP_VLAN_HWTAGGING) { 		eh = mtod(m, struct ether_header *); 		if (eh->ether_type == htons(ETHERTYPE_VLAN)) { 			vtnet_vlan_tag_remove(m); 			/* 			 * With the 802.1Q header removed, update the 			 * checksum starting location accordingly. 			 */ 			if (hdr->flags& VIRTIO_NET_HDR_F_NEEDS_CSUM) 				hdr->csum_start -= ETHER_VLAN_ENCAP_LEN; 		} 	}  	m->m_pkthdr.flowid = rxq->vtnrx_id; 	m->m_flags |= M_FLOWID;  	/* 	 * BMV: FreeBSD does not have the UNNECESSARY and PARTIAL checksum 	 * distinction that Linux does. Need to reevaluate if performing 	 * offloading for the NEEDS_CSUM case is really appropriate. 	 */ 	if (hdr->flags& (VIRTIO_NET_HDR_F_NEEDS_CSUM | 	    VIRTIO_NET_HDR_F_DATA_VALID)) { 		if (vtnet_rxq_csum(rxq, m, hdr) == 0) 			rxq->vtnrx_stats.vrxs_csum++; 		else 			rxq->vtnrx_stats.vrxs_csum_failed++; 	}  	rxq->vtnrx_stats.vrxs_ipackets++; 	rxq->vtnrx_stats.vrxs_ibytes += m->m_pkthdr.len;  	/* VTNET_RXQ_UNLOCK(rxq); */ 	(*ifp->if_input)(ifp, m); 	/* VTNET_RXQ_LOCK(rxq); */ }  static int vtnet_rxq_eof(struct vtnet_rxq *rxq) { 	struct virtio_net_hdr lhdr, *hdr; 	struct vtnet_softc *sc; 	struct ifnet *ifp; 	struct virtqueue *vq; 	struct mbuf *m; 	struct virtio_net_hdr_mrg_rxbuf *mhdr; 	int len, deq, nbufs, adjsz, count;  	sc = rxq->vtnrx_sc; 	vq = rxq->vtnrx_vq; 	ifp = sc->vtnet_ifp; 	hdr =&lhdr; 	deq = 0; 	count = sc->vtnet_rx_process_limit;  	VTNET_RXQ_LOCK_ASSERT(rxq);  	while (count--> 0) { 		m = virtqueue_dequeue(vq,&len); 		if (m == NULL) 			break; 		deq++;  		if (len< sc->vtnet_hdr_size + ETHER_HDR_LEN) { 			rxq->vtnrx_stats.vrxs_ierrors++; 			vtnet_rxq_discard_buf(rxq, m); 			continue; 		}  		if ((sc->vtnet_flags& VTNET_FLAG_MRG_RXBUFS) == 0) { 			nbufs = 1; 			adjsz = sizeof(struct vtnet_rx_header); 			/* 			 * Account for our pad inserted between the header 			 * and the actual start of the frame. 			 */ 			len += VTNET_RX_HEADER_PAD; 		} else { 			mhdr = mtod(m, struct virtio_net_hdr_mrg_rxbuf *); 			nbufs = mhdr->num_buffers; 			adjsz = sizeof(struct virtio_net_hdr_mrg_rxbuf); 		}  		if (vtnet_rxq_replace_buf(rxq, m, len) != 0) { 			rxq->vtnrx_stats.vrxs_iqdrops++; 			vtnet_rxq_discard_buf(rxq, m); 			if (nbufs> 1) 				vtnet_rxq_discard_merged_bufs(rxq, nbufs); 			continue; 		}  		m->m_pkthdr.len = len; 		m->m_pkthdr.rcvif = ifp; 		m->m_pkthdr.csum_flags = 0;  		if (nbufs> 1) { 			/* Dequeue the rest of chain. */ 			if (vtnet_rxq_merged_eof(rxq, m, nbufs) != 0) 				continue; 		}  		/* 		 * Save copy of header before we strip it. For both mergeable 		 * and non-mergeable, the header is at the beginning of the 		 * mbuf data. We no longer need num_buffers, so always use a 		 * regular header. 		 * 		 * BMV: Is this memcpy() expensive? We know the mbuf data is 		 * still valid even after the m_adj(). 		 */ 		memcpy(hdr, mtod(m, void *), sizeof(struct virtio_net_hdr)); 		m_adj(m, adjsz);  		vtnet_rxq_input(rxq, m, hdr); 	}  	if (deq> 0) 		virtqueue_notify(vq);  	return (count> 0 ? 0 : EAGAIN); }  static void vtnet_rx_vq_intr(void *xrxq) { 	struct vtnet_softc *sc; 	struct vtnet_rxq *rxq; 	struct ifnet *ifp; 	int tries, more;  	rxq = xrxq; 	sc = rxq->vtnrx_sc; 	ifp = sc->vtnet_ifp; 	tries = 0;  	if (__predict_false(rxq->vtnrx_id>= sc->vtnet_act_vq_pairs)) { 		/* 		 * Ignore this interrupt. Either this is a spurious interrupt 		 * or multiqueue without per-VQ MSIX so every queue needs to 		 * be polled (a brain dead configuration we could try harder 		 * to avoid). 		 */ 		vtnet_rxq_disable_intr(rxq); 		return; 	}  again: 	VTNET_RXQ_LOCK(rxq);  	if ((ifp->if_drv_flags& IFF_DRV_RUNNING) == 0) { 		VTNET_RXQ_UNLOCK(rxq); 		return; 	}  	more = vtnet_rxq_eof(rxq); 	if (more || vtnet_rxq_enable_intr(rxq) != 0) { 		if (!more) 			vtnet_rxq_disable_intr(rxq); 		/* 		 * This is an occasional condition or race (when !more), 		 * so retry a few times before scheduling the taskqueue. 		 */ 		rxq->vtnrx_stats.vrxs_rescheduled++; 		VTNET_RXQ_UNLOCK(rxq); 		if (tries++< VTNET_INTR_DISABLE_RETRIES) 			goto again; 		taskqueue_enqueue(rxq->vtnrx_tq,&rxq->vtnrx_intrtask); 	} else 		VTNET_RXQ_UNLOCK(rxq); }  static void vtnet_rxq_tq_intr(void *xrxq, int pending) { 	struct vtnet_softc *sc; 	struct vtnet_rxq *rxq; 	struct ifnet *ifp; 	int more;  	rxq = xrxq; 	sc = rxq->vtnrx_sc; 	ifp = sc->vtnet_ifp;  	VTNET_RXQ_LOCK(rxq);  	if ((ifp->if_drv_flags& IFF_DRV_RUNNING) == 0) { 		VTNET_RXQ_UNLOCK(rxq); 		return; 	}  	more = vtnet_rxq_eof(rxq); 	if (more || vtnet_rxq_enable_intr(rxq) != 0) { 		if (!more) 			vtnet_rxq_disable_intr(rxq); 		rxq->vtnrx_stats.vrxs_rescheduled++; 		taskqueue_enqueue(rxq->vtnrx_tq,&rxq->vtnrx_intrtask); 	}  	VTNET_RXQ_UNLOCK(rxq); }  static void vtnet_txq_free_mbufs(struct vtnet_txq *txq) { 	struct virtqueue *vq; 	struct vtnet_tx_header *txhdr; 	int last;  	vq = txq->vtntx_vq; 	last = 0;  	while ((txhdr = virtqueue_drain(vq,&last)) != NULL) { 		m_freem(txhdr->vth_mbuf); 		uma_zfree(vtnet_tx_header_zone, txhdr); 	}  	KASSERT(virtqueue_empty(vq), 	    ("%s: mbufs remaining in tx queue %p", __func__, txq)); }  /*  * BMV: Much of this can go away once we finally have offsets in  * the mbuf packet header. Bug andre@.  */ static int vtnet_txq_offload_ctx(struct vtnet_txq *txq, struct mbuf *m,     int *etype, int *proto, int *start) { 	struct vtnet_softc *sc; 	struct ether_vlan_header *evh; 	int offset;  	sc = txq->vtntx_sc;  	evh = mtod(m, struct ether_vlan_header *); 	if (evh->evl_encap_proto == htons(ETHERTYPE_VLAN)) { 		/* BMV: We should handle nested VLAN tags too. */ 		*etype = ntohs(evh->evl_proto); 		offset = sizeof(struct ether_vlan_header); 	} else { 		*etype = ntohs(evh->evl_encap_proto); 		offset = sizeof(struct ether_header); 	}  	switch (*etype) { #if defined(INET) 	case ETHERTYPE_IP: { 		struct ip *ip, iphdr; 		if (__predict_false(m->m_len< offset + sizeof(struct ip))) { 			m_copydata(m, offset, sizeof(struct ip), 			    (caddr_t)&iphdr); 			ip =&iphdr; 		} else 			ip = (struct ip *)(m->m_data + offset); 		*proto = ip->ip_p; 		*start = offset + (ip->ip_hl<< 2); 		break; 	} #endif #if defined(INET6) 	case ETHERTYPE_IPV6: 		*proto = -1; 		*start = ip6_lasthdr(m, offset, IPPROTO_IPV6, proto); 		/* Assert the network stack sent us a valid packet. */ 		KASSERT(*start> offset, 		    ("%s: mbuf %p start %d offset %d proto %d", __func__, m, 		    *start, offset, *proto)); 		break; #endif 	default: 		sc->vtnet_stats.tx_csum_bad_ethtype++; 		return (EINVAL); 	}  	return (0); }  static int vtnet_txq_offload_tso(struct vtnet_txq *txq, struct mbuf *m, int eth_type,     int offset, struct virtio_net_hdr *hdr) { 	static struct timeval lastecn; 	static int curecn; 	struct vtnet_softc *sc; 	struct tcphdr *tcp, tcphdr;  	sc = txq->vtntx_sc;  	if (__predict_false(m->m_len< offset + sizeof(struct tcphdr))) { 		m_copydata(m, offset, sizeof(struct tcphdr), (caddr_t)&tcphdr); 		tcp =&tcphdr; 	} else 		tcp = (struct tcphdr *)(m->m_data + offset);  	hdr->hdr_len = offset + (tcp->th_off<< 2); 	hdr->gso_size = m->m_pkthdr.tso_segsz; 	hdr->gso_type = eth_type == ETHERTYPE_IP ? VIRTIO_NET_HDR_GSO_TCPV4 : 	    VIRTIO_NET_HDR_GSO_TCPV6;  	if (tcp->th_flags& TH_CWR) { 		/* 		 * Drop if VIRTIO_NET_F_HOST_ECN was not negotiated. In FreeBSD, 		 * ECN support is not on a per-interface basis, but globally via 		 * the net.inet.tcp.ecn.enable sysctl knob. The default is off. 		 */ 		if ((sc->vtnet_flags& VTNET_FLAG_TSO_ECN) == 0) { 			if (ppsratecheck(&lastecn,&curecn, 1)) 				if_printf(sc->vtnet_ifp, 				    "TSO with ECN not negotiated with host\n"); 			return (ENOTSUP); 		} 		hdr->gso_type |= VIRTIO_NET_HDR_GSO_ECN; 	}  	txq->vtntx_stats.vtxs_tso++;  	return (0); }  static struct mbuf * vtnet_txq_offload(struct vtnet_txq *txq, struct mbuf *m,     struct virtio_net_hdr *hdr) { 	struct vtnet_softc *sc; 	int flags, etype, csum_start, proto, error;  	sc = txq->vtntx_sc; 	flags = m->m_pkthdr.csum_flags;  	error = vtnet_txq_offload_ctx(txq, m,&etype,&proto,&csum_start); 	if (error) 		goto drop;  	if ((etype == ETHERTYPE_IP&& flags& VTNET_CSUM_OFFLOAD) || 	    (etype == ETHERTYPE_IPV6&& flags& VTNET_CSUM_OFFLOAD_IPV6)) { 		/* 		 * We could compare the IP protocol vs the CSUM_ flag too, 		 * but that really should not be necessary. 		 */ 		hdr->flags |= VIRTIO_NET_HDR_F_NEEDS_CSUM; 		hdr->csum_start = csum_start; 		hdr->csum_offset = m->m_pkthdr.csum_data; 		txq->vtntx_stats.vtxs_csum++; 	}  	if (flags& CSUM_TSO) { 		if (__predict_false(proto != IPPROTO_TCP)) { 			/* Likely failed to correctly parse the mbuf. */ 			sc->vtnet_stats.tx_tso_not_tcp++; 			goto drop; 		}  		KASSERT(hdr->flags& VIRTIO_NET_HDR_F_NEEDS_CSUM, 		    ("%s: mbuf %p TSO without checksum offload", __func__, m));  		error = vtnet_txq_offload_tso(txq, m, etype, csum_start, hdr); 		if (error) 			goto drop; 	}  	return (m);  drop: 	m_freem(m); 	return (NULL); }  static int vtnet_txq_enqueue_buf(struct vtnet_txq *txq, struct mbuf **m_head,     struct vtnet_tx_header *txhdr) { 	struct sglist sg; 	struct sglist_seg segs[VTNET_MAX_TX_SEGS]; 	struct vtnet_softc *sc; 	struct virtqueue *vq; 	struct mbuf *m; 	int collapsed, error;  	vq = txq->vtntx_vq; 	sc = txq->vtntx_sc; 	m = *m_head; 	collapsed = 0;  	sglist_init(&sg, VTNET_MAX_TX_SEGS, segs); 	error = sglist_append(&sg,&txhdr->vth_uhdr, sc->vtnet_hdr_size); 	KASSERT(error == 0&& sg.sg_nseg == 1, 	    ("%s: error %d adding header to sglist", __func__, error));  again: 	error = sglist_append_mbuf(&sg, m); 	if (error) { 		if (collapsed) 			goto fail;  		m = m_collapse(m, M_NOWAIT, VTNET_MAX_TX_SEGS - 1); 		if (m == NULL) 			goto fail;  		*m_head = m; 		collapsed = 1; 		txq->vtntx_stats.vtxs_collapsed++; 		goto again; 	}  	txhdr->vth_mbuf = m; 	error = virtqueue_enqueue(vq, txhdr,&sg, sg.sg_nseg, 0);  	return (error);  fail: 	m_freem(*m_head); 	*m_head = NULL;  	return (ENOBUFS); }  static int vtnet_txq_encap(struct vtnet_txq *txq, struct mbuf **m_head) { 	struct vtnet_softc *sc; 	struct vtnet_tx_header *txhdr; 	struct virtio_net_hdr *hdr; 	struct mbuf *m; 	int error;  	sc = txq->vtntx_sc; 	m = *m_head; 	M_ASSERTPKTHDR(m);  	txhdr = uma_zalloc(vtnet_tx_header_zone, M_NOWAIT | M_ZERO); 	if (txhdr == NULL) { 		m_freem(m); 		*m_head = NULL; 		return (ENOMEM); 	}  	/* 	 * Always use the non-mergeable header, regardless if the feature 	 * was negotiated. For transmit, num_buffers is always zero. The 	 * vtnet_hdr_size is used to enqueue the correct header size. 	 */ 	hdr =&txhdr->vth_uhdr.hdr;  	if (m->m_flags& M_VLANTAG) { 		m = ether_vlanencap(m, m->m_pkthdr.ether_vtag); 		if ((*m_head = m) == NULL) { 			error = ENOBUFS; 			goto fail; 		} 		m->m_flags&= ~M_VLANTAG; 	}  	if (m->m_pkthdr.csum_flags& VTNET_CSUM_ALL_OFFLOAD) { 		m = vtnet_txq_offload(txq, m, hdr); 		if ((*m_head = m) == NULL) { 			error = ENOBUFS; 			goto fail; 		} 	}  	error = vtnet_txq_enqueue_buf(txq, m_head, txhdr); 	if (error == 0) 		return (0);  fail: 	uma_zfree(vtnet_tx_header_zone, txhdr);  	return (error); }  #ifdef VTNET_LEGACY_TX  static void vtnet_start_locked(struct vtnet_txq *txq, struct ifnet *ifp) { 	struct vtnet_softc *sc; 	struct virtqueue *vq; 	struct mbuf *m0; 	int enq;  	sc = txq->vtntx_sc; 	vq = txq->vtntx_vq; 	enq = 0;  	VTNET_TXQ_LOCK_ASSERT(txq);  	if ((ifp->if_drv_flags& IFF_DRV_RUNNING) == 0 || 	    sc->vtnet_link_active == 0) 		return;  	while (!IFQ_DRV_IS_EMPTY(&ifp->if_snd)) { 		if (virtqueue_full(vq)) 			break;  		IFQ_DRV_DEQUEUE(&ifp->if_snd, m0); 		if (m0 == NULL) 			break;  		if (vtnet_txq_encap(txq,&m0) != 0) { 			if (m0 != NULL) 				IFQ_DRV_PREPEND(&ifp->if_snd, m0); 			break; 		}  		enq++; 		ETHER_BPF_MTAP(ifp, m0); 	}  	if (enq> 0) { 		virtqueue_notify(vq); 		txq->vtntx_watchdog = VTNET_TX_TIMEOUT; 	} }  static void vtnet_start(struct ifnet *ifp) { 	struct vtnet_softc *sc; 	struct vtnet_txq *txq;  	sc = ifp->if_softc; 	txq =&sc->vtnet_txqs[0];  	VTNET_TXQ_LOCK(txq); 	vtnet_start_locked(txq, ifp); 	VTNET_TXQ_UNLOCK(txq); }  #else /* !VTNET_LEGACY_TX */  static int vtnet_txq_mq_start_locked(struct vtnet_txq *txq, struct mbuf *m) { 	struct vtnet_softc *sc; 	struct virtqueue *vq; 	struct buf_ring *br; 	struct ifnet *ifp; 	int enq, error;  	sc = txq->vtntx_sc; 	vq = txq->vtntx_vq; 	br = txq->vtntx_br; 	ifp = sc->vtnet_ifp; 	enq = 0; 	error = 0;  	VTNET_TXQ_LOCK_ASSERT(txq);  	if ((ifp->if_drv_flags& IFF_DRV_RUNNING) == 0 || 	    sc->vtnet_link_active == 0) { 		if (m != NULL) 			error = drbr_enqueue(ifp, br, m); 		return (error); 	}  	if (m != NULL) { 		error = drbr_enqueue(ifp, br, m); 		if (error) 			return (error); 	}  	while ((m = drbr_peek(ifp, br)) != NULL) { 		error = vtnet_txq_encap(txq,&m); 		if (error) { 			if (m != NULL) 				drbr_putback(ifp, br, m); 			else 				drbr_advance(ifp, br); 			break; 		} 		drbr_advance(ifp, br);  		enq++; 		ETHER_BPF_MTAP(ifp, m); 	}  	if (enq> 0) { 		virtqueue_notify(vq); 		txq->vtntx_watchdog = VTNET_TX_TIMEOUT; 	}  	return (error); }  static int vtnet_txq_mq_start(struct ifnet *ifp, struct mbuf *m) { 	struct vtnet_softc *sc; 	struct vtnet_txq *txq; 	int i, npairs, error;  	sc = ifp->if_softc; 	npairs = sc->vtnet_act_vq_pairs;  	if (m->m_flags& M_FLOWID) 		i = m->m_pkthdr.flowid % npairs; 	else 		i = curcpu % npairs;  	txq =&sc->vtnet_txqs[i];  	if (VTNET_TXQ_TRYLOCK(txq) != 0) { 		error = vtnet_txq_mq_start_locked(txq, m); 		VTNET_TXQ_UNLOCK(txq); 	} else { 		error = drbr_enqueue(ifp, txq->vtntx_br, m); 		taskqueue_enqueue(txq->vtntx_tq,&txq->vtntx_defrtask); 	}  	return (error); }  static void vtnet_txq_tq_deferred(void *xtxq, int pending) { 	struct vtnet_softc *sc; 	struct vtnet_txq *txq;  	txq = xtxq; 	sc = txq->vtntx_sc;  	VTNET_TXQ_LOCK(txq); 	if (!drbr_empty(sc->vtnet_ifp, txq->vtntx_br)) 		vtnet_txq_mq_start_locked(txq, NULL); 	VTNET_TXQ_UNLOCK(txq); }  #endif /* VTNET_LEGACY_TX */  static void vtnet_txq_tq_intr(void *xtxq, int pending) { 	struct vtnet_softc *sc; 	struct vtnet_txq *txq; 	struct ifnet *ifp;  	txq = xtxq; 	sc = txq->vtntx_sc; 	ifp = sc->vtnet_ifp;  	VTNET_TXQ_LOCK(txq);  	if ((ifp->if_drv_flags& IFF_DRV_RUNNING) == 0) { 		VTNET_TXQ_UNLOCK(txq); 		return; 	}  	vtnet_txq_eof(txq);  #ifdef VTNET_LEGACY_TX 	if (!IFQ_DRV_IS_EMPTY(&ifp->if_snd)) 		vtnet_start_locked(txq, ifp); #else 	if (!drbr_empty(ifp, txq->vtntx_br)) 		vtnet_txq_mq_start_locked(txq, NULL); #endif  	if (vtnet_txq_enable_intr(txq) != 0) { 		vtnet_txq_disable_intr(txq); 		txq->vtntx_stats.vtxs_rescheduled++; 		taskqueue_enqueue(txq->vtntx_tq,&txq->vtntx_intrtask); 	}  	VTNET_TXQ_UNLOCK(txq); }  static void vtnet_txq_eof(struct vtnet_txq *txq) { 	struct virtqueue *vq; 	struct vtnet_tx_header *txhdr; 	struct mbuf *m;  	vq = txq->vtntx_vq; 	VTNET_TXQ_LOCK_ASSERT(txq);  	while ((txhdr = virtqueue_dequeue(vq, NULL)) != NULL) { 		m = txhdr->vth_mbuf;  		txq->vtntx_stats.vtxs_opackets++; 		txq->vtntx_stats.vtxs_obytes += m->m_pkthdr.len; 		if (m->m_flags& M_MCAST) 			txq->vtntx_stats.vtxs_omcasts++;  		m_freem(m); 		uma_zfree(vtnet_tx_header_zone, txhdr); 	}  	if (virtqueue_empty(vq)) 		txq->vtntx_watchdog = 0; }  static void vtnet_tx_vq_intr(void *xtxq) { 	struct vtnet_softc *sc; 	struct vtnet_txq *txq; 	struct ifnet *ifp; 	int tries;  	txq = xtxq; 	sc = txq->vtntx_sc; 	ifp = sc->vtnet_ifp; 	tries = 0;  	if (__predict_false(txq->vtntx_id>= sc->vtnet_act_vq_pairs)) { 		/* 		 * Ignore this interrupt. Either this is a spurious interrupt 		 * or multiqueue without per-VQ MSIX so every queue needs to 		 * be polled (a brain dead configuration we could try harder 		 * to avoid). 		 */ 		vtnet_txq_disable_intr(txq); 		return; 	}  again: 	VTNET_TXQ_LOCK(txq);  	if ((ifp->if_drv_flags& IFF_DRV_RUNNING) == 0) { 		VTNET_TXQ_UNLOCK(txq); 		return; 	}  	vtnet_txq_eof(txq);  #ifdef VTNET_LEGACY_TX 	if (!IFQ_DRV_IS_EMPTY(&ifp->if_snd)) 		vtnet_start_locked(txq, ifp); #else 	if (!drbr_empty(ifp, txq->vtntx_br)) 		vtnet_txq_mq_start_locked(txq, NULL); #endif  	if (vtnet_txq_enable_intr(txq) != 0) { 		vtnet_txq_disable_intr(txq); 		/* 		 * This is an occasional race, so retry a few times 		 * before scheduling the taskqueue. 		 */ 		VTNET_TXQ_UNLOCK(txq); 		if (tries++< VTNET_INTR_DISABLE_RETRIES) 			goto again; 		txq->vtntx_stats.vtxs_rescheduled++; 		taskqueue_enqueue(txq->vtntx_tq,&txq->vtntx_intrtask); 	} else 		VTNET_TXQ_UNLOCK(txq); }  static void vtnet_tx_start_all(struct vtnet_softc *sc) { 	struct ifnet *ifp; 	struct vtnet_txq *txq; 	int i;  	ifp = sc->vtnet_ifp; 	VTNET_CORE_LOCK_ASSERT(sc);  	for (i = 0; i< sc->vtnet_act_vq_pairs; i++) { 		txq =&sc->vtnet_txqs[i];  		VTNET_TXQ_LOCK(txq); #ifdef VTNET_LEGACY_TX 		if (!IFQ_DRV_IS_EMPTY(&ifp->if_snd)) 			vtnet_start_locked(txq, ifp); #else 		if (!drbr_empty(ifp, txq->vtntx_br)) 			vtnet_txq_mq_start_locked(txq, NULL); #endif 		VTNET_TXQ_UNLOCK(txq); 	} }  #ifndef VTNET_LEGACY_TX static void vtnet_qflush(struct ifnet *ifp) { 	struct vtnet_softc *sc; 	struct vtnet_txq *txq; 	struct mbuf *m; 	int i;  	sc = ifp->if_softc;  	for (i = 0; i< sc->vtnet_act_vq_pairs; i++) { 		txq =&sc->vtnet_txqs[i];  		VTNET_TXQ_LOCK(txq); 		while ((m = buf_ring_dequeue_sc(txq->vtntx_br)) != NULL) 			m_freem(m); 		VTNET_TXQ_UNLOCK(txq); 	}  	if_qflush(ifp); } #endif  static int vtnet_watchdog(struct vtnet_txq *txq) { 	struct vtnet_softc *sc;  	sc = txq->vtntx_sc;  	VTNET_TXQ_LOCK(txq); 	if (txq->vtntx_watchdog == 0 || --txq->vtntx_watchdog) { 		VTNET_TXQ_UNLOCK(txq); 		return (0); 	} 	VTNET_TXQ_UNLOCK(txq);  	if_printf(sc->vtnet_ifp, "watchdog timeout on queue %d\n", 	    txq->vtntx_id); 	return (1); }  static void vtnet_rxq_accum_stats(struct vtnet_rxq *rxq, struct vtnet_rxq_stats *accum) { 	struct vtnet_rxq_stats *st;  	st =&rxq->vtnrx_stats;  	accum->vrxs_ipackets += st->vrxs_ipackets; 	accum->vrxs_ibytes += st->vrxs_ibytes; 	accum->vrxs_iqdrops += st->vrxs_iqdrops; 	accum->vrxs_csum += st->vrxs_csum; 	accum->vrxs_csum_failed += st->vrxs_csum_failed; 	accum->vrxs_rescheduled += st->vrxs_rescheduled; }  static void vtnet_txq_accum_stats(struct vtnet_txq *txq, struct vtnet_txq_stats *accum) { 	struct vtnet_txq_stats *st;  	st =&txq->vtntx_stats;  	accum->vtxs_opackets += st->vtxs_opackets; 	accum->vtxs_obytes += st->vtxs_obytes; 	accum->vtxs_csum += st->vtxs_csum; 	accum->vtxs_tso += st->vtxs_tso; 	accum->vtxs_collapsed += st->vtxs_collapsed; 	accum->vtxs_rescheduled += st->vtxs_rescheduled; }  static void vtnet_accumulate_stats(struct vtnet_softc *sc) { 	struct ifnet *ifp; 	struct vtnet_statistics *st; 	struct vtnet_rxq_stats rxaccum; 	struct vtnet_txq_stats txaccum; 	int i;  	ifp = sc->vtnet_ifp; 	st =&sc->vtnet_stats; 	bzero(&rxaccum, sizeof(struct vtnet_rxq_stats)); 	bzero(&txaccum, sizeof(struct vtnet_txq_stats));  	for (i = 0; i< sc->vtnet_max_vq_pairs; i++) { 		vtnet_rxq_accum_stats(&sc->vtnet_rxqs[i],&rxaccum); 		vtnet_txq_accum_stats(&sc->vtnet_txqs[i],&txaccum); 	}  	st->rx_csum_offloaded = rxaccum.vrxs_csum; 	st->rx_csum_failed = rxaccum.vrxs_csum_failed; 	st->rx_task_rescheduled = rxaccum.vrxs_rescheduled; 	st->tx_csum_offloaded = txaccum.vtxs_csum; 	st->tx_tso_offloaded = txaccum.vtxs_tso; 	st->tx_task_rescheduled = txaccum.vtxs_rescheduled;  	/* 	 * With the exception of if_ierrors, these ifnet statistics are 	 * only updated in the driver, so just set them to our accumulated 	 * values. if_ierrors is updated in ether_input() for malformed 	 * frames that we should have already discarded. 	 */ 	ifp->if_ipackets = rxaccum.vrxs_ipackets; 	ifp->if_iqdrops = rxaccum.vrxs_iqdrops; 	ifp->if_ierrors = rxaccum.vrxs_ierrors; 	ifp->if_opackets = txaccum.vtxs_opackets; #ifndef VTNET_LEGACY_TX 	ifp->if_obytes = txaccum.vtxs_obytes; 	ifp->if_omcasts = txaccum.vtxs_omcasts; #endif }  static void vtnet_tick(void *xsc) { 	struct vtnet_softc *sc; 	struct ifnet *ifp; 	int i, timedout;  	sc = xsc; 	ifp = sc->vtnet_ifp; 	timedout = 0;  	VTNET_CORE_LOCK_ASSERT(sc); 	vtnet_accumulate_stats(sc);  	for (i = 0; i< sc->vtnet_act_vq_pairs; i++) 		timedout |= vtnet_watchdog(&sc->vtnet_txqs[i]);  	if (timedout != 0) { 		ifp->if_drv_flags&= ~IFF_DRV_RUNNING; 		vtnet_init_locked(sc); 	} else 		callout_schedule(&sc->vtnet_tick_ch, hz); }  static void vtnet_start_taskqueues(struct vtnet_softc *sc) { 	device_t dev; 	struct vtnet_rxq *rxq; 	struct vtnet_txq *txq; 	int i, error;  	dev = sc->vtnet_dev;  	/* 	 * Errors here are very difficult to recover from - we cannot 	 * easily fail because, if this is during boot, we will hang 	 * when freeing any successfully started taskqueues because 	 * the scheduler isn't up yet. 	 * 	 * Most drivers just ignore the return value - it only fails 	 * with ENOMEM so an error is not likely. 	 */ 	for (i = 0; i< sc->vtnet_max_vq_pairs; i++) { 		rxq =&sc->vtnet_rxqs[i]; 		error = taskqueue_start_threads(&rxq->vtnrx_tq, 1, PI_NET, 		    "%s rxq %d", device_get_nameunit(dev), rxq->vtnrx_id); 		if (error) { 			device_printf(dev, "failed to start rx taskq %d\n", 			    rxq->vtnrx_id); 		}  		txq =&sc->vtnet_txqs[i]; 		error = taskqueue_start_threads(&txq->vtntx_tq, 1, PI_NET, 		    "%s txq %d", device_get_nameunit(dev), txq->vtntx_id); 		if (error) { 			device_printf(dev, "failed to start tx taskq %d\n", 			    txq->vtntx_id); 		} 	} }  static void vtnet_free_taskqueues(struct vtnet_softc *sc) { 	struct vtnet_rxq *rxq; 	struct vtnet_txq *txq; 	int i;  	for (i = 0; i< sc->vtnet_max_vq_pairs; i++) { 		rxq =&sc->vtnet_rxqs[i]; 		if (rxq->vtnrx_tq != NULL) { 			taskqueue_free(rxq->vtnrx_tq); 			rxq->vtnrx_vq = NULL; 		}  		txq =&sc->vtnet_txqs[i]; 		if (txq->vtntx_tq != NULL) { 			taskqueue_free(txq->vtntx_tq); 			txq->vtntx_tq = NULL; 		} 	} }  static void vtnet_drain_taskqueues(struct vtnet_softc *sc) { 	struct vtnet_rxq *rxq; 	struct vtnet_txq *txq; 	int i;  	for (i = 0; i< sc->vtnet_max_vq_pairs; i++) { 		rxq =&sc->vtnet_rxqs[i]; 		if (rxq->vtnrx_tq != NULL) 			taskqueue_drain(rxq->vtnrx_tq,&rxq->vtnrx_intrtask);  		txq =&sc->vtnet_txqs[i]; 		if (txq->vtntx_tq != NULL) { 			taskqueue_drain(txq->vtntx_tq,&txq->vtntx_intrtask); #ifndef VTNET_LEGACY_TX 			taskqueue_drain(txq->vtntx_tq,&txq->vtntx_defrtask); #endif 		} 	} }  static void vtnet_drain_rxtx_queues(struct vtnet_softc *sc) { 	struct vtnet_rxq *rxq; 	struct vtnet_txq *txq; 	int i;  	for (i = 0; i< sc->vtnet_act_vq_pairs; i++) { 		rxq =&sc->vtnet_rxqs[i]; 		vtnet_rxq_free_mbufs(rxq);  		txq =&sc->vtnet_txqs[i]; 		vtnet_txq_free_mbufs(txq); 	} }  static void vtnet_stop_rendezvous(struct vtnet_softc *sc) { 	struct vtnet_rxq *rxq; 	struct vtnet_txq *txq; 	int i;  	/* 	 * Lock and unlock the per-queue mutex so we known the stop 	 * state is visible. Doing only the active queues should be 	 * sufficient, but it does not cost much extra to do all the 	 * queues. Note we hold the core mutex here too. 	 */ 	for (i = 0; i< sc->vtnet_max_vq_pairs; i++) { 		rxq =&sc->vtnet_rxqs[i]; 		VTNET_RXQ_LOCK(rxq); 		VTNET_RXQ_UNLOCK(rxq);  		txq =&sc->vtnet_txqs[i]; 		VTNET_TXQ_LOCK(txq); 		VTNET_TXQ_UNLOCK(txq); 	} }  static void vtnet_stop(struct vtnet_softc *sc) { 	device_t dev; 	struct ifnet *ifp;  	dev = sc->vtnet_dev; 	ifp = sc->vtnet_ifp;  	VTNET_CORE_LOCK_ASSERT(sc);  	ifp->if_drv_flags&= ~IFF_DRV_RUNNING; 	sc->vtnet_link_active = 0; 	callout_stop(&sc->vtnet_tick_ch);  	/* Only advisory. */ 	vtnet_disable_interrupts(sc);  	/* 	 * Stop the host adapter. This resets it to the pre-initialized 	 * state. It will not generate any interrupts until after it is 	 * reinitialized. 	 */ 	virtio_stop(dev); 	vtnet_stop_rendezvous(sc);  	/* Free any mbufs left in the virtqueues. */ 	vtnet_drain_rxtx_queues(sc); }  static int vtnet_virtio_reinit(struct vtnet_softc *sc) { 	device_t dev; 	struct ifnet *ifp; 	uint64_t features; 	int mask, error;  	dev = sc->vtnet_dev; 	ifp = sc->vtnet_ifp; 	features = sc->vtnet_features;  	mask = 0; #if defined(INET) 	mask |= IFCAP_RXCSUM; #endif #if defined (INET6) 	mask |= IFCAP_RXCSUM_IPV6; #endif  	/* 	 * Re-negotiate with the host, removing any disabled receive 	 * features. Transmit features are disabled only on our side 	 * via if_capenable and if_hwassist. 	 */  	if (ifp->if_capabilities& mask) { 		/* 		 * We require both IPv4 and IPv6 offloading to be enabled 		 * in order to negotiated it: VirtIO does not distinguish 		 * between the two. 		 */ 		if ((ifp->if_capenable& mask) != mask) 			features&= ~VIRTIO_NET_F_GUEST_CSUM; 	}  	if (ifp->if_capabilities& IFCAP_LRO) { 		if ((ifp->if_capenable& IFCAP_LRO) == 0) 			features&= ~VTNET_LRO_FEATURES; 	}  	if (ifp->if_capabilities& IFCAP_VLAN_HWFILTER) { 		if ((ifp->if_capenable& IFCAP_VLAN_HWFILTER) == 0) 			features&= ~VIRTIO_NET_F_CTRL_VLAN; 	}  	error = virtio_reinit(dev, features); 	if (error) 		device_printf(dev, "virtio reinit error %d\n", error);  	return (error); }  static void vtnet_init_rx_filters(struct vtnet_softc *sc) { 	struct ifnet *ifp;  	ifp = sc->vtnet_ifp;  	if (sc->vtnet_flags& VTNET_FLAG_CTRL_RX) { 		/* Restore promiscuous and all-multicast modes. */ 		vtnet_rx_filter(sc); 		/* Restore filtered MAC addresses. */ 		vtnet_rx_filter_mac(sc); 	}  	if (ifp->if_capenable& IFCAP_VLAN_HWFILTER) 		vtnet_rx_filter_vlan(sc); }  static int vtnet_init_rx_queues(struct vtnet_softc *sc) { 	device_t dev; 	struct vtnet_rxq *rxq; 	int i, clsize, error;  	dev = sc->vtnet_dev;  	/* 	 * Use the new cluster size if one has been set (via a MTU 	 * change). Otherwise, use the standard 2K clusters. 	 * 	 * BMV: It might make sense to use page sized clusters as 	 * the default (depending on the features negotiated). 	 */ 	if (sc->vtnet_rx_new_clsize != 0) { 		clsize = sc->vtnet_rx_new_clsize; 		sc->vtnet_rx_new_clsize = 0; 	} else 		clsize = MCLBYTES;  	sc->vtnet_rx_clsize = clsize; 	sc->vtnet_rx_nmbufs = VTNET_NEEDED_RX_MBUFS(sc, clsize);  	/* The first segment is reserved for the header. */ 	KASSERT(sc->vtnet_rx_nmbufs< VTNET_MAX_RX_SEGS, 	    ("%s: too many rx mbufs %d", __func__, sc->vtnet_rx_nmbufs));  	for (i = 0; i< sc->vtnet_act_vq_pairs; i++) { 		rxq =&sc->vtnet_rxqs[i];  		/* Hold the lock to satisfy asserts. */ 		VTNET_RXQ_LOCK(rxq); 		error = vtnet_rxq_populate(rxq); 		VTNET_RXQ_UNLOCK(rxq);  		if (error) { 			device_printf(dev, 			    "cannot allocate mbufs for Rx queue %d\n", i); 			return (error); 		} 	}  	return (0); }  static int vtnet_init_tx_queues(struct vtnet_softc *sc) { 	struct vtnet_txq *txq; 	int i;  	for (i = 0; i< sc->vtnet_act_vq_pairs; i++) { 		txq =&sc->vtnet_txqs[i]; 		txq->vtntx_watchdog = 0; 	}  	return (0); }  static int vtnet_init_rxtx_queues(struct vtnet_softc *sc) { 	int error;  	error = vtnet_init_rx_queues(sc); 	if (error) 		return (error);  	error = vtnet_init_tx_queues(sc); 	if (error) 		return (error);  	return (0); }  static void vtnet_set_active_vq_pairs(struct vtnet_softc *sc) { 	device_t dev; 	int npairs;  	dev = sc->vtnet_dev;  	if ((sc->vtnet_flags& VTNET_FLAG_MULTIQ) == 0) { 		MPASS(sc->vtnet_max_vq_pairs == 1); 		sc->vtnet_act_vq_pairs = 1; 		return; 	}  	/* BMV: Just use the maximum configured for now. */ 	npairs = sc->vtnet_max_vq_pairs;  	if (vtnet_ctrl_mq_cmd(sc, npairs) != 0) { 		device_printf(dev, 		    "cannot set active queue pairs to %d\n", npairs); 		npairs = 1; 	}  	sc->vtnet_act_vq_pairs = npairs; }  static int vtnet_reinit(struct vtnet_softc *sc) { 	device_t dev; 	struct ifnet *ifp; 	int error;  	dev = sc->vtnet_dev; 	ifp = sc->vtnet_ifp;  	/* Use the current MAC address. */ 	bcopy(IF_LLADDR(ifp), sc->vtnet_hwaddr, ETHER_ADDR_LEN); 	vtnet_set_hwaddr(sc);  	vtnet_set_active_vq_pairs(sc);  	ifp->if_hwassist = 0; 	if (ifp->if_capenable& IFCAP_TXCSUM) 		ifp->if_hwassist |= VTNET_CSUM_OFFLOAD; 	if (ifp->if_capenable& IFCAP_TXCSUM_IPV6) 		ifp->if_hwassist |= VTNET_CSUM_OFFLOAD_IPV6; 	if (ifp->if_capenable& IFCAP_TSO4) 		ifp->if_hwassist |= CSUM_TSO; 	if (ifp->if_capenable& IFCAP_TSO6) 		ifp->if_hwassist |= CSUM_TSO; /* No CSUM_TSO_IPV6. */  	if (sc->vtnet_flags& VTNET_FLAG_CTRL_VQ) 		vtnet_init_rx_filters(sc);  	error = vtnet_init_rxtx_queues(sc); 	if (error) 		return (error);  	vtnet_enable_interrupts(sc); 	ifp->if_drv_flags |= IFF_DRV_RUNNING;  	return (0); }  static void vtnet_init_locked(struct vtnet_softc *sc) { 	device_t dev; 	struct ifnet *ifp;  	dev = sc->vtnet_dev; 	ifp = sc->vtnet_ifp;  	VTNET_CORE_LOCK_ASSERT(sc);  	if (ifp->if_drv_flags& IFF_DRV_RUNNING) 		return;  	vtnet_stop(sc);  	/* Reinitialize with the host. */ 	if (vtnet_virtio_reinit(sc) != 0) 		goto fail;  	if (vtnet_reinit(sc) != 0) 		goto fail;  	virtio_reinit_complete(dev);  	vtnet_update_link_status(sc); 	callout_reset(&sc->vtnet_tick_ch, hz, vtnet_tick, sc);  	return;  fail: 	vtnet_stop(sc); }  static void vtnet_init(void *xsc) { 	struct vtnet_softc *sc;  	sc = xsc;  	VTNET_CORE_LOCK(sc); 	vtnet_init_locked(sc); 	VTNET_CORE_UNLOCK(sc); }  static void vtnet_free_ctrl_vq(struct vtnet_softc *sc) { 	struct virtqueue *vq;  	vq = sc->vtnet_ctrl_vq;  	/* 	 * The control virtqueue is only polled and therefore it should 	 * already be empty. 	 */ 	KASSERT(virtqueue_empty(vq), 	    ("%s: ctrl vq %p not empty", __func__, vq)); }  static void vtnet_exec_ctrl_cmd(struct vtnet_softc *sc, void *cookie,     struct sglist *sg, int readable, int writable) { 	struct virtqueue *vq;  	vq = sc->vtnet_ctrl_vq;  	VTNET_CORE_LOCK_ASSERT(sc); 	KASSERT(sc->vtnet_flags& VTNET_FLAG_CTRL_VQ, 	    ("%s: CTRL_VQ feature not negotiated", __func__));  	if (!virtqueue_empty(vq)) 		return; 	if (virtqueue_enqueue(vq, cookie, sg, readable, writable) != 0) 		return;  	/* 	 * Poll for the response, but the command is likely already 	 * done when we return from the notify. 	 */ 	virtqueue_notify(vq); 	virtqueue_poll(vq, NULL); }  static int vtnet_ctrl_mac_cmd(struct vtnet_softc *sc, uint8_t *hwaddr) { 	struct virtio_net_ctrl_hdr hdr; 	struct sglist_seg segs[3]; 	struct sglist sg; 	uint8_t ack; 	int error;  	hdr.class = VIRTIO_NET_CTRL_MAC; 	hdr.cmd = VIRTIO_NET_CTRL_MAC_ADDR_SET; 	ack = VIRTIO_NET_ERR;  	sglist_init(&sg, 3, segs); 	error = 0; 	error |= sglist_append(&sg,&hdr, sizeof(struct virtio_net_ctrl_hdr)); 	error |= sglist_append(&sg, hwaddr, ETHER_ADDR_LEN); 	error |= sglist_append(&sg,&ack, sizeof(uint8_t)); 	KASSERT(error == 0&& sg.sg_nseg == 3, 	    ("%s: error %d adding set MAC msg to sglist", __func__, error));  	vtnet_exec_ctrl_cmd(sc,&ack,&sg, sg.sg_nseg - 1, 1);  	return (ack == VIRTIO_NET_OK ? 0 : EIO); }  static int vtnet_ctrl_mq_cmd(struct vtnet_softc *sc, uint16_t npairs) { 	struct sglist_seg segs[3]; 	struct sglist sg; 	struct { 		struct virtio_net_ctrl_hdr hdr; 		uint8_t pad1; 		struct virtio_net_ctrl_mq mq; 		uint8_t pad2; 		uint8_t ack; 	} s; 	int error;  	s.hdr.class = VIRTIO_NET_CTRL_MQ; 	s.hdr.cmd = VIRTIO_NET_CTRL_MQ_VQ_PAIRS_SET; 	s.mq.virtqueue_pairs = npairs; 	s.ack = VIRTIO_NET_ERR;  	sglist_init(&sg, 3, segs); 	error = 0; 	error |= sglist_append(&sg,&s.hdr, sizeof(struct virtio_net_ctrl_hdr)); 	error |= sglist_append(&sg,&s.mq, sizeof(struct virtio_net_ctrl_mq)); 	error |= sglist_append(&sg,&s.ack, sizeof(uint8_t)); 	KASSERT(error == 0&& sg.sg_nseg == 3, 	    ("%s: error %d adding MQ message to sglist", __func__, error));  	vtnet_exec_ctrl_cmd(sc,&s.ack,&sg, sg.sg_nseg - 1, 1);  	return (s.ack == VIRTIO_NET_OK ? 0 : EIO); }  static int vtnet_ctrl_rx_cmd(struct vtnet_softc *sc, int cmd, int on) { 	struct sglist_seg segs[3]; 	struct sglist sg; 	struct { 		struct virtio_net_ctrl_hdr hdr; 		uint8_t pad1; 		uint8_t onoff; 		uint8_t pad2; 		uint8_t ack; 	} s; 	int error;  	KASSERT(sc->vtnet_flags& VTNET_FLAG_CTRL_RX, 	    ("%s: CTRL_RX feature not negotiated", __func__));  	s.hdr.class = VIRTIO_NET_CTRL_RX; 	s.hdr.cmd = cmd; 	s.onoff = !!on; 	s.ack = VIRTIO_NET_ERR;  	sglist_init(&sg, 3, segs); 	error = 0; 	error |= sglist_append(&sg,&s.hdr, sizeof(struct virtio_net_ctrl_hdr)); 	error |= sglist_append(&sg,&s.onoff, sizeof(uint8_t)); 	error |= sglist_append(&sg,&s.ack, sizeof(uint8_t)); 	KASSERT(error == 0&& sg.sg_nseg == 3, 	    ("%s: error %d adding Rx message to sglist", __func__, error));  	vtnet_exec_ctrl_cmd(sc,&s.ack,&sg, sg.sg_nseg - 1, 1);  	return (s.ack == VIRTIO_NET_OK ? 0 : EIO); }  static int vtnet_set_promisc(struct vtnet_softc *sc, int on) {  	return (vtnet_ctrl_rx_cmd(sc, VIRTIO_NET_CTRL_RX_PROMISC, on)); }  static int vtnet_set_allmulti(struct vtnet_softc *sc, int on) {  	return (vtnet_ctrl_rx_cmd(sc, VIRTIO_NET_CTRL_RX_ALLMULTI, on)); }  /*  * The device defaults to promiscuous mode for backwards compatibility.  * Turn it off at attach time if possible.  */ static void vtnet_attach_disable_promisc(struct vtnet_softc *sc) { 	struct ifnet *ifp;  	ifp = sc->vtnet_ifp;  	VTNET_CORE_LOCK(sc); 	if ((sc->vtnet_flags& VTNET_FLAG_CTRL_RX) == 0) { 		ifp->if_flags |= IFF_PROMISC; 	} else if (vtnet_set_promisc(sc, 0) != 0) { 		ifp->if_flags |= IFF_PROMISC; 		device_printf(sc->vtnet_dev, 		    "cannot disable default promiscuous mode\n"); 	} 	VTNET_CORE_UNLOCK(sc); }  static void vtnet_rx_filter(struct vtnet_softc *sc) { 	device_t dev; 	struct ifnet *ifp;  	dev = sc->vtnet_dev; 	ifp = sc->vtnet_ifp;  	VTNET_CORE_LOCK_ASSERT(sc);  	if (vtnet_set_promisc(sc, ifp->if_flags& IFF_PROMISC) != 0) 		device_printf(dev, "cannot %s promiscuous mode\n", 		    ifp->if_flags& IFF_PROMISC ? "enable" : "disable");  	if (vtnet_set_allmulti(sc, ifp->if_flags& IFF_ALLMULTI) != 0) 		device_printf(dev, "cannot %s all-multicast mode\n", 		    ifp->if_flags& IFF_ALLMULTI ? "enable" : "disable"); }  static void vtnet_rx_filter_mac(struct vtnet_softc *sc) { 	struct virtio_net_ctrl_hdr hdr; 	struct vtnet_mac_filter *filter; 	struct sglist_seg segs[4]; 	struct sglist sg; 	struct ifnet *ifp; 	struct ifaddr *ifa; 	struct ifmultiaddr *ifma; 	int ucnt, mcnt, promisc, allmulti, error; 	uint8_t ack;  	ifp = sc->vtnet_ifp; 	filter = sc->vtnet_mac_filter; 	ucnt = 0; 	mcnt = 0; 	promisc = 0; 	allmulti = 0;  	VTNET_CORE_LOCK_ASSERT(sc); 	KASSERT(sc->vtnet_flags& VTNET_FLAG_CTRL_RX, 	    ("%s: CTRL_RX feature not negotiated", __func__));  	/* Unicast MAC addresses: */ 	if_addr_rlock(ifp); 	TAILQ_FOREACH(ifa,&ifp->if_addrhead, ifa_link) { 		if (ifa->ifa_addr->sa_family != AF_LINK) 			continue; 		else if (memcmp(LLADDR((struct sockaddr_dl *)ifa->ifa_addr), 		    sc->vtnet_hwaddr, ETHER_ADDR_LEN) == 0) 			continue; 		else if (ucnt == VTNET_MAX_MAC_ENTRIES) { 			promisc = 1; 			break; 		}  		bcopy(LLADDR((struct sockaddr_dl *)ifa->ifa_addr),&filter->vmf_unicast.macs[ucnt], ETHER_ADDR_LEN); 		ucnt++; 	} 	if_addr_runlock(ifp);  	if (promisc != 0) { 		filter->vmf_unicast.nentries = 0; 		if_printf(ifp, "more than %d MAC addresses assigned, " 		    "falling back to promiscuous mode\n", 		    VTNET_MAX_MAC_ENTRIES); 	} else 		filter->vmf_unicast.nentries = ucnt;  	/* Multicast MAC addresses: */ 	if_maddr_rlock(ifp); 	TAILQ_FOREACH(ifma,&ifp->if_multiaddrs, ifma_link) { 		if (ifma->ifma_addr->sa_family != AF_LINK) 			continue; 		else if (mcnt == VTNET_MAX_MAC_ENTRIES) { 			allmulti = 1; 			break; 		}  		bcopy(LLADDR((struct sockaddr_dl *)ifma->ifma_addr),&filter->vmf_multicast.macs[mcnt], ETHER_ADDR_LEN); 		mcnt++; 	} 	if_maddr_runlock(ifp);  	if (allmulti != 0) { 		filter->vmf_multicast.nentries = 0; 		if_printf(ifp, "more than %d multicast MAC addresses " 		    "assigned, falling back to all-multicast mode\n", 		    VTNET_MAX_MAC_ENTRIES); 	} else 		filter->vmf_multicast.nentries = mcnt;  	if (promisc != 0&& allmulti != 0) 		goto out;  	hdr.class = VIRTIO_NET_CTRL_MAC; 	hdr.cmd = VIRTIO_NET_CTRL_MAC_TABLE_SET; 	ack = VIRTIO_NET_ERR;  	sglist_init(&sg, 4, segs); 	error = 0; 	error |= sglist_append(&sg,&hdr, sizeof(struct virtio_net_ctrl_hdr)); 	error |= sglist_append(&sg,&filter->vmf_unicast, 	    sizeof(uint32_t) + filter->vmf_unicast.nentries * ETHER_ADDR_LEN); 	error |= sglist_append(&sg,&filter->vmf_multicast, 	    sizeof(uint32_t) + filter->vmf_multicast.nentries * ETHER_ADDR_LEN); 	error |= sglist_append(&sg,&ack, sizeof(uint8_t)); 	KASSERT(error == 0&& sg.sg_nseg == 4, 	    ("%s: error %d adding MAC filter msg to sglist", __func__, error));  	vtnet_exec_ctrl_cmd(sc,&ack,&sg, sg.sg_nseg - 1, 1);  	if (ack != VIRTIO_NET_OK) 		if_printf(ifp, "error setting host MAC filter table\n");  out: 	if (promisc != 0&& vtnet_set_promisc(sc, 1) != 0) 		if_printf(ifp, "cannot enable promiscuous mode\n"); 	if (allmulti != 0&& vtnet_set_allmulti(sc, 1) != 0) 		if_printf(ifp, "cannot enable all-multicast mode\n"); }  static int vtnet_exec_vlan_filter(struct vtnet_softc *sc, int add, uint16_t tag) { 	struct sglist_seg segs[3]; 	struct sglist sg; 	struct { 		struct virtio_net_ctrl_hdr hdr; 		uint8_t pad1; 		uint16_t tag; 		uint8_t pad2; 		uint8_t ack; 	} s; 	int error;  	s.hdr.class = VIRTIO_NET_CTRL_VLAN; 	s.hdr.cmd = add ? VIRTIO_NET_CTRL_VLAN_ADD : VIRTIO_NET_CTRL_VLAN_DEL; 	s.tag = tag; 	s.ack = VIRTIO_NET_ERR;  	sglist_init(&sg, 3, segs); 	error = 0; 	error |= sglist_append(&sg,&s.hdr, sizeof(struct virtio_net_ctrl_hdr)); 	error |= sglist_append(&sg,&s.tag, sizeof(uint16_t)); 	error |= sglist_append(&sg,&s.ack, sizeof(uint8_t)); 	KASSERT(error == 0&& sg.sg_nseg == 3, 	    ("%s: error %d adding VLAN message to sglist", __func__, error));  	vtnet_exec_ctrl_cmd(sc,&s.ack,&sg, sg.sg_nseg - 1, 1);  	return (s.ack == VIRTIO_NET_OK ? 0 : EIO); }  static void vtnet_rx_filter_vlan(struct vtnet_softc *sc) { 	uint32_t w; 	uint16_t tag; 	int i, bit;  	VTNET_CORE_LOCK_ASSERT(sc); 	KASSERT(sc->vtnet_flags& VTNET_FLAG_VLAN_FILTER, 	    ("%s: VLAN_FILTER feature not negotiated", __func__));  	/* Enable the filter for each configured VLAN. */ 	for (i = 0; i< VTNET_VLAN_FILTER_NWORDS; i++) { 		w = sc->vtnet_vlan_filter[i];  		while ((bit = ffs(w) - 1) != -1) { 			w&= ~(1<< bit); 			tag = sizeof(w) * CHAR_BIT * i + bit;  			if (vtnet_exec_vlan_filter(sc, 1, tag) != 0) { 				device_printf(sc->vtnet_dev, 				    "cannot enable VLAN %d filter\n", tag); 			} 		} 	} }  static void vtnet_update_vlan_filter(struct vtnet_softc *sc, int add, uint16_t tag) { 	struct ifnet *ifp; 	int idx, bit;  	ifp = sc->vtnet_ifp; 	idx = (tag>> 5)& 0x7F; 	bit = tag& 0x1F;  	if (tag == 0 || tag> 4095) 		return;  	VTNET_CORE_LOCK(sc);  	if (add) 		sc->vtnet_vlan_filter[idx] |= (1<< bit); 	else 		sc->vtnet_vlan_filter[idx]&= ~(1<< bit);  	if (ifp->if_capenable& IFCAP_VLAN_HWFILTER&& 	    vtnet_exec_vlan_filter(sc, add, tag) != 0) { 		device_printf(sc->vtnet_dev, 		    "cannot %s VLAN %d %s the host filter table\n", 		    add ? "add" : "remove", tag, add ? "to" : "from"); 	}  	VTNET_CORE_UNLOCK(sc); }  static void vtnet_register_vlan(void *arg, struct ifnet *ifp, uint16_t tag) {  	if (ifp->if_softc != arg) 		return;  	vtnet_update_vlan_filter(arg, 1, tag); }  static void vtnet_unregister_vlan(void *arg, struct ifnet *ifp, uint16_t tag) {  	if (ifp->if_softc != arg) 		return;  	vtnet_update_vlan_filter(arg, 0, tag); }  static int vtnet_is_link_up(struct vtnet_softc *sc) { 	device_t dev; 	struct ifnet *ifp; 	uint16_t status;  	dev = sc->vtnet_dev; 	ifp = sc->vtnet_ifp;  	if ((ifp->if_capabilities& IFCAP_LINKSTATE) == 0) 		status = VIRTIO_NET_S_LINK_UP; 	else 		status = virtio_read_dev_config_2(dev, 		    offsetof(struct virtio_net_config, status));  	return ((status& VIRTIO_NET_S_LINK_UP) != 0); }  static void vtnet_update_link_status(struct vtnet_softc *sc) { 	struct ifnet *ifp; 	int link;  	ifp = sc->vtnet_ifp;  	VTNET_CORE_LOCK_ASSERT(sc); 	link = vtnet_is_link_up(sc);  	/* Notify if the link status has changed. */ 	if (link != 0&& sc->vtnet_link_active == 0) { 		sc->vtnet_link_active = 1; 		if_link_state_change(ifp, LINK_STATE_UP); 	} else if (link == 0&& sc->vtnet_link_active != 0) { 		sc->vtnet_link_active = 0; 		if_link_state_change(ifp, LINK_STATE_DOWN); 	} }  static int vtnet_ifmedia_upd(struct ifnet *ifp) { 	struct vtnet_softc *sc; 	struct ifmedia *ifm;  	sc = ifp->if_softc; 	ifm =&sc->vtnet_media;  	if (IFM_TYPE(ifm->ifm_media) != IFM_ETHER) 		return (EINVAL);  	return (0); }  static void vtnet_ifmedia_sts(struct ifnet *ifp, struct ifmediareq *ifmr) { 	struct vtnet_softc *sc;  	sc = ifp->if_softc;  	ifmr->ifm_status = IFM_AVALID; 	ifmr->ifm_active = IFM_ETHER;  	VTNET_CORE_LOCK(sc); 	if (vtnet_is_link_up(sc) != 0) { 		ifmr->ifm_status |= IFM_ACTIVE; 		ifmr->ifm_active |= VTNET_MEDIATYPE; 	} else 		ifmr->ifm_active |= IFM_NONE; 	VTNET_CORE_UNLOCK(sc); }  static void vtnet_set_hwaddr(struct vtnet_softc *sc) { 	device_t dev;  	dev = sc->vtnet_dev;  	if (sc->vtnet_flags& VTNET_FLAG_CTRL_MAC) { 		if (vtnet_ctrl_mac_cmd(sc, sc->vtnet_hwaddr) != 0) 			device_printf(dev, "unable to set MAC address\n"); 	} else if (sc->vtnet_flags& VTNET_FLAG_MAC) { 		virtio_write_device_config(dev, 		    offsetof(struct virtio_net_config, mac), 		    sc->vtnet_hwaddr, ETHER_ADDR_LEN); 	} }  static void vtnet_get_hwaddr(struct vtnet_softc *sc) { 	device_t dev;  	dev = sc->vtnet_dev;  	if ((sc->vtnet_flags& VTNET_FLAG_MAC) == 0) { 		/* 		 * Generate a random locally administered unicast address. 		 * 		 * It would be nice to generate the same MAC address across 		 * reboots, but it seems all the hosts currently available 		 * support the MAC feature, so this isn't too important. 		 */ 		sc->vtnet_hwaddr[0] = 0xB2; 		arc4rand(&sc->vtnet_hwaddr[1], ETHER_ADDR_LEN - 1, 0); 		vtnet_set_hwaddr(sc); 		return; 	}  	virtio_read_device_config(dev, offsetof(struct virtio_net_config, mac), 	    sc->vtnet_hwaddr, ETHER_ADDR_LEN); }  static void vtnet_vlan_tag_remove(struct mbuf *m) { 	struct ether_vlan_header *evh;  	evh = mtod(m, struct ether_vlan_header *); 	m->m_pkthdr.ether_vtag = ntohs(evh->evl_tag); 	m->m_flags |= M_VLANTAG;  	/* Strip the 802.1Q header. */ 	bcopy((char *) evh, (char *) evh + ETHER_VLAN_ENCAP_LEN, 	    ETHER_HDR_LEN - ETHER_TYPE_LEN); 	m_adj(m, ETHER_VLAN_ENCAP_LEN); }  static void vtnet_setup_rxq_sysctl(struct sysctl_ctx_list *ctx,     struct sysctl_oid_list *child, struct vtnet_rxq *rxq) { 	struct sysctl_oid *node; 	struct sysctl_oid_list *list; 	struct vtnet_rxq_stats *stats; 	char namebuf[16];  	snprintf(namebuf, sizeof(namebuf), "rxq%d", rxq->vtnrx_id); 	node = SYSCTL_ADD_NODE(ctx, child, OID_AUTO, namebuf, 	    CTLFLAG_RD, NULL, "Receive Queue"); 	list = SYSCTL_CHILDREN(node);  	stats =&rxq->vtnrx_stats;  	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "ipackets", CTLFLAG_RD,&stats->vrxs_ipackets, "Receive packets"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "ibytes", CTLFLAG_RD,&stats->vrxs_ibytes, "Receive bytes"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "iqdrops", CTLFLAG_RD,&stats->vrxs_iqdrops, "Receive drops"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "ierrors", CTLFLAG_RD,&stats->vrxs_ierrors, "Receive errors"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "csum", CTLFLAG_RD,&stats->vrxs_csum, "Receive checksum offloaded"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "csum_failed", CTLFLAG_RD,&stats->vrxs_csum_failed, "Receive checksum offload failed"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "rescheduled", CTLFLAG_RD,&stats->vrxs_rescheduled, 	    "Receive interrupt handler rescheduled"); }  static void vtnet_setup_txq_sysctl(struct sysctl_ctx_list *ctx,     struct sysctl_oid_list *child, struct vtnet_txq *txq) { 	struct sysctl_oid *node; 	struct sysctl_oid_list *list; 	struct vtnet_txq_stats *stats; 	char namebuf[16];  	snprintf(namebuf, sizeof(namebuf), "txq%d", txq->vtntx_id); 	node = SYSCTL_ADD_NODE(ctx, child, OID_AUTO, namebuf, 	    CTLFLAG_RD, NULL, "Transmit Queue"); 	list = SYSCTL_CHILDREN(node);  	stats =&txq->vtntx_stats;  	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "opackets", CTLFLAG_RD,&stats->vtxs_opackets, "Transmit packets"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "obytes", CTLFLAG_RD,&stats->vtxs_obytes, "Transmit bytes"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "omcasts", CTLFLAG_RD,&stats->vtxs_omcasts, "Transmit multicasts"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "csum", CTLFLAG_RD,&stats->vtxs_csum, "Transmit checksum offloaded"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "tso", CTLFLAG_RD,&stats->vtxs_tso, "Transmit segmentation offloaded"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "collapsed", CTLFLAG_RD,&stats->vtxs_collapsed, "Transmit mbufs collapsed"); 	SYSCTL_ADD_UQUAD(ctx, list, OID_AUTO, "rescheduled", CTLFLAG_RD,&stats->vtxs_rescheduled, 	    "Transmit interrupt handler rescheduled"); }  static void vtnet_setup_queue_sysctl(struct vtnet_softc *sc) { 	device_t dev; 	struct sysctl_ctx_list *ctx; 	struct sysctl_oid *tree; 	struct sysctl_oid_list *child; 	int i;  	dev = sc->vtnet_dev; 	ctx = device_get_sysctl_ctx(dev); 	tree = device_get_sysctl_tree(dev); 	child = SYSCTL_CHILDREN(tree);  	for (i = 0; i< sc->vtnet_max_vq_pairs; i++) { 		vtnet_setup_rxq_sysctl(ctx, child,&sc->vtnet_rxqs[i]); 		vtnet_setup_txq_sysctl(ctx, child,&sc->vtnet_txqs[i]); 	} }  static void vtnet_setup_stat_sysctl(struct sysctl_ctx_list *ctx,     struct sysctl_oid_list *child, struct vtnet_softc *sc) { 	struct vtnet_statistics *stats;  	stats =&sc->vtnet_stats;  	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "mbuf_alloc_failed", 	    CTLFLAG_RD,&stats->mbuf_alloc_failed, 	    "Mbuf cluster allocation failures");  	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "rx_frame_too_large", 	    CTLFLAG_RD,&stats->rx_frame_too_large, 	    "Received frame larger than the mbuf chain"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "rx_enq_replacement_failed", 	    CTLFLAG_RD,&stats->rx_enq_replacement_failed, 	    "Enqueuing the replacement receive mbuf failed"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "rx_mergeable_failed", 	    CTLFLAG_RD,&stats->rx_mergeable_failed, 	    "Mergeable buffers receive failures"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "rx_csum_bad_ethtype", 	    CTLFLAG_RD,&stats->rx_csum_bad_ethtype, 	    "Received checksum offloaded buffer with unsupported " 	    "Ethernet type"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "rx_csum_bad_ipproto", 	    CTLFLAG_RD,&stats->rx_csum_bad_ipproto, 	    "Received checksum offloaded buffer with incorrect IP protocol"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "rx_csum_bad_offset", 	    CTLFLAG_RD,&stats->rx_csum_bad_offset, 	    "Received checksum offloaded buffer with incorrect offset"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "rx_csum_bad_proto", 	    CTLFLAG_RD,&stats->rx_csum_bad_proto, 	    "Received checksum offloaded buffer with incorrect protocol"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "rx_csum_failed", 	    CTLFLAG_RD,&stats->rx_csum_failed, 	    "Received buffer checksum offload failed"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "rx_csum_offloaded", 	    CTLFLAG_RD,&stats->rx_csum_offloaded, 	    "Received buffer checksum offload succeeded"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "rx_task_rescheduled", 	    CTLFLAG_RD,&stats->rx_task_rescheduled, 	    "Times the receive interrupt task rescheduled itself");  	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "tx_csum_bad_ethtype", 	    CTLFLAG_RD,&stats->tx_csum_bad_ethtype, 	    "Aborted transmit of checksum offloaded buffer with unknown " 	    "Ethernet type"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "tx_tso_bad_ethtype", 	    CTLFLAG_RD,&stats->tx_tso_bad_ethtype, 	    "Aborted transmit of TSO buffer with unknown Ethernet type"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "tx_tso_not_tcp", 	    CTLFLAG_RD,&stats->tx_tso_not_tcp, 	    "Aborted transmit of TSO buffer with non TCP protocol"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "tx_csum_offloaded", 	    CTLFLAG_RD,&stats->tx_csum_offloaded, 	    "Offloaded checksum of transmitted buffer"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "tx_tso_offloaded", 	    CTLFLAG_RD,&stats->tx_tso_offloaded, 	    "Segmentation offload of transmitted buffer"); 	SYSCTL_ADD_UQUAD(ctx, child, OID_AUTO, "tx_task_rescheduled", 	    CTLFLAG_RD,&stats->tx_task_rescheduled, 	    "Times the transmit interrupt task rescheduled itself"); }  static void vtnet_setup_sysctl(struct vtnet_softc *sc) { 	device_t dev; 	struct sysctl_ctx_list *ctx; 	struct sysctl_oid *tree; 	struct sysctl_oid_list *child;  	dev = sc->vtnet_dev; 	ctx = device_get_sysctl_ctx(dev); 	tree = device_get_sysctl_tree(dev); 	child = SYSCTL_CHILDREN(tree);  	SYSCTL_ADD_INT(ctx, child, OID_AUTO, "max_vq_pairs", 	    CTLFLAG_RD,&sc->vtnet_max_vq_pairs, 0, 	    "Maximum number of supported virtqueue pairs"); 	SYSCTL_ADD_INT(ctx, child, OID_AUTO, "act_vq_pairs", 	    CTLFLAG_RD,&sc->vtnet_act_vq_pairs, 0, 	    "Number of active virtqueue pairs");  	vtnet_setup_stat_sysctl(ctx, child, sc); }  static int vtnet_rxq_enable_intr(struct vtnet_rxq *rxq) {  	return (virtqueue_enable_intr(rxq->vtnrx_vq)); }  static void vtnet_rxq_disable_intr(struct vtnet_rxq *rxq) {  	virtqueue_disable_intr(rxq->vtnrx_vq); }  static int vtnet_txq_enable_intr(struct vtnet_txq *txq) {  	return (virtqueue_postpone_intr(txq->vtntx_vq, VQ_POSTPONE_LONG)); }  static void vtnet_txq_disable_intr(struct vtnet_txq *txq) {  	virtqueue_disable_intr(txq->vtntx_vq); }  static void vtnet_enable_rx_interrupts(struct vtnet_softc *sc) { 	int i;  	for (i = 0; i< sc->vtnet_act_vq_pairs; i++) 		vtnet_rxq_enable_intr(&sc->vtnet_rxqs[i]); }  static void vtnet_enable_tx_interrupts(struct vtnet_softc *sc) { 	int i;  	for (i = 0; i< sc->vtnet_act_vq_pairs; i++) 		vtnet_txq_enable_intr(&sc->vtnet_txqs[i]); }  static void vtnet_enable_interrupts(struct vtnet_softc *sc) {  	vtnet_enable_rx_interrupts(sc); 	vtnet_enable_tx_interrupts(sc); }  static void vtnet_disable_rx_interrupts(struct vtnet_softc *sc) { 	int i;  	for (i = 0; i< sc->vtnet_act_vq_pairs; i++) 		vtnet_rxq_disable_intr(&sc->vtnet_rxqs[i]); }  static void vtnet_disable_tx_interrupts(struct vtnet_softc *sc) { 	int i;  	for (i = 0; i< sc->vtnet_act_vq_pairs; i++) 		vtnet_txq_disable_intr(&sc->vtnet_txqs[i]); }  static void vtnet_disable_interrupts(struct vtnet_softc *sc) {  	vtnet_disable_rx_interrupts(sc); 	vtnet_disable_tx_interrupts(sc); }  static int vtnet_tunable_int(struct vtnet_softc *sc, const char *knob, int def) { 	char path[64];  	snprintf(path, sizeof(path), 	    "hw.vtnet.%d.%s", device_get_unit(sc->vtnet_dev), knob); 	TUNABLE_INT_FETCH(path,&def);  	return (def); }
end_unit

