begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*-  * Copyright (c) 1991 Regents of the University of California.  * All rights reserved.  * Copyright (c) 1994 John S. Dyson  * All rights reserved.  * Copyright (c) 1994 David Greenman  * All rights reserved.  * Copyright (c) 2005-2010 Alan L. Cox<alc@cs.rice.edu>  * All rights reserved.  *  * This code is derived from software contributed to Berkeley by  * the Systems Programming Group of the University of Utah Computer  * Science Department and William Jolitz of UUNET Technologies Inc.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  * 3. All advertising materials mentioning features or use of this software  *    must display the following acknowledgement:  *	This product includes software developed by the University of  *	California, Berkeley and its contributors.  * 4. Neither the name of the University nor the names of its contributors  *    may be used to endorse or promote products derived from this software  *    without specific prior written permission.  *  * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  *	from:	@(#)pmap.c	7.7 (Berkeley)	5/12/91  */
end_comment

begin_comment
comment|/*-  * Copyright (c) 2003 Networks Associates Technology, Inc.  * All rights reserved.  *  * This software was developed for the FreeBSD Project by Jake Burkholder,  * Safeport Network Services, and Network Associates Laboratories, the  * Security Research Division of Network Associates, Inc. under  * DARPA/SPAWAR contract N66001-01-C-8035 ("CBOSS"), as part of the DARPA  * CHATS research program.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  */
end_comment

begin_include
include|#
directive|include
file|<sys/cdefs.h>
end_include

begin_expr_stmt
name|__FBSDID
argument_list|(
literal|"$FreeBSD$"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *	Manages physical address maps.  *  *	Since the information managed by this module is  *	also stored by the logical address mapping module,  *	this module may throw away valid virtual-to-physical  *	mappings at almost any time.  However, invalidations  *	of virtual-to-physical mappings must be done as  *	requested.  *  *	In order to cope with hardware architectures which  *	make virtual-to-physical map invalidates expensive,  *	this module may delay invalidate or reduced protection  *	operations until such time as they are actually  *	necessary.  This module is given full information as  *	to which processors are currently using which maps,  *	and to when physical maps must be made correct.  */
end_comment

begin_include
include|#
directive|include
file|"opt_apic.h"
end_include

begin_include
include|#
directive|include
file|"opt_cpu.h"
end_include

begin_include
include|#
directive|include
file|"opt_pmap.h"
end_include

begin_include
include|#
directive|include
file|"opt_smp.h"
end_include

begin_include
include|#
directive|include
file|"opt_xbox.h"
end_include

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/kernel.h>
end_include

begin_include
include|#
directive|include
file|<sys/ktr.h>
end_include

begin_include
include|#
directive|include
file|<sys/lock.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<sys/mman.h>
end_include

begin_include
include|#
directive|include
file|<sys/msgbuf.h>
end_include

begin_include
include|#
directive|include
file|<sys/mutex.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/rwlock.h>
end_include

begin_include
include|#
directive|include
file|<sys/sf_buf.h>
end_include

begin_include
include|#
directive|include
file|<sys/sx.h>
end_include

begin_include
include|#
directive|include
file|<sys/vmmeter.h>
end_include

begin_include
include|#
directive|include
file|<sys/sched.h>
end_include

begin_include
include|#
directive|include
file|<sys/sysctl.h>
end_include

begin_include
include|#
directive|include
file|<sys/smp.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_param.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_map.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_object.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_extern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pageout.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_pager.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_phys.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_radix.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_reserv.h>
end_include

begin_include
include|#
directive|include
file|<vm/uma.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DEV_APIC
end_ifdef

begin_include
include|#
directive|include
file|<sys/bus.h>
end_include

begin_include
include|#
directive|include
file|<machine/intr_machdep.h>
end_include

begin_include
include|#
directive|include
file|<x86/apicvar.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/cputypes.h>
end_include

begin_include
include|#
directive|include
file|<machine/md_var.h>
end_include

begin_include
include|#
directive|include
file|<machine/pcb.h>
end_include

begin_include
include|#
directive|include
file|<machine/specialreg.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_include
include|#
directive|include
file|<machine/smp.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|XBOX
end_ifdef

begin_include
include|#
directive|include
file|<machine/xbox.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_ifndef
ifndef|#
directive|ifndef
name|PMAP_SHPGPERPROC
end_ifndef

begin_define
define|#
directive|define
name|PMAP_SHPGPERPROC
value|200
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_if
if|#
directive|if
operator|!
name|defined
argument_list|(
name|DIAGNOSTIC
argument_list|)
end_if

begin_ifdef
ifdef|#
directive|ifdef
name|__GNUC_GNU_INLINE__
end_ifdef

begin_define
define|#
directive|define
name|PMAP_INLINE
value|__attribute__((__gnu_inline__)) inline
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PMAP_INLINE
value|extern inline
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PMAP_INLINE
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifdef
ifdef|#
directive|ifdef
name|PV_STATS
end_ifdef

begin_define
define|#
directive|define
name|PV_STAT
parameter_list|(
name|x
parameter_list|)
value|do { x ; } while (0)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|PV_STAT
parameter_list|(
name|x
parameter_list|)
value|do { } while (0)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|pa_index
parameter_list|(
name|pa
parameter_list|)
value|((pa)>> PDRSHIFT)
end_define

begin_define
define|#
directive|define
name|pa_to_pvh
parameter_list|(
name|pa
parameter_list|)
value|(&pv_table[pa_index(pa)])
end_define

begin_comment
comment|/*  * Get PDEs and PTEs for user/kernel address space  */
end_comment

begin_define
define|#
directive|define
name|pmap_pde
parameter_list|(
name|m
parameter_list|,
name|v
parameter_list|)
value|(&((m)->pm_pdir[(vm_offset_t)(v)>> PDRSHIFT]))
end_define

begin_define
define|#
directive|define
name|pdir_pde
parameter_list|(
name|m
parameter_list|,
name|v
parameter_list|)
value|(m[(vm_offset_t)(v)>> PDRSHIFT])
end_define

begin_define
define|#
directive|define
name|pmap_pde_v
parameter_list|(
name|pte
parameter_list|)
value|((*(int *)pte& PG_V) != 0)
end_define

begin_define
define|#
directive|define
name|pmap_pte_w
parameter_list|(
name|pte
parameter_list|)
value|((*(int *)pte& PG_W) != 0)
end_define

begin_define
define|#
directive|define
name|pmap_pte_m
parameter_list|(
name|pte
parameter_list|)
value|((*(int *)pte& PG_M) != 0)
end_define

begin_define
define|#
directive|define
name|pmap_pte_u
parameter_list|(
name|pte
parameter_list|)
value|((*(int *)pte& PG_A) != 0)
end_define

begin_define
define|#
directive|define
name|pmap_pte_v
parameter_list|(
name|pte
parameter_list|)
value|((*(int *)pte& PG_V) != 0)
end_define

begin_define
define|#
directive|define
name|pmap_pte_set_w
parameter_list|(
name|pte
parameter_list|,
name|v
parameter_list|)
value|((v) ? atomic_set_int((u_int *)(pte), PG_W) : \     atomic_clear_int((u_int *)(pte), PG_W))
end_define

begin_define
define|#
directive|define
name|pmap_pte_set_prot
parameter_list|(
name|pte
parameter_list|,
name|v
parameter_list|)
value|((*(int *)pte&= ~PG_PROT), (*(int *)pte |= (v)))
end_define

begin_decl_stmt
name|struct
name|pmap
name|kernel_pmap_store
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|LIST_HEAD
argument_list|(
name|pmaplist
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|pmaplist
name|allpmaps
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|allpmaps_lock
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|virtual_avail
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* VA of first avail page (after kernel bss) */
end_comment

begin_decl_stmt
name|vm_offset_t
name|virtual_end
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* VA of last avail page (end of kernel AS) */
end_comment

begin_decl_stmt
name|int
name|pgeflag
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* PG_G or-in */
end_comment

begin_decl_stmt
name|int
name|pseflag
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* PG_PS or-in */
end_comment

begin_decl_stmt
specifier|static
name|int
name|nkpt
init|=
name|NKPT
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|kernel_vm_end
init|=
name|KERNBASE
operator|+
name|NKPT
operator|*
name|NBPDR
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|u_int32_t
name|KERNend
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|extern
name|u_int32_t
name|KPTphys
decl_stmt|;
end_decl_stmt

begin_if
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
end_if

begin_decl_stmt
name|pt_entry_t
name|pg_nx
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|uma_zone_t
name|pdptzone
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_expr_stmt
specifier|static
name|SYSCTL_NODE
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|pmap
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|"VM/pmap parameters"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pat_works
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pat_works
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pat_works
argument_list|,
literal|1
argument_list|,
literal|"Is page attribute table fully functional?"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pg_ps_enabled
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pg_ps_enabled
argument_list|,
name|CTLFLAG_RDTUN
operator||
name|CTLFLAG_NOFETCH
argument_list|,
operator|&
name|pg_ps_enabled
argument_list|,
literal|0
argument_list|,
literal|"Are large page mappings enabled?"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_define
define|#
directive|define
name|PAT_INDEX_SIZE
value|8
end_define

begin_decl_stmt
specifier|static
name|int
name|pat_index
index|[
name|PAT_INDEX_SIZE
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* cache mode to PAT index conversion */
end_comment

begin_comment
comment|/*  * pmap_mapdev support pre initialization (i.e. console)  */
end_comment

begin_define
define|#
directive|define
name|PMAP_PREINIT_MAPPING_COUNT
value|8
end_define

begin_struct
specifier|static
struct|struct
name|pmap_preinit_mapping
block|{
name|vm_paddr_t
name|pa
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_size_t
name|sz
decl_stmt|;
name|int
name|mode
decl_stmt|;
block|}
name|pmap_preinit_mapping
index|[
name|PMAP_PREINIT_MAPPING_COUNT
index|]
struct|;
end_struct

begin_decl_stmt
specifier|static
name|int
name|pmap_initialized
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|rwlock_padalign
name|pvh_global_lock
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Data for the pv entry allocation mechanism  */
end_comment

begin_expr_stmt
specifier|static
name|TAILQ_HEAD
argument_list|(
argument|pch
argument_list|,
argument|pv_chunk
argument_list|)
name|pv_chunks
operator|=
name|TAILQ_HEAD_INITIALIZER
argument_list|(
name|pv_chunks
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|pv_entry_count
init|=
literal|0
decl_stmt|,
name|pv_entry_max
init|=
literal|0
decl_stmt|,
name|pv_entry_high_water
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|struct
name|md_page
modifier|*
name|pv_table
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|shpgperproc
init|=
name|PMAP_SHPGPERPROC
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|pv_chunk
modifier|*
name|pv_chunkbase
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* KVA block for pv_chunks */
end_comment

begin_decl_stmt
name|int
name|pv_maxchunks
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* How many chunks we have KVA for */
end_comment

begin_decl_stmt
name|vm_offset_t
name|pv_vafree
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* freelist stored in the PTE */
end_comment

begin_comment
comment|/*  * All those kernel PT submaps that BSD is so fond of  */
end_comment

begin_decl_stmt
name|pt_entry_t
modifier|*
name|CMAP3
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|pd_entry_t
modifier|*
name|KPTD
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|caddr_t
name|ptvmmap
init|=
literal|0
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|caddr_t
name|CADDR3
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|msgbuf
modifier|*
name|msgbufp
init|=
name|NULL
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Crashdump maps.  */
end_comment

begin_decl_stmt
specifier|static
name|caddr_t
name|crashdumpmap
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|pt_entry_t
modifier|*
name|PMAP1
init|=
name|NULL
decl_stmt|,
modifier|*
name|PMAP2
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|pt_entry_t
modifier|*
name|PADDR1
init|=
name|NULL
decl_stmt|,
modifier|*
name|PADDR2
decl_stmt|;
end_decl_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_decl_stmt
specifier|static
name|int
name|PMAP1cpu
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|PMAP1changedcpu
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_debug
argument_list|,
name|OID_AUTO
argument_list|,
name|PMAP1changedcpu
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|PMAP1changedcpu
argument_list|,
literal|0
argument_list|,
literal|"Number of times pmap_pte_quick changed CPU with same PMAP1"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|static
name|int
name|PMAP1changed
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_debug
argument_list|,
name|OID_AUTO
argument_list|,
name|PMAP1changed
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|PMAP1changed
argument_list|,
literal|0
argument_list|,
literal|"Number of times pmap_pte_quick changed PMAP1"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|int
name|PMAP1unchanged
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_debug
argument_list|,
name|OID_AUTO
argument_list|,
name|PMAP1unchanged
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|PMAP1unchanged
argument_list|,
literal|0
argument_list|,
literal|"Number of times pmap_pte_quick didn't change PMAP1"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|struct
name|mtx
name|PMAP2mutex
decl_stmt|;
end_decl_stmt

begin_function_decl
specifier|static
name|void
name|free_pv_chunk
parameter_list|(
name|struct
name|pv_chunk
modifier|*
name|pc
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|free_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pv_entry_t
name|pv
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|pv_entry_t
name|get_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|boolean_t
name|try
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pv_demote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_pv_insert_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pv_promote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pvh_free
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|pv_entry_t
name|pmap_pvh_remove
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_pvh_wired_mappings
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|int
name|count
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_demote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_enter_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|pmap_enter_quick_locked
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|vm_page_t
name|mpte
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_flush_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_insert_pt_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|mpte
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_invalidate_pde_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|pde
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_fill_ptp
parameter_list|(
name|pt_entry_t
modifier|*
name|firstpte
parameter_list|,
name|pt_entry_t
name|newpte
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_is_modified_pvh
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_is_referenced_pvh
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_kenter_attr
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|int
name|mode
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_kenter_pde
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pde_attr
parameter_list|(
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|int
name|cache_bits
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_promote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_protect_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pte_attr
parameter_list|(
name|pt_entry_t
modifier|*
name|pte
parameter_list|,
name|int
name|cache_bits
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_remove_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pdq
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_remove_pte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt_entry_t
modifier|*
name|ptq
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|pmap_remove_pt_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_remove_page
parameter_list|(
name|struct
name|pmap
modifier|*
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_remove_entry
parameter_list|(
name|struct
name|pmap
modifier|*
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_insert_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|boolean_t
name|pmap_try_insert_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_update_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_update_pde_invalidate
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|pmap_allocpte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|u_int
name|flags
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|vm_page_t
name|_pmap_allocpte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|u_int
name|ptepindex
parameter_list|,
name|u_int
name|flags
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|_pmap_unwire_ptp
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|pt_entry_t
modifier|*
name|pmap_pte_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|void
name|pmap_pte_release
parameter_list|(
name|pt_entry_t
modifier|*
name|pte
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_unuse_pt
parameter_list|(
name|pmap_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|struct
name|spglist
modifier|*
parameter_list|)
function_decl|;
end_function_decl

begin_if
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
end_if

begin_function_decl
specifier|static
name|void
modifier|*
name|pmap_pdpt_allocf
parameter_list|(
name|uma_zone_t
name|zone
parameter_list|,
name|vm_size_t
name|bytes
parameter_list|,
name|uint8_t
modifier|*
name|flags
parameter_list|,
name|int
name|wait
parameter_list|)
function_decl|;
end_function_decl

begin_endif
endif|#
directive|endif
end_endif

begin_function_decl
specifier|static
name|void
name|pmap_set_pg
parameter_list|(
name|void
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|__inline
name|void
name|pagezero
parameter_list|(
name|void
modifier|*
name|page
parameter_list|)
function_decl|;
end_function_decl

begin_expr_stmt
name|CTASSERT
argument_list|(
literal|1
operator|<<
name|PDESHIFT
operator|==
sizeof|sizeof
argument_list|(
name|pd_entry_t
argument_list|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
literal|1
operator|<<
name|PTESHIFT
operator|==
sizeof|sizeof
argument_list|(
name|pt_entry_t
argument_list|)
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * If you get an error here, then you set KVA_PAGES wrong! See the  * description of KVA_PAGES in sys/i386/include/pmap.h. It must be  * multiple of 4 for a normal kernel, or a multiple of 8 for a PAE.  */
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
name|KERNBASE
operator|%
operator|(
literal|1
operator|<<
literal|24
operator|)
operator|==
literal|0
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  *	Bootstrap the system enough to run with virtual memory.  *  *	On the i386 this is called after mapping has already been enabled  *	and just syncs the pmap module with what has already been done.  *	[We can't call it easily with mapping off since the kernel is not  *	mapped with PA == VA, hence we would have to relocate every address  *	from the linked base (virtual) address "KERNBASE" to the actual  *	(physical) address starting relative to 0]  */
end_comment

begin_function
name|void
name|pmap_bootstrap
parameter_list|(
name|vm_paddr_t
name|firstaddr
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
modifier|*
name|unused
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * Add a physical memory segment (vm_phys_seg) corresponding to the 	 * preallocated kernel page table pages so that vm_page structures 	 * representing these pages will be created.  The vm_page structures 	 * are required for promotion of the corresponding kernel virtual 	 * addresses to superpage mappings. 	 */
name|vm_phys_add_seg
argument_list|(
name|KPTphys
argument_list|,
name|KPTphys
operator|+
name|ptoa
argument_list|(
name|nkpt
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the first available kernel virtual address.  However, 	 * using "firstaddr" may waste a few pages of the kernel virtual 	 * address space, because locore may not have mapped every physical 	 * page that it allocated.  Preferably, locore would provide a first 	 * unused virtual address in addition to "firstaddr". 	 */
name|virtual_avail
operator|=
operator|(
name|vm_offset_t
operator|)
name|KERNBASE
operator|+
name|firstaddr
expr_stmt|;
name|virtual_end
operator|=
name|VM_MAX_KERNEL_ADDRESS
expr_stmt|;
comment|/* 	 * Initialize the kernel pmap (which is statically allocated). 	 */
name|PMAP_LOCK_INIT
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
name|kernel_pmap
operator|->
name|pm_pdir
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
operator|(
name|KERNBASE
operator|+
operator|(
name|u_int
operator|)
name|IdlePTD
operator|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
name|kernel_pmap
operator|->
name|pm_pdpt
operator|=
operator|(
name|pdpt_entry_t
operator|*
operator|)
operator|(
name|KERNBASE
operator|+
operator|(
name|u_int
operator|)
name|IdlePDPT
operator|)
expr_stmt|;
endif|#
directive|endif
name|CPU_FILL
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
comment|/* don't allow deactivation */
name|TAILQ_INIT
argument_list|(
operator|&
name|kernel_pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize the global pv list lock. 	 */
name|rw_init
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
literal|"pmap pv global"
argument_list|)
expr_stmt|;
name|LIST_INIT
argument_list|(
operator|&
name|allpmaps
argument_list|)
expr_stmt|;
comment|/* 	 * Request a spin mutex so that changes to allpmaps cannot be 	 * preempted by smp_rendezvous_cpus().  Otherwise, 	 * pmap_update_pde_kernel() could access allpmaps while it is 	 * being changed. 	 */
name|mtx_init
argument_list|(
operator|&
name|allpmaps_lock
argument_list|,
literal|"allpmaps"
argument_list|,
name|NULL
argument_list|,
name|MTX_SPIN
argument_list|)
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|allpmaps
argument_list|,
name|kernel_pmap
argument_list|,
name|pm_list
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
comment|/* 	 * Reserve some special page table entries/VA space for temporary 	 * mapping of pages. 	 */
define|#
directive|define
name|SYSMAP
parameter_list|(
name|c
parameter_list|,
name|p
parameter_list|,
name|v
parameter_list|,
name|n
parameter_list|)
define|\
value|v = (c)va; va += ((n)*PAGE_SIZE); p = pte; pte += (n);
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * Initialize temporary map objects on the current CPU for use 	 * during early boot. 	 * CMAP1/CMAP2 are used for zeroing and copying pages. 	 * CMAP3 is used for the boot-time memory test. 	 */
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|mtx_init
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|,
literal|"SYSMAPS"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|SYSMAP
argument_list|(
argument|caddr_t
argument_list|,
argument|pc->pc_cmap_pte1
argument_list|,
argument|pc->pc_cmap_addr1
argument_list|,
literal|1
argument_list|)
name|SYSMAP
argument_list|(
argument|caddr_t
argument_list|,
argument|pc->pc_cmap_pte2
argument_list|,
argument|pc->pc_cmap_addr2
argument_list|,
literal|1
argument_list|)
name|SYSMAP
argument_list|(
argument|vm_offset_t
argument_list|,
argument|pte
argument_list|,
argument|pc->pc_qmap_addr
argument_list|,
literal|1
argument_list|)
name|SYSMAP
argument_list|(
name|caddr_t
argument_list|,
name|CMAP3
argument_list|,
name|CADDR3
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * Crashdump maps. 	 */
name|SYSMAP
argument_list|(
argument|caddr_t
argument_list|,
argument|unused
argument_list|,
argument|crashdumpmap
argument_list|,
argument|MAXDUMPPGS
argument_list|)
comment|/* 	 * ptvmmap is used for reading arbitrary physical pages via /dev/mem. 	 */
name|SYSMAP
argument_list|(
argument|caddr_t
argument_list|,
argument|unused
argument_list|,
argument|ptvmmap
argument_list|,
literal|1
argument_list|)
comment|/* 	 * msgbufp is used to map the system message buffer. 	 */
name|SYSMAP
argument_list|(
argument|struct msgbuf *
argument_list|,
argument|unused
argument_list|,
argument|msgbufp
argument_list|,
argument|atop(round_page(msgbufsize))
argument_list|)
comment|/* 	 * KPTmap is used by pmap_kextract(). 	 * 	 * KPTmap is first initialized by locore.  However, that initial 	 * KPTmap can only support NKPT page table pages.  Here, a larger 	 * KPTmap is created that can support KVA_PAGES page table pages. 	 */
name|SYSMAP
argument_list|(
argument|pt_entry_t *
argument_list|,
argument|KPTD
argument_list|,
argument|KPTmap
argument_list|,
argument|KVA_PAGES
argument_list|)
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NKPT
condition|;
name|i
operator|++
control|)
name|KPTD
index|[
name|i
index|]
operator|=
operator|(
name|KPTphys
operator|+
operator|(
name|i
operator|<<
name|PAGE_SHIFT
operator|)
operator|)
operator||
name|pgeflag
operator||
name|PG_RW
operator||
name|PG_V
expr_stmt|;
comment|/* 	 * Adjust the start of the KPTD and KPTmap so that the implementation 	 * of pmap_kextract() and pmap_growkernel() can be made simpler. 	 */
name|KPTD
operator|-=
name|KPTDI
expr_stmt|;
name|KPTmap
operator|-=
name|i386_btop
argument_list|(
name|KPTDI
operator|<<
name|PDRSHIFT
argument_list|)
expr_stmt|;
comment|/* 	 * PADDR1 and PADDR2 are used by pmap_pte_quick() and pmap_pte(), 	 * respectively. 	 */
name|SYSMAP
argument_list|(
argument|pt_entry_t *
argument_list|,
argument|PMAP1
argument_list|,
argument|PADDR1
argument_list|,
literal|1
argument_list|)
name|SYSMAP
argument_list|(
argument|pt_entry_t *
argument_list|,
argument|PMAP2
argument_list|,
argument|PADDR2
argument_list|,
literal|1
argument_list|)
name|mtx_init
argument_list|(
operator|&
name|PMAP2mutex
argument_list|,
literal|"PMAP2"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|virtual_avail
operator|=
name|va
expr_stmt|;
comment|/* 	 * Leave in place an identity mapping (virt == phys) for the low 1 MB 	 * physical memory region that is used by the ACPI wakeup code.  This 	 * mapping must not have PG_G set.  	 */
ifdef|#
directive|ifdef
name|XBOX
comment|/* FIXME: This is gross, but needed for the XBOX. Since we are in such 	 * an early stadium, we cannot yet neatly map video memory ... :-( 	 * Better fixes are very welcome! */
if|if
condition|(
operator|!
name|arch_i386_is_xbox
condition|)
endif|#
directive|endif
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|NKPT
condition|;
name|i
operator|++
control|)
name|PTD
index|[
name|i
index|]
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Initialize the PAT MSR if present. 	 * pmap_init_pat() clears and sets CR4_PGE, which, as a 	 * side-effect, invalidates stale PG_G TLB entries that might 	 * have been created in our pre-boot environment.  We assume 	 * that PAT support implies PGE and in reverse, PGE presence 	 * comes with PAT.  Both features were added for Pentium Pro. 	 */
name|pmap_init_pat
argument_list|()
expr_stmt|;
comment|/* Turn on PG_G on kernel page(s) */
name|pmap_set_pg
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_init_reserved_pages
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|vm_offset_t
name|pages
decl_stmt|;
name|int
name|i
decl_stmt|;
name|CPU_FOREACH
argument_list|(
argument|i
argument_list|)
block|{
name|pc
operator|=
name|pcpu_find
argument_list|(
name|i
argument_list|)
expr_stmt|;
comment|/* 		 * Skip if the mapping has already been initialized, 		 * i.e. this is the BSP. 		 */
if|if
condition|(
name|pc
operator|->
name|pc_cmap_addr1
operator|!=
literal|0
condition|)
continue|continue;
name|mtx_init
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|,
literal|"SYSMAPS"
argument_list|,
name|NULL
argument_list|,
name|MTX_DEF
argument_list|)
expr_stmt|;
name|pages
operator|=
name|kva_alloc
argument_list|(
name|PAGE_SIZE
operator|*
literal|3
argument_list|)
expr_stmt|;
if|if
condition|(
name|pages
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: unable to allocate KVA"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_cmap_pte1
operator|=
name|vtopte
argument_list|(
name|pages
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_cmap_pte2
operator|=
name|vtopte
argument_list|(
name|pages
operator|+
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_cmap_addr1
operator|=
operator|(
name|caddr_t
operator|)
name|pages
expr_stmt|;
name|pc
operator|->
name|pc_cmap_addr2
operator|=
call|(
name|caddr_t
call|)
argument_list|(
name|pages
operator|+
name|PAGE_SIZE
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_qmap_addr
operator|=
name|pages
operator|+
operator|(
name|PAGE_SIZE
operator|*
literal|2
operator|)
expr_stmt|;
block|}
block|}
end_function

begin_expr_stmt
name|SYSINIT
argument_list|(
name|rpages_init
argument_list|,
name|SI_SUB_CPU
argument_list|,
name|SI_ORDER_ANY
argument_list|,
name|pmap_init_reserved_pages
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Setup the PAT MSR.  */
end_comment

begin_function
name|void
name|pmap_init_pat
parameter_list|(
name|void
parameter_list|)
block|{
name|int
name|pat_table
index|[
name|PAT_INDEX_SIZE
index|]
decl_stmt|;
name|uint64_t
name|pat_msr
decl_stmt|;
name|u_long
name|cr0
decl_stmt|,
name|cr4
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* Set default PAT index table. */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PAT_INDEX_SIZE
condition|;
name|i
operator|++
control|)
name|pat_table
index|[
name|i
index|]
operator|=
operator|-
literal|1
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_BACK
index|]
operator|=
literal|0
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_THROUGH
index|]
operator|=
literal|1
expr_stmt|;
name|pat_table
index|[
name|PAT_UNCACHEABLE
index|]
operator|=
literal|3
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_COMBINING
index|]
operator|=
literal|3
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_PROTECTED
index|]
operator|=
literal|3
expr_stmt|;
name|pat_table
index|[
name|PAT_UNCACHED
index|]
operator|=
literal|3
expr_stmt|;
comment|/* 	 * Bail if this CPU doesn't implement PAT. 	 * We assume that PAT support implies PGE. 	 */
if|if
condition|(
operator|(
name|cpu_feature
operator|&
name|CPUID_PAT
operator|)
operator|==
literal|0
condition|)
block|{
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PAT_INDEX_SIZE
condition|;
name|i
operator|++
control|)
name|pat_index
index|[
name|i
index|]
operator|=
name|pat_table
index|[
name|i
index|]
expr_stmt|;
name|pat_works
operator|=
literal|0
expr_stmt|;
return|return;
block|}
comment|/* 	 * Due to some Intel errata, we can only safely use the lower 4 	 * PAT entries. 	 * 	 *   Intel Pentium III Processor Specification Update 	 * Errata E.27 (Upper Four PAT Entries Not Usable With Mode B 	 * or Mode C Paging) 	 * 	 *   Intel Pentium IV  Processor Specification Update 	 * Errata N46 (PAT Index MSB May Be Calculated Incorrectly) 	 */
if|if
condition|(
name|cpu_vendor_id
operator|==
name|CPU_VENDOR_INTEL
operator|&&
operator|!
operator|(
name|CPUID_TO_FAMILY
argument_list|(
name|cpu_id
argument_list|)
operator|==
literal|6
operator|&&
name|CPUID_TO_MODEL
argument_list|(
name|cpu_id
argument_list|)
operator|>=
literal|0xe
operator|)
condition|)
name|pat_works
operator|=
literal|0
expr_stmt|;
comment|/* Initialize default PAT entries. */
name|pat_msr
operator|=
name|PAT_VALUE
argument_list|(
literal|0
argument_list|,
name|PAT_WRITE_BACK
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|1
argument_list|,
name|PAT_WRITE_THROUGH
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|2
argument_list|,
name|PAT_UNCACHED
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|3
argument_list|,
name|PAT_UNCACHEABLE
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|4
argument_list|,
name|PAT_WRITE_BACK
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|5
argument_list|,
name|PAT_WRITE_THROUGH
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|6
argument_list|,
name|PAT_UNCACHED
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|7
argument_list|,
name|PAT_UNCACHEABLE
argument_list|)
expr_stmt|;
if|if
condition|(
name|pat_works
condition|)
block|{
comment|/* 		 * Leave the indices 0-3 at the default of WB, WT, UC-, and UC. 		 * Program 5 and 6 as WP and WC. 		 * Leave 4 and 7 as WB and UC. 		 */
name|pat_msr
operator|&=
operator|~
operator|(
name|PAT_MASK
argument_list|(
literal|5
argument_list|)
operator||
name|PAT_MASK
argument_list|(
literal|6
argument_list|)
operator|)
expr_stmt|;
name|pat_msr
operator||=
name|PAT_VALUE
argument_list|(
literal|5
argument_list|,
name|PAT_WRITE_PROTECTED
argument_list|)
operator||
name|PAT_VALUE
argument_list|(
literal|6
argument_list|,
name|PAT_WRITE_COMBINING
argument_list|)
expr_stmt|;
name|pat_table
index|[
name|PAT_UNCACHED
index|]
operator|=
literal|2
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_PROTECTED
index|]
operator|=
literal|5
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_COMBINING
index|]
operator|=
literal|6
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Just replace PAT Index 2 with WC instead of UC-. 		 */
name|pat_msr
operator|&=
operator|~
name|PAT_MASK
argument_list|(
literal|2
argument_list|)
expr_stmt|;
name|pat_msr
operator||=
name|PAT_VALUE
argument_list|(
literal|2
argument_list|,
name|PAT_WRITE_COMBINING
argument_list|)
expr_stmt|;
name|pat_table
index|[
name|PAT_WRITE_COMBINING
index|]
operator|=
literal|2
expr_stmt|;
block|}
comment|/* Disable PGE. */
name|cr4
operator|=
name|rcr4
argument_list|()
expr_stmt|;
name|load_cr4
argument_list|(
name|cr4
operator|&
operator|~
name|CR4_PGE
argument_list|)
expr_stmt|;
comment|/* Disable caches (CD = 1, NW = 0). */
name|cr0
operator|=
name|rcr0
argument_list|()
expr_stmt|;
name|load_cr0
argument_list|(
operator|(
name|cr0
operator|&
operator|~
name|CR0_NW
operator|)
operator||
name|CR0_CD
argument_list|)
expr_stmt|;
comment|/* Flushes caches and TLBs. */
name|wbinvd
argument_list|()
expr_stmt|;
name|invltlb
argument_list|()
expr_stmt|;
comment|/* Update PAT and index table. */
name|wrmsr
argument_list|(
name|MSR_PAT
argument_list|,
name|pat_msr
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PAT_INDEX_SIZE
condition|;
name|i
operator|++
control|)
name|pat_index
index|[
name|i
index|]
operator|=
name|pat_table
index|[
name|i
index|]
expr_stmt|;
comment|/* Flush caches and TLBs again. */
name|wbinvd
argument_list|()
expr_stmt|;
name|invltlb
argument_list|()
expr_stmt|;
comment|/* Restore caches and PGE. */
name|load_cr0
argument_list|(
name|cr0
argument_list|)
expr_stmt|;
name|load_cr4
argument_list|(
name|cr4
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Set PG_G on kernel pages.  Only the BSP calls this when SMP is turned on.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_set_pg
parameter_list|(
name|void
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|endva
decl_stmt|;
if|if
condition|(
name|pgeflag
operator|==
literal|0
condition|)
return|return;
name|endva
operator|=
name|KERNBASE
operator|+
name|KERNend
expr_stmt|;
if|if
condition|(
name|pseflag
condition|)
block|{
name|va
operator|=
name|KERNBASE
operator|+
name|KERNLOAD
expr_stmt|;
while|while
condition|(
name|va
operator|<
name|endva
condition|)
block|{
name|pdir_pde
argument_list|(
name|PTD
argument_list|,
name|va
argument_list|)
operator||=
name|pgeflag
expr_stmt|;
name|invltlb
argument_list|()
expr_stmt|;
comment|/* Flush non-PG_G entries. */
name|va
operator|+=
name|NBPDR
expr_stmt|;
block|}
block|}
else|else
block|{
name|va
operator|=
operator|(
name|vm_offset_t
operator|)
name|btext
expr_stmt|;
while|while
condition|(
name|va
operator|<
name|endva
condition|)
block|{
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pte
condition|)
operator|*
name|pte
operator||=
name|pgeflag
expr_stmt|;
name|invltlb
argument_list|()
expr_stmt|;
comment|/* Flush non-PG_G entries. */
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * Initialize a vm_page's machine-dependent fields.  */
end_comment

begin_function
name|void
name|pmap_page_init
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|TAILQ_INIT
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
expr_stmt|;
name|m
operator|->
name|md
operator|.
name|pat_mode
operator|=
name|PAT_WRITE_BACK
expr_stmt|;
block|}
end_function

begin_if
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
end_if

begin_function
specifier|static
name|void
modifier|*
name|pmap_pdpt_allocf
parameter_list|(
name|uma_zone_t
name|zone
parameter_list|,
name|vm_size_t
name|bytes
parameter_list|,
name|uint8_t
modifier|*
name|flags
parameter_list|,
name|int
name|wait
parameter_list|)
block|{
comment|/* Inform UMA that this allocator uses kernel_map/object. */
operator|*
name|flags
operator|=
name|UMA_SLAB_KERNEL
expr_stmt|;
return|return
operator|(
operator|(
name|void
operator|*
operator|)
name|kmem_alloc_contig
argument_list|(
name|kernel_arena
argument_list|,
name|bytes
argument_list|,
name|wait
argument_list|,
literal|0x0ULL
argument_list|,
literal|0xffffffffULL
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
name|VM_MEMATTR_DEFAULT
argument_list|)
operator|)
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Abuse the pte nodes for unmapped kva to thread a kva freelist through.  * Requirements:  *  - Must deal with pages in order to ensure that none of the PG_* bits  *    are ever set, PG_V in particular.  *  - Assumes we can write to ptes without pte_store() atomic ops, even  *    on PAE systems.  This should be ok.  *  - Assumes nothing will ever test these addresses for 0 to indicate  *    no mapping instead of correctly checking PG_V.  *  - Assumes a vm_offset_t will fit in a pte (true for i386).  * Because PG_V is never set, there can be no mappings to invalidate.  */
end_comment

begin_function
specifier|static
name|vm_offset_t
name|pmap_ptelist_alloc
parameter_list|(
name|vm_offset_t
modifier|*
name|head
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|va
operator|=
operator|*
name|head
expr_stmt|;
if|if
condition|(
name|va
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_ptelist_alloc: exhausted ptelist KVA"
argument_list|)
expr_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
operator|*
name|head
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|*
name|head
operator|&
name|PG_V
condition|)
name|panic
argument_list|(
literal|"pmap_ptelist_alloc: va with PG_V set!"
argument_list|)
expr_stmt|;
operator|*
name|pte
operator|=
literal|0
expr_stmt|;
return|return
operator|(
name|va
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_ptelist_free
parameter_list|(
name|vm_offset_t
modifier|*
name|head
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
if|if
condition|(
name|va
operator|&
name|PG_V
condition|)
name|panic
argument_list|(
literal|"pmap_ptelist_free: freeing va with PG_V set!"
argument_list|)
expr_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
operator|*
name|pte
operator|=
operator|*
name|head
expr_stmt|;
comment|/* virtual! PG_V is 0 though */
operator|*
name|head
operator|=
name|va
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_ptelist_init
parameter_list|(
name|vm_offset_t
modifier|*
name|head
parameter_list|,
name|void
modifier|*
name|base
parameter_list|,
name|int
name|npages
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
operator|*
name|head
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
name|npages
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|va
operator|=
operator|(
name|vm_offset_t
operator|)
name|base
operator|+
name|i
operator|*
name|PAGE_SIZE
expr_stmt|;
name|pmap_ptelist_free
argument_list|(
name|head
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	Initialize the pmap module.  *	Called by vm_init, to initialize any structures that the pmap  *	system needs to map virtual memory.  */
end_comment

begin_function
name|void
name|pmap_init
parameter_list|(
name|void
parameter_list|)
block|{
name|struct
name|pmap_preinit_mapping
modifier|*
name|ppim
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
name|vm_size_t
name|s
decl_stmt|;
name|int
name|i
decl_stmt|,
name|pv_npg
decl_stmt|;
comment|/* 	 * Initialize the vm page array entries for the kernel pmap's 	 * page table pages. 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NKPT
condition|;
name|i
operator|++
control|)
block|{
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|KPTphys
operator|+
operator|(
name|i
operator|<<
name|PAGE_SHIFT
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|>=
name|vm_page_array
operator|&&
name|mpte
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"pmap_init: page table page is out of range"
operator|)
argument_list|)
expr_stmt|;
name|mpte
operator|->
name|pindex
operator|=
name|i
operator|+
name|KPTDI
expr_stmt|;
name|mpte
operator|->
name|phys_addr
operator|=
name|KPTphys
operator|+
operator|(
name|i
operator|<<
name|PAGE_SHIFT
operator|)
expr_stmt|;
block|}
comment|/* 	 * Initialize the address space (zone) for the pv entries.  Set a 	 * high water mark so that the system can recover from excessive 	 * numbers of pv entries. 	 */
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.pmap.shpgperproc"
argument_list|,
operator|&
name|shpgperproc
argument_list|)
expr_stmt|;
name|pv_entry_max
operator|=
name|shpgperproc
operator|*
name|maxproc
operator|+
name|vm_cnt
operator|.
name|v_page_count
expr_stmt|;
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.pmap.pv_entries"
argument_list|,
operator|&
name|pv_entry_max
argument_list|)
expr_stmt|;
name|pv_entry_max
operator|=
name|roundup
argument_list|(
name|pv_entry_max
argument_list|,
name|_NPCPV
argument_list|)
expr_stmt|;
name|pv_entry_high_water
operator|=
literal|9
operator|*
operator|(
name|pv_entry_max
operator|/
literal|10
operator|)
expr_stmt|;
comment|/* 	 * If the kernel is running on a virtual machine, then it must assume 	 * that MCA is enabled by the hypervisor.  Moreover, the kernel must 	 * be prepared for the hypervisor changing the vendor and family that 	 * are reported by CPUID.  Consequently, the workaround for AMD Family 	 * 10h Erratum 383 is enabled if the processor's feature set does not 	 * include at least one feature that is only supported by older Intel 	 * or newer AMD processors. 	 */
if|if
condition|(
name|vm_guest
operator|!=
name|VM_GUEST_NO
operator|&&
operator|(
name|cpu_feature
operator|&
name|CPUID_SS
operator|)
operator|==
literal|0
operator|&&
operator|(
name|cpu_feature2
operator|&
operator|(
name|CPUID2_SSSE3
operator||
name|CPUID2_SSE41
operator||
name|CPUID2_AESNI
operator||
name|CPUID2_AVX
operator||
name|CPUID2_XSAVE
operator|)
operator|)
operator|==
literal|0
operator|&&
operator|(
name|amd_feature2
operator|&
operator|(
name|AMDID2_XOP
operator||
name|AMDID2_FMA4
operator|)
operator|)
operator|==
literal|0
condition|)
name|workaround_erratum383
operator|=
literal|1
expr_stmt|;
comment|/* 	 * Are large page mappings supported and enabled? 	 */
name|TUNABLE_INT_FETCH
argument_list|(
literal|"vm.pmap.pg_ps_enabled"
argument_list|,
operator|&
name|pg_ps_enabled
argument_list|)
expr_stmt|;
if|if
condition|(
name|pseflag
operator|==
literal|0
condition|)
name|pg_ps_enabled
operator|=
literal|0
expr_stmt|;
elseif|else
if|if
condition|(
name|pg_ps_enabled
condition|)
block|{
name|KASSERT
argument_list|(
name|MAXPAGESIZES
operator|>
literal|1
operator|&&
name|pagesizes
index|[
literal|1
index|]
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_init: can't assign to pagesizes[1]"
operator|)
argument_list|)
expr_stmt|;
name|pagesizes
index|[
literal|1
index|]
operator|=
name|NBPDR
expr_stmt|;
block|}
comment|/* 	 * Calculate the size of the pv head table for superpages. 	 * Handle the possibility that "vm_phys_segs[...].end" is zero. 	 */
name|pv_npg
operator|=
name|trunc_4mpage
argument_list|(
name|vm_phys_segs
index|[
name|vm_phys_nsegs
operator|-
literal|1
index|]
operator|.
name|end
operator|-
name|PAGE_SIZE
argument_list|)
operator|/
name|NBPDR
operator|+
literal|1
expr_stmt|;
comment|/* 	 * Allocate memory for the pv head table for superpages. 	 */
name|s
operator|=
call|(
name|vm_size_t
call|)
argument_list|(
name|pv_npg
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|md_page
argument_list|)
argument_list|)
expr_stmt|;
name|s
operator|=
name|round_page
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|pv_table
operator|=
operator|(
expr|struct
name|md_page
operator|*
operator|)
name|kmem_malloc
argument_list|(
name|kernel_arena
argument_list|,
name|s
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|pv_npg
condition|;
name|i
operator|++
control|)
name|TAILQ_INIT
argument_list|(
operator|&
name|pv_table
index|[
name|i
index|]
operator|.
name|pv_list
argument_list|)
expr_stmt|;
name|pv_maxchunks
operator|=
name|MAX
argument_list|(
name|pv_entry_max
operator|/
name|_NPCPV
argument_list|,
name|maxproc
argument_list|)
expr_stmt|;
name|pv_chunkbase
operator|=
operator|(
expr|struct
name|pv_chunk
operator|*
operator|)
name|kva_alloc
argument_list|(
name|PAGE_SIZE
operator|*
name|pv_maxchunks
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv_chunkbase
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_init: not enough kvm for pv chunks"
argument_list|)
expr_stmt|;
name|pmap_ptelist_init
argument_list|(
operator|&
name|pv_vafree
argument_list|,
name|pv_chunkbase
argument_list|,
name|pv_maxchunks
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
name|pdptzone
operator|=
name|uma_zcreate
argument_list|(
literal|"PDPT"
argument_list|,
name|NPGPTD
operator|*
sizeof|sizeof
argument_list|(
name|pdpt_entry_t
argument_list|)
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
name|NULL
argument_list|,
operator|(
name|NPGPTD
operator|*
sizeof|sizeof
argument_list|(
name|pdpt_entry_t
argument_list|)
operator|)
operator|-
literal|1
argument_list|,
name|UMA_ZONE_VM
operator||
name|UMA_ZONE_NOFREE
argument_list|)
expr_stmt|;
name|uma_zone_set_allocf
argument_list|(
name|pdptzone
argument_list|,
name|pmap_pdpt_allocf
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|pmap_initialized
operator|=
literal|1
expr_stmt|;
if|if
condition|(
operator|!
name|bootverbose
condition|)
return|return;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PMAP_PREINIT_MAPPING_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|ppim
operator|=
name|pmap_preinit_mapping
operator|+
name|i
expr_stmt|;
if|if
condition|(
name|ppim
operator|->
name|va
operator|==
literal|0
condition|)
continue|continue;
name|printf
argument_list|(
literal|"PPIM %u: PA=%#jx, VA=%#x, size=%#x, mode=%#x\n"
argument_list|,
name|i
argument_list|,
operator|(
name|uintmax_t
operator|)
name|ppim
operator|->
name|pa
argument_list|,
name|ppim
operator|->
name|va
argument_list|,
name|ppim
operator|->
name|sz
argument_list|,
name|ppim
operator|->
name|mode
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_max
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_max
argument_list|,
literal|0
argument_list|,
literal|"Max number of PV entries"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|shpgperproc
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|shpgperproc
argument_list|,
literal|0
argument_list|,
literal|"Page share factor per proc"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
specifier|static
name|SYSCTL_NODE
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pde
argument_list|,
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|"2/4MB page mapping counters"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pde_demotions
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pde
argument_list|,
name|OID_AUTO
argument_list|,
name|demotions
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pde_demotions
argument_list|,
literal|0
argument_list|,
literal|"2/4MB page demotions"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pde_mappings
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pde
argument_list|,
name|OID_AUTO
argument_list|,
name|mappings
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pde_mappings
argument_list|,
literal|0
argument_list|,
literal|"2/4MB page mappings"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pde_p_failures
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pde
argument_list|,
name|OID_AUTO
argument_list|,
name|p_failures
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pde_p_failures
argument_list|,
literal|0
argument_list|,
literal|"2/4MB page promotion failures"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|u_long
name|pmap_pde_promotions
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_ULONG
argument_list|(
name|_vm_pmap_pde
argument_list|,
name|OID_AUTO
argument_list|,
name|promotions
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pmap_pde_promotions
argument_list|,
literal|0
argument_list|,
literal|"2/4MB page promotions"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/***************************************************  * Low level helper routines.....  ***************************************************/
end_comment

begin_comment
comment|/*  * Determine the appropriate bits to set in a PTE or PDE for a specified  * caching mode.  */
end_comment

begin_function
name|int
name|pmap_cache_bits
parameter_list|(
name|int
name|mode
parameter_list|,
name|boolean_t
name|is_pde
parameter_list|)
block|{
name|int
name|cache_bits
decl_stmt|,
name|pat_flag
decl_stmt|,
name|pat_idx
decl_stmt|;
if|if
condition|(
name|mode
operator|<
literal|0
operator|||
name|mode
operator|>=
name|PAT_INDEX_SIZE
operator|||
name|pat_index
index|[
name|mode
index|]
operator|<
literal|0
condition|)
name|panic
argument_list|(
literal|"Unknown caching mode %d\n"
argument_list|,
name|mode
argument_list|)
expr_stmt|;
comment|/* The PAT bit is different for PTE's and PDE's. */
name|pat_flag
operator|=
name|is_pde
condition|?
name|PG_PDE_PAT
else|:
name|PG_PTE_PAT
expr_stmt|;
comment|/* Map the caching mode to a PAT index. */
name|pat_idx
operator|=
name|pat_index
index|[
name|mode
index|]
expr_stmt|;
comment|/* Map the 3-bit index value into the PAT, PCD, and PWT bits. */
name|cache_bits
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|pat_idx
operator|&
literal|0x4
condition|)
name|cache_bits
operator||=
name|pat_flag
expr_stmt|;
if|if
condition|(
name|pat_idx
operator|&
literal|0x2
condition|)
name|cache_bits
operator||=
name|PG_NC_PCD
expr_stmt|;
if|if
condition|(
name|pat_idx
operator|&
literal|0x1
condition|)
name|cache_bits
operator||=
name|PG_NC_PWT
expr_stmt|;
return|return
operator|(
name|cache_bits
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * The caller is responsible for maintaining TLB consistency.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_kenter_pde
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|boolean_t
name|PTD_updated
decl_stmt|;
name|PTD_updated
operator|=
name|FALSE
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
name|LIST_FOREACH
argument_list|(
argument|pmap
argument_list|,
argument|&allpmaps
argument_list|,
argument|pm_list
argument_list|)
block|{
if|if
condition|(
operator|(
name|pmap
operator|->
name|pm_pdir
index|[
name|PTDPTDI
index|]
operator|&
name|PG_FRAME
operator|)
operator|==
operator|(
name|PTDpde
index|[
literal|0
index|]
operator|&
name|PG_FRAME
operator|)
condition|)
name|PTD_updated
operator|=
name|TRUE
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pde_store
argument_list|(
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
block|}
name|mtx_unlock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|PTD_updated
argument_list|,
operator|(
literal|"pmap_kenter_pde: current page table is not in allpmaps"
operator|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * After changing the page size for the specified virtual address in the page  * table, flush the corresponding entries from the processor's TLB.  Only the  * calling processor's TLB is affected.  *  * The calling thread must be pinned to a processor.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_update_pde_invalidate
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
block|{
name|u_long
name|cr4
decl_stmt|;
if|if
condition|(
operator|(
name|newpde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
condition|)
comment|/* Demotion: flush a specific 2MB page mapping. */
name|invlpg
argument_list|(
name|va
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|newpde
operator|&
name|PG_G
operator|)
operator|==
literal|0
condition|)
comment|/* 		 * Promotion: flush every 4KB page mapping from the TLB 		 * because there are too many to flush individually. 		 */
name|invltlb
argument_list|()
expr_stmt|;
else|else
block|{
comment|/* 		 * Promotion: flush every 4KB page mapping from the TLB, 		 * including any global (PG_G) mappings. 		 */
name|cr4
operator|=
name|rcr4
argument_list|()
expr_stmt|;
name|load_cr4
argument_list|(
name|cr4
operator|&
operator|~
name|CR4_PGE
argument_list|)
expr_stmt|;
comment|/* 		 * Although preemption at this point could be detrimental to 		 * performance, it would not lead to an error.  PG_G is simply 		 * ignored if CR4.PGE is clear.  Moreover, in case this block 		 * is re-entered, the load_cr4() either above or below will 		 * modify CR4.PGE flushing the TLB. 		 */
name|load_cr4
argument_list|(
name|cr4
operator||
name|CR4_PGE
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|invltlb_glob
parameter_list|(
name|void
parameter_list|)
block|{
name|uint64_t
name|cr4
decl_stmt|;
if|if
condition|(
name|pgeflag
operator|==
literal|0
condition|)
block|{
name|invltlb
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|cr4
operator|=
name|rcr4
argument_list|()
expr_stmt|;
name|load_cr4
argument_list|(
name|cr4
operator|&
operator|~
name|CR4_PGE
argument_list|)
expr_stmt|;
name|load_cr4
argument_list|(
name|cr4
operator||
name|CR4_PGE
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|SMP
end_ifdef

begin_comment
comment|/*  * For SMP, these functions have to use the IPI mechanism for coherence.  *  * N.B.: Before calling any of the following TLB invalidation functions,  * the calling processor must ensure that all stores updating a non-  * kernel page table are globally performed.  Otherwise, another  * processor could cache an old, pre-update entry without being  * invalidated.  This can happen one of two ways: (1) The pmap becomes  * active on another processor after its pm_active field is checked by  * one of the following functions but before a store updating the page  * table is globally performed. (2) The pmap becomes active on another  * processor before its pm_active field is checked but due to  * speculative loads one of the following functions stills reads the  * pmap as inactive on the other processor.  *   * The kernel page table is exempt because its pm_active field is  * immutable.  The kernel page table is always active on every  * processor.  */
end_comment

begin_function
name|void
name|pmap_invalidate_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|cpuset_t
modifier|*
name|mask
decl_stmt|,
name|other_cpus
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
operator|!
name|CPU_CMP
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|,
operator|&
name|all_cpus
argument_list|)
condition|)
block|{
name|invlpg
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|mask
operator|=
operator|&
name|all_cpus
expr_stmt|;
block|}
else|else
block|{
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|other_cpus
operator|=
name|all_cpus
expr_stmt|;
name|CPU_CLR
argument_list|(
name|cpuid
argument_list|,
operator|&
name|other_cpus
argument_list|)
expr_stmt|;
if|if
condition|(
name|CPU_ISSET
argument_list|(
name|cpuid
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
condition|)
name|invlpg
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|CPU_AND
argument_list|(
operator|&
name|other_cpus
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|mask
operator|=
operator|&
name|other_cpus
expr_stmt|;
block|}
name|smp_masked_invlpg
argument_list|(
operator|*
name|mask
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/* 4k PTEs -- Chosen to exceed the total size of Broadwell L2 TLB */
end_comment

begin_define
define|#
directive|define
name|PMAP_INVLPG_THRESHOLD
value|(4 * 1024 * PAGE_SIZE)
end_define

begin_function
name|void
name|pmap_invalidate_range
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|cpuset_t
modifier|*
name|mask
decl_stmt|,
name|other_cpus
decl_stmt|;
name|vm_offset_t
name|addr
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|;
if|if
condition|(
name|eva
operator|-
name|sva
operator|>=
name|PMAP_INVLPG_THRESHOLD
condition|)
block|{
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
operator|!
name|CPU_CMP
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|,
operator|&
name|all_cpus
argument_list|)
condition|)
block|{
for|for
control|(
name|addr
operator|=
name|sva
init|;
name|addr
operator|<
name|eva
condition|;
name|addr
operator|+=
name|PAGE_SIZE
control|)
name|invlpg
argument_list|(
name|addr
argument_list|)
expr_stmt|;
name|mask
operator|=
operator|&
name|all_cpus
expr_stmt|;
block|}
else|else
block|{
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|other_cpus
operator|=
name|all_cpus
expr_stmt|;
name|CPU_CLR
argument_list|(
name|cpuid
argument_list|,
operator|&
name|other_cpus
argument_list|)
expr_stmt|;
if|if
condition|(
name|CPU_ISSET
argument_list|(
name|cpuid
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
condition|)
for|for
control|(
name|addr
operator|=
name|sva
init|;
name|addr
operator|<
name|eva
condition|;
name|addr
operator|+=
name|PAGE_SIZE
control|)
name|invlpg
argument_list|(
name|addr
argument_list|)
expr_stmt|;
name|CPU_AND
argument_list|(
operator|&
name|other_cpus
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|mask
operator|=
operator|&
name|other_cpus
expr_stmt|;
block|}
name|smp_masked_invlpg_range
argument_list|(
operator|*
name|mask
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_invalidate_all
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|cpuset_t
modifier|*
name|mask
decl_stmt|,
name|other_cpus
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|invltlb_glob
argument_list|()
expr_stmt|;
name|mask
operator|=
operator|&
name|all_cpus
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|CPU_CMP
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|,
operator|&
name|all_cpus
argument_list|)
condition|)
block|{
name|invltlb
argument_list|()
expr_stmt|;
name|mask
operator|=
operator|&
name|all_cpus
expr_stmt|;
block|}
else|else
block|{
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|other_cpus
operator|=
name|all_cpus
expr_stmt|;
name|CPU_CLR
argument_list|(
name|cpuid
argument_list|,
operator|&
name|other_cpus
argument_list|)
expr_stmt|;
if|if
condition|(
name|CPU_ISSET
argument_list|(
name|cpuid
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
condition|)
name|invltlb
argument_list|()
expr_stmt|;
name|CPU_AND
argument_list|(
operator|&
name|other_cpus
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|mask
operator|=
operator|&
name|other_cpus
expr_stmt|;
block|}
name|smp_masked_invltlb
argument_list|(
operator|*
name|mask
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_invalidate_cache
parameter_list|(
name|void
parameter_list|)
block|{
name|sched_pin
argument_list|()
expr_stmt|;
name|wbinvd
argument_list|()
expr_stmt|;
name|smp_cache_flush
argument_list|()
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_struct
struct|struct
name|pde_action
block|{
name|cpuset_t
name|invalidate
decl_stmt|;
comment|/* processors that invalidate their TLB */
name|vm_offset_t
name|va
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pd_entry_t
name|newpde
decl_stmt|;
name|u_int
name|store
decl_stmt|;
comment|/* processor that updates the PDE */
block|}
struct|;
end_struct

begin_function
specifier|static
name|void
name|pmap_update_pde_kernel
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|struct
name|pde_action
modifier|*
name|act
init|=
name|arg
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
if|if
condition|(
name|act
operator|->
name|store
operator|==
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
block|{
comment|/* 		 * Elsewhere, this operation requires allpmaps_lock for 		 * synchronization.  Here, it does not because it is being 		 * performed in the context of an all_cpus rendezvous. 		 */
name|LIST_FOREACH
argument_list|(
argument|pmap
argument_list|,
argument|&allpmaps
argument_list|,
argument|pm_list
argument_list|)
block|{
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|act
operator|->
name|va
argument_list|)
expr_stmt|;
name|pde_store
argument_list|(
name|pde
argument_list|,
name|act
operator|->
name|newpde
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_update_pde_user
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|struct
name|pde_action
modifier|*
name|act
init|=
name|arg
decl_stmt|;
if|if
condition|(
name|act
operator|->
name|store
operator|==
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
name|pde_store
argument_list|(
name|act
operator|->
name|pde
argument_list|,
name|act
operator|->
name|newpde
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_update_pde_teardown
parameter_list|(
name|void
modifier|*
name|arg
parameter_list|)
block|{
name|struct
name|pde_action
modifier|*
name|act
init|=
name|arg
decl_stmt|;
if|if
condition|(
name|CPU_ISSET
argument_list|(
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
argument_list|,
operator|&
name|act
operator|->
name|invalidate
argument_list|)
condition|)
name|pmap_update_pde_invalidate
argument_list|(
name|act
operator|->
name|va
argument_list|,
name|act
operator|->
name|newpde
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Change the page size for the specified virtual address in a way that  * prevents any possibility of the TLB ever having two entries that map the  * same virtual address using different page sizes.  This is the recommended  * workaround for Erratum 383 on AMD Family 10h processors.  It prevents a  * machine check exception for a TLB state that is improperly diagnosed as a  * hardware error.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_update_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
block|{
name|struct
name|pde_action
name|act
decl_stmt|;
name|cpuset_t
name|active
decl_stmt|,
name|other_cpus
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|other_cpus
operator|=
name|all_cpus
expr_stmt|;
name|CPU_CLR
argument_list|(
name|cpuid
argument_list|,
operator|&
name|other_cpus
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|active
operator|=
name|all_cpus
expr_stmt|;
else|else
name|active
operator|=
name|pmap
operator|->
name|pm_active
expr_stmt|;
if|if
condition|(
name|CPU_OVERLAP
argument_list|(
operator|&
name|active
argument_list|,
operator|&
name|other_cpus
argument_list|)
condition|)
block|{
name|act
operator|.
name|store
operator|=
name|cpuid
expr_stmt|;
name|act
operator|.
name|invalidate
operator|=
name|active
expr_stmt|;
name|act
operator|.
name|va
operator|=
name|va
expr_stmt|;
name|act
operator|.
name|pde
operator|=
name|pde
expr_stmt|;
name|act
operator|.
name|newpde
operator|=
name|newpde
expr_stmt|;
name|CPU_SET
argument_list|(
name|cpuid
argument_list|,
operator|&
name|active
argument_list|)
expr_stmt|;
name|smp_rendezvous_cpus
argument_list|(
name|active
argument_list|,
name|smp_no_rendezvous_barrier
argument_list|,
name|pmap
operator|==
name|kernel_pmap
condition|?
name|pmap_update_pde_kernel
else|:
name|pmap_update_pde_user
argument_list|,
name|pmap_update_pde_teardown
argument_list|,
operator|&
name|act
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|pmap_kenter_pde
argument_list|(
name|va
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
else|else
name|pde_store
argument_list|(
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
if|if
condition|(
name|CPU_ISSET
argument_list|(
name|cpuid
argument_list|,
operator|&
name|active
argument_list|)
condition|)
name|pmap_update_pde_invalidate
argument_list|(
name|va
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
block|}
end_function

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* !SMP */
end_comment

begin_comment
comment|/*  * Normal, non-SMP, 486+ invalidation functions.  * We inline these within pmap.c for speed.  */
end_comment

begin_function
name|PMAP_INLINE
name|void
name|pmap_invalidate_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
operator|!
name|CPU_EMPTY
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
condition|)
name|invlpg
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|PMAP_INLINE
name|void
name|pmap_invalidate_range
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|vm_offset_t
name|addr
decl_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
operator|!
name|CPU_EMPTY
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
condition|)
for|for
control|(
name|addr
operator|=
name|sva
init|;
name|addr
operator|<
name|eva
condition|;
name|addr
operator|+=
name|PAGE_SIZE
control|)
name|invlpg
argument_list|(
name|addr
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
name|PMAP_INLINE
name|void
name|pmap_invalidate_all
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|invltlb_glob
argument_list|()
expr_stmt|;
elseif|else
if|if
condition|(
operator|!
name|CPU_EMPTY
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
condition|)
name|invltlb
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|PMAP_INLINE
name|void
name|pmap_invalidate_cache
parameter_list|(
name|void
parameter_list|)
block|{
name|wbinvd
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_update_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|pd_entry_t
name|newpde
parameter_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|pmap_kenter_pde
argument_list|(
name|va
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
else|else
name|pde_store
argument_list|(
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
operator|||
operator|!
name|CPU_EMPTY
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
condition|)
name|pmap_update_pde_invalidate
argument_list|(
name|va
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* !SMP */
end_comment

begin_function
specifier|static
name|void
name|pmap_invalidate_pde_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|pd_entry_t
name|pde
parameter_list|)
block|{
comment|/* 	 * When the PDE has PG_PROMOTED set, the 2- or 4MB page mapping was 	 * created by a promotion that did not invalidate the 512 or 1024 4KB 	 * page mappings that might exist in the TLB.  Consequently, at this 	 * point, the TLB may hold both 4KB and 2- or 4MB page mappings for 	 * the address range [va, va + NBPDR).  Therefore, the entire range 	 * must be invalidated here.  In contrast, when PG_PROMOTED is clear, 	 * the TLB will not hold any 4KB page mappings for the address range 	 * [va, va + NBPDR), and so a single INVLPG suffices to invalidate the 	 * 2- or 4MB page mapping from the TLB. 	 */
if|if
condition|(
operator|(
name|pde
operator|&
name|PG_PROMOTED
operator|)
operator|!=
literal|0
condition|)
name|pmap_invalidate_range
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|va
operator|+
name|NBPDR
operator|-
literal|1
argument_list|)
expr_stmt|;
else|else
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_define
define|#
directive|define
name|PMAP_CLFLUSH_THRESHOLD
value|(2 * 1024 * 1024)
end_define

begin_function
name|void
name|pmap_invalidate_cache_range
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|boolean_t
name|force
parameter_list|)
block|{
if|if
condition|(
name|force
condition|)
block|{
name|sva
operator|&=
operator|~
call|(
name|vm_offset_t
call|)
argument_list|(
name|cpu_clflush_line_size
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|KASSERT
argument_list|(
operator|(
name|sva
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_invalidate_cache_range: sva not page-aligned"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|eva
operator|&
name|PAGE_MASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_invalidate_cache_range: eva not page-aligned"
operator|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|cpu_feature
operator|&
name|CPUID_SS
operator|)
operator|!=
literal|0
operator|&&
operator|!
name|force
condition|)
empty_stmt|;
comment|/* If "Self Snoop" is supported and allowed, do nothing. */
elseif|else
if|if
condition|(
operator|(
name|cpu_stdext_feature
operator|&
name|CPUID_STDEXT_CLFLUSHOPT
operator|)
operator|!=
literal|0
operator|&&
name|eva
operator|-
name|sva
operator|<
name|PMAP_CLFLUSH_THRESHOLD
condition|)
block|{
ifdef|#
directive|ifdef
name|DEV_APIC
comment|/* 		 * XXX: Some CPUs fault, hang, or trash the local APIC 		 * registers if we use CLFLUSH on the local APIC 		 * range.  The local APIC is always uncached, so we 		 * don't need to flush for that range anyway. 		 */
if|if
condition|(
name|pmap_kextract
argument_list|(
name|sva
argument_list|)
operator|==
name|lapic_paddr
condition|)
return|return;
endif|#
directive|endif
comment|/* 		 * Otherwise, do per-cache line flush.  Use the sfence 		 * instruction to insure that previous stores are 		 * included in the write-back.  The processor 		 * propagates flush to other processors in the cache 		 * coherence domain. 		 */
name|sfence
argument_list|()
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|+=
name|cpu_clflush_line_size
control|)
name|clflushopt
argument_list|(
name|sva
argument_list|)
expr_stmt|;
name|sfence
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
name|cpu_feature
operator|&
name|CPUID_CLFSH
operator|)
operator|!=
literal|0
operator|&&
name|eva
operator|-
name|sva
operator|<
name|PMAP_CLFLUSH_THRESHOLD
condition|)
block|{
ifdef|#
directive|ifdef
name|DEV_APIC
if|if
condition|(
name|pmap_kextract
argument_list|(
name|sva
argument_list|)
operator|==
name|lapic_paddr
condition|)
return|return;
endif|#
directive|endif
comment|/* 		 * Writes are ordered by CLFLUSH on Intel CPUs. 		 */
if|if
condition|(
name|cpu_vendor_id
operator|!=
name|CPU_VENDOR_INTEL
condition|)
name|mfence
argument_list|()
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|+=
name|cpu_clflush_line_size
control|)
name|clflush
argument_list|(
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|cpu_vendor_id
operator|!=
name|CPU_VENDOR_INTEL
condition|)
name|mfence
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * No targeted cache flush methods are supported by CPU, 		 * or the supplied range is bigger than 2MB. 		 * Globally invalidate cache. 		 */
name|pmap_invalidate_cache
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_function
name|void
name|pmap_invalidate_cache_pages
parameter_list|(
name|vm_page_t
modifier|*
name|pages
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|int
name|i
decl_stmt|;
if|if
condition|(
name|count
operator|>=
name|PMAP_CLFLUSH_THRESHOLD
operator|/
name|PAGE_SIZE
operator|||
operator|(
name|cpu_feature
operator|&
name|CPUID_CLFSH
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_invalidate_cache
argument_list|()
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
name|i
operator|++
control|)
name|pmap_flush_page
argument_list|(
name|pages
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Are we current address space or kernel?  */
end_comment

begin_function
specifier|static
name|__inline
name|int
name|pmap_is_current
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
return|return
operator|(
name|pmap
operator|==
name|kernel_pmap
operator|||
name|pmap
operator|==
name|vmspace_pmap
argument_list|(
name|curthread
operator|->
name|td_proc
operator|->
name|p_vmspace
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * If the given pmap is not the current or kernel pmap, the returned pte must  * be released by passing it to pmap_pte_release().  */
end_comment

begin_function
name|pt_entry_t
modifier|*
name|pmap_pte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
name|newpf
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pde
operator|&
name|PG_PS
condition|)
return|return
operator|(
name|pde
operator|)
return|;
if|if
condition|(
operator|*
name|pde
operator|!=
literal|0
condition|)
block|{
comment|/* are we current address space or kernel? */
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
return|return
operator|(
name|vtopte
argument_list|(
name|va
argument_list|)
operator|)
return|;
name|mtx_lock
argument_list|(
operator|&
name|PMAP2mutex
argument_list|)
expr_stmt|;
name|newpf
operator|=
operator|*
name|pde
operator|&
name|PG_FRAME
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|PMAP2
operator|&
name|PG_FRAME
operator|)
operator|!=
name|newpf
condition|)
block|{
operator|*
name|PMAP2
operator|=
name|newpf
operator||
name|PG_RW
operator||
name|PG_V
operator||
name|PG_A
operator||
name|PG_M
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|kernel_pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|PADDR2
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|PADDR2
operator|+
operator|(
name|i386_btop
argument_list|(
name|va
argument_list|)
operator|&
operator|(
name|NPTEPG
operator|-
literal|1
operator|)
operator|)
operator|)
return|;
block|}
return|return
operator|(
name|NULL
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Releases a pte that was obtained from pmap_pte().  Be prepared for the pte  * being NULL.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_pte_release
parameter_list|(
name|pt_entry_t
modifier|*
name|pte
parameter_list|)
block|{
if|if
condition|(
operator|(
name|pt_entry_t
operator|*
operator|)
operator|(
operator|(
name|vm_offset_t
operator|)
name|pte
operator|&
operator|~
name|PAGE_MASK
operator|)
operator|==
name|PADDR2
condition|)
name|mtx_unlock
argument_list|(
operator|&
name|PMAP2mutex
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * NB:  The sequence of updating a page table followed by accesses to the  * corresponding pages is subject to the situation described in the "AMD64  * Architecture Programmer's Manual Volume 2: System Programming" rev. 3.23,  * "7.3.1 Special Coherency Considerations".  Therefore, issuing the INVLPG  * right after modifying the PTE bits is crucial.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|invlcaddr
parameter_list|(
name|void
modifier|*
name|caddr
parameter_list|)
block|{
name|invlpg
argument_list|(
operator|(
name|u_int
operator|)
name|caddr
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Super fast pmap_pte routine best used when scanning  * the pv lists.  This eliminates many coarse-grained  * invltlb calls.  Note that many of the pv list  * scans are across different pmaps.  It is very wasteful  * to do an entire invltlb for checking a single mapping.  *  * If the given pmap is not the current pmap, pvh_global_lock  * must be held and curthread pinned to a CPU.  */
end_comment

begin_function
specifier|static
name|pt_entry_t
modifier|*
name|pmap_pte_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
name|newpf
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pde
operator|&
name|PG_PS
condition|)
return|return
operator|(
name|pde
operator|)
return|;
if|if
condition|(
operator|*
name|pde
operator|!=
literal|0
condition|)
block|{
comment|/* are we current address space or kernel? */
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
return|return
operator|(
name|vtopte
argument_list|(
name|va
argument_list|)
operator|)
return|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|curthread
operator|->
name|td_pinned
operator|>
literal|0
argument_list|,
operator|(
literal|"curthread not pinned"
operator|)
argument_list|)
expr_stmt|;
name|newpf
operator|=
operator|*
name|pde
operator|&
name|PG_FRAME
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|PMAP1
operator|&
name|PG_FRAME
operator|)
operator|!=
name|newpf
condition|)
block|{
operator|*
name|PMAP1
operator|=
name|newpf
operator||
name|PG_RW
operator||
name|PG_V
operator||
name|PG_A
operator||
name|PG_M
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|PMAP1cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|invlcaddr
argument_list|(
name|PADDR1
argument_list|)
expr_stmt|;
name|PMAP1changed
operator|++
expr_stmt|;
block|}
elseif|else
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|PMAP1cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
block|{
name|PMAP1cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|invlcaddr
argument_list|(
name|PADDR1
argument_list|)
expr_stmt|;
name|PMAP1changedcpu
operator|++
expr_stmt|;
block|}
else|else
endif|#
directive|endif
name|PMAP1unchanged
operator|++
expr_stmt|;
return|return
operator|(
name|PADDR1
operator|+
operator|(
name|i386_btop
argument_list|(
name|va
argument_list|)
operator|&
operator|(
name|NPTEPG
operator|-
literal|1
operator|)
operator|)
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Routine:	pmap_extract  *	Function:  *		Extract the physical page address associated  *		with the given map/virtual_address pair.  */
end_comment

begin_function
name|vm_paddr_t
name|pmap_extract
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|vm_paddr_t
name|rtval
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pd_entry_t
name|pde
decl_stmt|;
name|rtval
operator|=
literal|0
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|va
operator|>>
name|PDRSHIFT
index|]
expr_stmt|;
if|if
condition|(
name|pde
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
name|rtval
operator|=
operator|(
name|pde
operator|&
name|PG_PS_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PDRMASK
operator|)
expr_stmt|;
else|else
block|{
name|pte
operator|=
name|pmap_pte
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|rtval
operator|=
operator|(
operator|*
name|pte
operator|&
name|PG_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PAGE_MASK
operator|)
expr_stmt|;
name|pmap_pte_release
argument_list|(
name|pte
argument_list|)
expr_stmt|;
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|rtval
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Routine:	pmap_extract_and_hold  *	Function:  *		Atomically extract and hold the physical page  *		with the given pmap and virtual address pair  *		if that mapping permits the given protection.  */
end_comment

begin_function
name|vm_page_t
name|pmap_extract_and_hold
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|pd_entry_t
name|pde
decl_stmt|;
name|pt_entry_t
name|pte
decl_stmt|,
modifier|*
name|ptep
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
name|m
operator|=
name|NULL
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|pde
operator|=
operator|*
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pde
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|pde
operator|&
name|PG_PS
condition|)
block|{
if|if
condition|(
operator|(
name|pde
operator|&
name|PG_RW
operator|)
operator|||
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
operator|(
name|pde
operator|&
name|PG_PS_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PDRMASK
operator|)
argument_list|,
operator|&
name|pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|(
name|pde
operator|&
name|PG_PS_FRAME
operator|)
operator||
operator|(
name|va
operator|&
name|PDRMASK
operator|)
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|ptep
operator|=
name|pmap_pte
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pte
operator|=
operator|*
name|ptep
expr_stmt|;
name|pmap_pte_release
argument_list|(
name|ptep
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte
operator|!=
literal|0
operator|&&
operator|(
operator|(
name|pte
operator|&
name|PG_RW
operator|)
operator|||
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
operator|)
condition|)
block|{
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|pte
operator|&
name|PG_FRAME
argument_list|,
operator|&
name|pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|vm_page_hold
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|PA_UNLOCK_COND
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/***************************************************  * Low level mapping routines.....  ***************************************************/
end_comment

begin_comment
comment|/*  * Add a wired page to the kva.  * Note: not SMP coherent.  *  * This function may be used before pmap_bootstrap() is called.  */
end_comment

begin_function
name|PMAP_INLINE
name|void
name|pmap_kenter
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte_store
argument_list|(
name|pte
argument_list|,
name|pa
operator||
name|PG_RW
operator||
name|PG_V
operator||
name|pgeflag
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|void
name|pmap_kenter_attr
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|,
name|int
name|mode
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte_store
argument_list|(
name|pte
argument_list|,
name|pa
operator||
name|PG_RW
operator||
name|PG_V
operator||
name|pgeflag
operator||
name|pmap_cache_bits
argument_list|(
name|mode
argument_list|,
literal|0
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Remove a page from the kernel pagetables.  * Note: not SMP coherent.  *  * This function may be used before pmap_bootstrap() is called.  */
end_comment

begin_function
name|PMAP_INLINE
name|void
name|pmap_kremove
parameter_list|(
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte_clear
argument_list|(
name|pte
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Used to map a range of physical addresses into kernel  *	virtual address space.  *  *	The value passed in '*virt' is a suggested virtual address for  *	the mapping. Architectures which can support a direct-mapped  *	physical to virtual region can return the appropriate address  *	within that region, leaving '*virt' unchanged. Other  *	architectures should map the pages starting at '*virt' and  *	update '*virt' with the first usable address after the mapped  *	region.  */
end_comment

begin_function
name|vm_offset_t
name|pmap_map
parameter_list|(
name|vm_offset_t
modifier|*
name|virt
parameter_list|,
name|vm_paddr_t
name|start
parameter_list|,
name|vm_paddr_t
name|end
parameter_list|,
name|int
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|,
name|sva
decl_stmt|;
name|vm_paddr_t
name|superpage_offset
decl_stmt|;
name|pd_entry_t
name|newpde
decl_stmt|;
name|va
operator|=
operator|*
name|virt
expr_stmt|;
comment|/* 	 * Does the physical address range's size and alignment permit at 	 * least one superpage mapping to be created? 	 */
name|superpage_offset
operator|=
name|start
operator|&
name|PDRMASK
expr_stmt|;
if|if
condition|(
operator|(
name|end
operator|-
name|start
operator|)
operator|-
operator|(
operator|(
name|NBPDR
operator|-
name|superpage_offset
operator|)
operator|&
name|PDRMASK
operator|)
operator|>=
name|NBPDR
condition|)
block|{
comment|/* 		 * Increase the starting virtual address so that its alignment 		 * does not preclude the use of superpage mappings. 		 */
if|if
condition|(
operator|(
name|va
operator|&
name|PDRMASK
operator|)
operator|<
name|superpage_offset
condition|)
name|va
operator|=
operator|(
name|va
operator|&
operator|~
name|PDRMASK
operator|)
operator|+
name|superpage_offset
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|va
operator|&
name|PDRMASK
operator|)
operator|>
name|superpage_offset
condition|)
name|va
operator|=
operator|(
operator|(
name|va
operator|+
name|PDRMASK
operator|)
operator|&
operator|~
name|PDRMASK
operator|)
operator|+
name|superpage_offset
expr_stmt|;
block|}
name|sva
operator|=
name|va
expr_stmt|;
while|while
condition|(
name|start
operator|<
name|end
condition|)
block|{
if|if
condition|(
operator|(
name|start
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
operator|&&
name|end
operator|-
name|start
operator|>=
name|NBPDR
operator|&&
name|pseflag
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|va
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_map: misaligned va %#x"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
name|newpde
operator|=
name|start
operator||
name|PG_PS
operator||
name|pgeflag
operator||
name|PG_RW
operator||
name|PG_V
expr_stmt|;
name|pmap_kenter_pde
argument_list|(
name|va
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
name|va
operator|+=
name|NBPDR
expr_stmt|;
name|start
operator|+=
name|NBPDR
expr_stmt|;
block|}
else|else
block|{
name|pmap_kenter
argument_list|(
name|va
argument_list|,
name|start
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|start
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|va
argument_list|)
expr_stmt|;
operator|*
name|virt
operator|=
name|va
expr_stmt|;
return|return
operator|(
name|sva
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Add a list of wired pages to the kva  * this routine is only used for temporary  * kernel mappings that do not need to have  * page modification or references recorded.  * Note that old mappings are simply written  * over.  The page *must* be wired.  * Note: SMP coherent.  Uses a ranged shootdown IPI.  */
end_comment

begin_function
name|void
name|pmap_qenter
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|vm_page_t
modifier|*
name|ma
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|endpte
decl_stmt|,
name|oldpte
decl_stmt|,
name|pa
decl_stmt|,
modifier|*
name|pte
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|oldpte
operator|=
literal|0
expr_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|sva
argument_list|)
expr_stmt|;
name|endpte
operator|=
name|pte
operator|+
name|count
expr_stmt|;
while|while
condition|(
name|pte
operator|<
name|endpte
condition|)
block|{
name|m
operator|=
operator|*
name|ma
operator|++
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|pmap_cache_bits
argument_list|(
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_FRAME
operator||
name|PG_PTE_CACHE
operator|)
operator|)
operator|!=
name|pa
condition|)
block|{
name|oldpte
operator||=
operator|*
name|pte
expr_stmt|;
name|pte_store
argument_list|(
name|pte
argument_list|,
name|pa
operator||
name|pgeflag
operator||
name|PG_RW
operator||
name|PG_V
argument_list|)
expr_stmt|;
block|}
name|pte
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|__predict_false
argument_list|(
operator|(
name|oldpte
operator|&
name|PG_V
operator|)
operator|!=
literal|0
argument_list|)
condition|)
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|sva
operator|+
name|count
operator|*
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * This routine tears out page mappings from the  * kernel -- it is meant only for temporary mappings.  * Note: SMP coherent.  Uses a ranged shootdown IPI.  */
end_comment

begin_function
name|void
name|pmap_qremove
parameter_list|(
name|vm_offset_t
name|sva
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|va
operator|=
name|sva
expr_stmt|;
while|while
condition|(
name|count
operator|--
operator|>
literal|0
condition|)
block|{
name|pmap_kremove
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/***************************************************  * Page table page management routines.....  ***************************************************/
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_free_zero_pages
parameter_list|(
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
while|while
condition|(
operator|(
name|m
operator|=
name|SLIST_FIRST
argument_list|(
name|free
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|SLIST_REMOVE_HEAD
argument_list|(
name|free
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
comment|/* Preserve the page's PG_ZERO setting. */
name|vm_page_free_toq
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Schedule the specified unused page table page to be freed.  Specifically,  * add the page to the specified list of pages that will be released to the  * physical memory manager after the TLB has been updated.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_add_delayed_free_list
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|,
name|boolean_t
name|set_PG_ZERO
parameter_list|)
block|{
if|if
condition|(
name|set_PG_ZERO
condition|)
name|m
operator|->
name|flags
operator||=
name|PG_ZERO
expr_stmt|;
else|else
name|m
operator|->
name|flags
operator|&=
operator|~
name|PG_ZERO
expr_stmt|;
name|SLIST_INSERT_HEAD
argument_list|(
name|free
argument_list|,
name|m
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Inserts the specified page table page into the specified pmap's collection  * of idle page table pages.  Each of a pmap's page table pages is responsible  * for mapping a distinct range of virtual addresses.  The pmap's collection is  * ordered by this virtual address range.  */
end_comment

begin_function
specifier|static
name|__inline
name|int
name|pmap_insert_pt_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|mpte
parameter_list|)
block|{
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
name|vm_radix_insert
argument_list|(
operator|&
name|pmap
operator|->
name|pm_root
argument_list|,
name|mpte
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Removes the page table page mapping the specified virtual address from the  * specified pmap's collection of idle page table pages, and returns it.  * Otherwise, returns NULL if there is no page table page corresponding to the  * specified virtual address.  */
end_comment

begin_function
specifier|static
name|__inline
name|vm_page_t
name|pmap_remove_pt_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
return|return
operator|(
name|vm_radix_remove
argument_list|(
operator|&
name|pmap
operator|->
name|pm_root
argument_list|,
name|va
operator|>>
name|PDRSHIFT
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Decrements a page table page's wire count, which is used to record the  * number of valid page table entries within the page.  If the wire count  * drops to zero, then the page table page is unmapped.  Returns TRUE if the  * page table page was unmapped and FALSE otherwise.  */
end_comment

begin_function
specifier|static
specifier|inline
name|boolean_t
name|pmap_unwire_ptp
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
operator|--
name|m
operator|->
name|wire_count
expr_stmt|;
if|if
condition|(
name|m
operator|->
name|wire_count
operator|==
literal|0
condition|)
block|{
name|_pmap_unwire_ptp
argument_list|(
name|pmap
argument_list|,
name|m
argument_list|,
name|free
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|_pmap_unwire_ptp
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|vm_offset_t
name|pteva
decl_stmt|;
comment|/* 	 * unmap the page table page 	 */
name|pmap
operator|->
name|pm_pdir
index|[
name|m
operator|->
name|pindex
index|]
operator|=
literal|0
expr_stmt|;
operator|--
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
expr_stmt|;
comment|/* 	 * This is a release store so that the ordinary store unmapping 	 * the page table page is globally performed before TLB shoot- 	 * down is begun. 	 */
name|atomic_subtract_rel_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|/* 	 * Do an invltlb to make the invalidated mapping 	 * take effect immediately. 	 */
name|pteva
operator|=
name|VM_MAXUSER_ADDRESS
operator|+
name|i386_ptob
argument_list|(
name|m
operator|->
name|pindex
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pteva
argument_list|)
expr_stmt|;
comment|/*  	 * Put page on a list so that it is released after 	 * *ALL* TLB shootdown is done 	 */
name|pmap_add_delayed_free_list
argument_list|(
name|m
argument_list|,
name|free
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * After removing a page table entry, this routine is used to  * conditionally free the page, and manage the hold/wire counts.  */
end_comment

begin_function
specifier|static
name|int
name|pmap_unuse_pt
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|pd_entry_t
name|ptepde
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
if|if
condition|(
name|va
operator|>=
name|VM_MAXUSER_ADDRESS
condition|)
return|return
operator|(
literal|0
operator|)
return|;
name|ptepde
operator|=
operator|*
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|ptepde
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
return|return
operator|(
name|pmap_unwire_ptp
argument_list|(
name|pmap
argument_list|,
name|mpte
argument_list|,
name|free
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Initialize the pmap for the swapper process.  */
end_comment

begin_function
name|void
name|pmap_pinit0
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|PMAP_LOCK_INIT
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Since the page table directory is shared with the kernel pmap, 	 * which is already included in the list "allpmaps", this pmap does 	 * not need to be inserted into that list. 	 */
name|pmap
operator|->
name|pm_pdir
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
operator|(
name|KERNBASE
operator|+
operator|(
name|vm_offset_t
operator|)
name|IdlePTD
operator|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
name|pmap
operator|->
name|pm_pdpt
operator|=
operator|(
name|pdpt_entry_t
operator|*
operator|)
operator|(
name|KERNBASE
operator|+
operator|(
name|vm_offset_t
operator|)
name|IdlePDPT
operator|)
expr_stmt|;
endif|#
directive|endif
name|pmap
operator|->
name|pm_root
operator|.
name|rt_root
operator|=
literal|0
expr_stmt|;
name|CPU_ZERO
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pmap
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
name|pmap
operator|->
name|pm_stats
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Initialize a preallocated and zeroed pmap structure,  * such as one in a vmspace structure.  */
end_comment

begin_function
name|int
name|pmap_pinit
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|,
name|ptdpg
index|[
name|NPGPTD
index|]
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|int
name|i
decl_stmt|;
comment|/* 	 * No need to allocate page table space yet but we do need a valid 	 * page directory table. 	 */
if|if
condition|(
name|pmap
operator|->
name|pm_pdir
operator|==
name|NULL
condition|)
block|{
name|pmap
operator|->
name|pm_pdir
operator|=
operator|(
name|pd_entry_t
operator|*
operator|)
name|kva_alloc
argument_list|(
name|NBPTD
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_pdir
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
name|pmap
operator|->
name|pm_pdpt
operator|=
name|uma_zalloc
argument_list|(
name|pdptzone
argument_list|,
name|M_WAITOK
operator||
name|M_ZERO
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|(
name|vm_offset_t
operator|)
name|pmap
operator|->
name|pm_pdpt
operator|&
operator|(
operator|(
name|NPGPTD
operator|*
sizeof|sizeof
argument_list|(
name|pdpt_entry_t
argument_list|)
operator|)
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_pinit: pdpt misaligned"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pmap_kextract
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pmap
operator|->
name|pm_pdpt
argument_list|)
operator|<
operator|(
literal|4ULL
operator|<<
literal|30
operator|)
argument_list|,
operator|(
literal|"pmap_pinit: pdpt above 4g"
operator|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|pmap
operator|->
name|pm_root
operator|.
name|rt_root
operator|=
literal|0
expr_stmt|;
block|}
name|KASSERT
argument_list|(
name|vm_radix_is_empty
argument_list|(
operator|&
name|pmap
operator|->
name|pm_root
argument_list|)
argument_list|,
operator|(
literal|"pmap_pinit: pmap has reserved page table page(s)"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * allocate the page directory page(s) 	 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPGPTD
condition|;
control|)
block|{
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
name|VM_WAIT
expr_stmt|;
else|else
block|{
name|ptdpg
index|[
name|i
operator|++
index|]
operator|=
name|m
expr_stmt|;
block|}
block|}
name|pmap_qenter
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pmap
operator|->
name|pm_pdir
argument_list|,
name|ptdpg
argument_list|,
name|NPGPTD
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPGPTD
condition|;
name|i
operator|++
control|)
if|if
condition|(
operator|(
name|ptdpg
index|[
name|i
index|]
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pagezero
argument_list|(
name|pmap
operator|->
name|pm_pdir
operator|+
operator|(
name|i
operator|*
name|NPDEPG
operator|)
argument_list|)
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|allpmaps
argument_list|,
name|pmap
argument_list|,
name|pm_list
argument_list|)
expr_stmt|;
comment|/* Copy the kernel page table directory entries. */
name|bcopy
argument_list|(
name|PTD
operator|+
name|KPTDI
argument_list|,
name|pmap
operator|->
name|pm_pdir
operator|+
name|KPTDI
argument_list|,
name|nkpt
operator|*
sizeof|sizeof
argument_list|(
name|pd_entry_t
argument_list|)
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
comment|/* install self-referential address mapping entry(s) */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPGPTD
condition|;
name|i
operator|++
control|)
block|{
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|ptdpg
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_pdir
index|[
name|PTDPTDI
operator|+
name|i
index|]
operator|=
name|pa
operator||
name|PG_V
operator||
name|PG_RW
operator||
name|PG_A
operator||
name|PG_M
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
name|pmap
operator|->
name|pm_pdpt
index|[
name|i
index|]
operator|=
name|pa
operator||
name|PG_V
expr_stmt|;
endif|#
directive|endif
block|}
name|CPU_ZERO
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|&
name|pmap
operator|->
name|pm_stats
argument_list|,
sizeof|sizeof
name|pmap
operator|->
name|pm_stats
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * this routine is called if the page table page is not  * mapped correctly.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|_pmap_allocpte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|u_int
name|ptepindex
parameter_list|,
name|u_int
name|flags
parameter_list|)
block|{
name|vm_paddr_t
name|ptepa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
comment|/* 	 * Allocate a page table page. 	 */
if|if
condition|(
operator|(
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|ptepindex
argument_list|,
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
operator|(
name|flags
operator|&
name|PMAP_ENTER_NOSLEEP
operator|)
operator|==
literal|0
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|VM_WAIT
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Indicate the need to retry.  While waiting, the page table 		 * page may have been allocated. 		 */
return|return
operator|(
name|NULL
operator|)
return|;
block|}
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
comment|/* 	 * Map the pagetable page into the process address space, if 	 * it isn't already there. 	 */
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
name|ptepa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_pdir
index|[
name|ptepindex
index|]
operator|=
call|(
name|pd_entry_t
call|)
argument_list|(
name|ptepa
operator||
name|PG_U
operator||
name|PG_RW
operator||
name|PG_V
operator||
name|PG_A
operator||
name|PG_M
argument_list|)
expr_stmt|;
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|vm_page_t
name|pmap_allocpte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|u_int
name|flags
parameter_list|)
block|{
name|u_int
name|ptepindex
decl_stmt|;
name|pd_entry_t
name|ptepa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
comment|/* 	 * Calculate pagetable page index 	 */
name|ptepindex
operator|=
name|va
operator|>>
name|PDRSHIFT
expr_stmt|;
name|retry
label|:
comment|/* 	 * Get the page directory entry 	 */
name|ptepa
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|ptepindex
index|]
expr_stmt|;
comment|/* 	 * This supports switching from a 4MB page to a 	 * normal 4K page. 	 */
if|if
condition|(
name|ptepa
operator|&
name|PG_PS
condition|)
block|{
operator|(
name|void
operator|)
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
operator|&
name|pmap
operator|->
name|pm_pdir
index|[
name|ptepindex
index|]
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|ptepa
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|ptepindex
index|]
expr_stmt|;
block|}
comment|/* 	 * If the page table page is mapped, we just increment the 	 * hold count, and activate it. 	 */
if|if
condition|(
name|ptepa
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|ptepa
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|m
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Here if the pte page isn't mapped, or if it has 		 * been deallocated.  		 */
name|m
operator|=
name|_pmap_allocpte
argument_list|(
name|pmap
argument_list|,
name|ptepindex
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
operator|&&
operator|(
name|flags
operator|&
name|PMAP_ENTER_NOSLEEP
operator|)
operator|==
literal|0
condition|)
goto|goto
name|retry
goto|;
block|}
return|return
operator|(
name|m
operator|)
return|;
block|}
end_function

begin_comment
comment|/*************************************************** * Pmap allocation/deallocation routines.  ***************************************************/
end_comment

begin_comment
comment|/*  * Release any resources held by the given physical map.  * Called when a pmap initialized by pmap_pinit is being released.  * Should only be called if the map contains no valid mappings.  */
end_comment

begin_function
name|void
name|pmap_release
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|,
name|ptdpg
index|[
name|NPGPTD
index|]
decl_stmt|;
name|int
name|i
decl_stmt|;
name|KASSERT
argument_list|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_release: pmap resident count %ld != 0"
operator|,
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|vm_radix_is_empty
argument_list|(
operator|&
name|pmap
operator|->
name|pm_root
argument_list|)
argument_list|,
operator|(
literal|"pmap_release: pmap has reserved page table page(s)"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|CPU_EMPTY
argument_list|(
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
argument_list|,
operator|(
literal|"releasing active pmap %p"
operator|,
name|pmap
operator|)
argument_list|)
expr_stmt|;
name|mtx_lock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
name|LIST_REMOVE
argument_list|(
name|pmap
argument_list|,
name|pm_list
argument_list|)
expr_stmt|;
name|mtx_unlock_spin
argument_list|(
operator|&
name|allpmaps_lock
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPGPTD
condition|;
name|i
operator|++
control|)
name|ptdpg
index|[
name|i
index|]
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pmap
operator|->
name|pm_pdir
index|[
name|PTDPTDI
operator|+
name|i
index|]
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
name|pmap
operator|->
name|pm_pdir
operator|+
name|PTDPTDI
argument_list|,
operator|(
name|nkpt
operator|+
name|NPGPTD
operator|)
operator|*
sizeof|sizeof
argument_list|(
operator|*
name|pmap
operator|->
name|pm_pdir
argument_list|)
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pmap
operator|->
name|pm_pdir
argument_list|,
name|NPGPTD
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPGPTD
condition|;
name|i
operator|++
control|)
block|{
name|m
operator|=
name|ptdpg
index|[
name|i
index|]
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
name|KASSERT
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator|==
operator|(
name|pmap
operator|->
name|pm_pdpt
index|[
name|i
index|]
operator|&
name|PG_FRAME
operator|)
argument_list|,
operator|(
literal|"pmap_release: got wrong ptd page"
operator|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|m
operator|->
name|wire_count
operator|--
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_free_zero
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_escape
end_escape

begin_function
specifier|static
name|int
name|kvm_size
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|unsigned
name|long
name|ksize
init|=
name|VM_MAX_KERNEL_ADDRESS
operator|-
name|KERNBASE
decl_stmt|;
return|return
operator|(
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
operator|&
name|ksize
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
operator|)
return|;
block|}
end_function

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|kvm_size
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|kvm_size
argument_list|,
literal|"IU"
argument_list|,
literal|"Size of KVM"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_function
specifier|static
name|int
name|kvm_free
parameter_list|(
name|SYSCTL_HANDLER_ARGS
parameter_list|)
block|{
name|unsigned
name|long
name|kfree
init|=
name|VM_MAX_KERNEL_ADDRESS
operator|-
name|kernel_vm_end
decl_stmt|;
return|return
operator|(
name|sysctl_handle_long
argument_list|(
name|oidp
argument_list|,
operator|&
name|kfree
argument_list|,
literal|0
argument_list|,
name|req
argument_list|)
operator|)
return|;
block|}
end_function

begin_expr_stmt
name|SYSCTL_PROC
argument_list|(
name|_vm
argument_list|,
name|OID_AUTO
argument_list|,
name|kvm_free
argument_list|,
name|CTLTYPE_LONG
operator||
name|CTLFLAG_RD
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|kvm_free
argument_list|,
literal|"IU"
argument_list|,
literal|"Amount of KVM free"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * grow the number of kernel page table entries, if needed  */
end_comment

begin_function
name|void
name|pmap_growkernel
parameter_list|(
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|vm_paddr_t
name|ptppaddr
decl_stmt|;
name|vm_page_t
name|nkpg
decl_stmt|;
name|pd_entry_t
name|newpdir
decl_stmt|;
name|mtx_assert
argument_list|(
operator|&
name|kernel_map
operator|->
name|system_mtx
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|addr
operator|=
name|roundup2
argument_list|(
name|addr
argument_list|,
name|NBPDR
argument_list|)
expr_stmt|;
if|if
condition|(
name|addr
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
name|addr
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
while|while
condition|(
name|kernel_vm_end
operator|<
name|addr
condition|)
block|{
if|if
condition|(
name|pdir_pde
argument_list|(
name|PTD
argument_list|,
name|kernel_vm_end
argument_list|)
condition|)
block|{
name|kernel_vm_end
operator|=
operator|(
name|kernel_vm_end
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|kernel_vm_end
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
block|{
name|kernel_vm_end
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
break|break;
block|}
continue|continue;
block|}
name|nkpg
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|kernel_vm_end
operator|>>
name|PDRSHIFT
argument_list|,
name|VM_ALLOC_INTERRUPT
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
operator||
name|VM_ALLOC_ZERO
argument_list|)
expr_stmt|;
if|if
condition|(
name|nkpg
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_growkernel: no memory to grow kernel"
argument_list|)
expr_stmt|;
name|nkpt
operator|++
expr_stmt|;
if|if
condition|(
operator|(
name|nkpg
operator|->
name|flags
operator|&
name|PG_ZERO
operator|)
operator|==
literal|0
condition|)
name|pmap_zero_page
argument_list|(
name|nkpg
argument_list|)
expr_stmt|;
name|ptppaddr
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|nkpg
argument_list|)
expr_stmt|;
name|newpdir
operator|=
call|(
name|pd_entry_t
call|)
argument_list|(
name|ptppaddr
operator||
name|PG_V
operator||
name|PG_RW
operator||
name|PG_A
operator||
name|PG_M
argument_list|)
expr_stmt|;
name|pdir_pde
argument_list|(
name|KPTD
argument_list|,
name|kernel_vm_end
argument_list|)
operator|=
name|pgeflag
operator||
name|newpdir
expr_stmt|;
name|pmap_kenter_pde
argument_list|(
name|kernel_vm_end
argument_list|,
name|newpdir
argument_list|)
expr_stmt|;
name|kernel_vm_end
operator|=
operator|(
name|kernel_vm_end
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|kernel_vm_end
operator|-
literal|1
operator|>=
name|kernel_map
operator|->
name|max_offset
condition|)
block|{
name|kernel_vm_end
operator|=
name|kernel_map
operator|->
name|max_offset
expr_stmt|;
break|break;
block|}
block|}
block|}
end_function

begin_comment
comment|/***************************************************  * page management routines.  ***************************************************/
end_comment

begin_expr_stmt
name|CTASSERT
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|pv_chunk
argument_list|)
operator|==
name|PAGE_SIZE
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|_NPCM
operator|==
literal|11
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|CTASSERT
argument_list|(
name|_NPCPV
operator|==
literal|336
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
specifier|static
name|__inline
expr|struct
name|pv_chunk
operator|*
name|pv_to_chunk
argument_list|(
argument|pv_entry_t pv
argument_list|)
block|{
return|return
operator|(
operator|(
expr|struct
name|pv_chunk
operator|*
operator|)
operator|(
operator|(
name|uintptr_t
operator|)
name|pv
operator|&
operator|~
operator|(
name|uintptr_t
operator|)
name|PAGE_MASK
operator|)
operator|)
return|;
block|}
end_expr_stmt

begin_define
define|#
directive|define
name|PV_PMAP
parameter_list|(
name|pv
parameter_list|)
value|(pv_to_chunk(pv)->pc_pmap)
end_define

begin_define
define|#
directive|define
name|PC_FREE0_9
value|0xfffffffful
end_define

begin_comment
comment|/* Free values for index 0 through 9 */
end_comment

begin_define
define|#
directive|define
name|PC_FREE10
value|0x0000fffful
end_define

begin_comment
comment|/* Free values for index 10 */
end_comment

begin_decl_stmt
specifier|static
specifier|const
name|uint32_t
name|pc_freemask
index|[
name|_NPCM
index|]
init|=
block|{
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE0_9
block|,
name|PC_FREE10
block|}
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_count
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_count
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entries"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_ifdef
ifdef|#
directive|ifdef
name|PV_STATS
end_ifdef

begin_decl_stmt
specifier|static
name|int
name|pc_chunk_count
decl_stmt|,
name|pc_chunk_allocs
decl_stmt|,
name|pc_chunk_frees
decl_stmt|,
name|pc_chunk_tryfail
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_count
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_count
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry chunks"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_allocs
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_allocs
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry chunks allocated"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_frees
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_frees
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry chunks frees"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pc_chunk_tryfail
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pc_chunk_tryfail
argument_list|,
literal|0
argument_list|,
literal|"Number of times tried to get a chunk page but failed."
argument_list|)
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|static
name|long
name|pv_entry_frees
decl_stmt|,
name|pv_entry_allocs
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|static
name|int
name|pv_entry_spare
decl_stmt|;
end_decl_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_frees
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_frees
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry frees"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_LONG
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_allocs
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_allocs
argument_list|,
literal|0
argument_list|,
literal|"Current number of pv entry allocs"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_expr_stmt
name|SYSCTL_INT
argument_list|(
name|_vm_pmap
argument_list|,
name|OID_AUTO
argument_list|,
name|pv_entry_spare
argument_list|,
name|CTLFLAG_RD
argument_list|,
operator|&
name|pv_entry_spare
argument_list|,
literal|0
argument_list|,
literal|"Current number of spare pv entries"
argument_list|)
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * We are in a serious low memory condition.  Resort to  * drastic measures to free some pages so we can allocate  * another pv entry chunk.  */
end_comment

begin_function
specifier|static
name|vm_page_t
name|pmap_pv_reclaim
parameter_list|(
name|pmap_t
name|locked_pmap
parameter_list|)
block|{
name|struct
name|pch
name|newtail
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|tpte
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|m_pc
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|uint32_t
name|inuse
decl_stmt|;
name|int
name|bit
decl_stmt|,
name|field
decl_stmt|,
name|freed
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|locked_pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pmap
operator|=
name|NULL
expr_stmt|;
name|m_pc
operator|=
name|NULL
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|TAILQ_INIT
argument_list|(
operator|&
name|newtail
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|pc
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pv_chunks
argument_list|)
operator|)
operator|!=
name|NULL
operator|&&
operator|(
name|pv_vafree
operator|==
literal|0
operator|||
name|SLIST_EMPTY
argument_list|(
operator|&
name|free
argument_list|)
operator|)
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|pc
operator|->
name|pc_pmap
condition|)
block|{
if|if
condition|(
name|pmap
operator|!=
name|NULL
condition|)
block|{
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|locked_pmap
condition|)
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|pmap
operator|=
name|pc
operator|->
name|pc_pmap
expr_stmt|;
comment|/* Avoid deadlock and lock recursion. */
if|if
condition|(
name|pmap
operator|>
name|locked_pmap
condition|)
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|pmap
operator|!=
name|locked_pmap
operator|&&
operator|!
name|PMAP_TRYLOCK
argument_list|(
name|pmap
argument_list|)
condition|)
block|{
name|pmap
operator|=
name|NULL
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|newtail
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
continue|continue;
block|}
block|}
comment|/* 		 * Destroy every non-wired, 4 KB page mapping in the chunk. 		 */
name|freed
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
for|for
control|(
name|inuse
operator|=
operator|~
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&
name|pc_freemask
index|[
name|field
index|]
init|;
name|inuse
operator|!=
literal|0
condition|;
name|inuse
operator|&=
operator|~
operator|(
literal|1UL
operator|<<
name|bit
operator|)
control|)
block|{
name|bit
operator|=
name|bsfl
argument_list|(
name|inuse
argument_list|)
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|field
operator|*
literal|32
operator|+
name|bit
index|]
expr_stmt|;
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
continue|continue;
name|pte
operator|=
name|pmap_pte
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|tpte
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
name|tpte
operator|=
name|pte_load_clear
argument_list|(
name|pte
argument_list|)
expr_stmt|;
name|pmap_pte_release
argument_list|(
name|pte
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_W
operator|)
operator|!=
literal|0
condition|)
continue|continue;
name|KASSERT
argument_list|(
name|tpte
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_pv_reclaim: pmap %p va %x zero pte"
operator|,
name|pmap
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_G
operator|)
operator|!=
literal|0
condition|)
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|tpte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
block|{
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
block|}
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
literal|1UL
operator|<<
name|bit
expr_stmt|;
name|pmap_unuse_pt
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
name|freed
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|freed
operator|==
literal|0
condition|)
block|{
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|newtail
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|/* Every freed mapping is for a 4 KB page. */
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|-=
name|freed
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_frees
operator|+=
name|freed
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|+=
name|freed
argument_list|)
expr_stmt|;
name|pv_entry_count
operator|-=
name|freed
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|!=
name|pc_freemask
index|[
name|field
index|]
condition|)
block|{
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|newtail
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
comment|/* 				 * One freed pv entry in locked_pmap is 				 * sufficient. 				 */
if|if
condition|(
name|pmap
operator|==
name|locked_pmap
condition|)
goto|goto
name|out
goto|;
break|break;
block|}
if|if
condition|(
name|field
operator|==
name|_NPCM
condition|)
block|{
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|-=
name|_NPCPV
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_count
operator|--
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_frees
operator|++
argument_list|)
expr_stmt|;
comment|/* Entire chunk is free; return it. */
name|m_pc
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pmap_kextract
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|pmap_ptelist_free
argument_list|(
operator|&
name|pv_vafree
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
name|out
label|:
name|TAILQ_CONCAT
argument_list|(
operator|&
name|pv_chunks
argument_list|,
operator|&
name|newtail
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|NULL
condition|)
block|{
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|locked_pmap
condition|)
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|m_pc
operator|==
name|NULL
operator|&&
name|pv_vafree
operator|!=
literal|0
operator|&&
name|SLIST_EMPTY
argument_list|(
operator|&
name|free
argument_list|)
condition|)
block|{
name|m_pc
operator|=
name|SLIST_FIRST
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|SLIST_REMOVE_HEAD
argument_list|(
operator|&
name|free
argument_list|,
name|plinks
operator|.
name|s
operator|.
name|ss
argument_list|)
expr_stmt|;
comment|/* Recycle a freed page table page. */
name|m_pc
operator|->
name|wire_count
operator|=
literal|1
expr_stmt|;
name|atomic_add_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
return|return
operator|(
name|m_pc
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * free the pv_entry back to the free list  */
end_comment

begin_function
specifier|static
name|void
name|free_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pv_entry_t
name|pv
parameter_list|)
block|{
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|int
name|idx
decl_stmt|,
name|field
decl_stmt|,
name|bit
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_frees
operator|++
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|++
argument_list|)
expr_stmt|;
name|pv_entry_count
operator|--
expr_stmt|;
name|pc
operator|=
name|pv_to_chunk
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|idx
operator|=
name|pv
operator|-
operator|&
name|pc
operator|->
name|pc_pventry
index|[
literal|0
index|]
expr_stmt|;
name|field
operator|=
name|idx
operator|/
literal|32
expr_stmt|;
name|bit
operator|=
name|idx
operator|%
literal|32
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
literal|1ul
operator|<<
name|bit
expr_stmt|;
for|for
control|(
name|idx
operator|=
literal|0
init|;
name|idx
operator|<
name|_NPCM
condition|;
name|idx
operator|++
control|)
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
name|idx
index|]
operator|!=
name|pc_freemask
index|[
name|idx
index|]
condition|)
block|{
comment|/* 			 * 98% of the time, pc is already at the head of the 			 * list.  If it isn't already, move it to the head. 			 */
if|if
condition|(
name|__predict_false
argument_list|(
name|TAILQ_FIRST
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
operator|!=
name|pc
argument_list|)
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|free_pv_chunk
argument_list|(
name|pc
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|free_pv_chunk
parameter_list|(
name|struct
name|pv_chunk
modifier|*
name|pc
parameter_list|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|-=
name|_NPCPV
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_count
operator|--
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_frees
operator|++
argument_list|)
expr_stmt|;
comment|/* entire chunk is free, return it */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pmap_kextract
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
argument_list|)
expr_stmt|;
name|pmap_qremove
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|vm_page_unwire
argument_list|(
name|m
argument_list|,
name|PQ_NONE
argument_list|)
expr_stmt|;
name|vm_page_free
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_ptelist_free
argument_list|(
operator|&
name|pv_vafree
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * get a new pv_entry, allocating a block from the system  * when needed.  */
end_comment

begin_function
specifier|static
name|pv_entry_t
name|get_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|boolean_t
name|try
parameter_list|)
block|{
specifier|static
specifier|const
name|struct
name|timeval
name|printinterval
init|=
block|{
literal|60
block|,
literal|0
block|}
decl_stmt|;
specifier|static
name|struct
name|timeval
name|lastprint
decl_stmt|;
name|int
name|bit
decl_stmt|,
name|field
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_allocs
operator|++
argument_list|)
expr_stmt|;
name|pv_entry_count
operator|++
expr_stmt|;
if|if
condition|(
name|pv_entry_count
operator|>
name|pv_entry_high_water
condition|)
if|if
condition|(
name|ratecheck
argument_list|(
operator|&
name|lastprint
argument_list|,
operator|&
name|printinterval
argument_list|)
condition|)
name|printf
argument_list|(
literal|"Approaching the limit on PV entries, consider "
literal|"increasing either the vm.pmap.shpgperproc or the "
literal|"vm.pmap.pv_entry_max tunable.\n"
argument_list|)
expr_stmt|;
name|retry
label|:
name|pc
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|)
expr_stmt|;
if|if
condition|(
name|pc
operator|!=
name|NULL
condition|)
block|{
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
condition|)
block|{
name|bit
operator|=
name|bsfl
argument_list|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|field
operator|<
name|_NPCM
condition|)
block|{
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|field
operator|*
literal|32
operator|+
name|bit
index|]
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&=
operator|~
operator|(
literal|1ul
operator|<<
name|bit
operator|)
expr_stmt|;
comment|/* If this was the last item, move it to tail */
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
if|if
condition|(
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|!=
literal|0
condition|)
block|{
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|--
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
comment|/* not full, return */
block|}
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|--
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
block|}
block|}
comment|/* 	 * Access to the ptelist "pv_vafree" is synchronized by the pvh 	 * global lock.  If "pv_vafree" is currently non-empty, it will 	 * remain non-empty until pmap_ptelist_alloc() completes. 	 */
if|if
condition|(
name|pv_vafree
operator|==
literal|0
operator|||
operator|(
name|m
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
literal|0
argument_list|,
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_WIRED
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
if|if
condition|(
name|try
condition|)
block|{
name|pv_entry_count
operator|--
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_tryfail
operator|++
argument_list|)
expr_stmt|;
return|return
operator|(
name|NULL
operator|)
return|;
block|}
name|m
operator|=
name|pmap_pv_reclaim
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|m
operator|==
name|NULL
condition|)
goto|goto
name|retry
goto|;
block|}
name|PV_STAT
argument_list|(
name|pc_chunk_count
operator|++
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pc_chunk_allocs
operator|++
argument_list|)
expr_stmt|;
name|pc
operator|=
operator|(
expr|struct
name|pv_chunk
operator|*
operator|)
name|pmap_ptelist_alloc
argument_list|(
operator|&
name|pv_vafree
argument_list|)
expr_stmt|;
name|pmap_qenter
argument_list|(
operator|(
name|vm_offset_t
operator|)
name|pc
argument_list|,
operator|&
name|m
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|pc
operator|->
name|pc_pmap
operator|=
name|pmap
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
literal|0
index|]
operator|=
name|pc_freemask
index|[
literal|0
index|]
operator|&
operator|~
literal|1ul
expr_stmt|;
comment|/* preallocated bit 0 */
for|for
control|(
name|field
operator|=
literal|1
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|=
name|pc_freemask
index|[
name|field
index|]
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pv_chunks
argument_list|,
name|pc
argument_list|,
name|pc_lru
argument_list|)
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
literal|0
index|]
expr_stmt|;
name|TAILQ_INSERT_HEAD
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|+=
name|_NPCPV
operator|-
literal|1
argument_list|)
expr_stmt|;
return|return
operator|(
name|pv
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|__inline
name|pv_entry_t
name|pmap_pvh_remove
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|pmap
operator|==
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|&&
name|va
operator|==
name|pv
operator|->
name|pv_va
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
return|return
operator|(
name|pv
operator|)
return|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_pv_demote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_offset_t
name|va_last
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pa
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_pv_demote_pde: pa is not 4mpage aligned"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Transfer the 4mpage's pv entry for this mapping to the first 	 * page's pv list. 	 */
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|va
operator|=
name|trunc_4mpage
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
name|pvh
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pv
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_pv_demote_pde: pv not found"
operator|)
argument_list|)
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
comment|/* Instantiate the remaining NPTEPG - 1 pv entries. */
name|va_last
operator|=
name|va
operator|+
name|NBPDR
operator|-
name|PAGE_SIZE
expr_stmt|;
do|do
block|{
name|m
operator|++
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_pv_demote_pde: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pmap_insert_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|va
operator|<
name|va_last
condition|)
do|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_pv_promote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_offset_t
name|va_last
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|pa
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_pv_promote_pde: pa is not 4mpage aligned"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * Transfer the first page's pv entry for this mapping to the 	 * 4mpage's pv list.  Aside from avoiding the cost of a call 	 * to get_pv_entry(), a transfer avoids the possibility that 	 * get_pv_entry() calls pmap_collect() and that pmap_collect() 	 * removes one of the mappings that is being promoted. 	 */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|va
operator|=
name|trunc_4mpage
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pv
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_pv_promote_pde: pv not found"
operator|)
argument_list|)
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
comment|/* Free the remaining NPTEPG - 1 pv entries. */
name|va_last
operator|=
name|va
operator|+
name|NBPDR
operator|-
name|PAGE_SIZE
expr_stmt|;
do|do
block|{
name|m
operator|++
expr_stmt|;
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|pmap_pvh_free
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|va
operator|<
name|va_last
condition|)
do|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_pvh_free
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
name|pvh
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|pv
operator|!=
name|NULL
argument_list|,
operator|(
literal|"pmap_pvh_free: pv not found"
operator|)
argument_list|)
expr_stmt|;
name|free_pv_entry
argument_list|(
name|pmap
argument_list|,
name|pv
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_remove_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|pmap_pvh_free
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Create a pv entry for page at pa for  * (pmap, va).  */
end_comment

begin_function
specifier|static
name|void
name|pmap_insert_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Conditionally create a pv entry.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_try_insert_pv_entry
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv_entry_count
operator|<
name|pv_entry_high_water
operator|&&
operator|(
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|TRUE
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Create the pv entries for each of the pages within a superpage.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_pv_insert_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_paddr_t
name|pa
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv_entry_count
operator|<
name|pv_entry_high_water
operator|&&
operator|(
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|TRUE
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
else|else
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Fills a page table page with mappings to consecutive physical pages.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_fill_ptp
parameter_list|(
name|pt_entry_t
modifier|*
name|firstpte
parameter_list|,
name|pt_entry_t
name|newpte
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
for|for
control|(
name|pte
operator|=
name|firstpte
init|;
name|pte
operator|<
name|firstpte
operator|+
name|NPTEPG
condition|;
name|pte
operator|++
control|)
block|{
operator|*
name|pte
operator|=
name|newpte
expr_stmt|;
name|newpte
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Tries to demote a 2- or 4MB page mapping.  If demotion fails, the  * 2- or 4MB page mapping is invalidated.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_demote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
name|newpde
decl_stmt|,
name|oldpde
decl_stmt|;
name|pt_entry_t
modifier|*
name|firstpte
decl_stmt|,
name|newpte
decl_stmt|;
name|vm_paddr_t
name|mptepa
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|vm_offset_t
name|sva
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|oldpde
operator|=
operator|*
name|pde
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|oldpde
operator|&
operator|(
name|PG_PS
operator||
name|PG_V
operator|)
operator|)
operator|==
operator|(
name|PG_PS
operator||
name|PG_V
operator|)
argument_list|,
operator|(
literal|"pmap_demote_pde: oldpde is missing PG_PS and/or PG_V"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_A
operator|)
operator|==
literal|0
operator|||
operator|(
name|mpte
operator|=
name|pmap_remove_pt_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|oldpde
operator|&
name|PG_W
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_demote_pde: page table page for a wired mapping"
literal|" is missing"
operator|)
argument_list|)
expr_stmt|;
comment|/* 		 * Invalidate the 2- or 4MB page mapping and return 		 * "failure" if the mapping was never accessed or the 		 * allocation of the new page table page fails. 		 */
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_A
operator|)
operator|==
literal|0
operator|||
operator|(
name|mpte
operator|=
name|vm_page_alloc
argument_list|(
name|NULL
argument_list|,
name|va
operator|>>
name|PDRSHIFT
argument_list|,
name|VM_ALLOC_NOOBJ
operator||
name|VM_ALLOC_NORMAL
operator||
name|VM_ALLOC_WIRED
argument_list|)
operator|)
operator|==
name|NULL
condition|)
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|sva
operator|=
name|trunc_4mpage
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pmap_remove_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|sva
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_G
operator|)
operator|==
literal|0
condition|)
name|pmap_invalidate_pde_page
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
name|oldpde
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_demote_pde: failure for va %#x"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
block|}
name|mptepa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|mpte
argument_list|)
expr_stmt|;
comment|/* 	 * If the page mapping is in the kernel's address space, then the 	 * KPTmap can provide access to the page table page.  Otherwise, 	 * temporarily map the page table page (mpte) into the kernel's 	 * address space at either PADDR1 or PADDR2.  	 */
if|if
condition|(
name|va
operator|>=
name|KERNBASE
condition|)
name|firstpte
operator|=
operator|&
name|KPTmap
index|[
name|i386_btop
argument_list|(
name|trunc_4mpage
argument_list|(
name|va
argument_list|)
argument_list|)
index|]
expr_stmt|;
elseif|else
if|if
condition|(
name|curthread
operator|->
name|td_pinned
operator|>
literal|0
operator|&&
name|rw_wowned
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
condition|)
block|{
if|if
condition|(
operator|(
operator|*
name|PMAP1
operator|&
name|PG_FRAME
operator|)
operator|!=
name|mptepa
condition|)
block|{
operator|*
name|PMAP1
operator|=
name|mptepa
operator||
name|PG_RW
operator||
name|PG_V
operator||
name|PG_A
operator||
name|PG_M
expr_stmt|;
ifdef|#
directive|ifdef
name|SMP
name|PMAP1cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|invlcaddr
argument_list|(
name|PADDR1
argument_list|)
expr_stmt|;
name|PMAP1changed
operator|++
expr_stmt|;
block|}
elseif|else
ifdef|#
directive|ifdef
name|SMP
if|if
condition|(
name|PMAP1cpu
operator|!=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
condition|)
block|{
name|PMAP1cpu
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
name|invlcaddr
argument_list|(
name|PADDR1
argument_list|)
expr_stmt|;
name|PMAP1changedcpu
operator|++
expr_stmt|;
block|}
else|else
endif|#
directive|endif
name|PMAP1unchanged
operator|++
expr_stmt|;
name|firstpte
operator|=
name|PADDR1
expr_stmt|;
block|}
else|else
block|{
name|mtx_lock
argument_list|(
operator|&
name|PMAP2mutex
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|PMAP2
operator|&
name|PG_FRAME
operator|)
operator|!=
name|mptepa
condition|)
block|{
operator|*
name|PMAP2
operator|=
name|mptepa
operator||
name|PG_RW
operator||
name|PG_V
operator||
name|PG_A
operator||
name|PG_M
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|kernel_pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|PADDR2
argument_list|)
expr_stmt|;
block|}
name|firstpte
operator|=
name|PADDR2
expr_stmt|;
block|}
name|newpde
operator|=
name|mptepa
operator||
name|PG_M
operator||
name|PG_A
operator||
operator|(
name|oldpde
operator|&
name|PG_U
operator|)
operator||
name|PG_RW
operator||
name|PG_V
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|oldpde
operator|&
name|PG_A
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_demote_pde: oldpde is missing PG_A"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|oldpde
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|!=
name|PG_RW
argument_list|,
operator|(
literal|"pmap_demote_pde: oldpde is missing PG_M"
operator|)
argument_list|)
expr_stmt|;
name|newpte
operator|=
name|oldpde
operator|&
operator|~
name|PG_PS
expr_stmt|;
if|if
condition|(
operator|(
name|newpte
operator|&
name|PG_PDE_PAT
operator|)
operator|!=
literal|0
condition|)
name|newpte
operator|^=
name|PG_PDE_PAT
operator||
name|PG_PTE_PAT
expr_stmt|;
comment|/* 	 * If the page table page is new, initialize it. 	 */
if|if
condition|(
name|mpte
operator|->
name|wire_count
operator|==
literal|1
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|=
name|NPTEPG
expr_stmt|;
name|pmap_fill_ptp
argument_list|(
name|firstpte
argument_list|,
name|newpte
argument_list|)
expr_stmt|;
block|}
name|KASSERT
argument_list|(
operator|(
operator|*
name|firstpte
operator|&
name|PG_FRAME
operator|)
operator|==
operator|(
name|newpte
operator|&
name|PG_FRAME
operator|)
argument_list|,
operator|(
literal|"pmap_demote_pde: firstpte and newpte map different physical"
literal|" addresses"
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the mapping has changed attributes, update the page table 	 * entries. 	 */
if|if
condition|(
operator|(
operator|*
name|firstpte
operator|&
name|PG_PTE_PROMOTE
operator|)
operator|!=
operator|(
name|newpte
operator|&
name|PG_PTE_PROMOTE
operator|)
condition|)
name|pmap_fill_ptp
argument_list|(
name|firstpte
argument_list|,
name|newpte
argument_list|)
expr_stmt|;
comment|/* 	 * Demote the mapping.  This pmap is locked.  The old PDE has 	 * PG_A set.  If the old PDE has PG_RW set, it also has PG_M 	 * set.  Thus, there is no danger of a race with another 	 * processor changing the setting of PG_A and/or PG_M between 	 * the read above and the store below.  	 */
if|if
condition|(
name|workaround_erratum383
condition|)
name|pmap_update_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|pmap_kenter_pde
argument_list|(
name|va
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
else|else
name|pde_store
argument_list|(
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
if|if
condition|(
name|firstpte
operator|==
name|PADDR2
condition|)
name|mtx_unlock
argument_list|(
operator|&
name|PMAP2mutex
argument_list|)
expr_stmt|;
comment|/* 	 * Invalidate the recursive mapping of the page table page. 	 */
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|vtopte
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
comment|/* 	 * Demote the pv entry.  This depends on the earlier demotion 	 * of the mapping.  Specifically, the (re)creation of a per- 	 * page pv entry might trigger the execution of pmap_collect(), 	 * which might reclaim a newly (re)created per-page pv entry 	 * and destroy the associated mapping.  In order to destroy 	 * the mapping, the PDE must have already changed from mapping 	 * the 2mpage to referencing the page table page. 	 */
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
name|pmap_pv_demote_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|oldpde
operator|&
name|PG_PS_FRAME
argument_list|)
expr_stmt|;
name|pmap_pde_demotions
operator|++
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_demote_pde: success for va %#x"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Removes a 2- or 4MB page mapping from the kernel pmap.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_remove_kernel_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
name|newpde
decl_stmt|;
name|vm_paddr_t
name|mptepa
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|pmap_remove_pt_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_remove_kernel_pde: Missing pt page."
argument_list|)
expr_stmt|;
name|mptepa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|mpte
argument_list|)
expr_stmt|;
name|newpde
operator|=
name|mptepa
operator||
name|PG_M
operator||
name|PG_A
operator||
name|PG_RW
operator||
name|PG_V
expr_stmt|;
comment|/* 	 * Initialize the page table page. 	 */
name|pagezero
argument_list|(
operator|(
name|void
operator|*
operator|)
operator|&
name|KPTmap
index|[
name|i386_btop
argument_list|(
name|trunc_4mpage
argument_list|(
name|va
argument_list|)
argument_list|)
index|]
argument_list|)
expr_stmt|;
comment|/* 	 * Remove the mapping. 	 */
if|if
condition|(
name|workaround_erratum383
condition|)
name|pmap_update_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
else|else
name|pmap_kenter_pde
argument_list|(
name|va
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
comment|/* 	 * Invalidate the recursive mapping of the page table page. 	 */
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
operator|(
name|vm_offset_t
operator|)
name|vtopte
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * pmap_remove_pde: do the things to unmap a superpage in a process  */
end_comment

begin_function
specifier|static
name|void
name|pmap_remove_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pdq
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pd_entry_t
name|oldpde
decl_stmt|;
name|vm_offset_t
name|eva
decl_stmt|,
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mpte
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|sva
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_pde: sva is not 4mpage aligned"
operator|)
argument_list|)
expr_stmt|;
name|oldpde
operator|=
name|pte_load_clear
argument_list|(
name|pdq
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpde
operator|&
name|PG_W
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|-=
name|NBPDR
operator|/
name|PAGE_SIZE
expr_stmt|;
comment|/* 	 * Machines that don't support invlpg, also don't support 	 * PG_G. 	 */
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_G
operator|)
operator|!=
literal|0
condition|)
name|pmap_invalidate_pde_page
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|oldpde
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|-=
name|NBPDR
operator|/
name|PAGE_SIZE
expr_stmt|;
if|if
condition|(
name|oldpde
operator|&
name|PG_MANAGED
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|oldpde
operator|&
name|PG_PS_FRAME
argument_list|)
expr_stmt|;
name|pmap_pvh_free
argument_list|(
name|pvh
argument_list|,
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|eva
operator|=
name|sva
operator|+
name|NBPDR
expr_stmt|;
for|for
control|(
name|va
operator|=
name|sva
operator|,
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|oldpde
operator|&
name|PG_PS_FRAME
argument_list|)
init|;
name|va
operator|<
name|eva
condition|;
name|va
operator|+=
name|PAGE_SIZE
operator|,
name|m
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|oldpde
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpde
operator|&
name|PG_A
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|pmap_remove_kernel_pde
argument_list|(
name|pmap
argument_list|,
name|pdq
argument_list|,
name|sva
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mpte
operator|=
name|pmap_remove_pt_page
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|->
name|wire_count
operator|==
name|NPTEPG
argument_list|,
operator|(
literal|"pmap_remove_pde: pte page wire count error"
operator|)
argument_list|)
expr_stmt|;
name|mpte
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
name|pmap_add_delayed_free_list
argument_list|(
name|mpte
argument_list|,
name|free
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*  * pmap_remove_pte: do the things to unmap a page in a process  */
end_comment

begin_function
specifier|static
name|int
name|pmap_remove_pte
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pt_entry_t
modifier|*
name|ptq
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|pt_entry_t
name|oldpte
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|oldpte
operator|=
name|pte_load_clear
argument_list|(
name|ptq
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|oldpte
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_remove_pte: pmap %p va %x zero pte"
operator|,
name|pmap
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpte
operator|&
name|PG_W
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|-=
literal|1
expr_stmt|;
comment|/* 	 * Machines that don't support invlpg, also don't support 	 * PG_G. 	 */
if|if
condition|(
name|oldpte
operator|&
name|PG_G
condition|)
name|pmap_invalidate_page
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|-=
literal|1
expr_stmt|;
if|if
condition|(
name|oldpte
operator|&
name|PG_MANAGED
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|oldpte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|oldpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldpte
operator|&
name|PG_A
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
name|pmap_remove_entry
argument_list|(
name|pmap
argument_list|,
name|m
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|pmap_unuse_pt
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|free
argument_list|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Remove a single page from a process address space  */
end_comment

begin_function
specifier|static
name|void
name|pmap_remove_page
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|struct
name|spglist
modifier|*
name|free
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|curthread
operator|->
name|td_pinned
operator|>
literal|0
argument_list|,
operator|(
literal|"curthread not pinned"
operator|)
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
operator|)
operator|==
name|NULL
operator|||
operator|*
name|pte
operator|==
literal|0
condition|)
return|return;
name|pmap_remove_pte
argument_list|(
name|pmap
argument_list|,
name|pte
argument_list|,
name|va
argument_list|,
name|free
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Remove the given range of addresses from the specified map.  *  *	It is assumed that the start and end are properly  *	rounded to the page size.  */
end_comment

begin_function
name|void
name|pmap_remove
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|vm_offset_t
name|pdnxt
decl_stmt|;
name|pd_entry_t
name|ptpaddr
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|int
name|anyvalid
decl_stmt|;
comment|/* 	 * Perform an unsynchronized read.  This is, however, safe. 	 */
if|if
condition|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
condition|)
return|return;
name|anyvalid
operator|=
literal|0
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* 	 * special handling of removing one page.  a very 	 * common operation and easy to short circuit some 	 * code. 	 */
if|if
condition|(
operator|(
name|sva
operator|+
name|PAGE_SIZE
operator|==
name|eva
operator|)
operator|&&
operator|(
operator|(
name|pmap
operator|->
name|pm_pdir
index|[
operator|(
name|sva
operator|>>
name|PDRSHIFT
operator|)
index|]
operator|&
name|PG_PS
operator|)
operator|==
literal|0
operator|)
condition|)
block|{
name|pmap_remove_page
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
goto|goto
name|out
goto|;
block|}
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|pdnxt
control|)
block|{
name|u_int
name|pdirindex
decl_stmt|;
comment|/* 		 * Calculate index for next page table. 		 */
name|pdnxt
operator|=
operator|(
name|sva
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|pdnxt
operator|<
name|sva
condition|)
name|pdnxt
operator|=
name|eva
expr_stmt|;
if|if
condition|(
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|==
literal|0
condition|)
break|break;
name|pdirindex
operator|=
name|sva
operator|>>
name|PDRSHIFT
expr_stmt|;
name|ptpaddr
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|pdirindex
index|]
expr_stmt|;
comment|/* 		 * Weed out invalid mappings. Note: we assume that the page 		 * directory table is always allocated, and in kernel virtual. 		 */
if|if
condition|(
name|ptpaddr
operator|==
literal|0
condition|)
continue|continue;
comment|/* 		 * Check for large page. 		 */
if|if
condition|(
operator|(
name|ptpaddr
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * Are we removing the entire large page?  If not, 			 * demote the mapping and fall through. 			 */
if|if
condition|(
name|sva
operator|+
name|NBPDR
operator|==
name|pdnxt
operator|&&
name|eva
operator|>=
name|pdnxt
condition|)
block|{
comment|/* 				 * The TLB entry for a PG_G mapping is 				 * invalidated by pmap_remove_pde(). 				 */
if|if
condition|(
operator|(
name|ptpaddr
operator|&
name|PG_G
operator|)
operator|==
literal|0
condition|)
name|anyvalid
operator|=
literal|1
expr_stmt|;
name|pmap_remove_pde
argument_list|(
name|pmap
argument_list|,
operator|&
name|pmap
operator|->
name|pm_pdir
index|[
name|pdirindex
index|]
argument_list|,
name|sva
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
continue|continue;
block|}
elseif|else
if|if
condition|(
operator|!
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
operator|&
name|pmap
operator|->
name|pm_pdir
index|[
name|pdirindex
index|]
argument_list|,
name|sva
argument_list|)
condition|)
block|{
comment|/* The large page mapping was destroyed. */
continue|continue;
block|}
block|}
comment|/* 		 * Limit our scan to either the end of the va represented 		 * by the current page table page, or to the end of the 		 * range being removed. 		 */
if|if
condition|(
name|pdnxt
operator|>
name|eva
condition|)
name|pdnxt
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|pdnxt
condition|;
name|pte
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
if|if
condition|(
operator|*
name|pte
operator|==
literal|0
condition|)
continue|continue;
comment|/* 			 * The TLB entry for a PG_G mapping is invalidated 			 * by pmap_remove_pte(). 			 */
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_G
operator|)
operator|==
literal|0
condition|)
name|anyvalid
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|pmap_remove_pte
argument_list|(
name|pmap
argument_list|,
name|pte
argument_list|,
name|sva
argument_list|,
operator|&
name|free
argument_list|)
condition|)
break|break;
block|}
block|}
name|out
label|:
name|sched_unpin
argument_list|()
expr_stmt|;
if|if
condition|(
name|anyvalid
condition|)
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Routine:	pmap_remove_all  *	Function:  *		Removes this physical page from  *		all physical maps in which it resides.  *		Reflects back modify bits to the pager.  *  *	Notes:  *		Original versions of this routine were very  *		inefficient because they iteratively called  *		pmap_remove (slow...)  */
end_comment

begin_function
name|void
name|pmap_remove_all
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|tpte
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_all: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
goto|goto
name|small_mappings
goto|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|small_mappings
label|:
while|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_all: found"
literal|" a 4mpage in page %p's pv list"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|tpte
operator|=
name|pte_load_clear
argument_list|(
name|pte
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|tpte
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_remove_all: pmap %p va %x zero pte"
operator|,
name|pmap
operator|,
name|pv
operator|->
name|pv_va
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|tpte
operator|&
name|PG_W
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
if|if
condition|(
name|tpte
operator|&
name|PG_A
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
comment|/* 		 * Update the vm_page_t clean and reference bits. 		 */
if|if
condition|(
operator|(
name|tpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_unuse_pt
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|free_pv_entry
argument_list|(
name|pmap
argument_list|,
name|pv
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * pmap_protect_pde: do the things to protect a 4mpage in a process  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_protect_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|pd_entry_t
name|newpde
decl_stmt|,
name|oldpde
decl_stmt|;
name|vm_offset_t
name|eva
decl_stmt|,
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|boolean_t
name|anychanged
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|sva
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_protect_pde: sva is not 4mpage aligned"
operator|)
argument_list|)
expr_stmt|;
name|anychanged
operator|=
name|FALSE
expr_stmt|;
name|retry
label|:
name|oldpde
operator|=
name|newpde
operator|=
operator|*
name|pde
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
operator|(
name|PG_MANAGED
operator||
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_MANAGED
operator||
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
name|eva
operator|=
name|sva
operator|+
name|NBPDR
expr_stmt|;
for|for
control|(
name|va
operator|=
name|sva
operator|,
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|oldpde
operator|&
name|PG_PS_FRAME
argument_list|)
init|;
name|va
operator|<
name|eva
condition|;
name|va
operator|+=
name|PAGE_SIZE
operator|,
name|m
operator|++
control|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
condition|)
name|newpde
operator|&=
operator|~
operator|(
name|PG_RW
operator||
name|PG_M
operator|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|newpde
operator||=
name|pg_nx
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|newpde
operator|!=
name|oldpde
condition|)
block|{
comment|/* 		 * As an optimization to future operations on this PDE, clear 		 * PG_PROMOTED.  The impending invalidation will remove any 		 * lingering 4KB page mappings from the TLB. 		 */
if|if
condition|(
operator|!
name|pde_cmpset
argument_list|(
name|pde
argument_list|,
name|oldpde
argument_list|,
name|newpde
operator|&
operator|~
name|PG_PROMOTED
argument_list|)
condition|)
goto|goto
name|retry
goto|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_G
operator|)
operator|!=
literal|0
condition|)
name|pmap_invalidate_pde_page
argument_list|(
name|kernel_pmap
argument_list|,
name|sva
argument_list|,
name|oldpde
argument_list|)
expr_stmt|;
else|else
name|anychanged
operator|=
name|TRUE
expr_stmt|;
block|}
return|return
operator|(
name|anychanged
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Set the physical protection on the  *	specified range of this map as requested.  */
end_comment

begin_function
name|void
name|pmap_protect
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|pdnxt
decl_stmt|;
name|pd_entry_t
name|ptpaddr
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|boolean_t
name|anychanged
decl_stmt|,
name|pv_lists_locked
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|prot
operator|&
operator|~
name|VM_PROT_ALL
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"invalid prot %x"
operator|,
name|prot
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|prot
operator|==
name|VM_PROT_NONE
condition|)
block|{
name|pmap_remove
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
return|return;
block|}
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
if|if
condition|(
operator|(
name|prot
operator|&
operator|(
name|VM_PROT_WRITE
operator||
name|VM_PROT_EXECUTE
operator|)
operator|)
operator|==
operator|(
name|VM_PROT_WRITE
operator||
name|VM_PROT_EXECUTE
operator|)
condition|)
return|return;
else|#
directive|else
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
return|return;
endif|#
directive|endif
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
name|pv_lists_locked
operator|=
name|FALSE
expr_stmt|;
else|else
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
name|resume
label|:
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
block|}
name|anychanged
operator|=
name|FALSE
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|pdnxt
control|)
block|{
name|pt_entry_t
name|obits
decl_stmt|,
name|pbits
decl_stmt|;
name|u_int
name|pdirindex
decl_stmt|;
name|pdnxt
operator|=
operator|(
name|sva
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|pdnxt
operator|<
name|sva
condition|)
name|pdnxt
operator|=
name|eva
expr_stmt|;
name|pdirindex
operator|=
name|sva
operator|>>
name|PDRSHIFT
expr_stmt|;
name|ptpaddr
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|pdirindex
index|]
expr_stmt|;
comment|/* 		 * Weed out invalid mappings. Note: we assume that the page 		 * directory table is always allocated, and in kernel virtual. 		 */
if|if
condition|(
name|ptpaddr
operator|==
literal|0
condition|)
continue|continue;
comment|/* 		 * Check for large page. 		 */
if|if
condition|(
operator|(
name|ptpaddr
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * Are we protecting the entire large page?  If not, 			 * demote the mapping and fall through. 			 */
if|if
condition|(
name|sva
operator|+
name|NBPDR
operator|==
name|pdnxt
operator|&&
name|eva
operator|>=
name|pdnxt
condition|)
block|{
comment|/* 				 * The TLB entry for a PG_G mapping is 				 * invalidated by pmap_protect_pde(). 				 */
if|if
condition|(
name|pmap_protect_pde
argument_list|(
name|pmap
argument_list|,
operator|&
name|pmap
operator|->
name|pm_pdir
index|[
name|pdirindex
index|]
argument_list|,
name|sva
argument_list|,
name|prot
argument_list|)
condition|)
name|anychanged
operator|=
name|TRUE
expr_stmt|;
continue|continue;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|pv_lists_locked
condition|)
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
if|if
condition|(
operator|!
name|rw_try_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
condition|)
block|{
if|if
condition|(
name|anychanged
condition|)
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|resume
goto|;
block|}
name|sched_pin
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
operator|&
name|pmap
operator|->
name|pm_pdir
index|[
name|pdirindex
index|]
argument_list|,
name|sva
argument_list|)
condition|)
block|{
comment|/* 					 * The large page mapping was 					 * destroyed. 					 */
continue|continue;
block|}
block|}
block|}
if|if
condition|(
name|pdnxt
operator|>
name|eva
condition|)
name|pdnxt
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|pdnxt
condition|;
name|pte
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
name|vm_page_t
name|m
decl_stmt|;
name|retry
label|:
comment|/* 			 * Regardless of whether a pte is 32 or 64 bits in 			 * size, PG_RW, PG_A, and PG_M are among the least 			 * significant 32 bits. 			 */
name|obits
operator|=
name|pbits
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|pbits
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|pbits
operator|&
operator|(
name|PG_MANAGED
operator||
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_MANAGED
operator||
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pbits
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|pbits
operator|&=
operator|~
operator|(
name|PG_RW
operator||
name|PG_M
operator|)
expr_stmt|;
block|}
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|pbits
operator||=
name|pg_nx
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|pbits
operator|!=
name|obits
condition|)
block|{
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
if|if
condition|(
operator|!
name|atomic_cmpset_64
argument_list|(
name|pte
argument_list|,
name|obits
argument_list|,
name|pbits
argument_list|)
condition|)
goto|goto
name|retry
goto|;
else|#
directive|else
if|if
condition|(
operator|!
name|atomic_cmpset_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|obits
argument_list|,
name|pbits
argument_list|)
condition|)
goto|goto
name|retry
goto|;
endif|#
directive|endif
if|if
condition|(
name|obits
operator|&
name|PG_G
condition|)
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
else|else
name|anychanged
operator|=
name|TRUE
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|anychanged
condition|)
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv_lists_locked
condition|)
block|{
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Tries to promote the 512 or 1024, contiguous 4KB page mappings that are  * within a single page table page (PTP) to a single 2- or 4MB page mapping.  * For promotion to occur, two conditions must be met: (1) the 4KB page  * mappings must map aligned, contiguous physical memory and (2) the 4KB page  * mappings must have identical characteristics.  *  * Managed (PG_MANAGED) mappings within the kernel address space are not  * promoted.  The reason is that kernel PDEs are replicated in each pmap but  * pmap_clear_ptes() and pmap_ts_referenced() only read the PDE from the kernel  * pmap.  */
end_comment

begin_function
specifier|static
name|void
name|pmap_promote_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|vm_offset_t
name|va
parameter_list|)
block|{
name|pd_entry_t
name|newpde
decl_stmt|;
name|pt_entry_t
modifier|*
name|firstpte
decl_stmt|,
name|oldpte
decl_stmt|,
name|pa
decl_stmt|,
modifier|*
name|pte
decl_stmt|;
name|vm_offset_t
name|oldpteva
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * Examine the first PTE in the specified PTP.  Abort if this PTE is 	 * either invalid, unused, or does not map the first 4KB physical page 	 * within a 2- or 4MB page. 	 */
name|firstpte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|trunc_4mpage
argument_list|(
name|va
argument_list|)
argument_list|)
expr_stmt|;
name|setpde
label|:
name|newpde
operator|=
operator|*
name|firstpte
expr_stmt|;
if|if
condition|(
operator|(
name|newpde
operator|&
operator|(
operator|(
name|PG_FRAME
operator|&
name|PDRMASK
operator|)
operator||
name|PG_A
operator||
name|PG_V
operator|)
operator|)
operator|!=
operator|(
name|PG_A
operator||
name|PG_V
operator|)
condition|)
block|{
name|pmap_pde_p_failures
operator|++
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: failure for va %#x"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
operator|*
name|firstpte
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
operator|&&
name|pmap
operator|==
name|kernel_pmap
condition|)
block|{
name|pmap_pde_p_failures
operator|++
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: failure for va %#x"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|newpde
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
name|PG_RW
condition|)
block|{
comment|/* 		 * When PG_M is already clear, PG_RW can be cleared without 		 * a TLB invalidation. 		 */
if|if
condition|(
operator|!
name|atomic_cmpset_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|firstpte
argument_list|,
name|newpde
argument_list|,
name|newpde
operator|&
operator|~
name|PG_RW
argument_list|)
condition|)
goto|goto
name|setpde
goto|;
name|newpde
operator|&=
operator|~
name|PG_RW
expr_stmt|;
block|}
comment|/*  	 * Examine each of the other PTEs in the specified PTP.  Abort if this 	 * PTE maps an unexpected 4KB physical page or does not have identical 	 * characteristics to the first PTE. 	 */
name|pa
operator|=
operator|(
name|newpde
operator|&
operator|(
name|PG_PS_FRAME
operator||
name|PG_A
operator||
name|PG_V
operator|)
operator|)
operator|+
name|NBPDR
operator|-
name|PAGE_SIZE
expr_stmt|;
for|for
control|(
name|pte
operator|=
name|firstpte
operator|+
name|NPTEPG
operator|-
literal|1
init|;
name|pte
operator|>
name|firstpte
condition|;
name|pte
operator|--
control|)
block|{
name|setpte
label|:
name|oldpte
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|oldpte
operator|&
operator|(
name|PG_FRAME
operator||
name|PG_A
operator||
name|PG_V
operator|)
operator|)
operator|!=
name|pa
condition|)
block|{
name|pmap_pde_p_failures
operator|++
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: failure for va %#x"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|(
name|oldpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
name|PG_RW
condition|)
block|{
comment|/* 			 * When PG_M is already clear, PG_RW can be cleared 			 * without a TLB invalidation. 			 */
if|if
condition|(
operator|!
name|atomic_cmpset_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|oldpte
argument_list|,
name|oldpte
operator|&
operator|~
name|PG_RW
argument_list|)
condition|)
goto|goto
name|setpte
goto|;
name|oldpte
operator|&=
operator|~
name|PG_RW
expr_stmt|;
name|oldpteva
operator|=
operator|(
name|oldpte
operator|&
name|PG_FRAME
operator|&
name|PDRMASK
operator|)
operator||
operator|(
name|va
operator|&
operator|~
name|PDRMASK
operator|)
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: protect for va %#x"
literal|" in pmap %p"
argument_list|,
name|oldpteva
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|oldpte
operator|&
name|PG_PTE_PROMOTE
operator|)
operator|!=
operator|(
name|newpde
operator|&
name|PG_PTE_PROMOTE
operator|)
condition|)
block|{
name|pmap_pde_p_failures
operator|++
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: failure for va %#x"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
name|pa
operator|-=
name|PAGE_SIZE
expr_stmt|;
block|}
comment|/* 	 * Save the page table page in its current state until the PDE 	 * mapping the superpage is demoted by pmap_demote_pde() or 	 * destroyed by pmap_remove_pde().  	 */
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pde
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|>=
name|vm_page_array
operator|&&
name|mpte
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"pmap_promote_pde: page table page is out of range"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|->
name|pindex
operator|==
name|va
operator|>>
name|PDRSHIFT
argument_list|,
operator|(
literal|"pmap_promote_pde: page table page's pindex is wrong"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_insert_pt_page
argument_list|(
name|pmap
argument_list|,
name|mpte
argument_list|)
condition|)
block|{
name|pmap_pde_p_failures
operator|++
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: failure for va %#x in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * Promote the pv entries. 	 */
if|if
condition|(
operator|(
name|newpde
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
name|pmap_pv_promote_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|newpde
operator|&
name|PG_PS_FRAME
argument_list|)
expr_stmt|;
comment|/* 	 * Propagate the PAT index to its proper position. 	 */
if|if
condition|(
operator|(
name|newpde
operator|&
name|PG_PTE_PAT
operator|)
operator|!=
literal|0
condition|)
name|newpde
operator|^=
name|PG_PDE_PAT
operator||
name|PG_PTE_PAT
expr_stmt|;
comment|/* 	 * Map the superpage. 	 */
if|if
condition|(
name|workaround_erratum383
condition|)
name|pmap_update_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|pde
argument_list|,
name|PG_PS
operator||
name|newpde
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|pmap_kenter_pde
argument_list|(
name|va
argument_list|,
name|PG_PROMOTED
operator||
name|PG_PS
operator||
name|newpde
argument_list|)
expr_stmt|;
else|else
name|pde_store
argument_list|(
name|pde
argument_list|,
name|PG_PROMOTED
operator||
name|PG_PS
operator||
name|newpde
argument_list|)
expr_stmt|;
name|pmap_pde_promotions
operator|++
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_promote_pde: success for va %#x"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Insert the given physical page (p) at  *	the specified virtual address (v) in the  *	target physical map with the protection requested.  *  *	If specified, the page will be wired down, meaning  *	that the related pte can not be reclaimed.  *  *	NB:  This is the only routine which MAY NOT lazy-evaluate  *	or lose information.  That is, this routine must actually  *	insert this page into the given map NOW.  */
end_comment

begin_function
name|int
name|pmap_enter
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|u_int
name|flags
parameter_list|,
name|int8_t
name|psind
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pt_entry_t
name|newpte
decl_stmt|,
name|origpte
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|vm_paddr_t
name|opa
decl_stmt|,
name|pa
decl_stmt|;
name|vm_page_t
name|mpte
decl_stmt|,
name|om
decl_stmt|;
name|boolean_t
name|invlva
decl_stmt|,
name|wired
decl_stmt|;
name|va
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|NULL
expr_stmt|;
name|wired
operator|=
operator|(
name|flags
operator|&
name|PMAP_ENTER_WIRED
operator|)
operator|!=
literal|0
expr_stmt|;
name|KASSERT
argument_list|(
name|va
operator|<=
name|VM_MAX_KERNEL_ADDRESS
argument_list|,
operator|(
literal|"pmap_enter: toobig"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|va
operator|<
name|UPT_MIN_ADDRESS
operator|||
name|va
operator|>=
name|UPT_MAX_ADDRESS
argument_list|,
operator|(
literal|"pmap_enter: invalid to pmap_enter page table pages (va: 0x%x)"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|&&
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
condition|)
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
block|{
comment|/* 		 * va is for UVA. 		 * In the case that a page table page is not resident, 		 * we are creating it here.  pmap_allocpte() handles 		 * demotion. 		 */
name|mpte
operator|=
name|pmap_allocpte
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|flags
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|==
name|NULL
condition|)
block|{
name|KASSERT
argument_list|(
operator|(
name|flags
operator|&
name|PMAP_ENTER_NOSLEEP
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_allocpte failed with sleep allowed"
operator|)
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_RESOURCE_SHORTAGE
operator|)
return|;
block|}
block|}
else|else
block|{
comment|/* 		 * va is for KVA, so pmap_demote_pde() will never fail 		 * to install a page table page.  PG_V is also 		 * asserted by pmap_demote_pde(). 		 */
name|KASSERT
argument_list|(
name|pde
operator|!=
name|NULL
operator|&&
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"KVA %#x invalid pde pdir %#jx"
operator|,
name|va
operator|,
operator|(
name|uintmax_t
operator|)
name|pmap
operator|->
name|pm_pdir
index|[
name|PTDPTDI
index|]
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * Page Directory table entry is not valid, which should not 	 * happen.  We should have either allocated the page table 	 * page or demoted the existing mapping above. 	 */
if|if
condition|(
name|pte
operator|==
name|NULL
condition|)
block|{
name|panic
argument_list|(
literal|"pmap_enter: invalid page directory pdir=%#jx, va=%#x"
argument_list|,
operator|(
name|uintmax_t
operator|)
name|pmap
operator|->
name|pm_pdir
index|[
name|PTDPTDI
index|]
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|om
operator|=
name|NULL
expr_stmt|;
name|origpte
operator|=
operator|*
name|pte
expr_stmt|;
name|opa
operator|=
name|origpte
operator|&
name|PG_FRAME
expr_stmt|;
comment|/* 	 * Mapping has not changed, must be protection or wiring change. 	 */
if|if
condition|(
name|origpte
operator|&&
operator|(
name|opa
operator|==
name|pa
operator|)
condition|)
block|{
comment|/* 		 * Wiring change, just update stats. We don't worry about 		 * wiring PT pages as they remain resident as long as there 		 * are valid mappings in them. Hence, if a user page is wired, 		 * the PT page will be also. 		 */
if|if
condition|(
name|wired
operator|&&
operator|(
operator|(
name|origpte
operator|&
name|PG_W
operator|)
operator|==
literal|0
operator|)
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
elseif|else
if|if
condition|(
operator|!
name|wired
operator|&&
operator|(
name|origpte
operator|&
name|PG_W
operator|)
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
comment|/* 		 * Remove extra pte reference 		 */
if|if
condition|(
name|mpte
condition|)
name|mpte
operator|->
name|wire_count
operator|--
expr_stmt|;
if|if
condition|(
name|origpte
operator|&
name|PG_MANAGED
condition|)
block|{
name|om
operator|=
name|m
expr_stmt|;
name|pa
operator||=
name|PG_MANAGED
expr_stmt|;
block|}
goto|goto
name|validate
goto|;
block|}
name|pv
operator|=
name|NULL
expr_stmt|;
comment|/* 	 * Mapping has changed, invalidate old range and fall through to 	 * handle validating new mapping. 	 */
if|if
condition|(
name|opa
condition|)
block|{
if|if
condition|(
name|origpte
operator|&
name|PG_W
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
if|if
condition|(
name|origpte
operator|&
name|PG_MANAGED
condition|)
block|{
name|om
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|opa
argument_list|)
expr_stmt|;
name|pv
operator|=
name|pmap_pvh_remove
argument_list|(
operator|&
name|om
operator|->
name|md
argument_list|,
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|--
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|->
name|wire_count
operator|>
literal|0
argument_list|,
operator|(
literal|"pmap_enter: missing reference to page table page,"
literal|" va: 0x%x"
operator|,
name|va
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
comment|/* 	 * Enter on the PV list if part of our managed memory. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|KASSERT
argument_list|(
name|va
operator|<
name|kmi
operator|.
name|clean_sva
operator|||
name|va
operator|>=
name|kmi
operator|.
name|clean_eva
argument_list|,
operator|(
literal|"pmap_enter: managed mapping within the clean submap"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv
operator|==
name|NULL
condition|)
name|pv
operator|=
name|get_pv_entry
argument_list|(
name|pmap
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|pa
operator||=
name|PG_MANAGED
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pv
operator|!=
name|NULL
condition|)
name|free_pv_entry
argument_list|(
name|pmap
argument_list|,
name|pv
argument_list|)
expr_stmt|;
comment|/* 	 * Increment counters 	 */
if|if
condition|(
name|wired
condition|)
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|++
expr_stmt|;
name|validate
label|:
comment|/* 	 * Now validate mapping with desired protection/wiring. 	 */
name|newpte
operator|=
call|(
name|pt_entry_t
call|)
argument_list|(
name|pa
operator||
name|pmap_cache_bits
argument_list|(
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
operator||
name|PG_V
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|!=
literal|0
condition|)
block|{
name|newpte
operator||=
name|PG_RW
expr_stmt|;
if|if
condition|(
operator|(
name|newpte
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
name|vm_page_aflag_set
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|newpte
operator||=
name|pg_nx
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|wired
condition|)
name|newpte
operator||=
name|PG_W
expr_stmt|;
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|newpte
operator||=
name|PG_U
expr_stmt|;
if|if
condition|(
name|pmap
operator|==
name|kernel_pmap
condition|)
name|newpte
operator||=
name|pgeflag
expr_stmt|;
comment|/* 	 * if the mapping or permission bits are different, we need 	 * to update the pte. 	 */
if|if
condition|(
operator|(
name|origpte
operator|&
operator|~
operator|(
name|PG_M
operator||
name|PG_A
operator|)
operator|)
operator|!=
name|newpte
condition|)
block|{
name|newpte
operator||=
name|PG_A
expr_stmt|;
if|if
condition|(
operator|(
name|flags
operator|&
name|VM_PROT_WRITE
operator|)
operator|!=
literal|0
condition|)
name|newpte
operator||=
name|PG_M
expr_stmt|;
if|if
condition|(
name|origpte
operator|&
name|PG_V
condition|)
block|{
name|invlva
operator|=
name|FALSE
expr_stmt|;
name|origpte
operator|=
name|pte_load_store
argument_list|(
name|pte
argument_list|,
name|newpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|origpte
operator|&
name|PG_A
condition|)
block|{
if|if
condition|(
name|origpte
operator|&
name|PG_MANAGED
condition|)
name|vm_page_aflag_set
argument_list|(
name|om
argument_list|,
name|PGA_REFERENCED
argument_list|)
expr_stmt|;
if|if
condition|(
name|opa
operator|!=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
condition|)
name|invlva
operator|=
name|TRUE
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_NX
operator|)
operator|==
literal|0
operator|&&
operator|(
name|newpte
operator|&
name|PG_NX
operator|)
operator|!=
literal|0
condition|)
name|invlva
operator|=
name|TRUE
expr_stmt|;
endif|#
directive|endif
block|}
if|if
condition|(
operator|(
name|origpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
name|vm_page_dirty
argument_list|(
name|om
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_WRITE
operator|)
operator|==
literal|0
condition|)
name|invlva
operator|=
name|TRUE
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|origpte
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
operator|&&
name|TAILQ_EMPTY
argument_list|(
operator|&
name|om
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
operator|(
name|om
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
operator|||
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pa_to_pvh
argument_list|(
name|opa
argument_list|)
operator|->
name|pv_list
argument_list|)
operator|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|om
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
if|if
condition|(
name|invlva
condition|)
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
else|else
name|pte_store
argument_list|(
name|pte
argument_list|,
name|newpte
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * If both the page table page and the reservation are fully 	 * populated, then attempt promotion. 	 */
if|if
condition|(
operator|(
name|mpte
operator|==
name|NULL
operator|||
name|mpte
operator|->
name|wire_count
operator|==
name|NPTEPG
operator|)
operator|&&
name|pg_ps_enabled
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
name|vm_reserv_level_iffullpop
argument_list|(
name|m
argument_list|)
operator|==
literal|0
condition|)
name|pmap_promote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|KERN_SUCCESS
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Tries to create a 2- or 4MB page mapping.  Returns TRUE if successful and  * FALSE otherwise.  Fails if (1) a page table page cannot be allocated without  * blocking, (2) a mapping already exists at the specified virtual address, or  * (3) a pv entry cannot be allocated without reclaiming another pv entry.   */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_enter_pde
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|,
name|newpde
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pde
operator|!=
literal|0
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_enter_pde: failure for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
name|newpde
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|pmap_cache_bits
argument_list|(
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|1
argument_list|)
operator||
name|PG_PS
operator||
name|PG_V
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
condition|)
block|{
name|newpde
operator||=
name|PG_MANAGED
expr_stmt|;
comment|/* 		 * Abort this mapping if its PV entry could not be created. 		 */
if|if
condition|(
operator|!
name|pmap_pv_insert_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
condition|)
block|{
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_enter_pde: failure for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|FALSE
operator|)
return|;
block|}
block|}
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|newpde
operator||=
name|pg_nx
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
name|newpde
operator||=
name|PG_U
expr_stmt|;
comment|/* 	 * Increment counters. 	 */
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|+=
name|NBPDR
operator|/
name|PAGE_SIZE
expr_stmt|;
comment|/* 	 * Map the superpage.  (This is not a promoted mapping; there will not 	 * be any lingering 4KB page mappings in the TLB.) 	 */
name|pde_store
argument_list|(
name|pde
argument_list|,
name|newpde
argument_list|)
expr_stmt|;
name|pmap_pde_mappings
operator|++
expr_stmt|;
name|CTR2
argument_list|(
name|KTR_PMAP
argument_list|,
literal|"pmap_enter_pde: success for va %#lx"
literal|" in pmap %p"
argument_list|,
name|va
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|TRUE
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Maps a sequence of resident pages belonging to the same object.  * The sequence begins with the given page m_start.  This page is  * mapped at the given virtual address start.  Each subsequent page is  * mapped at a virtual address that is offset from start by the same  * amount as the page is offset from m_start within the object.  The  * last page in the sequence is the page with the largest offset from  * m_start that can be mapped at a virtual address less than the given  * virtual address end.  Not every virtual page between start and end  * is mapped; only those for which a resident page exists with the  * corresponding offset from m_start are mapped.  */
end_comment

begin_function
name|void
name|pmap_enter_object
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|start
parameter_list|,
name|vm_offset_t
name|end
parameter_list|,
name|vm_page_t
name|m_start
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mpte
decl_stmt|;
name|vm_pindex_t
name|diff
decl_stmt|,
name|psize
decl_stmt|;
name|VM_OBJECT_ASSERT_LOCKED
argument_list|(
name|m_start
operator|->
name|object
argument_list|)
expr_stmt|;
name|psize
operator|=
name|atop
argument_list|(
name|end
operator|-
name|start
argument_list|)
expr_stmt|;
name|mpte
operator|=
name|NULL
expr_stmt|;
name|m
operator|=
name|m_start
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
while|while
condition|(
name|m
operator|!=
name|NULL
operator|&&
operator|(
name|diff
operator|=
name|m
operator|->
name|pindex
operator|-
name|m_start
operator|->
name|pindex
operator|)
operator|<
name|psize
condition|)
block|{
name|va
operator|=
name|start
operator|+
name|ptoa
argument_list|(
name|diff
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|va
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
operator|&&
name|va
operator|+
name|NBPDR
operator|<=
name|end
operator|&&
name|m
operator|->
name|psind
operator|==
literal|1
operator|&&
name|pg_ps_enabled
operator|&&
name|pmap_enter_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|)
condition|)
name|m
operator|=
operator|&
name|m
index|[
name|NBPDR
operator|/
name|PAGE_SIZE
operator|-
literal|1
index|]
expr_stmt|;
else|else
name|mpte
operator|=
name|pmap_enter_quick_locked
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
name|mpte
argument_list|)
expr_stmt|;
name|m
operator|=
name|TAILQ_NEXT
argument_list|(
name|m
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * this code makes some *MAJOR* assumptions:  * 1. Current pmap& pmap exists.  * 2. Not wired.  * 3. Read access.  * 4. No page table pages.  * but is *MUCH* faster than pmap_enter...  */
end_comment

begin_function
name|void
name|pmap_enter_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|)
block|{
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|pmap_enter_quick_locked
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|,
name|prot
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|vm_page_t
name|pmap_enter_quick_locked
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_page_t
name|m
parameter_list|,
name|vm_prot_t
name|prot
parameter_list|,
name|vm_page_t
name|mpte
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|KASSERT
argument_list|(
name|va
operator|<
name|kmi
operator|.
name|clean_sva
operator|||
name|va
operator|>=
name|kmi
operator|.
name|clean_eva
operator|||
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_enter_quick_locked: managed mapping within the clean submap"
operator|)
argument_list|)
expr_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|PMAP_LOCK_ASSERT
argument_list|(
name|pmap
argument_list|,
name|MA_OWNED
argument_list|)
expr_stmt|;
comment|/* 	 * In the case that a page table page is not 	 * resident, we are creating it here. 	 */
if|if
condition|(
name|va
operator|<
name|VM_MAXUSER_ADDRESS
condition|)
block|{
name|u_int
name|ptepindex
decl_stmt|;
name|pd_entry_t
name|ptepa
decl_stmt|;
comment|/* 		 * Calculate pagetable page index 		 */
name|ptepindex
operator|=
name|va
operator|>>
name|PDRSHIFT
expr_stmt|;
if|if
condition|(
name|mpte
operator|&&
operator|(
name|mpte
operator|->
name|pindex
operator|==
name|ptepindex
operator|)
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* 			 * Get the page directory entry 			 */
name|ptepa
operator|=
name|pmap
operator|->
name|pm_pdir
index|[
name|ptepindex
index|]
expr_stmt|;
comment|/* 			 * If the page table page is mapped, we just increment 			 * the hold count, and activate it. 			 */
if|if
condition|(
name|ptepa
condition|)
block|{
if|if
condition|(
name|ptepa
operator|&
name|PG_PS
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|mpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|ptepa
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|mpte
operator|->
name|wire_count
operator|++
expr_stmt|;
block|}
else|else
block|{
name|mpte
operator|=
name|_pmap_allocpte
argument_list|(
name|pmap
argument_list|,
name|ptepindex
argument_list|,
name|PMAP_ENTER_NOSLEEP
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|==
name|NULL
condition|)
return|return
operator|(
name|mpte
operator|)
return|;
block|}
block|}
block|}
else|else
block|{
name|mpte
operator|=
name|NULL
expr_stmt|;
block|}
comment|/* 	 * This call to vtopte makes the assumption that we are 	 * entering the page into the current pmap.  In order to support 	 * quick entry into any pmap, one would likely use pmap_pte_quick. 	 * But that isn't as quick as vtopte. 	 */
name|pte
operator|=
name|vtopte
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pte
condition|)
block|{
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|mpte
operator|->
name|wire_count
operator|--
expr_stmt|;
name|mpte
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|mpte
operator|)
return|;
block|}
comment|/* 	 * Enter on the PV list if part of our managed memory. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
operator|&&
operator|!
name|pmap_try_insert_pv_entry
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|m
argument_list|)
condition|)
block|{
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_unwire_ptp
argument_list|(
name|pmap
argument_list|,
name|mpte
argument_list|,
operator|&
name|free
argument_list|)
condition|)
block|{
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
name|mpte
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|mpte
operator|)
return|;
block|}
comment|/* 	 * Increment counters 	 */
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|pmap_cache_bits
argument_list|(
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_EXECUTE
operator|)
operator|==
literal|0
condition|)
name|pa
operator||=
name|pg_nx
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Now validate mapping with RO protection 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
name|pte_store
argument_list|(
name|pte
argument_list|,
name|pa
operator||
name|PG_V
operator||
name|PG_U
argument_list|)
expr_stmt|;
else|else
name|pte_store
argument_list|(
name|pte
argument_list|,
name|pa
operator||
name|PG_V
operator||
name|PG_U
operator||
name|PG_MANAGED
argument_list|)
expr_stmt|;
return|return
operator|(
name|mpte
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Make a temporary mapping for a physical address.  This is only intended  * to be used for panic dumps.  */
end_comment

begin_function
name|void
modifier|*
name|pmap_kenter_temporary
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|int
name|i
parameter_list|)
block|{
name|vm_offset_t
name|va
decl_stmt|;
name|va
operator|=
operator|(
name|vm_offset_t
operator|)
name|crashdumpmap
operator|+
operator|(
name|i
operator|*
name|PAGE_SIZE
operator|)
expr_stmt|;
name|pmap_kenter
argument_list|(
name|va
argument_list|,
name|pa
argument_list|)
expr_stmt|;
name|invlpg
argument_list|(
name|va
argument_list|)
expr_stmt|;
return|return
operator|(
operator|(
name|void
operator|*
operator|)
name|crashdumpmap
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * This code maps large physical mmap regions into the  * processor address space.  Note that some shortcuts  * are taken, but the code works.  */
end_comment

begin_function
name|void
name|pmap_object_init_pt
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|vm_object_t
name|object
parameter_list|,
name|vm_pindex_t
name|pindex
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|,
name|ptepa
decl_stmt|;
name|vm_page_t
name|p
decl_stmt|;
name|int
name|pat_mode
decl_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|object
operator|->
name|type
operator|==
name|OBJT_DEVICE
operator|||
name|object
operator|->
name|type
operator|==
name|OBJT_SG
argument_list|,
operator|(
literal|"pmap_object_init_pt: non-device object"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pseflag
operator|&&
operator|(
name|addr
operator|&
operator|(
name|NBPDR
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
operator|&&
operator|(
name|size
operator|&
operator|(
name|NBPDR
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|vm_object_populate
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|,
name|pindex
operator|+
name|atop
argument_list|(
name|size
argument_list|)
argument_list|)
condition|)
return|return;
name|p
operator|=
name|vm_page_lookup
argument_list|(
name|object
argument_list|,
name|pindex
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|p
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
argument_list|,
operator|(
literal|"pmap_object_init_pt: invalid page %p"
operator|,
name|p
operator|)
argument_list|)
expr_stmt|;
name|pat_mode
operator|=
name|p
operator|->
name|md
operator|.
name|pat_mode
expr_stmt|;
comment|/* 		 * Abort the mapping if the first page is not physically 		 * aligned to a 2/4MB page boundary. 		 */
name|ptepa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|ptepa
operator|&
operator|(
name|NBPDR
operator|-
literal|1
operator|)
condition|)
return|return;
comment|/* 		 * Skip the first page.  Abort the mapping if the rest of 		 * the pages are not physically contiguous or have differing 		 * memory attributes. 		 */
name|p
operator|=
name|TAILQ_NEXT
argument_list|(
name|p
argument_list|,
name|listq
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|ptepa
operator|+
name|PAGE_SIZE
init|;
name|pa
operator|<
name|ptepa
operator|+
name|size
condition|;
name|pa
operator|+=
name|PAGE_SIZE
control|)
block|{
name|KASSERT
argument_list|(
name|p
operator|->
name|valid
operator|==
name|VM_PAGE_BITS_ALL
argument_list|,
operator|(
literal|"pmap_object_init_pt: invalid page %p"
operator|,
name|p
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pa
operator|!=
name|VM_PAGE_TO_PHYS
argument_list|(
name|p
argument_list|)
operator|||
name|pat_mode
operator|!=
name|p
operator|->
name|md
operator|.
name|pat_mode
condition|)
return|return;
name|p
operator|=
name|TAILQ_NEXT
argument_list|(
name|p
argument_list|,
name|listq
argument_list|)
expr_stmt|;
block|}
comment|/* 		 * Map using 2/4MB pages.  Since "ptepa" is 2/4M aligned and 		 * "size" is a multiple of 2/4M, adding the PAT setting to 		 * "pa" will not affect the termination of this loop. 		 */
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
name|pa
operator|=
name|ptepa
operator||
name|pmap_cache_bits
argument_list|(
name|pat_mode
argument_list|,
literal|1
argument_list|)
init|;
name|pa
operator|<
name|ptepa
operator|+
name|size
condition|;
name|pa
operator|+=
name|NBPDR
control|)
block|{
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pde
operator|==
literal|0
condition|)
block|{
name|pde_store
argument_list|(
name|pde
argument_list|,
name|pa
operator||
name|PG_PS
operator||
name|PG_M
operator||
name|PG_A
operator||
name|PG_U
operator||
name|PG_RW
operator||
name|PG_V
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|+=
name|NBPDR
operator|/
name|PAGE_SIZE
expr_stmt|;
name|pmap_pde_mappings
operator|++
expr_stmt|;
block|}
comment|/* Else continue on if the PDE is already valid. */
name|addr
operator|+=
name|NBPDR
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  *	Clear the wired attribute from the mappings for the specified range of  *	addresses in the given pmap.  Every valid mapping within that range  *	must have the wired attribute set.  In contrast, invalid mappings  *	cannot have the wired attribute set, so they are ignored.  *  *	The wired attribute of the page table entry is not a hardware feature,  *	so there is no need to invalidate any TLB entries.  */
end_comment

begin_function
name|void
name|pmap_unwire
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|)
block|{
name|vm_offset_t
name|pdnxt
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|boolean_t
name|pv_lists_locked
decl_stmt|;
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
name|pv_lists_locked
operator|=
name|FALSE
expr_stmt|;
else|else
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
name|resume
label|:
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
block|}
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|pdnxt
control|)
block|{
name|pdnxt
operator|=
operator|(
name|sva
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|pdnxt
operator|<
name|sva
condition|)
name|pdnxt
operator|=
name|eva
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_unwire: pde %#jx is missing PG_W"
argument_list|,
operator|(
name|uintmax_t
operator|)
operator|*
name|pde
argument_list|)
expr_stmt|;
comment|/* 			 * Are we unwiring the entire large page?  If not, 			 * demote the mapping and fall through. 			 */
if|if
condition|(
name|sva
operator|+
name|NBPDR
operator|==
name|pdnxt
operator|&&
name|eva
operator|>=
name|pdnxt
condition|)
block|{
comment|/* 				 * Regardless of whether a pde (or pte) is 32 				 * or 64 bits in size, PG_W is among the least 				 * significant 32 bits. 				 */
name|atomic_clear_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pde
argument_list|,
name|PG_W
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|-=
name|NBPDR
operator|/
name|PAGE_SIZE
expr_stmt|;
continue|continue;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|pv_lists_locked
condition|)
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
if|if
condition|(
operator|!
name|rw_try_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Repeat sva. */
goto|goto
name|resume
goto|;
block|}
name|sched_pin
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|sva
argument_list|)
condition|)
name|panic
argument_list|(
literal|"pmap_unwire: demotion failed"
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pdnxt
operator|>
name|eva
condition|)
name|pdnxt
operator|=
name|eva
expr_stmt|;
for|for
control|(
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|pdnxt
condition|;
name|pte
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_unwire: pte %#jx is missing PG_W"
argument_list|,
operator|(
name|uintmax_t
operator|)
operator|*
name|pte
argument_list|)
expr_stmt|;
comment|/* 			 * PG_W must be cleared atomically.  Although the pmap 			 * lock synchronizes access to PG_W, another processor 			 * could be setting PG_M and/or PG_A concurrently. 			 * 			 * PG_W is among the least significant 32 bits. 			 */
name|atomic_clear_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|PG_W
argument_list|)
expr_stmt|;
name|pmap
operator|->
name|pm_stats
operator|.
name|wired_count
operator|--
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pv_lists_locked
condition|)
block|{
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Copy the range specified by src_addr/len  *	from the source map to the range dst_addr/len  *	in the destination map.  *  *	This routine is only advisory and need not do anything.  */
end_comment

begin_function
name|void
name|pmap_copy
parameter_list|(
name|pmap_t
name|dst_pmap
parameter_list|,
name|pmap_t
name|src_pmap
parameter_list|,
name|vm_offset_t
name|dst_addr
parameter_list|,
name|vm_size_t
name|len
parameter_list|,
name|vm_offset_t
name|src_addr
parameter_list|)
block|{
name|struct
name|spglist
name|free
decl_stmt|;
name|vm_offset_t
name|addr
decl_stmt|;
name|vm_offset_t
name|end_addr
init|=
name|src_addr
operator|+
name|len
decl_stmt|;
name|vm_offset_t
name|pdnxt
decl_stmt|;
if|if
condition|(
name|dst_addr
operator|!=
name|src_addr
condition|)
return|return;
if|if
condition|(
operator|!
name|pmap_is_current
argument_list|(
name|src_pmap
argument_list|)
condition|)
return|return;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|dst_pmap
operator|<
name|src_pmap
condition|)
block|{
name|PMAP_LOCK
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|src_pmap
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|PMAP_LOCK
argument_list|(
name|src_pmap
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
block|}
name|sched_pin
argument_list|()
expr_stmt|;
for|for
control|(
name|addr
operator|=
name|src_addr
init|;
name|addr
operator|<
name|end_addr
condition|;
name|addr
operator|=
name|pdnxt
control|)
block|{
name|pt_entry_t
modifier|*
name|src_pte
decl_stmt|,
modifier|*
name|dst_pte
decl_stmt|;
name|vm_page_t
name|dstmpte
decl_stmt|,
name|srcmpte
decl_stmt|;
name|pd_entry_t
name|srcptepaddr
decl_stmt|;
name|u_int
name|ptepindex
decl_stmt|;
name|KASSERT
argument_list|(
name|addr
operator|<
name|UPT_MIN_ADDRESS
argument_list|,
operator|(
literal|"pmap_copy: invalid to pmap_copy page tables"
operator|)
argument_list|)
expr_stmt|;
name|pdnxt
operator|=
operator|(
name|addr
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|pdnxt
operator|<
name|addr
condition|)
name|pdnxt
operator|=
name|end_addr
expr_stmt|;
name|ptepindex
operator|=
name|addr
operator|>>
name|PDRSHIFT
expr_stmt|;
name|srcptepaddr
operator|=
name|src_pmap
operator|->
name|pm_pdir
index|[
name|ptepindex
index|]
expr_stmt|;
if|if
condition|(
name|srcptepaddr
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
name|srcptepaddr
operator|&
name|PG_PS
condition|)
block|{
if|if
condition|(
operator|(
name|addr
operator|&
name|PDRMASK
operator|)
operator|!=
literal|0
operator|||
name|addr
operator|+
name|NBPDR
operator|>
name|end_addr
condition|)
continue|continue;
if|if
condition|(
name|dst_pmap
operator|->
name|pm_pdir
index|[
name|ptepindex
index|]
operator|==
literal|0
operator|&&
operator|(
operator|(
name|srcptepaddr
operator|&
name|PG_MANAGED
operator|)
operator|==
literal|0
operator|||
name|pmap_pv_insert_pde
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|srcptepaddr
operator|&
name|PG_PS_FRAME
argument_list|)
operator|)
condition|)
block|{
name|dst_pmap
operator|->
name|pm_pdir
index|[
name|ptepindex
index|]
operator|=
name|srcptepaddr
operator|&
operator|~
name|PG_W
expr_stmt|;
name|dst_pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|+=
name|NBPDR
operator|/
name|PAGE_SIZE
expr_stmt|;
name|pmap_pde_mappings
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
name|srcmpte
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|srcptepaddr
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|srcmpte
operator|->
name|wire_count
operator|>
literal|0
argument_list|,
operator|(
literal|"pmap_copy: source page table page is unused"
operator|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|pdnxt
operator|>
name|end_addr
condition|)
name|pdnxt
operator|=
name|end_addr
expr_stmt|;
name|src_pte
operator|=
name|vtopte
argument_list|(
name|addr
argument_list|)
expr_stmt|;
while|while
condition|(
name|addr
operator|<
name|pdnxt
condition|)
block|{
name|pt_entry_t
name|ptetemp
decl_stmt|;
name|ptetemp
operator|=
operator|*
name|src_pte
expr_stmt|;
comment|/* 			 * we only virtual copy managed pages 			 */
if|if
condition|(
operator|(
name|ptetemp
operator|&
name|PG_MANAGED
operator|)
operator|!=
literal|0
condition|)
block|{
name|dstmpte
operator|=
name|pmap_allocpte
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|PMAP_ENTER_NOSLEEP
argument_list|)
expr_stmt|;
if|if
condition|(
name|dstmpte
operator|==
name|NULL
condition|)
goto|goto
name|out
goto|;
name|dst_pte
operator|=
name|pmap_pte_quick
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|dst_pte
operator|==
literal|0
operator|&&
name|pmap_try_insert_pv_entry
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|,
name|PHYS_TO_VM_PAGE
argument_list|(
name|ptetemp
operator|&
name|PG_FRAME
argument_list|)
argument_list|)
condition|)
block|{
comment|/* 					 * Clear the wired, modified, and 					 * accessed (referenced) bits 					 * during the copy. 					 */
operator|*
name|dst_pte
operator|=
name|ptetemp
operator|&
operator|~
operator|(
name|PG_W
operator||
name|PG_M
operator||
name|PG_A
operator|)
expr_stmt|;
name|dst_pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|++
expr_stmt|;
block|}
else|else
block|{
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmap_unwire_ptp
argument_list|(
name|dst_pmap
argument_list|,
name|dstmpte
argument_list|,
operator|&
name|free
argument_list|)
condition|)
block|{
name|pmap_invalidate_page
argument_list|(
name|dst_pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
goto|goto
name|out
goto|;
block|}
if|if
condition|(
name|dstmpte
operator|->
name|wire_count
operator|>=
name|srcmpte
operator|->
name|wire_count
condition|)
break|break;
block|}
name|addr
operator|+=
name|PAGE_SIZE
expr_stmt|;
name|src_pte
operator|++
expr_stmt|;
block|}
block|}
name|out
label|:
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|src_pmap
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|dst_pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Zero 1 page of virtual memory mapped from a hardware page by the caller.  */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pagezero
parameter_list|(
name|void
modifier|*
name|page
parameter_list|)
block|{
if|#
directive|if
name|defined
argument_list|(
name|I686_CPU
argument_list|)
if|if
condition|(
name|cpu_class
operator|==
name|CPUCLASS_686
condition|)
block|{
if|if
condition|(
name|cpu_feature
operator|&
name|CPUID_SSE2
condition|)
name|sse2_pagezero
argument_list|(
name|page
argument_list|)
expr_stmt|;
else|else
name|i686_pagezero
argument_list|(
name|page
argument_list|)
expr_stmt|;
block|}
else|else
endif|#
directive|endif
name|bzero
argument_list|(
name|page
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Zero the specified hardware page.  */
end_comment

begin_function
name|void
name|pmap_zero_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|cmap_pte2
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap_pte2
operator|=
name|pc
operator|->
name|pc_cmap_pte2
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cmap_pte2
condition|)
name|panic
argument_list|(
literal|"pmap_zero_page: CMAP2 busy"
argument_list|)
expr_stmt|;
operator|*
name|cmap_pte2
operator|=
name|PG_V
operator||
name|PG_RW
operator||
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|PG_A
operator||
name|PG_M
operator||
name|pmap_cache_bits
argument_list|(
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|invlcaddr
argument_list|(
name|pc
operator|->
name|pc_cmap_addr2
argument_list|)
expr_stmt|;
name|pagezero
argument_list|(
name|pc
operator|->
name|pc_cmap_addr2
argument_list|)
expr_stmt|;
operator|*
name|cmap_pte2
operator|=
literal|0
expr_stmt|;
comment|/* 	 * Unpin the thread before releasing the lock.  Otherwise the thread 	 * could be rescheduled while still bound to the current CPU, only 	 * to unpin itself immediately upon resuming execution. 	 */
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Zero an an area within a single hardware page.  off and size must not  * cover an area beyond a single hardware page.  */
end_comment

begin_function
name|void
name|pmap_zero_page_area
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|size
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|cmap_pte2
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap_pte2
operator|=
name|pc
operator|->
name|pc_cmap_pte2
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cmap_pte2
condition|)
name|panic
argument_list|(
literal|"pmap_zero_page_area: CMAP2 busy"
argument_list|)
expr_stmt|;
operator|*
name|cmap_pte2
operator|=
name|PG_V
operator||
name|PG_RW
operator||
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|PG_A
operator||
name|PG_M
operator||
name|pmap_cache_bits
argument_list|(
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|invlcaddr
argument_list|(
name|pc
operator|->
name|pc_cmap_addr2
argument_list|)
expr_stmt|;
if|if
condition|(
name|off
operator|==
literal|0
operator|&&
name|size
operator|==
name|PAGE_SIZE
condition|)
name|pagezero
argument_list|(
name|pc
operator|->
name|pc_cmap_addr2
argument_list|)
expr_stmt|;
else|else
name|bzero
argument_list|(
name|pc
operator|->
name|pc_cmap_addr2
operator|+
name|off
argument_list|,
name|size
argument_list|)
expr_stmt|;
operator|*
name|cmap_pte2
operator|=
literal|0
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Copy 1 specified hardware page to another.  */
end_comment

begin_function
name|void
name|pmap_copy_page
parameter_list|(
name|vm_page_t
name|src
parameter_list|,
name|vm_page_t
name|dst
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|cmap_pte1
decl_stmt|,
modifier|*
name|cmap_pte2
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap_pte1
operator|=
name|pc
operator|->
name|pc_cmap_pte1
expr_stmt|;
name|cmap_pte2
operator|=
name|pc
operator|->
name|pc_cmap_pte2
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cmap_pte1
condition|)
name|panic
argument_list|(
literal|"pmap_copy_page: CMAP1 busy"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cmap_pte2
condition|)
name|panic
argument_list|(
literal|"pmap_copy_page: CMAP2 busy"
argument_list|)
expr_stmt|;
operator|*
name|cmap_pte1
operator|=
name|PG_V
operator||
name|VM_PAGE_TO_PHYS
argument_list|(
name|src
argument_list|)
operator||
name|PG_A
operator||
name|pmap_cache_bits
argument_list|(
name|src
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|invlcaddr
argument_list|(
name|pc
operator|->
name|pc_cmap_addr1
argument_list|)
expr_stmt|;
operator|*
name|cmap_pte2
operator|=
name|PG_V
operator||
name|PG_RW
operator||
name|VM_PAGE_TO_PHYS
argument_list|(
name|dst
argument_list|)
operator||
name|PG_A
operator||
name|PG_M
operator||
name|pmap_cache_bits
argument_list|(
name|dst
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|invlcaddr
argument_list|(
name|pc
operator|->
name|pc_cmap_addr2
argument_list|)
expr_stmt|;
name|bcopy
argument_list|(
name|pc
operator|->
name|pc_cmap_addr1
argument_list|,
name|pc
operator|->
name|pc_cmap_addr2
argument_list|,
name|PAGE_SIZE
argument_list|)
expr_stmt|;
operator|*
name|cmap_pte1
operator|=
literal|0
expr_stmt|;
operator|*
name|cmap_pte2
operator|=
literal|0
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_decl_stmt
name|int
name|unmapped_buf_allowed
init|=
literal|1
decl_stmt|;
end_decl_stmt

begin_function
name|void
name|pmap_copy_pages
parameter_list|(
name|vm_page_t
name|ma
index|[]
parameter_list|,
name|vm_offset_t
name|a_offset
parameter_list|,
name|vm_page_t
name|mb
index|[]
parameter_list|,
name|vm_offset_t
name|b_offset
parameter_list|,
name|int
name|xfersize
parameter_list|)
block|{
name|vm_page_t
name|a_pg
decl_stmt|,
name|b_pg
decl_stmt|;
name|char
modifier|*
name|a_cp
decl_stmt|,
modifier|*
name|b_cp
decl_stmt|;
name|vm_offset_t
name|a_pg_offset
decl_stmt|,
name|b_pg_offset
decl_stmt|;
name|pt_entry_t
modifier|*
name|cmap_pte1
decl_stmt|,
modifier|*
name|cmap_pte2
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|int
name|cnt
decl_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap_pte1
operator|=
name|pc
operator|->
name|pc_cmap_pte1
expr_stmt|;
name|cmap_pte2
operator|=
name|pc
operator|->
name|pc_cmap_pte2
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cmap_pte1
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_copy_pages: CMAP1 busy"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cmap_pte2
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_copy_pages: CMAP2 busy"
argument_list|)
expr_stmt|;
while|while
condition|(
name|xfersize
operator|>
literal|0
condition|)
block|{
name|a_pg
operator|=
name|ma
index|[
name|a_offset
operator|>>
name|PAGE_SHIFT
index|]
expr_stmt|;
name|a_pg_offset
operator|=
name|a_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|xfersize
argument_list|,
name|PAGE_SIZE
operator|-
name|a_pg_offset
argument_list|)
expr_stmt|;
name|b_pg
operator|=
name|mb
index|[
name|b_offset
operator|>>
name|PAGE_SHIFT
index|]
expr_stmt|;
name|b_pg_offset
operator|=
name|b_offset
operator|&
name|PAGE_MASK
expr_stmt|;
name|cnt
operator|=
name|min
argument_list|(
name|cnt
argument_list|,
name|PAGE_SIZE
operator|-
name|b_pg_offset
argument_list|)
expr_stmt|;
operator|*
name|cmap_pte1
operator|=
name|PG_V
operator||
name|VM_PAGE_TO_PHYS
argument_list|(
name|a_pg
argument_list|)
operator||
name|PG_A
operator||
name|pmap_cache_bits
argument_list|(
name|a_pg
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|invlcaddr
argument_list|(
name|pc
operator|->
name|pc_cmap_addr1
argument_list|)
expr_stmt|;
operator|*
name|cmap_pte2
operator|=
name|PG_V
operator||
name|PG_RW
operator||
name|VM_PAGE_TO_PHYS
argument_list|(
name|b_pg
argument_list|)
operator||
name|PG_A
operator||
name|PG_M
operator||
name|pmap_cache_bits
argument_list|(
name|b_pg
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|invlcaddr
argument_list|(
name|pc
operator|->
name|pc_cmap_addr2
argument_list|)
expr_stmt|;
name|a_cp
operator|=
name|pc
operator|->
name|pc_cmap_addr1
operator|+
name|a_pg_offset
expr_stmt|;
name|b_cp
operator|=
name|pc
operator|->
name|pc_cmap_addr2
operator|+
name|b_pg_offset
expr_stmt|;
name|bcopy
argument_list|(
name|a_cp
argument_list|,
name|b_cp
argument_list|,
name|cnt
argument_list|)
expr_stmt|;
name|a_offset
operator|+=
name|cnt
expr_stmt|;
name|b_offset
operator|+=
name|cnt
expr_stmt|;
name|xfersize
operator|-=
name|cnt
expr_stmt|;
block|}
operator|*
name|cmap_pte1
operator|=
literal|0
expr_stmt|;
operator|*
name|cmap_pte2
operator|=
literal|0
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Returns true if the pmap's pv is one of the first  * 16 pvs linked to from this page.  This count may  * be changed upwards or downwards in the future; it  * is only necessary that true be returned for a small  * subset of pmaps for proper page aging.  */
end_comment

begin_function
name|boolean_t
name|pmap_page_exists_quick
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|int
name|loops
init|=
literal|0
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_page_exists_quick: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|==
name|pmap
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
name|loops
operator|++
expr_stmt|;
if|if
condition|(
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
if|if
condition|(
operator|!
name|rv
operator|&&
name|loops
operator|<
literal|16
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
if|if
condition|(
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
operator|==
name|pmap
condition|)
block|{
name|rv
operator|=
name|TRUE
expr_stmt|;
break|break;
block|}
name|loops
operator|++
expr_stmt|;
if|if
condition|(
name|loops
operator|>=
literal|16
condition|)
break|break;
block|}
block|}
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_page_wired_mappings:  *  *	Return the number of managed mappings to the given physical page  *	that are wired.  */
end_comment

begin_function
name|int
name|pmap_page_wired_mappings
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|int
name|count
decl_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|count
operator|)
return|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|count
operator|=
name|pmap_pvh_wired_mappings
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|,
name|count
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|count
operator|=
name|pmap_pvh_wired_mappings
argument_list|(
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_pvh_wired_mappings:  *  *	Return the updated number "count" of managed mappings that are wired.  */
end_comment

begin_function
specifier|static
name|int
name|pmap_pvh_wired_mappings
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|,
name|int
name|count
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_W
operator|)
operator|!=
literal|0
condition|)
name|count
operator|++
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
return|return
operator|(
name|count
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns TRUE if the given page is mapped individually or as part of  * a 4mpage.  Otherwise, returns FALSE.  */
end_comment

begin_function
name|boolean_t
name|pmap_page_is_mapped
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|boolean_t
name|rv
decl_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|!=
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|rv
operator|=
operator|!
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|||
operator|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
operator|!
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
operator|->
name|pv_list
argument_list|)
operator|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Remove all pages from specified address space  * this aids process exit speeds.  Also, this code  * is special cased for current process only, but  * can have the more generic (and slightly slower)  * mode enabled.  This is much faster than pmap_remove  * in the case of running down an entire address space.  */
end_comment

begin_function
name|void
name|pmap_remove_pages
parameter_list|(
name|pmap_t
name|pmap
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|pte
decl_stmt|,
name|tpte
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|,
name|mpte
decl_stmt|,
name|mt
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|;
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|struct
name|pv_chunk
modifier|*
name|pc
decl_stmt|,
modifier|*
name|npc
decl_stmt|;
name|struct
name|spglist
name|free
decl_stmt|;
name|int
name|field
decl_stmt|,
name|idx
decl_stmt|;
name|int32_t
name|bit
decl_stmt|;
name|uint32_t
name|inuse
decl_stmt|,
name|bitmask
decl_stmt|;
name|int
name|allfree
decl_stmt|;
if|if
condition|(
name|pmap
operator|!=
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
condition|)
block|{
name|printf
argument_list|(
literal|"warning: pmap_remove_pages called with non-current pmap\n"
argument_list|)
expr_stmt|;
return|return;
block|}
name|SLIST_INIT
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|pc
argument_list|,
argument|&pmap->pm_pvchunk
argument_list|,
argument|pc_list
argument_list|,
argument|npc
argument_list|)
block|{
name|KASSERT
argument_list|(
name|pc
operator|->
name|pc_pmap
operator|==
name|pmap
argument_list|,
operator|(
literal|"Wrong pmap %p %p"
operator|,
name|pmap
operator|,
name|pc
operator|->
name|pc_pmap
operator|)
argument_list|)
expr_stmt|;
name|allfree
operator|=
literal|1
expr_stmt|;
for|for
control|(
name|field
operator|=
literal|0
init|;
name|field
operator|<
name|_NPCM
condition|;
name|field
operator|++
control|)
block|{
name|inuse
operator|=
operator|~
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator|&
name|pc_freemask
index|[
name|field
index|]
expr_stmt|;
while|while
condition|(
name|inuse
operator|!=
literal|0
condition|)
block|{
name|bit
operator|=
name|bsfl
argument_list|(
name|inuse
argument_list|)
expr_stmt|;
name|bitmask
operator|=
literal|1UL
operator|<<
name|bit
expr_stmt|;
name|idx
operator|=
name|field
operator|*
literal|32
operator|+
name|bit
expr_stmt|;
name|pv
operator|=
operator|&
name|pc
operator|->
name|pc_pventry
index|[
name|idx
index|]
expr_stmt|;
name|inuse
operator|&=
operator|~
name|bitmask
expr_stmt|;
name|pte
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|tpte
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_PS
operator|)
operator|==
literal|0
condition|)
block|{
name|pte
operator|=
name|vtopte
argument_list|(
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|tpte
operator|=
operator|*
name|pte
operator|&
operator|~
name|PG_PTE_PAT
expr_stmt|;
block|}
if|if
condition|(
name|tpte
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"TPTE at %p  IS ZERO @ VA %08x\n"
argument_list|,
name|pte
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|panic
argument_list|(
literal|"bad pte"
argument_list|)
expr_stmt|;
block|}
comment|/*  * We cannot remove wired pages from a process' mapping at this time  */
if|if
condition|(
name|tpte
operator|&
name|PG_W
condition|)
block|{
name|allfree
operator|=
literal|0
expr_stmt|;
continue|continue;
block|}
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|tpte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|m
operator|->
name|phys_addr
operator|==
operator|(
name|tpte
operator|&
name|PG_FRAME
operator|)
argument_list|,
operator|(
literal|"vm_page_t %p phys_addr mismatch %016jx %016jx"
operator|,
name|m
operator|,
operator|(
name|uintmax_t
operator|)
name|m
operator|->
name|phys_addr
operator|,
operator|(
name|uintmax_t
operator|)
name|tpte
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
operator|||
name|m
operator|<
operator|&
name|vm_page_array
index|[
name|vm_page_array_size
index|]
argument_list|,
operator|(
literal|"pmap_remove_pages: bad tpte %#jx"
operator|,
operator|(
name|uintmax_t
operator|)
name|tpte
operator|)
argument_list|)
expr_stmt|;
name|pte_clear
argument_list|(
name|pte
argument_list|)
expr_stmt|;
comment|/* 				 * Update the vm_page_t clean/reference bits. 				 */
if|if
condition|(
operator|(
name|tpte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
for|for
control|(
name|mt
operator|=
name|m
init|;
name|mt
operator|<
operator|&
name|m
index|[
name|NBPDR
operator|/
name|PAGE_SIZE
index|]
condition|;
name|mt
operator|++
control|)
name|vm_page_dirty
argument_list|(
name|mt
argument_list|)
expr_stmt|;
block|}
else|else
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
comment|/* Mark free */
name|PV_STAT
argument_list|(
name|pv_entry_frees
operator|++
argument_list|)
expr_stmt|;
name|PV_STAT
argument_list|(
name|pv_entry_spare
operator|++
argument_list|)
expr_stmt|;
name|pv_entry_count
operator|--
expr_stmt|;
name|pc
operator|->
name|pc_map
index|[
name|field
index|]
operator||=
name|bitmask
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|-=
name|NBPDR
operator|/
name|PAGE_SIZE
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|tpte
operator|&
name|PG_PS_FRAME
argument_list|)
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
block|{
for|for
control|(
name|mt
operator|=
name|m
init|;
name|mt
operator|<
operator|&
name|m
index|[
name|NBPDR
operator|/
name|PAGE_SIZE
index|]
condition|;
name|mt
operator|++
control|)
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|mt
operator|->
name|md
operator|.
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|mt
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
name|mpte
operator|=
name|pmap_remove_pt_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
name|mpte
operator|!=
name|NULL
condition|)
block|{
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
name|KASSERT
argument_list|(
name|mpte
operator|->
name|wire_count
operator|==
name|NPTEPG
argument_list|,
operator|(
literal|"pmap_remove_pages: pte page wire count error"
operator|)
argument_list|)
expr_stmt|;
name|mpte
operator|->
name|wire_count
operator|=
literal|0
expr_stmt|;
name|pmap_add_delayed_free_list
argument_list|(
name|mpte
argument_list|,
operator|&
name|free
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|atomic_subtract_int
argument_list|(
operator|&
name|vm_cnt
operator|.
name|v_wire_count
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|pmap
operator|->
name|pm_stats
operator|.
name|resident_count
operator|--
expr_stmt|;
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
condition|)
block|{
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|TAILQ_EMPTY
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
condition|)
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
block|}
name|pmap_unuse_pt
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|,
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|allfree
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pmap
operator|->
name|pm_pvchunk
argument_list|,
name|pc
argument_list|,
name|pc_list
argument_list|)
expr_stmt|;
name|free_pv_chunk
argument_list|(
name|pc
argument_list|)
expr_stmt|;
block|}
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pmap_free_zero_pages
argument_list|(
operator|&
name|free
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_modified:  *  *	Return whether or not the specified physical page was modified  *	in any physical maps.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_modified
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_is_modified: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not exclusive busied, then PGA_WRITEABLE cannot be 	 * concurrently set while the object is locked.  Thus, if PGA_WRITEABLE 	 * is clear, no PTEs can have PG_M set. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return
operator|(
name|FALSE
operator|)
return|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|rv
operator|=
name|pmap_is_modified_pvh
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|)
operator|||
operator|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
name|pmap_is_modified_pvh
argument_list|(
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
operator|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns TRUE if any of the given mappings were used to modify  * physical memory.  Otherwise, returns FALSE.  Both page and 2mpage  * mappings are supported.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_is_modified_pvh
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|rv
operator|=
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
condition|)
break|break;
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_prefaultable:  *  *	Return whether or not the specified virtual address is elgible  *	for prefault.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_prefaultable
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pde
operator|!=
literal|0
operator|&&
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
condition|)
block|{
name|pte
operator|=
name|vtopte
argument_list|(
name|addr
argument_list|)
expr_stmt|;
name|rv
operator|=
operator|*
name|pte
operator|==
literal|0
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	pmap_is_referenced:  *  *	Return whether or not the specified physical page was referenced  *	in any physical maps.  */
end_comment

begin_function
name|boolean_t
name|pmap_is_referenced
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|boolean_t
name|rv
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_is_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|rv
operator|=
name|pmap_is_referenced_pvh
argument_list|(
operator|&
name|m
operator|->
name|md
argument_list|)
operator|||
operator|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|==
literal|0
operator|&&
name|pmap_is_referenced_pvh
argument_list|(
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
argument_list|)
operator|)
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Returns TRUE if any of the given mappings were referenced and FALSE  * otherwise.  Both page and 4mpage mappings are supported.  */
end_comment

begin_function
specifier|static
name|boolean_t
name|pmap_is_referenced_pvh
parameter_list|(
name|struct
name|md_page
modifier|*
name|pvh
parameter_list|)
block|{
name|pv_entry_t
name|pv
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|boolean_t
name|rv
decl_stmt|;
name|rw_assert
argument_list|(
operator|&
name|pvh_global_lock
argument_list|,
name|RA_WLOCKED
argument_list|)
expr_stmt|;
name|rv
operator|=
name|FALSE
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|rv
operator|=
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_A
operator||
name|PG_V
operator|)
operator|)
operator|==
operator|(
name|PG_A
operator||
name|PG_V
operator|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|rv
condition|)
break|break;
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
return|return
operator|(
name|rv
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Clear the write and modified bits in each of the given page's mappings.  */
end_comment

begin_function
name|void
name|pmap_remove_write
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|next_pv
decl_stmt|,
name|pv
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
name|oldpte
decl_stmt|,
modifier|*
name|pte
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_remove_write: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not exclusive busied, then PGA_WRITEABLE cannot be 	 * set by another thread while the object is locked.  Thus, 	 * if PGA_WRITEABLE is clear, no page table entries need updating. 	 */
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
operator|&&
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
goto|goto
name|small_mappings
goto|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|,
argument|next_pv
argument_list|)
block|{
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_RW
operator|)
operator|!=
literal|0
condition|)
operator|(
name|void
operator|)
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|small_mappings
label|:
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_clear_write: found"
literal|" a 4mpage in page %p's pv list"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|retry
label|:
name|oldpte
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|oldpte
operator|&
name|PG_RW
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * Regardless of whether a pte is 32 or 64 bits 			 * in size, PG_RW and PG_M are among the least 			 * significant 32 bits. 			 */
if|if
condition|(
operator|!
name|atomic_cmpset_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|oldpte
argument_list|,
name|oldpte
operator|&
operator|~
operator|(
name|PG_RW
operator||
name|PG_M
operator|)
argument_list|)
condition|)
goto|goto
name|retry
goto|;
if|if
condition|(
operator|(
name|oldpte
operator|&
name|PG_M
operator|)
operator|!=
literal|0
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|vm_page_aflag_clear
argument_list|(
name|m
argument_list|,
name|PGA_WRITEABLE
argument_list|)
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	pmap_ts_referenced:  *  *	Return a count of reference bits for a page, clearing those bits.  *	It is not necessary for every reference bit to be cleared, but it  *	is necessary that 0 only be returned when there are truly no  *	reference bits set.  *  *	As an optimization, update the page's dirty field if a modified bit is  *	found while counting reference bits.  This opportunistic update can be  *	performed at low cost and can eliminate the need for some future calls  *	to pmap_is_modified().  However, since this function stops after  *	finding PMAP_TS_REFERENCED_MAX reference bits, it may not detect some  *	dirty pages.  Those dirty pages will only be detected by a future call  *	to pmap_is_modified().  */
end_comment

begin_function
name|int
name|pmap_ts_referenced
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|pv
decl_stmt|,
name|pvf
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|int
name|rtval
init|=
literal|0
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_ts_referenced: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pa
operator|=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
operator|||
operator|(
name|pvf
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
operator|)
operator|==
name|NULL
condition|)
goto|goto
name|small_mappings
goto|;
name|pv
operator|=
name|pvf
expr_stmt|;
do|do
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
comment|/* 			 * Although "*pde" is mapping a 2/4MB page, because 			 * this function is called at a 4KB page granularity, 			 * we only update the 4KB page under test. 			 */
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 			 * Since this reference bit is shared by either 1024 			 * or 512 4KB pages, it should not be cleared every 			 * time it is tested.  Apply a simple "hash" function 			 * on the physical page number, the virtual superpage 			 * number, and the pmap address to select one 4KB page 			 * out of the 1024 or 512 on which testing the 			 * reference bit will result in clearing that bit. 			 * This function is designed to avoid the selection of 			 * the same 4KB page for every 2- or 4MB page mapping. 			 * 			 * On demotion, a mapping that hasn't been referenced 			 * is simply destroyed.  To avoid the possibility of a 			 * subsequent page fault on a demoted wired mapping, 			 * always leave its reference bit set.  Moreover, 			 * since the superpage is wired, the current state of 			 * its reference bit won't affect page replacement. 			 */
if|if
condition|(
operator|(
operator|(
operator|(
name|pa
operator|>>
name|PAGE_SHIFT
operator|)
operator|^
operator|(
name|pv
operator|->
name|pv_va
operator|>>
name|PDRSHIFT
operator|)
operator|^
operator|(
name|uintptr_t
operator|)
name|pmap
operator|)
operator|&
operator|(
name|NPTEPG
operator|-
literal|1
operator|)
operator|)
operator|==
literal|0
operator|&&
operator|(
operator|*
name|pde
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
block|{
name|atomic_clear_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pde
argument_list|,
name|PG_A
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
block|}
name|rtval
operator|++
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Rotate the PV list if it has more than one entry. */
if|if
condition|(
name|TAILQ_NEXT
argument_list|(
name|pv
argument_list|,
name|pv_next
argument_list|)
operator|!=
name|NULL
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|rtval
operator|>=
name|PMAP_TS_REFERENCED_MAX
condition|)
goto|goto
name|out
goto|;
block|}
do|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|pvh
operator|->
name|pv_list
argument_list|)
operator|)
operator|!=
name|pvf
condition|)
do|;
name|small_mappings
label|:
if|if
condition|(
operator|(
name|pvf
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|==
name|NULL
condition|)
goto|goto
name|out
goto|;
name|pv
operator|=
name|pvf
expr_stmt|;
do|do
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_ts_referenced: found a 4mpage in page %p's pv list"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
block|{
name|atomic_clear_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|PG_A
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|rtval
operator|++
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
comment|/* Rotate the PV list if it has more than one entry. */
if|if
condition|(
name|TAILQ_NEXT
argument_list|(
name|pv
argument_list|,
name|pv_next
argument_list|)
operator|!=
name|NULL
condition|)
block|{
name|TAILQ_REMOVE
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
name|TAILQ_INSERT_TAIL
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|,
name|pv
argument_list|,
name|pv_next
argument_list|)
expr_stmt|;
block|}
block|}
do|while
condition|(
operator|(
name|pv
operator|=
name|TAILQ_FIRST
argument_list|(
operator|&
name|m
operator|->
name|md
operator|.
name|pv_list
argument_list|)
operator|)
operator|!=
name|pvf
operator|&&
name|rtval
operator|<
name|PMAP_TS_REFERENCED_MAX
condition|)
do|;
name|out
label|:
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|rtval
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  *	Apply the given advice to the specified range of addresses within the  *	given pmap.  Depending on the advice, clear the referenced and/or  *	modified flags in each mapping and set the mapped page's dirty field.  */
end_comment

begin_function
name|void
name|pmap_advise
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|sva
parameter_list|,
name|vm_offset_t
name|eva
parameter_list|,
name|int
name|advice
parameter_list|)
block|{
name|pd_entry_t
name|oldpde
decl_stmt|,
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|pdnxt
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|boolean_t
name|anychanged
decl_stmt|,
name|pv_lists_locked
decl_stmt|;
if|if
condition|(
name|advice
operator|!=
name|MADV_DONTNEED
operator|&&
name|advice
operator|!=
name|MADV_FREE
condition|)
return|return;
if|if
condition|(
name|pmap_is_current
argument_list|(
name|pmap
argument_list|)
condition|)
name|pv_lists_locked
operator|=
name|FALSE
expr_stmt|;
else|else
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
name|resume
label|:
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
block|}
name|anychanged
operator|=
name|FALSE
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|=
name|pdnxt
control|)
block|{
name|pdnxt
operator|=
operator|(
name|sva
operator|+
name|NBPDR
operator|)
operator|&
operator|~
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|pdnxt
operator|<
name|sva
condition|)
name|pdnxt
operator|=
name|eva
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|oldpde
operator|=
operator|*
name|pde
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
continue|continue;
elseif|else
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_PS
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_MANAGED
operator|)
operator|==
literal|0
condition|)
continue|continue;
if|if
condition|(
operator|!
name|pv_lists_locked
condition|)
block|{
name|pv_lists_locked
operator|=
name|TRUE
expr_stmt|;
if|if
condition|(
operator|!
name|rw_try_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
condition|)
block|{
if|if
condition|(
name|anychanged
condition|)
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
goto|goto
name|resume
goto|;
block|}
name|sched_pin
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|sva
argument_list|)
condition|)
block|{
comment|/* 				 * The large page mapping was destroyed. 				 */
continue|continue;
block|}
comment|/* 			 * Unless the page mappings are wired, remove the 			 * mapping to a single page so that a subsequent 			 * access may repromote.  Since the underlying page 			 * table page is fully populated, this removal never 			 * frees a page table page. 			 */
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
block|{
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|*
name|pte
operator|&
name|PG_V
operator|)
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_advise: invalid PTE"
operator|)
argument_list|)
expr_stmt|;
name|pmap_remove_pte
argument_list|(
name|pmap
argument_list|,
name|pte
argument_list|,
name|sva
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|anychanged
operator|=
name|TRUE
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pdnxt
operator|>
name|eva
condition|)
name|pdnxt
operator|=
name|eva
expr_stmt|;
name|va
operator|=
name|pdnxt
expr_stmt|;
for|for
control|(
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|sva
argument_list|)
init|;
name|sva
operator|!=
name|pdnxt
condition|;
name|pte
operator|++
operator|,
name|sva
operator|+=
name|PAGE_SIZE
control|)
block|{
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_MANAGED
operator||
name|PG_V
operator|)
operator|)
operator|!=
operator|(
name|PG_MANAGED
operator||
name|PG_V
operator|)
condition|)
goto|goto
name|maybe_invlrng
goto|;
elseif|else
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
if|if
condition|(
name|advice
operator|==
name|MADV_DONTNEED
condition|)
block|{
comment|/* 					 * Future calls to pmap_is_modified() 					 * can be avoided by making the page 					 * dirty now. 					 */
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
operator|*
name|pte
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
name|atomic_clear_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|PG_M
operator||
name|PG_A
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
name|atomic_clear_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|PG_A
argument_list|)
expr_stmt|;
else|else
goto|goto
name|maybe_invlrng
goto|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_G
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|va
operator|==
name|pdnxt
condition|)
name|va
operator|=
name|sva
expr_stmt|;
block|}
else|else
name|anychanged
operator|=
name|TRUE
expr_stmt|;
continue|continue;
name|maybe_invlrng
label|:
if|if
condition|(
name|va
operator|!=
name|pdnxt
condition|)
block|{
name|pmap_invalidate_range
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|sva
argument_list|)
expr_stmt|;
name|va
operator|=
name|pdnxt
expr_stmt|;
block|}
block|}
if|if
condition|(
name|va
operator|!=
name|pdnxt
condition|)
name|pmap_invalidate_range
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|,
name|sva
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|anychanged
condition|)
name|pmap_invalidate_all
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv_lists_locked
condition|)
block|{
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  *	Clear the modify bits on the specified physical page.  */
end_comment

begin_function
name|void
name|pmap_clear_modify
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|struct
name|md_page
modifier|*
name|pvh
decl_stmt|;
name|pv_entry_t
name|next_pv
decl_stmt|,
name|pv
decl_stmt|;
name|pmap_t
name|pmap
decl_stmt|;
name|pd_entry_t
name|oldpde
decl_stmt|,
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
name|oldpte
decl_stmt|,
modifier|*
name|pte
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|KASSERT
argument_list|(
operator|(
name|m
operator|->
name|oflags
operator|&
name|VPO_UNMANAGED
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_clear_modify: page %p is not managed"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|VM_OBJECT_ASSERT_WLOCKED
argument_list|(
name|m
operator|->
name|object
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|!
name|vm_page_xbusied
argument_list|(
name|m
argument_list|)
argument_list|,
operator|(
literal|"pmap_clear_modify: page %p is exclusive busied"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
comment|/* 	 * If the page is not PGA_WRITEABLE, then no PTEs can have PG_M set. 	 * If the object containing the page is locked and the page is not 	 * exclusive busied, then PGA_WRITEABLE cannot be concurrently set. 	 */
if|if
condition|(
operator|(
name|m
operator|->
name|aflags
operator|&
name|PGA_WRITEABLE
operator|)
operator|==
literal|0
condition|)
return|return;
name|rw_wlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
name|sched_pin
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
goto|goto
name|small_mappings
goto|;
name|pvh
operator|=
name|pa_to_pvh
argument_list|(
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
name|TAILQ_FOREACH_SAFE
argument_list|(
argument|pv
argument_list|,
argument|&pvh->pv_list
argument_list|,
argument|pv_next
argument_list|,
argument|next_pv
argument_list|)
block|{
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|oldpde
operator|=
operator|*
name|pde
expr_stmt|;
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_RW
operator|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|pmap_demote_pde
argument_list|(
name|pmap
argument_list|,
name|pde
argument_list|,
name|va
argument_list|)
condition|)
block|{
if|if
condition|(
operator|(
name|oldpde
operator|&
name|PG_W
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* 					 * Write protect the mapping to a 					 * single page so that a subsequent 					 * write access may repromote. 					 */
name|va
operator|+=
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator|-
operator|(
name|oldpde
operator|&
name|PG_PS_FRAME
operator|)
expr_stmt|;
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|oldpte
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|oldpte
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* 						 * Regardless of whether a pte is 32 or 64 bits 						 * in size, PG_RW and PG_M are among the least 						 * significant 32 bits. 						 */
while|while
condition|(
operator|!
name|atomic_cmpset_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|oldpte
argument_list|,
name|oldpte
operator|&
operator|~
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
argument_list|)
condition|)
name|oldpte
operator|=
operator|*
name|pte
expr_stmt|;
name|vm_page_dirty
argument_list|(
name|m
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|small_mappings
label|:
name|TAILQ_FOREACH
argument_list|(
argument|pv
argument_list|,
argument|&m->md.pv_list
argument_list|,
argument|pv_next
argument_list|)
block|{
name|pmap
operator|=
name|PV_PMAP
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|pde
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|(
operator|*
name|pde
operator|&
name|PG_PS
operator|)
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_clear_modify: found"
literal|" a 4mpage in page %p's pv list"
operator|,
name|m
operator|)
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pmap_pte_quick
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
block|{
comment|/* 			 * Regardless of whether a pte is 32 or 64 bits 			 * in size, PG_M is among the least significant 			 * 32 bits.  			 */
name|atomic_clear_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|PG_M
argument_list|)
expr_stmt|;
name|pmap_invalidate_page
argument_list|(
name|pmap
argument_list|,
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
block|}
name|sched_unpin
argument_list|()
expr_stmt|;
name|rw_wunlock
argument_list|(
operator|&
name|pvh_global_lock
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Miscellaneous support routines follow  */
end_comment

begin_comment
comment|/* Adjust the cache mode for a 4KB page mapped via a PTE. */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_pte_attr
parameter_list|(
name|pt_entry_t
modifier|*
name|pte
parameter_list|,
name|int
name|cache_bits
parameter_list|)
block|{
name|u_int
name|opte
decl_stmt|,
name|npte
decl_stmt|;
comment|/* 	 * The cache mode bits are all in the low 32-bits of the 	 * PTE, so we can just spin on updating the low 32-bits. 	 */
do|do
block|{
name|opte
operator|=
operator|*
operator|(
name|u_int
operator|*
operator|)
name|pte
expr_stmt|;
name|npte
operator|=
name|opte
operator|&
operator|~
name|PG_PTE_CACHE
expr_stmt|;
name|npte
operator||=
name|cache_bits
expr_stmt|;
block|}
do|while
condition|(
name|npte
operator|!=
name|opte
operator|&&
operator|!
name|atomic_cmpset_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pte
argument_list|,
name|opte
argument_list|,
name|npte
argument_list|)
condition|)
do|;
block|}
end_function

begin_comment
comment|/* Adjust the cache mode for a 2/4MB page mapped via a PDE. */
end_comment

begin_function
specifier|static
name|__inline
name|void
name|pmap_pde_attr
parameter_list|(
name|pd_entry_t
modifier|*
name|pde
parameter_list|,
name|int
name|cache_bits
parameter_list|)
block|{
name|u_int
name|opde
decl_stmt|,
name|npde
decl_stmt|;
comment|/* 	 * The cache mode bits are all in the low 32-bits of the 	 * PDE, so we can just spin on updating the low 32-bits. 	 */
do|do
block|{
name|opde
operator|=
operator|*
operator|(
name|u_int
operator|*
operator|)
name|pde
expr_stmt|;
name|npde
operator|=
name|opde
operator|&
operator|~
name|PG_PDE_CACHE
expr_stmt|;
name|npde
operator||=
name|cache_bits
expr_stmt|;
block|}
do|while
condition|(
name|npde
operator|!=
name|opde
operator|&&
operator|!
name|atomic_cmpset_int
argument_list|(
operator|(
name|u_int
operator|*
operator|)
name|pde
argument_list|,
name|opde
argument_list|,
name|npde
argument_list|)
condition|)
do|;
block|}
end_function

begin_comment
comment|/*  * Map a set of physical memory pages into the kernel virtual  * address space. Return a pointer to where it is mapped. This  * routine is intended to be used for mapping device memory,  * NOT real memory.  */
end_comment

begin_function
name|void
modifier|*
name|pmap_mapdev_attr
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|int
name|mode
parameter_list|)
block|{
name|struct
name|pmap_preinit_mapping
modifier|*
name|ppim
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|offset
decl_stmt|;
name|vm_size_t
name|tmpsize
decl_stmt|;
name|int
name|i
decl_stmt|;
name|offset
operator|=
name|pa
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|offset
operator|+
name|size
argument_list|)
expr_stmt|;
name|pa
operator|=
name|pa
operator|&
name|PG_FRAME
expr_stmt|;
if|if
condition|(
name|pa
operator|<
name|KERNLOAD
operator|&&
name|pa
operator|+
name|size
operator|<=
name|KERNLOAD
condition|)
name|va
operator|=
name|KERNBASE
operator|+
name|pa
expr_stmt|;
elseif|else
if|if
condition|(
operator|!
name|pmap_initialized
condition|)
block|{
name|va
operator|=
literal|0
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PMAP_PREINIT_MAPPING_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|ppim
operator|=
name|pmap_preinit_mapping
operator|+
name|i
expr_stmt|;
if|if
condition|(
name|ppim
operator|->
name|va
operator|==
literal|0
condition|)
block|{
name|ppim
operator|->
name|pa
operator|=
name|pa
expr_stmt|;
name|ppim
operator|->
name|sz
operator|=
name|size
expr_stmt|;
name|ppim
operator|->
name|mode
operator|=
name|mode
expr_stmt|;
name|ppim
operator|->
name|va
operator|=
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|+=
name|size
expr_stmt|;
name|va
operator|=
name|ppim
operator|->
name|va
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|va
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: too many preinit mappings"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * If we have a preinit mapping, re-use it. 		 */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PMAP_PREINIT_MAPPING_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|ppim
operator|=
name|pmap_preinit_mapping
operator|+
name|i
expr_stmt|;
if|if
condition|(
name|ppim
operator|->
name|pa
operator|==
name|pa
operator|&&
name|ppim
operator|->
name|sz
operator|==
name|size
operator|&&
name|ppim
operator|->
name|mode
operator|==
name|mode
condition|)
return|return
operator|(
operator|(
name|void
operator|*
operator|)
operator|(
name|ppim
operator|->
name|va
operator|+
name|offset
operator|)
operator|)
return|;
block|}
name|va
operator|=
name|kva_alloc
argument_list|(
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|va
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"%s: Couldn't allocate KVA"
argument_list|,
name|__func__
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|tmpsize
operator|=
literal|0
init|;
name|tmpsize
operator|<
name|size
condition|;
name|tmpsize
operator|+=
name|PAGE_SIZE
control|)
name|pmap_kenter_attr
argument_list|(
name|va
operator|+
name|tmpsize
argument_list|,
name|pa
operator|+
name|tmpsize
argument_list|,
name|mode
argument_list|)
expr_stmt|;
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|,
name|va
operator|+
name|tmpsize
argument_list|)
expr_stmt|;
name|pmap_invalidate_cache_range
argument_list|(
name|va
argument_list|,
name|va
operator|+
name|size
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
return|return
operator|(
operator|(
name|void
operator|*
operator|)
operator|(
name|va
operator|+
name|offset
operator|)
operator|)
return|;
block|}
end_function

begin_function
name|void
modifier|*
name|pmap_mapdev
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
return|return
operator|(
name|pmap_mapdev_attr
argument_list|(
name|pa
argument_list|,
name|size
argument_list|,
name|PAT_UNCACHEABLE
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
modifier|*
name|pmap_mapbios
parameter_list|(
name|vm_paddr_t
name|pa
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
return|return
operator|(
name|pmap_mapdev_attr
argument_list|(
name|pa
argument_list|,
name|size
argument_list|,
name|PAT_WRITE_BACK
argument_list|)
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_unmapdev
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|struct
name|pmap_preinit_mapping
modifier|*
name|ppim
decl_stmt|;
name|vm_offset_t
name|offset
decl_stmt|;
name|int
name|i
decl_stmt|;
if|if
condition|(
name|va
operator|>=
name|KERNBASE
operator|&&
name|va
operator|+
name|size
operator|<=
name|KERNBASE
operator|+
name|KERNLOAD
condition|)
return|return;
name|offset
operator|=
name|va
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|offset
operator|+
name|size
argument_list|)
expr_stmt|;
name|va
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|PMAP_PREINIT_MAPPING_COUNT
condition|;
name|i
operator|++
control|)
block|{
name|ppim
operator|=
name|pmap_preinit_mapping
operator|+
name|i
expr_stmt|;
if|if
condition|(
name|ppim
operator|->
name|va
operator|==
name|va
operator|&&
name|ppim
operator|->
name|sz
operator|==
name|size
condition|)
block|{
if|if
condition|(
name|pmap_initialized
condition|)
return|return;
name|ppim
operator|->
name|pa
operator|=
literal|0
expr_stmt|;
name|ppim
operator|->
name|va
operator|=
literal|0
expr_stmt|;
name|ppim
operator|->
name|sz
operator|=
literal|0
expr_stmt|;
name|ppim
operator|->
name|mode
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|va
operator|+
name|size
operator|==
name|virtual_avail
condition|)
name|virtual_avail
operator|=
name|va
expr_stmt|;
return|return;
block|}
block|}
if|if
condition|(
name|pmap_initialized
condition|)
name|kva_free
argument_list|(
name|va
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Sets the memory attribute for the specified page.  */
end_comment

begin_function
name|void
name|pmap_page_set_memattr
parameter_list|(
name|vm_page_t
name|m
parameter_list|,
name|vm_memattr_t
name|ma
parameter_list|)
block|{
name|m
operator|->
name|md
operator|.
name|pat_mode
operator|=
name|ma
expr_stmt|;
if|if
condition|(
operator|(
name|m
operator|->
name|flags
operator|&
name|PG_FICTITIOUS
operator|)
operator|!=
literal|0
condition|)
return|return;
comment|/* 	 * If "m" is a normal page, flush it from the cache. 	 * See pmap_invalidate_cache_range(). 	 * 	 * First, try to find an existing mapping of the page by sf 	 * buffer. sf_buf_invalidate_cache() modifies mapping and 	 * flushes the cache. 	 */
if|if
condition|(
name|sf_buf_invalidate_cache
argument_list|(
name|m
argument_list|)
condition|)
return|return;
comment|/* 	 * If page is not mapped by sf buffer, but CPU does not 	 * support self snoop, map the page transient and do 	 * invalidation. In the worst case, whole cache is flushed by 	 * pmap_invalidate_cache_range(). 	 */
if|if
condition|(
operator|(
name|cpu_feature
operator|&
name|CPUID_SS
operator|)
operator|==
literal|0
condition|)
name|pmap_flush_page
argument_list|(
name|m
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|static
name|void
name|pmap_flush_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|pt_entry_t
modifier|*
name|cmap_pte2
decl_stmt|;
name|struct
name|pcpu
modifier|*
name|pc
decl_stmt|;
name|vm_offset_t
name|sva
decl_stmt|,
name|eva
decl_stmt|;
name|bool
name|useclflushopt
decl_stmt|;
name|useclflushopt
operator|=
operator|(
name|cpu_stdext_feature
operator|&
name|CPUID_STDEXT_CLFLUSHOPT
operator|)
operator|!=
literal|0
expr_stmt|;
if|if
condition|(
name|useclflushopt
operator|||
operator|(
name|cpu_feature
operator|&
name|CPUID_CLFSH
operator|)
operator|!=
literal|0
condition|)
block|{
name|sched_pin
argument_list|()
expr_stmt|;
name|pc
operator|=
name|get_pcpu
argument_list|()
expr_stmt|;
name|cmap_pte2
operator|=
name|pc
operator|->
name|pc_cmap_pte2
expr_stmt|;
name|mtx_lock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|cmap_pte2
condition|)
name|panic
argument_list|(
literal|"pmap_flush_page: CMAP2 busy"
argument_list|)
expr_stmt|;
operator|*
name|cmap_pte2
operator|=
name|PG_V
operator||
name|PG_RW
operator||
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|PG_A
operator||
name|PG_M
operator||
name|pmap_cache_bits
argument_list|(
name|m
operator|->
name|md
operator|.
name|pat_mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|invlcaddr
argument_list|(
name|pc
operator|->
name|pc_cmap_addr2
argument_list|)
expr_stmt|;
name|sva
operator|=
operator|(
name|vm_offset_t
operator|)
name|pc
operator|->
name|pc_cmap_addr2
expr_stmt|;
name|eva
operator|=
name|sva
operator|+
name|PAGE_SIZE
expr_stmt|;
comment|/* 		 * Use mfence or sfence despite the ordering implied by 		 * mtx_{un,}lock() because clflush on non-Intel CPUs 		 * and clflushopt are not guaranteed to be ordered by 		 * any other instruction. 		 */
if|if
condition|(
name|useclflushopt
condition|)
name|sfence
argument_list|()
expr_stmt|;
elseif|else
if|if
condition|(
name|cpu_vendor_id
operator|!=
name|CPU_VENDOR_INTEL
condition|)
name|mfence
argument_list|()
expr_stmt|;
for|for
control|(
init|;
name|sva
operator|<
name|eva
condition|;
name|sva
operator|+=
name|cpu_clflush_line_size
control|)
block|{
if|if
condition|(
name|useclflushopt
condition|)
name|clflushopt
argument_list|(
name|sva
argument_list|)
expr_stmt|;
else|else
name|clflush
argument_list|(
name|sva
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|useclflushopt
condition|)
name|sfence
argument_list|()
expr_stmt|;
elseif|else
if|if
condition|(
name|cpu_vendor_id
operator|!=
name|CPU_VENDOR_INTEL
condition|)
name|mfence
argument_list|()
expr_stmt|;
operator|*
name|cmap_pte2
operator|=
literal|0
expr_stmt|;
name|sched_unpin
argument_list|()
expr_stmt|;
name|mtx_unlock
argument_list|(
operator|&
name|pc
operator|->
name|pc_cmap_lock
argument_list|)
expr_stmt|;
block|}
else|else
name|pmap_invalidate_cache
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Changes the specified virtual address range's memory type to that given by  * the parameter "mode".  The specified virtual address range must be  * completely contained within either the kernel map.  *  * Returns zero if the change completed successfully, and either EINVAL or  * ENOMEM if the change failed.  Specifically, EINVAL is returned if some part  * of the virtual address range was not mapped, and ENOMEM is returned if  * there was insufficient memory available to complete the change.  */
end_comment

begin_function
name|int
name|pmap_change_attr
parameter_list|(
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|size
parameter_list|,
name|int
name|mode
parameter_list|)
block|{
name|vm_offset_t
name|base
decl_stmt|,
name|offset
decl_stmt|,
name|tmpva
decl_stmt|;
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|int
name|cache_bits_pte
decl_stmt|,
name|cache_bits_pde
decl_stmt|;
name|boolean_t
name|changed
decl_stmt|;
name|base
operator|=
name|trunc_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|offset
operator|=
name|va
operator|&
name|PAGE_MASK
expr_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|offset
operator|+
name|size
argument_list|)
expr_stmt|;
comment|/* 	 * Only supported on kernel virtual addresses above the recursive map. 	 */
if|if
condition|(
name|base
operator|<
name|VM_MIN_KERNEL_ADDRESS
condition|)
return|return
operator|(
name|EINVAL
operator|)
return|;
name|cache_bits_pde
operator|=
name|pmap_cache_bits
argument_list|(
name|mode
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|cache_bits_pte
operator|=
name|pmap_cache_bits
argument_list|(
name|mode
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|changed
operator|=
name|FALSE
expr_stmt|;
comment|/* 	 * Pages that aren't mapped aren't supported.  Also break down 	 * 2/4MB pages into 4KB pages if required. 	 */
name|PMAP_LOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
for|for
control|(
name|tmpva
operator|=
name|base
init|;
name|tmpva
operator|<
name|base
operator|+
name|size
condition|;
control|)
block|{
name|pde
operator|=
name|pmap_pde
argument_list|(
name|kernel_pmap
argument_list|,
name|tmpva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pde
operator|==
literal|0
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|EINVAL
operator|)
return|;
block|}
if|if
condition|(
operator|*
name|pde
operator|&
name|PG_PS
condition|)
block|{
comment|/* 			 * If the current 2/4MB page already has 			 * the required memory type, then we need not 			 * demote this page.  Just increment tmpva to 			 * the next 2/4MB page frame. 			 */
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PDE_CACHE
operator|)
operator|==
name|cache_bits_pde
condition|)
block|{
name|tmpva
operator|=
name|trunc_4mpage
argument_list|(
name|tmpva
argument_list|)
operator|+
name|NBPDR
expr_stmt|;
continue|continue;
block|}
comment|/* 			 * If the current offset aligns with a 2/4MB 			 * page frame and there is at least 2/4MB left 			 * within the range, then we need not break 			 * down this page into 4KB pages. 			 */
if|if
condition|(
operator|(
name|tmpva
operator|&
name|PDRMASK
operator|)
operator|==
literal|0
operator|&&
name|tmpva
operator|+
name|PDRMASK
operator|<
name|base
operator|+
name|size
condition|)
block|{
name|tmpva
operator|+=
name|NBPDR
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|!
name|pmap_demote_pde
argument_list|(
name|kernel_pmap
argument_list|,
name|pde
argument_list|,
name|tmpva
argument_list|)
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|ENOMEM
operator|)
return|;
block|}
block|}
name|pte
operator|=
name|vtopte
argument_list|(
name|tmpva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pte
operator|==
literal|0
condition|)
block|{
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|EINVAL
operator|)
return|;
block|}
name|tmpva
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
name|PMAP_UNLOCK
argument_list|(
name|kernel_pmap
argument_list|)
expr_stmt|;
comment|/* 	 * Ok, all the pages exist, so run through them updating their 	 * cache mode if required. 	 */
for|for
control|(
name|tmpva
operator|=
name|base
init|;
name|tmpva
operator|<
name|base
operator|+
name|size
condition|;
control|)
block|{
name|pde
operator|=
name|pmap_pde
argument_list|(
name|kernel_pmap
argument_list|,
name|tmpva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pde
operator|&
name|PG_PS
condition|)
block|{
if|if
condition|(
operator|(
operator|*
name|pde
operator|&
name|PG_PDE_CACHE
operator|)
operator|!=
name|cache_bits_pde
condition|)
block|{
name|pmap_pde_attr
argument_list|(
name|pde
argument_list|,
name|cache_bits_pde
argument_list|)
expr_stmt|;
name|changed
operator|=
name|TRUE
expr_stmt|;
block|}
name|tmpva
operator|=
name|trunc_4mpage
argument_list|(
name|tmpva
argument_list|)
operator|+
name|NBPDR
expr_stmt|;
block|}
else|else
block|{
name|pte
operator|=
name|vtopte
argument_list|(
name|tmpva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_PTE_CACHE
operator|)
operator|!=
name|cache_bits_pte
condition|)
block|{
name|pmap_pte_attr
argument_list|(
name|pte
argument_list|,
name|cache_bits_pte
argument_list|)
expr_stmt|;
name|changed
operator|=
name|TRUE
expr_stmt|;
block|}
name|tmpva
operator|+=
name|PAGE_SIZE
expr_stmt|;
block|}
block|}
comment|/* 	 * Flush CPU caches to make sure any data isn't cached that 	 * shouldn't be, etc. 	 */
if|if
condition|(
name|changed
condition|)
block|{
name|pmap_invalidate_range
argument_list|(
name|kernel_pmap
argument_list|,
name|base
argument_list|,
name|tmpva
argument_list|)
expr_stmt|;
name|pmap_invalidate_cache_range
argument_list|(
name|base
argument_list|,
name|tmpva
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * perform the pmap work for mincore  */
end_comment

begin_function
name|int
name|pmap_mincore
parameter_list|(
name|pmap_t
name|pmap
parameter_list|,
name|vm_offset_t
name|addr
parameter_list|,
name|vm_paddr_t
modifier|*
name|locked_pa
parameter_list|)
block|{
name|pd_entry_t
modifier|*
name|pdep
decl_stmt|;
name|pt_entry_t
modifier|*
name|ptep
decl_stmt|,
name|pte
decl_stmt|;
name|vm_paddr_t
name|pa
decl_stmt|;
name|int
name|val
decl_stmt|;
name|PMAP_LOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
name|retry
label|:
name|pdep
operator|=
name|pmap_pde
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
if|if
condition|(
operator|*
name|pdep
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
operator|*
name|pdep
operator|&
name|PG_PS
condition|)
block|{
name|pte
operator|=
operator|*
name|pdep
expr_stmt|;
comment|/* Compute the physical address of the 4KB page. */
name|pa
operator|=
operator|(
operator|(
operator|*
name|pdep
operator|&
name|PG_PS_FRAME
operator|)
operator||
operator|(
name|addr
operator|&
name|PDRMASK
operator|)
operator|)
operator|&
name|PG_FRAME
expr_stmt|;
name|val
operator|=
name|MINCORE_SUPER
expr_stmt|;
block|}
else|else
block|{
name|ptep
operator|=
name|pmap_pte
argument_list|(
name|pmap
argument_list|,
name|addr
argument_list|)
expr_stmt|;
name|pte
operator|=
operator|*
name|ptep
expr_stmt|;
name|pmap_pte_release
argument_list|(
name|ptep
argument_list|)
expr_stmt|;
name|pa
operator|=
name|pte
operator|&
name|PG_FRAME
expr_stmt|;
name|val
operator|=
literal|0
expr_stmt|;
block|}
block|}
else|else
block|{
name|pte
operator|=
literal|0
expr_stmt|;
name|pa
operator|=
literal|0
expr_stmt|;
name|val
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|pte
operator|&
name|PG_V
operator|)
operator|!=
literal|0
condition|)
block|{
name|val
operator||=
name|MINCORE_INCORE
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|&
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
operator|)
operator|==
operator|(
name|PG_M
operator||
name|PG_RW
operator|)
condition|)
name|val
operator||=
name|MINCORE_MODIFIED
operator||
name|MINCORE_MODIFIED_OTHER
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|&
name|PG_A
operator|)
operator|!=
literal|0
condition|)
name|val
operator||=
name|MINCORE_REFERENCED
operator||
name|MINCORE_REFERENCED_OTHER
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|val
operator|&
operator|(
name|MINCORE_MODIFIED_OTHER
operator||
name|MINCORE_REFERENCED_OTHER
operator|)
operator|)
operator|!=
operator|(
name|MINCORE_MODIFIED_OTHER
operator||
name|MINCORE_REFERENCED_OTHER
operator|)
operator|&&
operator|(
name|pte
operator|&
operator|(
name|PG_MANAGED
operator||
name|PG_V
operator|)
operator|)
operator|==
operator|(
name|PG_MANAGED
operator||
name|PG_V
operator|)
condition|)
block|{
comment|/* Ensure that "PHYS_TO_VM_PAGE(pa)->object" doesn't change. */
if|if
condition|(
name|vm_page_pa_tryrelock
argument_list|(
name|pmap
argument_list|,
name|pa
argument_list|,
name|locked_pa
argument_list|)
condition|)
goto|goto
name|retry
goto|;
block|}
else|else
name|PA_UNLOCK_COND
argument_list|(
operator|*
name|locked_pa
argument_list|)
expr_stmt|;
name|PMAP_UNLOCK
argument_list|(
name|pmap
argument_list|)
expr_stmt|;
return|return
operator|(
name|val
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_activate
parameter_list|(
name|struct
name|thread
modifier|*
name|td
parameter_list|)
block|{
name|pmap_t
name|pmap
decl_stmt|,
name|oldpmap
decl_stmt|;
name|u_int
name|cpuid
decl_stmt|;
name|u_int32_t
name|cr3
decl_stmt|;
name|critical_enter
argument_list|()
expr_stmt|;
name|pmap
operator|=
name|vmspace_pmap
argument_list|(
name|td
operator|->
name|td_proc
operator|->
name|p_vmspace
argument_list|)
expr_stmt|;
name|oldpmap
operator|=
name|PCPU_GET
argument_list|(
name|curpmap
argument_list|)
expr_stmt|;
name|cpuid
operator|=
name|PCPU_GET
argument_list|(
name|cpuid
argument_list|)
expr_stmt|;
if|#
directive|if
name|defined
argument_list|(
name|SMP
argument_list|)
name|CPU_CLR_ATOMIC
argument_list|(
name|cpuid
argument_list|,
operator|&
name|oldpmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|CPU_SET_ATOMIC
argument_list|(
name|cpuid
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
else|#
directive|else
name|CPU_CLR
argument_list|(
name|cpuid
argument_list|,
operator|&
name|oldpmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
name|CPU_SET
argument_list|(
name|cpuid
argument_list|,
operator|&
name|pmap
operator|->
name|pm_active
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|#
directive|if
name|defined
argument_list|(
name|PAE
argument_list|)
operator|||
name|defined
argument_list|(
name|PAE_TABLES
argument_list|)
name|cr3
operator|=
name|vtophys
argument_list|(
name|pmap
operator|->
name|pm_pdpt
argument_list|)
expr_stmt|;
else|#
directive|else
name|cr3
operator|=
name|vtophys
argument_list|(
name|pmap
operator|->
name|pm_pdir
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * pmap_activate is for the current thread on the current cpu 	 */
name|td
operator|->
name|td_pcb
operator|->
name|pcb_cr3
operator|=
name|cr3
expr_stmt|;
name|load_cr3
argument_list|(
name|cr3
argument_list|)
expr_stmt|;
name|PCPU_SET
argument_list|(
name|curpmap
argument_list|,
name|pmap
argument_list|)
expr_stmt|;
name|critical_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
name|void
name|pmap_sync_icache
parameter_list|(
name|pmap_t
name|pm
parameter_list|,
name|vm_offset_t
name|va
parameter_list|,
name|vm_size_t
name|sz
parameter_list|)
block|{ }
end_function

begin_comment
comment|/*  *	Increase the starting virtual address of the given mapping if a  *	different alignment might result in more superpage mappings.  */
end_comment

begin_function
name|void
name|pmap_align_superpage
parameter_list|(
name|vm_object_t
name|object
parameter_list|,
name|vm_ooffset_t
name|offset
parameter_list|,
name|vm_offset_t
modifier|*
name|addr
parameter_list|,
name|vm_size_t
name|size
parameter_list|)
block|{
name|vm_offset_t
name|superpage_offset
decl_stmt|;
if|if
condition|(
name|size
operator|<
name|NBPDR
condition|)
return|return;
if|if
condition|(
name|object
operator|!=
name|NULL
operator|&&
operator|(
name|object
operator|->
name|flags
operator|&
name|OBJ_COLORED
operator|)
operator|!=
literal|0
condition|)
name|offset
operator|+=
name|ptoa
argument_list|(
name|object
operator|->
name|pg_color
argument_list|)
expr_stmt|;
name|superpage_offset
operator|=
name|offset
operator|&
name|PDRMASK
expr_stmt|;
if|if
condition|(
name|size
operator|-
operator|(
operator|(
name|NBPDR
operator|-
name|superpage_offset
operator|)
operator|&
name|PDRMASK
operator|)
operator|<
name|NBPDR
operator|||
operator|(
operator|*
name|addr
operator|&
name|PDRMASK
operator|)
operator|==
name|superpage_offset
condition|)
return|return;
if|if
condition|(
operator|(
operator|*
name|addr
operator|&
name|PDRMASK
operator|)
operator|<
name|superpage_offset
condition|)
operator|*
name|addr
operator|=
operator|(
operator|*
name|addr
operator|&
operator|~
name|PDRMASK
operator|)
operator|+
name|superpage_offset
expr_stmt|;
else|else
operator|*
name|addr
operator|=
operator|(
operator|(
operator|*
name|addr
operator|+
name|PDRMASK
operator|)
operator|&
operator|~
name|PDRMASK
operator|)
operator|+
name|superpage_offset
expr_stmt|;
block|}
end_function

begin_function
name|vm_offset_t
name|pmap_quick_enter_page
parameter_list|(
name|vm_page_t
name|m
parameter_list|)
block|{
name|vm_offset_t
name|qaddr
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|critical_enter
argument_list|()
expr_stmt|;
name|qaddr
operator|=
name|PCPU_GET
argument_list|(
name|qmap_addr
argument_list|)
expr_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|qaddr
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|*
name|pte
operator|==
literal|0
argument_list|,
operator|(
literal|"pmap_quick_enter_page: PTE busy"
operator|)
argument_list|)
expr_stmt|;
operator|*
name|pte
operator|=
name|PG_V
operator||
name|PG_RW
operator||
name|VM_PAGE_TO_PHYS
argument_list|(
name|m
argument_list|)
operator||
name|PG_A
operator||
name|PG_M
operator||
name|pmap_cache_bits
argument_list|(
name|pmap_page_get_memattr
argument_list|(
name|m
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|invlpg
argument_list|(
name|qaddr
argument_list|)
expr_stmt|;
return|return
operator|(
name|qaddr
operator|)
return|;
block|}
end_function

begin_function
name|void
name|pmap_quick_remove_page
parameter_list|(
name|vm_offset_t
name|addr
parameter_list|)
block|{
name|vm_offset_t
name|qaddr
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|qaddr
operator|=
name|PCPU_GET
argument_list|(
name|qmap_addr
argument_list|)
expr_stmt|;
name|pte
operator|=
name|vtopte
argument_list|(
name|qaddr
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
operator|*
name|pte
operator|!=
literal|0
argument_list|,
operator|(
literal|"pmap_quick_remove_page: PTE not in use"
operator|)
argument_list|)
expr_stmt|;
name|KASSERT
argument_list|(
name|addr
operator|==
name|qaddr
argument_list|,
operator|(
literal|"pmap_quick_remove_page: invalid address"
operator|)
argument_list|)
expr_stmt|;
operator|*
name|pte
operator|=
literal|0
expr_stmt|;
name|critical_exit
argument_list|()
expr_stmt|;
block|}
end_function

begin_if
if|#
directive|if
name|defined
argument_list|(
name|PMAP_DEBUG
argument_list|)
end_if

begin_macro
name|pmap_pid_dump
argument_list|(
argument|int pid
argument_list|)
end_macro

begin_block
block|{
name|pmap_t
name|pmap
decl_stmt|;
name|struct
name|proc
modifier|*
name|p
decl_stmt|;
name|int
name|npte
init|=
literal|0
decl_stmt|;
name|int
name|index
decl_stmt|;
name|sx_slock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
name|FOREACH_PROC_IN_SYSTEM
argument_list|(
argument|p
argument_list|)
block|{
if|if
condition|(
name|p
operator|->
name|p_pid
operator|!=
name|pid
condition|)
continue|continue;
if|if
condition|(
name|p
operator|->
name|p_vmspace
condition|)
block|{
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
name|index
operator|=
literal|0
expr_stmt|;
name|pmap
operator|=
name|vmspace_pmap
argument_list|(
name|p
operator|->
name|p_vmspace
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|NPDEPTD
condition|;
name|i
operator|++
control|)
block|{
name|pd_entry_t
modifier|*
name|pde
decl_stmt|;
name|pt_entry_t
modifier|*
name|pte
decl_stmt|;
name|vm_offset_t
name|base
init|=
name|i
operator|<<
name|PDRSHIFT
decl_stmt|;
name|pde
operator|=
operator|&
name|pmap
operator|->
name|pm_pdir
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|pde
operator|&&
name|pmap_pde_v
argument_list|(
name|pde
argument_list|)
condition|)
block|{
for|for
control|(
name|j
operator|=
literal|0
init|;
name|j
operator|<
name|NPTEPG
condition|;
name|j
operator|++
control|)
block|{
name|vm_offset_t
name|va
init|=
name|base
operator|+
operator|(
name|j
operator|<<
name|PAGE_SHIFT
operator|)
decl_stmt|;
if|if
condition|(
name|va
operator|>=
operator|(
name|vm_offset_t
operator|)
name|VM_MIN_KERNEL_ADDRESS
condition|)
block|{
if|if
condition|(
name|index
condition|)
block|{
name|index
operator|=
literal|0
expr_stmt|;
name|printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|npte
operator|)
return|;
block|}
name|pte
operator|=
name|pmap_pte
argument_list|(
name|pmap
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte
operator|&&
name|pmap_pte_v
argument_list|(
name|pte
argument_list|)
condition|)
block|{
name|pt_entry_t
name|pa
decl_stmt|;
name|vm_page_t
name|m
decl_stmt|;
name|pa
operator|=
operator|*
name|pte
expr_stmt|;
name|m
operator|=
name|PHYS_TO_VM_PAGE
argument_list|(
name|pa
operator|&
name|PG_FRAME
argument_list|)
expr_stmt|;
name|printf
argument_list|(
literal|"va: 0x%x, pt: 0x%x, h: %d, w: %d, f: 0x%x"
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|m
operator|->
name|hold_count
argument_list|,
name|m
operator|->
name|wire_count
argument_list|,
name|m
operator|->
name|flags
argument_list|)
expr_stmt|;
name|npte
operator|++
expr_stmt|;
name|index
operator|++
expr_stmt|;
if|if
condition|(
name|index
operator|>=
literal|2
condition|)
block|{
name|index
operator|=
literal|0
expr_stmt|;
name|printf
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|printf
argument_list|(
literal|" "
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
block|}
block|}
name|sx_sunlock
argument_list|(
operator|&
name|allproc_lock
argument_list|)
expr_stmt|;
return|return
operator|(
name|npte
operator|)
return|;
block|}
end_block

begin_endif
endif|#
directive|endif
end_endif

end_unit

