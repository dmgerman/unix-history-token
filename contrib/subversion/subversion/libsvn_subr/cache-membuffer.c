begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * cache-membuffer.c: in-memory caching for Subversion  *  * ====================================================================  *    Licensed to the Apache Software Foundation (ASF) under one  *    or more contributor license agreements.  See the NOTICE file  *    distributed with this work for additional information  *    regarding copyright ownership.  The ASF licenses this file  *    to you under the Apache License, Version 2.0 (the  *    "License"); you may not use this file except in compliance  *    with the License.  You may obtain a copy of the License at  *  *      http://www.apache.org/licenses/LICENSE-2.0  *  *    Unless required by applicable law or agreed to in writing,  *    software distributed under the License is distributed on an  *    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  *    KIND, either express or implied.  See the License for the  *    specific language governing permissions and limitations  *    under the License.  * ====================================================================  */
end_comment

begin_include
include|#
directive|include
file|<assert.h>
end_include

begin_include
include|#
directive|include
file|<apr_md5.h>
end_include

begin_include
include|#
directive|include
file|<apr_thread_rwlock.h>
end_include

begin_include
include|#
directive|include
file|"svn_pools.h"
end_include

begin_include
include|#
directive|include
file|"svn_checksum.h"
end_include

begin_include
include|#
directive|include
file|"svn_private_config.h"
end_include

begin_include
include|#
directive|include
file|"svn_string.h"
end_include

begin_include
include|#
directive|include
file|"svn_sorts.h"
end_include

begin_comment
comment|/* get the MIN macro */
end_comment

begin_include
include|#
directive|include
file|"private/svn_atomic.h"
end_include

begin_include
include|#
directive|include
file|"private/svn_dep_compat.h"
end_include

begin_include
include|#
directive|include
file|"private/svn_mutex.h"
end_include

begin_include
include|#
directive|include
file|"private/svn_string_private.h"
end_include

begin_include
include|#
directive|include
file|"cache.h"
end_include

begin_include
include|#
directive|include
file|"fnv1a.h"
end_include

begin_comment
comment|/*  * This svn_cache__t implementation actually consists of two parts:  * a shared (per-process) singleton membuffer cache instance and shallow  * svn_cache__t front-end instances that each use different key spaces.  * For data management, they all forward to the singleton membuffer cache.  *  * A membuffer cache consists of two parts:  *  * 1. A linear data buffer containing cached items in a serialized  *    representation, prefixed by their full cache keys. There may be  *    arbitrary gaps between entries.  This buffer is sub-devided into  *    (currently two) cache levels.  *  * 2. A directory of cache entries. This is organized similar to CPU  *    data caches: for every possible key, there is exactly one group  *    of entries that may contain the header info for an item with  *    that given key.  The result is a GROUP_SIZE+-way associative cache  *    whose associativity can be dynamically increased.  *  * Only the start address of these two data parts are given as a native  * pointer. All other references are expressed as offsets to these pointers.  * With that design, it is relatively easy to share the same data structure  * between different processes and / or to persist them on disk. These  * out-of-process features have not been implemented, yet.  *  * Superficially, cache levels are being used as usual: insertion happens  * into L1 and evictions will promote items to L2.  But their whole point  * is a different one.  L1 uses a circular buffer, i.e. we have perfect  * caching for the last N bytes where N is the size of L1.  L2 uses a more  * elaborate scheme based on priorities and hit counts as described below.  *  * The data buffer usage information is implicitly given by the directory  * entries. Every USED entry has a reference to the previous and the next  * used dictionary entry and this double-linked list is ordered by the  * offsets of their item data within the data buffer. So removing data,  * for instance, is done simply by unlinking it from the chain, implicitly  * marking the entry as well as the data buffer section previously  * associated to it as unused.  First and last element of that chain are  * being referenced from the respective cache level.  *  * Insertion can occur at only one, sliding position per cache level.  It is  * marked by its offset in the data buffer and the index of the first used  * entry at or behind that position.  If this gap is too small to accommodate  * the new item (plus its full key), the insertion window is extended as  * described below.  The new entry will always be inserted at the bottom end  * of the window and since the next used entry is known, properly sorted  * insertion is possible.  *  * To make the cache perform robustly in a wide range of usage scenarios,  * L2 uses a randomized variant of LFU (see ensure_data_insertable_l2 for  * details). Every item holds a read hit counter and there is a global read  * hit counter. The more hits an entry has in relation to the average, the  * more it is likely to be kept using a rand()-based condition. The test is  * applied only to the entry following the insertion window. If it doesn't  * get evicted, it is moved to the begin of that window and the window is  * moved.  *  * Moreover, the entry's hits get halved to make that entry more likely to  * be removed the next time the sliding insertion / removal window comes by.  * As a result, frequently used entries are likely not to be dropped until  * they get not used for a while. Also, even a cache thrashing situation  * about 50% of the content survives every 50% of the cache being re-written  * with new entries. For details on the fine-tuning involved, see the  * comments in ensure_data_insertable_l2().  *  * Due to the randomized mapping of keys to entry groups, some groups may  * overflow.  In that case, there are spare groups that can be chained to  * an already used group to extend it.  *  * To limit the entry size and management overhead, not the actual item keys  * but only their hashed "fingerprint" will be stored.  These are reasonably  * unique to prevent collisions, so we only need to support up to one entry  * per entry key.  To guarantee that there are no conflicts, however, we  * store the actual full key immediately in front of the serialized item  * data.  That is, the entry offset actually points to the full key and the  * key length stored in the entry acts as an additional offset to find the  * actual item.  *  * All access to the cached data needs to be serialized. Because we want  * to scale well despite that bottleneck, we simply segment the cache into  * a number of independent caches (segments). Items will be multiplexed based  * on their hash key.  */
end_comment

begin_comment
comment|/* APR's read-write lock implementation on Windows is horribly inefficient.  * Even with very low contention a runtime overhead of 35% percent has been  * measured for 'svn-bench null-export' over ra_serf.  *  * Use a simple mutex on Windows.  Because there is one mutex per segment,  * large machines should (and usually can) be configured with large caches  * such that read contention is kept low.  This is basically the situation  * we had before 1.8.  */
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|WIN32
end_ifdef

begin_define
define|#
directive|define
name|USE_SIMPLE_MUTEX
value|1
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|USE_SIMPLE_MUTEX
value|0
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* For more efficient copy operations, let's align all data items properly.  * Since we can't portably align pointers, this is rather the item size  * granularity which ensures *relative* alignment within the cache - still  * giving us decent copy speeds on most machines.  *  * Must be a power of 2.  */
end_comment

begin_define
define|#
directive|define
name|ITEM_ALIGNMENT
value|16
end_define

begin_comment
comment|/* By default, don't create cache segments smaller than this value unless  * the total cache size itself is smaller.  */
end_comment

begin_define
define|#
directive|define
name|DEFAULT_MIN_SEGMENT_SIZE
value|APR_UINT64_C(0x2000000)
end_define

begin_comment
comment|/* The minimum segment size we will allow for multi-segmented caches  */
end_comment

begin_define
define|#
directive|define
name|MIN_SEGMENT_SIZE
value|APR_UINT64_C(0x10000)
end_define

begin_comment
comment|/* The maximum number of segments allowed. Larger numbers reduce the size  * of each segment, in turn reducing the max size of a cachable item.  * Also, each segment gets its own lock object. The actual number supported  * by the OS may therefore be lower and svn_cache__membuffer_cache_create  * may return an error.  */
end_comment

begin_define
define|#
directive|define
name|MAX_SEGMENT_COUNT
value|0x10000
end_define

begin_comment
comment|/* As of today, APR won't allocate chunks of 4GB or more. So, limit the  * segment size to slightly below that.  */
end_comment

begin_define
define|#
directive|define
name|MAX_SEGMENT_SIZE
value|APR_UINT64_C(0xffff0000)
end_define

begin_comment
comment|/* We don't mark the initialization status for every group but initialize  * a number of groups at once. That will allow for a very small init flags  * vector that is likely to fit into the CPU caches even for fairly large  * membuffer caches. For instance, the default of 32 means 8x32 groups per  * byte, i.e. 8 flags/byte x 32 groups/flag x 8 entries/group x 40 index  * bytes/entry x 8 cache bytes/index byte = 1kB init vector / 640MB cache.  */
end_comment

begin_define
define|#
directive|define
name|GROUP_INIT_GRANULARITY
value|32
end_define

begin_comment
comment|/* Invalid index reference value. Equivalent to APR_UINT32_T(-1)  */
end_comment

begin_define
define|#
directive|define
name|NO_INDEX
value|APR_UINT32_MAX
end_define

begin_comment
comment|/* To save space in our group structure, we only use 32 bit size values  * and, therefore, limit the size of each entry to just below 4GB.  * Supporting larger items is not a good idea as the data transfer  * to and from the cache would block other threads for a very long time.  */
end_comment

begin_define
define|#
directive|define
name|MAX_ITEM_SIZE
value|((apr_uint32_t)(0 - ITEM_ALIGNMENT))
end_define

begin_comment
comment|/* We use this structure to identify cache entries. There cannot be two  * entries with the same entry key. However unlikely, though, two different  * full keys (see full_key_t) may have the same entry key.  That is a  * collision and at most one of them can be stored in the cache at any time.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|entry_key_t
block|{
comment|/* 16 byte finger print of the full key. */
name|apr_uint64_t
name|fingerprint
index|[
literal|2
index|]
decl_stmt|;
comment|/* Length of the full key.  This value is aligned to ITEM_ALIGNMENT to    * make sure the subsequent item content is properly aligned. */
name|apr_size_t
name|key_len
decl_stmt|;
block|}
name|entry_key_t
typedef|;
end_typedef

begin_comment
comment|/* A full key, i.e. the combination of the cache's key prefix with some  * dynamic part appended to it.  It also contains its ENTRY_KEY.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|full_key_t
block|{
comment|/* Reduced form identifying the cache entry (if such an entry exists). */
name|entry_key_t
name|entry_key
decl_stmt|;
comment|/* This contains the full combination.  Note that the SIZE element may    * be larger than ENTRY_KEY.KEY_LEN, but only the latter determines the    * valid key size. */
name|svn_membuf_t
name|full_key
decl_stmt|;
block|}
name|full_key_t
typedef|;
end_typedef

begin_comment
comment|/* Debugging / corruption detection support.  * If you define this macro, the getter functions will performed expensive  * checks on the item data, requested keys and entry types. If there is  * a mismatch found in any of them when being compared with the values  * remembered in the setter function, an error will be returned.  */
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|SVN_DEBUG_CACHE_MEMBUFFER
end_ifdef

begin_comment
comment|/* The prefix passed to svn_cache__create_membuffer_cache() effectively  * defines the type of all items stored by that cache instance. We'll take  * the last 15 bytes + \0 as plaintext for easy identification by the dev.  */
end_comment

begin_define
define|#
directive|define
name|PREFIX_TAIL_LEN
value|16
end_define

begin_comment
comment|/* This record will be attached to any cache entry. It tracks item data  * (content), key and type as hash values and is the baseline against which  * the getters will compare their results to detect inconsistencies.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|entry_tag_t
block|{
comment|/* MD5 checksum over the serialized item data.    */
name|unsigned
name|char
name|content_hash
index|[
name|APR_MD5_DIGESTSIZE
index|]
decl_stmt|;
comment|/* Hash value of the svn_cache_t instance that wrote the item    * (i.e. a combination of type and repository)    */
name|unsigned
name|char
name|prefix_hash
index|[
name|APR_MD5_DIGESTSIZE
index|]
decl_stmt|;
comment|/* Note that this only covers the variable part of the key,    * i.e. it will be different from the full key hash used for    * cache indexing.    */
name|unsigned
name|char
name|key_hash
index|[
name|APR_MD5_DIGESTSIZE
index|]
decl_stmt|;
comment|/* Last letters from of the key in human readable format    * (ends with the type identifier, e.g. "DAG")    */
name|char
name|prefix_tail
index|[
name|PREFIX_TAIL_LEN
index|]
decl_stmt|;
comment|/* Length of the variable key part.    */
name|apr_size_t
name|key_len
decl_stmt|;
block|}
name|entry_tag_t
typedef|;
end_typedef

begin_comment
comment|/* Initialize all members of TAG except for the content hash.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|store_key_part
parameter_list|(
name|entry_tag_t
modifier|*
name|tag
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|prefix_key
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|apr_size_t
name|key_len
parameter_list|,
name|apr_pool_t
modifier|*
name|pool
parameter_list|)
block|{
name|svn_checksum_t
modifier|*
name|checksum
decl_stmt|;
specifier|const
name|char
modifier|*
name|prefix
init|=
name|prefix_key
operator|->
name|full_key
operator|.
name|data
decl_stmt|;
name|apr_size_t
name|prefix_len
init|=
name|strlen
argument_list|(
name|prefix
argument_list|)
decl_stmt|;
if|if
condition|(
name|prefix_len
operator|>
sizeof|sizeof
argument_list|(
name|tag
operator|->
name|prefix_tail
argument_list|)
condition|)
block|{
name|prefix
operator|+=
name|prefix_len
operator|-
operator|(
sizeof|sizeof
argument_list|(
name|tag
operator|->
name|prefix_tail
argument_list|)
operator|-
literal|1
operator|)
expr_stmt|;
name|prefix_len
operator|=
sizeof|sizeof
argument_list|(
name|tag
operator|->
name|prefix_tail
argument_list|)
operator|-
literal|1
expr_stmt|;
block|}
name|SVN_ERR
argument_list|(
name|svn_checksum
argument_list|(
operator|&
name|checksum
argument_list|,
name|svn_checksum_md5
argument_list|,
name|key
argument_list|,
name|key_len
argument_list|,
name|pool
argument_list|)
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
name|tag
operator|->
name|prefix_hash
argument_list|,
name|prefix_key
operator|->
name|entry_key
operator|.
name|fingerprint
argument_list|,
sizeof|sizeof
argument_list|(
name|tag
operator|->
name|prefix_hash
argument_list|)
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
name|tag
operator|->
name|key_hash
argument_list|,
name|checksum
operator|->
name|digest
argument_list|,
sizeof|sizeof
argument_list|(
name|tag
operator|->
name|key_hash
argument_list|)
argument_list|)
expr_stmt|;
name|memset
argument_list|(
name|tag
operator|->
name|prefix_tail
argument_list|,
literal|0
argument_list|,
sizeof|sizeof
argument_list|(
name|tag
operator|->
name|key_hash
argument_list|)
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
name|tag
operator|->
name|prefix_tail
argument_list|,
name|prefix
argument_list|,
name|prefix_len
operator|+
literal|1
argument_list|)
expr_stmt|;
name|tag
operator|->
name|key_len
operator|=
name|key_len
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Initialize the content hash member of TAG.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|store_content_part
parameter_list|(
name|entry_tag_t
modifier|*
name|tag
parameter_list|,
specifier|const
name|void
modifier|*
name|data
parameter_list|,
name|apr_size_t
name|size
parameter_list|,
name|apr_pool_t
modifier|*
name|pool
parameter_list|)
block|{
name|svn_checksum_t
modifier|*
name|checksum
decl_stmt|;
name|SVN_ERR
argument_list|(
name|svn_checksum
argument_list|(
operator|&
name|checksum
argument_list|,
name|svn_checksum_md5
argument_list|,
name|data
argument_list|,
name|size
argument_list|,
name|pool
argument_list|)
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
name|tag
operator|->
name|content_hash
argument_list|,
name|checksum
operator|->
name|digest
argument_list|,
sizeof|sizeof
argument_list|(
name|tag
operator|->
name|content_hash
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Compare two tags and fail with an assertion upon differences.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|assert_equal_tags
parameter_list|(
specifier|const
name|entry_tag_t
modifier|*
name|lhs
parameter_list|,
specifier|const
name|entry_tag_t
modifier|*
name|rhs
parameter_list|)
block|{
name|SVN_ERR_ASSERT
argument_list|(
name|memcmp
argument_list|(
name|lhs
operator|->
name|content_hash
argument_list|,
name|rhs
operator|->
name|content_hash
argument_list|,
sizeof|sizeof
argument_list|(
name|lhs
operator|->
name|content_hash
argument_list|)
argument_list|)
operator|==
literal|0
argument_list|)
expr_stmt|;
name|SVN_ERR_ASSERT
argument_list|(
name|memcmp
argument_list|(
name|lhs
operator|->
name|prefix_hash
argument_list|,
name|rhs
operator|->
name|prefix_hash
argument_list|,
sizeof|sizeof
argument_list|(
name|lhs
operator|->
name|prefix_hash
argument_list|)
argument_list|)
operator|==
literal|0
argument_list|)
expr_stmt|;
name|SVN_ERR_ASSERT
argument_list|(
name|memcmp
argument_list|(
name|lhs
operator|->
name|key_hash
argument_list|,
name|rhs
operator|->
name|key_hash
argument_list|,
sizeof|sizeof
argument_list|(
name|lhs
operator|->
name|key_hash
argument_list|)
argument_list|)
operator|==
literal|0
argument_list|)
expr_stmt|;
name|SVN_ERR_ASSERT
argument_list|(
name|memcmp
argument_list|(
name|lhs
operator|->
name|prefix_tail
argument_list|,
name|rhs
operator|->
name|prefix_tail
argument_list|,
sizeof|sizeof
argument_list|(
name|lhs
operator|->
name|prefix_tail
argument_list|)
argument_list|)
operator|==
literal|0
argument_list|)
expr_stmt|;
name|SVN_ERR_ASSERT
argument_list|(
name|lhs
operator|->
name|key_len
operator|==
name|rhs
operator|->
name|key_len
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Reoccurring code snippets.  */
end_comment

begin_define
define|#
directive|define
name|DEBUG_CACHE_MEMBUFFER_TAG_ARG
value|entry_tag_t *tag,
end_define

begin_define
define|#
directive|define
name|DEBUG_CACHE_MEMBUFFER_TAG
value|tag,
end_define

begin_define
define|#
directive|define
name|DEBUG_CACHE_MEMBUFFER_INIT_TAG
parameter_list|(
name|pool
parameter_list|)
define|\
value|entry_tag_t _tag;                                              \   entry_tag_t *tag =&_tag;                                      \   if (key)                                                       \     SVN_ERR(store_key_part(tag,                                  \&cache->prefix,                       \                            key,                                  \                            cache->key_len == APR_HASH_KEY_STRING \                                ? strlen((const char *) key)      \                                : cache->key_len,                 \                            pool));
end_define

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* Don't generate any checks if consistency checks have not been enabled.  */
end_comment

begin_define
define|#
directive|define
name|DEBUG_CACHE_MEMBUFFER_TAG_ARG
end_define

begin_define
define|#
directive|define
name|DEBUG_CACHE_MEMBUFFER_TAG
end_define

begin_define
define|#
directive|define
name|DEBUG_CACHE_MEMBUFFER_INIT_TAG
parameter_list|(
name|pool
parameter_list|)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* SVN_DEBUG_CACHE_MEMBUFFER */
end_comment

begin_comment
comment|/* A single dictionary entry. Since all entries will be allocated once  * during cache creation, those entries might be either used or unused.  * An entry is used if and only if it is contained in the doubly-linked  * list of used entries per cache level.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|entry_t
block|{
comment|/* Identifying the data item. Only valid for used entries.    */
name|entry_key_t
name|key
decl_stmt|;
comment|/* The offset of the cached item's serialized data within the caches    * DATA buffer.    */
name|apr_uint64_t
name|offset
decl_stmt|;
comment|/* Size of the serialized item data. May be 0.  The MAX_ITEM_SIZE macro    * above ensures that there will be no overflows.    * Only valid for used entries.    */
name|apr_size_t
name|size
decl_stmt|;
comment|/* Number of (read) hits for this entry. Will be reset upon write.    * Only valid for used entries.    */
name|svn_atomic_t
name|hit_count
decl_stmt|;
comment|/* Reference to the next used entry in the order defined by offset.    * NO_INDEX indicates the end of the list; this entry must be referenced    * by the caches cache_level_t.last member.  NO_INDEX also implies that    * the data buffer is not used beyond offset+size.    * Only valid for used entries.    */
name|apr_uint32_t
name|next
decl_stmt|;
comment|/* Reference to the previous used entry in the order defined by offset.    * NO_INDEX indicates the end of the list; this entry must be referenced    * by the caches cache_level_t.first member.    * Only valid for used entries.    */
name|apr_uint32_t
name|previous
decl_stmt|;
comment|/* Priority of this entry.  This entry will not be replaced by lower-    * priority items.    */
name|apr_uint32_t
name|priority
decl_stmt|;
ifdef|#
directive|ifdef
name|SVN_DEBUG_CACHE_MEMBUFFER
comment|/* Remember type, content and key hashes.    */
name|entry_tag_t
name|tag
decl_stmt|;
endif|#
directive|endif
block|}
name|entry_t
typedef|;
end_typedef

begin_comment
comment|/* Group header struct.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|group_header_t
block|{
comment|/* number of entries used [0 .. USED-1] */
name|apr_uint32_t
name|used
decl_stmt|;
comment|/* next group in the chain or NO_INDEX for the last.    * For recycleable unused spare groups, this points to the next    * unused spare group */
name|apr_uint32_t
name|next
decl_stmt|;
comment|/* previously group in the chain or NO_INDEX for the first */
name|apr_uint32_t
name|previous
decl_stmt|;
comment|/* number of elements in the chain from start to here.    *>= 1 for used groups, 0 for unused spare groups */
name|apr_uint32_t
name|chain_length
decl_stmt|;
block|}
name|group_header_t
typedef|;
end_typedef

begin_comment
comment|/* The size of the group struct should be a power of two make sure it does  * not cross memory page boundaries.  Since we already access the cache  * randomly, having two page table lookups instead of one is bad.  */
end_comment

begin_define
define|#
directive|define
name|GROUP_BLOCK_SIZE
value|512
end_define

begin_comment
comment|/* A ~10-way associative cache seems to be a good compromise between  * performance (worst-case lookups) and efficiency-loss due to collisions.  *  * This value may be changed to any positive integer.  */
end_comment

begin_define
define|#
directive|define
name|GROUP_SIZE
define|\
value|((GROUP_BLOCK_SIZE - sizeof(group_header_t)) / sizeof(entry_t))
end_define

begin_comment
comment|/* Maximum number of groups in a chain, i.e. a cache index group can hold  * up to GROUP_SIZE * MAX_GROUP_CHAIN_LENGTH entries.  */
end_comment

begin_define
define|#
directive|define
name|MAX_GROUP_CHAIN_LENGTH
value|8
end_define

begin_comment
comment|/* We group dictionary entries to make this GROUP-SIZE-way associative.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|entry_group_t
block|{
comment|/* group globals */
name|group_header_t
name|header
decl_stmt|;
comment|/* padding and also room for future extensions */
name|char
name|padding
index|[
name|GROUP_BLOCK_SIZE
operator|-
sizeof|sizeof
argument_list|(
name|group_header_t
argument_list|)
operator|-
sizeof|sizeof
argument_list|(
name|entry_t
argument_list|)
operator|*
name|GROUP_SIZE
index|]
decl_stmt|;
comment|/* the actual entries */
name|entry_t
name|entries
index|[
name|GROUP_SIZE
index|]
decl_stmt|;
block|}
name|entry_group_t
typedef|;
end_typedef

begin_comment
comment|/* Per-cache level header structure.  Instances of this are members of  * svn_membuffer_t and will use non-overlapping sections of its DATA buffer.  * All offset values are global / absolute to that whole buffer.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|cache_level_t
block|{
comment|/* Reference to the first (defined by the order content in the data    * buffer) dictionary entry used by any data item.    * NO_INDEX for an empty cache.    */
name|apr_uint32_t
name|first
decl_stmt|;
comment|/* Reference to the last (defined by the order content in the data    * buffer) dictionary entry used by any data item.    * NO_INDEX for an empty cache.    */
name|apr_uint32_t
name|last
decl_stmt|;
comment|/* Reference to the first (defined by the order content in the data    * buffer) used dictionary entry behind the insertion position    * (current_data). If NO_INDEX, the data buffer is free starting at the    * current_data offset.    */
name|apr_uint32_t
name|next
decl_stmt|;
comment|/* First offset in the caches DATA buffer that belongs to this level.    */
name|apr_uint64_t
name|start_offset
decl_stmt|;
comment|/* Size of data buffer allocated to this level in bytes. Must be> 0.    */
name|apr_uint64_t
name|size
decl_stmt|;
comment|/* Offset in the data buffer where the next insertion shall occur.    */
name|apr_uint64_t
name|current_data
decl_stmt|;
block|}
name|cache_level_t
typedef|;
end_typedef

begin_comment
comment|/* The cache header structure.  */
end_comment

begin_struct
struct|struct
name|svn_membuffer_t
block|{
comment|/* Number of cache segments. Must be a power of 2.      Please note that this structure represents only one such segment      and that all segments must / will report the same values here. */
name|apr_uint32_t
name|segment_count
decl_stmt|;
comment|/* The dictionary, GROUP_SIZE * (group_count + spare_group_count)    * entries long.  Never NULL.    */
name|entry_group_t
modifier|*
name|directory
decl_stmt|;
comment|/* Flag array with group_count / GROUP_INIT_GRANULARITY _bit_ elements.    * Allows for efficiently marking groups as "not initialized".    */
name|unsigned
name|char
modifier|*
name|group_initialized
decl_stmt|;
comment|/* Size of dictionary in groups. Must be> 0.    */
name|apr_uint32_t
name|group_count
decl_stmt|;
comment|/* Total number of spare groups.    */
name|apr_uint32_t
name|spare_group_count
decl_stmt|;
comment|/* First recycleable spare group.    */
name|apr_uint32_t
name|first_spare_group
decl_stmt|;
comment|/* Maximum number of spare groups ever used.  I.e. group index    * group_count + max_spare_used is the first unused spare group    * if first_spare_group is NO_INDEX.    */
name|apr_uint32_t
name|max_spare_used
decl_stmt|;
comment|/* Pointer to the data buffer, data_size bytes long. Never NULL.    */
name|unsigned
name|char
modifier|*
name|data
decl_stmt|;
comment|/* Total number of data buffer bytes in use.    */
name|apr_uint64_t
name|data_used
decl_stmt|;
comment|/* Largest entry size that we would accept.  For total cache sizes    * less than 4TB (sic!), this is determined by the total cache size.    */
name|apr_uint64_t
name|max_entry_size
decl_stmt|;
comment|/* The cache levels, organized as sub-buffers.  Since entries in the    * DIRECTORY use offsets in DATA for addressing, a cache lookup does    * not need to know the cache level of a specific item.  Cache levels    * are only used to implement a hybrid insertion / eviction strategy.    */
comment|/* First cache level, i.e. most insertions happen here.  Very large    * items might get inserted directly into L2.  L1 is a strict FIFO    * ring buffer that does not care about item priorities.  All evicted    * items get a chance to be promoted to L2.    */
name|cache_level_t
name|l1
decl_stmt|;
comment|/* Second cache level, i.e. data evicted from L1 will be added here    * if the item is "important" enough or the L2 insertion window is large    * enough.    */
name|cache_level_t
name|l2
decl_stmt|;
comment|/* Number of used dictionary entries, i.e. number of cached items.    * Purely statistical information that may be used for profiling only.    * Updates are not synchronized and values may be nonsensicle on some    * platforms.    */
name|apr_uint32_t
name|used_entries
decl_stmt|;
comment|/* Total number of calls to membuffer_cache_get.    * Purely statistical information that may be used for profiling only.    * Updates are not synchronized and values may be nonsensicle on some    * platforms.    */
name|apr_uint64_t
name|total_reads
decl_stmt|;
comment|/* Total number of calls to membuffer_cache_set.    * Purely statistical information that may be used for profiling only.    * Updates are not synchronized and values may be nonsensicle on some    * platforms.    */
name|apr_uint64_t
name|total_writes
decl_stmt|;
comment|/* Total number of hits since the cache's creation.    * Purely statistical information that may be used for profiling only.    * Updates are not synchronized and values may be nonsensicle on some    * platforms.    */
name|apr_uint64_t
name|total_hits
decl_stmt|;
if|#
directive|if
operator|(
name|APR_HAS_THREADS
operator|&&
name|USE_SIMPLE_MUTEX
operator|)
comment|/* A lock for intra-process synchronization to the cache, or NULL if    * the cache's creator doesn't feel the cache needs to be    * thread-safe.    */
name|svn_mutex__t
modifier|*
name|lock
decl_stmt|;
elif|#
directive|elif
operator|(
name|APR_HAS_THREADS
operator|&&
operator|!
name|USE_SIMPLE_MUTEX
operator|)
comment|/* Same for read-write lock. */
name|apr_thread_rwlock_t
modifier|*
name|lock
decl_stmt|;
comment|/* If set, write access will wait until they get exclusive access.    * Otherwise, they will become no-ops if the segment is currently    * read-locked.  Only used when LOCK is an r/w lock.    */
name|svn_boolean_t
name|allow_blocking_writes
decl_stmt|;
endif|#
directive|endif
block|}
struct|;
end_struct

begin_comment
comment|/* Align integer VALUE to the next ITEM_ALIGNMENT boundary.  */
end_comment

begin_define
define|#
directive|define
name|ALIGN_VALUE
parameter_list|(
name|value
parameter_list|)
value|(((value) + ITEM_ALIGNMENT-1)& -ITEM_ALIGNMENT)
end_define

begin_comment
comment|/* If locking is supported for CACHE, acquire a read lock for it.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|read_lock_cache
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|)
block|{
if|#
directive|if
operator|(
name|APR_HAS_THREADS
operator|&&
name|USE_SIMPLE_MUTEX
operator|)
return|return
name|svn_mutex__lock
argument_list|(
name|cache
operator|->
name|lock
argument_list|)
return|;
elif|#
directive|elif
operator|(
name|APR_HAS_THREADS
operator|&&
operator|!
name|USE_SIMPLE_MUTEX
operator|)
if|if
condition|(
name|cache
operator|->
name|lock
condition|)
block|{
name|apr_status_t
name|status
init|=
name|apr_thread_rwlock_rdlock
argument_list|(
name|cache
operator|->
name|lock
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
condition|)
return|return
name|svn_error_wrap_apr
argument_list|(
name|status
argument_list|,
name|_
argument_list|(
literal|"Can't lock cache mutex"
argument_list|)
argument_list|)
return|;
block|}
return|return
name|SVN_NO_ERROR
return|;
else|#
directive|else
return|return
name|SVN_NO_ERROR
return|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/* If locking is supported for CACHE, acquire a write lock for it.  * Set *SUCCESS to FALSE, if we couldn't acquire the write lock;  * leave it untouched otherwise.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|write_lock_cache
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|svn_boolean_t
modifier|*
name|success
parameter_list|)
block|{
if|#
directive|if
operator|(
name|APR_HAS_THREADS
operator|&&
name|USE_SIMPLE_MUTEX
operator|)
return|return
name|svn_mutex__lock
argument_list|(
name|cache
operator|->
name|lock
argument_list|)
return|;
elif|#
directive|elif
operator|(
name|APR_HAS_THREADS
operator|&&
operator|!
name|USE_SIMPLE_MUTEX
operator|)
if|if
condition|(
name|cache
operator|->
name|lock
condition|)
block|{
name|apr_status_t
name|status
decl_stmt|;
if|if
condition|(
name|cache
operator|->
name|allow_blocking_writes
condition|)
block|{
name|status
operator|=
name|apr_thread_rwlock_wrlock
argument_list|(
name|cache
operator|->
name|lock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|status
operator|=
name|apr_thread_rwlock_trywrlock
argument_list|(
name|cache
operator|->
name|lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|SVN_LOCK_IS_BUSY
argument_list|(
name|status
argument_list|)
condition|)
block|{
operator|*
name|success
operator|=
name|FALSE
expr_stmt|;
name|status
operator|=
name|APR_SUCCESS
expr_stmt|;
block|}
block|}
if|if
condition|(
name|status
condition|)
return|return
name|svn_error_wrap_apr
argument_list|(
name|status
argument_list|,
name|_
argument_list|(
literal|"Can't write-lock cache mutex"
argument_list|)
argument_list|)
return|;
block|}
return|return
name|SVN_NO_ERROR
return|;
else|#
directive|else
return|return
name|SVN_NO_ERROR
return|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/* If locking is supported for CACHE, acquire an unconditional write lock  * for it.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|force_write_lock_cache
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|)
block|{
if|#
directive|if
operator|(
name|APR_HAS_THREADS
operator|&&
name|USE_SIMPLE_MUTEX
operator|)
return|return
name|svn_mutex__lock
argument_list|(
name|cache
operator|->
name|lock
argument_list|)
return|;
elif|#
directive|elif
operator|(
name|APR_HAS_THREADS
operator|&&
operator|!
name|USE_SIMPLE_MUTEX
operator|)
name|apr_status_t
name|status
init|=
name|apr_thread_rwlock_wrlock
argument_list|(
name|cache
operator|->
name|lock
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
condition|)
return|return
name|svn_error_wrap_apr
argument_list|(
name|status
argument_list|,
name|_
argument_list|(
literal|"Can't write-lock cache mutex"
argument_list|)
argument_list|)
return|;
return|return
name|SVN_NO_ERROR
return|;
else|#
directive|else
return|return
name|SVN_NO_ERROR
return|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/* If locking is supported for CACHE, release the current lock  * (read or write).  Return ERR upon success.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|unlock_cache
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|svn_error_t
modifier|*
name|err
parameter_list|)
block|{
if|#
directive|if
operator|(
name|APR_HAS_THREADS
operator|&&
name|USE_SIMPLE_MUTEX
operator|)
return|return
name|svn_mutex__unlock
argument_list|(
name|cache
operator|->
name|lock
argument_list|,
name|err
argument_list|)
return|;
elif|#
directive|elif
operator|(
name|APR_HAS_THREADS
operator|&&
operator|!
name|USE_SIMPLE_MUTEX
operator|)
if|if
condition|(
name|cache
operator|->
name|lock
condition|)
block|{
name|apr_status_t
name|status
init|=
name|apr_thread_rwlock_unlock
argument_list|(
name|cache
operator|->
name|lock
argument_list|)
decl_stmt|;
if|if
condition|(
name|err
condition|)
return|return
name|err
return|;
if|if
condition|(
name|status
condition|)
return|return
name|svn_error_wrap_apr
argument_list|(
name|status
argument_list|,
name|_
argument_list|(
literal|"Can't unlock cache mutex"
argument_list|)
argument_list|)
return|;
block|}
return|return
name|err
return|;
else|#
directive|else
return|return
name|err
return|;
endif|#
directive|endif
block|}
end_function

begin_comment
comment|/* If supported, guard the execution of EXPR with a read lock to CACHE.  * The macro has been modeled after SVN_MUTEX__WITH_LOCK.  */
end_comment

begin_define
define|#
directive|define
name|WITH_READ_LOCK
parameter_list|(
name|cache
parameter_list|,
name|expr
parameter_list|)
define|\
value|do {                                        \   SVN_ERR(read_lock_cache(cache));          \   SVN_ERR(unlock_cache(cache, (expr)));     \ } while (0)
end_define

begin_comment
comment|/* If supported, guard the execution of EXPR with a write lock to CACHE.  * The macro has been modeled after SVN_MUTEX__WITH_LOCK.  *  * The write lock process is complicated if we don't allow to wait for  * the lock: If we didn't get the lock, we may still need to remove an  * existing entry for the given key because that content is now stale.  * Once we discovered such an entry, we unconditionally do a blocking  * wait for the write lock.  In case no old content could be found, a  * failing lock attempt is simply a no-op and we exit the macro.  */
end_comment

begin_define
define|#
directive|define
name|WITH_WRITE_LOCK
parameter_list|(
name|cache
parameter_list|,
name|expr
parameter_list|)
define|\
value|do {                                                            \   svn_boolean_t got_lock = TRUE;                                \   SVN_ERR(write_lock_cache(cache,&got_lock));                  \   if (!got_lock)                                                \     {                                                           \       svn_boolean_t exists;                                     \       SVN_ERR(entry_exists(cache, group_index, key,&exists));  \       if (exists)                                               \         SVN_ERR(force_write_lock_cache(cache));                 \       else                                                      \         break;                                                  \     }                                                           \   SVN_ERR(unlock_cache(cache, (expr)));                         \ } while (0)
end_define

begin_comment
comment|/* Returns 0 if the entry group identified by GROUP_INDEX in CACHE has not  * been initialized, yet. In that case, this group can not data. Otherwise,  * a non-zero value is returned.  */
end_comment

begin_function
specifier|static
name|APR_INLINE
name|unsigned
name|char
name|is_group_initialized
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|group_index
parameter_list|)
block|{
name|unsigned
name|char
name|flags
init|=
name|cache
operator|->
name|group_initialized
index|[
name|group_index
operator|/
operator|(
literal|8
operator|*
name|GROUP_INIT_GRANULARITY
operator|)
index|]
decl_stmt|;
name|unsigned
name|char
name|bit_mask
init|=
call|(
name|unsigned
name|char
call|)
argument_list|(
literal|1
operator|<<
operator|(
operator|(
name|group_index
operator|/
name|GROUP_INIT_GRANULARITY
operator|)
operator|%
literal|8
operator|)
argument_list|)
decl_stmt|;
return|return
name|flags
operator|&
name|bit_mask
return|;
block|}
end_function

begin_comment
comment|/* Initializes the section of the directory in CACHE that contains  * the entry group identified by GROUP_INDEX. */
end_comment

begin_function
specifier|static
name|void
name|initialize_group
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|group_index
parameter_list|)
block|{
name|unsigned
name|char
name|bit_mask
decl_stmt|;
name|apr_uint32_t
name|i
decl_stmt|;
comment|/* range of groups to initialize due to GROUP_INIT_GRANULARITY */
name|apr_uint32_t
name|first_index
init|=
operator|(
name|group_index
operator|/
name|GROUP_INIT_GRANULARITY
operator|)
operator|*
name|GROUP_INIT_GRANULARITY
decl_stmt|;
name|apr_uint32_t
name|last_index
init|=
name|first_index
operator|+
name|GROUP_INIT_GRANULARITY
decl_stmt|;
if|if
condition|(
name|last_index
operator|>
name|cache
operator|->
name|group_count
operator|+
name|cache
operator|->
name|spare_group_count
condition|)
name|last_index
operator|=
name|cache
operator|->
name|group_count
operator|+
name|cache
operator|->
name|spare_group_count
expr_stmt|;
for|for
control|(
name|i
operator|=
name|first_index
init|;
name|i
operator|<
name|last_index
condition|;
operator|++
name|i
control|)
block|{
name|group_header_t
modifier|*
name|header
init|=
operator|&
name|cache
operator|->
name|directory
index|[
name|i
index|]
operator|.
name|header
decl_stmt|;
name|header
operator|->
name|used
operator|=
literal|0
expr_stmt|;
name|header
operator|->
name|chain_length
operator|=
literal|1
expr_stmt|;
name|header
operator|->
name|next
operator|=
name|NO_INDEX
expr_stmt|;
name|header
operator|->
name|previous
operator|=
name|NO_INDEX
expr_stmt|;
block|}
comment|/* set the "initialized" bit for these groups */
name|bit_mask
operator|=
call|(
name|unsigned
name|char
call|)
argument_list|(
literal|1
operator|<<
operator|(
operator|(
name|group_index
operator|/
name|GROUP_INIT_GRANULARITY
operator|)
operator|%
literal|8
operator|)
argument_list|)
expr_stmt|;
name|cache
operator|->
name|group_initialized
index|[
name|group_index
operator|/
operator|(
literal|8
operator|*
name|GROUP_INIT_GRANULARITY
operator|)
index|]
operator||=
name|bit_mask
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Return the next available spare group from CACHE and mark it as used.  * May return NULL.  */
end_comment

begin_function
specifier|static
name|entry_group_t
modifier|*
name|allocate_spare_group
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|)
block|{
name|entry_group_t
modifier|*
name|group
init|=
name|NULL
decl_stmt|;
comment|/* is there some ready-to-use group? */
if|if
condition|(
name|cache
operator|->
name|first_spare_group
operator|!=
name|NO_INDEX
condition|)
block|{
name|group
operator|=
operator|&
name|cache
operator|->
name|directory
index|[
name|cache
operator|->
name|first_spare_group
index|]
expr_stmt|;
name|cache
operator|->
name|first_spare_group
operator|=
name|group
operator|->
name|header
operator|.
name|next
expr_stmt|;
block|}
comment|/* any so far untouched spares available? */
elseif|else
if|if
condition|(
name|cache
operator|->
name|max_spare_used
operator|<
name|cache
operator|->
name|spare_group_count
condition|)
block|{
name|apr_uint32_t
name|group_index
init|=
name|cache
operator|->
name|group_count
operator|+
name|cache
operator|->
name|max_spare_used
decl_stmt|;
operator|++
name|cache
operator|->
name|max_spare_used
expr_stmt|;
if|if
condition|(
operator|!
name|is_group_initialized
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|)
condition|)
name|initialize_group
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|)
expr_stmt|;
name|group
operator|=
operator|&
name|cache
operator|->
name|directory
index|[
name|group_index
index|]
expr_stmt|;
block|}
comment|/* spare groups must be empty */
name|assert
argument_list|(
operator|!
name|group
operator|||
operator|!
name|group
operator|->
name|header
operator|.
name|used
argument_list|)
expr_stmt|;
return|return
name|group
return|;
block|}
end_function

begin_comment
comment|/* Mark previously allocated spare group GROUP in CACHE as "unused".  */
end_comment

begin_function
specifier|static
name|void
name|free_spare_group
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_group_t
modifier|*
name|group
parameter_list|)
block|{
name|assert
argument_list|(
name|group
operator|->
name|header
operator|.
name|used
operator|==
literal|0
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|group
operator|->
name|header
operator|.
name|previous
operator|!=
name|NO_INDEX
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|group
operator|-
name|cache
operator|->
name|directory
operator|>=
operator|(
name|apr_ssize_t
operator|)
name|cache
operator|->
name|group_count
argument_list|)
expr_stmt|;
comment|/* unchain */
name|cache
operator|->
name|directory
index|[
name|group
operator|->
name|header
operator|.
name|previous
index|]
operator|.
name|header
operator|.
name|next
operator|=
name|NO_INDEX
expr_stmt|;
name|group
operator|->
name|header
operator|.
name|chain_length
operator|=
literal|0
expr_stmt|;
name|group
operator|->
name|header
operator|.
name|previous
operator|=
name|NO_INDEX
expr_stmt|;
comment|/* add to chain of spares */
name|group
operator|->
name|header
operator|.
name|next
operator|=
name|cache
operator|->
name|first_spare_group
expr_stmt|;
name|cache
operator|->
name|first_spare_group
operator|=
call|(
name|apr_uint32_t
call|)
argument_list|(
name|group
operator|-
name|cache
operator|->
name|directory
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Follow the group chain from GROUP in CACHE to its end and return the last  * group.  May return GROUP.  */
end_comment

begin_function
specifier|static
name|entry_group_t
modifier|*
name|last_group_in_chain
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_group_t
modifier|*
name|group
parameter_list|)
block|{
while|while
condition|(
name|group
operator|->
name|header
operator|.
name|next
operator|!=
name|NO_INDEX
condition|)
name|group
operator|=
operator|&
name|cache
operator|->
name|directory
index|[
name|group
operator|->
name|header
operator|.
name|next
index|]
expr_stmt|;
return|return
name|group
return|;
block|}
end_function

begin_comment
comment|/* Return the CHAIN_INDEX-th element in the group chain starting from group  * START_GROUP_INDEX in CACHE.  */
end_comment

begin_function
specifier|static
name|entry_group_t
modifier|*
name|get_group
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|start_group_index
parameter_list|,
name|apr_uint32_t
name|chain_index
parameter_list|)
block|{
name|entry_group_t
modifier|*
name|group
init|=
operator|&
name|cache
operator|->
name|directory
index|[
name|start_group_index
index|]
decl_stmt|;
for|for
control|(
init|;
name|chain_index
condition|;
operator|--
name|chain_index
control|)
name|group
operator|=
operator|&
name|cache
operator|->
name|directory
index|[
name|group
operator|->
name|header
operator|.
name|next
index|]
expr_stmt|;
return|return
name|group
return|;
block|}
end_function

begin_comment
comment|/* Resolve a dictionary entry reference, i.e. return the entry  * for the given IDX.  */
end_comment

begin_function
specifier|static
name|APR_INLINE
name|entry_t
modifier|*
name|get_entry
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|idx
parameter_list|)
block|{
return|return
operator|&
name|cache
operator|->
name|directory
index|[
name|idx
operator|/
name|GROUP_SIZE
index|]
operator|.
name|entries
index|[
name|idx
operator|%
name|GROUP_SIZE
index|]
return|;
block|}
end_function

begin_comment
comment|/* Get the entry references for the given ENTRY.  */
end_comment

begin_function
specifier|static
name|APR_INLINE
name|apr_uint32_t
name|get_index
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_t
modifier|*
name|entry
parameter_list|)
block|{
name|apr_size_t
name|group_index
init|=
operator|(
operator|(
name|char
operator|*
operator|)
name|entry
operator|-
operator|(
name|char
operator|*
operator|)
name|cache
operator|->
name|directory
operator|)
operator|/
sizeof|sizeof
argument_list|(
name|entry_group_t
argument_list|)
decl_stmt|;
return|return
operator|(
name|apr_uint32_t
operator|)
name|group_index
operator|*
name|GROUP_SIZE
operator|+
call|(
name|apr_uint32_t
call|)
argument_list|(
name|entry
operator|-
name|cache
operator|->
name|directory
index|[
name|group_index
index|]
operator|.
name|entries
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/* Return the cache level of ENTRY in CACHE.  */
end_comment

begin_function
specifier|static
name|cache_level_t
modifier|*
name|get_cache_level
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_t
modifier|*
name|entry
parameter_list|)
block|{
return|return
name|entry
operator|->
name|offset
operator|<
name|cache
operator|->
name|l1
operator|.
name|size
condition|?
operator|&
name|cache
operator|->
name|l1
else|:
operator|&
name|cache
operator|->
name|l2
return|;
block|}
end_function

begin_comment
comment|/* Insert ENTRY to the chain of items that belong to LEVEL in CACHE.  IDX  * is ENTRY's item index and is only given for efficiency.  The insertion  * takes place just before LEVEL->NEXT.  *CACHE will not be modified.  */
end_comment

begin_function
specifier|static
name|void
name|chain_entry
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|cache_level_t
modifier|*
name|level
parameter_list|,
name|entry_t
modifier|*
name|entry
parameter_list|,
name|apr_uint32_t
name|idx
parameter_list|)
block|{
comment|/* insert ENTRY before this item */
name|entry_t
modifier|*
name|next
init|=
name|level
operator|->
name|next
operator|==
name|NO_INDEX
condition|?
name|NULL
else|:
name|get_entry
argument_list|(
name|cache
argument_list|,
name|level
operator|->
name|next
argument_list|)
decl_stmt|;
name|assert
argument_list|(
name|idx
operator|==
name|get_index
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
argument_list|)
expr_stmt|;
comment|/* update entry chain    */
name|entry
operator|->
name|next
operator|=
name|level
operator|->
name|next
expr_stmt|;
if|if
condition|(
name|level
operator|->
name|first
operator|==
name|NO_INDEX
condition|)
block|{
comment|/* insert as the first entry and only in the chain        */
name|entry
operator|->
name|previous
operator|=
name|NO_INDEX
expr_stmt|;
name|level
operator|->
name|last
operator|=
name|idx
expr_stmt|;
name|level
operator|->
name|first
operator|=
name|idx
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|next
operator|==
name|NULL
condition|)
block|{
comment|/* insert as the last entry in the chain.        * Note that it cannot also be at the beginning of the chain.        */
name|entry
operator|->
name|previous
operator|=
name|level
operator|->
name|last
expr_stmt|;
name|get_entry
argument_list|(
name|cache
argument_list|,
name|level
operator|->
name|last
argument_list|)
operator|->
name|next
operator|=
name|idx
expr_stmt|;
name|level
operator|->
name|last
operator|=
name|idx
expr_stmt|;
block|}
else|else
block|{
comment|/* insert either at the start of a non-empty list or        * somewhere in the middle        */
name|entry
operator|->
name|previous
operator|=
name|next
operator|->
name|previous
expr_stmt|;
name|next
operator|->
name|previous
operator|=
name|idx
expr_stmt|;
if|if
condition|(
name|entry
operator|->
name|previous
operator|!=
name|NO_INDEX
condition|)
name|get_entry
argument_list|(
name|cache
argument_list|,
name|entry
operator|->
name|previous
argument_list|)
operator|->
name|next
operator|=
name|idx
expr_stmt|;
else|else
name|level
operator|->
name|first
operator|=
name|idx
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/* Remove ENTRY from the chain of items that belong to LEVEL in CACHE. IDX  * is ENTRY's item index and is only given for efficiency.  Please note  * that neither *CACHE nor *ENTRY will not be modified.  */
end_comment

begin_function
specifier|static
name|void
name|unchain_entry
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|cache_level_t
modifier|*
name|level
parameter_list|,
name|entry_t
modifier|*
name|entry
parameter_list|,
name|apr_uint32_t
name|idx
parameter_list|)
block|{
name|assert
argument_list|(
name|idx
operator|==
name|get_index
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
argument_list|)
expr_stmt|;
comment|/* update    */
if|if
condition|(
name|level
operator|->
name|next
operator|==
name|idx
condition|)
name|level
operator|->
name|next
operator|=
name|entry
operator|->
name|next
expr_stmt|;
comment|/* unlink it from the chain of used entries    */
if|if
condition|(
name|entry
operator|->
name|previous
operator|==
name|NO_INDEX
condition|)
name|level
operator|->
name|first
operator|=
name|entry
operator|->
name|next
expr_stmt|;
else|else
name|get_entry
argument_list|(
name|cache
argument_list|,
name|entry
operator|->
name|previous
argument_list|)
operator|->
name|next
operator|=
name|entry
operator|->
name|next
expr_stmt|;
if|if
condition|(
name|entry
operator|->
name|next
operator|==
name|NO_INDEX
condition|)
name|level
operator|->
name|last
operator|=
name|entry
operator|->
name|previous
expr_stmt|;
else|else
name|get_entry
argument_list|(
name|cache
argument_list|,
name|entry
operator|->
name|next
argument_list|)
operator|->
name|previous
operator|=
name|entry
operator|->
name|previous
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Remove the used ENTRY from the CACHE, i.e. make it "unused".  * In contrast to insertion, removal is possible for any entry.  */
end_comment

begin_function
specifier|static
name|void
name|drop_entry
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_t
modifier|*
name|entry
parameter_list|)
block|{
comment|/* the group that ENTRY belongs to plus a number of useful index values    */
name|apr_uint32_t
name|idx
init|=
name|get_index
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
decl_stmt|;
name|apr_uint32_t
name|group_index
init|=
name|idx
operator|/
name|GROUP_SIZE
decl_stmt|;
name|entry_group_t
modifier|*
name|last_group
init|=
name|last_group_in_chain
argument_list|(
name|cache
argument_list|,
operator|&
name|cache
operator|->
name|directory
index|[
name|group_index
index|]
argument_list|)
decl_stmt|;
name|apr_uint32_t
name|last_in_group
init|=
call|(
name|apr_uint32_t
call|)
argument_list|(
operator|(
name|last_group
operator|-
name|cache
operator|->
name|directory
operator|)
operator|*
name|GROUP_SIZE
operator|+
name|last_group
operator|->
name|header
operator|.
name|used
operator|-
literal|1
argument_list|)
decl_stmt|;
name|cache_level_t
modifier|*
name|level
init|=
name|get_cache_level
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
decl_stmt|;
comment|/* update global cache usage counters    */
name|cache
operator|->
name|used_entries
operator|--
expr_stmt|;
name|cache
operator|->
name|data_used
operator|-=
name|entry
operator|->
name|size
expr_stmt|;
comment|/* extend the insertion window, if the entry happens to border it    */
if|if
condition|(
name|idx
operator|==
name|level
operator|->
name|next
condition|)
name|level
operator|->
name|next
operator|=
name|entry
operator|->
name|next
expr_stmt|;
elseif|else
if|if
condition|(
name|entry
operator|->
name|next
operator|==
name|level
operator|->
name|next
condition|)
block|{
comment|/* insertion window starts right behind the entry to remove          */
if|if
condition|(
name|entry
operator|->
name|previous
operator|==
name|NO_INDEX
condition|)
block|{
comment|/* remove the first entry -> insertion may start at pos 0, now */
name|level
operator|->
name|current_data
operator|=
name|level
operator|->
name|start_offset
expr_stmt|;
block|}
else|else
block|{
comment|/* insertion may start right behind the previous entry */
name|entry_t
modifier|*
name|previous
init|=
name|get_entry
argument_list|(
name|cache
argument_list|,
name|entry
operator|->
name|previous
argument_list|)
decl_stmt|;
name|level
operator|->
name|current_data
operator|=
name|ALIGN_VALUE
argument_list|(
name|previous
operator|->
name|offset
operator|+
name|previous
operator|->
name|size
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* unlink it from the chain of used entries    */
name|unchain_entry
argument_list|(
name|cache
argument_list|,
name|level
argument_list|,
name|entry
argument_list|,
name|idx
argument_list|)
expr_stmt|;
comment|/* Move last entry into hole (if the removed one is not the last used).    * We need to do this since all used entries are at the beginning of    * the group's entries array.    */
if|if
condition|(
name|idx
operator|!=
name|last_in_group
condition|)
block|{
comment|/* copy the last used entry to the removed entry's index        */
operator|*
name|entry
operator|=
name|last_group
operator|->
name|entries
index|[
name|last_group
operator|->
name|header
operator|.
name|used
operator|-
literal|1
index|]
expr_stmt|;
comment|/* this ENTRY may belong to a different cache level than the entry        * we have just removed */
name|level
operator|=
name|get_cache_level
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
comment|/* update foreign links to new index        */
if|if
condition|(
name|last_in_group
operator|==
name|level
operator|->
name|next
condition|)
name|level
operator|->
name|next
operator|=
name|idx
expr_stmt|;
if|if
condition|(
name|entry
operator|->
name|previous
operator|==
name|NO_INDEX
condition|)
name|level
operator|->
name|first
operator|=
name|idx
expr_stmt|;
else|else
name|get_entry
argument_list|(
name|cache
argument_list|,
name|entry
operator|->
name|previous
argument_list|)
operator|->
name|next
operator|=
name|idx
expr_stmt|;
if|if
condition|(
name|entry
operator|->
name|next
operator|==
name|NO_INDEX
condition|)
name|level
operator|->
name|last
operator|=
name|idx
expr_stmt|;
else|else
name|get_entry
argument_list|(
name|cache
argument_list|,
name|entry
operator|->
name|next
argument_list|)
operator|->
name|previous
operator|=
name|idx
expr_stmt|;
block|}
comment|/* Update the number of used entries.    */
name|last_group
operator|->
name|header
operator|.
name|used
operator|--
expr_stmt|;
comment|/* Release the last group in the chain if it is a spare group    */
if|if
condition|(
operator|!
name|last_group
operator|->
name|header
operator|.
name|used
operator|&&
name|last_group
operator|->
name|header
operator|.
name|previous
operator|!=
name|NO_INDEX
condition|)
name|free_spare_group
argument_list|(
name|cache
argument_list|,
name|last_group
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Insert ENTRY into the chain of used dictionary entries. The entry's  * offset and size members must already have been initialized. Also,  * the offset must match the beginning of the insertion window.  */
end_comment

begin_function
specifier|static
name|void
name|insert_entry
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_t
modifier|*
name|entry
parameter_list|)
block|{
comment|/* the group that ENTRY belongs to plus a number of useful index values    */
name|apr_uint32_t
name|idx
init|=
name|get_index
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
decl_stmt|;
name|apr_uint32_t
name|group_index
init|=
name|idx
operator|/
name|GROUP_SIZE
decl_stmt|;
name|entry_group_t
modifier|*
name|group
init|=
operator|&
name|cache
operator|->
name|directory
index|[
name|group_index
index|]
decl_stmt|;
name|cache_level_t
modifier|*
name|level
init|=
name|get_cache_level
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
decl_stmt|;
comment|/* The entry must start at the beginning of the insertion window.    * It must also be the first unused entry in the group.    */
name|assert
argument_list|(
name|entry
operator|->
name|offset
operator|==
name|level
operator|->
name|current_data
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|idx
operator|==
name|group_index
operator|*
name|GROUP_SIZE
operator|+
name|group
operator|->
name|header
operator|.
name|used
argument_list|)
expr_stmt|;
name|level
operator|->
name|current_data
operator|=
name|ALIGN_VALUE
argument_list|(
name|entry
operator|->
name|offset
operator|+
name|entry
operator|->
name|size
argument_list|)
expr_stmt|;
comment|/* update usage counters    */
name|cache
operator|->
name|used_entries
operator|++
expr_stmt|;
name|cache
operator|->
name|data_used
operator|+=
name|entry
operator|->
name|size
expr_stmt|;
name|entry
operator|->
name|hit_count
operator|=
literal|0
expr_stmt|;
name|group
operator|->
name|header
operator|.
name|used
operator|++
expr_stmt|;
comment|/* update entry chain    */
name|chain_entry
argument_list|(
name|cache
argument_list|,
name|level
argument_list|,
name|entry
argument_list|,
name|idx
argument_list|)
expr_stmt|;
comment|/* The current insertion position must never point outside our    * data buffer.    */
name|assert
argument_list|(
name|level
operator|->
name|current_data
operator|<=
name|level
operator|->
name|start_offset
operator|+
name|level
operator|->
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Map a KEY of 16 bytes to the CACHE and group that shall contain the  * respective item.  */
end_comment

begin_function
specifier|static
name|apr_uint32_t
name|get_group_index
parameter_list|(
name|svn_membuffer_t
modifier|*
modifier|*
name|cache
parameter_list|,
specifier|const
name|entry_key_t
modifier|*
name|key
parameter_list|)
block|{
name|svn_membuffer_t
modifier|*
name|segment0
init|=
operator|*
name|cache
decl_stmt|;
name|apr_uint64_t
name|key0
init|=
name|key
operator|->
name|fingerprint
index|[
literal|0
index|]
decl_stmt|;
name|apr_uint64_t
name|key1
init|=
name|key
operator|->
name|fingerprint
index|[
literal|1
index|]
decl_stmt|;
comment|/* select the cache segment to use. they have all the same group_count.    * Since key may not be well-distributed, pre-fold it to a smaller but    * "denser" ranger.  The modulus is a prime larger than the largest    * counts. */
operator|*
name|cache
operator|=
operator|&
name|segment0
index|[
operator|(
name|key1
operator|%
name|APR_UINT64_C
argument_list|(
literal|2809637
argument_list|)
operator|+
operator|(
name|key0
operator|/
literal|37
operator|)
operator|)
operator|&
operator|(
name|segment0
operator|->
name|segment_count
operator|-
literal|1
operator|)
index|]
expr_stmt|;
return|return
operator|(
name|key0
operator|%
name|APR_UINT64_C
argument_list|(
literal|5030895599
argument_list|)
operator|)
operator|%
name|segment0
operator|->
name|group_count
return|;
block|}
end_function

begin_comment
comment|/* Reduce the hit count of ENTRY and update the accumulated hit info  * in CACHE accordingly.  */
end_comment

begin_function
specifier|static
name|APR_INLINE
name|void
name|let_entry_age
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_t
modifier|*
name|entry
parameter_list|)
block|{
name|apr_uint32_t
name|hits_removed
init|=
operator|(
name|entry
operator|->
name|hit_count
operator|+
literal|1
operator|)
operator|>>
literal|1
decl_stmt|;
if|if
condition|(
name|hits_removed
condition|)
block|{
name|entry
operator|->
name|hit_count
operator|-=
name|hits_removed
expr_stmt|;
block|}
else|else
block|{
name|entry
operator|->
name|priority
operator|/=
literal|2
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/* Return whether the keys in LHS and RHS match.  */
end_comment

begin_function
specifier|static
name|svn_boolean_t
name|entry_keys_match
parameter_list|(
specifier|const
name|entry_key_t
modifier|*
name|lhs
parameter_list|,
specifier|const
name|entry_key_t
modifier|*
name|rhs
parameter_list|)
block|{
return|return
operator|(
name|lhs
operator|->
name|fingerprint
index|[
literal|0
index|]
operator|==
name|rhs
operator|->
name|fingerprint
index|[
literal|0
index|]
operator|)
operator|&&
operator|(
name|lhs
operator|->
name|fingerprint
index|[
literal|1
index|]
operator|==
name|rhs
operator|->
name|fingerprint
index|[
literal|1
index|]
operator|)
operator|&&
operator|(
name|lhs
operator|->
name|key_len
operator|==
name|rhs
operator|->
name|key_len
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Given the GROUP_INDEX that shall contain an entry with the hash key  * TO_FIND, find that entry in the specified group.  *  * If FIND_EMPTY is not set, this function will return the one used entry  * that actually matches the hash or NULL, if no such entry exists.  *  * If FIND_EMPTY has been set, this function will drop the one used entry  * that actually matches the hash (i.e. make it fit to be replaced with  * new content), an unused entry or a forcibly removed entry (if all  * group entries are currently in use). The entries' hash value will be  * initialized with TO_FIND.  *  * Note: This function requires the caller to appropriately lock the CACHE.  * For FIND_EMPTY==FALSE, a read lock is required, for FIND_EMPTY==TRUE,  * the write lock must have been acquired.  */
end_comment

begin_function
specifier|static
name|entry_t
modifier|*
name|find_entry
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|group_index
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|to_find
parameter_list|,
name|svn_boolean_t
name|find_empty
parameter_list|)
block|{
name|entry_group_t
modifier|*
name|group
decl_stmt|;
name|entry_t
modifier|*
name|entry
init|=
name|NULL
decl_stmt|;
name|apr_size_t
name|i
decl_stmt|;
comment|/* get the group that *must* contain the entry    */
name|group
operator|=
operator|&
name|cache
operator|->
name|directory
index|[
name|group_index
index|]
expr_stmt|;
comment|/* If the entry group has not been initialized, yet, there is no data.    */
if|if
condition|(
operator|!
name|is_group_initialized
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|)
condition|)
block|{
if|if
condition|(
name|find_empty
condition|)
block|{
name|initialize_group
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|)
expr_stmt|;
name|entry
operator|=
operator|&
name|group
operator|->
name|entries
index|[
literal|0
index|]
expr_stmt|;
comment|/* initialize entry for the new key */
name|entry
operator|->
name|key
operator|=
name|to_find
operator|->
name|entry_key
expr_stmt|;
block|}
return|return
name|entry
return|;
block|}
comment|/* try to find the matching entry    */
while|while
condition|(
literal|1
condition|)
block|{
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|group
operator|->
name|header
operator|.
name|used
condition|;
operator|++
name|i
control|)
if|if
condition|(
name|entry_keys_match
argument_list|(
operator|&
name|group
operator|->
name|entries
index|[
name|i
index|]
operator|.
name|key
argument_list|,
operator|&
name|to_find
operator|->
name|entry_key
argument_list|)
condition|)
block|{
comment|/* This is the only entry that _may_ contain the correct data. */
name|entry
operator|=
operator|&
name|group
operator|->
name|entries
index|[
name|i
index|]
expr_stmt|;
comment|/* If we want to preserve it, check that it is actual a match. */
if|if
condition|(
operator|!
name|find_empty
condition|)
block|{
comment|/* If there is no full key to compare, we are done. */
if|if
condition|(
operator|!
name|entry
operator|->
name|key
operator|.
name|key_len
condition|)
return|return
name|entry
return|;
comment|/* Compare the full key. */
if|if
condition|(
name|memcmp
argument_list|(
name|to_find
operator|->
name|full_key
operator|.
name|data
argument_list|,
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
argument_list|,
name|entry
operator|->
name|key
operator|.
name|key_len
argument_list|)
operator|==
literal|0
condition|)
return|return
name|entry
return|;
comment|/* Key conflict. The entry to find cannot be anywhere else.                  * Therefore, it is not cached. */
return|return
name|NULL
return|;
block|}
comment|/* need to empty that entry */
name|drop_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
if|if
condition|(
name|group
operator|->
name|header
operator|.
name|used
operator|==
name|GROUP_SIZE
condition|)
name|group
operator|=
name|last_group_in_chain
argument_list|(
name|cache
argument_list|,
name|group
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|group
operator|->
name|header
operator|.
name|chain_length
operator|==
literal|0
condition|)
name|group
operator|=
name|last_group_in_chain
argument_list|(
name|cache
argument_list|,
operator|&
name|cache
operator|->
name|directory
index|[
name|group_index
index|]
argument_list|)
expr_stmt|;
comment|/* No entry found (actually, none left to find). */
name|entry
operator|=
name|NULL
expr_stmt|;
break|break;
block|}
comment|/* end of chain? */
if|if
condition|(
name|group
operator|->
name|header
operator|.
name|next
operator|==
name|NO_INDEX
condition|)
break|break;
comment|/* only full groups may chain */
name|assert
argument_list|(
name|group
operator|->
name|header
operator|.
name|used
operator|==
name|GROUP_SIZE
argument_list|)
expr_stmt|;
name|group
operator|=
operator|&
name|cache
operator|->
name|directory
index|[
name|group
operator|->
name|header
operator|.
name|next
index|]
expr_stmt|;
block|}
comment|/* None found. Are we looking for a free entry?    */
if|if
condition|(
name|find_empty
condition|)
block|{
comment|/* There is no empty entry in the chain, try chaining a spare group.        */
if|if
condition|(
name|group
operator|->
name|header
operator|.
name|used
operator|==
name|GROUP_SIZE
operator|&&
name|group
operator|->
name|header
operator|.
name|chain_length
operator|<
name|MAX_GROUP_CHAIN_LENGTH
condition|)
block|{
name|entry_group_t
modifier|*
name|new_group
init|=
name|allocate_spare_group
argument_list|(
name|cache
argument_list|)
decl_stmt|;
if|if
condition|(
name|new_group
condition|)
block|{
comment|/* chain groups                */
name|new_group
operator|->
name|header
operator|.
name|chain_length
operator|=
name|group
operator|->
name|header
operator|.
name|chain_length
operator|+
literal|1
expr_stmt|;
name|new_group
operator|->
name|header
operator|.
name|previous
operator|=
call|(
name|apr_uint32_t
call|)
argument_list|(
name|group
operator|-
name|cache
operator|->
name|directory
argument_list|)
expr_stmt|;
name|new_group
operator|->
name|header
operator|.
name|next
operator|=
name|NO_INDEX
expr_stmt|;
name|group
operator|->
name|header
operator|.
name|next
operator|=
call|(
name|apr_uint32_t
call|)
argument_list|(
name|new_group
operator|-
name|cache
operator|->
name|directory
argument_list|)
expr_stmt|;
name|group
operator|=
name|new_group
expr_stmt|;
block|}
block|}
comment|/* if GROUP is still filled, we need to remove a random entry */
if|if
condition|(
name|group
operator|->
name|header
operator|.
name|used
operator|==
name|GROUP_SIZE
condition|)
block|{
comment|/* every entry gets the same chance of being removed.            * Otherwise, we free the first entry, fill it and            * remove it again on the next occasion without considering            * the other entries in this group.            *            * We hit only one random group instead of processing all            * groups in the chain.            */
name|cache_level_t
modifier|*
name|entry_level
decl_stmt|;
name|int
name|to_remove
init|=
name|rand
argument_list|()
operator|%
operator|(
name|GROUP_SIZE
operator|*
name|group
operator|->
name|header
operator|.
name|chain_length
operator|)
decl_stmt|;
name|entry_group_t
modifier|*
name|to_shrink
init|=
name|get_group
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_remove
operator|/
name|GROUP_SIZE
argument_list|)
decl_stmt|;
name|entry
operator|=
operator|&
name|to_shrink
operator|->
name|entries
index|[
name|to_remove
operator|%
name|GROUP_SIZE
index|]
expr_stmt|;
name|entry_level
operator|=
name|get_cache_level
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|GROUP_SIZE
condition|;
operator|++
name|i
control|)
block|{
comment|/* keep L1 entries whenever possible */
name|cache_level_t
modifier|*
name|level
init|=
name|get_cache_level
argument_list|(
name|cache
argument_list|,
operator|&
name|to_shrink
operator|->
name|entries
index|[
name|i
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|level
operator|!=
name|entry_level
operator|&&
name|entry_level
operator|==
operator|&
name|cache
operator|->
name|l1
operator|)
operator|||
operator|(
name|entry
operator|->
name|hit_count
operator|>
name|to_shrink
operator|->
name|entries
index|[
name|i
index|]
operator|.
name|hit_count
operator|)
condition|)
block|{
name|entry_level
operator|=
name|level
expr_stmt|;
name|entry
operator|=
operator|&
name|to_shrink
operator|->
name|entries
index|[
name|i
index|]
expr_stmt|;
block|}
block|}
comment|/* for the entries that don't have been removed,            * reduce their hit counts to put them at a relative            * disadvantage the next time.            */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|GROUP_SIZE
condition|;
operator|++
name|i
control|)
if|if
condition|(
name|entry
operator|!=
operator|&
name|to_shrink
operator|->
name|entries
index|[
name|i
index|]
condition|)
name|let_entry_age
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|drop_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
block|}
comment|/* initialize entry for the new key        */
name|entry
operator|=
operator|&
name|group
operator|->
name|entries
index|[
name|group
operator|->
name|header
operator|.
name|used
index|]
expr_stmt|;
name|entry
operator|->
name|key
operator|=
name|to_find
operator|->
name|entry_key
expr_stmt|;
block|}
return|return
name|entry
return|;
block|}
end_function

begin_comment
comment|/* Move a surviving ENTRY from just behind the insertion window to  * its beginning and move the insertion window up accordingly.  */
end_comment

begin_function
specifier|static
name|void
name|move_entry
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_t
modifier|*
name|entry
parameter_list|)
block|{
name|apr_size_t
name|size
init|=
name|ALIGN_VALUE
argument_list|(
name|entry
operator|->
name|size
argument_list|)
decl_stmt|;
name|cache_level_t
modifier|*
name|level
init|=
name|get_cache_level
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
decl_stmt|;
comment|/* This entry survived this cleansing run. Reset half of its    * hit count so that its removal gets more likely in the next    * run unless someone read / hit this entry in the meantime.    */
name|let_entry_age
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
comment|/* Move the entry to the start of the empty / insertion section    * (if it isn't there already). Size-aligned moves are legal    * since all offsets and block sizes share this same alignment.    * Size-aligned moves tend to be faster than non-aligned ones    * because no "odd" bytes at the end need to special treatment.    */
if|if
condition|(
name|entry
operator|->
name|offset
operator|!=
name|level
operator|->
name|current_data
condition|)
block|{
name|memmove
argument_list|(
name|cache
operator|->
name|data
operator|+
name|level
operator|->
name|current_data
argument_list|,
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|entry
operator|->
name|offset
operator|=
name|level
operator|->
name|current_data
expr_stmt|;
block|}
comment|/* The insertion position is now directly behind this entry.    */
name|level
operator|->
name|current_data
operator|=
name|entry
operator|->
name|offset
operator|+
name|size
expr_stmt|;
name|level
operator|->
name|next
operator|=
name|entry
operator|->
name|next
expr_stmt|;
comment|/* The current insertion position must never point outside our    * data buffer.    */
name|assert
argument_list|(
name|level
operator|->
name|current_data
operator|<=
name|level
operator|->
name|start_offset
operator|+
name|level
operator|->
name|size
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Move ENTRY in CACHE from L1 to L2.  */
end_comment

begin_function
specifier|static
name|void
name|promote_entry
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_t
modifier|*
name|entry
parameter_list|)
block|{
name|apr_uint32_t
name|idx
init|=
name|get_index
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
decl_stmt|;
name|apr_size_t
name|size
init|=
name|ALIGN_VALUE
argument_list|(
name|entry
operator|->
name|size
argument_list|)
decl_stmt|;
name|assert
argument_list|(
name|get_cache_level
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
operator|==
operator|&
name|cache
operator|->
name|l1
argument_list|)
expr_stmt|;
name|assert
argument_list|(
name|idx
operator|==
name|cache
operator|->
name|l1
operator|.
name|next
argument_list|)
expr_stmt|;
comment|/* copy item from the current location in L1 to the start of L2's    * insertion window */
name|memmove
argument_list|(
name|cache
operator|->
name|data
operator|+
name|cache
operator|->
name|l2
operator|.
name|current_data
argument_list|,
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|entry
operator|->
name|offset
operator|=
name|cache
operator|->
name|l2
operator|.
name|current_data
expr_stmt|;
comment|/* The insertion position is now directly behind this entry.    */
name|cache
operator|->
name|l2
operator|.
name|current_data
operator|+=
name|size
expr_stmt|;
comment|/* remove ENTRY from chain of L1 entries and put it into L2    */
name|unchain_entry
argument_list|(
name|cache
argument_list|,
operator|&
name|cache
operator|->
name|l1
argument_list|,
name|entry
argument_list|,
name|idx
argument_list|)
expr_stmt|;
name|chain_entry
argument_list|(
name|cache
argument_list|,
operator|&
name|cache
operator|->
name|l2
argument_list|,
name|entry
argument_list|,
name|idx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* This function implements the cache insertion / eviction strategy for L2.  *  * If necessary, enlarge the insertion window of CACHE->L2 until it is at  * least TO_FIT_IN->SIZE bytes long. TO_FIT_IN->SIZE must not exceed the  * data buffer size allocated to CACHE->L2.  IDX is the item index of  * TO_FIT_IN and is given for performance reasons.  *  * Return TRUE if enough room could be found or made.  A FALSE result  * indicates that the respective item shall not be added.  */
end_comment

begin_function
specifier|static
name|svn_boolean_t
name|ensure_data_insertable_l2
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_t
modifier|*
name|to_fit_in
parameter_list|)
block|{
name|entry_t
modifier|*
name|entry
decl_stmt|;
comment|/* accumulated size of the entries that have been removed to make    * room for the new one.    */
name|apr_size_t
name|moved_size
init|=
literal|0
decl_stmt|;
comment|/* count the number of entries that got moved.  A single large entry    * being moved is not enough to reject an insertion.    */
name|apr_size_t
name|moved_count
init|=
literal|0
decl_stmt|;
comment|/* accumulated "worth" of items dropped so far */
name|apr_uint64_t
name|drop_hits
init|=
literal|0
decl_stmt|;
comment|/* estimated "worth" of the new entry */
name|apr_uint64_t
name|drop_hits_limit
init|=
operator|(
name|to_fit_in
operator|->
name|hit_count
operator|+
literal|1
operator|)
operator|*
operator|(
name|apr_uint64_t
operator|)
name|to_fit_in
operator|->
name|priority
decl_stmt|;
comment|/* This loop will eventually terminate because every cache entry    * would get dropped eventually:    *    * - the incoming entry is small enough to fit into L2    * - every iteration either frees parts of L2 or counts the moved size    * - eventually, we either moved too many items with too much total size    *   to accept the new entry, or made enough room in L2 for the new entry    *    * Low-prio items get rejected even sooner.    */
while|while
condition|(
literal|1
condition|)
block|{
comment|/* first offset behind the insertion window        */
name|apr_uint64_t
name|end
init|=
name|cache
operator|->
name|l2
operator|.
name|next
operator|==
name|NO_INDEX
condition|?
name|cache
operator|->
name|l2
operator|.
name|start_offset
operator|+
name|cache
operator|->
name|l2
operator|.
name|size
else|:
name|get_entry
argument_list|(
name|cache
argument_list|,
name|cache
operator|->
name|l2
operator|.
name|next
argument_list|)
operator|->
name|offset
decl_stmt|;
comment|/* leave function as soon as the insertion window is large enough        */
if|if
condition|(
name|end
operator|>=
name|to_fit_in
operator|->
name|size
operator|+
name|cache
operator|->
name|l2
operator|.
name|current_data
condition|)
return|return
name|TRUE
return|;
comment|/* Don't be too eager to cache data.  If a lot of data has been moved        * around, the current item has probably a relatively low priority.        * We must also limit the effort spent here (if even in case of faulty        * heuristics).  Therefore, give up after some time.        */
if|if
condition|(
name|moved_size
operator|>
literal|4
operator|*
name|to_fit_in
operator|->
name|size
operator|&&
name|moved_count
operator|>
literal|7
condition|)
return|return
name|FALSE
return|;
comment|/* if the net worth (in weighted hits) of items removed is already        * larger than what we want to insert, reject TO_FIT_IN because it        * still does not fit in. */
if|if
condition|(
name|drop_hits
operator|>
name|drop_hits_limit
condition|)
return|return
name|FALSE
return|;
comment|/* try to enlarge the insertion window        */
if|if
condition|(
name|cache
operator|->
name|l2
operator|.
name|next
operator|==
name|NO_INDEX
condition|)
block|{
comment|/* We reached the end of the data buffer; restart at the beginning.            * Due to the randomized nature of our LFU implementation, very            * large data items may require multiple passes. Therefore, SIZE            * should be restricted to significantly less than data_size.            */
name|cache
operator|->
name|l2
operator|.
name|current_data
operator|=
name|cache
operator|->
name|l2
operator|.
name|start_offset
expr_stmt|;
name|cache
operator|->
name|l2
operator|.
name|next
operator|=
name|cache
operator|->
name|l2
operator|.
name|first
expr_stmt|;
block|}
else|else
block|{
name|svn_boolean_t
name|keep
decl_stmt|;
name|entry
operator|=
name|get_entry
argument_list|(
name|cache
argument_list|,
name|cache
operator|->
name|l2
operator|.
name|next
argument_list|)
expr_stmt|;
if|if
condition|(
name|to_fit_in
operator|->
name|priority
operator|<
name|SVN_CACHE__MEMBUFFER_DEFAULT_PRIORITY
condition|)
block|{
comment|/* Low prio items can only be accepted only if the current                * entry is of even lower prio and has fewer hits.                */
if|if
condition|(
name|entry
operator|->
name|priority
operator|>
name|to_fit_in
operator|->
name|priority
operator|||
name|entry
operator|->
name|hit_count
operator|>
name|to_fit_in
operator|->
name|hit_count
condition|)
return|return
name|FALSE
return|;
block|}
if|if
condition|(
name|entry
operator|->
name|priority
operator|<=
name|SVN_CACHE__MEMBUFFER_LOW_PRIORITY
condition|)
block|{
comment|/* Be quick to remove low-prio entries - even if the incoming                * one is low-prio as well.  This makes room for more important                * data and replaces existing data with newly read information.                */
name|keep
operator|=
name|FALSE
expr_stmt|;
block|}
else|else
block|{
comment|/* If the existing data is the same prio as the incoming data,                * drop the existing entry if it had seen fewer (probably 0)                * hits than the entry coming in from L1.  In case of different                * priorities, keep the current entry of it has higher prio.                * The new entry may still find room by ousting other entries.                */
name|keep
operator|=
name|to_fit_in
operator|->
name|priority
operator|==
name|entry
operator|->
name|priority
condition|?
name|entry
operator|->
name|hit_count
operator|>=
name|to_fit_in
operator|->
name|hit_count
else|:
name|entry
operator|->
name|priority
operator|>
name|to_fit_in
operator|->
name|priority
expr_stmt|;
block|}
comment|/* keepers or destroyers? */
if|if
condition|(
name|keep
condition|)
block|{
comment|/* Moving entries around is not for free -> track costs. */
name|moved_size
operator|+=
name|entry
operator|->
name|size
expr_stmt|;
name|moved_count
operator|++
expr_stmt|;
name|move_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Drop the entry from the end of the insertion window.                * Count the "hit importance" such that we are not sacrificing                * too much of the high-hit contents.  However, don't count                * low-priority hits because higher prio entries will often                * provide the same data but in a further stage of processing.                */
if|if
condition|(
name|entry
operator|->
name|priority
operator|>
name|SVN_CACHE__MEMBUFFER_LOW_PRIORITY
condition|)
name|drop_hits
operator|+=
name|entry
operator|->
name|hit_count
operator|*
operator|(
name|apr_uint64_t
operator|)
name|entry
operator|->
name|priority
expr_stmt|;
name|drop_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/* This will never be reached. But if it was, "can't insert" was the    * right answer. */
block|}
end_function

begin_comment
comment|/* This function implements the cache insertion / eviction strategy for L1.  *  * If necessary, enlarge the insertion window of CACHE->L1 by promoting  * entries to L2 until it is at least SIZE bytes long.  *  * Return TRUE if enough room could be found or made.  A FALSE result  * indicates that the respective item shall not be added because it is  * too large.  */
end_comment

begin_function
specifier|static
name|svn_boolean_t
name|ensure_data_insertable_l1
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_size_t
name|size
parameter_list|)
block|{
comment|/* Guarantees that the while loop will terminate. */
if|if
condition|(
name|size
operator|>
name|cache
operator|->
name|l1
operator|.
name|size
condition|)
return|return
name|FALSE
return|;
comment|/* This loop will eventually terminate because every cache entry    * would get dropped eventually.    */
while|while
condition|(
literal|1
condition|)
block|{
comment|/* first offset behind the insertion window        */
name|apr_uint32_t
name|entry_index
init|=
name|cache
operator|->
name|l1
operator|.
name|next
decl_stmt|;
name|entry_t
modifier|*
name|entry
init|=
name|get_entry
argument_list|(
name|cache
argument_list|,
name|entry_index
argument_list|)
decl_stmt|;
name|apr_uint64_t
name|end
init|=
name|cache
operator|->
name|l1
operator|.
name|next
operator|==
name|NO_INDEX
condition|?
name|cache
operator|->
name|l1
operator|.
name|start_offset
operator|+
name|cache
operator|->
name|l1
operator|.
name|size
else|:
name|entry
operator|->
name|offset
decl_stmt|;
comment|/* leave function as soon as the insertion window is large enough        */
if|if
condition|(
name|end
operator|>=
name|size
operator|+
name|cache
operator|->
name|l1
operator|.
name|current_data
condition|)
return|return
name|TRUE
return|;
comment|/* Enlarge the insertion window        */
if|if
condition|(
name|cache
operator|->
name|l1
operator|.
name|next
operator|==
name|NO_INDEX
condition|)
block|{
comment|/* We reached the end of the data buffer; restart at the beginning.            * Due to the randomized nature of our LFU implementation, very            * large data items may require multiple passes. Therefore, SIZE            * should be restricted to significantly less than data_size.            */
name|cache
operator|->
name|l1
operator|.
name|current_data
operator|=
name|cache
operator|->
name|l1
operator|.
name|start_offset
expr_stmt|;
name|cache
operator|->
name|l1
operator|.
name|next
operator|=
name|cache
operator|->
name|l1
operator|.
name|first
expr_stmt|;
block|}
else|else
block|{
comment|/* Remove the entry from the end of insertion window and promote            * it to L2, if it is important enough.            */
name|svn_boolean_t
name|keep
init|=
name|ensure_data_insertable_l2
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
decl_stmt|;
comment|/* We might have touched the group that contains ENTRY. Recheck. */
if|if
condition|(
name|entry_index
operator|==
name|cache
operator|->
name|l1
operator|.
name|next
condition|)
block|{
if|if
condition|(
name|keep
condition|)
name|promote_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
else|else
name|drop_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/* This will never be reached. But if it was, "can't insert" was the    * right answer. */
block|}
end_function

begin_function
name|svn_error_t
modifier|*
name|svn_cache__membuffer_cache_create
parameter_list|(
name|svn_membuffer_t
modifier|*
modifier|*
name|cache
parameter_list|,
name|apr_size_t
name|total_size
parameter_list|,
name|apr_size_t
name|directory_size
parameter_list|,
name|apr_size_t
name|segment_count
parameter_list|,
name|svn_boolean_t
name|thread_safe
parameter_list|,
name|svn_boolean_t
name|allow_blocking_writes
parameter_list|,
name|apr_pool_t
modifier|*
name|pool
parameter_list|)
block|{
name|svn_membuffer_t
modifier|*
name|c
decl_stmt|;
name|apr_uint32_t
name|seg
decl_stmt|;
name|apr_uint32_t
name|group_count
decl_stmt|;
name|apr_uint32_t
name|main_group_count
decl_stmt|;
name|apr_uint32_t
name|spare_group_count
decl_stmt|;
name|apr_uint32_t
name|group_init_size
decl_stmt|;
name|apr_uint64_t
name|data_size
decl_stmt|;
name|apr_uint64_t
name|max_entry_size
decl_stmt|;
comment|/* Limit the total size (only relevant if we can address> 4GB)    */
if|#
directive|if
name|APR_SIZEOF_VOIDP
operator|>
literal|4
if|if
condition|(
name|total_size
operator|>
name|MAX_SEGMENT_SIZE
operator|*
name|MAX_SEGMENT_COUNT
condition|)
name|total_size
operator|=
name|MAX_SEGMENT_SIZE
operator|*
name|MAX_SEGMENT_COUNT
expr_stmt|;
endif|#
directive|endif
comment|/* Limit the segment count    */
if|if
condition|(
name|segment_count
operator|>
name|MAX_SEGMENT_COUNT
condition|)
name|segment_count
operator|=
name|MAX_SEGMENT_COUNT
expr_stmt|;
if|if
condition|(
name|segment_count
operator|*
name|MIN_SEGMENT_SIZE
operator|>
name|total_size
condition|)
name|segment_count
operator|=
name|total_size
operator|/
name|MIN_SEGMENT_SIZE
expr_stmt|;
comment|/* The segment count must be a power of two. Round it down as necessary.    */
while|while
condition|(
operator|(
name|segment_count
operator|&
operator|(
name|segment_count
operator|-
literal|1
operator|)
operator|)
operator|!=
literal|0
condition|)
name|segment_count
operator|&=
name|segment_count
operator|-
literal|1
expr_stmt|;
comment|/* if the caller hasn't provided a reasonable segment count or the above    * limitations set it to 0, derive one from the absolute cache size    */
if|if
condition|(
name|segment_count
operator|<
literal|1
condition|)
block|{
comment|/* Determine a reasonable number of cache segments. Segmentation is        * only useful for multi-threaded / multi-core servers as it reduces        * lock contention on these systems.        *        * But on these systems, we can assume that ample memory has been        * allocated to this cache. Smaller caches should not be segmented        * as this severely limits the maximum size of cachable items.        *        * Segments should not be smaller than 32MB and max. cachable item        * size should grow as fast as segmentation.        */
name|apr_uint32_t
name|segment_count_shift
init|=
literal|0
decl_stmt|;
while|while
condition|(
operator|(
operator|(
literal|2
operator|*
name|DEFAULT_MIN_SEGMENT_SIZE
operator|)
operator|<<
operator|(
literal|2
operator|*
name|segment_count_shift
operator|)
operator|)
operator|<
name|total_size
condition|)
operator|++
name|segment_count_shift
expr_stmt|;
name|segment_count
operator|=
operator|(
name|apr_size_t
operator|)
literal|1
operator|<<
name|segment_count_shift
expr_stmt|;
block|}
comment|/* If we have an extremely large cache (>512 GB), the default segment    * size may exceed the amount allocatable as one chunk. In that case,    * increase segmentation until we are under the threshold.    */
while|while
condition|(
name|total_size
operator|/
name|segment_count
operator|>
name|MAX_SEGMENT_SIZE
operator|&&
name|segment_count
operator|<
name|MAX_SEGMENT_COUNT
condition|)
name|segment_count
operator|*=
literal|2
expr_stmt|;
comment|/* allocate cache as an array of segments / cache objects */
name|c
operator|=
name|apr_palloc
argument_list|(
name|pool
argument_list|,
name|segment_count
operator|*
sizeof|sizeof
argument_list|(
operator|*
name|c
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Split total cache size into segments of equal size    */
name|total_size
operator|/=
name|segment_count
expr_stmt|;
name|directory_size
operator|/=
name|segment_count
expr_stmt|;
comment|/* prevent pathological conditions: ensure a certain minimum cache size    */
if|if
condition|(
name|total_size
operator|<
literal|2
operator|*
sizeof|sizeof
argument_list|(
name|entry_group_t
argument_list|)
condition|)
name|total_size
operator|=
literal|2
operator|*
sizeof|sizeof
argument_list|(
name|entry_group_t
argument_list|)
expr_stmt|;
comment|/* adapt the dictionary size accordingly, if necessary:    * It must hold at least one group and must not exceed the cache size.    */
if|if
condition|(
name|directory_size
operator|>
name|total_size
operator|-
sizeof|sizeof
argument_list|(
name|entry_group_t
argument_list|)
condition|)
name|directory_size
operator|=
name|total_size
operator|-
sizeof|sizeof
argument_list|(
name|entry_group_t
argument_list|)
expr_stmt|;
if|if
condition|(
name|directory_size
operator|<
literal|2
operator|*
sizeof|sizeof
argument_list|(
name|entry_group_t
argument_list|)
condition|)
name|directory_size
operator|=
literal|2
operator|*
sizeof|sizeof
argument_list|(
name|entry_group_t
argument_list|)
expr_stmt|;
comment|/* limit the data size to what we can address.    * Note that this cannot overflow since all values are of size_t.    * Also, make it a multiple of the item placement granularity to    * prevent subtle overflows.    */
name|data_size
operator|=
name|ALIGN_VALUE
argument_list|(
name|total_size
operator|-
name|directory_size
operator|+
literal|1
argument_list|)
operator|-
name|ITEM_ALIGNMENT
expr_stmt|;
comment|/* For cache sizes> 16TB, individual cache segments will be larger    * than 32GB allowing for>4GB entries.  But caching chunks larger    * than 4GB are simply not supported.    */
name|max_entry_size
operator|=
name|data_size
operator|/
literal|8
operator|>
name|MAX_ITEM_SIZE
condition|?
name|MAX_ITEM_SIZE
else|:
name|data_size
operator|/
literal|8
expr_stmt|;
comment|/* to keep the entries small, we use 32 bit indexes only    * -> we need to ensure that no more then 4G entries exist.    *    * Note, that this limit could only be exceeded in a very    * theoretical setup with about 1EB of cache.    */
name|group_count
operator|=
name|directory_size
operator|/
sizeof|sizeof
argument_list|(
name|entry_group_t
argument_list|)
operator|>=
operator|(
name|APR_UINT32_MAX
operator|/
name|GROUP_SIZE
operator|)
condition|?
operator|(
name|APR_UINT32_MAX
operator|/
name|GROUP_SIZE
operator|)
operator|-
literal|1
else|:
call|(
name|apr_uint32_t
call|)
argument_list|(
name|directory_size
operator|/
sizeof|sizeof
argument_list|(
name|entry_group_t
argument_list|)
argument_list|)
expr_stmt|;
comment|/* set some of the index directory aside as over-flow (spare) buffers */
name|spare_group_count
operator|=
name|MAX
argument_list|(
name|group_count
operator|/
literal|4
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|main_group_count
operator|=
name|group_count
operator|-
name|spare_group_count
expr_stmt|;
name|assert
argument_list|(
name|spare_group_count
operator|>
literal|0
operator|&&
name|main_group_count
operator|>
literal|0
argument_list|)
expr_stmt|;
name|group_init_size
operator|=
literal|1
operator|+
name|group_count
operator|/
operator|(
literal|8
operator|*
name|GROUP_INIT_GRANULARITY
operator|)
expr_stmt|;
for|for
control|(
name|seg
operator|=
literal|0
init|;
name|seg
operator|<
name|segment_count
condition|;
operator|++
name|seg
control|)
block|{
comment|/* allocate buffers and initialize cache members        */
name|c
index|[
name|seg
index|]
operator|.
name|segment_count
operator|=
operator|(
name|apr_uint32_t
operator|)
name|segment_count
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|group_count
operator|=
name|main_group_count
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|spare_group_count
operator|=
name|spare_group_count
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|first_spare_group
operator|=
name|NO_INDEX
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|max_spare_used
operator|=
literal|0
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|directory
operator|=
name|apr_pcalloc
argument_list|(
name|pool
argument_list|,
name|group_count
operator|*
sizeof|sizeof
argument_list|(
name|entry_group_t
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Allocate and initialize directory entries as "not initialized",          hence "unused" */
name|c
index|[
name|seg
index|]
operator|.
name|group_initialized
operator|=
name|apr_pcalloc
argument_list|(
name|pool
argument_list|,
name|group_init_size
argument_list|)
expr_stmt|;
comment|/* Allocate 1/4th of the data buffer to L1        */
name|c
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|first
operator|=
name|NO_INDEX
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|last
operator|=
name|NO_INDEX
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|next
operator|=
name|NO_INDEX
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|start_offset
operator|=
literal|0
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|size
operator|=
name|ALIGN_VALUE
argument_list|(
name|data_size
operator|/
literal|4
argument_list|)
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|current_data
operator|=
literal|0
expr_stmt|;
comment|/* The remaining 3/4th will be used as L2        */
name|c
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|first
operator|=
name|NO_INDEX
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|last
operator|=
name|NO_INDEX
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|next
operator|=
name|NO_INDEX
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|start_offset
operator|=
name|c
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|size
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|size
operator|=
name|ALIGN_VALUE
argument_list|(
name|data_size
argument_list|)
operator|-
name|c
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|size
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|current_data
operator|=
name|c
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|start_offset
expr_stmt|;
comment|/* This cast is safe because DATA_SIZE<= MAX_SEGMENT_SIZE. */
name|c
index|[
name|seg
index|]
operator|.
name|data
operator|=
name|apr_palloc
argument_list|(
name|pool
argument_list|,
operator|(
name|apr_size_t
operator|)
name|ALIGN_VALUE
argument_list|(
name|data_size
argument_list|)
argument_list|)
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|data_used
operator|=
literal|0
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|max_entry_size
operator|=
name|max_entry_size
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|used_entries
operator|=
literal|0
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|total_reads
operator|=
literal|0
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|total_writes
operator|=
literal|0
expr_stmt|;
name|c
index|[
name|seg
index|]
operator|.
name|total_hits
operator|=
literal|0
expr_stmt|;
comment|/* were allocations successful?        * If not, initialize a minimal cache structure.        */
if|if
condition|(
name|c
index|[
name|seg
index|]
operator|.
name|data
operator|==
name|NULL
operator|||
name|c
index|[
name|seg
index|]
operator|.
name|directory
operator|==
name|NULL
condition|)
block|{
comment|/* We are OOM. There is no need to proceed with "half a cache".            */
return|return
name|svn_error_wrap_apr
argument_list|(
name|APR_ENOMEM
argument_list|,
literal|"OOM"
argument_list|)
return|;
block|}
if|#
directive|if
operator|(
name|APR_HAS_THREADS
operator|&&
name|USE_SIMPLE_MUTEX
operator|)
comment|/* A lock for intra-process synchronization to the cache, or NULL if        * the cache's creator doesn't feel the cache needs to be        * thread-safe.        */
name|SVN_ERR
argument_list|(
name|svn_mutex__init
argument_list|(
operator|&
name|c
index|[
name|seg
index|]
operator|.
name|lock
argument_list|,
name|thread_safe
argument_list|,
name|pool
argument_list|)
argument_list|)
expr_stmt|;
elif|#
directive|elif
operator|(
name|APR_HAS_THREADS
operator|&&
operator|!
name|USE_SIMPLE_MUTEX
operator|)
comment|/* Same for read-write lock. */
name|c
index|[
name|seg
index|]
operator|.
name|lock
operator|=
name|NULL
expr_stmt|;
if|if
condition|(
name|thread_safe
condition|)
block|{
name|apr_status_t
name|status
init|=
name|apr_thread_rwlock_create
argument_list|(
operator|&
operator|(
name|c
index|[
name|seg
index|]
operator|.
name|lock
operator|)
argument_list|,
name|pool
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
condition|)
return|return
name|svn_error_wrap_apr
argument_list|(
name|status
argument_list|,
name|_
argument_list|(
literal|"Can't create cache mutex"
argument_list|)
argument_list|)
return|;
block|}
comment|/* Select the behavior of write operations.        */
name|c
index|[
name|seg
index|]
operator|.
name|allow_blocking_writes
operator|=
name|allow_blocking_writes
expr_stmt|;
endif|#
directive|endif
block|}
comment|/* done here    */
operator|*
name|cache
operator|=
name|c
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_function
name|svn_error_t
modifier|*
name|svn_cache__membuffer_clear
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|)
block|{
name|apr_size_t
name|seg
decl_stmt|;
name|apr_size_t
name|segment_count
init|=
name|cache
operator|->
name|segment_count
decl_stmt|;
comment|/* Length of the group_initialized array in bytes.      See also svn_cache__membuffer_cache_create(). */
name|apr_size_t
name|group_init_size
init|=
literal|1
operator|+
operator|(
name|cache
operator|->
name|group_count
operator|+
name|cache
operator|->
name|spare_group_count
operator|)
operator|/
operator|(
literal|8
operator|*
name|GROUP_INIT_GRANULARITY
operator|)
decl_stmt|;
comment|/* Clear segment by segment.  This implies that other thread may read      and write to other segments after we cleared them and before the      last segment is done.       However, that is no different from a write request coming through      right after we cleared all segments because dependencies between      cache entries (recursive lookup / access locks) are not allowed.    */
for|for
control|(
name|seg
operator|=
literal|0
init|;
name|seg
operator|<
name|segment_count
condition|;
operator|++
name|seg
control|)
block|{
comment|/* Unconditionally acquire the write lock. */
name|SVN_ERR
argument_list|(
name|force_write_lock_cache
argument_list|(
operator|&
name|cache
index|[
name|seg
index|]
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Mark all groups as "not initialized", which implies "empty". */
name|cache
index|[
name|seg
index|]
operator|.
name|first_spare_group
operator|=
name|NO_INDEX
expr_stmt|;
name|cache
index|[
name|seg
index|]
operator|.
name|max_spare_used
operator|=
literal|0
expr_stmt|;
name|memset
argument_list|(
name|cache
index|[
name|seg
index|]
operator|.
name|group_initialized
argument_list|,
literal|0
argument_list|,
name|group_init_size
argument_list|)
expr_stmt|;
comment|/* Unlink L1 contents. */
name|cache
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|first
operator|=
name|NO_INDEX
expr_stmt|;
name|cache
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|last
operator|=
name|NO_INDEX
expr_stmt|;
name|cache
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|next
operator|=
name|NO_INDEX
expr_stmt|;
name|cache
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|current_data
operator|=
name|cache
index|[
name|seg
index|]
operator|.
name|l1
operator|.
name|start_offset
expr_stmt|;
comment|/* Unlink L2 contents. */
name|cache
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|first
operator|=
name|NO_INDEX
expr_stmt|;
name|cache
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|last
operator|=
name|NO_INDEX
expr_stmt|;
name|cache
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|next
operator|=
name|NO_INDEX
expr_stmt|;
name|cache
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|current_data
operator|=
name|cache
index|[
name|seg
index|]
operator|.
name|l2
operator|.
name|start_offset
expr_stmt|;
comment|/* Reset content counters. */
name|cache
index|[
name|seg
index|]
operator|.
name|data_used
operator|=
literal|0
expr_stmt|;
name|cache
index|[
name|seg
index|]
operator|.
name|used_entries
operator|=
literal|0
expr_stmt|;
comment|/* Segment may be used again. */
name|SVN_ERR
argument_list|(
name|unlock_cache
argument_list|(
operator|&
name|cache
index|[
name|seg
index|]
argument_list|,
name|SVN_NO_ERROR
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* done here */
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Look for the cache entry in group GROUP_INDEX of CACHE, identified  * by the hash value TO_FIND and set *FOUND accordingly.  *  * Note: This function requires the caller to serialize access.  * Don't call it directly, call entry_exists instead.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|entry_exists_internal
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|group_index
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|to_find
parameter_list|,
name|svn_boolean_t
modifier|*
name|found
parameter_list|)
block|{
operator|*
name|found
operator|=
name|find_entry
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_find
argument_list|,
name|FALSE
argument_list|)
operator|!=
name|NULL
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Look for the cache entry in group GROUP_INDEX of CACHE, identified  * by the hash value TO_FIND and set *FOUND accordingly.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|entry_exists
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|group_index
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|to_find
parameter_list|,
name|svn_boolean_t
modifier|*
name|found
parameter_list|)
block|{
name|WITH_READ_LOCK
argument_list|(
name|cache
argument_list|,
name|entry_exists_internal
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_find
argument_list|,
name|found
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Given the SIZE and PRIORITY of a new item, return the cache level    (L1 or L2) in fragment CACHE that this item shall be inserted into.    If we can't find nor make enough room for the item, return NULL.  */
end_comment

begin_function
specifier|static
name|cache_level_t
modifier|*
name|select_level
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_size_t
name|size
parameter_list|,
name|apr_uint32_t
name|priority
parameter_list|)
block|{
if|if
condition|(
name|cache
operator|->
name|max_entry_size
operator|>=
name|size
condition|)
block|{
comment|/* Small items go into L1. */
return|return
name|ensure_data_insertable_l1
argument_list|(
name|cache
argument_list|,
name|size
argument_list|)
condition|?
operator|&
name|cache
operator|->
name|l1
else|:
name|NULL
return|;
block|}
elseif|else
if|if
condition|(
name|cache
operator|->
name|l2
operator|.
name|size
operator|>=
name|size
operator|&&
name|MAX_ITEM_SIZE
operator|>=
name|size
operator|&&
name|priority
operator|>
name|SVN_CACHE__MEMBUFFER_DEFAULT_PRIORITY
condition|)
block|{
comment|/* Large but important items go into L2. */
name|entry_t
name|dummy_entry
init|=
block|{
block|{
block|{
literal|0
block|}
block|}
block|}
decl_stmt|;
name|dummy_entry
operator|.
name|priority
operator|=
name|priority
expr_stmt|;
name|dummy_entry
operator|.
name|size
operator|=
name|size
expr_stmt|;
return|return
name|ensure_data_insertable_l2
argument_list|(
name|cache
argument_list|,
operator|&
name|dummy_entry
argument_list|)
condition|?
operator|&
name|cache
operator|->
name|l2
else|:
name|NULL
return|;
block|}
comment|/* Don't cache large, unimportant items. */
return|return
name|NULL
return|;
block|}
end_function

begin_comment
comment|/* Try to insert the serialized item given in BUFFER with ITEM_SIZE  * into the group GROUP_INDEX of CACHE and uniquely identify it by  * hash value TO_FIND.  *  * However, there is no guarantee that it will actually be put into  * the cache. If there is already some data associated with TO_FIND,  * it will be removed from the cache even if the new data cannot  * be inserted.  *  * Note: This function requires the caller to serialization access.  * Don't call it directly, call membuffer_cache_set instead.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|membuffer_cache_set_internal
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|to_find
parameter_list|,
name|apr_uint32_t
name|group_index
parameter_list|,
name|char
modifier|*
name|buffer
parameter_list|,
name|apr_size_t
name|item_size
parameter_list|,
name|apr_uint32_t
name|priority
parameter_list|,
name|DEBUG_CACHE_MEMBUFFER_TAG_ARG
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
name|cache_level_t
modifier|*
name|level
decl_stmt|;
name|apr_size_t
name|size
init|=
name|item_size
operator|+
name|to_find
operator|->
name|entry_key
operator|.
name|key_len
decl_stmt|;
comment|/* first, look for a previous entry for the given key */
name|entry_t
modifier|*
name|entry
init|=
name|find_entry
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_find
argument_list|,
name|FALSE
argument_list|)
decl_stmt|;
comment|/* if there is an old version of that entry and the new data fits into    * the old spot, just re-use that space. */
if|if
condition|(
name|entry
operator|&&
name|ALIGN_VALUE
argument_list|(
name|entry
operator|->
name|size
argument_list|)
operator|>=
name|size
operator|&&
name|buffer
condition|)
block|{
comment|/* Careful! We need to cast SIZE to the full width of CACHE->DATA_USED        * lest we run into trouble with 32 bit underflow *not* treated as a        * negative value.        */
name|cache
operator|->
name|data_used
operator|+=
operator|(
name|apr_uint64_t
operator|)
name|size
operator|-
name|entry
operator|->
name|size
expr_stmt|;
name|entry
operator|->
name|size
operator|=
name|size
expr_stmt|;
name|entry
operator|->
name|priority
operator|=
name|priority
expr_stmt|;
ifdef|#
directive|ifdef
name|SVN_DEBUG_CACHE_MEMBUFFER
comment|/* Remember original content, type and key (hashes)        */
name|SVN_ERR
argument_list|(
name|store_content_part
argument_list|(
name|tag
argument_list|,
name|buffer
argument_list|,
name|item_size
argument_list|,
name|scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
operator|&
name|entry
operator|->
name|tag
argument_list|,
name|tag
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|tag
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|entry
operator|->
name|key
operator|.
name|key_len
condition|)
name|memcpy
argument_list|(
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
argument_list|,
name|to_find
operator|->
name|full_key
operator|.
name|data
argument_list|,
name|entry
operator|->
name|key
operator|.
name|key_len
argument_list|)
expr_stmt|;
if|if
condition|(
name|item_size
condition|)
name|memcpy
argument_list|(
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
operator|+
name|entry
operator|->
name|key
operator|.
name|key_len
argument_list|,
name|buffer
argument_list|,
name|item_size
argument_list|)
expr_stmt|;
name|cache
operator|->
name|total_writes
operator|++
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
comment|/* if necessary, enlarge the insertion window.    */
name|level
operator|=
name|buffer
condition|?
name|select_level
argument_list|(
name|cache
argument_list|,
name|size
argument_list|,
name|priority
argument_list|)
else|:
name|NULL
expr_stmt|;
if|if
condition|(
name|level
condition|)
block|{
comment|/* Remove old data for this key, if that exists.        * Get an unused entry for the key and and initialize it with        * the serialized item's (future) position within data buffer.        */
name|entry
operator|=
name|find_entry
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_find
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
name|entry
operator|->
name|size
operator|=
name|size
expr_stmt|;
name|entry
operator|->
name|offset
operator|=
name|level
operator|->
name|current_data
expr_stmt|;
name|entry
operator|->
name|priority
operator|=
name|priority
expr_stmt|;
ifdef|#
directive|ifdef
name|SVN_DEBUG_CACHE_MEMBUFFER
comment|/* Remember original content, type and key (hashes)        */
name|SVN_ERR
argument_list|(
name|store_content_part
argument_list|(
name|tag
argument_list|,
name|buffer
argument_list|,
name|item_size
argument_list|,
name|scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
operator|&
name|entry
operator|->
name|tag
argument_list|,
name|tag
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|tag
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* Link the entry properly.        */
name|insert_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
comment|/* Copy the serialized item data into the cache.        */
if|if
condition|(
name|entry
operator|->
name|key
operator|.
name|key_len
condition|)
name|memcpy
argument_list|(
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
argument_list|,
name|to_find
operator|->
name|full_key
operator|.
name|data
argument_list|,
name|entry
operator|->
name|key
operator|.
name|key_len
argument_list|)
expr_stmt|;
if|if
condition|(
name|item_size
condition|)
name|memcpy
argument_list|(
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
operator|+
name|entry
operator|->
name|key
operator|.
name|key_len
argument_list|,
name|buffer
argument_list|,
name|item_size
argument_list|)
expr_stmt|;
name|cache
operator|->
name|total_writes
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|/* if there is already an entry for this key, drop it.        * Since ensure_data_insertable may have removed entries from        * ENTRY's group, re-do the lookup.        */
name|entry
operator|=
name|find_entry
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_find
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
if|if
condition|(
name|entry
condition|)
name|drop_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
block|}
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Try to insert the ITEM and use the KEY to uniquely identify it.  * However, there is no guarantee that it will actually be put into  * the cache. If there is already some data associated to the KEY,  * it will be removed from the cache even if the new data cannot  * be inserted.  *  * The SERIALIZER is called to transform the ITEM into a single,  * flat data buffer. Temporary allocations may be done in POOL.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|membuffer_cache_set
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|key
parameter_list|,
name|void
modifier|*
name|item
parameter_list|,
name|svn_cache__serialize_func_t
name|serializer
parameter_list|,
name|apr_uint32_t
name|priority
parameter_list|,
name|DEBUG_CACHE_MEMBUFFER_TAG_ARG
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
name|apr_uint32_t
name|group_index
decl_stmt|;
name|void
modifier|*
name|buffer
init|=
name|NULL
decl_stmt|;
name|apr_size_t
name|size
init|=
literal|0
decl_stmt|;
comment|/* find the entry group that will hold the key.    */
name|group_index
operator|=
name|get_group_index
argument_list|(
operator|&
name|cache
argument_list|,
operator|&
name|key
operator|->
name|entry_key
argument_list|)
expr_stmt|;
comment|/* Serialize data data.    */
if|if
condition|(
name|item
condition|)
name|SVN_ERR
argument_list|(
name|serializer
argument_list|(
operator|&
name|buffer
argument_list|,
operator|&
name|size
argument_list|,
name|item
argument_list|,
name|scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
comment|/* The actual cache data access needs to sync'ed    */
name|WITH_WRITE_LOCK
argument_list|(
name|cache
argument_list|,
name|membuffer_cache_set_internal
argument_list|(
argument|cache
argument_list|,
argument|key
argument_list|,
argument|group_index
argument_list|,
argument|buffer
argument_list|,
argument|size
argument_list|,
argument|priority
argument_list|,
argument|DEBUG_CACHE_MEMBUFFER_TAG                                                scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Count a hit in ENTRY within CACHE.  */
end_comment

begin_function
specifier|static
name|void
name|increment_hit_counters
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|entry_t
modifier|*
name|entry
parameter_list|)
block|{
comment|/* To minimize the memory footprint of the cache index, we limit local    * hit counters to 32 bits.  These may overflow but we don't really    * care because at worst, ENTRY will be dropped from cache once every    * few billion hits. */
name|svn_atomic_inc
argument_list|(
operator|&
name|entry
operator|->
name|hit_count
argument_list|)
expr_stmt|;
comment|/* That one is for stats only. */
name|cache
operator|->
name|total_hits
operator|++
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Look for the cache entry in group GROUP_INDEX of CACHE, identified  * by the hash value TO_FIND. If no item has been stored for KEY,  * *BUFFER will be NULL. Otherwise, return a copy of the serialized  * data in *BUFFER and return its size in *ITEM_SIZE. Allocations will  * be done in POOL.  *  * Note: This function requires the caller to serialization access.  * Don't call it directly, call membuffer_cache_get instead.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|membuffer_cache_get_internal
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|group_index
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|to_find
parameter_list|,
name|char
modifier|*
modifier|*
name|buffer
parameter_list|,
name|apr_size_t
modifier|*
name|item_size
parameter_list|,
name|DEBUG_CACHE_MEMBUFFER_TAG_ARG
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|entry_t
modifier|*
name|entry
decl_stmt|;
name|apr_size_t
name|size
decl_stmt|;
comment|/* The actual cache data access needs to sync'ed    */
name|entry
operator|=
name|find_entry
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_find
argument_list|,
name|FALSE
argument_list|)
expr_stmt|;
name|cache
operator|->
name|total_reads
operator|++
expr_stmt|;
if|if
condition|(
name|entry
operator|==
name|NULL
condition|)
block|{
comment|/* no such entry found.        */
operator|*
name|buffer
operator|=
name|NULL
expr_stmt|;
operator|*
name|item_size
operator|=
literal|0
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
name|size
operator|=
name|ALIGN_VALUE
argument_list|(
name|entry
operator|->
name|size
argument_list|)
operator|-
name|entry
operator|->
name|key
operator|.
name|key_len
expr_stmt|;
operator|*
name|buffer
operator|=
name|apr_palloc
argument_list|(
name|result_pool
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
operator|*
name|buffer
argument_list|,
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
operator|+
name|entry
operator|->
name|key
operator|.
name|key_len
argument_list|,
name|size
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SVN_DEBUG_CACHE_MEMBUFFER
comment|/* Check for overlapping entries.    */
name|SVN_ERR_ASSERT
argument_list|(
name|entry
operator|->
name|next
operator|==
name|NO_INDEX
operator|||
name|entry
operator|->
name|offset
operator|+
name|size
operator|<=
name|get_entry
argument_list|(
name|cache
argument_list|,
name|entry
operator|->
name|next
argument_list|)
operator|->
name|offset
argument_list|)
expr_stmt|;
comment|/* Compare original content, type and key (hashes)    */
name|SVN_ERR
argument_list|(
name|store_content_part
argument_list|(
name|tag
argument_list|,
operator|*
name|buffer
argument_list|,
name|entry
operator|->
name|size
operator|-
name|entry
operator|->
name|key
operator|.
name|key_len
argument_list|,
name|result_pool
argument_list|)
argument_list|)
expr_stmt|;
name|SVN_ERR
argument_list|(
name|assert_equal_tags
argument_list|(
operator|&
name|entry
operator|->
name|tag
argument_list|,
name|tag
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* update hit statistics    */
name|increment_hit_counters
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
operator|*
name|item_size
operator|=
name|entry
operator|->
name|size
operator|-
name|entry
operator|->
name|key
operator|.
name|key_len
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Look for the *ITEM identified by KEY. If no item has been stored  * for KEY, *ITEM will be NULL. Otherwise, the DESERIALIZER is called  * re-construct the proper object from the serialized data.  * Allocations will be done in POOL.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|membuffer_cache_get
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|key
parameter_list|,
name|void
modifier|*
modifier|*
name|item
parameter_list|,
name|svn_cache__deserialize_func_t
name|deserializer
parameter_list|,
name|DEBUG_CACHE_MEMBUFFER_TAG_ARG
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|apr_uint32_t
name|group_index
decl_stmt|;
name|char
modifier|*
name|buffer
decl_stmt|;
name|apr_size_t
name|size
decl_stmt|;
comment|/* find the entry group that will hold the key.    */
name|group_index
operator|=
name|get_group_index
argument_list|(
operator|&
name|cache
argument_list|,
operator|&
name|key
operator|->
name|entry_key
argument_list|)
expr_stmt|;
name|WITH_READ_LOCK
argument_list|(
name|cache
argument_list|,
name|membuffer_cache_get_internal
argument_list|(
argument|cache
argument_list|,
argument|group_index
argument_list|,
argument|key
argument_list|,
argument|&buffer
argument_list|,
argument|&size
argument_list|,
argument|DEBUG_CACHE_MEMBUFFER_TAG                                               result_pool
argument_list|)
argument_list|)
expr_stmt|;
comment|/* re-construct the original data object from its serialized form.    */
if|if
condition|(
name|buffer
operator|==
name|NULL
condition|)
block|{
operator|*
name|item
operator|=
name|NULL
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
return|return
name|deserializer
argument_list|(
name|item
argument_list|,
name|buffer
argument_list|,
name|size
argument_list|,
name|result_pool
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/* Look for the cache entry in group GROUP_INDEX of CACHE, identified  * by the hash value TO_FIND.  If no item has been stored for KEY, *FOUND  * will be FALSE and TRUE otherwise.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|membuffer_cache_has_key_internal
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|group_index
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|to_find
parameter_list|,
name|svn_boolean_t
modifier|*
name|found
parameter_list|)
block|{
name|entry_t
modifier|*
name|entry
init|=
name|find_entry
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_find
argument_list|,
name|FALSE
argument_list|)
decl_stmt|;
if|if
condition|(
name|entry
condition|)
block|{
comment|/* This often be called by "block read" when most data is already          in L2 and only a few previously evicted items are added to L1          again.  While items in L1 are well protected for a while, L2          items may get evicted soon.  Thus, mark all them as "hit" to give          them a higher chance of survival. */
name|increment_hit_counters
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
operator|*
name|found
operator|=
name|TRUE
expr_stmt|;
block|}
else|else
block|{
operator|*
name|found
operator|=
name|FALSE
expr_stmt|;
block|}
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Look for an entry identified by KEY.  If no item has been stored  * for KEY, *FOUND will be set to FALSE and TRUE otherwise.  */
end_comment

begin_comment
comment|/* Implements svn_cache__has_key for membuffer caches.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|membuffer_cache_has_key
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|key
parameter_list|,
name|svn_boolean_t
modifier|*
name|found
parameter_list|)
block|{
comment|/* find the entry group that will hold the key.    */
name|apr_uint32_t
name|group_index
init|=
name|get_group_index
argument_list|(
operator|&
name|cache
argument_list|,
operator|&
name|key
operator|->
name|entry_key
argument_list|)
decl_stmt|;
name|cache
operator|->
name|total_reads
operator|++
expr_stmt|;
name|WITH_READ_LOCK
argument_list|(
name|cache
argument_list|,
name|membuffer_cache_has_key_internal
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|key
argument_list|,
name|found
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Look for the cache entry in group GROUP_INDEX of CACHE, identified  * by the hash value TO_FIND. FOUND indicates whether that entry exists.  * If not found, *ITEM will be NULL.  *  * Otherwise, the DESERIALIZER is called with that entry and the BATON  * provided and will extract the desired information. The result is set  * in *ITEM. Allocations will be done in POOL.  *  * Note: This function requires the caller to serialization access.  * Don't call it directly, call membuffer_cache_get_partial instead.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|membuffer_cache_get_partial_internal
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|group_index
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|to_find
parameter_list|,
name|void
modifier|*
modifier|*
name|item
parameter_list|,
name|svn_boolean_t
modifier|*
name|found
parameter_list|,
name|svn_cache__partial_getter_func_t
name|deserializer
parameter_list|,
name|void
modifier|*
name|baton
parameter_list|,
name|DEBUG_CACHE_MEMBUFFER_TAG_ARG
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|entry_t
modifier|*
name|entry
init|=
name|find_entry
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_find
argument_list|,
name|FALSE
argument_list|)
decl_stmt|;
name|cache
operator|->
name|total_reads
operator|++
expr_stmt|;
if|if
condition|(
name|entry
operator|==
name|NULL
condition|)
block|{
operator|*
name|item
operator|=
name|NULL
expr_stmt|;
operator|*
name|found
operator|=
name|FALSE
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
else|else
block|{
specifier|const
name|void
modifier|*
name|item_data
init|=
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
operator|+
name|entry
operator|->
name|key
operator|.
name|key_len
decl_stmt|;
name|apr_size_t
name|item_size
init|=
name|entry
operator|->
name|size
operator|-
name|entry
operator|->
name|key
operator|.
name|key_len
decl_stmt|;
operator|*
name|found
operator|=
name|TRUE
expr_stmt|;
name|increment_hit_counters
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|SVN_DEBUG_CACHE_MEMBUFFER
comment|/* Check for overlapping entries.        */
name|SVN_ERR_ASSERT
argument_list|(
name|entry
operator|->
name|next
operator|==
name|NO_INDEX
operator|||
name|entry
operator|->
name|offset
operator|+
name|entry
operator|->
name|size
operator|<=
name|get_entry
argument_list|(
name|cache
argument_list|,
name|entry
operator|->
name|next
argument_list|)
operator|->
name|offset
argument_list|)
expr_stmt|;
comment|/* Compare original content, type and key (hashes)        */
name|SVN_ERR
argument_list|(
name|store_content_part
argument_list|(
name|tag
argument_list|,
name|item_data
argument_list|,
name|item_size
argument_list|,
name|result_pool
argument_list|)
argument_list|)
expr_stmt|;
name|SVN_ERR
argument_list|(
name|assert_equal_tags
argument_list|(
operator|&
name|entry
operator|->
name|tag
argument_list|,
name|tag
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
return|return
name|deserializer
argument_list|(
name|item
argument_list|,
name|item_data
argument_list|,
name|item_size
argument_list|,
name|baton
argument_list|,
name|result_pool
argument_list|)
return|;
block|}
block|}
end_function

begin_comment
comment|/* Look for the cache entry identified by KEY. FOUND indicates  * whether that entry exists. If not found, *ITEM will be NULL. Otherwise,  * the DESERIALIZER is called with that entry and the BATON provided  * and will extract the desired information. The result is set in *ITEM.  * Allocations will be done in POOL.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|membuffer_cache_get_partial
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|key
parameter_list|,
name|void
modifier|*
modifier|*
name|item
parameter_list|,
name|svn_boolean_t
modifier|*
name|found
parameter_list|,
name|svn_cache__partial_getter_func_t
name|deserializer
parameter_list|,
name|void
modifier|*
name|baton
parameter_list|,
name|DEBUG_CACHE_MEMBUFFER_TAG_ARG
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|apr_uint32_t
name|group_index
init|=
name|get_group_index
argument_list|(
operator|&
name|cache
argument_list|,
operator|&
name|key
operator|->
name|entry_key
argument_list|)
decl_stmt|;
name|WITH_READ_LOCK
argument_list|(
name|cache
argument_list|,
name|membuffer_cache_get_partial_internal
argument_list|(
argument|cache
argument_list|,
argument|group_index
argument_list|,
argument|key
argument_list|,
argument|item
argument_list|,
argument|found
argument_list|,
argument|deserializer
argument_list|,
argument|baton
argument_list|,
argument|DEBUG_CACHE_MEMBUFFER_TAG                       result_pool
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Look for the cache entry in group GROUP_INDEX of CACHE, identified  * by the hash value TO_FIND. If no entry has been found, the function  * returns without modifying the cache.  *  * Otherwise, FUNC is called with that entry and the BATON provided  * and may modify the cache entry. Allocations will be done in POOL.  *  * Note: This function requires the caller to serialization access.  * Don't call it directly, call membuffer_cache_set_partial instead.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|membuffer_cache_set_partial_internal
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
name|apr_uint32_t
name|group_index
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|to_find
parameter_list|,
name|svn_cache__partial_setter_func_t
name|func
parameter_list|,
name|void
modifier|*
name|baton
parameter_list|,
name|DEBUG_CACHE_MEMBUFFER_TAG_ARG
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
comment|/* cache item lookup    */
name|entry_t
modifier|*
name|entry
init|=
name|find_entry
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_find
argument_list|,
name|FALSE
argument_list|)
decl_stmt|;
name|cache
operator|->
name|total_reads
operator|++
expr_stmt|;
comment|/* this function is a no-op if the item is not in cache    */
if|if
condition|(
name|entry
operator|!=
name|NULL
condition|)
block|{
name|svn_error_t
modifier|*
name|err
decl_stmt|;
comment|/* access the serialized cache item */
name|apr_size_t
name|key_len
init|=
name|entry
operator|->
name|key
operator|.
name|key_len
decl_stmt|;
name|void
modifier|*
name|item_data
init|=
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
operator|+
name|key_len
decl_stmt|;
name|void
modifier|*
name|orig_data
init|=
name|item_data
decl_stmt|;
name|apr_size_t
name|item_size
init|=
name|entry
operator|->
name|size
operator|-
name|key_len
decl_stmt|;
name|increment_hit_counters
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
name|cache
operator|->
name|total_writes
operator|++
expr_stmt|;
ifdef|#
directive|ifdef
name|SVN_DEBUG_CACHE_MEMBUFFER
comment|/* Check for overlapping entries.        */
name|SVN_ERR_ASSERT
argument_list|(
name|entry
operator|->
name|next
operator|==
name|NO_INDEX
operator|||
name|entry
operator|->
name|offset
operator|+
name|entry
operator|->
name|size
operator|<=
name|get_entry
argument_list|(
name|cache
argument_list|,
name|entry
operator|->
name|next
argument_list|)
operator|->
name|offset
argument_list|)
expr_stmt|;
comment|/* Compare original content, type and key (hashes)        */
name|SVN_ERR
argument_list|(
name|store_content_part
argument_list|(
name|tag
argument_list|,
name|item_data
argument_list|,
name|item_size
argument_list|,
name|scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
name|SVN_ERR
argument_list|(
name|assert_equal_tags
argument_list|(
operator|&
name|entry
operator|->
name|tag
argument_list|,
name|tag
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* modify it, preferably in-situ.        */
name|err
operator|=
name|func
argument_list|(
operator|&
name|item_data
argument_list|,
operator|&
name|item_size
argument_list|,
name|baton
argument_list|,
name|scratch_pool
argument_list|)
expr_stmt|;
if|if
condition|(
name|err
condition|)
block|{
comment|/* Something somewhere when wrong while FUNC was modifying the            * changed item. Thus, it might have become invalid /corrupted.            * We better drop that.            */
name|drop_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
return|return
name|err
return|;
block|}
else|else
block|{
comment|/* if the modification caused a re-allocation, we need to remove            * the old entry and to copy the new data back into cache.            */
if|if
condition|(
name|item_data
operator|!=
name|orig_data
condition|)
block|{
comment|/* Remove the old entry and try to make space for the new one.                */
name|drop_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|cache
operator|->
name|max_entry_size
operator|>=
name|item_size
operator|+
name|key_len
operator|)
operator|&&
name|ensure_data_insertable_l1
argument_list|(
name|cache
argument_list|,
name|item_size
operator|+
name|key_len
argument_list|)
condition|)
block|{
comment|/* Write the new entry.                    */
name|entry
operator|=
name|find_entry
argument_list|(
name|cache
argument_list|,
name|group_index
argument_list|,
name|to_find
argument_list|,
name|TRUE
argument_list|)
expr_stmt|;
name|entry
operator|->
name|size
operator|=
name|item_size
operator|+
name|key_len
expr_stmt|;
name|entry
operator|->
name|offset
operator|=
name|cache
operator|->
name|l1
operator|.
name|current_data
expr_stmt|;
if|if
condition|(
name|key_len
condition|)
name|memcpy
argument_list|(
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
argument_list|,
name|to_find
operator|->
name|full_key
operator|.
name|data
argument_list|,
name|key_len
argument_list|)
expr_stmt|;
if|if
condition|(
name|item_size
condition|)
name|memcpy
argument_list|(
name|cache
operator|->
name|data
operator|+
name|entry
operator|->
name|offset
operator|+
name|key_len
argument_list|,
name|item_data
argument_list|,
name|item_size
argument_list|)
expr_stmt|;
comment|/* Link the entry properly.                    */
name|insert_entry
argument_list|(
name|cache
argument_list|,
name|entry
argument_list|)
expr_stmt|;
block|}
block|}
ifdef|#
directive|ifdef
name|SVN_DEBUG_CACHE_MEMBUFFER
comment|/* Remember original content, type and key (hashes)            */
name|SVN_ERR
argument_list|(
name|store_content_part
argument_list|(
name|tag
argument_list|,
name|item_data
argument_list|,
name|item_size
argument_list|,
name|scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
operator|&
name|entry
operator|->
name|tag
argument_list|,
name|tag
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|tag
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
block|}
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Look for the cache entry identified by KEY. If no entry  * has been found, the function returns without modifying the cache.  * Otherwise, FUNC is called with that entry and the BATON provided  * and may modify the cache entry. Allocations will be done in POOL.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|membuffer_cache_set_partial
parameter_list|(
name|svn_membuffer_t
modifier|*
name|cache
parameter_list|,
specifier|const
name|full_key_t
modifier|*
name|key
parameter_list|,
name|svn_cache__partial_setter_func_t
name|func
parameter_list|,
name|void
modifier|*
name|baton
parameter_list|,
name|DEBUG_CACHE_MEMBUFFER_TAG_ARG
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
comment|/* cache item lookup    */
name|apr_uint32_t
name|group_index
init|=
name|get_group_index
argument_list|(
operator|&
name|cache
argument_list|,
operator|&
name|key
operator|->
name|entry_key
argument_list|)
decl_stmt|;
name|WITH_WRITE_LOCK
argument_list|(
name|cache
argument_list|,
name|membuffer_cache_set_partial_internal
argument_list|(
argument|cache
argument_list|,
argument|group_index
argument_list|,
argument|key
argument_list|,
argument|func
argument_list|,
argument|baton
argument_list|,
argument|DEBUG_CACHE_MEMBUFFER_TAG                       scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
comment|/* done here -> unlock the cache    */
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Implement the svn_cache__t interface on top of a shared membuffer cache.  *  * Because membuffer caches tend to be very large, there will be rather few  * of them (usually only one). Thus, the same instance shall be used as the  * backend to many application-visible svn_cache__t instances. This should  * also achieve global resource usage fairness.  *  * To accommodate items from multiple resources, the individual keys must be  * unique over all sources. This is achieved by simply adding a prefix key  * that unambiguously identifies the item's context (e.g. path to the  * respective repository). The prefix will be set upon construction of the  * svn_cache__t instance.  */
end_comment

begin_comment
comment|/* Internal cache structure (used in svn_cache__t.cache_internal) basically  * holding the additional parameters needed to call the respective membuffer  * functions.  */
end_comment

begin_typedef
typedef|typedef
struct|struct
name|svn_membuffer_cache_t
block|{
comment|/* this is where all our data will end up in    */
name|svn_membuffer_t
modifier|*
name|membuffer
decl_stmt|;
comment|/* use this conversion function when inserting an item into the memcache    */
name|svn_cache__serialize_func_t
name|serializer
decl_stmt|;
comment|/* use this conversion function when reading an item from the memcache    */
name|svn_cache__deserialize_func_t
name|deserializer
decl_stmt|;
comment|/* Prepend this byte sequence to any key passed to us.    * This makes our keys different from all keys used by svn_membuffer_cache_t    * instances that we don't want to share cached data with.    */
name|full_key_t
name|prefix
decl_stmt|;
comment|/* length of the keys that will be passed to us through the    * svn_cache_t interface. May be APR_HASH_KEY_STRING.    */
name|apr_ssize_t
name|key_len
decl_stmt|;
comment|/* priority class for all items written through this interface */
name|apr_uint32_t
name|priority
decl_stmt|;
comment|/* Temporary buffer containing the hash key for the current access    */
name|full_key_t
name|combined_key
decl_stmt|;
comment|/* if enabled, this will serialize the access to this instance.    */
name|svn_mutex__t
modifier|*
name|mutex
decl_stmt|;
block|}
name|svn_membuffer_cache_t
typedef|;
end_typedef

begin_comment
comment|/* After an estimated ALLOCATIONS_PER_POOL_CLEAR allocations, we should  * clear the svn_membuffer_cache_t.pool to keep memory consumption in check.  */
end_comment

begin_define
define|#
directive|define
name|ALLOCATIONS_PER_POOL_CLEAR
value|10
end_define

begin_comment
comment|/* Basically calculate a hash value for KEY of length KEY_LEN, combine it  * with the CACHE->PREFIX and write the result in CACHE->COMBINED_KEY.  * This could replace combine_key() entirely but we actually use it only  * when the quick path failed.  */
end_comment

begin_function
specifier|static
name|void
name|combine_long_key
parameter_list|(
name|svn_membuffer_cache_t
modifier|*
name|cache
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|apr_ssize_t
name|key_len
parameter_list|)
block|{
name|apr_uint32_t
modifier|*
name|digest_buffer
decl_stmt|;
name|char
modifier|*
name|key_copy
decl_stmt|;
name|apr_size_t
name|prefix_len
init|=
name|cache
operator|->
name|prefix
operator|.
name|entry_key
operator|.
name|key_len
decl_stmt|;
name|apr_size_t
name|aligned_key_len
decl_stmt|;
comment|/* handle variable-length keys */
if|if
condition|(
name|key_len
operator|==
name|APR_HASH_KEY_STRING
condition|)
name|key_len
operator|=
name|strlen
argument_list|(
operator|(
specifier|const
name|char
operator|*
operator|)
name|key
argument_list|)
expr_stmt|;
name|aligned_key_len
operator|=
name|ALIGN_VALUE
argument_list|(
name|key_len
argument_list|)
expr_stmt|;
comment|/* Combine keys. */
name|svn_membuf__ensure
argument_list|(
operator|&
name|cache
operator|->
name|combined_key
operator|.
name|full_key
argument_list|,
name|aligned_key_len
operator|+
name|prefix_len
argument_list|)
expr_stmt|;
name|key_copy
operator|=
operator|(
name|char
operator|*
operator|)
name|cache
operator|->
name|combined_key
operator|.
name|full_key
operator|.
name|data
operator|+
name|prefix_len
expr_stmt|;
name|cache
operator|->
name|combined_key
operator|.
name|entry_key
operator|.
name|key_len
operator|=
name|aligned_key_len
operator|+
name|prefix_len
expr_stmt|;
name|memcpy
argument_list|(
name|key_copy
argument_list|,
name|key
argument_list|,
name|key_len
argument_list|)
expr_stmt|;
name|memset
argument_list|(
name|key_copy
operator|+
name|key_len
argument_list|,
literal|0
argument_list|,
name|aligned_key_len
operator|-
name|key_len
argument_list|)
expr_stmt|;
comment|/* Hash key into 16 bytes. */
name|digest_buffer
operator|=
operator|(
name|apr_uint32_t
operator|*
operator|)
name|cache
operator|->
name|combined_key
operator|.
name|entry_key
operator|.
name|fingerprint
expr_stmt|;
name|svn__fnv1a_32x4_raw
argument_list|(
name|digest_buffer
argument_list|,
name|key
argument_list|,
name|key_len
argument_list|)
expr_stmt|;
comment|/* Combine with prefix. */
name|cache
operator|->
name|combined_key
operator|.
name|entry_key
operator|.
name|fingerprint
index|[
literal|0
index|]
operator|^=
name|cache
operator|->
name|prefix
operator|.
name|entry_key
operator|.
name|fingerprint
index|[
literal|0
index|]
expr_stmt|;
name|cache
operator|->
name|combined_key
operator|.
name|entry_key
operator|.
name|fingerprint
index|[
literal|1
index|]
operator|^=
name|cache
operator|->
name|prefix
operator|.
name|entry_key
operator|.
name|fingerprint
index|[
literal|1
index|]
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Basically calculate a hash value for KEY of length KEY_LEN, combine it  * with the CACHE->PREFIX and write the result in CACHE->COMBINED_KEY.  */
end_comment

begin_function
specifier|static
name|void
name|combine_key
parameter_list|(
name|svn_membuffer_cache_t
modifier|*
name|cache
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|apr_ssize_t
name|key_len
parameter_list|)
block|{
comment|/* short, fixed-size keys are the most common case */
if|if
condition|(
name|key_len
operator|!=
name|APR_HASH_KEY_STRING
operator|&&
name|key_len
operator|<=
literal|16
condition|)
block|{
specifier|const
name|apr_size_t
name|prefix_len
init|=
name|cache
operator|->
name|prefix
operator|.
name|entry_key
operator|.
name|key_len
decl_stmt|;
comment|/* Copy of *key, padded with 0.        * We put it just behind the prefix already copied into the COMBINED_KEY.        * The buffer space has been allocated when the cache was created. */
name|apr_uint64_t
modifier|*
name|data
init|=
operator|(
name|void
operator|*
operator|)
operator|(
operator|(
name|char
operator|*
operator|)
name|cache
operator|->
name|combined_key
operator|.
name|full_key
operator|.
name|data
operator|+
name|prefix_len
operator|)
decl_stmt|;
name|assert
argument_list|(
name|prefix_len
operator|<=
name|cache
operator|->
name|combined_key
operator|.
name|full_key
operator|.
name|size
operator|-
literal|16
argument_list|)
expr_stmt|;
name|cache
operator|->
name|combined_key
operator|.
name|entry_key
operator|.
name|key_len
operator|=
name|prefix_len
operator|+
literal|16
expr_stmt|;
name|data
index|[
literal|0
index|]
operator|=
literal|0
expr_stmt|;
name|data
index|[
literal|1
index|]
operator|=
literal|0
expr_stmt|;
name|memcpy
argument_list|(
name|data
argument_list|,
name|key
argument_list|,
name|key_len
argument_list|)
expr_stmt|;
comment|/* scramble key DATA.  All of this must be reversible to prevent key        * collisions.  So, we limit ourselves to xor and permutations. */
name|data
index|[
literal|1
index|]
operator|=
operator|(
name|data
index|[
literal|1
index|]
operator|<<
literal|27
operator|)
operator||
operator|(
name|data
index|[
literal|1
index|]
operator|>>
literal|37
operator|)
expr_stmt|;
name|data
index|[
literal|1
index|]
operator|^=
name|data
index|[
literal|0
index|]
operator|&
literal|0xffff
expr_stmt|;
name|data
index|[
literal|0
index|]
operator|^=
name|data
index|[
literal|1
index|]
operator|&
name|APR_UINT64_C
argument_list|(
literal|0xffffffffffff0000
argument_list|)
expr_stmt|;
comment|/* combine with this cache's namespace */
name|cache
operator|->
name|combined_key
operator|.
name|entry_key
operator|.
name|fingerprint
index|[
literal|0
index|]
operator|=
name|data
index|[
literal|0
index|]
operator|^
name|cache
operator|->
name|prefix
operator|.
name|entry_key
operator|.
name|fingerprint
index|[
literal|0
index|]
expr_stmt|;
name|cache
operator|->
name|combined_key
operator|.
name|entry_key
operator|.
name|fingerprint
index|[
literal|1
index|]
operator|=
name|data
index|[
literal|1
index|]
operator|^
name|cache
operator|->
name|prefix
operator|.
name|entry_key
operator|.
name|fingerprint
index|[
literal|1
index|]
expr_stmt|;
block|}
else|else
block|{
comment|/* longer or variably sized keys */
name|combine_long_key
argument_list|(
name|cache
argument_list|,
name|key
argument_list|,
name|key_len
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.get (not thread-safe)  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_get
parameter_list|(
name|void
modifier|*
modifier|*
name|value_p
parameter_list|,
name|svn_boolean_t
modifier|*
name|found
parameter_list|,
name|void
modifier|*
name|cache_void
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
name|DEBUG_CACHE_MEMBUFFER_INIT_TAG
argument_list|(
argument|result_pool
argument_list|)
comment|/* special case */
if|if
condition|(
name|key
operator|==
name|NULL
condition|)
block|{
operator|*
name|value_p
operator|=
name|NULL
expr_stmt|;
operator|*
name|found
operator|=
name|FALSE
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
comment|/* construct the full, i.e. globally unique, key by adding    * this cache instances' prefix    */
name|combine_key
argument_list|(
name|cache
argument_list|,
name|key
argument_list|,
name|cache
operator|->
name|key_len
argument_list|)
expr_stmt|;
comment|/* Look the item up. */
name|SVN_ERR
argument_list|(
name|membuffer_cache_get
argument_list|(
argument|cache->membuffer
argument_list|,
argument|&cache->combined_key
argument_list|,
argument|value_p
argument_list|,
argument|cache->deserializer
argument_list|,
argument|DEBUG_CACHE_MEMBUFFER_TAG                               result_pool
argument_list|)
argument_list|)
expr_stmt|;
comment|/* return result */
operator|*
name|found
operator|=
operator|*
name|value_p
operator|!=
name|NULL
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.has_key (not thread-safe)  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_has_key
parameter_list|(
name|svn_boolean_t
modifier|*
name|found
parameter_list|,
name|void
modifier|*
name|cache_void
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
comment|/* special case */
if|if
condition|(
name|key
operator|==
name|NULL
condition|)
block|{
operator|*
name|found
operator|=
name|FALSE
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
comment|/* construct the full, i.e. globally unique, key by adding    * this cache instances' prefix    */
name|combine_key
argument_list|(
name|cache
argument_list|,
name|key
argument_list|,
name|cache
operator|->
name|key_len
argument_list|)
expr_stmt|;
comment|/* Look the item up. */
name|SVN_ERR
argument_list|(
name|membuffer_cache_has_key
argument_list|(
name|cache
operator|->
name|membuffer
argument_list|,
operator|&
name|cache
operator|->
name|combined_key
argument_list|,
name|found
argument_list|)
argument_list|)
expr_stmt|;
comment|/* return result */
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.set (not thread-safe)  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_set
parameter_list|(
name|void
modifier|*
name|cache_void
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|void
modifier|*
name|value
parameter_list|,
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
name|DEBUG_CACHE_MEMBUFFER_INIT_TAG
argument_list|(
argument|scratch_pool
argument_list|)
comment|/* special case */
if|if
condition|(
name|key
operator|==
name|NULL
condition|)
return|return
name|SVN_NO_ERROR
return|;
comment|/* construct the full, i.e. globally unique, key by adding    * this cache instances' prefix    */
name|combine_key
argument_list|(
name|cache
argument_list|,
name|key
argument_list|,
name|cache
operator|->
name|key_len
argument_list|)
expr_stmt|;
comment|/* (probably) add the item to the cache. But there is no real guarantee    * that the item will actually be cached afterwards.    */
return|return
name|membuffer_cache_set
argument_list|(
argument|cache->membuffer
argument_list|,
argument|&cache->combined_key
argument_list|,
argument|value
argument_list|,
argument|cache->serializer
argument_list|,
argument|cache->priority
argument_list|,
argument|DEBUG_CACHE_MEMBUFFER_TAG                              scratch_pool
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.iter as "not implemented"  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_iter
parameter_list|(
name|svn_boolean_t
modifier|*
name|completed
parameter_list|,
name|void
modifier|*
name|cache_void
parameter_list|,
name|svn_iter_apr_hash_cb_t
name|user_cb
parameter_list|,
name|void
modifier|*
name|user_baton
parameter_list|,
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
return|return
name|svn_error_create
argument_list|(
name|SVN_ERR_UNSUPPORTED_FEATURE
argument_list|,
name|NULL
argument_list|,
name|_
argument_list|(
literal|"Can't iterate a membuffer-based cache"
argument_list|)
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.get_partial (not thread-safe)  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_get_partial
parameter_list|(
name|void
modifier|*
modifier|*
name|value_p
parameter_list|,
name|svn_boolean_t
modifier|*
name|found
parameter_list|,
name|void
modifier|*
name|cache_void
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|svn_cache__partial_getter_func_t
name|func
parameter_list|,
name|void
modifier|*
name|baton
parameter_list|,
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
name|DEBUG_CACHE_MEMBUFFER_INIT_TAG
argument_list|(
argument|result_pool
argument_list|)
if|if
condition|(
name|key
operator|==
name|NULL
condition|)
block|{
operator|*
name|value_p
operator|=
name|NULL
expr_stmt|;
operator|*
name|found
operator|=
name|FALSE
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
name|combine_key
argument_list|(
name|cache
argument_list|,
name|key
argument_list|,
name|cache
operator|->
name|key_len
argument_list|)
expr_stmt|;
name|SVN_ERR
argument_list|(
name|membuffer_cache_get_partial
argument_list|(
argument|cache->membuffer
argument_list|,
argument|&cache->combined_key
argument_list|,
argument|value_p
argument_list|,
argument|found
argument_list|,
argument|func
argument_list|,
argument|baton
argument_list|,
argument|DEBUG_CACHE_MEMBUFFER_TAG                                       result_pool
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.set_partial (not thread-safe)  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_set_partial
parameter_list|(
name|void
modifier|*
name|cache_void
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|svn_cache__partial_setter_func_t
name|func
parameter_list|,
name|void
modifier|*
name|baton
parameter_list|,
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
name|DEBUG_CACHE_MEMBUFFER_INIT_TAG
argument_list|(
argument|scratch_pool
argument_list|)
if|if
condition|(
name|key
operator|!=
name|NULL
condition|)
block|{
name|combine_key
argument_list|(
name|cache
argument_list|,
name|key
argument_list|,
name|cache
operator|->
name|key_len
argument_list|)
expr_stmt|;
name|SVN_ERR
argument_list|(
name|membuffer_cache_set_partial
argument_list|(
argument|cache->membuffer
argument_list|,
argument|&cache->combined_key
argument_list|,
argument|func
argument_list|,
argument|baton
argument_list|,
argument|DEBUG_CACHE_MEMBUFFER_TAG                                           scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.is_cachable  * (thread-safe even without mutex)  */
end_comment

begin_function
specifier|static
name|svn_boolean_t
name|svn_membuffer_cache_is_cachable
parameter_list|(
name|void
modifier|*
name|cache_void
parameter_list|,
name|apr_size_t
name|size
parameter_list|)
block|{
comment|/* Don't allow extremely large element sizes. Otherwise, the cache    * might by thrashed by a few extremely large entries. And the size    * must be small enough to be stored in a 32 bit value.    */
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
return|return
name|cache
operator|->
name|priority
operator|>
name|SVN_CACHE__MEMBUFFER_DEFAULT_PRIORITY
condition|?
name|cache
operator|->
name|membuffer
operator|->
name|l2
operator|.
name|size
operator|>=
name|size
operator|&&
name|MAX_ITEM_SIZE
operator|>=
name|size
else|:
name|size
operator|<=
name|cache
operator|->
name|membuffer
operator|->
name|max_entry_size
return|;
block|}
end_function

begin_comment
comment|/* Add statistics of SEGMENT to INFO.  If INCLUDE_HISTOGRAM is TRUE,  * accumulate index bucket fill levels in INFO->HISTOGRAM.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_get_segment_info
parameter_list|(
name|svn_membuffer_t
modifier|*
name|segment
parameter_list|,
name|svn_cache__info_t
modifier|*
name|info
parameter_list|,
name|svn_boolean_t
name|include_histogram
parameter_list|)
block|{
name|apr_uint32_t
name|i
decl_stmt|;
name|info
operator|->
name|data_size
operator|+=
name|segment
operator|->
name|l1
operator|.
name|size
operator|+
name|segment
operator|->
name|l2
operator|.
name|size
expr_stmt|;
name|info
operator|->
name|used_size
operator|+=
name|segment
operator|->
name|data_used
expr_stmt|;
name|info
operator|->
name|total_size
operator|+=
name|segment
operator|->
name|l1
operator|.
name|size
operator|+
name|segment
operator|->
name|l2
operator|.
name|size
operator|+
name|segment
operator|->
name|group_count
operator|*
name|GROUP_SIZE
operator|*
sizeof|sizeof
argument_list|(
name|entry_t
argument_list|)
expr_stmt|;
name|info
operator|->
name|used_entries
operator|+=
name|segment
operator|->
name|used_entries
expr_stmt|;
name|info
operator|->
name|total_entries
operator|+=
name|segment
operator|->
name|group_count
operator|*
name|GROUP_SIZE
expr_stmt|;
if|if
condition|(
name|include_histogram
condition|)
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|segment
operator|->
name|group_count
condition|;
operator|++
name|i
control|)
if|if
condition|(
name|is_group_initialized
argument_list|(
name|segment
argument_list|,
name|i
argument_list|)
condition|)
block|{
name|entry_group_t
modifier|*
name|chain_end
init|=
name|last_group_in_chain
argument_list|(
name|segment
argument_list|,
operator|&
name|segment
operator|->
name|directory
index|[
name|i
index|]
argument_list|)
decl_stmt|;
name|apr_size_t
name|use
init|=
name|MIN
argument_list|(
name|chain_end
operator|->
name|header
operator|.
name|used
argument_list|,
sizeof|sizeof
argument_list|(
name|info
operator|->
name|histogram
argument_list|)
operator|/
sizeof|sizeof
argument_list|(
name|info
operator|->
name|histogram
index|[
literal|0
index|]
argument_list|)
operator|-
literal|1
argument_list|)
decl_stmt|;
name|info
operator|->
name|histogram
index|[
name|use
index|]
operator|++
expr_stmt|;
block|}
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.get_info  * (thread-safe even without mutex)  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_get_info
parameter_list|(
name|void
modifier|*
name|cache_void
parameter_list|,
name|svn_cache__info_t
modifier|*
name|info
parameter_list|,
name|svn_boolean_t
name|reset
parameter_list|,
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
name|apr_uint32_t
name|i
decl_stmt|;
comment|/* cache front-end specific data */
name|info
operator|->
name|id
operator|=
name|apr_pstrdup
argument_list|(
name|result_pool
argument_list|,
name|cache
operator|->
name|prefix
operator|.
name|full_key
operator|.
name|data
argument_list|)
expr_stmt|;
comment|/* collect info from shared cache back-end */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|cache
operator|->
name|membuffer
operator|->
name|segment_count
condition|;
operator|++
name|i
control|)
block|{
name|svn_membuffer_t
modifier|*
name|segment
init|=
name|cache
operator|->
name|membuffer
operator|+
name|i
decl_stmt|;
name|WITH_READ_LOCK
argument_list|(
name|segment
argument_list|,
name|svn_membuffer_get_segment_info
argument_list|(
name|segment
argument_list|,
name|info
argument_list|,
name|FALSE
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* the v-table for membuffer-based caches (single-threaded access)  */
end_comment

begin_decl_stmt
specifier|static
name|svn_cache__vtable_t
name|membuffer_cache_vtable
init|=
block|{
name|svn_membuffer_cache_get
block|,
name|svn_membuffer_cache_has_key
block|,
name|svn_membuffer_cache_set
block|,
name|svn_membuffer_cache_iter
block|,
name|svn_membuffer_cache_is_cachable
block|,
name|svn_membuffer_cache_get_partial
block|,
name|svn_membuffer_cache_set_partial
block|,
name|svn_membuffer_cache_get_info
block|}
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Implement svn_cache__vtable_t.get and serialize all cache access.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_get_synced
parameter_list|(
name|void
modifier|*
modifier|*
name|value_p
parameter_list|,
name|svn_boolean_t
modifier|*
name|found
parameter_list|,
name|void
modifier|*
name|cache_void
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
name|SVN_MUTEX__WITH_LOCK
argument_list|(
name|cache
operator|->
name|mutex
argument_list|,
name|svn_membuffer_cache_get
argument_list|(
name|value_p
argument_list|,
name|found
argument_list|,
name|cache_void
argument_list|,
name|key
argument_list|,
name|result_pool
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.has_key and serialize all cache access.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_has_key_synced
parameter_list|(
name|svn_boolean_t
modifier|*
name|found
parameter_list|,
name|void
modifier|*
name|cache_void
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
name|SVN_MUTEX__WITH_LOCK
argument_list|(
name|cache
operator|->
name|mutex
argument_list|,
name|svn_membuffer_cache_has_key
argument_list|(
name|found
argument_list|,
name|cache_void
argument_list|,
name|key
argument_list|,
name|result_pool
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.set and serialize all cache access.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_set_synced
parameter_list|(
name|void
modifier|*
name|cache_void
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|void
modifier|*
name|value
parameter_list|,
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
name|SVN_MUTEX__WITH_LOCK
argument_list|(
name|cache
operator|->
name|mutex
argument_list|,
name|svn_membuffer_cache_set
argument_list|(
name|cache_void
argument_list|,
name|key
argument_list|,
name|value
argument_list|,
name|scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.get_partial and serialize all cache access.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_get_partial_synced
parameter_list|(
name|void
modifier|*
modifier|*
name|value_p
parameter_list|,
name|svn_boolean_t
modifier|*
name|found
parameter_list|,
name|void
modifier|*
name|cache_void
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|svn_cache__partial_getter_func_t
name|func
parameter_list|,
name|void
modifier|*
name|baton
parameter_list|,
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
name|SVN_MUTEX__WITH_LOCK
argument_list|(
name|cache
operator|->
name|mutex
argument_list|,
name|svn_membuffer_cache_get_partial
argument_list|(
name|value_p
argument_list|,
name|found
argument_list|,
name|cache_void
argument_list|,
name|key
argument_list|,
name|func
argument_list|,
name|baton
argument_list|,
name|result_pool
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Implement svn_cache__vtable_t.set_partial and serialize all cache access.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_cache_set_partial_synced
parameter_list|(
name|void
modifier|*
name|cache_void
parameter_list|,
specifier|const
name|void
modifier|*
name|key
parameter_list|,
name|svn_cache__partial_setter_func_t
name|func
parameter_list|,
name|void
modifier|*
name|baton
parameter_list|,
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|cache_void
decl_stmt|;
name|SVN_MUTEX__WITH_LOCK
argument_list|(
name|cache
operator|->
name|mutex
argument_list|,
name|svn_membuffer_cache_set_partial
argument_list|(
name|cache_void
argument_list|,
name|key
argument_list|,
name|func
argument_list|,
name|baton
argument_list|,
name|scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* the v-table for membuffer-based caches with multi-threading support)  */
end_comment

begin_decl_stmt
specifier|static
name|svn_cache__vtable_t
name|membuffer_cache_synced_vtable
init|=
block|{
name|svn_membuffer_cache_get_synced
block|,
name|svn_membuffer_cache_has_key_synced
block|,
name|svn_membuffer_cache_set_synced
block|,
name|svn_membuffer_cache_iter
block|,
comment|/* no sync required */
name|svn_membuffer_cache_is_cachable
block|,
comment|/* no sync required */
name|svn_membuffer_cache_get_partial_synced
block|,
name|svn_membuffer_cache_set_partial_synced
block|,
name|svn_membuffer_cache_get_info
comment|/* no sync required */
block|}
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* standard serialization function for svn_stringbuf_t items.  * Implements svn_cache__serialize_func_t.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|serialize_svn_stringbuf
parameter_list|(
name|void
modifier|*
modifier|*
name|buffer
parameter_list|,
name|apr_size_t
modifier|*
name|buffer_size
parameter_list|,
name|void
modifier|*
name|item
parameter_list|,
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|svn_stringbuf_t
modifier|*
name|value_str
init|=
name|item
decl_stmt|;
operator|*
name|buffer
operator|=
name|value_str
operator|->
name|data
expr_stmt|;
operator|*
name|buffer_size
operator|=
name|value_str
operator|->
name|len
operator|+
literal|1
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* standard de-serialization function for svn_stringbuf_t items.  * Implements svn_cache__deserialize_func_t.  */
end_comment

begin_function
specifier|static
name|svn_error_t
modifier|*
name|deserialize_svn_stringbuf
parameter_list|(
name|void
modifier|*
modifier|*
name|item
parameter_list|,
name|void
modifier|*
name|buffer
parameter_list|,
name|apr_size_t
name|buffer_size
parameter_list|,
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|)
block|{
name|svn_stringbuf_t
modifier|*
name|value_str
init|=
name|apr_palloc
argument_list|(
name|result_pool
argument_list|,
sizeof|sizeof
argument_list|(
name|svn_stringbuf_t
argument_list|)
argument_list|)
decl_stmt|;
name|value_str
operator|->
name|pool
operator|=
name|result_pool
expr_stmt|;
name|value_str
operator|->
name|blocksize
operator|=
name|buffer_size
expr_stmt|;
name|value_str
operator|->
name|data
operator|=
name|buffer
expr_stmt|;
name|value_str
operator|->
name|len
operator|=
name|buffer_size
operator|-
literal|1
expr_stmt|;
operator|*
name|item
operator|=
name|value_str
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_comment
comment|/* Construct a svn_cache__t object on top of a shared memcache.  */
end_comment

begin_function
name|svn_error_t
modifier|*
name|svn_cache__create_membuffer_cache
parameter_list|(
name|svn_cache__t
modifier|*
modifier|*
name|cache_p
parameter_list|,
name|svn_membuffer_t
modifier|*
name|membuffer
parameter_list|,
name|svn_cache__serialize_func_t
name|serializer
parameter_list|,
name|svn_cache__deserialize_func_t
name|deserializer
parameter_list|,
name|apr_ssize_t
name|klen
parameter_list|,
specifier|const
name|char
modifier|*
name|prefix
parameter_list|,
name|apr_uint32_t
name|priority
parameter_list|,
name|svn_boolean_t
name|thread_safe
parameter_list|,
name|apr_pool_t
modifier|*
name|result_pool
parameter_list|,
name|apr_pool_t
modifier|*
name|scratch_pool
parameter_list|)
block|{
name|svn_checksum_t
modifier|*
name|checksum
decl_stmt|;
name|apr_size_t
name|prefix_len
decl_stmt|,
name|prefix_orig_len
decl_stmt|;
comment|/* allocate the cache header structures    */
name|svn_cache__t
modifier|*
name|wrapper
init|=
name|apr_pcalloc
argument_list|(
name|result_pool
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|wrapper
argument_list|)
argument_list|)
decl_stmt|;
name|svn_membuffer_cache_t
modifier|*
name|cache
init|=
name|apr_pcalloc
argument_list|(
name|result_pool
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|cache
argument_list|)
argument_list|)
decl_stmt|;
comment|/* initialize our internal cache header    */
name|cache
operator|->
name|membuffer
operator|=
name|membuffer
expr_stmt|;
name|cache
operator|->
name|serializer
operator|=
name|serializer
condition|?
name|serializer
else|:
name|serialize_svn_stringbuf
expr_stmt|;
name|cache
operator|->
name|deserializer
operator|=
name|deserializer
condition|?
name|deserializer
else|:
name|deserialize_svn_stringbuf
expr_stmt|;
name|cache
operator|->
name|priority
operator|=
name|priority
expr_stmt|;
name|cache
operator|->
name|key_len
operator|=
name|klen
expr_stmt|;
name|SVN_ERR
argument_list|(
name|svn_mutex__init
argument_list|(
operator|&
name|cache
operator|->
name|mutex
argument_list|,
name|thread_safe
argument_list|,
name|result_pool
argument_list|)
argument_list|)
expr_stmt|;
comment|/* Copy the prefix into the prefix full key. Align it to ITEM_ALIGMENT.    * Don't forget to include the terminating NUL. */
name|prefix_orig_len
operator|=
name|strlen
argument_list|(
name|prefix
argument_list|)
operator|+
literal|1
expr_stmt|;
name|prefix_len
operator|=
name|ALIGN_VALUE
argument_list|(
name|prefix_orig_len
argument_list|)
expr_stmt|;
name|svn_membuf__create
argument_list|(
operator|&
name|cache
operator|->
name|prefix
operator|.
name|full_key
argument_list|,
name|prefix_len
argument_list|,
name|result_pool
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
operator|(
name|char
operator|*
operator|)
name|cache
operator|->
name|prefix
operator|.
name|full_key
operator|.
name|data
argument_list|,
name|prefix
argument_list|,
name|prefix_orig_len
argument_list|)
expr_stmt|;
name|memset
argument_list|(
operator|(
name|char
operator|*
operator|)
name|cache
operator|->
name|prefix
operator|.
name|full_key
operator|.
name|data
operator|+
name|prefix_orig_len
argument_list|,
literal|0
argument_list|,
name|prefix_len
operator|-
name|prefix_orig_len
argument_list|)
expr_stmt|;
comment|/* Construct the folded prefix key. */
name|SVN_ERR
argument_list|(
name|svn_checksum
argument_list|(
operator|&
name|checksum
argument_list|,
name|svn_checksum_md5
argument_list|,
name|prefix
argument_list|,
name|strlen
argument_list|(
name|prefix
argument_list|)
argument_list|,
name|scratch_pool
argument_list|)
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
name|cache
operator|->
name|prefix
operator|.
name|entry_key
operator|.
name|fingerprint
argument_list|,
name|checksum
operator|->
name|digest
argument_list|,
sizeof|sizeof
argument_list|(
name|cache
operator|->
name|prefix
operator|.
name|entry_key
operator|.
name|fingerprint
argument_list|)
argument_list|)
expr_stmt|;
name|cache
operator|->
name|prefix
operator|.
name|entry_key
operator|.
name|key_len
operator|=
name|prefix_len
expr_stmt|;
comment|/* Initialize the combined key. Pre-allocate some extra room in the full    * key such that we probably don't need to re-alloc. */
name|cache
operator|->
name|combined_key
operator|.
name|entry_key
operator|=
name|cache
operator|->
name|prefix
operator|.
name|entry_key
expr_stmt|;
name|svn_membuf__create
argument_list|(
operator|&
name|cache
operator|->
name|combined_key
operator|.
name|full_key
argument_list|,
name|prefix_len
operator|+
literal|200
argument_list|,
name|result_pool
argument_list|)
expr_stmt|;
name|memcpy
argument_list|(
name|cache
operator|->
name|combined_key
operator|.
name|full_key
operator|.
name|data
argument_list|,
name|cache
operator|->
name|prefix
operator|.
name|full_key
operator|.
name|data
argument_list|,
name|prefix_len
argument_list|)
expr_stmt|;
comment|/* initialize the generic cache wrapper    */
name|wrapper
operator|->
name|vtable
operator|=
name|thread_safe
condition|?
operator|&
name|membuffer_cache_synced_vtable
else|:
operator|&
name|membuffer_cache_vtable
expr_stmt|;
name|wrapper
operator|->
name|cache_internal
operator|=
name|cache
expr_stmt|;
name|wrapper
operator|->
name|error_handler
operator|=
literal|0
expr_stmt|;
name|wrapper
operator|->
name|error_baton
operator|=
literal|0
expr_stmt|;
name|wrapper
operator|->
name|pretend_empty
operator|=
operator|!
operator|!
name|getenv
argument_list|(
literal|"SVN_X_DOES_NOT_MARK_THE_SPOT"
argument_list|)
expr_stmt|;
operator|*
name|cache_p
operator|=
name|wrapper
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_function
specifier|static
name|svn_error_t
modifier|*
name|svn_membuffer_get_global_segment_info
parameter_list|(
name|svn_membuffer_t
modifier|*
name|segment
parameter_list|,
name|svn_cache__info_t
modifier|*
name|info
parameter_list|)
block|{
name|info
operator|->
name|gets
operator|+=
name|segment
operator|->
name|total_reads
expr_stmt|;
name|info
operator|->
name|sets
operator|+=
name|segment
operator|->
name|total_writes
expr_stmt|;
name|info
operator|->
name|hits
operator|+=
name|segment
operator|->
name|total_hits
expr_stmt|;
name|WITH_READ_LOCK
argument_list|(
name|segment
argument_list|,
name|svn_membuffer_get_segment_info
argument_list|(
name|segment
argument_list|,
name|info
argument_list|,
name|TRUE
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|SVN_NO_ERROR
return|;
block|}
end_function

begin_function
name|svn_cache__info_t
modifier|*
name|svn_cache__membuffer_get_global_info
parameter_list|(
name|apr_pool_t
modifier|*
name|pool
parameter_list|)
block|{
name|apr_uint32_t
name|i
decl_stmt|;
name|svn_membuffer_t
modifier|*
name|membuffer
init|=
name|svn_cache__get_global_membuffer_cache
argument_list|()
decl_stmt|;
name|svn_cache__info_t
modifier|*
name|info
init|=
name|apr_pcalloc
argument_list|(
name|pool
argument_list|,
sizeof|sizeof
argument_list|(
operator|*
name|info
argument_list|)
argument_list|)
decl_stmt|;
comment|/* cache front-end specific data */
name|info
operator|->
name|id
operator|=
literal|"membuffer globals"
expr_stmt|;
comment|/* collect info from shared cache back-end */
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|membuffer
operator|->
name|segment_count
condition|;
operator|++
name|i
control|)
name|svn_error_clear
argument_list|(
name|svn_membuffer_get_global_segment_info
argument_list|(
name|membuffer
operator|+
name|i
argument_list|,
name|info
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|info
return|;
block|}
end_function

end_unit

