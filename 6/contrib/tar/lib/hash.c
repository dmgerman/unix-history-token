begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/* hash - hashing table processing.    Copyright (C) 1998, 1999, 2000 Free Software Foundation, Inc.    Written by Jim Meyering, 1992.     This program is free software; you can redistribute it and/or modify    it under the terms of the GNU General Public License as published by    the Free Software Foundation; either version 2, or (at your option)    any later version.     This program is distributed in the hope that it will be useful,    but WITHOUT ANY WARRANTY; without even the implied warranty of    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the    GNU General Public License for more details.     You should have received a copy of the GNU General Public License    along with this program; if not, write to the Free Software Foundation,    Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.  */
end_comment

begin_comment
comment|/* A generic hash table package.  */
end_comment

begin_comment
comment|/* Define USE_OBSTACK to 1 if you want the allocator to use obstacks instead    of malloc.  If you change USE_OBSTACK, you have to recompile!  */
end_comment

begin_if
if|#
directive|if
name|HAVE_CONFIG_H
end_if

begin_include
include|#
directive|include
file|<config.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_if
if|#
directive|if
name|HAVE_STDLIB_H
end_if

begin_include
include|#
directive|include
file|<stdlib.h>
end_include

begin_endif
endif|#
directive|endif
end_endif

begin_if
if|#
directive|if
name|HAVE_STDBOOL_H
end_if

begin_include
include|#
directive|include
file|<stdbool.h>
end_include

begin_else
else|#
directive|else
end_else

begin_typedef
typedef|typedef
enum|enum
block|{
name|false
init|=
literal|0
block|,
name|true
init|=
literal|1
block|}
name|bool
typedef|;
end_typedef

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|<stdio.h>
end_include

begin_include
include|#
directive|include
file|<assert.h>
end_include

begin_ifndef
ifndef|#
directive|ifndef
name|HAVE_DECL_FREE
end_ifndef

begin_expr_stmt
literal|"this configure-time declaration test was not run"
endif|#
directive|endif
if|#
directive|if
operator|!
name|HAVE_DECL_FREE
name|void
name|free
argument_list|()
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_ifndef
ifndef|#
directive|ifndef
name|HAVE_DECL_MALLOC
end_ifndef

begin_expr_stmt
literal|"this configure-time declaration test was not run"
endif|#
directive|endif
if|#
directive|if
operator|!
name|HAVE_DECL_MALLOC
name|char
operator|*
name|malloc
argument_list|()
expr_stmt|;
end_expr_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_if
if|#
directive|if
name|USE_OBSTACK
end_if

begin_include
include|#
directive|include
file|"obstack.h"
end_include

begin_ifndef
ifndef|#
directive|ifndef
name|obstack_chunk_alloc
end_ifndef

begin_define
define|#
directive|define
name|obstack_chunk_alloc
value|malloc
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_ifndef
ifndef|#
directive|ifndef
name|obstack_chunk_free
end_ifndef

begin_define
define|#
directive|define
name|obstack_chunk_free
value|free
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_endif
endif|#
directive|endif
end_endif

begin_include
include|#
directive|include
file|"hash.h"
end_include

begin_comment
comment|/* A hash table contains many internal entries, each holding a pointer to    some user provided data (also called a user entry).  An entry indistinctly    refers to both the internal entry and its associated user entry.  A user    entry contents may be hashed by a randomization function (the hashing    function, or just `hasher' for short) into a number (or `slot') between 0    and the current table size.  At each slot position in the hash table,    starts a linked chain of entries for which the user data all hash to this    slot.  A bucket is the collection of all entries hashing to the same slot.     A good `hasher' function will distribute entries rather evenly in buckets.    In the ideal case, the length of each bucket is roughly the number of    entries divided by the table size.  Finding the slot for a data is usually    done in constant time by the `hasher', and the later finding of a precise    entry is linear in time with the size of the bucket.  Consequently, a    larger hash table size (that is, a larger number of buckets) is prone to    yielding shorter chains, *given* the `hasher' function behaves properly.     Long buckets slow down the lookup algorithm.  One might use big hash table    sizes in hope to reduce the average length of buckets, but this might    become inordinate, as unused slots in the hash table take some space.  The    best bet is to make sure you are using a good `hasher' function (beware    that those are not that easy to write! :-), and to use a table size    larger than the actual number of entries.  */
end_comment

begin_comment
comment|/* If an insertion makes the ratio of nonempty buckets to table size larger    than the growth threshold (a number between 0.0 and 1.0), then increase    the table size by multiplying by the growth factor (a number greater than    1.0).  The growth threshold defaults to 0.8, and the growth factor    defaults to 1.414, meaning that the table will have doubled its size    every second time 80% of the buckets get used.  */
end_comment

begin_define
define|#
directive|define
name|DEFAULT_GROWTH_THRESHOLD
value|0.8
end_define

begin_define
define|#
directive|define
name|DEFAULT_GROWTH_FACTOR
value|1.414
end_define

begin_comment
comment|/* If a deletion empties a bucket and causes the ratio of used buckets to    table size to become smaller than the shrink threshold (a number between    0.0 and 1.0), then shrink the table by multiplying by the shrink factor (a    number greater than the shrink threshold but smaller than 1.0).  The shrink    threshold and factor default to 0.0 and 1.0, meaning that the table never    shrinks.  */
end_comment

begin_define
define|#
directive|define
name|DEFAULT_SHRINK_THRESHOLD
value|0.0
end_define

begin_define
define|#
directive|define
name|DEFAULT_SHRINK_FACTOR
value|1.0
end_define

begin_comment
comment|/* Use this to initialize or reset a TUNING structure to    some sensible values. */
end_comment

begin_decl_stmt
specifier|static
specifier|const
name|Hash_tuning
name|default_tuning
init|=
block|{
name|DEFAULT_SHRINK_THRESHOLD
block|,
name|DEFAULT_SHRINK_FACTOR
block|,
name|DEFAULT_GROWTH_THRESHOLD
block|,
name|DEFAULT_GROWTH_FACTOR
block|,
name|false
block|}
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* Information and lookup.  */
end_comment

begin_comment
comment|/* The following few functions provide information about the overall hash    table organization: the number of entries, number of buckets and maximum    length of buckets.  */
end_comment

begin_comment
comment|/* Return the number of buckets in the hash table.  The table size, the total    number of buckets (used plus unused), or the maximum number of slots, are    the same quantity.  */
end_comment

begin_function
name|unsigned
name|hash_get_n_buckets
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
return|return
name|table
operator|->
name|n_buckets
return|;
block|}
end_function

begin_comment
comment|/* Return the number of slots in use (non-empty buckets).  */
end_comment

begin_function
name|unsigned
name|hash_get_n_buckets_used
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
return|return
name|table
operator|->
name|n_buckets_used
return|;
block|}
end_function

begin_comment
comment|/* Return the number of active entries.  */
end_comment

begin_function
name|unsigned
name|hash_get_n_entries
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
return|return
name|table
operator|->
name|n_entries
return|;
block|}
end_function

begin_comment
comment|/* Return the length of the longest chain (bucket).  */
end_comment

begin_function
name|unsigned
name|hash_get_max_bucket_length
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
name|unsigned
name|max_bucket_length
init|=
literal|0
decl_stmt|;
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
block|{
if|if
condition|(
name|bucket
operator|->
name|data
condition|)
block|{
name|struct
name|hash_entry
modifier|*
name|cursor
init|=
name|bucket
decl_stmt|;
name|unsigned
name|bucket_length
init|=
literal|1
decl_stmt|;
while|while
condition|(
name|cursor
operator|=
name|cursor
operator|->
name|next
operator|,
name|cursor
condition|)
name|bucket_length
operator|++
expr_stmt|;
if|if
condition|(
name|bucket_length
operator|>
name|max_bucket_length
condition|)
name|max_bucket_length
operator|=
name|bucket_length
expr_stmt|;
block|}
block|}
return|return
name|max_bucket_length
return|;
block|}
end_function

begin_comment
comment|/* Do a mild validation of a hash table, by traversing it and checking two    statistics.  */
end_comment

begin_function
name|bool
name|hash_table_ok
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
name|unsigned
name|n_buckets_used
init|=
literal|0
decl_stmt|;
name|unsigned
name|n_entries
init|=
literal|0
decl_stmt|;
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
block|{
if|if
condition|(
name|bucket
operator|->
name|data
condition|)
block|{
name|struct
name|hash_entry
modifier|*
name|cursor
init|=
name|bucket
decl_stmt|;
comment|/* Count bucket head.  */
name|n_buckets_used
operator|++
expr_stmt|;
name|n_entries
operator|++
expr_stmt|;
comment|/* Count bucket overflow.  */
while|while
condition|(
name|cursor
operator|=
name|cursor
operator|->
name|next
operator|,
name|cursor
condition|)
name|n_entries
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|n_buckets_used
operator|==
name|table
operator|->
name|n_buckets_used
operator|&&
name|n_entries
operator|==
name|table
operator|->
name|n_entries
condition|)
return|return
name|true
return|;
return|return
name|false
return|;
block|}
end_function

begin_function
name|void
name|hash_print_statistics
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|,
name|FILE
modifier|*
name|stream
parameter_list|)
block|{
name|unsigned
name|n_entries
init|=
name|hash_get_n_entries
argument_list|(
name|table
argument_list|)
decl_stmt|;
name|unsigned
name|n_buckets
init|=
name|hash_get_n_buckets
argument_list|(
name|table
argument_list|)
decl_stmt|;
name|unsigned
name|n_buckets_used
init|=
name|hash_get_n_buckets_used
argument_list|(
name|table
argument_list|)
decl_stmt|;
name|unsigned
name|max_bucket_length
init|=
name|hash_get_max_bucket_length
argument_list|(
name|table
argument_list|)
decl_stmt|;
name|fprintf
argument_list|(
name|stream
argument_list|,
literal|"# entries:         %u\n"
argument_list|,
name|n_entries
argument_list|)
expr_stmt|;
name|fprintf
argument_list|(
name|stream
argument_list|,
literal|"# buckets:         %u\n"
argument_list|,
name|n_buckets
argument_list|)
expr_stmt|;
name|fprintf
argument_list|(
name|stream
argument_list|,
literal|"# buckets used:    %u (%.2f%%)\n"
argument_list|,
name|n_buckets_used
argument_list|,
operator|(
literal|100.0
operator|*
name|n_buckets_used
operator|)
operator|/
name|n_buckets
argument_list|)
expr_stmt|;
name|fprintf
argument_list|(
name|stream
argument_list|,
literal|"max bucket length: %u\n"
argument_list|,
name|max_bucket_length
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* If ENTRY matches an entry already in the hash table, return the    entry from the table.  Otherwise, return NULL.  */
end_comment

begin_function
name|void
modifier|*
name|hash_lookup
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|,
specifier|const
name|void
modifier|*
name|entry
parameter_list|)
block|{
name|struct
name|hash_entry
modifier|*
name|bucket
init|=
name|table
operator|->
name|bucket
operator|+
name|table
operator|->
name|hasher
argument_list|(
name|entry
argument_list|,
name|table
operator|->
name|n_buckets
argument_list|)
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|cursor
decl_stmt|;
name|assert
argument_list|(
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
argument_list|)
expr_stmt|;
if|if
condition|(
name|bucket
operator|->
name|data
operator|==
name|NULL
condition|)
return|return
name|NULL
return|;
for|for
control|(
name|cursor
operator|=
name|bucket
init|;
name|cursor
condition|;
name|cursor
operator|=
name|cursor
operator|->
name|next
control|)
if|if
condition|(
name|table
operator|->
name|comparator
argument_list|(
name|entry
argument_list|,
name|cursor
operator|->
name|data
argument_list|)
condition|)
return|return
name|cursor
operator|->
name|data
return|;
return|return
name|NULL
return|;
block|}
end_function

begin_comment
comment|/* Walking.  */
end_comment

begin_comment
comment|/* The functions in this page traverse the hash table and process the    contained entries.  For the traversal to work properly, the hash table    should not be resized nor modified while any particular entry is being    processed.  In particular, entries should not be added or removed.  */
end_comment

begin_comment
comment|/* Return the first data in the table, or NULL if the table is empty.  */
end_comment

begin_function
name|void
modifier|*
name|hash_get_first
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
if|if
condition|(
name|table
operator|->
name|n_entries
operator|==
literal|0
condition|)
return|return
name|NULL
return|;
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
if|if
condition|(
name|bucket
operator|->
name|data
condition|)
return|return
name|bucket
operator|->
name|data
return|;
name|assert
argument_list|(
literal|0
argument_list|)
expr_stmt|;
return|return
name|NULL
return|;
block|}
end_function

begin_comment
comment|/* Return the user data for the entry following ENTRY, where ENTRY has been    returned by a previous call to either `hash_get_first' or `hash_get_next'.    Return NULL if there are no more entries.  */
end_comment

begin_function
name|void
modifier|*
name|hash_get_next
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|,
specifier|const
name|void
modifier|*
name|entry
parameter_list|)
block|{
name|struct
name|hash_entry
modifier|*
name|bucket
init|=
name|table
operator|->
name|bucket
operator|+
name|table
operator|->
name|hasher
argument_list|(
name|entry
argument_list|,
name|table
operator|->
name|n_buckets
argument_list|)
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|cursor
decl_stmt|;
name|assert
argument_list|(
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
argument_list|)
expr_stmt|;
comment|/* Find next entry in the same bucket.  */
for|for
control|(
name|cursor
operator|=
name|bucket
init|;
name|cursor
condition|;
name|cursor
operator|=
name|cursor
operator|->
name|next
control|)
if|if
condition|(
name|cursor
operator|->
name|data
operator|==
name|entry
operator|&&
name|cursor
operator|->
name|next
condition|)
return|return
name|cursor
operator|->
name|next
operator|->
name|data
return|;
comment|/* Find first entry in any subsequent bucket.  */
while|while
condition|(
operator|++
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|)
if|if
condition|(
name|bucket
operator|->
name|data
condition|)
return|return
name|bucket
operator|->
name|data
return|;
comment|/* None found.  */
return|return
name|NULL
return|;
block|}
end_function

begin_comment
comment|/* Fill BUFFER with pointers to active user entries in the hash table, then    return the number of pointers copied.  Do not copy more than BUFFER_SIZE    pointers.  */
end_comment

begin_function
name|unsigned
name|hash_get_entries
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|,
name|void
modifier|*
modifier|*
name|buffer
parameter_list|,
name|unsigned
name|buffer_size
parameter_list|)
block|{
name|unsigned
name|counter
init|=
literal|0
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|cursor
decl_stmt|;
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
block|{
if|if
condition|(
name|bucket
operator|->
name|data
condition|)
block|{
for|for
control|(
name|cursor
operator|=
name|bucket
init|;
name|cursor
condition|;
name|cursor
operator|=
name|cursor
operator|->
name|next
control|)
block|{
if|if
condition|(
name|counter
operator|>=
name|buffer_size
condition|)
return|return
name|counter
return|;
name|buffer
index|[
name|counter
operator|++
index|]
operator|=
name|cursor
operator|->
name|data
expr_stmt|;
block|}
block|}
block|}
return|return
name|counter
return|;
block|}
end_function

begin_comment
comment|/* Call a PROCESSOR function for each entry of a hash table, and return the    number of entries for which the processor function returned success.  A    pointer to some PROCESSOR_DATA which will be made available to each call to    the processor function.  The PROCESSOR accepts two arguments: the first is    the user entry being walked into, the second is the value of PROCESSOR_DATA    as received.  The walking continue for as long as the PROCESSOR function    returns nonzero.  When it returns zero, the walking is interrupted.  */
end_comment

begin_function
name|unsigned
name|hash_do_for_each
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|,
name|Hash_processor
name|processor
parameter_list|,
name|void
modifier|*
name|processor_data
parameter_list|)
block|{
name|unsigned
name|counter
init|=
literal|0
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|cursor
decl_stmt|;
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
block|{
if|if
condition|(
name|bucket
operator|->
name|data
condition|)
block|{
for|for
control|(
name|cursor
operator|=
name|bucket
init|;
name|cursor
condition|;
name|cursor
operator|=
name|cursor
operator|->
name|next
control|)
block|{
if|if
condition|(
operator|!
call|(
modifier|*
name|processor
call|)
argument_list|(
name|cursor
operator|->
name|data
argument_list|,
name|processor_data
argument_list|)
condition|)
return|return
name|counter
return|;
name|counter
operator|++
expr_stmt|;
block|}
block|}
block|}
return|return
name|counter
return|;
block|}
end_function

begin_comment
comment|/* Allocation and clean-up.  */
end_comment

begin_comment
comment|/* Return a hash index for a NUL-terminated STRING between 0 and N_BUCKETS-1.    This is a convenience routine for constructing other hashing functions.  */
end_comment

begin_if
if|#
directive|if
name|USE_DIFF_HASH
end_if

begin_comment
comment|/* About hashings, Paul Eggert writes to me (FP), on 1994-01-01: "Please see    B. J. McKenzie, R. Harries& T. Bell, Selecting a hashing algorithm,    Software--practice& experience 20, 2 (Feb 1990), 209-224.  Good hash    algorithms tend to be domain-specific, so what's good for [diffutils'] io.c    may not be good for your application."  */
end_comment

begin_function
name|unsigned
name|hash_string
parameter_list|(
specifier|const
name|char
modifier|*
name|string
parameter_list|,
name|unsigned
name|n_buckets
parameter_list|)
block|{
ifndef|#
directive|ifndef
name|CHAR_BIT
define|#
directive|define
name|CHAR_BIT
value|8
endif|#
directive|endif
define|#
directive|define
name|ROTATE_LEFT
parameter_list|(
name|Value
parameter_list|,
name|Shift
parameter_list|)
define|\
value|((Value)<< (Shift) | (Value)>> ((sizeof (unsigned) * CHAR_BIT) - (Shift)))
define|#
directive|define
name|HASH_ONE_CHAR
parameter_list|(
name|Value
parameter_list|,
name|Byte
parameter_list|)
define|\
value|((Byte) + ROTATE_LEFT (Value, 7))
name|unsigned
name|value
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
operator|*
name|string
condition|;
name|string
operator|++
control|)
name|value
operator|=
name|HASH_ONE_CHAR
argument_list|(
name|value
argument_list|,
operator|*
operator|(
specifier|const
name|unsigned
name|char
operator|*
operator|)
name|string
argument_list|)
expr_stmt|;
return|return
name|value
operator|%
name|n_buckets
return|;
undef|#
directive|undef
name|ROTATE_LEFT
undef|#
directive|undef
name|HASH_ONE_CHAR
block|}
end_function

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* not USE_DIFF_HASH */
end_comment

begin_comment
comment|/* This one comes from `recode', and performs a bit better than the above as    per a few experiments.  It is inspired from a hashing routine found in the    very old Cyber `snoop', itself written in typical Greg Mansfield style.    (By the way, what happened to this excellent man?  Is he still alive?)  */
end_comment

begin_function
name|unsigned
name|hash_string
parameter_list|(
specifier|const
name|char
modifier|*
name|string
parameter_list|,
name|unsigned
name|n_buckets
parameter_list|)
block|{
name|unsigned
name|value
init|=
literal|0
decl_stmt|;
while|while
condition|(
operator|*
name|string
condition|)
name|value
operator|=
operator|(
operator|(
name|value
operator|*
literal|31
operator|+
operator|(
name|int
operator|)
operator|*
operator|(
specifier|const
name|unsigned
name|char
operator|*
operator|)
name|string
operator|++
operator|)
operator|%
name|n_buckets
operator|)
expr_stmt|;
return|return
name|value
return|;
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* not USE_DIFF_HASH */
end_comment

begin_comment
comment|/* Return true if CANDIDATE is a prime number.  CANDIDATE should be an odd    number at least equal to 11.  */
end_comment

begin_function
specifier|static
name|bool
name|is_prime
parameter_list|(
name|unsigned
name|long
name|candidate
parameter_list|)
block|{
name|unsigned
name|long
name|divisor
init|=
literal|3
decl_stmt|;
name|unsigned
name|long
name|square
init|=
name|divisor
operator|*
name|divisor
decl_stmt|;
while|while
condition|(
name|square
operator|<
name|candidate
operator|&&
operator|(
name|candidate
operator|%
name|divisor
operator|)
condition|)
block|{
name|divisor
operator|++
expr_stmt|;
name|square
operator|+=
literal|4
operator|*
name|divisor
expr_stmt|;
name|divisor
operator|++
expr_stmt|;
block|}
return|return
operator|(
name|candidate
operator|%
name|divisor
condition|?
name|true
else|:
name|false
operator|)
return|;
block|}
end_function

begin_comment
comment|/* Round a given CANDIDATE number up to the nearest prime, and return that    prime.  Primes lower than 10 are merely skipped.  */
end_comment

begin_function
specifier|static
name|unsigned
name|long
name|next_prime
parameter_list|(
name|unsigned
name|long
name|candidate
parameter_list|)
block|{
comment|/* Skip small primes.  */
if|if
condition|(
name|candidate
operator|<
literal|10
condition|)
name|candidate
operator|=
literal|10
expr_stmt|;
comment|/* Make it definitely odd.  */
name|candidate
operator||=
literal|1
expr_stmt|;
while|while
condition|(
operator|!
name|is_prime
argument_list|(
name|candidate
argument_list|)
condition|)
name|candidate
operator|+=
literal|2
expr_stmt|;
return|return
name|candidate
return|;
block|}
end_function

begin_function
name|void
name|hash_reset_tuning
parameter_list|(
name|Hash_tuning
modifier|*
name|tuning
parameter_list|)
block|{
operator|*
name|tuning
operator|=
name|default_tuning
expr_stmt|;
block|}
end_function

begin_comment
comment|/* For the given hash TABLE, check the user supplied tuning structure for    reasonable values, and return true if there is no gross error with it.    Otherwise, definitively reset the TUNING field to some acceptable default    in the hash table (that is, the user loses the right of further modifying    tuning arguments), and return false.  */
end_comment

begin_function
specifier|static
name|bool
name|check_tuning
parameter_list|(
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
specifier|const
name|Hash_tuning
modifier|*
name|tuning
init|=
name|table
operator|->
name|tuning
decl_stmt|;
if|if
condition|(
name|tuning
operator|->
name|growth_threshold
operator|>
literal|0.0
operator|&&
name|tuning
operator|->
name|growth_threshold
operator|<
literal|1.0
operator|&&
name|tuning
operator|->
name|growth_factor
operator|>
literal|1.0
operator|&&
name|tuning
operator|->
name|shrink_threshold
operator|>=
literal|0.0
operator|&&
name|tuning
operator|->
name|shrink_threshold
operator|<
literal|1.0
operator|&&
name|tuning
operator|->
name|shrink_factor
operator|>
name|tuning
operator|->
name|shrink_threshold
operator|&&
name|tuning
operator|->
name|shrink_factor
operator|<=
literal|1.0
operator|&&
name|tuning
operator|->
name|shrink_threshold
operator|<
name|tuning
operator|->
name|growth_threshold
condition|)
return|return
name|true
return|;
name|table
operator|->
name|tuning
operator|=
operator|&
name|default_tuning
expr_stmt|;
return|return
name|false
return|;
block|}
end_function

begin_comment
comment|/* Allocate and return a new hash table, or NULL upon failure.  The initial    number of buckets is automatically selected so as to _guarantee_ that you    may insert at least CANDIDATE different user entries before any growth of    the hash table size occurs.  So, if have a reasonably tight a-priori upper    bound on the number of entries you intend to insert in the hash table, you    may save some table memory and insertion time, by specifying it here.  If    the IS_N_BUCKETS field of the TUNING structure is true, the CANDIDATE    argument has its meaning changed to the wanted number of buckets.     TUNING points to a structure of user-supplied values, in case some fine    tuning is wanted over the default behavior of the hasher.  If TUNING is    NULL, the default tuning parameters are used instead.     The user-supplied HASHER function should be provided.  It accepts two    arguments ENTRY and TABLE_SIZE.  It computes, by hashing ENTRY contents, a    slot number for that entry which should be in the range 0..TABLE_SIZE-1.    This slot number is then returned.     The user-supplied COMPARATOR function should be provided.  It accepts two    arguments pointing to user data, it then returns true for a pair of entries    that compare equal, or false otherwise.  This function is internally called    on entries which are already known to hash to the same bucket index.     The user-supplied DATA_FREER function, when not NULL, may be later called    with the user data as an argument, just before the entry containing the    data gets freed.  This happens from within `hash_free' or `hash_clear'.    You should specify this function only if you want these functions to free    all of your `data' data.  This is typically the case when your data is    simply an auxiliary struct that you have malloc'd to aggregate several    values.  */
end_comment

begin_function
name|Hash_table
modifier|*
name|hash_initialize
parameter_list|(
name|unsigned
name|candidate
parameter_list|,
specifier|const
name|Hash_tuning
modifier|*
name|tuning
parameter_list|,
name|Hash_hasher
name|hasher
parameter_list|,
name|Hash_comparator
name|comparator
parameter_list|,
name|Hash_data_freer
name|data_freer
parameter_list|)
block|{
name|Hash_table
modifier|*
name|table
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
if|if
condition|(
name|hasher
operator|==
name|NULL
operator|||
name|comparator
operator|==
name|NULL
condition|)
return|return
name|NULL
return|;
name|table
operator|=
operator|(
name|Hash_table
operator|*
operator|)
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
name|Hash_table
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|table
operator|==
name|NULL
condition|)
return|return
name|NULL
return|;
if|if
condition|(
operator|!
name|tuning
condition|)
name|tuning
operator|=
operator|&
name|default_tuning
expr_stmt|;
name|table
operator|->
name|tuning
operator|=
name|tuning
expr_stmt|;
if|if
condition|(
operator|!
name|check_tuning
argument_list|(
name|table
argument_list|)
condition|)
block|{
comment|/* Fail if the tuning options are invalid.  This is the only occasion 	 when the user gets some feedback about it.  Once the table is created, 	 if the user provides invalid tuning options, we silently revert to 	 using the defaults, and ignore further request to change the tuning 	 options.  */
name|free
argument_list|(
name|table
argument_list|)
expr_stmt|;
return|return
name|NULL
return|;
block|}
name|table
operator|->
name|n_buckets
operator|=
name|next_prime
argument_list|(
name|tuning
operator|->
name|is_n_buckets
condition|?
name|candidate
else|:
call|(
name|unsigned
call|)
argument_list|(
name|candidate
operator|/
name|tuning
operator|->
name|growth_threshold
argument_list|)
argument_list|)
expr_stmt|;
name|table
operator|->
name|bucket
operator|=
operator|(
expr|struct
name|hash_entry
operator|*
operator|)
name|malloc
argument_list|(
name|table
operator|->
name|n_buckets
operator|*
sizeof|sizeof
argument_list|(
expr|struct
name|hash_entry
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|table
operator|->
name|bucket
operator|==
name|NULL
condition|)
block|{
name|free
argument_list|(
name|table
argument_list|)
expr_stmt|;
return|return
name|NULL
return|;
block|}
name|table
operator|->
name|bucket_limit
operator|=
name|table
operator|->
name|bucket
operator|+
name|table
operator|->
name|n_buckets
expr_stmt|;
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
block|{
name|bucket
operator|->
name|data
operator|=
name|NULL
expr_stmt|;
name|bucket
operator|->
name|next
operator|=
name|NULL
expr_stmt|;
block|}
name|table
operator|->
name|n_buckets_used
operator|=
literal|0
expr_stmt|;
name|table
operator|->
name|n_entries
operator|=
literal|0
expr_stmt|;
name|table
operator|->
name|hasher
operator|=
name|hasher
expr_stmt|;
name|table
operator|->
name|comparator
operator|=
name|comparator
expr_stmt|;
name|table
operator|->
name|data_freer
operator|=
name|data_freer
expr_stmt|;
name|table
operator|->
name|free_entry_list
operator|=
name|NULL
expr_stmt|;
if|#
directive|if
name|USE_OBSTACK
name|obstack_init
argument_list|(
operator|&
name|table
operator|->
name|entry_stack
argument_list|)
expr_stmt|;
endif|#
directive|endif
return|return
name|table
return|;
block|}
end_function

begin_comment
comment|/* Make all buckets empty, placing any chained entries on the free list.    Apply the user-specified function data_freer (if any) to the datas of any    affected entries.  */
end_comment

begin_function
name|void
name|hash_clear
parameter_list|(
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|cursor
decl_stmt|;
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
block|{
if|if
condition|(
name|bucket
operator|->
name|data
condition|)
block|{
comment|/* Free the bucket overflow.  */
for|for
control|(
name|cursor
operator|=
name|bucket
operator|->
name|next
init|;
name|cursor
condition|;
name|cursor
operator|=
name|cursor
operator|->
name|next
control|)
block|{
if|if
condition|(
name|table
operator|->
name|data_freer
condition|)
call|(
modifier|*
name|table
operator|->
name|data_freer
call|)
argument_list|(
name|cursor
operator|->
name|data
argument_list|)
expr_stmt|;
name|cursor
operator|->
name|data
operator|=
name|NULL
expr_stmt|;
comment|/* Relinking is done one entry at a time, as it is to be expected 		 that overflows are either rare or short.  */
name|cursor
operator|->
name|next
operator|=
name|table
operator|->
name|free_entry_list
expr_stmt|;
name|table
operator|->
name|free_entry_list
operator|=
name|cursor
expr_stmt|;
block|}
comment|/* Free the bucket head.  */
if|if
condition|(
name|table
operator|->
name|data_freer
condition|)
call|(
modifier|*
name|table
operator|->
name|data_freer
call|)
argument_list|(
name|bucket
operator|->
name|data
argument_list|)
expr_stmt|;
name|bucket
operator|->
name|data
operator|=
name|NULL
expr_stmt|;
name|bucket
operator|->
name|next
operator|=
name|NULL
expr_stmt|;
block|}
block|}
name|table
operator|->
name|n_buckets_used
operator|=
literal|0
expr_stmt|;
name|table
operator|->
name|n_entries
operator|=
literal|0
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Reclaim all storage associated with a hash table.  If a data_freer    function has been supplied by the user when the hash table was created,    this function applies it to the data of each entry before freeing that    entry.  */
end_comment

begin_function
name|void
name|hash_free
parameter_list|(
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|cursor
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|next
decl_stmt|;
comment|/* Call the user data_freer function.  */
if|if
condition|(
name|table
operator|->
name|data_freer
operator|&&
name|table
operator|->
name|n_entries
condition|)
block|{
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
block|{
if|if
condition|(
name|bucket
operator|->
name|data
condition|)
block|{
for|for
control|(
name|cursor
operator|=
name|bucket
init|;
name|cursor
condition|;
name|cursor
operator|=
name|cursor
operator|->
name|next
control|)
block|{
call|(
modifier|*
name|table
operator|->
name|data_freer
call|)
argument_list|(
name|cursor
operator|->
name|data
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
if|#
directive|if
name|USE_OBSTACK
name|obstack_free
argument_list|(
operator|&
name|table
operator|->
name|entry_stack
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
else|#
directive|else
comment|/* Free all bucket overflowed entries.  */
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
block|{
for|for
control|(
name|cursor
operator|=
name|bucket
operator|->
name|next
init|;
name|cursor
condition|;
name|cursor
operator|=
name|next
control|)
block|{
name|next
operator|=
name|cursor
operator|->
name|next
expr_stmt|;
name|free
argument_list|(
name|cursor
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* Also reclaim the internal list of previously freed entries.  */
for|for
control|(
name|cursor
operator|=
name|table
operator|->
name|free_entry_list
init|;
name|cursor
condition|;
name|cursor
operator|=
name|next
control|)
block|{
name|next
operator|=
name|cursor
operator|->
name|next
expr_stmt|;
name|free
argument_list|(
name|cursor
argument_list|)
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* Free the remainder of the hash table structure.  */
name|free
argument_list|(
name|table
operator|->
name|bucket
argument_list|)
expr_stmt|;
name|free
argument_list|(
name|table
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* Insertion and deletion.  */
end_comment

begin_comment
comment|/* Get a new hash entry for a bucket overflow, possibly by reclying a    previously freed one.  If this is not possible, allocate a new one.  */
end_comment

begin_function
specifier|static
name|struct
name|hash_entry
modifier|*
name|allocate_entry
parameter_list|(
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
name|struct
name|hash_entry
modifier|*
name|new
decl_stmt|;
if|if
condition|(
name|table
operator|->
name|free_entry_list
condition|)
block|{
name|new
operator|=
name|table
operator|->
name|free_entry_list
expr_stmt|;
name|table
operator|->
name|free_entry_list
operator|=
name|new
operator|->
name|next
expr_stmt|;
block|}
else|else
block|{
if|#
directive|if
name|USE_OBSTACK
name|new
operator|=
operator|(
expr|struct
name|hash_entry
operator|*
operator|)
name|obstack_alloc
argument_list|(
operator|&
name|table
operator|->
name|entry_stack
argument_list|,
sizeof|sizeof
argument_list|(
expr|struct
name|hash_entry
argument_list|)
argument_list|)
expr_stmt|;
else|#
directive|else
name|new
operator|=
operator|(
expr|struct
name|hash_entry
operator|*
operator|)
name|malloc
argument_list|(
sizeof|sizeof
argument_list|(
expr|struct
name|hash_entry
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
block|}
return|return
name|new
return|;
block|}
end_function

begin_comment
comment|/* Free a hash entry which was part of some bucket overflow,    saving it for later recycling.  */
end_comment

begin_function
specifier|static
name|void
name|free_entry
parameter_list|(
name|Hash_table
modifier|*
name|table
parameter_list|,
name|struct
name|hash_entry
modifier|*
name|entry
parameter_list|)
block|{
name|entry
operator|->
name|data
operator|=
name|NULL
expr_stmt|;
name|entry
operator|->
name|next
operator|=
name|table
operator|->
name|free_entry_list
expr_stmt|;
name|table
operator|->
name|free_entry_list
operator|=
name|entry
expr_stmt|;
block|}
end_function

begin_comment
comment|/* This private function is used to help with insertion and deletion.  When    ENTRY matches an entry in the table, return a pointer to the corresponding    user data and set *BUCKET_HEAD to the head of the selected bucket.    Otherwise, return NULL.  When DELETE is true and ENTRY matches an entry in    the table, unlink the matching entry.  */
end_comment

begin_function
specifier|static
name|void
modifier|*
name|hash_find_entry
parameter_list|(
name|Hash_table
modifier|*
name|table
parameter_list|,
specifier|const
name|void
modifier|*
name|entry
parameter_list|,
name|struct
name|hash_entry
modifier|*
modifier|*
name|bucket_head
parameter_list|,
name|bool
name|delete
parameter_list|)
block|{
name|struct
name|hash_entry
modifier|*
name|bucket
init|=
name|table
operator|->
name|bucket
operator|+
name|table
operator|->
name|hasher
argument_list|(
name|entry
argument_list|,
name|table
operator|->
name|n_buckets
argument_list|)
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|cursor
decl_stmt|;
name|assert
argument_list|(
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
argument_list|)
expr_stmt|;
operator|*
name|bucket_head
operator|=
name|bucket
expr_stmt|;
comment|/* Test for empty bucket.  */
if|if
condition|(
name|bucket
operator|->
name|data
operator|==
name|NULL
condition|)
return|return
name|NULL
return|;
comment|/* See if the entry is the first in the bucket.  */
if|if
condition|(
call|(
modifier|*
name|table
operator|->
name|comparator
call|)
argument_list|(
name|entry
argument_list|,
name|bucket
operator|->
name|data
argument_list|)
condition|)
block|{
name|void
modifier|*
name|data
init|=
name|bucket
operator|->
name|data
decl_stmt|;
if|if
condition|(
name|delete
condition|)
block|{
if|if
condition|(
name|bucket
operator|->
name|next
condition|)
block|{
name|struct
name|hash_entry
modifier|*
name|next
init|=
name|bucket
operator|->
name|next
decl_stmt|;
comment|/* Bump the first overflow entry into the bucket head, then save 		 the previous first overflow entry for later recycling.  */
operator|*
name|bucket
operator|=
operator|*
name|next
expr_stmt|;
name|free_entry
argument_list|(
name|table
argument_list|,
name|next
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|bucket
operator|->
name|data
operator|=
name|NULL
expr_stmt|;
block|}
block|}
return|return
name|data
return|;
block|}
comment|/* Scan the bucket overflow.  */
for|for
control|(
name|cursor
operator|=
name|bucket
init|;
name|cursor
operator|->
name|next
condition|;
name|cursor
operator|=
name|cursor
operator|->
name|next
control|)
block|{
if|if
condition|(
call|(
modifier|*
name|table
operator|->
name|comparator
call|)
argument_list|(
name|entry
argument_list|,
name|cursor
operator|->
name|next
operator|->
name|data
argument_list|)
condition|)
block|{
name|void
modifier|*
name|data
init|=
name|cursor
operator|->
name|next
operator|->
name|data
decl_stmt|;
if|if
condition|(
name|delete
condition|)
block|{
name|struct
name|hash_entry
modifier|*
name|next
init|=
name|cursor
operator|->
name|next
decl_stmt|;
comment|/* Unlink the entry to delete, then save the freed entry for later 		 recycling.  */
name|cursor
operator|->
name|next
operator|=
name|next
operator|->
name|next
expr_stmt|;
name|free_entry
argument_list|(
name|table
argument_list|,
name|next
argument_list|)
expr_stmt|;
block|}
return|return
name|data
return|;
block|}
block|}
comment|/* No entry found.  */
return|return
name|NULL
return|;
block|}
end_function

begin_comment
comment|/* For an already existing hash table, change the number of buckets through    specifying CANDIDATE.  The contents of the hash table are preserved.  The    new number of buckets is automatically selected so as to _guarantee_ that    the table may receive at least CANDIDATE different user entries, including    those already in the table, before any other growth of the hash table size    occurs.  If TUNING->IS_N_BUCKETS is true, then CANDIDATE specifies the    exact number of buckets desired.  */
end_comment

begin_function
name|bool
name|hash_rehash
parameter_list|(
name|Hash_table
modifier|*
name|table
parameter_list|,
name|unsigned
name|candidate
parameter_list|)
block|{
name|Hash_table
modifier|*
name|new_table
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|cursor
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|next
decl_stmt|;
name|new_table
operator|=
name|hash_initialize
argument_list|(
name|candidate
argument_list|,
name|table
operator|->
name|tuning
argument_list|,
name|table
operator|->
name|hasher
argument_list|,
name|table
operator|->
name|comparator
argument_list|,
name|table
operator|->
name|data_freer
argument_list|)
expr_stmt|;
if|if
condition|(
name|new_table
operator|==
name|NULL
condition|)
return|return
name|false
return|;
comment|/* Merely reuse the extra old space into the new table.  */
if|#
directive|if
name|USE_OBSTACK
name|obstack_free
argument_list|(
operator|&
name|new_table
operator|->
name|entry_stack
argument_list|,
name|NULL
argument_list|)
expr_stmt|;
name|new_table
operator|->
name|entry_stack
operator|=
name|table
operator|->
name|entry_stack
expr_stmt|;
endif|#
directive|endif
name|new_table
operator|->
name|free_entry_list
operator|=
name|table
operator|->
name|free_entry_list
expr_stmt|;
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
if|if
condition|(
name|bucket
operator|->
name|data
condition|)
for|for
control|(
name|cursor
operator|=
name|bucket
init|;
name|cursor
condition|;
name|cursor
operator|=
name|next
control|)
block|{
name|void
modifier|*
name|data
init|=
name|cursor
operator|->
name|data
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|new_bucket
init|=
operator|(
name|new_table
operator|->
name|bucket
operator|+
name|new_table
operator|->
name|hasher
argument_list|(
name|data
argument_list|,
name|new_table
operator|->
name|n_buckets
argument_list|)
operator|)
decl_stmt|;
name|assert
argument_list|(
name|new_bucket
operator|<
name|new_table
operator|->
name|bucket_limit
argument_list|)
expr_stmt|;
name|next
operator|=
name|cursor
operator|->
name|next
expr_stmt|;
if|if
condition|(
name|new_bucket
operator|->
name|data
condition|)
block|{
if|if
condition|(
name|cursor
operator|==
name|bucket
condition|)
block|{
comment|/* Allocate or recycle an entry, when moving from a bucket 		     header into a bucket overflow.  */
name|struct
name|hash_entry
modifier|*
name|new_entry
init|=
name|allocate_entry
argument_list|(
name|new_table
argument_list|)
decl_stmt|;
if|if
condition|(
name|new_entry
operator|==
name|NULL
condition|)
return|return
name|false
return|;
name|new_entry
operator|->
name|data
operator|=
name|data
expr_stmt|;
name|new_entry
operator|->
name|next
operator|=
name|new_bucket
operator|->
name|next
expr_stmt|;
name|new_bucket
operator|->
name|next
operator|=
name|new_entry
expr_stmt|;
block|}
else|else
block|{
comment|/* Merely relink an existing entry, when moving from a 		     bucket overflow into a bucket overflow.  */
name|cursor
operator|->
name|next
operator|=
name|new_bucket
operator|->
name|next
expr_stmt|;
name|new_bucket
operator|->
name|next
operator|=
name|cursor
expr_stmt|;
block|}
block|}
else|else
block|{
comment|/* Free an existing entry, when moving from a bucket 		 overflow into a bucket header.  Also take care of the 		 simple case of moving from a bucket header into a bucket 		 header.  */
name|new_bucket
operator|->
name|data
operator|=
name|data
expr_stmt|;
name|new_table
operator|->
name|n_buckets_used
operator|++
expr_stmt|;
if|if
condition|(
name|cursor
operator|!=
name|bucket
condition|)
name|free_entry
argument_list|(
name|new_table
argument_list|,
name|cursor
argument_list|)
expr_stmt|;
block|}
block|}
name|free
argument_list|(
name|table
operator|->
name|bucket
argument_list|)
expr_stmt|;
name|table
operator|->
name|bucket
operator|=
name|new_table
operator|->
name|bucket
expr_stmt|;
name|table
operator|->
name|bucket_limit
operator|=
name|new_table
operator|->
name|bucket_limit
expr_stmt|;
name|table
operator|->
name|n_buckets
operator|=
name|new_table
operator|->
name|n_buckets
expr_stmt|;
name|table
operator|->
name|n_buckets_used
operator|=
name|new_table
operator|->
name|n_buckets_used
expr_stmt|;
name|table
operator|->
name|free_entry_list
operator|=
name|new_table
operator|->
name|free_entry_list
expr_stmt|;
comment|/* table->n_entries already holds its value.  */
if|#
directive|if
name|USE_OBSTACK
name|table
operator|->
name|entry_stack
operator|=
name|new_table
operator|->
name|entry_stack
expr_stmt|;
endif|#
directive|endif
name|free
argument_list|(
name|new_table
argument_list|)
expr_stmt|;
return|return
name|true
return|;
block|}
end_function

begin_comment
comment|/* If ENTRY matches an entry already in the hash table, return the pointer    to the entry from the table.  Otherwise, insert ENTRY and return ENTRY.    Return NULL if the storage required for insertion cannot be allocated.  */
end_comment

begin_function
name|void
modifier|*
name|hash_insert
parameter_list|(
name|Hash_table
modifier|*
name|table
parameter_list|,
specifier|const
name|void
modifier|*
name|entry
parameter_list|)
block|{
name|void
modifier|*
name|data
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
name|assert
argument_list|(
name|entry
argument_list|)
expr_stmt|;
comment|/* cannot insert a NULL entry */
comment|/* If there's a matching entry already in the table, return that.  */
if|if
condition|(
operator|(
name|data
operator|=
name|hash_find_entry
argument_list|(
name|table
argument_list|,
name|entry
argument_list|,
operator|&
name|bucket
argument_list|,
name|false
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
return|return
name|data
return|;
comment|/* ENTRY is not matched, it should be inserted.  */
if|if
condition|(
name|bucket
operator|->
name|data
condition|)
block|{
name|struct
name|hash_entry
modifier|*
name|new_entry
init|=
name|allocate_entry
argument_list|(
name|table
argument_list|)
decl_stmt|;
if|if
condition|(
name|new_entry
operator|==
name|NULL
condition|)
return|return
name|NULL
return|;
comment|/* Add ENTRY in the overflow of the bucket.  */
name|new_entry
operator|->
name|data
operator|=
operator|(
name|void
operator|*
operator|)
name|entry
expr_stmt|;
name|new_entry
operator|->
name|next
operator|=
name|bucket
operator|->
name|next
expr_stmt|;
name|bucket
operator|->
name|next
operator|=
name|new_entry
expr_stmt|;
name|table
operator|->
name|n_entries
operator|++
expr_stmt|;
return|return
operator|(
name|void
operator|*
operator|)
name|entry
return|;
block|}
comment|/* Add ENTRY right in the bucket head.  */
name|bucket
operator|->
name|data
operator|=
operator|(
name|void
operator|*
operator|)
name|entry
expr_stmt|;
name|table
operator|->
name|n_entries
operator|++
expr_stmt|;
name|table
operator|->
name|n_buckets_used
operator|++
expr_stmt|;
comment|/* If the growth threshold of the buckets in use has been reached, increase      the table size and rehash.  There's no point in checking the number of      entries:  if the hashing function is ill-conditioned, rehashing is not      likely to improve it.  */
if|if
condition|(
name|table
operator|->
name|n_buckets_used
operator|>
name|table
operator|->
name|tuning
operator|->
name|growth_threshold
operator|*
name|table
operator|->
name|n_buckets
condition|)
block|{
comment|/* Check more fully, before starting real work.  If tuning arguments 	 became invalid, the second check will rely on proper defaults.  */
name|check_tuning
argument_list|(
name|table
argument_list|)
expr_stmt|;
if|if
condition|(
name|table
operator|->
name|n_buckets_used
operator|>
name|table
operator|->
name|tuning
operator|->
name|growth_threshold
operator|*
name|table
operator|->
name|n_buckets
condition|)
block|{
specifier|const
name|Hash_tuning
modifier|*
name|tuning
init|=
name|table
operator|->
name|tuning
decl_stmt|;
name|unsigned
name|candidate
init|=
call|(
name|unsigned
call|)
argument_list|(
name|tuning
operator|->
name|is_n_buckets
condition|?
operator|(
name|table
operator|->
name|n_buckets
operator|*
name|tuning
operator|->
name|growth_factor
operator|)
else|:
operator|(
name|table
operator|->
name|n_buckets
operator|*
name|tuning
operator|->
name|growth_factor
operator|*
name|tuning
operator|->
name|growth_threshold
operator|)
argument_list|)
decl_stmt|;
comment|/* If the rehash fails, arrange to return NULL.  */
if|if
condition|(
operator|!
name|hash_rehash
argument_list|(
name|table
argument_list|,
name|candidate
argument_list|)
condition|)
name|entry
operator|=
name|NULL
expr_stmt|;
block|}
block|}
return|return
operator|(
name|void
operator|*
operator|)
name|entry
return|;
block|}
end_function

begin_comment
comment|/* If ENTRY is already in the table, remove it and return the just-deleted    data (the user may want to deallocate its storage).  If ENTRY is not in the    table, don't modify the table and return NULL.  */
end_comment

begin_function
name|void
modifier|*
name|hash_delete
parameter_list|(
name|Hash_table
modifier|*
name|table
parameter_list|,
specifier|const
name|void
modifier|*
name|entry
parameter_list|)
block|{
name|void
modifier|*
name|data
decl_stmt|;
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
name|data
operator|=
name|hash_find_entry
argument_list|(
name|table
argument_list|,
name|entry
argument_list|,
operator|&
name|bucket
argument_list|,
name|true
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|data
condition|)
return|return
name|NULL
return|;
name|table
operator|->
name|n_entries
operator|--
expr_stmt|;
if|if
condition|(
operator|!
name|bucket
operator|->
name|data
condition|)
block|{
name|table
operator|->
name|n_buckets_used
operator|--
expr_stmt|;
comment|/* If the shrink threshold of the buckets in use has been reached, 	 rehash into a smaller table.  */
if|if
condition|(
name|table
operator|->
name|n_buckets_used
operator|<
name|table
operator|->
name|tuning
operator|->
name|shrink_threshold
operator|*
name|table
operator|->
name|n_buckets
condition|)
block|{
comment|/* Check more fully, before starting real work.  If tuning arguments 	     became invalid, the second check will rely on proper defaults.  */
name|check_tuning
argument_list|(
name|table
argument_list|)
expr_stmt|;
if|if
condition|(
name|table
operator|->
name|n_buckets_used
operator|<
name|table
operator|->
name|tuning
operator|->
name|shrink_threshold
operator|*
name|table
operator|->
name|n_buckets
condition|)
block|{
specifier|const
name|Hash_tuning
modifier|*
name|tuning
init|=
name|table
operator|->
name|tuning
decl_stmt|;
name|unsigned
name|candidate
init|=
call|(
name|unsigned
call|)
argument_list|(
name|tuning
operator|->
name|is_n_buckets
condition|?
name|table
operator|->
name|n_buckets
operator|*
name|tuning
operator|->
name|shrink_factor
else|:
operator|(
name|table
operator|->
name|n_buckets
operator|*
name|tuning
operator|->
name|shrink_factor
operator|*
name|tuning
operator|->
name|growth_threshold
operator|)
argument_list|)
decl_stmt|;
name|hash_rehash
argument_list|(
name|table
argument_list|,
name|candidate
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|data
return|;
block|}
end_function

begin_comment
comment|/* Testing.  */
end_comment

begin_if
if|#
directive|if
name|TESTING
end_if

begin_function
name|void
name|hash_print
parameter_list|(
specifier|const
name|Hash_table
modifier|*
name|table
parameter_list|)
block|{
name|struct
name|hash_entry
modifier|*
name|bucket
decl_stmt|;
for|for
control|(
name|bucket
operator|=
name|table
operator|->
name|bucket
init|;
name|bucket
operator|<
name|table
operator|->
name|bucket_limit
condition|;
name|bucket
operator|++
control|)
block|{
name|struct
name|hash_entry
modifier|*
name|cursor
decl_stmt|;
if|if
condition|(
name|bucket
condition|)
name|printf
argument_list|(
literal|"%d:\n"
argument_list|,
name|slot
argument_list|)
expr_stmt|;
for|for
control|(
name|cursor
operator|=
name|bucket
init|;
name|cursor
condition|;
name|cursor
operator|=
name|cursor
operator|->
name|next
control|)
block|{
name|char
modifier|*
name|s
init|=
operator|(
name|char
operator|*
operator|)
name|cursor
operator|->
name|data
decl_stmt|;
comment|/* FIXME */
name|printf
argument_list|(
literal|"  %s\n"
argument_list|,
name|s
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* TESTING */
end_comment

end_unit

