begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * Copyright (c) 2001 Daniel Eischen<deischen@freebsd.org>  * Copyright (c) 2000-2001 Jason Evans<jasone@freebsd.org>  * All rights reserved.  *  * Redistribution and use in source and binary forms, with or without  * modification, are permitted provided that the following conditions  * are met:  * 1. Redistributions of source code must retain the above copyright  *    notice, this list of conditions and the following disclaimer.  * 2. Redistributions in binary form must reproduce the above copyright  *    notice, this list of conditions and the following disclaimer in the  *    documentation and/or other materials provided with the distribution.  *  * THIS SOFTWARE IS PROVIDED BY THE AUTHORS AND CONTRIBUTORS ``AS IS'' AND  * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE LIABLE  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS  * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF  * SUCH DAMAGE.  *  * $FreeBSD$  */
end_comment

begin_include
include|#
directive|include
file|<sys/types.h>
end_include

begin_include
include|#
directive|include
file|<sys/mman.h>
end_include

begin_include
include|#
directive|include
file|<sys/queue.h>
end_include

begin_include
include|#
directive|include
file|<stdlib.h>
end_include

begin_include
include|#
directive|include
file|<pthread.h>
end_include

begin_include
include|#
directive|include
file|"thr_private.h"
end_include

begin_comment
comment|/* Spare thread stack. */
end_comment

begin_struct
struct|struct
name|stack
block|{
name|LIST_ENTRY
argument_list|(
argument|stack
argument_list|)
name|qe
expr_stmt|;
comment|/* Stack queue linkage. */
name|size_t
name|stacksize
decl_stmt|;
comment|/* Stack size (rounded up). */
name|size_t
name|guardsize
decl_stmt|;
comment|/* Guard size. */
name|void
modifier|*
name|stackaddr
decl_stmt|;
comment|/* Stack address. */
block|}
struct|;
end_struct

begin_comment
comment|/*  * Default sized (stack and guard) spare stack queue.  Stacks are cached  * to avoid additional complexity managing mmap()ed stack regions.  Spare  * stacks are used in LIFO order to increase cache locality.  */
end_comment

begin_expr_stmt
specifier|static
name|LIST_HEAD
argument_list|(
argument_list|,
argument|stack
argument_list|)
name|dstackq
operator|=
name|LIST_HEAD_INITIALIZER
argument_list|(
name|dstackq
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/*  * Miscellaneous sized (non-default stack and/or guard) spare stack queue.  * Stacks are cached to avoid additional complexity managing mmap()ed  * stack regions.  This list is unordered, since ordering on both stack  * size and guard size would be more trouble than it's worth.  Stacks are  * allocated from this cache on a first size match basis.  */
end_comment

begin_expr_stmt
specifier|static
name|LIST_HEAD
argument_list|(
argument_list|,
argument|stack
argument_list|)
name|mstackq
operator|=
name|LIST_HEAD_INITIALIZER
argument_list|(
name|mstackq
argument_list|)
expr_stmt|;
end_expr_stmt

begin_comment
comment|/**  * Base address of the last stack allocated (including its red zone, if  * there is one).  Stacks are allocated contiguously, starting beyond the  * top of the main stack.  When a new stack is created, a red zone is  * typically created (actually, the red zone is simply left unmapped) above  * the top of the stack, such that the stack will not be able to grow all  * the way to the bottom of the next stack.  This isn't fool-proof.  It is  * possible for a stack to grow by a large amount, such that it grows into  * the next stack, and as long as the memory within the red zone is never  * accessed, nothing will prevent one thread stack from trouncing all over  * the next.  *  * low memory  *     . . . . . . . . . . . . . . . . . .   *    |                                   |  *    |             stack 3               | start of 3rd thread stack  *    +-----------------------------------+  *    |                                   |  *    |       Red Zone (guard page)       | red zone for 2nd thread  *    |                                   |  *    +-----------------------------------+  *    |  stack 2 - PTHREAD_STACK_DEFAULT  | top of 2nd thread stack  *    |                                   |  *    |                                   |  *    |                                   |  *    |                                   |  *    |             stack 2               |  *    +-----------------------------------+<-- start of 2nd thread stack  *    |                                   |  *    |       Red Zone                    | red zone for 1st thread  *    |                                   |  *    +-----------------------------------+  *    |  stack 1 - PTHREAD_STACK_DEFAULT  | top of 1st thread stack  *    |                                   |  *    |                                   |  *    |                                   |  *    |                                   |  *    |             stack 1               |  *    +-----------------------------------+<-- start of 1st thread stack  *    |                                   |   (initial value of last_stack)  *    |       Red Zone                    |  *    |                                   | red zone for main thread  *    +-----------------------------------+  *    | USRSTACK - PTHREAD_STACK_INITIAL  | top of main thread stack  *    |                                   | ^  *    |                                   | |  *    |                                   | |  *    |                                   | | stack growth  *    |                                   |  *    +-----------------------------------+<-- start of main thread stack  *                                              (USRSTACK)  * high memory  *  */
end_comment

begin_decl_stmt
specifier|static
name|void
modifier|*
name|last_stack
init|=
name|NULL
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * Round size up to the nearest multiple of  * _thr_page_size.  */
end_comment

begin_function
specifier|static
specifier|inline
name|size_t
name|round_up
parameter_list|(
name|size_t
name|size
parameter_list|)
block|{
if|if
condition|(
name|size
operator|%
name|_thr_page_size
operator|!=
literal|0
condition|)
name|size
operator|=
operator|(
operator|(
name|size
operator|/
name|_thr_page_size
operator|)
operator|+
literal|1
operator|)
operator|*
name|_thr_page_size
expr_stmt|;
return|return
name|size
return|;
block|}
end_function

begin_function
name|int
name|_thr_stack_alloc
parameter_list|(
name|struct
name|pthread_attr
modifier|*
name|attr
parameter_list|)
block|{
name|struct
name|stack
modifier|*
name|spare_stack
decl_stmt|;
name|struct
name|kse
modifier|*
name|curkse
decl_stmt|;
name|kse_critical_t
name|crit
decl_stmt|;
name|size_t
name|stacksize
decl_stmt|;
name|size_t
name|guardsize
decl_stmt|;
comment|/* 	 * Round up stack size to nearest multiple of _thr_page_size so 	 * that mmap() * will work.  If the stack size is not an even 	 * multiple, we end up initializing things such that there is 	 * unused space above the beginning of the stack, so the stack 	 * sits snugly against its guard. 	 */
name|stacksize
operator|=
name|round_up
argument_list|(
name|attr
operator|->
name|stacksize_attr
argument_list|)
expr_stmt|;
name|guardsize
operator|=
name|round_up
argument_list|(
name|attr
operator|->
name|guardsize_attr
argument_list|)
expr_stmt|;
name|attr
operator|->
name|stackaddr_attr
operator|=
name|NULL
expr_stmt|;
name|attr
operator|->
name|flags
operator|&=
operator|~
name|THR_STACK_USER
expr_stmt|;
comment|/* 	 * Use the garbage collector lock for synchronization of the 	 * spare stack lists and allocations from usrstack. 	 */
name|crit
operator|=
name|_kse_critical_enter
argument_list|()
expr_stmt|;
name|curkse
operator|=
name|_get_curkse
argument_list|()
expr_stmt|;
name|KSE_LOCK_ACQUIRE
argument_list|(
name|curkse
argument_list|,
operator|&
name|_thread_list_lock
argument_list|)
expr_stmt|;
comment|/* 	 * If the stack and guard sizes are default, try to allocate a stack 	 * from the default-size stack cache: 	 */
if|if
condition|(
operator|(
name|stacksize
operator|==
name|THR_STACK_DEFAULT
operator|)
operator|&&
operator|(
name|guardsize
operator|==
name|_thr_guard_default
operator|)
condition|)
block|{
if|if
condition|(
operator|(
name|spare_stack
operator|=
name|LIST_FIRST
argument_list|(
operator|&
name|dstackq
argument_list|)
operator|)
operator|!=
name|NULL
condition|)
block|{
comment|/* Use the spare stack. */
name|LIST_REMOVE
argument_list|(
name|spare_stack
argument_list|,
name|qe
argument_list|)
expr_stmt|;
name|attr
operator|->
name|stackaddr_attr
operator|=
name|spare_stack
operator|->
name|stackaddr
expr_stmt|;
block|}
block|}
comment|/* 	 * The user specified a non-default stack and/or guard size, so try to 	 * allocate a stack from the non-default size stack cache, using the 	 * rounded up stack size (stack_size) in the search: 	 */
else|else
block|{
name|LIST_FOREACH
argument_list|(
argument|spare_stack
argument_list|,
argument|&mstackq
argument_list|,
argument|qe
argument_list|)
block|{
if|if
condition|(
name|spare_stack
operator|->
name|stacksize
operator|==
name|stacksize
operator|&&
name|spare_stack
operator|->
name|guardsize
operator|==
name|guardsize
condition|)
block|{
name|LIST_REMOVE
argument_list|(
name|spare_stack
argument_list|,
name|qe
argument_list|)
expr_stmt|;
name|attr
operator|->
name|stackaddr_attr
operator|=
name|spare_stack
operator|->
name|stackaddr
expr_stmt|;
break|break;
block|}
block|}
block|}
if|if
condition|(
name|attr
operator|->
name|stackaddr_attr
operator|!=
name|NULL
condition|)
block|{
comment|/* A cached stack was found.  Release the lock. */
name|KSE_LOCK_RELEASE
argument_list|(
name|curkse
argument_list|,
operator|&
name|_thread_list_lock
argument_list|)
expr_stmt|;
name|_kse_critical_leave
argument_list|(
name|crit
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Allocate a stack from usrstack. */
if|if
condition|(
name|last_stack
operator|==
name|NULL
condition|)
name|last_stack
operator|=
name|_usrstack
operator|-
name|THR_STACK_INITIAL
operator|-
name|_thr_guard_default
expr_stmt|;
comment|/* Allocate a new stack. */
name|attr
operator|->
name|stackaddr_attr
operator|=
name|last_stack
operator|-
name|stacksize
expr_stmt|;
comment|/* 		 * Even if stack allocation fails, we don't want to try to 		 * use this location again, so unconditionally decrement 		 * last_stack.  Under normal operating conditions, the most 		 * likely reason for an mmap() error is a stack overflow of 		 * the adjacent thread stack. 		 */
name|last_stack
operator|-=
operator|(
name|stacksize
operator|+
name|guardsize
operator|)
expr_stmt|;
comment|/* Release the lock before mmap'ing it. */
name|KSE_LOCK_RELEASE
argument_list|(
name|curkse
argument_list|,
operator|&
name|_thread_list_lock
argument_list|)
expr_stmt|;
name|_kse_critical_leave
argument_list|(
name|crit
argument_list|)
expr_stmt|;
comment|/* Map the stack, but not the guard page: */
if|if
condition|(
operator|(
name|attr
operator|->
name|stackaddr_attr
operator|=
name|mmap
argument_list|(
name|attr
operator|->
name|stackaddr_attr
argument_list|,
name|stacksize
argument_list|,
name|PROT_READ
operator||
name|PROT_WRITE
argument_list|,
name|MAP_STACK
argument_list|,
operator|-
literal|1
argument_list|,
literal|0
argument_list|)
operator|)
operator|==
name|MAP_FAILED
condition|)
name|attr
operator|->
name|stackaddr_attr
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|attr
operator|->
name|stackaddr_attr
operator|!=
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
else|else
return|return
operator|(
operator|-
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/* This function must be called with _thread_list_lock held. */
end_comment

begin_function
name|void
name|_thr_stack_free
parameter_list|(
name|struct
name|pthread_attr
modifier|*
name|attr
parameter_list|)
block|{
name|struct
name|stack
modifier|*
name|spare_stack
decl_stmt|;
if|if
condition|(
operator|(
name|attr
operator|!=
name|NULL
operator|)
operator|&&
operator|(
operator|(
name|attr
operator|->
name|flags
operator|&
name|THR_STACK_USER
operator|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|attr
operator|->
name|stackaddr_attr
operator|!=
name|NULL
operator|)
condition|)
block|{
name|spare_stack
operator|=
operator|(
name|attr
operator|->
name|stackaddr_attr
operator|+
name|attr
operator|->
name|stacksize_attr
operator|-
sizeof|sizeof
argument_list|(
expr|struct
name|stack
argument_list|)
operator|)
expr_stmt|;
name|spare_stack
operator|->
name|stacksize
operator|=
name|round_up
argument_list|(
name|attr
operator|->
name|stacksize_attr
argument_list|)
expr_stmt|;
name|spare_stack
operator|->
name|guardsize
operator|=
name|round_up
argument_list|(
name|attr
operator|->
name|guardsize_attr
argument_list|)
expr_stmt|;
name|spare_stack
operator|->
name|stackaddr
operator|=
name|attr
operator|->
name|stackaddr_attr
expr_stmt|;
if|if
condition|(
name|spare_stack
operator|->
name|stacksize
operator|==
name|THR_STACK_DEFAULT
operator|&&
name|spare_stack
operator|->
name|guardsize
operator|==
name|_thr_guard_default
condition|)
block|{
comment|/* Default stack/guard size. */
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|dstackq
argument_list|,
name|spare_stack
argument_list|,
name|qe
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* Non-default stack/guard size. */
name|LIST_INSERT_HEAD
argument_list|(
operator|&
name|mstackq
argument_list|,
name|spare_stack
argument_list|,
name|qe
argument_list|)
expr_stmt|;
block|}
name|attr
operator|->
name|stackaddr_attr
operator|=
name|NULL
expr_stmt|;
block|}
block|}
end_function

end_unit

