begin_unit|revision:0.9.5;language:C;cregit-version:0.0.1
begin_comment
comment|/*  * Copyright (c) 1992, 1993  *	The Regents of the University of California.  All rights reserved.  *  * This software was developed by the Computer Systems Engineering group  * at Lawrence Berkeley Laboratory under DARPA contract BG 91-66 and  * contributed to Berkeley.  *  * All advertising materials mentioning features or use of this software  * must display the following acknowledgement:  *	This product includes software developed by the University of  *	California, Lawrence Berkeley Laboratory.  *  * %sccs.include.redist.c%  *  *	@(#)pmap.c	8.4 (Berkeley) %G%  *  * from: $Header: pmap.c,v 1.43 93/10/31 05:34:56 torek Exp $  */
end_comment

begin_comment
comment|/*  * SPARC physical map management code.  * Does not function on multiprocessors (yet).  */
end_comment

begin_include
include|#
directive|include
file|<sys/param.h>
end_include

begin_include
include|#
directive|include
file|<sys/systm.h>
end_include

begin_include
include|#
directive|include
file|<sys/device.h>
end_include

begin_include
include|#
directive|include
file|<sys/proc.h>
end_include

begin_include
include|#
directive|include
file|<sys/malloc.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_kern.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_prot.h>
end_include

begin_include
include|#
directive|include
file|<vm/vm_page.h>
end_include

begin_include
include|#
directive|include
file|<machine/autoconf.h>
end_include

begin_include
include|#
directive|include
file|<machine/bsd_openprom.h>
end_include

begin_include
include|#
directive|include
file|<machine/cpu.h>
end_include

begin_include
include|#
directive|include
file|<machine/ctlreg.h>
end_include

begin_include
include|#
directive|include
file|<sparc/sparc/asm.h>
end_include

begin_include
include|#
directive|include
file|<sparc/sparc/cache.h>
end_include

begin_include
include|#
directive|include
file|<sparc/sparc/vaddrs.h>
end_include

begin_ifdef
ifdef|#
directive|ifdef
name|DEBUG
end_ifdef

begin_define
define|#
directive|define
name|PTE_BITS
value|"\20\40V\37W\36S\35NC\33IO\32U\31M"
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_decl_stmt
specifier|extern
name|struct
name|promvec
modifier|*
name|promvec
decl_stmt|;
end_decl_stmt

begin_comment
comment|/*  * The SPARCstation offers us the following challenges:  *  *   1. A virtual address cache.  This is, strictly speaking, not  *	part of the architecture, but the code below assumes one.  *	This is a write-through cache on the 4c and a write-back cache  *	on others.  *  *   2. An MMU that acts like a cache.  There is not enough space  *	in the MMU to map everything all the time.  Instead, we need  *	to load MMU with the `working set' of translations for each  *	process.  *  *   3.	Segmented virtual and physical spaces.  The upper 12 bits of  *	a virtual address (the virtual segment) index a segment table,  *	giving a physical segment.  The physical segment selects a  *	`Page Map Entry Group' (PMEG) and the virtual page number---the  *	next 5 or 6 bits of the virtual address---select the particular  *	`Page Map Entry' for the page.  We call the latter a PTE and  *	call each Page Map Entry Group a pmeg (for want of a better name).  *  *	Since there are no valid bits in the segment table, the only way  *	to have an invalid segment is to make one full pmeg of invalid PTEs.  *	We use the last one (since the ROM does as well).  *  *   4. Discontiguous physical pages.  The Mach VM expects physical pages  *	to be in one sequential lump.  *  *   5. The MMU is always on: it is not possible to disable it.  This is  *	mainly a startup hassle.  */
end_comment

begin_struct
struct|struct
name|pmap_stats
block|{
name|int
name|ps_unlink_pvfirst
decl_stmt|;
comment|/* # of pv_unlinks on head */
name|int
name|ps_unlink_pvsearch
decl_stmt|;
comment|/* # of pv_unlink searches */
name|int
name|ps_changeprots
decl_stmt|;
comment|/* # of calls to changeprot */
name|int
name|ps_useless_changeprots
decl_stmt|;
comment|/* # of changeprots for wiring */
name|int
name|ps_enter_firstpv
decl_stmt|;
comment|/* pv heads entered */
name|int
name|ps_enter_secondpv
decl_stmt|;
comment|/* pv nonheads entered */
name|int
name|ps_useless_changewire
decl_stmt|;
comment|/* useless wiring changes */
name|int
name|ps_npg_prot_all
decl_stmt|;
comment|/* # of active pages protected */
name|int
name|ps_npg_prot_actual
decl_stmt|;
comment|/* # pages actually affected */
block|}
name|pmap_stats
struct|;
end_struct

begin_ifdef
ifdef|#
directive|ifdef
name|DEBUG
end_ifdef

begin_define
define|#
directive|define
name|PDB_CREATE
value|0x0001
end_define

begin_define
define|#
directive|define
name|PDB_DESTROY
value|0x0002
end_define

begin_define
define|#
directive|define
name|PDB_REMOVE
value|0x0004
end_define

begin_define
define|#
directive|define
name|PDB_CHANGEPROT
value|0x0008
end_define

begin_define
define|#
directive|define
name|PDB_ENTER
value|0x0010
end_define

begin_define
define|#
directive|define
name|PDB_MMU_ALLOC
value|0x0100
end_define

begin_define
define|#
directive|define
name|PDB_MMU_STEAL
value|0x0200
end_define

begin_define
define|#
directive|define
name|PDB_CTX_ALLOC
value|0x0400
end_define

begin_define
define|#
directive|define
name|PDB_CTX_STEAL
value|0x0800
end_define

begin_decl_stmt
name|int
name|pmapdebug
init|=
literal|0x0
decl_stmt|;
end_decl_stmt

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|splpmap
parameter_list|()
value|splimp()
end_define

begin_comment
comment|/*  * First and last managed physical addresses.  */
end_comment

begin_if
if|#
directive|if
literal|0
end_if

begin_define
unit|vm_offset_t	vm_first_phys, vm_last_phys;
define|#
directive|define
name|managed
parameter_list|(
name|pa
parameter_list|)
value|((pa)>= vm_first_phys&& (pa)< vm_last_phys)
end_define

begin_else
else|#
directive|else
end_else

begin_decl_stmt
name|vm_offset_t
name|vm_first_phys
decl_stmt|,
name|vm_num_phys
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|managed
parameter_list|(
name|pa
parameter_list|)
value|((unsigned)((pa) - vm_first_phys)< vm_num_phys)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * For each managed physical page, there is a list of all currently  * valid virtual mappings of that page.  Since there is usually one  * (or zero) mapping per page, the table begins with an initial entry,  * rather than a pointer; this head entry is empty iff its pv_pmap  * field is NULL.  *  * Note that these are per machine independent page (so there may be  * only one for every two hardware pages, e.g.).  Since the virtual  * address is aligned on a page boundary, the low order bits are free  * for storing flags.  Only the head of each list has flags.  *  * THIS SHOULD BE PART OF THE CORE MAP  */
end_comment

begin_struct
struct|struct
name|pvlist
block|{
name|struct
name|pvlist
modifier|*
name|pv_next
decl_stmt|;
comment|/* next pvlist, if any */
name|struct
name|pmap
modifier|*
name|pv_pmap
decl_stmt|;
comment|/* pmap of this va */
name|int
name|pv_va
decl_stmt|;
comment|/* virtual address */
name|int
name|pv_flags
decl_stmt|;
comment|/* flags (below) */
block|}
struct|;
end_struct

begin_comment
comment|/*  * Flags in pv_flags.  Note that PV_MOD must be 1 and PV_REF must be 2  * since they must line up with the bits in the hardware PTEs (see pte.h).  */
end_comment

begin_define
define|#
directive|define
name|PV_MOD
value|1
end_define

begin_comment
comment|/* page modified */
end_comment

begin_define
define|#
directive|define
name|PV_REF
value|2
end_define

begin_comment
comment|/* page referenced */
end_comment

begin_define
define|#
directive|define
name|PV_NC
value|4
end_define

begin_comment
comment|/* page cannot be cached */
end_comment

begin_comment
comment|/*efine	PV_ALLF	7		** all of the above */
end_comment

begin_decl_stmt
name|struct
name|pvlist
modifier|*
name|pv_table
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* array of entries, one per physical page */
end_comment

begin_define
define|#
directive|define
name|pvhead
parameter_list|(
name|pa
parameter_list|)
value|(&pv_table[atop((pa) - vm_first_phys)])
end_define

begin_comment
comment|/*  * Each virtual segment within each pmap is either valid or invalid.  * It is valid if pm_npte[VA_VSEG(va)] is not 0.  This does not mean  * it is in the MMU, however; that is true iff pm_segmap[VA_VSEG(va)]  * does not point to the invalid PMEG.  *  * If a virtual segment is valid and loaded, the correct PTEs appear  * in the MMU only.  If it is valid and unloaded, the correct PTEs appear  * in the pm_pte[VA_VSEG(va)] only.  However, some effort is made to keep  * the software copies consistent enough with the MMU so that libkvm can  * do user address translations.  In particular, pv_changepte() and  * pmap_enu() maintain consistency, while less critical changes are  * not maintained.  pm_pte[VA_VSEG(va)] always points to space for those  * PTEs, unless this is the kernel pmap, in which case pm_pte[x] is not  * used (sigh).  *  * Each PMEG in the MMU is either free or contains PTEs corresponding to  * some pmap and virtual segment.  If it contains some PTEs, it also contains  * reference and modify bits that belong in the pv_table.  If we need  * to steal a PMEG from some process (if we need one and none are free)  * we must copy the ref and mod bits, and update pm_segmap in the other  * pmap to show that its virtual segment is no longer in the MMU.  *  * There are 128 PMEGs in a small Sun-4, of which only a few dozen are  * tied down permanently, leaving `about' 100 to be spread among  * running processes.  These are managed as an LRU cache.  Before  * calling the VM paging code for a user page fault, the fault handler  * calls mmu_load(pmap, va) to try to get a set of PTEs put into the  * MMU.  mmu_load will check the validity of the segment and tell whether  * it did something.  *  * Since I hate the name PMEG I call this data structure an `mmu entry'.  * Each mmuentry is on exactly one of three `usage' lists: free, LRU,  * or locked.  The LRU list is for user processes; the locked list is  * for kernel entries; both are doubly linked queues headed by `mmuhd's.  * The free list is a simple list, headed by a free list pointer.  */
end_comment

begin_struct
struct|struct
name|mmuhd
block|{
name|struct
name|mmuentry
modifier|*
name|mh_next
decl_stmt|;
name|struct
name|mmuentry
modifier|*
name|mh_prev
decl_stmt|;
block|}
struct|;
end_struct

begin_struct
struct|struct
name|mmuentry
block|{
name|struct
name|mmuentry
modifier|*
name|me_next
decl_stmt|;
comment|/* queue (MUST BE FIRST) or next free */
name|struct
name|mmuentry
modifier|*
name|me_prev
decl_stmt|;
comment|/* queue (MUST BE FIRST) */
name|struct
name|pmap
modifier|*
name|me_pmap
decl_stmt|;
comment|/* pmap, if in use */
name|struct
name|mmuentry
modifier|*
name|me_pmforw
decl_stmt|;
comment|/* pmap pmeg chain */
name|struct
name|mmuentry
modifier|*
modifier|*
name|me_pmback
decl_stmt|;
comment|/* pmap pmeg chain */
name|u_short
name|me_vseg
decl_stmt|;
comment|/* virtual segment number in pmap */
name|pmeg_t
name|me_pmeg
decl_stmt|;
comment|/* hardware PMEG number */
block|}
struct|;
end_struct

begin_decl_stmt
name|struct
name|mmuentry
modifier|*
name|mmuentry
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* allocated in pmap_bootstrap */
end_comment

begin_decl_stmt
name|struct
name|mmuentry
modifier|*
name|me_freelist
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* free list (not a queue) */
end_comment

begin_decl_stmt
name|struct
name|mmuhd
name|me_lru
init|=
block|{
comment|/* LRU (user) entries */
operator|(
expr|struct
name|mmuentry
operator|*
operator|)
operator|&
name|me_lru
block|,
operator|(
expr|struct
name|mmuentry
operator|*
operator|)
operator|&
name|me_lru
block|}
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|struct
name|mmuhd
name|me_locked
init|=
block|{
comment|/* locked (kernel) entries */
operator|(
expr|struct
name|mmuentry
operator|*
operator|)
operator|&
name|me_locked
block|,
operator|(
expr|struct
name|mmuentry
operator|*
operator|)
operator|&
name|me_locked
block|}
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|seginval
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* the invalid segment number */
end_comment

begin_comment
comment|/*  * A context is simply a small number that dictates which set of 4096  * segment map entries the MMU uses.  The Sun 4c has eight such sets.  * These are alloted in an `almost MRU' fashion.  *  * Each context is either free or attached to a pmap.  *  * Since the virtual address cache is tagged by context, when we steal  * a context we have to flush (that part of) the cache.  */
end_comment

begin_union
union|union
name|ctxinfo
block|{
name|union
name|ctxinfo
modifier|*
name|c_nextfree
decl_stmt|;
comment|/* free list (if free) */
name|struct
name|pmap
modifier|*
name|c_pmap
decl_stmt|;
comment|/* pmap (if busy) */
block|}
union|;
end_union

begin_decl_stmt
name|union
name|ctxinfo
modifier|*
name|ctxinfo
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* allocated at in pmap_bootstrap */
end_comment

begin_decl_stmt
name|int
name|ncontext
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|union
name|ctxinfo
modifier|*
name|ctx_freelist
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* context free list */
end_comment

begin_decl_stmt
name|int
name|ctx_kick
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* allocation rover when none free */
end_comment

begin_decl_stmt
name|int
name|ctx_kickdir
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* ctx_kick roves both directions */
end_comment

begin_comment
comment|/* XXX need per-cpu vpage[]s (and vmempage, unless we lock in /dev/mem) */
end_comment

begin_decl_stmt
name|caddr_t
name|vpage
index|[
literal|2
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* two reserved MD virtual pages */
end_comment

begin_decl_stmt
name|caddr_t
name|vmempage
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* one reserved MI vpage for /dev/mem */
end_comment

begin_decl_stmt
name|caddr_t
name|vdumppages
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* 32KB worth of reserved dump pages */
end_comment

begin_decl_stmt
name|struct
name|kpmap
name|kernel_pmap_store
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* the kernel's pmap */
end_comment

begin_comment
comment|/*  * We need to know real physical memory ranges (for /dev/mem).  */
end_comment

begin_define
define|#
directive|define
name|MA_SIZE
value|32
end_define

begin_comment
comment|/* size of memory descriptor arrays */
end_comment

begin_decl_stmt
name|struct
name|memarr
name|pmemarr
index|[
name|MA_SIZE
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* physical memory regions */
end_comment

begin_decl_stmt
name|int
name|npmemarr
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* number of entries in pmemarr */
end_comment

begin_comment
comment|/*  * The following four global variables are set in pmap_bootstrap  * for the vm code to find.  This is Wrong.  */
end_comment

begin_decl_stmt
name|vm_offset_t
name|avail_start
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* first free physical page number */
end_comment

begin_decl_stmt
name|vm_offset_t
name|avail_end
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* last free physical page number */
end_comment

begin_decl_stmt
name|vm_offset_t
name|virtual_avail
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* first free virtual page number */
end_comment

begin_decl_stmt
name|vm_offset_t
name|virtual_end
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* last free virtual page number */
end_comment

begin_comment
comment|/*  * pseudo-functions for mnemonic value #ifdef notyet  * NB: setsegmap should be stba for 4c, but stha works and makes the  * code right for the Sun-4 as well. #endif  */
end_comment

begin_define
define|#
directive|define
name|getcontext
parameter_list|()
value|lduba(AC_CONTEXT, ASI_CONTROL)
end_define

begin_define
define|#
directive|define
name|setcontext
parameter_list|(
name|c
parameter_list|)
value|stba(AC_CONTEXT, ASI_CONTROL, c)
end_define

begin_ifdef
ifdef|#
directive|ifdef
name|notyet
end_ifdef

begin_define
define|#
directive|define
name|getsegmap
parameter_list|(
name|va
parameter_list|)
value|lduha(va, ASI_SEGMAP)
end_define

begin_define
define|#
directive|define
name|setsegmap
parameter_list|(
name|va
parameter_list|,
name|pmeg
parameter_list|)
value|stha(va, ASI_SEGMAP, pmeg)
end_define

begin_else
else|#
directive|else
end_else

begin_define
define|#
directive|define
name|getsegmap
parameter_list|(
name|va
parameter_list|)
value|lduba(va, ASI_SEGMAP)
end_define

begin_define
define|#
directive|define
name|setsegmap
parameter_list|(
name|va
parameter_list|,
name|pmeg
parameter_list|)
value|stba(va, ASI_SEGMAP, pmeg)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_define
define|#
directive|define
name|getpte
parameter_list|(
name|va
parameter_list|)
value|lda(va, ASI_PTE)
end_define

begin_define
define|#
directive|define
name|setpte
parameter_list|(
name|va
parameter_list|,
name|pte
parameter_list|)
value|sta(va, ASI_PTE, pte)
end_define

begin_comment
comment|/*----------------------------------------------------------------*/
end_comment

begin_ifdef
ifdef|#
directive|ifdef
name|sun4c
end_ifdef

begin_comment
comment|/*  * Translations from dense (contiguous) pseudo physical addresses  * (fed to the VM code, to keep it happy) to sparse (real, hardware)  * physical addresses.  We call the former `software' page frame  * numbers and the latter `hardware' page frame numbers.  The  * translation is done on a `per bank' basis.  *  * The HWTOSW and SWTOHW macros handle the actual translation.  * They are defined as no-ops on Sun-4s.  *  * SHOULD DO atop AND ptoa DIRECTLY IN THESE MACROS SINCE ALL CALLERS  * ALWAYS NEED THAT ANYWAY ... CAN JUST PRECOOK THE TABLES	(TODO)  *  * Since we cannot use the memory allocated to the ROM monitor, and  * this happens to be just under 64K, I have chosen a bank size of  * 64K.  This is necessary since all banks must be completely full.  * I have also chosen a physical memory limit of 128 MB.  The 4c is  * architecturally limited to 256 MB, but 128 MB is more than will  * fit on present hardware.  *  * XXX	FIX THIS: just make all of each bank available and then  *	take out the pages reserved to the monitor!!  */
end_comment

begin_define
define|#
directive|define
name|MAXMEM
value|(128 * 1024 * 1024)
end_define

begin_comment
comment|/* no more than 128 MB phys mem */
end_comment

begin_define
define|#
directive|define
name|NPGBANK
value|16
end_define

begin_comment
comment|/* 2^4 pages per bank (64K / bank) */
end_comment

begin_define
define|#
directive|define
name|BSHIFT
value|4
end_define

begin_comment
comment|/* log2(NPGBANK) */
end_comment

begin_define
define|#
directive|define
name|BOFFSET
value|(NPGBANK - 1)
end_define

begin_define
define|#
directive|define
name|BTSIZE
value|(MAXMEM / NBPG / NPGBANK)
end_define

begin_decl_stmt
name|int
name|pmap_dtos
index|[
name|BTSIZE
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* dense to sparse */
end_comment

begin_decl_stmt
name|int
name|pmap_stod
index|[
name|BTSIZE
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* sparse to dense */
end_comment

begin_define
define|#
directive|define
name|HWTOSW
parameter_list|(
name|pg
parameter_list|)
value|(pmap_stod[(pg)>> BSHIFT] | ((pg)& BOFFSET))
end_define

begin_define
define|#
directive|define
name|SWTOHW
parameter_list|(
name|pg
parameter_list|)
value|(pmap_dtos[(pg)>> BSHIFT] | ((pg)& BOFFSET))
end_define

begin_comment
comment|/*  * Sort a memory array by address.  */
end_comment

begin_function
specifier|static
name|void
name|sortm
parameter_list|(
name|mp
parameter_list|,
name|n
parameter_list|)
specifier|register
name|struct
name|memarr
modifier|*
name|mp
decl_stmt|;
specifier|register
name|int
name|n
decl_stmt|;
block|{
specifier|register
name|struct
name|memarr
modifier|*
name|mpj
decl_stmt|;
specifier|register
name|int
name|i
decl_stmt|,
name|j
decl_stmt|;
specifier|register
name|u_int
name|addr
decl_stmt|,
name|len
decl_stmt|;
comment|/* Insertion sort.  This is O(n^2), but so what? */
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|n
condition|;
name|i
operator|++
control|)
block|{
comment|/* save i'th entry */
name|addr
operator|=
name|mp
index|[
name|i
index|]
operator|.
name|addr
expr_stmt|;
name|len
operator|=
name|mp
index|[
name|i
index|]
operator|.
name|len
expr_stmt|;
comment|/* find j such that i'th entry goes before j'th */
for|for
control|(
name|j
operator|=
literal|0
operator|,
name|mpj
operator|=
name|mp
init|;
name|j
operator|<
name|i
condition|;
name|j
operator|++
operator|,
name|mpj
operator|++
control|)
if|if
condition|(
name|addr
operator|<
name|mpj
operator|->
name|addr
condition|)
break|break;
comment|/* slide up any additional entries */
name|ovbcopy
argument_list|(
name|mpj
argument_list|,
name|mpj
operator|+
literal|1
argument_list|,
operator|(
name|i
operator|-
name|j
operator|)
operator|*
sizeof|sizeof
argument_list|(
operator|*
name|mp
argument_list|)
argument_list|)
expr_stmt|;
name|mpj
operator|->
name|addr
operator|=
name|addr
expr_stmt|;
name|mpj
operator|->
name|len
operator|=
name|len
expr_stmt|;
block|}
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|DEBUG
end_ifdef

begin_decl_stmt
name|struct
name|memarr
name|pmap_ama
index|[
name|MA_SIZE
index|]
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|pmap_nama
decl_stmt|;
end_decl_stmt

begin_define
define|#
directive|define
name|ama
value|pmap_ama
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * init_translations sets up pmap_dtos[] and pmap_stod[], and  * returns the number of usable physical pages.  */
end_comment

begin_function
name|int
name|init_translations
parameter_list|()
block|{
specifier|register
name|struct
name|memarr
modifier|*
name|mp
decl_stmt|;
specifier|register
name|int
name|n
decl_stmt|,
name|nmem
decl_stmt|;
specifier|register
name|u_int
name|vbank
init|=
literal|0
decl_stmt|,
name|pbank
decl_stmt|,
name|v
decl_stmt|,
name|a
decl_stmt|;
specifier|register
name|u_int
name|pages
init|=
literal|0
decl_stmt|,
name|lost
init|=
literal|0
decl_stmt|;
ifndef|#
directive|ifndef
name|DEBUG
name|struct
name|memarr
name|ama
index|[
name|MA_SIZE
index|]
decl_stmt|;
comment|/* available memory array */
endif|#
directive|endif
name|nmem
operator|=
name|makememarr
argument_list|(
name|ama
argument_list|,
name|MA_SIZE
argument_list|,
name|MEMARR_AVAILPHYS
argument_list|)
expr_stmt|;
comment|/* 	 * Open Boot supposedly guarantees at least 3 MB free mem at 0; 	 * this is where the kernel has been loaded (we certainly hope the 	 * kernel is<= 3 MB).  We need the memory array to be sorted, and 	 * to start at 0, so that `software page 0' and `hardware page 0' 	 * are the same (otherwise the VM reserves the wrong pages for the 	 * kernel). 	 */
name|sortm
argument_list|(
name|ama
argument_list|,
name|nmem
argument_list|)
expr_stmt|;
if|if
condition|(
name|ama
index|[
literal|0
index|]
operator|.
name|addr
operator|!=
literal|0
condition|)
block|{
comment|/* cannot panic here; there's no real kernel yet. */
name|printf
argument_list|(
literal|"init_translations: no kernel memory?!\n"
argument_list|)
expr_stmt|;
name|callrom
argument_list|()
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|DEBUG
name|pmap_nama
operator|=
name|nmem
expr_stmt|;
endif|#
directive|endif
for|for
control|(
name|mp
operator|=
name|ama
init|;
operator|--
name|nmem
operator|>=
literal|0
condition|;
name|mp
operator|++
control|)
block|{
name|a
operator|=
name|mp
operator|->
name|addr
operator|>>
name|PGSHIFT
expr_stmt|;
name|v
operator|=
name|mp
operator|->
name|len
operator|>>
name|PGSHIFT
expr_stmt|;
if|if
condition|(
operator|(
name|n
operator|=
name|a
operator|&
name|BOFFSET
operator|)
operator|!=
literal|0
condition|)
block|{
comment|/* round up to next bank */
name|n
operator|=
name|NPGBANK
operator|-
name|n
expr_stmt|;
if|if
condition|(
name|v
operator|<
name|n
condition|)
block|{
comment|/* not a whole bank: skip it */
name|lost
operator|+=
name|v
expr_stmt|;
continue|continue;
block|}
name|lost
operator|+=
name|n
expr_stmt|;
comment|/* lose n pages from front */
name|a
operator|+=
name|n
expr_stmt|;
name|v
operator|-=
name|n
expr_stmt|;
block|}
name|n
operator|=
name|v
operator|>>
name|BSHIFT
expr_stmt|;
comment|/* calculate number of banks */
name|pbank
operator|=
name|a
operator|>>
name|BSHIFT
expr_stmt|;
comment|/* and the bank itself */
if|if
condition|(
name|pbank
operator|+
name|n
operator|>=
name|BTSIZE
condition|)
name|n
operator|=
name|BTSIZE
operator|-
name|pbank
expr_stmt|;
name|pages
operator|+=
name|n
expr_stmt|;
comment|/* off by a factor of 2^BSHIFT */
name|lost
operator|+=
name|v
operator|-
operator|(
name|n
operator|<<
name|BSHIFT
operator|)
expr_stmt|;
while|while
condition|(
operator|--
name|n
operator|>=
literal|0
condition|)
block|{
name|pmap_dtos
index|[
name|vbank
index|]
operator|=
name|pbank
operator|<<
name|BSHIFT
expr_stmt|;
name|pmap_stod
index|[
name|pbank
index|]
operator|=
name|vbank
operator|<<
name|BSHIFT
expr_stmt|;
name|pbank
operator|++
expr_stmt|;
name|vbank
operator|++
expr_stmt|;
block|}
block|}
comment|/* adjust page count */
name|pages
operator|<<=
name|BSHIFT
expr_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
name|printf
argument_list|(
literal|"note: lost %d pages in translation\n"
argument_list|,
name|lost
argument_list|)
expr_stmt|;
endif|#
directive|endif
return|return
operator|(
name|pages
operator|)
return|;
block|}
end_function

begin_else
else|#
directive|else
end_else

begin_comment
comment|/* sun4c */
end_comment

begin_comment
comment|/*  * Pages are physically contiguous, and hardware PFN == software PFN.  *  * XXX assumes PAGE_SIZE == NBPG (???)  */
end_comment

begin_define
define|#
directive|define
name|HWTOSW
parameter_list|(
name|pg
parameter_list|)
value|(pg)
end_define

begin_define
define|#
directive|define
name|SWTOHW
parameter_list|(
name|pg
parameter_list|)
value|(pg)
end_define

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/* sun4c */
end_comment

begin_comment
comment|/* update pv_flags given a valid pte */
end_comment

begin_define
define|#
directive|define
name|MR
parameter_list|(
name|pte
parameter_list|)
value|(((pte)>> PG_M_SHIFT)& (PV_MOD | PV_REF))
end_define

begin_comment
comment|/*----------------------------------------------------------------*/
end_comment

begin_comment
comment|/*  * Agree with the monitor ROM as to how many MMU entries are  * to be reserved, and map all of its segments into all contexts.  *  * Unfortunately, while the Version 0 PROM had a nice linked list of  * taken virtual memory, the Version 2 PROM provides instead a convoluted  * description of *free* virtual memory.  Rather than invert this, we  * resort to two magic constants from the PROM vector description file.  */
end_comment

begin_function
name|int
name|mmu_reservemon
parameter_list|(
name|nmmu
parameter_list|)
specifier|register
name|int
name|nmmu
decl_stmt|;
block|{
specifier|register
name|u_int
name|va
decl_stmt|,
name|eva
decl_stmt|;
specifier|register
name|int
name|mmuseg
decl_stmt|,
name|i
decl_stmt|;
name|va
operator|=
name|OPENPROM_STARTVADDR
expr_stmt|;
name|eva
operator|=
name|OPENPROM_ENDVADDR
expr_stmt|;
while|while
condition|(
name|va
operator|<
name|eva
condition|)
block|{
name|mmuseg
operator|=
name|getsegmap
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|mmuseg
operator|<
name|nmmu
condition|)
name|nmmu
operator|=
name|mmuseg
expr_stmt|;
for|for
control|(
name|i
operator|=
name|ncontext
init|;
operator|--
name|i
operator|>
literal|0
condition|;
control|)
call|(
modifier|*
name|promvec
operator|->
name|pv_setctxt
call|)
argument_list|(
name|i
argument_list|,
operator|(
name|caddr_t
operator|)
name|va
argument_list|,
name|mmuseg
argument_list|)
expr_stmt|;
if|if
condition|(
name|mmuseg
operator|==
name|seginval
condition|)
block|{
name|va
operator|+=
name|NBPSG
expr_stmt|;
continue|continue;
block|}
comment|/* PROM maps its memory user-accessible: fix it. */
for|for
control|(
name|i
operator|=
name|NPTESG
init|;
operator|--
name|i
operator|>=
literal|0
condition|;
name|va
operator|+=
name|NBPG
control|)
name|setpte
argument_list|(
name|va
argument_list|,
name|getpte
argument_list|(
name|va
argument_list|)
operator||
name|PG_S
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|nmmu
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * TODO: agree with the ROM on physical pages by taking them away  * from the page list, rather than having a dinky BTSIZE above.  */
end_comment

begin_comment
comment|/*----------------------------------------------------------------*/
end_comment

begin_comment
comment|/*  * MMU management.  */
end_comment

begin_comment
comment|/*  * Change contexts.  We need the old context number as well as the new  * one.  If the context is changing, we must write all user windows  * first, lest an interrupt cause them to be written to the (other)  * user whose context we set here.  */
end_comment

begin_define
define|#
directive|define
name|CHANGE_CONTEXTS
parameter_list|(
name|old
parameter_list|,
name|new
parameter_list|)
define|\
value|if ((old) != (new)) { \ 		write_user_windows(); \ 		setcontext(new); \ 	}
end_define

begin_comment
comment|/*  * Allocate an MMU entry (i.e., a PMEG).  * If necessary, steal one from someone else.  * Put it on the tail of the given queue  * (which is either the LRU list or the locked list).  * The locked list is not actually ordered, but this is easiest.  * Also put it on the given (new) pmap's chain,  * enter its pmeg number into that pmap's segmap,  * and store the pmeg's new virtual segment number (me->me_vseg).  *  * This routine is large and complicated, but it must be fast  * since it implements the dynamic allocation of MMU entries.  */
end_comment

begin_function
name|struct
name|mmuentry
modifier|*
name|me_alloc
parameter_list|(
name|mh
parameter_list|,
name|newpm
parameter_list|,
name|newvseg
parameter_list|)
specifier|register
name|struct
name|mmuhd
modifier|*
name|mh
decl_stmt|;
specifier|register
name|struct
name|pmap
modifier|*
name|newpm
decl_stmt|;
specifier|register
name|int
name|newvseg
decl_stmt|;
block|{
specifier|register
name|struct
name|mmuentry
modifier|*
name|me
decl_stmt|;
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|int
name|i
decl_stmt|,
name|va
decl_stmt|,
name|pa
decl_stmt|,
modifier|*
name|pte
decl_stmt|,
name|tpte
decl_stmt|;
name|int
name|ctx
decl_stmt|;
comment|/* try free list first */
if|if
condition|(
operator|(
name|me
operator|=
name|me_freelist
operator|)
operator|!=
name|NULL
condition|)
block|{
name|me_freelist
operator|=
name|me
operator|->
name|me_next
expr_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|me
operator|->
name|me_pmap
operator|!=
name|NULL
condition|)
name|panic
argument_list|(
literal|"me_alloc: freelist entry has pmap"
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmapdebug
operator|&
name|PDB_MMU_ALLOC
condition|)
name|printf
argument_list|(
literal|"me_alloc: got pmeg %x\n"
argument_list|,
name|me
operator|->
name|me_pmeg
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|insque
argument_list|(
name|me
argument_list|,
name|mh
operator|->
name|mh_prev
argument_list|)
expr_stmt|;
comment|/* onto end of queue */
comment|/* onto on pmap chain; pmap is already locked, if needed */
name|me
operator|->
name|me_pmforw
operator|=
name|NULL
expr_stmt|;
name|me
operator|->
name|me_pmback
operator|=
name|newpm
operator|->
name|pm_mmuback
expr_stmt|;
operator|*
name|newpm
operator|->
name|pm_mmuback
operator|=
name|me
expr_stmt|;
name|newpm
operator|->
name|pm_mmuback
operator|=
operator|&
name|me
operator|->
name|me_pmforw
expr_stmt|;
comment|/* into pmap segment table, with backpointers */
name|newpm
operator|->
name|pm_segmap
index|[
name|newvseg
index|]
operator|=
name|me
operator|->
name|me_pmeg
expr_stmt|;
name|me
operator|->
name|me_pmap
operator|=
name|newpm
expr_stmt|;
name|me
operator|->
name|me_vseg
operator|=
name|newvseg
expr_stmt|;
return|return
operator|(
name|me
operator|)
return|;
block|}
comment|/* no luck, take head of LRU list */
if|if
condition|(
operator|(
name|me
operator|=
name|me_lru
operator|.
name|mh_next
operator|)
operator|==
operator|(
expr|struct
name|mmuentry
operator|*
operator|)
operator|&
name|me_lru
condition|)
name|panic
argument_list|(
literal|"me_alloc: all pmegs gone"
argument_list|)
expr_stmt|;
name|pm
operator|=
name|me
operator|->
name|me_pmap
expr_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pm
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"me_alloc: LRU entry has no pmap"
argument_list|)
expr_stmt|;
if|if
condition|(
name|pm
operator|==
name|kernel_pmap
condition|)
name|panic
argument_list|(
literal|"me_alloc: stealing from kernel"
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pm
operator|->
name|pm_pte
index|[
name|me
operator|->
name|me_vseg
index|]
expr_stmt|;
if|if
condition|(
name|pte
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"me_alloc: LRU entry's pmap has no ptes"
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmapdebug
operator|&
operator|(
name|PDB_MMU_ALLOC
operator||
name|PDB_MMU_STEAL
operator|)
condition|)
name|printf
argument_list|(
literal|"me_alloc: stealing pmeg %x from pmap %x\n"
argument_list|,
name|me
operator|->
name|me_pmeg
argument_list|,
name|pm
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Remove from LRU list, and insert at end of new list 	 * (probably the LRU list again, but so what?). 	 */
name|remque
argument_list|(
name|me
argument_list|)
expr_stmt|;
name|insque
argument_list|(
name|me
argument_list|,
name|mh
operator|->
name|mh_prev
argument_list|)
expr_stmt|;
comment|/* 	 * The PMEG must be mapped into some context so that we can 	 * read its PTEs.  Use its current context if it has one; 	 * if not, and since context 0 is reserved for the kernel, 	 * the simplest method is to switch to 0 and map the PMEG 	 * to virtual address 0---which, being a user space address, 	 * is by definition not in use. 	 * 	 * XXX for ncpus>1 must use per-cpu VA? 	 * XXX do not have to flush cache immediately 	 */
name|ctx
operator|=
name|getcontext
argument_list|()
expr_stmt|;
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
block|{
name|CHANGE_CONTEXTS
argument_list|(
name|ctx
argument_list|,
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|notdef
if|if
condition|(
name|vactype
operator|!=
name|VAC_NONE
condition|)
endif|#
directive|endif
name|cache_flush_segment
argument_list|(
name|me
operator|->
name|me_vseg
argument_list|)
expr_stmt|;
name|va
operator|=
name|VSTOVA
argument_list|(
name|me
operator|->
name|me_vseg
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|CHANGE_CONTEXTS
argument_list|(
name|ctx
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|setsegmap
argument_list|(
literal|0
argument_list|,
name|me
operator|->
name|me_pmeg
argument_list|)
expr_stmt|;
comment|/* 		 * No cache flush needed: it happened earlier when 		 * the old context was taken. 		 */
name|va
operator|=
literal|0
expr_stmt|;
block|}
comment|/* 	 * Record reference and modify bits for each page, 	 * and copy PTEs into kernel memory so that they can 	 * be reloaded later. 	 */
name|i
operator|=
name|NPTESG
expr_stmt|;
do|do
block|{
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|tpte
operator|&
name|PG_V
condition|)
block|{
name|pa
operator|=
name|ptoa
argument_list|(
name|HWTOSW
argument_list|(
name|tpte
operator|&
name|PG_PFNUM
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|pa
argument_list|)
condition|)
name|pvhead
argument_list|(
name|pa
argument_list|)
operator|->
name|pv_flags
operator||=
name|MR
argument_list|(
name|tpte
argument_list|)
expr_stmt|;
block|}
operator|*
name|pte
operator|++
operator|=
name|tpte
operator|&
operator|~
operator|(
name|PG_U
operator||
name|PG_M
operator|)
expr_stmt|;
name|va
operator|+=
name|NBPG
expr_stmt|;
block|}
do|while
condition|(
operator|--
name|i
operator|>
literal|0
condition|)
do|;
comment|/* update segment tables */
name|simple_lock
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
comment|/* what if other cpu takes mmuentry ?? */
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
name|setsegmap
argument_list|(
name|VSTOVA
argument_list|(
name|me
operator|->
name|me_vseg
argument_list|)
argument_list|,
name|seginval
argument_list|)
expr_stmt|;
name|pm
operator|->
name|pm_segmap
index|[
name|me
operator|->
name|me_vseg
index|]
operator|=
name|seginval
expr_stmt|;
comment|/* off old pmap chain */
if|if
condition|(
operator|(
operator|*
name|me
operator|->
name|me_pmback
operator|=
name|me
operator|->
name|me_pmforw
operator|)
operator|!=
name|NULL
condition|)
block|{
name|me
operator|->
name|me_pmforw
operator|->
name|me_pmback
operator|=
name|me
operator|->
name|me_pmback
expr_stmt|;
name|me
operator|->
name|me_pmforw
operator|=
name|NULL
expr_stmt|;
block|}
else|else
name|pm
operator|->
name|pm_mmuback
operator|=
name|me
operator|->
name|me_pmback
expr_stmt|;
name|simple_unlock
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
name|setcontext
argument_list|(
name|ctx
argument_list|)
expr_stmt|;
comment|/* done with old context */
comment|/* onto new pmap chain; new pmap is already locked, if needed */
comment|/* me->me_pmforw = NULL; */
comment|/* done earlier */
name|me
operator|->
name|me_pmback
operator|=
name|newpm
operator|->
name|pm_mmuback
expr_stmt|;
operator|*
name|newpm
operator|->
name|pm_mmuback
operator|=
name|me
expr_stmt|;
name|newpm
operator|->
name|pm_mmuback
operator|=
operator|&
name|me
operator|->
name|me_pmforw
expr_stmt|;
comment|/* into new segment table, with backpointers */
name|newpm
operator|->
name|pm_segmap
index|[
name|newvseg
index|]
operator|=
name|me
operator|->
name|me_pmeg
expr_stmt|;
name|me
operator|->
name|me_pmap
operator|=
name|newpm
expr_stmt|;
name|me
operator|->
name|me_vseg
operator|=
name|newvseg
expr_stmt|;
return|return
operator|(
name|me
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Free an MMU entry.  *  * Assumes the corresponding pmap is already locked.  * Does NOT flush cache, but does record ref and mod bits.  * The rest of each PTE is discarded.  * CALLER MUST SET CONTEXT to pm->pm_ctxnum (if pmap has  * a context) or to 0 (if not).  Caller must also update  * pm->pm_segmap and (possibly) the hardware.  */
end_comment

begin_function
name|void
name|me_free
parameter_list|(
name|pm
parameter_list|,
name|pmeg
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|u_int
name|pmeg
decl_stmt|;
block|{
specifier|register
name|struct
name|mmuentry
modifier|*
name|me
init|=
operator|&
name|mmuentry
index|[
name|pmeg
index|]
decl_stmt|;
specifier|register
name|int
name|i
decl_stmt|,
name|va
decl_stmt|,
name|pa
decl_stmt|,
name|tpte
decl_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pmapdebug
operator|&
name|PDB_MMU_ALLOC
condition|)
name|printf
argument_list|(
literal|"me_free: freeing pmeg %x from pmap %x\n"
argument_list|,
name|me
operator|->
name|me_pmeg
argument_list|,
name|pm
argument_list|)
expr_stmt|;
if|if
condition|(
name|me
operator|->
name|me_pmeg
operator|!=
name|pmeg
condition|)
name|panic
argument_list|(
literal|"me_free: wrong mmuentry"
argument_list|)
expr_stmt|;
if|if
condition|(
name|pm
operator|!=
name|me
operator|->
name|me_pmap
condition|)
name|panic
argument_list|(
literal|"me_free: pm != me_pmap"
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* just like me_alloc, but no cache flush, and context already set */
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
name|va
operator|=
name|VSTOVA
argument_list|(
name|me
operator|->
name|me_vseg
argument_list|)
expr_stmt|;
else|else
block|{
name|setsegmap
argument_list|(
literal|0
argument_list|,
name|me
operator|->
name|me_pmeg
argument_list|)
expr_stmt|;
name|va
operator|=
literal|0
expr_stmt|;
block|}
name|i
operator|=
name|NPTESG
expr_stmt|;
do|do
block|{
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|tpte
operator|&
name|PG_V
condition|)
block|{
name|pa
operator|=
name|ptoa
argument_list|(
name|HWTOSW
argument_list|(
name|tpte
operator|&
name|PG_PFNUM
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|pa
argument_list|)
condition|)
name|pvhead
argument_list|(
name|pa
argument_list|)
operator|->
name|pv_flags
operator||=
name|MR
argument_list|(
name|tpte
argument_list|)
expr_stmt|;
block|}
name|va
operator|+=
name|NBPG
expr_stmt|;
block|}
do|while
condition|(
operator|--
name|i
operator|>
literal|0
condition|)
do|;
comment|/* take mmu entry off pmap chain */
operator|*
name|me
operator|->
name|me_pmback
operator|=
name|me
operator|->
name|me_pmforw
expr_stmt|;
if|if
condition|(
operator|(
operator|*
name|me
operator|->
name|me_pmback
operator|=
name|me
operator|->
name|me_pmforw
operator|)
operator|!=
name|NULL
condition|)
name|me
operator|->
name|me_pmforw
operator|->
name|me_pmback
operator|=
name|me
operator|->
name|me_pmback
expr_stmt|;
else|else
name|pm
operator|->
name|pm_mmuback
operator|=
name|me
operator|->
name|me_pmback
expr_stmt|;
comment|/* ... and remove from segment map */
name|pm
operator|->
name|pm_segmap
index|[
name|me
operator|->
name|me_vseg
index|]
operator|=
name|seginval
expr_stmt|;
comment|/* off LRU or lock chain */
name|remque
argument_list|(
name|me
argument_list|)
expr_stmt|;
comment|/* no associated pmap; on free list */
name|me
operator|->
name|me_pmap
operator|=
name|NULL
expr_stmt|;
name|me
operator|->
name|me_next
operator|=
name|me_freelist
expr_stmt|;
name|me_freelist
operator|=
name|me
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * `Page in' (load or inspect) an MMU entry; called on page faults.  * Returns 1 if we reloaded the segment, -1 if the segment was  * already loaded and the page was marked valid (in which case the  * fault must be a bus error or something), or 0 (segment loaded but  * PTE not valid, or segment not loaded at all).  */
end_comment

begin_function
name|int
name|mmu_pagein
parameter_list|(
name|pm
parameter_list|,
name|va
parameter_list|,
name|bits
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|int
name|va
decl_stmt|,
name|bits
decl_stmt|;
block|{
specifier|register
name|int
modifier|*
name|pte
decl_stmt|;
specifier|register
name|struct
name|mmuentry
modifier|*
name|me
decl_stmt|;
specifier|register
name|int
name|vseg
init|=
name|VA_VSEG
argument_list|(
name|va
argument_list|)
decl_stmt|,
name|pmeg
decl_stmt|,
name|i
decl_stmt|,
name|s
decl_stmt|;
comment|/* return 0 if we have no PTEs to load */
if|if
condition|(
operator|(
name|pte
operator|=
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
operator|)
operator|==
name|NULL
condition|)
return|return
operator|(
literal|0
operator|)
return|;
comment|/* return -1 if the fault is `hard', 0 if not */
if|if
condition|(
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
operator|!=
name|seginval
condition|)
return|return
operator|(
name|bits
operator|&&
operator|(
name|getpte
argument_list|(
name|va
argument_list|)
operator|&
name|bits
operator|)
operator|==
name|bits
condition|?
operator|-
literal|1
else|:
literal|0
operator|)
return|;
comment|/* reload segment: write PTEs into a new LRU entry */
name|va
operator|=
name|VA_ROUNDDOWNTOSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|s
operator|=
name|splpmap
argument_list|()
expr_stmt|;
comment|/* paranoid */
name|pmeg
operator|=
name|me_alloc
argument_list|(
operator|&
name|me_lru
argument_list|,
name|pm
argument_list|,
name|vseg
argument_list|)
operator|->
name|me_pmeg
expr_stmt|;
name|setsegmap
argument_list|(
name|va
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
name|i
operator|=
name|NPTESG
expr_stmt|;
do|do
block|{
name|setpte
argument_list|(
name|va
argument_list|,
operator|*
name|pte
operator|++
argument_list|)
expr_stmt|;
name|va
operator|+=
name|NBPG
expr_stmt|;
block|}
do|while
condition|(
operator|--
name|i
operator|>
literal|0
condition|)
do|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
operator|(
literal|1
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Allocate a context.  If necessary, steal one from someone else.  * Changes hardware context number and loads segment map.  *  * This routine is only ever called from locore.s just after it has  * saved away the previous process, so there are no active user windows.  */
end_comment

begin_function
name|void
name|ctx_alloc
parameter_list|(
name|pm
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
block|{
specifier|register
name|union
name|ctxinfo
modifier|*
name|c
decl_stmt|;
specifier|register
name|int
name|cnum
decl_stmt|,
name|i
decl_stmt|,
name|va
decl_stmt|;
specifier|register
name|pmeg_t
modifier|*
name|segp
decl_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
name|panic
argument_list|(
literal|"ctx_alloc pm_ctx"
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmapdebug
operator|&
name|PDB_CTX_ALLOC
condition|)
name|printf
argument_list|(
literal|"ctx_alloc(%x)\n"
argument_list|,
name|pm
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
operator|(
name|c
operator|=
name|ctx_freelist
operator|)
operator|!=
name|NULL
condition|)
block|{
name|ctx_freelist
operator|=
name|c
operator|->
name|c_nextfree
expr_stmt|;
name|cnum
operator|=
name|c
operator|-
name|ctxinfo
expr_stmt|;
name|setcontext
argument_list|(
name|cnum
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|(
name|ctx_kick
operator|+=
name|ctx_kickdir
operator|)
operator|>=
name|ncontext
condition|)
block|{
name|ctx_kick
operator|=
name|ncontext
operator|-
literal|1
expr_stmt|;
name|ctx_kickdir
operator|=
operator|-
literal|1
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ctx_kick
operator|<
literal|1
condition|)
block|{
name|ctx_kick
operator|=
literal|1
expr_stmt|;
name|ctx_kickdir
operator|=
literal|1
expr_stmt|;
block|}
name|c
operator|=
operator|&
name|ctxinfo
index|[
name|cnum
operator|=
name|ctx_kick
index|]
expr_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|c
operator|->
name|c_pmap
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"ctx_alloc cu_pmap"
argument_list|)
expr_stmt|;
if|if
condition|(
name|pmapdebug
operator|&
operator|(
name|PDB_CTX_ALLOC
operator||
name|PDB_CTX_STEAL
operator|)
condition|)
name|printf
argument_list|(
literal|"ctx_alloc: steal context %x from %x\n"
argument_list|,
name|cnum
argument_list|,
name|c
operator|->
name|c_pmap
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|c
operator|->
name|c_pmap
operator|->
name|pm_ctx
operator|=
name|NULL
expr_stmt|;
name|setcontext
argument_list|(
name|cnum
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|notdef
if|if
condition|(
name|vactype
operator|!=
name|VAC_NONE
condition|)
endif|#
directive|endif
name|cache_flush_context
argument_list|()
expr_stmt|;
block|}
name|c
operator|->
name|c_pmap
operator|=
name|pm
expr_stmt|;
name|pm
operator|->
name|pm_ctx
operator|=
name|c
expr_stmt|;
name|pm
operator|->
name|pm_ctxnum
operator|=
name|cnum
expr_stmt|;
comment|/* 	 * XXX	loop below makes 3584 iterations ... could reduce 	 *	by remembering valid ranges per context: two ranges 	 *	should suffice (for text/data/bss and for stack). 	 */
name|segp
operator|=
name|pm
operator|->
name|pm_rsegmap
expr_stmt|;
for|for
control|(
name|va
operator|=
literal|0
operator|,
name|i
operator|=
name|NUSEG
init|;
operator|--
name|i
operator|>=
literal|0
condition|;
name|va
operator|+=
name|NBPSG
control|)
name|setsegmap
argument_list|(
name|va
argument_list|,
operator|*
name|segp
operator|++
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Give away a context.  Flushes cache and sets current context to 0.  */
end_comment

begin_function
name|void
name|ctx_free
parameter_list|(
name|pm
parameter_list|)
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
block|{
specifier|register
name|union
name|ctxinfo
modifier|*
name|c
decl_stmt|;
specifier|register
name|int
name|newc
decl_stmt|,
name|oldc
decl_stmt|;
if|if
condition|(
operator|(
name|c
operator|=
name|pm
operator|->
name|pm_ctx
operator|)
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"ctx_free"
argument_list|)
expr_stmt|;
name|pm
operator|->
name|pm_ctx
operator|=
name|NULL
expr_stmt|;
name|oldc
operator|=
name|getcontext
argument_list|()
expr_stmt|;
if|if
condition|(
name|vactype
operator|!=
name|VAC_NONE
condition|)
block|{
name|newc
operator|=
name|pm
operator|->
name|pm_ctxnum
expr_stmt|;
name|CHANGE_CONTEXTS
argument_list|(
name|oldc
argument_list|,
name|newc
argument_list|)
expr_stmt|;
name|cache_flush_context
argument_list|()
expr_stmt|;
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|CHANGE_CONTEXTS
argument_list|(
name|oldc
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
name|c
operator|->
name|c_nextfree
operator|=
name|ctx_freelist
expr_stmt|;
name|ctx_freelist
operator|=
name|c
expr_stmt|;
block|}
end_function

begin_comment
comment|/*----------------------------------------------------------------*/
end_comment

begin_comment
comment|/*  * pvlist functions.  */
end_comment

begin_comment
comment|/*  * Walk the given pv list, and for each PTE, set or clear some bits  * (e.g., PG_W or PG_NC).  *  * As a special case, this never clears PG_W on `pager' pages.  * These, being kernel addresses, are always in hardware and have  * a context.  *  * This routine flushes the cache for any page whose PTE changes,  * as long as the process has a context; this is overly conservative.  * It also copies ref and mod bits to the pvlist, on the theory that  * this might save work later.  (XXX should test this theory)  */
end_comment

begin_function
name|void
name|pv_changepte
parameter_list|(
name|pv0
parameter_list|,
name|bis
parameter_list|,
name|bic
parameter_list|)
specifier|register
name|struct
name|pvlist
modifier|*
name|pv0
decl_stmt|;
specifier|register
name|int
name|bis
decl_stmt|,
name|bic
decl_stmt|;
block|{
specifier|register
name|int
modifier|*
name|pte
decl_stmt|;
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|int
name|va
decl_stmt|,
name|vseg
decl_stmt|,
name|pmeg
decl_stmt|,
name|i
decl_stmt|,
name|flags
decl_stmt|;
name|int
name|ctx
decl_stmt|,
name|s
decl_stmt|;
name|write_user_windows
argument_list|()
expr_stmt|;
comment|/* paranoid? */
name|s
operator|=
name|splpmap
argument_list|()
expr_stmt|;
comment|/* paranoid? */
if|if
condition|(
name|pv0
operator|->
name|pv_pmap
operator|==
name|NULL
condition|)
block|{
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
name|ctx
operator|=
name|getcontext
argument_list|()
expr_stmt|;
name|flags
operator|=
name|pv0
operator|->
name|pv_flags
expr_stmt|;
for|for
control|(
name|pv
operator|=
name|pv0
init|;
name|pv
operator|!=
name|NULL
condition|;
name|pv
operator|=
name|pv
operator|->
name|pv_next
control|)
block|{
name|pm
operator|=
name|pv
operator|->
name|pv_pmap
expr_stmt|;
if|if
condition|(
name|pm
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pv_changepte 1"
argument_list|)
expr_stmt|;
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|vseg
operator|=
name|VA_VSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pte
operator|=
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
expr_stmt|;
if|if
condition|(
operator|(
name|pmeg
operator|=
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
operator|)
operator|!=
name|seginval
condition|)
block|{
specifier|register
name|int
name|tpte
decl_stmt|;
comment|/* in hardware: fix hardware copy */
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
block|{
specifier|extern
name|vm_offset_t
name|pager_sva
decl_stmt|,
name|pager_eva
decl_stmt|;
comment|/* 				 * Bizarreness:  we never clear PG_W on 				 * pager pages, nor PG_NC on DVMA pages. 				 */
if|if
condition|(
name|bic
operator|==
name|PG_W
operator|&&
name|va
operator|>=
name|pager_sva
operator|&&
name|va
operator|<
name|pager_eva
condition|)
continue|continue;
if|if
condition|(
name|bic
operator|==
name|PG_NC
operator|&&
name|va
operator|>=
name|DVMA_BASE
operator|&&
name|va
operator|<
name|DVMA_END
condition|)
continue|continue;
name|setcontext
argument_list|(
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
comment|/* XXX should flush only when necessary */
ifdef|#
directive|ifdef
name|notdef
if|if
condition|(
name|vactype
operator|!=
name|VAC_NONE
condition|)
endif|#
directive|endif
name|cache_flush_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* XXX per-cpu va? */
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|setsegmap
argument_list|(
literal|0
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
name|va
operator|=
name|VA_VPG
argument_list|(
name|va
argument_list|)
operator|*
name|NBPG
expr_stmt|;
block|}
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|tpte
operator|&
name|PG_V
condition|)
name|flags
operator||=
operator|(
name|tpte
operator|>>
name|PG_M_SHIFT
operator|)
operator|&
operator|(
name|PV_MOD
operator||
name|PV_REF
operator|)
expr_stmt|;
name|tpte
operator|=
operator|(
name|tpte
operator||
name|bis
operator|)
operator|&
operator|~
name|bic
expr_stmt|;
name|setpte
argument_list|(
name|va
argument_list|,
name|tpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|pte
operator|!=
name|NULL
condition|)
comment|/* update software copy */
name|pte
index|[
name|VA_VPG
argument_list|(
name|va
argument_list|)
index|]
operator|=
name|tpte
expr_stmt|;
block|}
else|else
block|{
comment|/* not in hardware: just fix software copy */
if|if
condition|(
name|pte
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pv_changepte 2"
argument_list|)
expr_stmt|;
name|pte
operator|+=
name|VA_VPG
argument_list|(
name|va
argument_list|)
expr_stmt|;
operator|*
name|pte
operator|=
operator|(
operator|*
name|pte
operator||
name|bis
operator|)
operator|&
operator|~
name|bic
expr_stmt|;
block|}
block|}
name|pv0
operator|->
name|pv_flags
operator|=
name|flags
expr_stmt|;
name|setcontext
argument_list|(
name|ctx
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Sync ref and mod bits in pvlist (turns off same in hardware PTEs).  * Returns the new flags.  *  * This is just like pv_changepte, but we never add or remove bits,  * hence never need to adjust software copies.  */
end_comment

begin_function
name|int
name|pv_syncflags
parameter_list|(
name|pv0
parameter_list|)
specifier|register
name|struct
name|pvlist
modifier|*
name|pv0
decl_stmt|;
block|{
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|int
name|tpte
decl_stmt|,
name|va
decl_stmt|,
name|vseg
decl_stmt|,
name|pmeg
decl_stmt|,
name|i
decl_stmt|,
name|flags
decl_stmt|;
name|int
name|ctx
decl_stmt|,
name|s
decl_stmt|;
name|write_user_windows
argument_list|()
expr_stmt|;
comment|/* paranoid? */
name|s
operator|=
name|splpmap
argument_list|()
expr_stmt|;
comment|/* paranoid? */
if|if
condition|(
name|pv0
operator|->
name|pv_pmap
operator|==
name|NULL
condition|)
block|{
comment|/* paranoid */
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|ctx
operator|=
name|getcontext
argument_list|()
expr_stmt|;
name|flags
operator|=
name|pv0
operator|->
name|pv_flags
expr_stmt|;
for|for
control|(
name|pv
operator|=
name|pv0
init|;
name|pv
operator|!=
name|NULL
condition|;
name|pv
operator|=
name|pv
operator|->
name|pv_next
control|)
block|{
name|pm
operator|=
name|pv
operator|->
name|pv_pmap
expr_stmt|;
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|vseg
operator|=
name|VA_VSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pmeg
operator|=
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
operator|)
operator|==
name|seginval
condition|)
continue|continue;
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
block|{
name|setcontext
argument_list|(
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
comment|/* XXX should flush only when necessary */
ifdef|#
directive|ifdef
name|notdef
if|if
condition|(
name|vactype
operator|!=
name|VAC_NONE
condition|)
endif|#
directive|endif
name|cache_flush_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* XXX per-cpu va? */
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|setsegmap
argument_list|(
literal|0
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
name|va
operator|=
name|VA_VPG
argument_list|(
name|va
argument_list|)
operator|*
name|NBPG
expr_stmt|;
block|}
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|tpte
operator|&
operator|(
name|PG_M
operator||
name|PG_U
operator|)
operator|&&
name|tpte
operator|&
name|PG_V
condition|)
block|{
name|flags
operator||=
operator|(
name|tpte
operator|>>
name|PG_M_SHIFT
operator|)
operator|&
operator|(
name|PV_MOD
operator||
name|PV_REF
operator|)
expr_stmt|;
name|tpte
operator|&=
operator|~
operator|(
name|PG_M
operator||
name|PG_U
operator|)
expr_stmt|;
name|setpte
argument_list|(
name|va
argument_list|,
name|tpte
argument_list|)
expr_stmt|;
block|}
block|}
name|pv0
operator|->
name|pv_flags
operator|=
name|flags
expr_stmt|;
name|setcontext
argument_list|(
name|ctx
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return
operator|(
name|flags
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * pv_unlink is a helper function for pmap_remove.  * It takes a pointer to the pv_table head for some physical address  * and removes the appropriate (pmap, va) entry.  *  * Once the entry is removed, if the pv_table head has the cache  * inhibit bit set, see if we can turn that off; if so, walk the  * pvlist and turn off PG_NC in each PTE.  (The pvlist is by  * definition nonempty, since it must have at least two elements  * in it to have PV_NC set, and we only remove one here.)  */
end_comment

begin_function
specifier|static
name|void
name|pv_unlink
parameter_list|(
name|pv
parameter_list|,
name|pm
parameter_list|,
name|va
parameter_list|)
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|vm_offset_t
name|va
decl_stmt|;
block|{
specifier|register
name|struct
name|pvlist
modifier|*
name|npv
decl_stmt|;
comment|/* 	 * First entry is special (sigh). 	 */
name|npv
operator|=
name|pv
operator|->
name|pv_next
expr_stmt|;
if|if
condition|(
name|pv
operator|->
name|pv_pmap
operator|==
name|pm
operator|&&
name|pv
operator|->
name|pv_va
operator|==
name|va
condition|)
block|{
name|pmap_stats
operator|.
name|ps_unlink_pvfirst
operator|++
expr_stmt|;
if|if
condition|(
name|npv
operator|!=
name|NULL
condition|)
block|{
name|pv
operator|->
name|pv_next
operator|=
name|npv
operator|->
name|pv_next
expr_stmt|;
name|pv
operator|->
name|pv_pmap
operator|=
name|npv
operator|->
name|pv_pmap
expr_stmt|;
name|pv
operator|->
name|pv_va
operator|=
name|npv
operator|->
name|pv_va
expr_stmt|;
name|free
argument_list|(
operator|(
name|caddr_t
operator|)
name|npv
argument_list|,
name|M_VMPVENT
argument_list|)
expr_stmt|;
block|}
else|else
name|pv
operator|->
name|pv_pmap
operator|=
name|NULL
expr_stmt|;
block|}
else|else
block|{
specifier|register
name|struct
name|pvlist
modifier|*
name|prev
decl_stmt|;
for|for
control|(
name|prev
operator|=
name|pv
init|;
condition|;
name|prev
operator|=
name|npv
operator|,
name|npv
operator|=
name|npv
operator|->
name|pv_next
control|)
block|{
name|pmap_stats
operator|.
name|ps_unlink_pvsearch
operator|++
expr_stmt|;
if|if
condition|(
name|npv
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pv_unlink"
argument_list|)
expr_stmt|;
if|if
condition|(
name|npv
operator|->
name|pv_pmap
operator|==
name|pm
operator|&&
name|npv
operator|->
name|pv_va
operator|==
name|va
condition|)
break|break;
block|}
name|prev
operator|->
name|pv_next
operator|=
name|npv
operator|->
name|pv_next
expr_stmt|;
name|free
argument_list|(
operator|(
name|caddr_t
operator|)
name|npv
argument_list|,
name|M_VMPVENT
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pv
operator|->
name|pv_flags
operator|&
name|PV_NC
condition|)
block|{
comment|/* 		 * Not cached: check to see if we can fix that now. 		 */
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
for|for
control|(
name|npv
operator|=
name|pv
operator|->
name|pv_next
init|;
name|npv
operator|!=
name|NULL
condition|;
name|npv
operator|=
name|npv
operator|->
name|pv_next
control|)
if|if
condition|(
name|BADALIAS
argument_list|(
name|va
argument_list|,
name|npv
operator|->
name|pv_va
argument_list|)
condition|)
return|return;
name|pv
operator|->
name|pv_flags
operator|&=
operator|~
name|PV_NC
expr_stmt|;
name|pv_changepte
argument_list|(
name|pv
argument_list|,
literal|0
argument_list|,
name|PG_NC
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * pv_link is the inverse of pv_unlink, and is used in pmap_enter.  * It returns PG_NC if the (new) pvlist says that the address cannot  * be cached.  */
end_comment

begin_function
specifier|static
name|int
name|pv_link
parameter_list|(
name|pv
parameter_list|,
name|pm
parameter_list|,
name|va
parameter_list|)
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|vm_offset_t
name|va
decl_stmt|;
block|{
specifier|register
name|struct
name|pvlist
modifier|*
name|npv
decl_stmt|;
specifier|register
name|int
name|ret
decl_stmt|;
if|if
condition|(
name|pv
operator|->
name|pv_pmap
operator|==
name|NULL
condition|)
block|{
comment|/* no pvlist entries yet */
name|pmap_stats
operator|.
name|ps_enter_firstpv
operator|++
expr_stmt|;
name|pv
operator|->
name|pv_next
operator|=
name|NULL
expr_stmt|;
name|pv
operator|->
name|pv_pmap
operator|=
name|pm
expr_stmt|;
name|pv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
comment|/* 	 * Before entering the new mapping, see if 	 * it will cause old mappings to become aliased 	 * and thus need to be `discached'. 	 */
name|ret
operator|=
literal|0
expr_stmt|;
name|pmap_stats
operator|.
name|ps_enter_secondpv
operator|++
expr_stmt|;
if|if
condition|(
name|pv
operator|->
name|pv_flags
operator|&
name|PV_NC
condition|)
block|{
comment|/* already uncached, just stay that way */
name|ret
operator|=
name|PG_NC
expr_stmt|;
block|}
else|else
block|{
comment|/* MAY NEED TO DISCACHE ANYWAY IF va IS IN DVMA SPACE? */
for|for
control|(
name|npv
operator|=
name|pv
init|;
name|npv
operator|!=
name|NULL
condition|;
name|npv
operator|=
name|npv
operator|->
name|pv_next
control|)
block|{
if|if
condition|(
name|BADALIAS
argument_list|(
name|va
argument_list|,
name|npv
operator|->
name|pv_va
argument_list|)
condition|)
block|{
name|pv
operator|->
name|pv_flags
operator||=
name|PV_NC
expr_stmt|;
name|pv_changepte
argument_list|(
name|pv
argument_list|,
name|ret
operator|=
name|PG_NC
argument_list|,
literal|0
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
block|}
name|npv
operator|=
operator|(
expr|struct
name|pvlist
operator|*
operator|)
name|malloc
argument_list|(
sizeof|sizeof
expr|*
name|npv
argument_list|,
name|M_VMPVENT
argument_list|,
name|M_WAITOK
argument_list|)
expr_stmt|;
name|npv
operator|->
name|pv_next
operator|=
name|pv
operator|->
name|pv_next
expr_stmt|;
name|npv
operator|->
name|pv_pmap
operator|=
name|pm
expr_stmt|;
name|npv
operator|->
name|pv_va
operator|=
name|va
expr_stmt|;
name|pv
operator|->
name|pv_next
operator|=
name|npv
expr_stmt|;
return|return
operator|(
name|ret
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Walk the given list and flush the cache for each (MI) page that is  * potentially in the cache.  */
end_comment

begin_expr_stmt
name|pv_flushcache
argument_list|(
name|pv
argument_list|)
specifier|register
expr|struct
name|pvlist
operator|*
name|pv
expr_stmt|;
end_expr_stmt

begin_block
block|{
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|int
name|i
decl_stmt|,
name|s
decl_stmt|,
name|ctx
decl_stmt|;
name|write_user_windows
argument_list|()
expr_stmt|;
comment|/* paranoia? */
name|s
operator|=
name|splpmap
argument_list|()
expr_stmt|;
comment|/* XXX extreme paranoia */
if|if
condition|(
operator|(
name|pm
operator|=
name|pv
operator|->
name|pv_pmap
operator|)
operator|!=
name|NULL
condition|)
block|{
name|ctx
operator|=
name|getcontext
argument_list|()
expr_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
block|{
name|setcontext
argument_list|(
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
name|cache_flush_page
argument_list|(
name|pv
operator|->
name|pv_va
argument_list|)
expr_stmt|;
block|}
name|pv
operator|=
name|pv
operator|->
name|pv_next
expr_stmt|;
if|if
condition|(
name|pv
operator|==
name|NULL
condition|)
break|break;
name|pm
operator|=
name|pv
operator|->
name|pv_pmap
expr_stmt|;
block|}
name|setcontext
argument_list|(
name|ctx
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_block

begin_comment
comment|/*----------------------------------------------------------------*/
end_comment

begin_comment
comment|/*  * At last, pmap code.  */
end_comment

begin_comment
comment|/*  * Bootstrap the system enough to run with VM enabled.  *  * nmmu is the number of mmu entries (``PMEGs'');  * nctx is the number of contexts.  */
end_comment

begin_function
name|void
name|pmap_bootstrap
parameter_list|(
name|nmmu
parameter_list|,
name|nctx
parameter_list|)
name|int
name|nmmu
decl_stmt|,
name|nctx
decl_stmt|;
block|{
specifier|register
name|union
name|ctxinfo
modifier|*
name|ci
decl_stmt|;
specifier|register
name|struct
name|mmuentry
modifier|*
name|me
decl_stmt|;
specifier|register
name|int
name|i
decl_stmt|,
name|j
decl_stmt|,
name|n
decl_stmt|,
name|z
decl_stmt|,
name|vs
decl_stmt|;
specifier|register
name|caddr_t
name|p
decl_stmt|;
specifier|register
name|void
function_decl|(
modifier|*
name|rom_setmap
function_decl|)
parameter_list|(
name|int
name|ctx
parameter_list|,
name|caddr_t
name|va
parameter_list|,
name|int
name|pmeg
parameter_list|)
function_decl|;
name|int
name|lastpage
decl_stmt|;
specifier|extern
name|char
name|end
index|[]
decl_stmt|;
specifier|extern
name|caddr_t
name|reserve_dumppages
argument_list|(
name|caddr_t
argument_list|)
decl_stmt|;
name|ncontext
operator|=
name|nctx
expr_stmt|;
comment|/* 	 * Last segment is the `invalid' one (one PMEG of pte's with !pg_v). 	 * It will never be used for anything else. 	 */
name|seginval
operator|=
operator|--
name|nmmu
expr_stmt|;
comment|/* 	 * Preserve the monitor ROM's reserved VM region, so that 	 * we can use L1-A or the monitor's debugger.  As a side 	 * effect we map the ROM's reserved VM into all contexts 	 * (otherwise L1-A crashes the machine!). 	 */
name|nmmu
operator|=
name|mmu_reservemon
argument_list|(
name|nmmu
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate and clear mmu entry and context structures. 	 */
name|p
operator|=
name|end
expr_stmt|;
name|mmuentry
operator|=
name|me
operator|=
operator|(
expr|struct
name|mmuentry
operator|*
operator|)
name|p
expr_stmt|;
name|p
operator|+=
name|nmmu
operator|*
sizeof|sizeof
expr|*
name|me
expr_stmt|;
name|ctxinfo
operator|=
name|ci
operator|=
operator|(
expr|union
name|ctxinfo
operator|*
operator|)
name|p
expr_stmt|;
name|p
operator|+=
name|nctx
operator|*
sizeof|sizeof
expr|*
name|ci
expr_stmt|;
name|bzero
argument_list|(
name|end
argument_list|,
name|p
operator|-
name|end
argument_list|)
expr_stmt|;
comment|/* 	 * Set up the `constants' for the call to vm_init() 	 * in main().  All pages beginning at p (rounded up to 	 * the next whole page) and continuing through the number 	 * of available pages are free, but they start at a higher 	 * virtual address.  This gives us two mappable MD pages 	 * for pmap_zero_page and pmap_copy_page, and one MI page 	 * for /dev/mem, all with no associated physical memory. 	 */
name|p
operator|=
call|(
name|caddr_t
call|)
argument_list|(
operator|(
operator|(
name|u_int
operator|)
name|p
operator|+
name|NBPG
operator|-
literal|1
operator|)
operator|&
operator|~
name|PGOFSET
argument_list|)
expr_stmt|;
name|avail_start
operator|=
operator|(
name|int
operator|)
name|p
operator|-
name|KERNBASE
expr_stmt|;
name|avail_end
operator|=
name|init_translations
argument_list|()
operator|<<
name|PGSHIFT
expr_stmt|;
name|i
operator|=
operator|(
name|int
operator|)
name|p
expr_stmt|;
name|vpage
index|[
literal|0
index|]
operator|=
name|p
operator|,
name|p
operator|+=
name|NBPG
expr_stmt|;
name|vpage
index|[
literal|1
index|]
operator|=
name|p
operator|,
name|p
operator|+=
name|NBPG
expr_stmt|;
name|vmempage
operator|=
name|p
operator|,
name|p
operator|+=
name|NBPG
expr_stmt|;
name|p
operator|=
name|reserve_dumppages
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|virtual_avail
operator|=
operator|(
name|vm_offset_t
operator|)
name|p
expr_stmt|;
name|virtual_end
operator|=
name|VM_MAX_KERNEL_ADDRESS
expr_stmt|;
name|p
operator|=
operator|(
name|caddr_t
operator|)
name|i
expr_stmt|;
comment|/* retract to first free phys */
comment|/* 	 * Intialize the kernel pmap. 	 */
block|{
specifier|register
name|struct
name|kpmap
modifier|*
name|k
init|=
operator|&
name|kernel_pmap_store
decl_stmt|;
comment|/*		kernel_pmap = (struct pmap *)k; */
name|k
operator|->
name|pm_ctx
operator|=
name|ctxinfo
expr_stmt|;
comment|/* k->pm_ctxnum = 0; */
name|simple_lock_init
argument_list|(
operator|&
name|k
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
name|k
operator|->
name|pm_refcount
operator|=
literal|1
expr_stmt|;
comment|/* k->pm_mmuforw = 0; */
name|k
operator|->
name|pm_mmuback
operator|=
operator|&
name|k
operator|->
name|pm_mmuforw
expr_stmt|;
name|k
operator|->
name|pm_segmap
operator|=
operator|&
name|k
operator|->
name|pm_rsegmap
index|[
operator|-
name|NUSEG
index|]
expr_stmt|;
name|k
operator|->
name|pm_pte
operator|=
operator|&
name|k
operator|->
name|pm_rpte
index|[
operator|-
name|NUSEG
index|]
expr_stmt|;
name|k
operator|->
name|pm_npte
operator|=
operator|&
name|k
operator|->
name|pm_rnpte
index|[
operator|-
name|NUSEG
index|]
expr_stmt|;
for|for
control|(
name|i
operator|=
name|NKSEG
init|;
operator|--
name|i
operator|>=
literal|0
condition|;
control|)
name|k
operator|->
name|pm_rsegmap
index|[
name|i
index|]
operator|=
name|seginval
expr_stmt|;
block|}
comment|/* 	 * All contexts are free except the kernel's. 	 * 	 * XXX sun4c could use context 0 for users? 	 */
name|ci
operator|->
name|c_pmap
operator|=
name|kernel_pmap
expr_stmt|;
name|ctx_freelist
operator|=
name|ci
operator|+
literal|1
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|1
init|;
name|i
operator|<
name|ncontext
condition|;
name|i
operator|++
control|)
block|{
name|ci
operator|++
expr_stmt|;
name|ci
operator|->
name|c_nextfree
operator|=
name|ci
operator|+
literal|1
expr_stmt|;
block|}
name|ci
operator|->
name|c_nextfree
operator|=
name|NULL
expr_stmt|;
name|ctx_kick
operator|=
literal|0
expr_stmt|;
name|ctx_kickdir
operator|=
operator|-
literal|1
expr_stmt|;
comment|/* me_freelist = NULL; */
comment|/* already NULL */
comment|/* 	 * Init mmu entries that map the kernel physical addresses. 	 * If the page bits in p are 0, we filled the last segment 	 * exactly (now how did that happen?); if not, it is 	 * the last page filled in the last segment. 	 * 	 * All the other MMU entries are free. 	 * 	 * THIS ASSUMES SEGMENT i IS MAPPED BY MMU ENTRY i DURING THE 	 * BOOT PROCESS 	 */
name|z
operator|=
operator|(
operator|(
operator|(
operator|(
name|u_int
operator|)
name|p
operator|+
name|NBPSG
operator|-
literal|1
operator|)
operator|&
operator|~
name|SGOFSET
operator|)
operator|-
name|KERNBASE
operator|)
operator|>>
name|SGSHIFT
expr_stmt|;
name|lastpage
operator|=
name|VA_VPG
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|lastpage
operator|==
literal|0
condition|)
name|lastpage
operator|=
name|NPTESG
expr_stmt|;
name|p
operator|=
operator|(
name|caddr_t
operator|)
name|KERNBASE
expr_stmt|;
comment|/* first va */
name|vs
operator|=
name|VA_VSEG
argument_list|(
name|KERNBASE
argument_list|)
expr_stmt|;
comment|/* first virtual segment */
name|rom_setmap
operator|=
name|promvec
operator|->
name|pv_setctxt
expr_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
condition|;
control|)
block|{
comment|/* 		 * Distribute each kernel segment into all contexts. 		 * This is done through the monitor ROM, rather than 		 * directly here: if we do a setcontext we will fault, 		 * as we are not (yet) mapped in any other context. 		 */
for|for
control|(
name|j
operator|=
literal|1
init|;
name|j
operator|<
name|nctx
condition|;
name|j
operator|++
control|)
name|rom_setmap
argument_list|(
name|j
argument_list|,
name|p
argument_list|,
name|i
argument_list|)
expr_stmt|;
comment|/* set up the mmu entry */
name|me
operator|->
name|me_pmeg
operator|=
name|i
expr_stmt|;
name|insque
argument_list|(
name|me
argument_list|,
name|me_locked
operator|.
name|mh_prev
argument_list|)
expr_stmt|;
comment|/* me->me_pmforw = NULL; */
name|me
operator|->
name|me_pmback
operator|=
name|kernel_pmap
operator|->
name|pm_mmuback
expr_stmt|;
operator|*
name|kernel_pmap
operator|->
name|pm_mmuback
operator|=
name|me
expr_stmt|;
name|kernel_pmap
operator|->
name|pm_mmuback
operator|=
operator|&
name|me
operator|->
name|me_pmforw
expr_stmt|;
name|me
operator|->
name|me_pmap
operator|=
name|kernel_pmap
expr_stmt|;
name|me
operator|->
name|me_vseg
operator|=
name|vs
expr_stmt|;
name|kernel_pmap
operator|->
name|pm_segmap
index|[
name|vs
index|]
operator|=
name|i
expr_stmt|;
name|n
operator|=
operator|++
name|i
operator|<
name|z
condition|?
name|NPTESG
else|:
name|lastpage
expr_stmt|;
name|kernel_pmap
operator|->
name|pm_npte
index|[
name|vs
index|]
operator|=
name|n
expr_stmt|;
name|me
operator|++
expr_stmt|;
name|vs
operator|++
expr_stmt|;
if|if
condition|(
name|i
operator|<
name|z
condition|)
block|{
name|p
operator|+=
name|NBPSG
expr_stmt|;
continue|continue;
block|}
comment|/* 		 * Unmap the pages, if any, that are not part of 		 * the final segment. 		 */
for|for
control|(
name|p
operator|+=
name|n
operator|*
name|NBPG
init|;
name|j
operator|<
name|NPTESG
condition|;
name|j
operator|++
operator|,
name|p
operator|+=
name|NBPG
control|)
name|setpte
argument_list|(
name|p
argument_list|,
literal|0
argument_list|)
expr_stmt|;
break|break;
block|}
for|for
control|(
init|;
name|i
operator|<
name|nmmu
condition|;
name|i
operator|++
operator|,
name|me
operator|++
control|)
block|{
name|me
operator|->
name|me_pmeg
operator|=
name|i
expr_stmt|;
name|me
operator|->
name|me_next
operator|=
name|me_freelist
expr_stmt|;
comment|/* me->me_pmap = NULL; */
name|me_freelist
operator|=
name|me
expr_stmt|;
block|}
comment|/* 	 * write protect& encache kernel text; 	 * set red zone at kernel base; enable cache on message buffer. 	 */
block|{
specifier|extern
name|char
name|etext
index|[]
decl_stmt|,
name|trapbase
index|[]
decl_stmt|;
ifdef|#
directive|ifdef
name|KGDB
specifier|register
name|int
name|mask
init|=
operator|~
name|PG_NC
decl_stmt|;
comment|/* XXX chgkprot is busted */
else|#
directive|else
specifier|register
name|int
name|mask
init|=
operator|~
operator|(
name|PG_W
operator||
name|PG_NC
operator|)
decl_stmt|;
endif|#
directive|endif
for|for
control|(
name|p
operator|=
name|trapbase
init|;
name|p
operator|<
name|etext
condition|;
name|p
operator|+=
name|NBPG
control|)
name|setpte
argument_list|(
name|p
argument_list|,
name|getpte
argument_list|(
name|p
argument_list|)
operator|&
name|mask
argument_list|)
expr_stmt|;
name|p
operator|=
operator|(
name|caddr_t
operator|)
name|KERNBASE
expr_stmt|;
name|setpte
argument_list|(
name|p
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|p
operator|+=
name|NBPG
expr_stmt|;
name|setpte
argument_list|(
name|p
argument_list|,
name|getpte
argument_list|(
name|p
argument_list|)
operator|&
operator|~
name|PG_NC
argument_list|)
expr_stmt|;
block|}
comment|/* 	 * Grab physical memory list (for /dev/mem). 	 */
name|npmemarr
operator|=
name|makememarr
argument_list|(
name|pmemarr
argument_list|,
name|MA_SIZE
argument_list|,
name|MEMARR_TOTALPHYS
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Bootstrap memory allocator. This function allows for early dynamic  * memory allocation until the virtual memory system has been bootstrapped.  * After that point, either kmem_alloc or malloc should be used. This  * function works by stealing pages from the (to be) managed page pool,  * stealing virtual address space, then mapping the pages and zeroing them.  *  * It should be used from pmap_bootstrap till vm_page_startup, afterwards  * it cannot be used, and will generate a panic if tried. Note that this  * memory will never be freed, and in essence it is wired down.  */
end_comment

begin_function
name|void
modifier|*
name|pmap_bootstrap_alloc
parameter_list|(
name|size
parameter_list|)
name|int
name|size
decl_stmt|;
block|{
specifier|register
name|void
modifier|*
name|mem
decl_stmt|;
specifier|extern
name|int
name|vm_page_startup_initialized
decl_stmt|;
if|if
condition|(
name|vm_page_startup_initialized
condition|)
name|panic
argument_list|(
literal|"pmap_bootstrap_alloc: called after startup initialized"
argument_list|)
expr_stmt|;
name|size
operator|=
name|round_page
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|mem
operator|=
operator|(
name|void
operator|*
operator|)
name|virtual_avail
expr_stmt|;
name|virtual_avail
operator|=
name|pmap_map
argument_list|(
name|virtual_avail
argument_list|,
name|avail_start
argument_list|,
name|avail_start
operator|+
name|size
argument_list|,
name|VM_PROT_READ
operator||
name|VM_PROT_WRITE
argument_list|)
expr_stmt|;
name|avail_start
operator|+=
name|size
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|void
operator|*
operator|)
name|mem
argument_list|,
name|size
argument_list|)
expr_stmt|;
return|return
operator|(
name|mem
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Initialize the pmap module.  */
end_comment

begin_function
name|void
name|pmap_init
parameter_list|(
name|phys_start
parameter_list|,
name|phys_end
parameter_list|)
specifier|register
name|vm_offset_t
name|phys_start
decl_stmt|,
name|phys_end
decl_stmt|;
block|{
specifier|register
name|vm_size_t
name|s
decl_stmt|;
if|if
condition|(
name|PAGE_SIZE
operator|!=
name|NBPG
condition|)
name|panic
argument_list|(
literal|"pmap_init: CLSIZE!=1"
argument_list|)
expr_stmt|;
comment|/* 	 * Allocate and clear memory for the pv_table. 	 */
name|s
operator|=
sizeof|sizeof
argument_list|(
expr|struct
name|pvlist
argument_list|)
operator|*
name|atop
argument_list|(
name|phys_end
operator|-
name|phys_start
argument_list|)
expr_stmt|;
name|s
operator|=
name|round_page
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|pv_table
operator|=
operator|(
expr|struct
name|pvlist
operator|*
operator|)
name|kmem_alloc
argument_list|(
name|kernel_map
argument_list|,
name|s
argument_list|)
expr_stmt|;
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|pv_table
argument_list|,
name|s
argument_list|)
expr_stmt|;
name|vm_first_phys
operator|=
name|phys_start
expr_stmt|;
name|vm_num_phys
operator|=
name|phys_end
operator|-
name|phys_start
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Map physical addresses into kernel VM.  */
end_comment

begin_function
name|vm_offset_t
name|pmap_map
parameter_list|(
name|va
parameter_list|,
name|pa
parameter_list|,
name|endpa
parameter_list|,
name|prot
parameter_list|)
specifier|register
name|vm_offset_t
name|va
decl_stmt|,
name|pa
decl_stmt|,
name|endpa
decl_stmt|;
specifier|register
name|int
name|prot
decl_stmt|;
block|{
specifier|register
name|int
name|pgsize
init|=
name|PAGE_SIZE
decl_stmt|;
while|while
condition|(
name|pa
operator|<
name|endpa
condition|)
block|{
name|pmap_enter
argument_list|(
name|kernel_pmap
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|prot
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|va
operator|+=
name|pgsize
expr_stmt|;
name|pa
operator|+=
name|pgsize
expr_stmt|;
block|}
return|return
operator|(
name|va
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Create and return a physical map.  *  * If size is nonzero, the map is useless. (ick)  */
end_comment

begin_function
name|struct
name|pmap
modifier|*
name|pmap_create
parameter_list|(
name|size
parameter_list|)
name|vm_size_t
name|size
decl_stmt|;
block|{
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
if|if
condition|(
name|size
condition|)
return|return
operator|(
name|NULL
operator|)
return|;
name|pm
operator|=
operator|(
expr|struct
name|pmap
operator|*
operator|)
name|malloc
argument_list|(
sizeof|sizeof
expr|*
name|pm
argument_list|,
name|M_VMPMAP
argument_list|,
name|M_WAITOK
argument_list|)
expr_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pmapdebug
operator|&
name|PDB_CREATE
condition|)
name|printf
argument_list|(
literal|"pmap_create: created %x\n"
argument_list|,
name|pm
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|pm
argument_list|,
sizeof|sizeof
expr|*
name|pm
argument_list|)
expr_stmt|;
name|pmap_pinit
argument_list|(
name|pm
argument_list|)
expr_stmt|;
return|return
operator|(
name|pm
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Initialize a preallocated and zeroed pmap structure,  * such as one in a vmspace structure.  */
end_comment

begin_function
name|void
name|pmap_pinit
parameter_list|(
name|pm
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
block|{
specifier|register
name|int
name|i
decl_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pmapdebug
operator|&
name|PDB_CREATE
condition|)
name|printf
argument_list|(
literal|"pmap_pinit(%x)\n"
argument_list|,
name|pm
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* pm->pm_ctx = NULL; */
name|simple_lock_init
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
name|pm
operator|->
name|pm_refcount
operator|=
literal|1
expr_stmt|;
comment|/* pm->pm_mmuforw = NULL; */
name|pm
operator|->
name|pm_mmuback
operator|=
operator|&
name|pm
operator|->
name|pm_mmuforw
expr_stmt|;
name|pm
operator|->
name|pm_segmap
operator|=
name|pm
operator|->
name|pm_rsegmap
expr_stmt|;
name|pm
operator|->
name|pm_pte
operator|=
name|pm
operator|->
name|pm_rpte
expr_stmt|;
name|pm
operator|->
name|pm_npte
operator|=
name|pm
operator|->
name|pm_rnpte
expr_stmt|;
for|for
control|(
name|i
operator|=
name|NUSEG
init|;
operator|--
name|i
operator|>=
literal|0
condition|;
control|)
name|pm
operator|->
name|pm_rsegmap
index|[
name|i
index|]
operator|=
name|seginval
expr_stmt|;
comment|/* bzero((caddr_t)pm->pm_rpte, sizeof pm->pm_rpte); */
comment|/* bzero((caddr_t)pm->pm_rnpte, sizeof pm->pm_rnpte); */
block|}
end_function

begin_comment
comment|/*  * Retire the given pmap from service.  * Should only be called if the map contains no valid mappings.  */
end_comment

begin_function
name|void
name|pmap_destroy
parameter_list|(
name|pm
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
block|{
name|int
name|count
decl_stmt|;
if|if
condition|(
name|pm
operator|==
name|NULL
condition|)
return|return;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pmapdebug
operator|&
name|PDB_DESTROY
condition|)
name|printf
argument_list|(
literal|"pmap_destroy(%x)\n"
argument_list|,
name|pm
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|simple_lock
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
name|count
operator|=
operator|--
name|pm
operator|->
name|pm_refcount
expr_stmt|;
name|simple_unlock
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
if|if
condition|(
name|count
operator|==
literal|0
condition|)
block|{
name|pmap_release
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|free
argument_list|(
operator|(
name|caddr_t
operator|)
name|pm
argument_list|,
name|M_VMPMAP
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Release any resources held by the given physical map.  * Called when a pmap initialized by pmap_pinit is being released.  */
end_comment

begin_function
name|void
name|pmap_release
parameter_list|(
name|pm
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
block|{
specifier|register
name|union
name|ctxinfo
modifier|*
name|c
decl_stmt|;
specifier|register
name|int
name|s
init|=
name|splpmap
argument_list|()
decl_stmt|;
comment|/* paranoia */
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pmapdebug
operator|&
name|PDB_DESTROY
condition|)
name|printf
argument_list|(
literal|"pmap_release(%x)\n"
argument_list|,
name|pm
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|pm
operator|->
name|pm_mmuforw
condition|)
name|panic
argument_list|(
literal|"pmap_release mmuforw"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|c
operator|=
name|pm
operator|->
name|pm_ctx
operator|)
operator|!=
name|NULL
condition|)
block|{
if|if
condition|(
name|pm
operator|->
name|pm_ctxnum
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_release: releasing kernel"
argument_list|)
expr_stmt|;
name|ctx_free
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Add a reference to the given pmap.  */
end_comment

begin_function
name|void
name|pmap_reference
parameter_list|(
name|pm
parameter_list|)
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
block|{
if|if
condition|(
name|pm
operator|!=
name|NULL
condition|)
block|{
name|simple_lock
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
name|pm
operator|->
name|pm_refcount
operator|++
expr_stmt|;
name|simple_unlock
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function_decl
specifier|static
name|int
name|pmap_rmk
parameter_list|(
name|struct
name|pmap
modifier|*
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_function_decl
specifier|static
name|int
name|pmap_rmu
parameter_list|(
name|struct
name|pmap
modifier|*
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
end_function_decl

begin_comment
comment|/*  * Remove the given range of mapping entries.  * The starting and ending addresses are already rounded to pages.  * Sheer lunacy: pmap_remove is often asked to remove nonexistent  * mappings.  */
end_comment

begin_function
name|void
name|pmap_remove
parameter_list|(
name|pm
parameter_list|,
name|va
parameter_list|,
name|endva
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|vm_offset_t
name|va
decl_stmt|,
name|endva
decl_stmt|;
block|{
specifier|register
name|vm_offset_t
name|nva
decl_stmt|;
specifier|register
name|int
name|vseg
decl_stmt|,
name|nleft
decl_stmt|,
name|s
decl_stmt|,
name|ctx
decl_stmt|;
specifier|register
name|int
function_decl|(
modifier|*
name|rm
function_decl|)
parameter_list|(
name|struct
name|pmap
modifier|*
parameter_list|,
name|vm_offset_t
parameter_list|,
name|vm_offset_t
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|,
name|int
parameter_list|)
function_decl|;
if|if
condition|(
name|pm
operator|==
name|NULL
condition|)
return|return;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pmapdebug
operator|&
name|PDB_REMOVE
condition|)
name|printf
argument_list|(
literal|"pmap_remove(%x, %x, %x)\n"
argument_list|,
name|pm
argument_list|,
name|va
argument_list|,
name|endva
argument_list|)
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|pm
operator|==
name|kernel_pmap
condition|)
block|{
comment|/* 		 * Removing from kernel address space. 		 */
name|rm
operator|=
name|pmap_rmk
expr_stmt|;
block|}
else|else
block|{
comment|/* 		 * Removing from user address space. 		 */
name|write_user_windows
argument_list|()
expr_stmt|;
name|rm
operator|=
name|pmap_rmu
expr_stmt|;
block|}
name|ctx
operator|=
name|getcontext
argument_list|()
expr_stmt|;
name|s
operator|=
name|splpmap
argument_list|()
expr_stmt|;
comment|/* XXX conservative */
name|simple_lock
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|va
operator|<
name|endva
condition|;
name|va
operator|=
name|nva
control|)
block|{
comment|/* do one virtual segment at a time */
name|vseg
operator|=
name|VA_VSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|nva
operator|=
name|VSTOVA
argument_list|(
name|vseg
operator|+
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|nva
operator|==
literal|0
operator|||
name|nva
operator|>
name|endva
condition|)
name|nva
operator|=
name|endva
expr_stmt|;
if|if
condition|(
operator|(
name|nleft
operator|=
name|pm
operator|->
name|pm_npte
index|[
name|vseg
index|]
operator|)
operator|!=
literal|0
condition|)
name|pm
operator|->
name|pm_npte
index|[
name|vseg
index|]
operator|=
call|(
modifier|*
name|rm
call|)
argument_list|(
name|pm
argument_list|,
name|va
argument_list|,
name|nva
argument_list|,
name|vseg
argument_list|,
name|nleft
argument_list|,
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
argument_list|)
expr_stmt|;
block|}
name|simple_unlock
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|setcontext
argument_list|(
name|ctx
argument_list|)
expr_stmt|;
block|}
end_function

begin_define
define|#
directive|define
name|perftest
end_define

begin_ifdef
ifdef|#
directive|ifdef
name|perftest
end_ifdef

begin_comment
comment|/* counters, one per possible length */
end_comment

begin_decl_stmt
name|int
name|rmk_vlen
index|[
name|NPTESG
operator|+
literal|1
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* virtual length per rmk() call */
end_comment

begin_decl_stmt
name|int
name|rmk_npg
index|[
name|NPTESG
operator|+
literal|1
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* n valid pages per rmk() call */
end_comment

begin_decl_stmt
name|int
name|rmk_vlendiff
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* # times npg != vlen */
end_comment

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * The following magic number was chosen because:  *	1. It is the same amount of work to cache_flush_page 4 pages  *	   as to cache_flush_segment 1 segment (so at 4 the cost of  *	   flush is the same).  *	2. Flushing extra pages is bad (causes cache not to work).  *	3. The current code, which malloc()s 5 pages for each process  *	   for a user vmspace/pmap, almost never touches all 5 of those  *	   pages.  */
end_comment

begin_define
define|#
directive|define
name|PMAP_RMK_MAGIC
value|5
end_define

begin_comment
comment|/* if> magic, use cache_flush_segment */
end_comment

begin_comment
comment|/*  * Remove a range contained within a single segment.  * These are egregiously complicated routines.  */
end_comment

begin_comment
comment|/* remove from kernel, return new nleft */
end_comment

begin_function
specifier|static
name|int
name|pmap_rmk
parameter_list|(
name|pm
parameter_list|,
name|va
parameter_list|,
name|endva
parameter_list|,
name|vseg
parameter_list|,
name|nleft
parameter_list|,
name|pmeg
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|vm_offset_t
name|va
decl_stmt|,
name|endva
decl_stmt|;
specifier|register
name|int
name|vseg
decl_stmt|,
name|nleft
decl_stmt|,
name|pmeg
decl_stmt|;
block|{
specifier|register
name|int
name|i
decl_stmt|,
name|tpte
decl_stmt|,
name|perpage
decl_stmt|,
name|npg
decl_stmt|;
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
ifdef|#
directive|ifdef
name|perftest
specifier|register
name|int
name|nvalid
decl_stmt|;
endif|#
directive|endif
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pmeg
operator|==
name|seginval
condition|)
name|panic
argument_list|(
literal|"pmap_rmk: not loaded"
argument_list|)
expr_stmt|;
if|if
condition|(
name|pm
operator|->
name|pm_ctx
operator|==
name|NULL
condition|)
name|panic
argument_list|(
literal|"pmap_rmk: lost context"
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|/* decide how to flush cache */
name|npg
operator|=
operator|(
name|endva
operator|-
name|va
operator|)
operator|>>
name|PGSHIFT
expr_stmt|;
if|if
condition|(
name|npg
operator|>
name|PMAP_RMK_MAGIC
condition|)
block|{
comment|/* flush the whole segment */
name|perpage
operator|=
literal|0
expr_stmt|;
ifdef|#
directive|ifdef
name|notdef
if|if
condition|(
name|vactype
operator|!=
name|VAC_NONE
condition|)
endif|#
directive|endif
name|cache_flush_segment
argument_list|(
name|vseg
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* flush each page individually; some never need flushing */
name|perpage
operator|=
literal|1
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|perftest
name|nvalid
operator|=
literal|0
expr_stmt|;
endif|#
directive|endif
while|while
condition|(
name|va
operator|<
name|endva
condition|)
block|{
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|va
operator|+=
name|PAGE_SIZE
expr_stmt|;
continue|continue;
block|}
name|pv
operator|=
name|NULL
expr_stmt|;
comment|/* if cacheable, flush page as needed */
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_NC
operator|)
operator|==
literal|0
condition|)
block|{
ifdef|#
directive|ifdef
name|perftest
name|nvalid
operator|++
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|perpage
condition|)
name|cache_flush_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_TYPE
operator|)
operator|==
name|PG_OBMEM
condition|)
block|{
name|i
operator|=
name|ptoa
argument_list|(
name|HWTOSW
argument_list|(
name|tpte
operator|&
name|PG_PFNUM
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|i
argument_list|)
condition|)
block|{
name|pv
operator|=
name|pvhead
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|pv
operator|->
name|pv_flags
operator||=
name|MR
argument_list|(
name|tpte
argument_list|)
expr_stmt|;
name|pv_unlink
argument_list|(
name|pv
argument_list|,
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
block|}
name|nleft
operator|--
expr_stmt|;
name|setpte
argument_list|(
name|va
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|va
operator|+=
name|NBPG
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|perftest
name|rmk_vlen
index|[
name|npg
index|]
operator|++
expr_stmt|;
name|rmk_npg
index|[
name|nvalid
index|]
operator|++
expr_stmt|;
if|if
condition|(
name|npg
operator|!=
name|nvalid
condition|)
name|rmk_vlendiff
operator|++
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * If the segment is all gone, remove it from everyone and 	 * free the MMU entry. 	 */
if|if
condition|(
name|nleft
operator|==
literal|0
condition|)
block|{
name|va
operator|=
name|VSTOVA
argument_list|(
name|vseg
argument_list|)
expr_stmt|;
comment|/* retract */
name|setsegmap
argument_list|(
name|va
argument_list|,
name|seginval
argument_list|)
expr_stmt|;
for|for
control|(
name|i
operator|=
name|ncontext
init|;
operator|--
name|i
operator|>
literal|0
condition|;
control|)
block|{
name|setcontext
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|setsegmap
argument_list|(
name|va
argument_list|,
name|seginval
argument_list|)
expr_stmt|;
block|}
name|me_free
argument_list|(
name|pm
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|nleft
operator|)
return|;
block|}
end_function

begin_ifdef
ifdef|#
directive|ifdef
name|perftest
end_ifdef

begin_comment
comment|/* as before but for pmap_rmu */
end_comment

begin_decl_stmt
name|int
name|rmu_vlen
index|[
name|NPTESG
operator|+
literal|1
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* virtual length per rmu() call */
end_comment

begin_decl_stmt
name|int
name|rmu_npg
index|[
name|NPTESG
operator|+
literal|1
index|]
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* n valid pages per rmu() call */
end_comment

begin_decl_stmt
name|int
name|rmu_vlendiff
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* # times npg != vlen */
end_comment

begin_decl_stmt
name|int
name|rmu_noflush
decl_stmt|;
end_decl_stmt

begin_comment
comment|/* # times rmu does not need to flush at all */
end_comment

begin_endif
endif|#
directive|endif
end_endif

begin_comment
comment|/*  * Just like pmap_rmk_magic, but we have a different threshold.  * Note that this may well deserve further tuning work.  */
end_comment

begin_define
define|#
directive|define
name|PMAP_RMU_MAGIC
value|4
end_define

begin_comment
comment|/* if> magic, use cache_flush_segment */
end_comment

begin_comment
comment|/* remove from user */
end_comment

begin_function
specifier|static
name|int
name|pmap_rmu
parameter_list|(
name|pm
parameter_list|,
name|va
parameter_list|,
name|endva
parameter_list|,
name|vseg
parameter_list|,
name|nleft
parameter_list|,
name|pmeg
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|vm_offset_t
name|va
decl_stmt|,
name|endva
decl_stmt|;
specifier|register
name|int
name|vseg
decl_stmt|,
name|nleft
decl_stmt|,
name|pmeg
decl_stmt|;
block|{
specifier|register
name|int
modifier|*
name|pte0
decl_stmt|,
name|i
decl_stmt|,
name|pteva
decl_stmt|,
name|tpte
decl_stmt|,
name|perpage
decl_stmt|,
name|npg
decl_stmt|;
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
ifdef|#
directive|ifdef
name|perftest
specifier|register
name|int
name|doflush
decl_stmt|,
name|nvalid
decl_stmt|;
endif|#
directive|endif
name|pte0
operator|=
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
expr_stmt|;
if|if
condition|(
name|pmeg
operator|==
name|seginval
condition|)
block|{
specifier|register
name|int
modifier|*
name|pte
init|=
name|pte0
operator|+
name|VA_VPG
argument_list|(
name|va
argument_list|)
decl_stmt|;
comment|/* 		 * PTEs are not in MMU.  Just invalidate software copies. 		 */
for|for
control|(
init|;
name|va
operator|<
name|endva
condition|;
name|pte
operator|++
operator|,
name|va
operator|+=
name|PAGE_SIZE
control|)
block|{
name|tpte
operator|=
operator|*
name|pte
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
comment|/* nothing to remove (braindead VM layer) */
continue|continue;
block|}
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_TYPE
operator|)
operator|==
name|PG_OBMEM
condition|)
block|{
name|i
operator|=
name|ptoa
argument_list|(
name|HWTOSW
argument_list|(
name|tpte
operator|&
name|PG_PFNUM
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|i
argument_list|)
condition|)
name|pv_unlink
argument_list|(
name|pvhead
argument_list|(
name|i
argument_list|)
argument_list|,
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
name|nleft
operator|--
expr_stmt|;
operator|*
name|pte
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|nleft
operator|==
literal|0
condition|)
block|{
name|free
argument_list|(
operator|(
name|caddr_t
operator|)
name|pte0
argument_list|,
name|M_VMPMAP
argument_list|)
expr_stmt|;
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
operator|=
name|NULL
expr_stmt|;
block|}
return|return
operator|(
name|nleft
operator|)
return|;
block|}
comment|/* 	 * PTEs are in MMU.  Invalidate in hardware, update ref& 	 * mod bits, and flush cache if required. 	 */
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
block|{
comment|/* process has a context, must flush cache */
name|npg
operator|=
operator|(
name|endva
operator|-
name|va
operator|)
operator|>>
name|PGSHIFT
expr_stmt|;
ifdef|#
directive|ifdef
name|perftest
name|doflush
operator|=
literal|1
expr_stmt|;
name|nvalid
operator|=
literal|0
expr_stmt|;
endif|#
directive|endif
name|setcontext
argument_list|(
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
if|if
condition|(
name|npg
operator|>
name|PMAP_RMU_MAGIC
condition|)
block|{
name|perpage
operator|=
literal|0
expr_stmt|;
comment|/* flush the whole segment */
ifdef|#
directive|ifdef
name|notdef
if|if
condition|(
name|vactype
operator|!=
name|VAC_NONE
condition|)
endif|#
directive|endif
name|cache_flush_segment
argument_list|(
name|vseg
argument_list|)
expr_stmt|;
block|}
else|else
name|perpage
operator|=
literal|1
expr_stmt|;
name|pteva
operator|=
name|va
expr_stmt|;
block|}
else|else
block|{
comment|/* no context, use context 0; cache flush unnecessary */
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|/* XXX use per-cpu pteva? */
name|setsegmap
argument_list|(
literal|0
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
name|pteva
operator|=
name|VA_VPG
argument_list|(
name|va
argument_list|)
operator|*
name|NBPG
expr_stmt|;
name|perpage
operator|=
literal|0
expr_stmt|;
ifdef|#
directive|ifdef
name|perftest
name|npg
operator|=
literal|0
expr_stmt|;
name|doflush
operator|=
literal|0
expr_stmt|;
name|nvalid
operator|=
literal|0
expr_stmt|;
name|rmu_noflush
operator|++
expr_stmt|;
endif|#
directive|endif
block|}
for|for
control|(
init|;
name|va
operator|<
name|endva
condition|;
name|pteva
operator|+=
name|PAGE_SIZE
operator|,
name|va
operator|+=
name|PAGE_SIZE
control|)
block|{
name|tpte
operator|=
name|getpte
argument_list|(
name|pteva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
continue|continue;
name|pv
operator|=
name|NULL
expr_stmt|;
comment|/* if cacheable, flush page as needed */
if|if
condition|(
name|doflush
operator|&&
operator|(
name|tpte
operator|&
name|PG_NC
operator|)
operator|==
literal|0
condition|)
block|{
ifdef|#
directive|ifdef
name|perftest
name|nvalid
operator|++
expr_stmt|;
endif|#
directive|endif
if|if
condition|(
name|perpage
condition|)
name|cache_flush_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_TYPE
operator|)
operator|==
name|PG_OBMEM
condition|)
block|{
name|i
operator|=
name|ptoa
argument_list|(
name|HWTOSW
argument_list|(
name|tpte
operator|&
name|PG_PFNUM
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|i
argument_list|)
condition|)
block|{
name|pv
operator|=
name|pvhead
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|pv
operator|->
name|pv_flags
operator||=
name|MR
argument_list|(
name|tpte
argument_list|)
expr_stmt|;
name|pv_unlink
argument_list|(
name|pv
argument_list|,
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
block|}
block|}
name|nleft
operator|--
expr_stmt|;
name|setpte
argument_list|(
name|pteva
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
ifdef|#
directive|ifdef
name|perftest
if|if
condition|(
name|doflush
condition|)
block|{
name|rmu_vlen
index|[
name|npg
index|]
operator|++
expr_stmt|;
name|rmu_npg
index|[
name|nvalid
index|]
operator|++
expr_stmt|;
if|if
condition|(
name|npg
operator|!=
name|nvalid
condition|)
name|rmu_vlendiff
operator|++
expr_stmt|;
block|}
endif|#
directive|endif
comment|/* 	 * If the segment is all gone, and the context is loaded, give 	 * the segment back. 	 */
if|if
condition|(
name|nleft
operator|==
literal|0
operator|&&
name|pm
operator|->
name|pm_ctx
operator|!=
name|NULL
condition|)
block|{
name|va
operator|=
name|VSTOVA
argument_list|(
name|vseg
argument_list|)
expr_stmt|;
comment|/* retract */
name|setsegmap
argument_list|(
name|va
argument_list|,
name|seginval
argument_list|)
expr_stmt|;
name|free
argument_list|(
operator|(
name|caddr_t
operator|)
name|pte0
argument_list|,
name|M_VMPMAP
argument_list|)
expr_stmt|;
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
operator|=
name|NULL
expr_stmt|;
name|me_free
argument_list|(
name|pm
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
block|}
return|return
operator|(
name|nleft
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Lower (make more strict) the protection on the specified  * physical page.  *  * There are only two cases: either the protection is going to 0  * (in which case we do the dirty work here), or it is going from  * to read-only (in which case pv_changepte does the trick).  */
end_comment

begin_function
name|void
name|pmap_page_protect
parameter_list|(
name|pa
parameter_list|,
name|prot
parameter_list|)
name|vm_offset_t
name|pa
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
block|{
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|,
modifier|*
name|pv0
decl_stmt|,
modifier|*
name|npv
decl_stmt|;
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|int
modifier|*
name|pte
decl_stmt|;
specifier|register
name|int
name|va
decl_stmt|,
name|vseg
decl_stmt|,
name|pteva
decl_stmt|,
name|tpte
decl_stmt|;
specifier|register
name|int
name|flags
decl_stmt|,
name|nleft
decl_stmt|,
name|i
decl_stmt|,
name|pmeg
decl_stmt|,
name|s
decl_stmt|,
name|ctx
decl_stmt|,
name|doflush
decl_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
operator|(
name|pmapdebug
operator|&
name|PDB_CHANGEPROT
operator|)
operator|||
operator|(
name|pmapdebug
operator|&
name|PDB_REMOVE
operator|&&
name|prot
operator|==
name|VM_PROT_NONE
operator|)
condition|)
name|printf
argument_list|(
literal|"pmap_page_protect(%x, %x)\n"
argument_list|,
name|pa
argument_list|,
name|prot
argument_list|)
expr_stmt|;
endif|#
directive|endif
comment|/* 	 * Skip unmanaged pages, or operations that do not take 	 * away write permission. 	 */
if|if
condition|(
operator|!
name|managed
argument_list|(
name|pa
argument_list|)
operator|||
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
return|return;
name|write_user_windows
argument_list|()
expr_stmt|;
comment|/* paranoia */
if|if
condition|(
name|prot
operator|&
name|VM_PROT_READ
condition|)
block|{
name|pv_changepte
argument_list|(
name|pvhead
argument_list|(
name|pa
argument_list|)
argument_list|,
literal|0
argument_list|,
name|PG_W
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 	 * Remove all access to all people talking to this page. 	 * Walk down PV list, removing all mappings. 	 * The logic is much like that for pmap_remove, 	 * but we know we are removing exactly one page. 	 */
name|pv
operator|=
name|pvhead
argument_list|(
name|pa
argument_list|)
expr_stmt|;
name|s
operator|=
name|splpmap
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|pm
operator|=
name|pv
operator|->
name|pv_pmap
operator|)
operator|==
name|NULL
condition|)
block|{
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
block|}
name|ctx
operator|=
name|getcontext
argument_list|()
expr_stmt|;
name|pv0
operator|=
name|pv
expr_stmt|;
name|flags
operator|=
name|pv
operator|->
name|pv_flags
operator|&
operator|~
name|PV_NC
expr_stmt|;
for|for
control|(
init|;
condition|;
name|pm
operator|=
name|pv
operator|->
name|pv_pmap
control|)
block|{
name|va
operator|=
name|pv
operator|->
name|pv_va
expr_stmt|;
name|vseg
operator|=
name|VA_VSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|nleft
operator|=
name|pm
operator|->
name|pm_npte
index|[
name|vseg
index|]
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_remove_all: empty vseg"
argument_list|)
expr_stmt|;
name|nleft
operator|--
expr_stmt|;
name|pm
operator|->
name|pm_npte
index|[
name|vseg
index|]
operator|=
name|nleft
expr_stmt|;
name|pmeg
operator|=
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
expr_stmt|;
name|pte
operator|=
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
expr_stmt|;
if|if
condition|(
name|pmeg
operator|==
name|seginval
condition|)
block|{
if|if
condition|(
name|nleft
condition|)
block|{
name|pte
operator|+=
name|VA_VPG
argument_list|(
name|va
argument_list|)
expr_stmt|;
operator|*
name|pte
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
name|free
argument_list|(
operator|(
name|caddr_t
operator|)
name|pte
argument_list|,
name|M_VMPMAP
argument_list|)
expr_stmt|;
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
operator|=
name|NULL
expr_stmt|;
block|}
goto|goto
name|nextpv
goto|;
block|}
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
block|{
name|setcontext
argument_list|(
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
name|pteva
operator|=
name|va
expr_stmt|;
ifdef|#
directive|ifdef
name|notdef
name|doflush
operator|=
name|vactype
operator|!=
name|VAC_NONE
expr_stmt|;
else|#
directive|else
name|doflush
operator|=
literal|1
expr_stmt|;
endif|#
directive|endif
block|}
else|else
block|{
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|/* XXX use per-cpu pteva? */
name|setsegmap
argument_list|(
literal|0
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
name|pteva
operator|=
name|VA_VPG
argument_list|(
name|va
argument_list|)
operator|*
name|NBPG
expr_stmt|;
name|doflush
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|nleft
condition|)
block|{
if|if
condition|(
name|doflush
condition|)
name|cache_flush_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|tpte
operator|=
name|getpte
argument_list|(
name|pteva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_page_protect !PG_V 1"
argument_list|)
expr_stmt|;
name|flags
operator||=
name|MR
argument_list|(
name|tpte
argument_list|)
expr_stmt|;
name|setpte
argument_list|(
name|pteva
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|doflush
condition|)
name|cache_flush_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|tpte
operator|=
name|getpte
argument_list|(
name|pteva
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_page_protect !PG_V 2"
argument_list|)
expr_stmt|;
name|flags
operator||=
name|MR
argument_list|(
name|tpte
argument_list|)
expr_stmt|;
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
block|{
name|setsegmap
argument_list|(
name|va
argument_list|,
name|seginval
argument_list|)
expr_stmt|;
if|if
condition|(
name|pm
operator|==
name|kernel_pmap
condition|)
block|{
for|for
control|(
name|i
operator|=
name|ncontext
init|;
operator|--
name|i
operator|>
literal|0
condition|;
control|)
block|{
name|setcontext
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|setsegmap
argument_list|(
name|va
argument_list|,
name|seginval
argument_list|)
expr_stmt|;
block|}
goto|goto
name|skipptefree
goto|;
block|}
block|}
name|free
argument_list|(
operator|(
name|caddr_t
operator|)
name|pte
argument_list|,
name|M_VMPMAP
argument_list|)
expr_stmt|;
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
operator|=
name|NULL
expr_stmt|;
name|skipptefree
label|:
name|me_free
argument_list|(
name|pm
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
block|}
name|nextpv
label|:
name|npv
operator|=
name|pv
operator|->
name|pv_next
expr_stmt|;
if|if
condition|(
name|pv
operator|!=
name|pv0
condition|)
name|free
argument_list|(
operator|(
name|caddr_t
operator|)
name|pv
argument_list|,
name|M_VMPVENT
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pv
operator|=
name|npv
operator|)
operator|==
name|NULL
condition|)
break|break;
block|}
name|pv0
operator|->
name|pv_pmap
operator|=
name|NULL
expr_stmt|;
name|pv0
operator|->
name|pv_flags
operator|=
name|flags
expr_stmt|;
name|setcontext
argument_list|(
name|ctx
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Lower (make more strict) the protection on the specified  * range of this pmap.  *  * There are only two cases: either the protection is going to 0  * (in which case we call pmap_remove to do the dirty work), or  * it is going from read/write to read-only.  The latter is  * fairly easy.  */
end_comment

begin_function
name|void
name|pmap_protect
parameter_list|(
name|pm
parameter_list|,
name|sva
parameter_list|,
name|eva
parameter_list|,
name|prot
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
name|vm_offset_t
name|sva
decl_stmt|,
name|eva
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
block|{
specifier|register
name|int
name|va
decl_stmt|,
name|nva
decl_stmt|,
name|vseg
decl_stmt|,
name|pteva
decl_stmt|,
name|pmeg
decl_stmt|;
specifier|register
name|int
name|s
decl_stmt|,
name|ctx
decl_stmt|;
if|if
condition|(
name|pm
operator|==
name|NULL
operator|||
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
return|return;
if|if
condition|(
operator|(
name|prot
operator|&
name|VM_PROT_READ
operator|)
operator|==
literal|0
condition|)
block|{
name|pmap_remove
argument_list|(
name|pm
argument_list|,
name|sva
argument_list|,
name|eva
argument_list|)
expr_stmt|;
return|return;
block|}
name|write_user_windows
argument_list|()
expr_stmt|;
name|ctx
operator|=
name|getcontext
argument_list|()
expr_stmt|;
name|s
operator|=
name|splpmap
argument_list|()
expr_stmt|;
name|simple_lock
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
for|for
control|(
name|va
operator|=
name|sva
init|;
name|va
operator|<
name|eva
condition|;
control|)
block|{
name|vseg
operator|=
name|VA_VSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|nva
operator|=
name|VSTOVA
argument_list|(
name|vseg
operator|+
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|nva
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_protect: last segment"
argument_list|)
expr_stmt|;
comment|/* cannot happen */
if|if
condition|(
name|nva
operator|>
name|eva
condition|)
name|nva
operator|=
name|eva
expr_stmt|;
if|if
condition|(
name|pm
operator|->
name|pm_npte
index|[
name|vseg
index|]
operator|==
literal|0
condition|)
block|{
name|va
operator|=
name|nva
expr_stmt|;
continue|continue;
block|}
name|pmeg
operator|=
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
expr_stmt|;
if|if
condition|(
name|pmeg
operator|==
name|seginval
condition|)
block|{
specifier|register
name|int
modifier|*
name|pte
init|=
operator|&
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
index|[
name|VA_VPG
argument_list|(
name|va
argument_list|)
index|]
decl_stmt|;
comment|/* not in MMU; just clear PG_W from core copies */
for|for
control|(
init|;
name|va
operator|<
name|nva
condition|;
name|va
operator|+=
name|NBPG
control|)
operator|*
name|pte
operator|++
operator|&=
operator|~
name|PG_W
expr_stmt|;
block|}
else|else
block|{
comment|/* in MMU: take away write bits from MMU PTEs */
if|if
condition|(
ifdef|#
directive|ifdef
name|notdef
name|vactype
operator|!=
name|VAC_NONE
operator|&&
endif|#
directive|endif
name|pm
operator|->
name|pm_ctx
condition|)
block|{
specifier|register
name|int
name|tpte
decl_stmt|;
comment|/* 				 * Flush cache so that any existing cache 				 * tags are updated.  This is really only 				 * needed for PTEs that lose PG_W. 				 */
name|setcontext
argument_list|(
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
for|for
control|(
init|;
name|va
operator|<
name|nva
condition|;
name|va
operator|+=
name|NBPG
control|)
block|{
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|pmap_stats
operator|.
name|ps_npg_prot_all
operator|++
expr_stmt|;
if|if
condition|(
name|tpte
operator|&
name|PG_W
condition|)
block|{
name|pmap_stats
operator|.
name|ps_npg_prot_actual
operator|++
expr_stmt|;
name|cache_flush_page
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|setpte
argument_list|(
name|va
argument_list|,
name|tpte
operator|&
operator|~
name|PG_W
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
specifier|register
name|int
name|pteva
decl_stmt|;
comment|/* 				 * No context, hence not cached; 				 * just update PTEs. 				 */
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|/* XXX use per-cpu pteva? */
name|setsegmap
argument_list|(
literal|0
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
name|pteva
operator|=
name|VA_VPG
argument_list|(
name|va
argument_list|)
operator|*
name|NBPG
expr_stmt|;
for|for
control|(
init|;
name|va
operator|<
name|nva
condition|;
name|pteva
operator|+=
name|NBPG
operator|,
name|va
operator|+=
name|NBPG
control|)
name|setpte
argument_list|(
name|pteva
argument_list|,
name|getpte
argument_list|(
name|pteva
argument_list|)
operator|&
operator|~
name|PG_W
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|simple_unlock
argument_list|(
operator|&
name|pm
operator|->
name|pm_lock
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Change the protection and/or wired status of the given (MI) virtual page.  * XXX: should have separate function (or flag) telling whether only wiring  * is changing.  */
end_comment

begin_function
name|void
name|pmap_changeprot
parameter_list|(
name|pm
parameter_list|,
name|va
parameter_list|,
name|prot
parameter_list|,
name|wired
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
specifier|register
name|vm_offset_t
name|va
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
name|int
name|wired
decl_stmt|;
block|{
specifier|register
name|int
name|vseg
decl_stmt|,
name|tpte
decl_stmt|,
name|newprot
decl_stmt|,
name|pmeg
decl_stmt|,
name|ctx
decl_stmt|,
name|i
decl_stmt|,
name|s
decl_stmt|;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pmapdebug
operator|&
name|PDB_CHANGEPROT
condition|)
name|printf
argument_list|(
literal|"pmap_changeprot(%x, %x, %x, %x)\n"
argument_list|,
name|pm
argument_list|,
name|va
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|write_user_windows
argument_list|()
expr_stmt|;
comment|/* paranoia */
if|if
condition|(
name|pm
operator|==
name|kernel_pmap
condition|)
name|newprot
operator|=
name|prot
operator|&
name|VM_PROT_WRITE
condition|?
name|PG_S
operator||
name|PG_W
else|:
name|PG_S
expr_stmt|;
else|else
name|newprot
operator|=
name|prot
operator|&
name|VM_PROT_WRITE
condition|?
name|PG_W
else|:
literal|0
expr_stmt|;
name|vseg
operator|=
name|VA_VSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|s
operator|=
name|splpmap
argument_list|()
expr_stmt|;
comment|/* conservative */
name|pmap_stats
operator|.
name|ps_changeprots
operator|++
expr_stmt|;
comment|/* update PTEs in software or hardware */
if|if
condition|(
operator|(
name|pmeg
operator|=
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
operator|)
operator|==
name|seginval
condition|)
block|{
specifier|register
name|int
modifier|*
name|pte
init|=
operator|&
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
index|[
name|VA_VPG
argument_list|(
name|va
argument_list|)
index|]
decl_stmt|;
comment|/* update in software */
if|if
condition|(
operator|(
operator|*
name|pte
operator|&
name|PG_PROT
operator|)
operator|==
name|newprot
condition|)
goto|goto
name|useless
goto|;
operator|*
name|pte
operator|=
operator|(
operator|*
name|pte
operator|&
operator|~
name|PG_PROT
operator|)
operator||
name|newprot
expr_stmt|;
block|}
else|else
block|{
comment|/* update in hardware */
name|ctx
operator|=
name|getcontext
argument_list|()
expr_stmt|;
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
block|{
comment|/* use current context; flush writeback cache */
name|setcontext
argument_list|(
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_PROT
operator|)
operator|==
name|newprot
condition|)
goto|goto
name|useless
goto|;
if|if
condition|(
name|vactype
operator|==
name|VAC_WRITEBACK
operator|&&
operator|(
name|newprot
operator|&
name|PG_W
operator|)
operator|==
literal|0
operator|&&
operator|(
name|tpte
operator|&
operator|(
name|PG_W
operator||
name|PG_NC
operator|)
operator|)
operator|==
name|PG_W
condition|)
name|cache_flush_page
argument_list|(
operator|(
name|int
operator|)
name|va
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|/* XXX use per-cpu va? */
name|setsegmap
argument_list|(
literal|0
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
name|va
operator|=
name|VA_VPG
argument_list|(
name|va
argument_list|)
operator|*
name|NBPG
expr_stmt|;
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_PROT
operator|)
operator|==
name|newprot
condition|)
goto|goto
name|useless
goto|;
block|}
name|tpte
operator|=
operator|(
name|tpte
operator|&
operator|~
name|PG_PROT
operator|)
operator||
name|newprot
expr_stmt|;
name|setpte
argument_list|(
name|va
argument_list|,
name|tpte
argument_list|)
expr_stmt|;
name|setcontext
argument_list|(
name|ctx
argument_list|)
expr_stmt|;
block|}
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
return|return;
name|useless
label|:
comment|/* only wiring changed, and we ignore wiring */
name|pmap_stats
operator|.
name|ps_useless_changeprots
operator|++
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Insert (MI) physical page pa at virtual address va in the given pmap.  * NB: the pa parameter includes type bits PMAP_OBIO, PMAP_NC as necessary.  *  * If pa is not in the `managed' range it will not be `bank mapped'.  * This works during bootstrap only because the first 4MB happens to  * map one-to-one.  *  * There may already be something else there, or we might just be  * changing protections and/or wiring on an existing mapping.  *	XXX	should have different entry points for changing!  */
end_comment

begin_function
name|void
name|pmap_enter
parameter_list|(
name|pm
parameter_list|,
name|va
parameter_list|,
name|pa
parameter_list|,
name|prot
parameter_list|,
name|wired
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|pa
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
name|int
name|wired
decl_stmt|;
block|{
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
specifier|register
name|int
name|pteproto
decl_stmt|,
name|ctx
decl_stmt|;
if|if
condition|(
name|pm
operator|==
name|NULL
condition|)
return|return;
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pmapdebug
operator|&
name|PDB_ENTER
condition|)
name|printf
argument_list|(
literal|"pmap_enter(%x, %x, %x, %x, %x)\n"
argument_list|,
name|pm
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|pteproto
operator|=
name|PG_V
operator||
operator|(
operator|(
name|pa
operator|&
name|PMAP_TNC
operator|)
operator|<<
name|PG_TNC_SHIFT
operator|)
expr_stmt|;
name|pa
operator|&=
operator|~
name|PMAP_TNC
expr_stmt|;
comment|/* 	 * Set up prototype for new PTE.  Cannot set PG_NC from PV_NC yet 	 * since the pvlist no-cache bit might change as a result of the 	 * new mapping. 	 */
if|if
condition|(
name|managed
argument_list|(
name|pa
argument_list|)
condition|)
block|{
name|pteproto
operator||=
name|SWTOHW
argument_list|(
name|atop
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
name|pv
operator|=
name|pvhead
argument_list|(
name|pa
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|pteproto
operator||=
name|atop
argument_list|(
name|pa
argument_list|)
operator|&
name|PG_PFNUM
expr_stmt|;
name|pv
operator|=
name|NULL
expr_stmt|;
block|}
if|if
condition|(
name|prot
operator|&
name|VM_PROT_WRITE
condition|)
name|pteproto
operator||=
name|PG_W
expr_stmt|;
name|ctx
operator|=
name|getcontext
argument_list|()
expr_stmt|;
if|if
condition|(
name|pm
operator|==
name|kernel_pmap
condition|)
name|pmap_enk
argument_list|(
name|pm
argument_list|,
name|va
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|,
name|pv
argument_list|,
name|pteproto
operator||
name|PG_S
argument_list|)
expr_stmt|;
else|else
name|pmap_enu
argument_list|(
name|pm
argument_list|,
name|va
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|,
name|pv
argument_list|,
name|pteproto
argument_list|)
expr_stmt|;
name|setcontext
argument_list|(
name|ctx
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/* enter new (or change existing) kernel mapping */
end_comment

begin_expr_stmt
name|pmap_enk
argument_list|(
name|pm
argument_list|,
name|va
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|,
name|pv
argument_list|,
name|pteproto
argument_list|)
specifier|register
expr|struct
name|pmap
operator|*
name|pm
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|vm_offset_t
name|va
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_prot_t
name|prot
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|wired
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|register
name|int
name|pteproto
decl_stmt|;
end_decl_stmt

begin_block
block|{
specifier|register
name|int
name|vseg
decl_stmt|,
name|tpte
decl_stmt|,
name|pmeg
decl_stmt|,
name|i
decl_stmt|,
name|s
decl_stmt|;
name|vseg
operator|=
name|VA_VSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|s
operator|=
name|splpmap
argument_list|()
expr_stmt|;
comment|/* XXX way too conservative */
if|if
condition|(
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
operator|!=
name|seginval
operator|&&
operator|(
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
operator|)
operator|&
name|PG_V
condition|)
block|{
specifier|register
name|int
name|addr
init|=
name|tpte
operator|&
name|PG_PFNUM
decl_stmt|;
comment|/* old mapping exists */
if|if
condition|(
name|addr
operator|==
operator|(
name|pteproto
operator|&
name|PG_PFNUM
operator|)
condition|)
block|{
comment|/* just changing protection and/or wiring */
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|pmap_changeprot
argument_list|(
name|pm
argument_list|,
name|va
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/*printf("pmap_enk: changing existing va=>pa entry\n");*/
comment|/* 		 * Switcheroo: changing pa for this va. 		 * If old pa was managed, remove from pvlist. 		 * If old page was cached, flush cache. 		 */
name|addr
operator|=
name|ptoa
argument_list|(
name|HWTOSW
argument_list|(
name|addr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|addr
argument_list|)
condition|)
name|pv_unlink
argument_list|(
name|pvhead
argument_list|(
name|addr
argument_list|)
argument_list|,
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
ifdef|#
directive|ifdef
name|notdef
name|vactype
operator|!=
name|VAC_NONE
operator|&&
endif|#
directive|endif
operator|(
name|tpte
operator|&
name|PG_NC
operator|)
operator|==
literal|0
condition|)
block|{
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|/* ??? */
name|cache_flush_page
argument_list|(
operator|(
name|int
operator|)
name|va
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|/* adding new entry */
name|pm
operator|->
name|pm_npte
index|[
name|vseg
index|]
operator|++
expr_stmt|;
block|}
comment|/* 	 * If the new mapping is for a managed PA, enter into pvlist. 	 * Note that the mapping for a malloc page will always be 	 * unique (hence will never cause a second call to malloc). 	 */
if|if
condition|(
name|pv
operator|!=
name|NULL
condition|)
name|pteproto
operator||=
name|pv_link
argument_list|(
name|pv
argument_list|,
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
name|pmeg
operator|=
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
expr_stmt|;
if|if
condition|(
name|pmeg
operator|==
name|seginval
condition|)
block|{
specifier|register
name|int
name|tva
decl_stmt|;
comment|/* 		 * Allocate an MMU entry now (on locked list), 		 * and map it into every context.  Set all its 		 * PTEs invalid (we will then overwrite one, but 		 * this is more efficient than looping twice). 		 */
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pm
operator|->
name|pm_ctx
operator|==
name|NULL
operator|||
name|pm
operator|->
name|pm_ctxnum
operator|!=
literal|0
condition|)
name|panic
argument_list|(
literal|"pmap_enk: kern seg but no kern ctx"
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|pmeg
operator|=
name|me_alloc
argument_list|(
operator|&
name|me_locked
argument_list|,
name|pm
argument_list|,
name|vseg
argument_list|)
operator|->
name|me_pmeg
expr_stmt|;
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
operator|=
name|pmeg
expr_stmt|;
name|i
operator|=
name|ncontext
operator|-
literal|1
expr_stmt|;
do|do
block|{
name|setcontext
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|setsegmap
argument_list|(
name|va
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
operator|--
name|i
operator|>=
literal|0
condition|)
do|;
comment|/* set all PTEs to invalid, then overwrite one PTE below */
name|tva
operator|=
name|VA_ROUNDDOWNTOSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|i
operator|=
name|NPTESG
expr_stmt|;
do|do
block|{
name|setpte
argument_list|(
name|tva
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|tva
operator|+=
name|NBPG
expr_stmt|;
block|}
do|while
condition|(
operator|--
name|i
operator|>
literal|0
condition|)
do|;
block|}
comment|/* ptes kept in hardware only */
name|setpte
argument_list|(
name|va
argument_list|,
name|pteproto
argument_list|)
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_block

begin_comment
comment|/* enter new (or change existing) user mapping */
end_comment

begin_expr_stmt
name|pmap_enu
argument_list|(
name|pm
argument_list|,
name|va
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|,
name|pv
argument_list|,
name|pteproto
argument_list|)
specifier|register
expr|struct
name|pmap
operator|*
name|pm
expr_stmt|;
end_expr_stmt

begin_decl_stmt
name|vm_offset_t
name|va
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_prot_t
name|prot
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|int
name|wired
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
end_decl_stmt

begin_decl_stmt
specifier|register
name|int
name|pteproto
decl_stmt|;
end_decl_stmt

begin_block
block|{
specifier|register
name|int
name|vseg
decl_stmt|,
modifier|*
name|pte
decl_stmt|,
name|tpte
decl_stmt|,
name|pmeg
decl_stmt|,
name|i
decl_stmt|,
name|s
decl_stmt|,
name|doflush
decl_stmt|;
name|write_user_windows
argument_list|()
expr_stmt|;
comment|/* XXX conservative */
name|vseg
operator|=
name|VA_VSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|s
operator|=
name|splpmap
argument_list|()
expr_stmt|;
comment|/* XXX conservative */
comment|/* 	 * If there is no space in which the PTEs can be written 	 * while they are not in the hardware, this must be a new 	 * virtual segment.  Get PTE space and count the segment. 	 * 	 * TO SPEED UP CTX ALLOC, PUT SEGMENT BOUNDS STUFF HERE 	 * AND IN pmap_rmu() 	 */
name|retry
label|:
name|pte
operator|=
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
expr_stmt|;
if|if
condition|(
name|pte
operator|==
name|NULL
condition|)
block|{
comment|/* definitely a new mapping */
specifier|register
name|int
name|size
init|=
name|NPTESG
operator|*
sizeof|sizeof
expr|*
name|pte
decl_stmt|;
name|pte
operator|=
operator|(
name|int
operator|*
operator|)
name|malloc
argument_list|(
operator|(
name|u_long
operator|)
name|size
argument_list|,
name|M_VMPMAP
argument_list|,
name|M_WAITOK
argument_list|)
expr_stmt|;
if|if
condition|(
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
operator|!=
name|NULL
condition|)
block|{
name|printf
argument_list|(
literal|"pmap_enter: pte filled during sleep\n"
argument_list|)
expr_stmt|;
comment|/* can this happen? */
name|free
argument_list|(
operator|(
name|caddr_t
operator|)
name|pte
argument_list|,
name|M_VMPMAP
argument_list|)
expr_stmt|;
goto|goto
name|retry
goto|;
block|}
ifdef|#
directive|ifdef
name|DEBUG
if|if
condition|(
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
operator|!=
name|seginval
condition|)
name|panic
argument_list|(
literal|"pmap_enter: new ptes, but not seginval"
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|bzero
argument_list|(
operator|(
name|caddr_t
operator|)
name|pte
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
operator|=
name|pte
expr_stmt|;
name|pm
operator|->
name|pm_npte
index|[
name|vseg
index|]
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
comment|/* might be a change: fetch old pte */
name|doflush
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|(
name|pmeg
operator|=
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
operator|)
operator|==
name|seginval
condition|)
name|tpte
operator|=
name|pte
index|[
name|VA_VPG
argument_list|(
name|va
argument_list|)
index|]
expr_stmt|;
comment|/* software pte */
else|else
block|{
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
block|{
comment|/* hardware pte */
name|setcontext
argument_list|(
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
name|doflush
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|/* XXX use per-cpu pteva? */
name|setsegmap
argument_list|(
literal|0
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
name|tpte
operator|=
name|getpte
argument_list|(
name|VA_VPG
argument_list|(
name|va
argument_list|)
operator|*
name|NBPG
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|tpte
operator|&
name|PG_V
condition|)
block|{
specifier|register
name|int
name|addr
init|=
name|tpte
operator|&
name|PG_PFNUM
decl_stmt|;
comment|/* old mapping exists */
if|if
condition|(
name|addr
operator|==
operator|(
name|pteproto
operator|&
name|PG_PFNUM
operator|)
condition|)
block|{
comment|/* just changing prot and/or wiring */
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
comment|/* caller should call this directly: */
name|pmap_changeprot
argument_list|(
name|pm
argument_list|,
name|va
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/* 			 * Switcheroo: changing pa for this va. 			 * If old pa was managed, remove from pvlist. 			 * If old page was cached, flush cache. 			 */
comment|/*printf("%s[%d]: pmap_enu: changing existing va(%x)=>pa entry\n", curproc->p_comm, curproc->p_pid, va);*/
name|addr
operator|=
name|ptoa
argument_list|(
name|HWTOSW
argument_list|(
name|addr
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|addr
argument_list|)
condition|)
name|pv_unlink
argument_list|(
name|pvhead
argument_list|(
name|addr
argument_list|)
argument_list|,
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
ifdef|#
directive|ifdef
name|notdef
name|vactype
operator|!=
name|VAC_NONE
operator|&&
endif|#
directive|endif
name|doflush
operator|&&
operator|(
name|tpte
operator|&
name|PG_NC
operator|)
operator|==
literal|0
condition|)
name|cache_flush_page
argument_list|(
operator|(
name|int
operator|)
name|va
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|/* adding new entry */
name|pm
operator|->
name|pm_npte
index|[
name|vseg
index|]
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pv
operator|!=
name|NULL
condition|)
name|pteproto
operator||=
name|pv_link
argument_list|(
name|pv
argument_list|,
name|pm
argument_list|,
name|va
argument_list|)
expr_stmt|;
comment|/* 	 * Update hardware or software PTEs (whichever are active). 	 */
if|if
condition|(
operator|(
name|pmeg
operator|=
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
operator|)
operator|!=
name|seginval
condition|)
block|{
comment|/* ptes are in hardare */
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
name|setcontext
argument_list|(
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
else|else
block|{
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|/* XXX use per-cpu pteva? */
name|setsegmap
argument_list|(
literal|0
argument_list|,
name|pmeg
argument_list|)
expr_stmt|;
name|va
operator|=
name|VA_VPG
argument_list|(
name|va
argument_list|)
operator|*
name|NBPG
expr_stmt|;
block|}
name|setpte
argument_list|(
name|va
argument_list|,
name|pteproto
argument_list|)
expr_stmt|;
block|}
comment|/* update software copy */
name|pte
operator|+=
name|VA_VPG
argument_list|(
name|va
argument_list|)
expr_stmt|;
operator|*
name|pte
operator|=
name|pteproto
expr_stmt|;
name|splx
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
end_block

begin_comment
comment|/*  * Change the wiring attribute for a map/virtual-address pair.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
name|void
name|pmap_change_wiring
parameter_list|(
name|pm
parameter_list|,
name|va
parameter_list|,
name|wired
parameter_list|)
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
name|int
name|wired
decl_stmt|;
block|{
name|pmap_stats
operator|.
name|ps_useless_changewire
operator|++
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Extract the physical page address associated  * with the given map/virtual_address pair.  * GRR, the vm code knows; we should not have to do this!  */
end_comment

begin_function
name|vm_offset_t
name|pmap_extract
parameter_list|(
name|pm
parameter_list|,
name|va
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|;
block|{
specifier|register
name|int
name|tpte
decl_stmt|;
specifier|register
name|int
name|vseg
decl_stmt|;
if|if
condition|(
name|pm
operator|==
name|NULL
condition|)
block|{
name|printf
argument_list|(
literal|"pmap_extract: null pmap\n"
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|vseg
operator|=
name|VA_VSEG
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
name|pm
operator|->
name|pm_segmap
index|[
name|vseg
index|]
operator|!=
name|seginval
condition|)
block|{
specifier|register
name|int
name|ctx
init|=
name|getcontext
argument_list|()
decl_stmt|;
if|if
condition|(
name|pm
operator|->
name|pm_ctx
condition|)
block|{
name|setcontext
argument_list|(
name|pm
operator|->
name|pm_ctxnum
argument_list|)
expr_stmt|;
name|tpte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|setcontext
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|tpte
operator|=
name|getpte
argument_list|(
name|VA_VPG
argument_list|(
name|va
argument_list|)
operator|*
name|NBPG
argument_list|)
expr_stmt|;
block|}
name|setcontext
argument_list|(
name|ctx
argument_list|)
expr_stmt|;
block|}
else|else
block|{
specifier|register
name|int
modifier|*
name|pte
init|=
name|pm
operator|->
name|pm_pte
index|[
name|vseg
index|]
decl_stmt|;
if|if
condition|(
name|pte
operator|==
name|NULL
condition|)
block|{
name|printf
argument_list|(
literal|"pmap_extract: invalid vseg\n"
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|tpte
operator|=
name|pte
index|[
name|VA_VPG
argument_list|(
name|va
argument_list|)
index|]
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|tpte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
block|{
name|printf
argument_list|(
literal|"pmap_extract: invalid pte\n"
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
name|tpte
operator|&=
name|PG_PFNUM
expr_stmt|;
name|tpte
operator|=
name|HWTOSW
argument_list|(
name|tpte
argument_list|)
expr_stmt|;
return|return
operator|(
operator|(
name|tpte
operator|<<
name|PGSHIFT
operator|)
operator||
operator|(
name|va
operator|&
name|PGOFSET
operator|)
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Copy the range specified by src_addr/len  * from the source map to the range dst_addr/len  * in the destination map.  *  * This routine is only advisory and need not do anything.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
name|void
name|pmap_copy
parameter_list|(
name|dst_pmap
parameter_list|,
name|src_pmap
parameter_list|,
name|dst_addr
parameter_list|,
name|len
parameter_list|,
name|src_addr
parameter_list|)
name|struct
name|pmap
modifier|*
name|dst_pmap
decl_stmt|,
decl|*
name|src_pmap
decl_stmt|;
end_function

begin_decl_stmt
name|vm_offset_t
name|dst_addr
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_size_t
name|len
decl_stmt|;
end_decl_stmt

begin_decl_stmt
name|vm_offset_t
name|src_addr
decl_stmt|;
end_decl_stmt

begin_block
block|{ }
end_block

begin_comment
comment|/*  * Require that all active physical maps contain no  * incorrect entries NOW.  [This update includes  * forcing updates of any address map caching.]  */
end_comment

begin_function
name|void
name|pmap_update
parameter_list|()
block|{ }
end_function

begin_comment
comment|/*  * Garbage collects the physical map system for  * pages which are no longer used.  * Success need not be guaranteed -- that is, there  * may well be pages which are not referenced, but  * others may be collected.  * Called by the pageout daemon when pages are scarce.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
name|void
name|pmap_collect
parameter_list|(
name|pm
parameter_list|)
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
block|{ }
end_function

begin_comment
comment|/*  * Clear the modify bit for the given physical page.  */
end_comment

begin_function
name|void
name|pmap_clear_modify
parameter_list|(
name|pa
parameter_list|)
specifier|register
name|vm_offset_t
name|pa
decl_stmt|;
block|{
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|pa
argument_list|)
condition|)
block|{
name|pv
operator|=
name|pvhead
argument_list|(
name|pa
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|pv_syncflags
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|pv
operator|->
name|pv_flags
operator|&=
operator|~
name|PV_MOD
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Tell whether the given physical page has been modified.  */
end_comment

begin_function
name|int
name|pmap_is_modified
parameter_list|(
name|pa
parameter_list|)
specifier|register
name|vm_offset_t
name|pa
decl_stmt|;
block|{
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|pa
argument_list|)
condition|)
block|{
name|pv
operator|=
name|pvhead
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv
operator|->
name|pv_flags
operator|&
name|PV_MOD
operator|||
name|pv_syncflags
argument_list|(
name|pv
argument_list|)
operator|&
name|PV_MOD
condition|)
return|return
operator|(
literal|1
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Clear the reference bit for the given physical page.  */
end_comment

begin_function
name|void
name|pmap_clear_reference
parameter_list|(
name|pa
parameter_list|)
name|vm_offset_t
name|pa
decl_stmt|;
block|{
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|pa
argument_list|)
condition|)
block|{
name|pv
operator|=
name|pvhead
argument_list|(
name|pa
argument_list|)
expr_stmt|;
operator|(
name|void
operator|)
name|pv_syncflags
argument_list|(
name|pv
argument_list|)
expr_stmt|;
name|pv
operator|->
name|pv_flags
operator|&=
operator|~
name|PV_REF
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*  * Tell whether the given physical page has been referenced.  */
end_comment

begin_function
name|int
name|pmap_is_referenced
parameter_list|(
name|pa
parameter_list|)
name|vm_offset_t
name|pa
decl_stmt|;
block|{
specifier|register
name|struct
name|pvlist
modifier|*
name|pv
decl_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|pa
argument_list|)
condition|)
block|{
name|pv
operator|=
name|pvhead
argument_list|(
name|pa
argument_list|)
expr_stmt|;
if|if
condition|(
name|pv
operator|->
name|pv_flags
operator|&
name|PV_REF
operator|||
name|pv_syncflags
argument_list|(
name|pv
argument_list|)
operator|&
name|PV_REF
condition|)
return|return
operator|(
literal|1
operator|)
return|;
block|}
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Make the specified pages (by pmap, offset) pageable (or not) as requested.  *  * A page which is not pageable may not take a fault; therefore, its page  * table entry must remain valid for the duration (or at least, the trap  * handler must not call vm_fault).  *  * This routine is merely advisory; pmap_enter will specify that these pages  * are to be wired down (or not) as appropriate.  */
end_comment

begin_comment
comment|/* ARGSUSED */
end_comment

begin_function
name|void
name|pmap_pageable
parameter_list|(
name|pm
parameter_list|,
name|start
parameter_list|,
name|end
parameter_list|,
name|pageable
parameter_list|)
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
name|vm_offset_t
name|start
decl_stmt|,
name|end
decl_stmt|;
name|int
name|pageable
decl_stmt|;
block|{ }
end_function

begin_comment
comment|/*  * Fill the given MI physical page with zero bytes.  *  * We avoid stomping on the cache.  * XXX	might be faster to use destination's context and allow cache to fill?  */
end_comment

begin_function
name|void
name|pmap_zero_page
parameter_list|(
name|pa
parameter_list|)
specifier|register
name|vm_offset_t
name|pa
decl_stmt|;
block|{
specifier|register
name|caddr_t
name|va
decl_stmt|;
specifier|register
name|int
name|pte
decl_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|pa
argument_list|)
condition|)
block|{
comment|/* 		 * The following might not be necessary since the page 		 * is being cleared because it is about to be allocated, 		 * i.e., is in use by no one. 		 */
if|#
directive|if
literal|1
ifdef|#
directive|ifdef
name|notdef
if|if
condition|(
name|vactype
operator|!=
name|VAC_NONE
condition|)
endif|#
directive|endif
name|pv_flushcache
argument_list|(
name|pvhead
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|pte
operator|=
name|PG_V
operator||
name|PG_S
operator||
name|PG_W
operator||
name|PG_NC
operator||
name|SWTOHW
argument_list|(
name|atop
argument_list|(
name|pa
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
name|pte
operator|=
name|PG_V
operator||
name|PG_S
operator||
name|PG_W
operator||
name|PG_NC
operator||
operator|(
name|atop
argument_list|(
name|pa
argument_list|)
operator|&
name|PG_PFNUM
operator|)
expr_stmt|;
name|va
operator|=
name|vpage
index|[
literal|0
index|]
expr_stmt|;
name|setpte
argument_list|(
name|va
argument_list|,
name|pte
argument_list|)
expr_stmt|;
name|qzero
argument_list|(
name|va
argument_list|,
name|NBPG
argument_list|)
expr_stmt|;
name|setpte
argument_list|(
name|va
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Copy the given MI physical source page to its destination.  *  * We avoid stomping on the cache as above (with same `XXX' note).  * We must first flush any write-back cache for the source page.  * We go ahead and stomp on the kernel's virtual cache for the  * source page, since the cache can read memory MUCH faster than  * the processor.  */
end_comment

begin_function
name|void
name|pmap_copy_page
parameter_list|(
name|src
parameter_list|,
name|dst
parameter_list|)
name|vm_offset_t
name|src
decl_stmt|,
name|dst
decl_stmt|;
block|{
specifier|register
name|caddr_t
name|sva
decl_stmt|,
name|dva
decl_stmt|;
specifier|register
name|int
name|spte
decl_stmt|,
name|dpte
decl_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|src
argument_list|)
condition|)
block|{
if|if
condition|(
name|vactype
operator|==
name|VAC_WRITEBACK
condition|)
name|pv_flushcache
argument_list|(
name|pvhead
argument_list|(
name|src
argument_list|)
argument_list|)
expr_stmt|;
name|spte
operator|=
name|PG_V
operator||
name|PG_S
operator||
name|SWTOHW
argument_list|(
name|atop
argument_list|(
name|src
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
name|spte
operator|=
name|PG_V
operator||
name|PG_S
operator||
operator|(
name|atop
argument_list|(
name|src
argument_list|)
operator|&
name|PG_PFNUM
operator|)
expr_stmt|;
if|if
condition|(
name|managed
argument_list|(
name|dst
argument_list|)
condition|)
block|{
comment|/* similar `might not be necessary' comment applies */
if|#
directive|if
literal|1
ifdef|#
directive|ifdef
name|notdef
if|if
condition|(
name|vactype
operator|!=
name|VAC_NONE
condition|)
endif|#
directive|endif
name|pv_flushcache
argument_list|(
name|pvhead
argument_list|(
name|dst
argument_list|)
argument_list|)
expr_stmt|;
endif|#
directive|endif
name|dpte
operator|=
name|PG_V
operator||
name|PG_S
operator||
name|PG_W
operator||
name|PG_NC
operator||
name|SWTOHW
argument_list|(
name|atop
argument_list|(
name|dst
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
name|dpte
operator|=
name|PG_V
operator||
name|PG_S
operator||
name|PG_W
operator||
name|PG_NC
operator||
operator|(
name|atop
argument_list|(
name|dst
argument_list|)
operator|&
name|PG_PFNUM
operator|)
expr_stmt|;
name|sva
operator|=
name|vpage
index|[
literal|0
index|]
expr_stmt|;
name|dva
operator|=
name|vpage
index|[
literal|1
index|]
expr_stmt|;
name|setpte
argument_list|(
name|sva
argument_list|,
name|spte
argument_list|)
expr_stmt|;
name|setpte
argument_list|(
name|dva
argument_list|,
name|dpte
argument_list|)
expr_stmt|;
name|qcopy
argument_list|(
name|sva
argument_list|,
name|dva
argument_list|,
name|NBPG
argument_list|)
expr_stmt|;
comment|/* loads cache, so we must ... */
name|cache_flush_page
argument_list|(
operator|(
name|int
operator|)
name|sva
argument_list|)
expr_stmt|;
name|setpte
argument_list|(
name|sva
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|setpte
argument_list|(
name|dva
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/*  * Turn a cdevsw d_mmap value into a byte address for pmap_enter.  * XXX	this should almost certainly be done differently, and  *	elsewhere, or even not at all  */
end_comment

begin_function
name|vm_offset_t
name|pmap_phys_address
parameter_list|(
name|x
parameter_list|)
name|int
name|x
decl_stmt|;
block|{
return|return
operator|(
name|x
operator|)
return|;
block|}
end_function

begin_comment
comment|/*  * Turn off cache for a given (va, number of pages).  *  * We just assert PG_NC for each PTE; the addresses must reside  * in locked kernel space.  A cache flush is also done.  */
end_comment

begin_expr_stmt
name|kvm_uncache
argument_list|(
name|va
argument_list|,
name|npages
argument_list|)
specifier|register
name|caddr_t
name|va
expr_stmt|;
end_expr_stmt

begin_decl_stmt
specifier|register
name|int
name|npages
decl_stmt|;
end_decl_stmt

begin_block
block|{
specifier|register
name|int
name|pte
decl_stmt|;
for|for
control|(
init|;
operator|--
name|npages
operator|>=
literal|0
condition|;
name|va
operator|+=
name|NBPG
control|)
block|{
name|pte
operator|=
name|getpte
argument_list|(
name|va
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|pte
operator|&
name|PG_V
operator|)
operator|==
literal|0
condition|)
name|panic
argument_list|(
literal|"kvm_uncache !pg_v"
argument_list|)
expr_stmt|;
name|pte
operator||=
name|PG_NC
expr_stmt|;
name|setpte
argument_list|(
name|va
argument_list|,
name|pte
argument_list|)
expr_stmt|;
name|cache_flush_page
argument_list|(
operator|(
name|int
operator|)
name|va
argument_list|)
expr_stmt|;
block|}
block|}
end_block

begin_comment
comment|/*  * For /dev/mem.  */
end_comment

begin_function
name|int
name|pmap_enter_hw
parameter_list|(
name|pm
parameter_list|,
name|va
parameter_list|,
name|pa
parameter_list|,
name|prot
parameter_list|,
name|wired
parameter_list|)
specifier|register
name|struct
name|pmap
modifier|*
name|pm
decl_stmt|;
name|vm_offset_t
name|va
decl_stmt|,
name|pa
decl_stmt|;
name|vm_prot_t
name|prot
decl_stmt|;
name|int
name|wired
decl_stmt|;
block|{
specifier|register
name|struct
name|memarr
modifier|*
name|ma
decl_stmt|;
specifier|register
name|int
name|n
decl_stmt|;
specifier|register
name|u_int
name|t
decl_stmt|;
if|if
condition|(
name|pa
operator|>=
name|MAXMEM
condition|)
comment|/* ??? */
return|return
operator|(
name|EFAULT
operator|)
return|;
for|for
control|(
name|ma
operator|=
name|pmemarr
operator|,
name|n
operator|=
name|npmemarr
init|;
operator|--
name|n
operator|>=
literal|0
condition|;
name|ma
operator|++
control|)
block|{
name|t
operator|=
operator|(
name|u_int
operator|)
name|pa
operator|-
name|ma
operator|->
name|addr
expr_stmt|;
if|if
condition|(
name|t
operator|<
name|ma
operator|->
name|len
condition|)
goto|goto
name|ok
goto|;
block|}
return|return
operator|(
name|EFAULT
operator|)
return|;
name|ok
label|:
name|pa
operator|=
operator|(
name|HWTOSW
argument_list|(
name|atop
argument_list|(
name|pa
argument_list|)
argument_list|)
operator|<<
name|PGSHIFT
operator|)
operator||
operator|(
name|pa
operator|&
name|PGOFSET
operator|)
expr_stmt|;
if|if
condition|(
name|pa
operator|>=
name|vm_first_phys
operator|+
name|vm_num_phys
condition|)
comment|/* ??? */
return|return
operator|(
name|EFAULT
operator|)
return|;
name|pmap_enter
argument_list|(
name|pm
argument_list|,
name|va
argument_list|,
name|pa
argument_list|,
name|prot
argument_list|,
name|wired
argument_list|)
expr_stmt|;
return|return
operator|(
literal|0
operator|)
return|;
block|}
end_function

end_unit

